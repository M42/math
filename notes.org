#+TITLE: Math Notes
#+AUTHOR: Mario Román
#+EMAIL: mromang08@gmail.com
#+OPTIONS: num:nil broken-links:mark
#+LANGUAGE: es
#+STARTUP: indent
#+SETUPFILE: math.setup
#+SETUPFILE: html.setup

* Papers & articles
** TODO Dependent types at work - Ana Bove, Peter Dybjer
*** 1. What are dependent types?
*** 2. Simply Typed Functional Programming in Agda
**** 2.1. Truth Values
**** 2.2. Natural numbers
***** Notion of Inductive type
      /Recursive types/ in Haskell are *inductive types* in constructive type
      theory.
***** Notion of Canonical form
      Elements on canonical form are built up by constructors only. They do not
      contain defined functions. Martin-Löf considers /lazy canonical forms/, where
      it suffices to begin with a constructor:

      #+BEGIN_SRC haskell
      Zero * Zero        -- Not a canonical form
      Succ (Zero + Zero) -- Lazy canonical form
      Succ (Succ Zero)   -- Canonical form
      #+END_SRC
      
**** 2.3. Lambda Notation and Polymorphism
     In Agda we have no type variables, we have families of functions:

     #+BEGIN_SRC 
     id : (A : Set) -> A -> A
     id = \(A : Set) -> \(x : A) -> x
     #+END_SRC

**** 2.4. Implicit Arguments
     Implicit arguments are declared by enclosing their typings within curly 
     braces.

**** 2.5. Gödel System T
     Gödel System T is a system of primitive recursive functionals. All typable
     programs in Gödel System T terminate. We can only use β-reduction and the
     definitions of:

     #+BEGIN_SRC 
     true
     false
     zero
     succ
     if_then_else
     natrec
     #+END_SRC

     We can define all primitive recursive functions, but also others such as the
     Ackermann fuction.

**** 2.6. Parametrised Types
**** 2.7. Termination-checking
     In M-L Type Theory, all recursion is *primitive recursion*; a structural
     recursion on the well-founded data types.

     As the Agda's termination-checker has not yet been documented, if Agda will
     be used as a system for formalising mathematics rigorously, it is advisable to
     stay within a well-specified subset such as Martin-Löf type theory.

     In fact, the termination checker will not recognize calls to non-constructors
     as smaller arguments. =(m-n)= will not be recognized as smaller than =m=,
     for example.

*** 3. Dependent Types
**** 3.1. Vectors of a given length
     We have to alternatives to define vectors of a given length:
     
     - *As a Recursive Family*:
       
       #+BEGIN_SRC 
       Vec : Set -> Nat -> Set
       Vec A zero = Unit
       Vec A (succ n) = A X Vec A n
       #+END_SRC

       Functions must be written by induction on the length of the vector.

     - *As an Inductive Family*:

       #+BEGIN_SRC 
       data Vec (A : Set) : Nat -> Set where
         [] : Vec A zero
	 _::_ : {n : Nat} -> A -> Vec A n -> Vec A (succ n)
       #+END_SRC
       
     We can use type-checking to define functions that work only over non-empty
     vectors, such as =tail= or =head=.

**** 3.2. Finite Sets
     This data type is useful when we want to access the element at a certain
     position in a vector.

**** 3.3. More Inductive Families
*** TODO 4. Propositions as Types
** TODO Monads for functional programming - Philip Wadler
*** 1. Introduction
*** 2. Evaluating monads
**** 2.1. Variation zero: The basic evaluator
**** 2.2. Variation one: Exceptions
**** 2.3. Variation two: State
**** 2.4. Variation three: Output
**** 2.5. A monadic evaluator
**** 2.6. Variation zero, revisited: The basic evaluator
**** 2.7. Variation one, revisited: Exceptions
**** 2.8. Variation two, revisited: State
**** 2.9. Variation three, revisited: Output
*** 3. Monad Laws
    Son equivalentes =return,join= y =return,bind=. Y además, desde cualesquiera
    de ellos, se define =map=.
*** 4. State
**** 4.1. Arrays
**** 4.2. Array transformers
**** 4.3. Array readers
     Conmutative monads.
**** 4.4. Conclusion
*** TODO 5. Parsers
** P?=NP - Scott Aaronson
** Koszul Pairs and applications - Pascual Jara, Dragoş Ştefan
*** Introduction
**** Koszul ring
*Koszul ring*. A graded ring $A$ is *Koszul* if $A^0$ is a semisimple ring 
and it has a resolution $P_\ast$ by projective graded left A-modules such 
that each $P_n$ is generated by homogeneous elements of degree $n$.

**** Graded ring
*Graded ring*. A ring that is a direct sum of abelian groups:

\[ A = \bigoplus_{n \in \mathbb{N}} A_n\]

such that $A_iA_j \subset A_{i+j}$.

***** Homogeneous Elements
A *homogeneous element* is an element of any factor $A_i$ of the 
decomposition.

*Example:* A polynomial ring $A = \mathbb{K}[x_1,x_2, \dots]$ is graded with $A_i$ 
being the abelian group of polynomials with only monomials of 
degree $i$.
# QUESTION: Do they admit a different gradation?
# We can take $A_i$ to be the group of polynomials of degree 
# *equal or less* than i!

**** Semisimple group
*Semisimple group*. A group is semisimple if it has no non-trivial 
normal abelian subgroups.

Different uses of this term can be found [[http://planetmath.org/semisimplegroup][here]].
# QUESTION: Which are we interested in?

**** Semisimple module
*Semisimple module*. It is a direct sum of simple modules, that is, 
they have no non-zero proper submodules.

**** Semisimple algebra
An associative finite dimensional algebra $A$ is *semisimple* if
$A$ is a direct product of simple algebras or equivalently, if $A$ has
trivial Jacobson radical.

*** 1. Almost-koszul pairs
**** 1.1. R-rings
***** R-Ring
*R-ring*. Associative and unital algebra. It is an associative and 
unital ring $A$ together with a morphism $u : R \longrightarrow A$.

***** Graded and connected R-rings
*Graded and connected R-rings*. A R-ring is graded if it is equipped 
with a decomposition:

\[A = \bigoplus_{n \in \mathbb{N}} A^n \]

such that multiplicaton $m^{p,q}$ maps $A^p \otimes A^q$ into $A^{p+q}$. It is *connected* 
when $A_0 = R$. It is *strongly graded* when $m^{1,p}$ is surjective. We 
call $\pi^n_A$ to the projection of $A$ onto $A^n$.

**** 1.2. R-corings
***** Definition of coalgebra
A [[https://en.wikipedia.org/wiki/Coalgebra#Formal_definition][coalgebra]] over a field $K$ is a *vector space* $V$ together with linear
maps $\Delta : V \longrightarrow V \otimes V$ and $\varepsilon : V \longrightarrow K$ such that:

 1. $(id \otimes \Delta) \circ \Delta = (\Delta \otimes id) \circ \Delta$
 2. $(id \otimes \varepsilon) \circ \Delta = id 
    = (\varepsilon \otimes id) \circ \Delta$

Sometimes, the coalgebras use [[https://en.wikipedia.org/wiki/Coalgebra#Sweedler_notation][Sweedler notation]].

***** Examples of coalgebras
****** The divided power coalgebra
Consider $K[X]$, the polynomial ring, where we define by linearity:

\[\Delta(X^n) = \sum^n_{k=0} {n \choose k} X^k \otimes X^{n-k}\]

\[\epsilon(X^n) = \twopartdef{1}{n=0}{0}{n>0}\]

When the structures of algebra and coalgebra are compatible, they
are called [[https://en.wikipedia.org/wiki/Bialgebra][bialgebras]].

***** R-coring
*R-coring*. Coassociative and counital coalgebra. It is an R-bimodule 
with a /comultiplication/ $\Delta : C \longrightarrow C \otimes C$ and 
a /counit/ $\epsilon : C \longrightarrow R$.

***** Graded corings
*Graded corings*. Decomposition $C = \bigoplus_{n \in \mathbb{N}} C_n$, 
such that:

\[\Delta(C_n) \subset \bigoplus_{p=0}^n C_p \otimes C_{n-p}\]

**** 1.3. Almost-Koszul pair
*Almost-Koszul pair*. Connected R-ring and R-coring $(A,C)$ with an 
isomorphism $\theta_{C,A} : C_1 \longrightarrow A^1$, that satisfies the relation:

\[ m^{1,1} \circ (\theta_{C,A} \otimes \theta_{C,A}) \circ \Delta_{1,1}
= 0\]

Or, using Sweedler notation, for any $c \in C_2$:

\[ \sum \theta_{C,A}(c_{(1,1)}) \theta_{C,A}(c_{(2,1)}) = 0\]

**** 1.4. Opposite Koszul pair
If $(A,C)$ is a Koszul pair, then $(A^{op},C^{op})$ are Koszul pairs with
respect to:

\[\theta_{C^{op},A^{op}} = \theta_{C,A}\]

**** 1.5. The normalized bar resolution of R
For every strongly graded R-ring A, there is a graded coring C such that
$(A,C)$ is an almost-Koszul pair.

***** The normalized right bar resolution
The exact sequence $\beta_\ast^r(A)$:

\[ 0 \longleftarrow 
R \overset{\delta_0}\longleftarrow 
A \overset{\delta_1}\longleftarrow
\overline{A} \otimes A \overset{\delta_2}\longleftarrow
\overline{A} \otimes \overline{A} \otimes A \overset{\delta_3}\longleftarrow
\overline{A} \otimes \overline{A} \otimes \overline{A} \otimes A \longleftarrow
\dots
\]

is called the *normalized right bar resolution*. Where
the $\delta$ are defined as:

 - $\delta_0 = \pi^0_A$
 - \[ \delta_n(a_1 \otimes \dots \otimes a_n \otimes a_{n+1}) 
      = \sum_{i=1}^n (-1)^i  a_1 \otimes \dots \otimes a_ia_{i+1} \otimes \dots \otimes a_{n+1}\]

***** TODO Normalized bar complex

*** 2. Koszul Pairs

*** 3. Hochschild (co)homology of Koszul rings
**** 3.1. The cyclic tensor product
***** Enveloping algebra of R
The tensor product algebra $R^e = R \otimes_\mathbb{K} R^{op}$ is called the 
*enveloping algebra* of $R$.

*** 4. Almost-Koszul pairs associated to twisted tensor products

*** 5. The Hochschlid cohomology of a twisted tensor product
* Aluffi - Algebra Chapter 0
** III. Anillos y módulos
*** 7. Complejos y homología
**** 7.1. Complejos y secuencias exactas.
 #+begin_definition
 *Complejo*. Un complejo es una serie de morfismos $d_i$ entre R-Módulos:

 \[\dots \longrightarrow M_{i+1} \longrightarrow M_i \longrightarrow M_{i-1} \longrightarrow \dots\]

 tales que $d_i \circ d_{i+1} = 0$.
 #+end_definition

 Además lo llamamos *exacto* cuando $im (d_{i+1}) = ker (d_i)$.

 #+begin_proposition
 *Exactitud de monomorfismos y epimorfismos*. Dos complejos de la forma:

 \[ \dots \longrightarrow 0 \longrightarrow L \overset{\alpha}\longrightarrow M \longrightarrow \dots \]
 \[ \dots \longrightarrow M \overset{\beta} \longrightarrow N \longrightarrow 0 \longrightarrow \dots \]

 Son exactos en $L$ y $N$ ssi $\alpha$ y $\beta$ son monomorfismo y epimorfismo, 
 respectivamente.
 #+end_proposition

 #+begin_definition
 *Secuencia exacta corta*. Una secuencia exacta corta es un complejo de la forma:

 \[ 0 \longrightarrow L \overset{\alpha}\longrightarrow M \overset{\beta}\longrightarrow N \longrightarrow 0 \]
 #+end_definition

 El primer teorema de isomorfía nos dice que $N \cong \frac{M}{ker(\beta)} = \frac{M}{im(\alpha)}$ lo que nos 
 lleva a identificar   $N \cong \frac{M}{L}$. De hecho, cada monomorfismo da lugar a una 
 secuencia exacta corta:

 \[ 0 \longrightarrow \ker(\phi) \longrightarrow M \longrightarrow im(\phi) \longrightarrow 0 \]

**** 7.2. Secuencias exactas escindidas
 #+begin_definition
 *Secuencia escindida*. Una secuencia exacta corta:

 \[ 0 \longrightarrow M_1 \longrightarrow N \longrightarrow M_2 \longrightarrow 0 \]

 es escindida si es isomorfa a una secuencia de la forma siguiente:

 \[ \begin{tikzcd}
 0   \arrow{r}{} & 
 M_1 \arrow{d}{\sim}\arrow{r}{} & 
 N   \arrow{d}{\sim}\arrow{r}{} & 
 M_2 \arrow{d}{\sim}\arrow{r}{} & 
 0 \\
 0   \arrow{r}{} & 
 M_1 \arrow{r}{} & 
 M_1 \oplus M_2   \arrow{r}{} & 
 M_2 \arrow{r}{} & 
 0
 \end{tikzcd} \]

 Es decir, hay un isomorfismo entre secuencias.
 #+end_definition

 #+begin_theorem
 *Relación entre secuencias escindidas e inversas*. Sea $\phi$ un homomorfismo;
 entonces tiene inversa izquierda ssi la secuencia siguiente escinde:

 \[ 0 \longrightarrow M \overset{\phi}\longrightarrow N \longrightarrow coker(\phi) \longrightarrow 0 \]

 Y tiene inversa derecha si la secuencia siguiente escinde:

 \[ 0 \longrightarrow ker(\phi) \longrightarrow M \overset{\phi}\longrightarrow N \longrightarrow 0 \]
 #+end_theorem

**** 7.3. Homología, y el lema de la serpiente
 #+begin_definition
 *Homología*. La i-ésima homología de un complejo,

 \[ \dots \longrightarrow M_{i+1} \overset{d_{i+1}}\longrightarrow M_i \overset{d_i}\longrightarrow M_{i-1} \longrightarrow \dots \]

 es el R-módulo:

 \[H_i(M) = \frac{ker(d_i)}{im(d_{i+1})}\]
 #+end_definition

 La homología mide lo que se aleja de ser exacto en un punto determinado, y
 es $0$ cuando el complejo es exacto. Puede verse como una generalización de
 kernel y cokernel; que los realiza en este caso extremo:

 \[ 0 \longrightarrow M_1 \overset{\phi}\longrightarrow M_0 \longrightarrow 0 \]

 En el que $H_1(M) \cong ker(\phi)$ y $H_0(M) \cong coker(\phi)$.

 #+begin_theorem
 *Lema de la serpiente*. Teniendo dos secuencias exactas en el diagrama 
 conmutativo siguiente:

 \[ \begin{tikzcd}
 0 \rar & L_1 \rar{\alpha_1}\arrow{d}{\lambda} & M_1 \rar{\beta_1}\arrow{d}{\mu} & N_1 \rar\arrow{d}{\eta} & 0 \\
 0 \rar & L_0 \rar{\alpha_0}                   & M_0 \rar{\beta_0}               & N_0 \rar                & 0
 \end{tikzcd} \]

 Existe una secuencia exacta de la forma:

 \[ 0 \overset{}\longrightarrow 
 ker(\lambda) \overset{}\longrightarrow 
 ker(\mu) \overset{}\longrightarrow 
 ker(\eta) \overset{\delta}\longrightarrow 
 coker(\lambda) \overset{}\longrightarrow 
 coker(\mu) \overset{}\longrightarrow 
 coker(\eta) \overset{}\longrightarrow 
 0\]
 #+end_theorem

 El diagrama desde el que se deduce todo esto, con columnas exactas, es
 el siguiente:

 \[ \begin{tikzcd}
	& 0 \dar              & 0 \dar            & 0 \dar           &   \\
 0 \rar & ker(\lambda) \rar \dar  & ker(\mu) \rar \dar    & ker(\eta) \dar \ar[out=355, in=175,looseness=1, overlay, swap]{dddll}{\delta}       &   \\
 0 \rar & L_1 \rar{\alpha_1} \dar{\lambda}  & M_1 \rar{\beta_1} \dar{\mu} & N_1 \rar \dar{\eta}        & 0 \\
 0 \rar & L_0 \rar{\alpha_0} \dar & M_0 \rar{\beta_0} \dar & N_0 \rar \dar        & 0 \\
	& coker(\lambda) \rar \dar & coker(\mu) \rar \dar  & coker(\eta) \rar \dar & 0 \\
	& 0                   & 0                 & 0                &
 \end{tikzcd} \]

** IV. Álgebra lineal
*** 4. Presentaciones y resoluciones
**** 4.1. Torsión
 #+begin_definition
 *Torsión*. Un elemento $m \in M$ módulo de $R$ es de *torsión* si $\{m\}$ es linealmente
 dependiente. Es decir,

   \[ \exists r \in R,\ r \neq 0\ :\ rm = 0 \]

 El conjunto de elementos de torsión se llama $Tor(M)$. Un módulo es *libre de torsión*
 si $Tor(M) = 0$ y *de torsión* si $Tor(M)=M$.
 #+end_definition

 Un anillo conmutativo es libre de torsión sobre sí mismo si y sólo si es dominio de
 integridad. Cuando esto ocurre, $Tor(M)$ es siempre submódulo de $M$. Submódulos o
 sumas de módulos libres de tensión serán libres de torsión, y por todo esto, los módulos
 libres sobre dominios de integridad serán libres de torsión.

 #+begin_definition
 *Cíclico*. Un módulo es *cíclico* cuando es generado por un elemento. Es decir,
 cuando $M \cong R/I$ para algún ideal.
 #+end_definition

 Cuando en un dominio de integridad todos sus
 módulos cíclicos son libres de torsión, es un cuerpo. Otra forma de pensar sobre un módulo
 cíclico es como aquel que admite un epimorfismo:

 \[ R \longrightarrow M \longrightarrow 0 \]

**** 4.2. Módulos finitamente presentados y resoluciones libres
 #+begin_definition
 *Anulador.* El anulador de un módulo $M$ es:

 \[Ann_R(M) = \{ r \in R\ |\ \forall m \in M, rm = 0 \}\]
 #+end_definition

 Es un ideal de $R$. Cuando $M$ es finitamente generado y $R$ es dominio de integridad,
 $M$ es de torsión si y sólo si $Ann(M) \neq 0$.

 #+begin_definition
 *Módulos finitamente generados y presentados*. Sabemos que todos los módulos admiten un
 epimorfismo de la forma:

 \[ R^{\oplus A} \longrightarrow M \longrightarrow 0\]

 Cuando lo admiten con $A$ finito, se tiene $M$ *finitamente generado*. Un módulo se dice
 *finitamente presentado* si hay una secuencia exacta de la forma:

 \[R^n \overset{\phi}\longrightarrow R^m \longrightarrow M \longrightarrow 0\]

 .
 #+end_definition

 Si $R$ es Noetheriano, todo módulo finitamente generado es finitamente presentado.

 #+begin_definition
 *Resolución*. Una resolución de $M$ mediante módulos libres finitamente generados es
 un complejo exacto:

 \[ \dots \rightarrow R^{m_3} \rightarrow R^{m_2} \rightarrow R^{m_1} \rightarrow R^{m_0} \rightarrow M \rightarrow 0 \]
 #+end_definition

 Aquí podemos entender que $R^{m_0}$ contiene los generadores, $R^{m_1}$ las relaciones
 entre los generadores, $R^{m_2}$ las relaciones entre relaciones, y así sucesivamente.

 Un dominio de integridad es *cuerpo si y sólo si todos sus módulos son finitamente generados*,
 esto es equivalente a tener:

 \[ 0 \longrightarrow R^m \longrightarrow M \longrightarrow 0 \]

 para cualquier módulo.

 Un dominio de integridad es *PID si todas las resoluciones como finitamente generado 
 extienden a finitamente presentado*, de la forma:

 \[0 \longrightarrow R^{m_1} \longrightarrow R^{m_0} \overset{\pi}\longrightarrow M \longrightarrow 0\]

 esto equivale a pedir que $\ker(\pi)$ sea libre.

**** 4.3. Leyendo una presentación
 Hemos visto que podemos estudiar un módulo finitamente presentado por un
 morfismo $\phi: R^n \longrightarrow R^m$, donde $M = coker(\phi)$. Esto quiere decir que 
 podemos asignarle una matriz explícita.

 #+begin_theorem
 *Producto de módulos en matrices*. Sean $M,N$ módulos con matrices $A,B$.
 Tenemos $M \oplus N$ con matriz:

 \[\left(\begin{array}{c|c}
 A & 0 \\ \hline 0 & B 
 \end{array}\right)\]
 #+end_theorem

 Además nótese que las *matrices equivalentes* representan el mismo 
 homeomorfismo, y por tanto el mismo módulo.

 #+begin_theorem
 *Transformaciones de matrices de módulos*. Una matriz representa el mismo módulo
 tras las transformaciones de:
  - Permutar filas o columnas
  - Añadir filas o columnas linealmente dependientes
  - Multiplicar filas o columnas por una unidad
  - Quitar una fila y columna en la que sólo queda una unidad
 #+end_theorem

 Las primeras son consecuencia de la equivalencia. La última puede colocarse como
 una parte de identidad en una matriz de la forma:

 \[A = \left(\begin{array}{c|c}
 u & 0 \\ \hline 0 & A' 
 \end{array}\right)\]

 Que no afecta al cokernel.

** VII. Cuerpos
*** 1. Extensiones de cuerpos I
**** 1.1. Definiciones básicas
***** Categoría de los cuerpos
Los cuerpos forman la *categoría $\mathtt{Fld}$* con los homomorfismos de 
anillos entre ellos. Todo homomorfismo de anillos entre cuerpos
es inyectivo y todo morfismo en esta categoría es monomorfismo.

Así, todo morfismo entre cuerpos en $Hom(k,K)$ es una extensión $K/k$.

***** Característica de un cuerpo
      La *característica* de $K$ es el generador de $ker(i)$ para 
      $i : \mathbb{Z} \longrightarrow K$. Las extensiones preservan la 
      característica, así que podemos particionar la categoría en categorías 
      $\mathtt{Fld}_p$.

***** Cuerpos primos
      El inicial de $\mathtt{Fld}_0$ es $\mathbb{Q}$, y el de $\mathtt{Fld}_p$ es $\mathbb{F}_p = \mathbb{Z}/p\mathbb{Z}$. Todos los
      cuerpos son extensiones de uno de estos llamados *cuerpos primos*.

***** Grado de una extensión
El *grado*, $[F : K]$, de una extensión es su dimensión como espacio
vectorial sobre la base. Es *finita* o *infinita* si lo es su grado.

**** 1.2. Extensiones simples
***** Extensión simple
Una extensión es *simple* si es de la forma $K(\alpha)$ donde 
$K(\alpha)$ es la intersección de todos los subcuerpos de algún
$F$ conteniendo al cuerpo $K$ y el elemento $\alpha$.

***** Polinomio irreducible mínimo
Dada una extensión simple $K(\alpha)$, consideramos la evaluación
$\epsilon : K[X] \longrightarrow K(\alpha)$ por casos:

 - Es *inyectiva* ssi es una *extensión infinita*. En este
   caso $K(\alpha) \cong K(X)$ es el cuerpo de funciones racionales.
 - No es *inyectiva*. Existe un único polinomio mónico
   irreducible $p$ que genera el núcleo,

   \[ K(\alpha) \cong \frac{K[t]}{(p(t))}\]

   Se le llama *polinomio mínimo*.

***** TODO Extensión de isomorfismos a extensiones simples
Proposition 1.5
***** Automorfismos de una extensión
El *grupo de automorfismos* de una extensión $Aut_K(F)$, es el
grupo de los automorfismos de cuerpos que dejan fijo $K$.
***** Automorfismos y raíces
Sea $K(\alpha)$ con $p$ polinomio mínimo. Entonces $p$ tiene $|Aut_K(K(\alpha))|$ raíces
distintas en $K(\alpha)$. En particular,

\[ |Aut_K(K(\alpha))| \leq [K(\alpha):K] \]

y el caso de igualdad se tiene con $p$ factorizando en factores 
lineales sobre $F$.
**** 1.3. Extensiones finitas y algebraicas
***** Elementos algebraicos y trascendentes
Sea $F/K$ una extensión con $\alpha \in F$, entonces $\alpha$ es *algebraico*
cuando $K(\alpha)/K$ es finita, y *trascendente* si no. Una extensión
es *algebraica* si todos sus elementos lo son.

*** 6. Un poco de teoría de Galois
**** 6.1. Correspondencia de Galois y extensiones de Galois
***** Cuerpo fijo
Sea $F/k$ extensión y $G \subseteq Aut_k(F)$. Llamamos *cuerpo fijo* de $G$ a:

\[ F^G = \{ \alpha\in F \mid \forall g \in G, g\alpha=\alpha\}\]

***** Correspondencia de Galois
Hay correspondencia entre los cuerpos intermedios de la extensión
y los subgrupos del grupo de automorfismos.

Dado $E$ cuerpo intermedio, lo enviamos a $Aut_E(F)$. Dado $G$ lo enviamos
a $F^G$.

***** Inclusión y correspondencia
Para cualesquiera subgrupo $G$ y cuerpo intermedio $E$:

 - $E \subseteq F^{Aut_E(F)}$
 - $G \subseteq Aut_{F^G}(F)$

Si llamamos $E_1E_2$ al menor subcuerpo de $F$ conteniendo $E_1,E_2$ y llamamos
$<G_1,G_2>$ al menor subgrupo de los automorfismos conteniendo $G_1,G_2$:

 - $Aut_{E_1E_2}(F) = Aut_{E_1}(F) \cap Aut_{E_2}(F)$
 - $F^{<G_1,G_2>} = F^{G_1} \cap F^{G_2}$

***** Extensiones de Galois
Sea $F/k$ extensión, equivalen:

 - $F$ es cuerpo de descomposición de algún $f \in k[t]$.
 - $F/k$ es normal y separable.
 - $|Aut_k(F)| = [F : k]$.
 - La correspondencia de Galois es biyección.
 - $F/k$ separable y, si $E/F$ es algebraica con $\sigma \in Aut_k(E)$, $\sigma(F)=F$.

Llamamos a esto una *extensión de Galois*.
** VIII. Vuelta al álgebra lineal
*** 1. Preliminares
**** 1.1. Funtores
 #+begin_definition
 *Funtor*. Un funtor covariante:

 \[{\cal F} : C \longrightarrow D\]

 Asigna a cada $A \in C$ un ${\cal F}(A) \in D$ y mapea los morfismos entre cada par de objetos:

 \[Hom_C(A,B) \rightarrow Hom_D({\cal F}(A),{\cal F}(B))\]

 Respetando la identidad y la composición de morfismos. 

 Un *funtor contravariante* es un funtor desde la categoría opuesta:

 \[{\cal F} : C^{op} \longrightarrow D\]
 #+end_definition

 Los funtores preservan los diagramas conmutativos. Llamamos *prehaz* a un funtor
 contravariante $C \longrightarrow \mathtt{Set}$.

 #+begin_definition
 *Funtor aditivo*. Llamamos a un funtor 
 ${\cal F}: R-\mathtt{Mod} \longrightarrow S-\mathtt{Mod}$ *aditivo* cuando
 la función $Hom_{R}(A,B) \rightarrow Hom_{S}({\cal F}(A),{\cal F}(B))$ es homomorfismo de grupos.
 #+end_definition

**** 1.3. Equivalencia de categorías
 #+begin_definition
 *Funtores plenamente fieles*. Dada la función inducida:
 \[Hom_C(A,B) \rightarrow Hom_D({\cal F}(A),{\cal F}(B))\]
 Un funtor es *fiel* si es inyectiva, *pleno* si es sobreyectiva y *plenamente fiel*
 si es biyectiva.
 #+end_definition

 #+begin_definition
 *Equivalencia de categorías*. Un funtor es una equivalencia de categorías si 
 es plenamente fiel y esencialmente sobreyectivo, es decir, para cada $Y \in D$,
 existe un $X \in C$ tal que $F(X) \cong Y$.
 #+end_definition

**** 1.4. Límites y colímites

 #+begin_definition
 *Límite*. Para un funtor ${\cal F}: {\cal I} \longrightarrow C$, su límite es
 un objeto $L \in C$ con morfismos $\lambda_I: L \longrightarrow {\cal F}(I)$ tales que

 - Conmuta el siguiente diagrama para cualquier $\alpha : I \longrightarrow J$:

 \[ \begin{tikzcd}[column sep=1.5em]
  & L \arrow{dr}{\lambda_J} \arrow{dl}[swap]{\lambda_I} \\
 {\cal F}(I) \arrow{rr}{{\cal F}(\alpha)} && {\cal F}(J)
 \end{tikzcd} \]

 - $L$ es final en este diagrama.
 #+end_definition

 Será esencialmente único y puede notarse por $\varprojlim {\cal F}$.

 #+begin_theorem
 *Límites sobre cadenas en R-Mod*. En R-Mod siempre existe un límite llamado \(\varprojlim {\cal A}_i\) sobre una
 cadena de la forma:

 \[ \begin{tikzcd}
 & & A 
 \arrow{lld}[swap]{\phi_5}
 \arrow{ld}{\phi_4}
 \arrow{d}{\phi_3}
 \arrow{rd}[swap]{\phi_2}
 \arrow{rrd}{\phi_1} 
 & & \\
 \dots \arrow{r}[swap]{\phi_{45}}  &
 A_4 \arrow{r}[swap]{\phi_{34}} &
 A_3 \arrow{r}[swap]{\phi_{23}} &
 A_2 \arrow{r}[swap]{\phi_{12}} &
 A_1
 \end{tikzcd} \]
 #+end_theorem

 Este límite es el submódulo de las /secuencias coherentes/ en $\prod_i A_i$, es decir, de
 aquellas tales que $a_i = \phi_{i,i+1}(a_{i+1})$; teniendo como morfismos $\phi_i$ las proyecciones
 canónicas


 #+begin_definition
 *Colímite*. La noción dual de límite es el *colímite*, es decir, para
 un funtor ${\cal F} : I \longrightarrow C$, su colímite es un objeto $L \in C$ con morfismos $\gamma_i : {\cal F}(I) \longrightarrow L$
 tales que

 - Conmuta el siguiente diagrama para cualquier $\alpha : I \longrightarrow J$:

 \[ \begin{tikzcd}[column sep=1.5em]
  & L  \\
 {\cal F}(I) \arrow{ur}{\gamma_I} \arrow{rr}{{\cal F}(\alpha)} && {\cal F}(J) \arrow{ul}[swap]{\gamma_J}
 \end{tikzcd} \]

 - $L$ es inicial en este diagrama.
 #+end_definition

**** 1.5. Comparando funtores
 #+begin_definition
 *Transformación natural*. Una transformación natural entre dos funtores ${\cal F} \Longrightarrow {\cal G}$ 
 consiste en morfismos $\upsilon_X : {\cal F}(X) \longrightarrow {\cal G}(X)$ tales que conmuta el diagrama:

 \[ \begin{tikzcd}
 {\cal F}(X) \arrow{r}{{\cal F}(\alpha)} \arrow{d}{\upsilon_X} & {\cal F}(Y) \arrow{d}{\upsilon_Y} \\
 {\cal G}(X) \arrow{r}{{\cal G}(\alpha)} & {\cal G}(Y)
 \end{tikzcd}
 \]

 para cualquier morfismo $\alpha$.

 Llamamos *isomorfismo natural* a una transformación natural donde cada $\upsilon$
 es un isomorfismo.
 #+end_definition

 #+begin_definition
 *Funtor adjunto*. Llamamos ${F}$ y ${G}$ adjuntos si tenemos:

 \[ Hom_C(X,GY) \cong Hom_D(FX,Y) \]

 Isomorfismos naturales.
 #+end_definition

 Lo que nos da realmente un isormorfismo natural de $Hom_C(F-,-)$ con $Hom_D(-,G-)$,
 entendidos como funtores. Llamamos aquí adjunto izquierdo a $F$ y adjunto derecho a $G$.
 Tenemos más sobre funtores adjuntos en la lista de reproducción de [[https://www.youtube.com/playlist?list=PL54B49729E5102248][The Catsters]].

 #+begin_theorem
 *Continuidad de adjuntos*. Los funtores adjuntos derechos son continuos, los adjuntos
 izquierdos son cocontinuos. Es decir, para $I : {\cal I}\longrightarrow D$, $J : {\cal J}\longrightarrow C$

 \[G(\varprojlim I) = \varprojlim (G \circ I)\]
 \[F(\varinjlim J) = \varinjlim (F \circ J)\]
 #+end_theorem

 Siempre que existan los límites. La demostración de esto se puede hacer aplicando los
 funtores en los diagramas conmutativos y usando las propiedades universales de los límites.

 #+begin_definition
 *Funtor exacto*. Un funtor exacto respeta la exactitud de las secuencias. Es decir,
 siendo la siguiente secuencia exacta:

 \[ 0 \longrightarrow A \overset{\phi}\longrightarrow B \overset{\psi}\longrightarrow C \longrightarrow 0\]

 La siguiente secuencia será exacta:

 \[ 0 \longrightarrow FA \overset{F\phi}\longrightarrow FB \overset{F\psi}\longrightarrow FC \longrightarrow 0\]
 #+end_definition

 En particular, lo llamamos /exacto a la izquierda/ si preserva la exactitud de:

 \[ 0 \longrightarrow A \overset{\phi}\longrightarrow B \overset{\psi}\longrightarrow C\]

 Y /exacto a la derecha/ si preserva la exactitud de:

 \[ A \overset{\phi}\longrightarrow B \overset{\psi}\longrightarrow C \longrightarrow 0\]

*** 2. Producto tensor y el funtor Tor
**** 2.1. Aplicaciones bilineales
 #+begin_definition
 *Aplicación bilineal*. Una aplicación $\phi:M\times N \longrightarrow P$ es bilineal si
 son lineales $\phi(\_,n)$ y $\phi(m,\_)$ para cualesquiera $m,n$.
 #+end_definition

 #+begin_definition
 *Producto tensor*. $M \otimes_R N$ es el producto tensor de $M$ y $N$ como módulos de $R$
 si cualquier aplicación bilineal factoriza de forma única a través de él:

 \[ \begin{tikzcd}
 M \times N \arrow{r}{\phi} \arrow{d}{\otimes} & P \\
 M \otimes N \arrow{ru}[swap]{\exists! \overline\phi} &
 \end{tikzcd} \]
 #+end_definition

 Usando universalidad podemos ver que $R \otimes N \cong N$ y que $M\otimes N \cong N\otimes M$. La construcción
 explícita del producto tensor se hace sobre el módulo libre sobre $M \times N$ provocando un
 cociente sobre los submódulos generados por:

 \[(m,r_1n_1+r_2n_2) - r_1(m,n_1) - r_2(m,n_2)\]
 \[(r_1m_1+r_2m_2,n) - r_1(m_1,n) - r_2(m_2,n)\]

 Lo que nos permite actuar con ellos de forma bilineal. La demostración se basa en usar
 la propiedad universal de la proyección sobre ese cociente.

**** 2.2. Adjunción con Hom
 Dado un módulo $N$ de $R$, tenemos un funtor covariante $\otimes_R N$, que será *adjunto izquierdo*
 a $Hom_{R-mod}(N,-)$. Podemos observar simplemente que una aplicación bilineal, al currificarse,
 determina una función que va de $M$ a $Hom(N,P)$, y que es lineal. Sabiendo esto, es trivial
 que:

 \[ Hom_R(M, Hom_R(N,P)) \cong Hom_R(M \otimes N, P)\]

 La naturalidad y el hecho de que es un isomorfismo se comprueban fácilmente. El hecho de
 que exista una adjunción nos dice además que $\otimes_R N$, o $N\otimes_R$ por la isomorfía anterior,
 son cocontinuos.

 #+begin_fact
 Para cualesquiera \(R\)-módulos, se tiene:

 \[(M_1 \oplus M_2) \otimes N \cong (M_1 \otimes N) \oplus (M_2 \otimes N)\]

 \[N \otimes (M_1 \oplus M_2) \cong (N \otimes M_1) \oplus (N \otimes M_2)\]

 \[(\oplus_\alpha M_\alpha) \otimes N \cong \oplus_\alpha (M_\alpha \otimes N)\]
 #+end_fact

 Por cocontinuidad.

 #+begin_fact
 Para cualesquiera dos conjuntos $A,B$, se tiene:

 \[R^{\oplus A} \otimes R^{\oplus B} \cong R^{\oplus A \times B}\]
 #+end_fact

 Teniendo \(R^{\oplus n} \otimes R^{\oplus m} \cong R^{\oplus nm}\). De hecho, la base del espacio producto
 tensor la forman los vectores puros que emparejan elementos de las 
 bases de cada uno de los espacios.

 #+begin_theorem
 *Producto tensor de cocientes*. Dado un $N$ módulo de $R$, e $I$ ideal,
 tenemos:

 \[\frac{R}{I}\otimes N \cong \frac{N}{IN}\]

 Y desde ahí, aplicando además el tercer teorema de isomorfía, tenemos:

 \[\frac{R}{I} \otimes \frac{R}{J} \cong \frac{R}{I+J}\]
 #+end_theorem

 Esto se deduce de aplicar el funtor $\_ \otimes N$ a la secuencia exacta del 
 ideal:

 \[I \longrightarrow R \longrightarrow \frac{R}{I} \longrightarrow 0\]
 
 \[I \otimes N \longrightarrow N \longrightarrow \frac{R}{I} \otimes N \longrightarrow 0\]

 Desde donde se obtiene $IN$ como inclusión de $I\otimes N$ en $N$.

**** 2.3. Exactitud y planitud
 #+begin_definition
 *Módulo plano*. El módulo $N$ es *plano* si el funtor $\_ \otimes N$ es un
 funtor exacto.
 #+end_definition

 Un *módulo libre* será siempre plano.

**** 2.4. Los funtores Tor
 #+begin_definition
 *El funtor Tor*. Lo que se aleja de la exactitud el funtor $\_ \otimes N$
 es medido por el funtor $Tor_1(\_,N)$. De hecho, si tenemos una secuencia
 exacta:

 \[0\longrightarrow A \longrightarrow B \longrightarrow C \longrightarrow 0\]

 Obtenemos aplicando el funtor $\otimes N$ esta otra secuencia:

 \[Tor_1(C,N) \longrightarrow A \otimes N \longrightarrow B \otimes N \longrightarrow C \otimes N \longrightarrow 0\]

 Y de hecho, esta secuencia podrá extenderse aún más con /funtores derivados/,
 que se definen como:

 \[Tor_i^R(M,N) = H_i(M_{\bullet} \otimes N)\]
 #+end_definition

 Aquí entendemos $M_\bullet \otimes N$ como el complejo que se obtiene tomando una resolución
 libre de $M$:

 \[\dots \longrightarrow R^{\otimes S_2} \longrightarrow R^{\otimes S_1} 
 \longrightarrow R^{\otimes S_0} \longrightarrow M \longrightarrow 0}\]

 Y retirando $M$ y tensando sobre $N$, para tener:

 \[\dots \longrightarrow N^{\otimes S_2} \longrightarrow N^{\otimes S_1} 
 \longrightarrow N^{\otimes S_0} \longrightarrow 0}\]

 Todo esto se obtendrá de manera natural aplicando el lema de la serpiente a una secuencia
 de resoluciones compatibles, algo que, si los módulos fueran PID y tuvieran una resolución
 de grado 2, sería de la forma:

 \[ \begin{tikzcd}
    & 0 \dar & 0 \dar & 0 \dar &   \\
 0 \rar & R^{\oplus a_1}\rar\dar & R^{\oplus b_1} \rar\dar & R^{\oplus c_1} \rar\dar & 0 \\
 0 \rar & R^{\oplus a_0}\rar\dar & R^{\oplus b_0} \rar\dar & R^{\oplus c_0} \rar\dar & 0 \\
 0 \rar & A\rar\dar & B \rar\dar & C \rar\dar & 0 \\
  & 0 & 0 & 0 & 
 \end{tikzcd} \]

 Tensando las dos filas superiores, que son libres, nos quedarían dos filas sobre las que aplicar
 el lema de la serpiente y obtener los funtores derivados tal y como los hemos definido.

*** 5. Funtor Hom y dualidad 
**** 5.1. Adjunciones, de nuevo
 Ya sabemos que el funtor $Hom(N,\_)$ es adjunto derecho a $\_\otimes N$, ahora
 estudiamos el funtor $Hom(\_,N)$.

 #+begin_theorem
 *Adjunción de Hom contravariante*. El funtor $Hom(\_,N)$ es adjunto derecho
 de su funtor opuesto, $Hom^{op}(\_,N)$.
 #+end_theorem

 Aplicando currificación tenemos trivialmente:

 \[Hom(L,Hom(M,N)) \cong Hom(M,Hom(L,N))\]

 Que, teniendo en cuenta que estamos usando la categoría opuesta, prueba la
 adjunción.

 #+begin_proposition
 *Exactitud de Hom*. Ambos funtores $Hom$ son adjuntos derechos y por tanto,
 exactos por la izquierda. Teniendo en cuenta que uno es contravariante, quiere
 decir que:

 \[ A \overset{}\longrightarrow B \overset{}\longrightarrow C \overset{}\longrightarrow 0\]

 Lleva a:

 \[ 0 \overset{}\longrightarrow Hom(C,N) \overset{}\longrightarrow 
 Hom(B,N) \overset{}\longrightarrow Hom(A,N)\]
 #+end_proposition

**** 5.2. Módulos duales.
 #+begin_definition
 *Módulo dual*. El dual de un R-módulo $M$ es el módulo $M^{\vee} = Hom_R(M,R)$.
 #+end_definition

 Tenemos que $Hom(M,R^n) \cong M^{\vee} \otimes R^n$.

*** 6. Módulos proyectivos e inyectivos, y el funtor Ext
**** 6.1. Proyectividad e inyectividad
 #+begin_definition
 *Módulos proyectivos e inyectivos*. Un R-módulo es /proyectivo/ si $Hom(P,\_)$
 es exacto; e /inyectivo/ si $Hom(\_,P)$ es exacto.
 #+end_definition

 Esto es equivalente a decir que cada epimorfismo $M \longrightarrow N$ lleva un
 morfismo $P \longrightarrow N$ a $P \longrightarrow M$, en el caso de /proyectividad/:

 \[ \begin{tikzcd}
  & P \dlar[swap,dashed]{\exists p'} \dar[swap]{p} \drar{0} & \\
 M \rar & N \rar & 0
 \end{tikzcd} \]

 O que cada monomorfismo $L \longrightarrow M$ lleva un morfismo $L \longrightarrow Q$ a
 un monomorfismo $M \longrightarrow Q$, en el de la /inyectividad/:

 \[ \begin{tikzcd}
  & Q & \\
 0 \urar{0} \rar & N \rar \uar[swap]{q} & M \ular[dashed,swap]{\exists q'}
 \end{tikzcd} \]

 Además, esto es equivalente a decir que un módulo $P$ es /proyectivo/ si toda secuencia

 \[ 0 \overset{}\longrightarrow L \overset{}\longrightarrow M \overset{}\longrightarrow P \overset{}\longrightarrow 0 \]

 es escindida, y $Q$ es /inyectivo/ si toda secuencia:

 \[ 0 \overset{}\longrightarrow Q \overset{}\longrightarrow M \overset{}\longrightarrow N \overset{}\longrightarrow 0 \]

 es escindida.

**** 6.2. Módulos proyectivos
 #+begin_theorem
 *Caracterización de proyectividad*. Un módulo es proyectivo ssi es el sumando
 directo de un módulo libre.
 #+end_theorem

 Así, la suma directa de dos módulos proyectivos es proyectiva; el producto tensor
 de dos módulos proyectivos es proyectivo, y todo módulo proyectivo es plano.

**** 6.3. Módulos inyectivos
 #+begin_theorem
 *Caracterización de inyectividad*. Un módulo es *inyectivo* ssi toda aplicación
 $f : I \longrightarrow Q$ extiende a una aplicación $\hat f : R \longrightarrow Q$, donde I es ideal de R.
 #+end_theorem

**** 6.4. El funtor Ext
 Existirían dos formas naturales de definir *Ext*, que coinciden no trivialmente:

 #+begin_definition
 *Funtor Ext*. Dado $M$ con una resolución proyectiva:

 \[ \dots \overset{}\longrightarrow P_1 \overset{}\longrightarrow P_0 \overset{}\longrightarrow M \overset{}\longrightarrow 0 \]

 aplicamos el funtor contravariante $Hom(\_,N)$ eliminando $M$ para obtener:

 \[ 0 \overset{}\longrightarrow Hom(P_0,N) \overset{}\longrightarrow Hom(P_1,N) \overset{}\longrightarrow Hom(P_2,N) \overset{}\longrightarrow \dots \]

 Y tomamos la cohomología de este complejo $Hom(M_\bullet,N)$, dejando como definición:

 \[Ext^i_R(M,N) = H^i(Hom(M_\bullet,N))\]
 #+end_definition

 #+begin_definition
 *Funtor Ext*. Dado $N$ con una resolución inyectiva:

 \[ 0 \overset{}\longrightarrow N \overset{}\longrightarrow Q_0 \overset{}\longrightarrow Q_1 \overset{}\longrightarrow \dots \]

 aplicamos el funtor covariante $Hom(M,\_)$ eliminando $N$ para obtener:

 \[ 0 \overset{}\longrightarrow 
 Hom(M,Q_0) \overset{}\longrightarrow 
 Hom(M,Q_1) \overset{}\longrightarrow 
 Hom(M,Q_2) \overset{}\longrightarrow \dots \]

 Y tomamos la cohomología de este complejo $Hom(M,N_\bullet)$, dejando como definición:

 \[Ext^i_R(M,N) = H^i(Hom(M,N_\bullet))\]
 #+end_definition

** IX. Álgebra homológica
*** Complejos y homología, de nuevo
**** 3.1. Recordatorio de definiciones básicas
 #+begin_definition
 *Resolución*. La /resolución/ de un objeto $A$ es un complejo
 exacto excepto en un punto, donde es isomorfa a $A$.
 #+end_definition

 Esto es equivalente a tener un complejo exacto de la forma:

 \[ \dots \overset{}\longrightarrow 
 M_2 \overset{}\longrightarrow 
 M_1 \overset{}\longrightarrow 
 M_0 \overset{}\longrightarrow 
 A \longrightarrow
 0\]

**** 3.2. La categoría de los complejos
 #+begin_definition
 *Categoría de complejos de cocadenas*. La categoría $C(A)$ tiene como objetos
 los complejos de cocadenas en una categoría $A$; y como morfismos entre dos 
 cocadenas,   $Hom(M^\bullet,N^\bullet)$, los diagramas conmutativos entre ellas. Por ejemplo:

 \[ \begin{tikzcd}
 \dots \rar & M^{i-1} \rar\dar{\alpha^{i-1}} & M^{i} \rar\dar{\alpha^{i}} &  M^{i+1} \rar\dar{\alpha^{i+1}} & \dots \\
 \dots \rar & N^{i-1} \rar & N^{i} \rar & N^{i+1} \rar & \dots
 \end{tikzcd} \]

 representa el morfismo $\alpha_\bullet$.
 #+end_definition

 Esta es una categoría abeliana. De ella definiremos además dos variantes:

 - $C^+(A)$, subcategoría plena de los complejos acotados por debajo.
 - $C^-(A)$, subcategoría plena de los complejos acotados por arriba.
** Ejercicios
*** III. Rings and modules
**** 5. Modules over a ring
***** 4. Simple modules. Lema de Schur
 Tenemos que, siendo kernel e imagen submódulos, serán,
 o bien $\{0\}$, o bien $M$. Dividiendo por casos:
  - $ker \phi = \{0\}$, nos da un monomorfismo. Como su imagen debe ser
    distinta de $0$ para algún elemento y es submódulo, debe ser $N$.
  - $ker \phi = M$, nos da $\phi = 0$.

**** 6. Products and coproducts in R-Mod
***** 16. Cyclic modules
****** Un módulo simple es cíclico
 Tomemos un elemento suyo cualquiera y
 creamos $<m>$. Ocurre que debe ser un submódulo y por ser simple, todo
 el módulo.

****** Un cociente por ideal es cíclico.
 Sea $M = R/I$, un módulo sobre $R$ podemos generarlo simplemente 
 por $<1>$, luego es cíclico.
 Sea $M=<m>$ un módulo cíclico. Podemos tomar un isomorfismo que lleve
 $r \mapsto rm$ y definir $I = \{r\;|\;rm=0\}$. Por 1er Teorema de isomorfía:

 \[M \cong R/ker(\phi) \cong R/I\]

****** Todo cociente de cíclico es cíclico.
 Usando el tercer teorema de isomorfía:

 \[\frac{\frac{R}{I}}{J} \cong \frac{\frac{R}{I}}{\frac{I+J}{I}} \cong \frac{R}{I+J}\] (?)

**** 7. Complexes and homology
***** 1. Exactitud entre ceros.
 \[ \dots \overset{}\longrightarrow 0 \overset{}\longrightarrow M \overset{}\longrightarrow 0 \overset{}\longrightarrow \dots \]
 Tenemos que el núcleo de la segunda debe ser igual a la imagen de la primera y
 por tanto, cero. Eso sólo es posible si $M=0$.

***** 2. Exactitud entre isomorfías
     \[ \dots \overset{}\longrightarrow 0 \overset{}\longrightarrow M \overset{}\longrightarrow M' \overset{}\longrightarrow 0 \longrightarrow \dots\]
 Tenemos por el primer 0 la función inyectiva y por el segundo la función 
 sobreyectiva. Debe ser por tanto isomorfismo.

***** 3. Kernel y cokernel en secuencia exacta
     \[ \dots \overset{}\longrightarrow 0 \overset{}\longrightarrow L \overset{}\longrightarrow M 
     \overset{\phi}\longrightarrow M' \longrightarrow N \longrightarrow 0 \longrightarrow \dots \]
 Por el primer 0 tengo una inyección $i$ de $L$ en $M$, que lo identifica con
 $im(i) = ker(\phi)$. Del segundo 0 tengo que la imagen de la proyección $\pi$ de
 $M'$ en $N$ es todo $N$. Entonces, por teorema de isomorfía y por exactitud:

 \[N = im(\pi) \cong \frac{M'}{ker(\pi)} = \frac{M'}{im(\phi)} = coker(\phi)\]

***** 4. Hotel de Hilbert
 Dada una secuencia de enteros, podemos moverla un paso a la derecha:

 \[(a_1,a_2,a_3,\dots) \longrightarrow (0,a_1,a_2,\dots)\] 

 Para tener el morfismo $\alpha$ que nos da la secuencia exacta:

 \[ 0 \overset{}\longrightarrow \mathbb{Z}^{\oplus \mathbb{N}} \overset{\alpha}\longrightarrow \mathbb{Z}^{\oplus \mathbb{N}} \overset{\pi_1}\longrightarrow \mathbb{Z} \overset{}\longrightarrow 0 \]

 Dada una secuencia de enteros, podemos moverla a los sitios pares y hacer
 proyección de los impares luego:

 \[(a_1,a_2,a_3,\dots) \longrightarrow (0,a_1,0,a_2,0,a_3,\dots)\]

 Para tener los morfismos $\beta$ y $\pi$ que nos dan la secuencia exacta:

 \[ 0 \overset{}\longrightarrow \mathbb{Z}^{\oplus \mathbb{N}} \overset{\beta}\longrightarrow \mathbb{Z}^{\oplus \mathbb{N}} \overset{\pi}\longrightarrow \mathbb{Z}^{\oplus \mathbb{N}} \overset{}\longrightarrow 0 \] 

***** 5. Exactitud entre noetherianos
 Tenemos la secuencia exacta:

 \[ \dots \overset{}\longrightarrow L \overset{\alpha}\longrightarrow M \overset{\beta}\longrightarrow N \overset{}\longrightarrow \dots \]

 Y supongamos $L,N$ noetherianos. Sea entonces una sucesión de ideales \(\{M_i\}\),
 tenemos que las sucesiones de ideales \(\{\alpha^{-1}(M_i)\}\) y \(\{\beta(M_i)\}\) se estabilizarán
 a partir de un cierto $j$. Tomando un $i > j$ tendremos que $M_i = M_{i+1}$ y por tanto,
 se estabilizará la secuencia inicial.

 Supongamos que existiera $x \in M_{i+1}$ pero $x \notin M_i$. Dividimos en dos casos:

 *Caso 1*. $x \in im(\alpha)$, tendríamos que existiría algún elemento 
 $a \in \alpha^{-1}(x) \subset \alpha^{-1}(M_{i+1}) = \alpha^{-1}(M_{i})$, pero por definición entonces $x = \alpha(a) \in M_i$.

 *Caso 2*. $x \notin im(\alpha)$, tendríamos $\beta(x) \in \beta(M_{i+1})$. Existe un $y \in M_i$ tal que 
 $\beta(y) = \beta(x)$, es decir, $x-y \in ker(\beta)$. Pero entonces $x-y \in im(\alpha)$ y por tanto,
 $x-y \in M_i$, llevando a $x\in M_i$.

***** 6. Epimorfismo escindido
 Sea una sucesión:

 \[ 0 \overset{}\longrightarrow ker(\phi) \overset{}\longrightarrow M \overset{\phi}\longrightarrow N \overset{}\longrightarrow 0 \]

 Supongamos que *escinde*, entonces $\phi$ es la proyección hacia $N$ y tiene
 como inversa derecha a la inclusión.

 Supongamos que *tiene inversa* derecha $\psi$, entonces buscamos un isomorfismo
 entre $M \cong ker(\phi) \oplus N$, que tenemos con estos dos morfismos:

 \[(k,n) \mapsto \psi n + k\]
 \[m \mapsto (m-\psi \phi m, \phi m)\]

***** 10. Lema corto de los cinco 
 Si en el lema de la serpiente son $\lambda$ y $\nu$ isomorfismos, tenemos la sucesión:

 \[0 \longrightarrow 0 \longrightarrow ker(\mu) \longrightarrow 0 \overset{\delta}\longrightarrow
   0 \longrightarrow coker(\mu) \longrightarrow 0 \longrightarrow 0\]

 Por tanto, el kernel y cokernel de $\mu$ son nulos y es isomorfismo.

***** 11. Todo morfismo de escisión es isomorfismo
 Directamente aplicando el ejercicio anterior, tenemos que $N \cong M_1 \oplus M_2$.

***** 12. Lema de los cuatro (1)
 Lo probamos por caza del diagrama. Primero tomamos un elemento en el núcleo
 de C y aplicamos:

 - Inyectividad de $\delta$. 
 - Exactitud de $BCD$.
 - Exactitud de $ABC$.
 - Sobreyectividad de $\alpha$.
 - Exactitud de $ABC$.

 Teniendo que el elemento es nulo.

***** 13. Lema de los cuatro (2)
 Volvemos a cazar diagramas. Tomamos un $c'$ en $coker(\gamma)$ y hacemos:

 - Exactitud de CDE.
 - Inyectividad en E.
 - Sobreyectividad de D.
 - Exactitud de CDE.

 Y así llegamos a un $z \in C$ que tiene como imagen un $z' \in C'$. Tomamos $c'-z'$,
 que tiene imagen nula en $D$ y aplicamos:

 - Exactitud de BCD.
 - Sobreyectividad en $B$.

 Y obtenemos un $x \in C$ que tiene como imagen a $c'-z'$. Finalmente: $\gamma(x+z) = c'$.

***** 14. Lema de los cinco
 Trivial uniendo ambos lemas de los cuatro.

*** VI. Linear Algebra
**** 1. Free modules revisited
***** 1. R y C son isomorfos como espacios vectoriales de Q
 Sabemos que $C \cong R \oplus R$. Dada una base $B$ de $\mathbb{R}$, podemos ver que será
 infinita y por axioma de elección isomorfa a $B+B$, que será a su
 vez una base de $\mathbb{R}^2$. Luego $\mathbb{R} \cong \mathbb{R} \oplus \mathbb{R}$.

***** 4. Álgebras de Lie
 Demostramos que $[u,v] = -[v,u]$. Ya que tenemos:

 $$[u,v] + [v,u] = [u,v] + [u,u] + [v,v] + [v,u] = [u+v,v] + [u+v,u] = [u+v,u+v] = 0$$

 Para todas las K-álgebras, tomar $[v,w] = vw-wv$ nos da un álgebra de Lie.
 Podemos verlo porque cumple las tres primeras propiedades que se le piden a un
 álgebra de Lie y además:

 \begin{align*}
 [[u,v],w] + [[v,w],u] + [[w,u],v] & = \\
 (uvw-vuw-wuv+wvu) &+\\
 (vwu-wvu-uvw+uwv) &+\\
 (wuv-uwv-vwu+vuw) &=\\
 0
 \end{align*}

***** 5. Sistemas generadores e independientes en dominios de integridad
 Un sistema independiente puede no crecer a base y un sistema generador
 puede no reducirse a base en un dominio de integridad. Como ejemplos
 tenemos $\mathbb{Z}$ con: {2} como sistema independiente y $\{2,3\}$ como sistema generador.
 Ninguno puede crear base porque las únicas bases posibles serían $\{1\}$ y $\{-1\}$.

***** 13. Un grupo abeliano con endomorfismos de característica 0.
 Si tiene endomorfismos que forman un cuerpo de característica 0, podemos
 identificar $\mathbb{Z}$ con los endomorfismos por propiedad universal y
 luego podemos extenderlo por contener $Q$ las inversas. De otro modo, 
 $Q$ es inicial en la categoría de cuerpos de característica 0, así, hay
 forma de identificarlo con endomorfismos del cuerpo.

 Así, nuestro grupo $A$ es espacio vectorial sobre $Q$. Y es de dimensión 1,
 porque si tuviera dimensión mayor y una base de más de un elemento, colapsar
 dos elementos de la base en uno sería un endomorfismo sin inversa.

***** 14. La potencia de un isomorfismo estabiliza kernel e imagen.
 Tenemos que $ker(\phi^n) \subset ker(\phi^{n+1})$ y que dos subespacios contenidos de la misma
 dimensión deben ser iguales. Por tanto, la dimensión debe crecer o estabilizarse
 a cada paso. Si la dimensión es finita debe estabilizarse en algún punto.

 Por otro lado, tenemos que las imágenes deben estabilizarse en dimensión
 para tener $ker(\phi^n) \oplus im(\phi^{n+1}) = V$. Y entonces, para que el kernel no crezca,
 ninguno de los vectores que forman la base de $im(\phi^n)$ pueden tener como
 imagen algo que esté en $ker(\phi)$, así que vuelven a tener como imagen algo en
 $im(\phi^{n+1})$, que debe estar contenido en $im(\phi^n)$ y ser de la misma
 dimensión.

**** 2. Homomorphisms of free modules I
***** 1. Grupo isomorfo a la suma
 Tenemos que:

 \[
 \left( \begin{matrix} 1 & 0 \\ r & 1 \end{matrix} \right)
 \left( \begin{matrix} 1 & 0 \\ p & 1 \end{matrix} \right) =
 \left( \begin{matrix} 1 & 0 \\ r+p & 1 \end{matrix} \right)
 \]

 Luego la proyección del tercer elemento es un isomorfismo
 de grupos.

***** 6. Row echelon form
 Cuando trabajamos en un cuerpo podemos pasar a /row echelon form/ usando
 los siguientes pasos:

  - Pasamos el primer elemento no nulo a la fila más alta.
  - Lo hacemos uno con su inversa y reducimos toda la columna restante.
  - Hacemos lo mismo con la submatriz a la derecha y debajo de ese 1.

 Esto debe dejarnos sólo ceros debajo y encima de los 1 pivotes.

**** 4. Presentations and resolutions
***** 1. Tor(M) es submódulo de M cuando R es dominio de integridad.
 Tenemos $Tor(M) = \{ m | \exists r \in R : r \neq 0, rm = 0\}$, y siendo dos elementos $m,n$ en $Tor(M)$, 
 que cumplen que $rm = 0$ y $qn = 0$, podemos
 ver que su suma será cerrada y que el producto por $r\in R$ será cerrado cuando
 $R$ es conmutativo:

  - $rq(m+n) = rqm+qrn = 0+0 = 0$
  - $r(pm) = p(rm) = 0$

 Usando aquí que es dominio de integridad y por tanto $rq \neq 0$.

***** 2. Hom(M,N) es libre de torsión cuando lo es N.
 Supongamos que no lo fuera, existiría un $f \in Hom_R(M,N)$ tal que 
 $rf = 0$ para algún $r$ no divisor de $0$. Pero entonces, esto haría
 que en el anillo $N$ existiese $rf(m) = 0$ para cualquier $m$, y por 
 ser libre de torsión, se tendría $f(m) = 0$ para todo $m$.
 Luego $f=0$.

 En particular $Hom_R(M,R)$ es libre de torsión.

***** 4. Propiedades del anulador
 Suponiendo $p,q \in Ann(R)$, tenemos que para todo $m \in M$ se tendrá
 $pm=0$ y $qm=0$. Por lo tanto $(p+q)m=0$ y $rpm = 0$, haciéndolo ideal.

****** M de torsión si y sólo si el anulador es no nulo.
 Si $Ann(M) \neq 0$, existe un elemento de $R$ que anula todo $M$, como
 además $R$ es dominio de integridad, este elemento no será divisor de 0, y $M$
 será torsión. Si $M$ es torsión y finitamente generado, tendrá un elemento
 $r_i$ que anulará cada uno de sus generadores $m_i$. Siendo $R$ conmutativo,
 el elemento producto estará en el anulador

                      \[
 \prod_{i} r_i
 \] 

 Nótese que si quitamos la condición de que $M$ sea finitamente generado, existen
 módulos como \(\mathbb{Z}_2 \oplus \mathbb{Z}_4 \oplus \mathbb{Z}_8 \dots\) que son torsión porque todo elemento se anula pero
 tienen anulador vacío porque no existen elementos que anulen todo el módulo.

***** 13. Complejo de Koszul

****** Es un complejo.
 Comprobamos que es un complejo viendo que las siguientes composiciones son $0$:

  - \(d_1 \circ d_2 (t) = bta - atb = 0\)
  - \(\pi \circ d_1 (r,s) = (ra+sb)\ mod(a,b)) = 0 \)

****** Es un complejo exacto cuando la secuencia es regular.
 Y comprobamos que es exacto en el caso en el que la secuencia es regular viendo
 que:

 - \(ker(d_2) = 0\), ya que $a$ no es divisor de cero.
 - \(ker(d_1) = <(b,-a)>\). Tenemos que $b$ no es divisor de cero módulo $a$, así, para que
   sea linealmente dependiente con $a$ necesitamos algo que sea cero módulo $a$. Este
   caso requiere $s$ múltiplo de $a$. Esto requiere estar dentro del ideal generado por
   $(b,-a)$.
 - Que la imagen de $d_1$ es el núcleo de $\pi$ y que la proyección es sobreyectiva
   es trivial.

***** 14. Complejo de Koszul en el caso de 3 elementos
****** Es un complejo
 Volvemos a comprobar que las composiciones son nulas. Tenemos de hecho que:

 \[d_2 \circ d_1 = d_3 \circ d_2 = 0\]

 Y que la proyección coincide con el generado por $d_1$.

****** Es un complejo exacto cuando la secuencia es regular
 Otra vez, como $c$ no es divisor de cero módulo $(a,b)$, tenemos que el kernel
 de $d_3$ es nulo. De la misma forma, se tiene que el $ker(d_2)=im(d_3)$, aplicando
 en cada caso el no ser divisor de cero. Vuelve a tenerse una ecuación similar
 que demuestra $ker(d_1) = im(d_2)$. El caso de la proyección es trivial.
***** 15. Resolución de Z sobre Z[x,y]
 Podemos encontrar una resolución como:

 \[0 \longrightarrow 
 \mathbb{Z}[x,y] \overset{\phi} \longrightarrow 
 \mathbb{Z}[x,y]^2 \overset{\delta} \longrightarrow 
 \mathbb{Z}[x,y] \overset{\pi} \longrightarrow 
 \mathbb{Z} \longrightarrow 0 \]

 Donde $\pi$ es un morfismo que cancela $x,y$. $\delta$ es un morfismo que lleva
 cada una de las copias del $1$ a $x$ e $y$. Finalmente, $\phi$ es monomorfismo
 que lleva $1$ a $(y,-x)$ que es generador de $ker(\delta)$.

*** VIII. Linear algebra, reprise
**** 1. Preliminaries, reprise
***** 1.2. Funtor plenamente fiel respeta isomorfías 
 Sea ${\cal F}(A) \cong {\cal F}(B)$, gracias a dos morfismos inversos $\alpha,\beta$. Como
 el funtor es pleno, existen dos morfismos preimagen de ambos
 llamados $\alpha',\beta'$ y tenemos que:

 \[{\cal F}(\alpha' \circ \beta') = \alpha \circ \beta = 1\]

 Por ser fiel, debemos tener $\alpha' \circ \beta' = 1$.
***** 1.3. Acción de grupo como funtor
 Sea $G$ un grupo. Su acción sobre un objeto $C$ será un morfismo que
 envíe cada elemento del grupo a un isomorfismo de $C$. Es decir, un
 homomorfismo de grupos:

 \[(G,\ast) \longrightarrow (Aut(C),\circ)\]

 Pero como podemos ver $G$ como un objeto tal que cada uno de sus elementos
 sea un isomorfismo, tenemos claramente un isomorfismo:

 \[(Aut(G),\circ) \cong (G,\ast) \longrightarrow (Aut(C),\circ)\]

 Y podemos definir el funtor que lleva $G$ a $C$ y que lleva cada endomorfismo
 de $G$ a uno de $C$.

***** 1.17. Compleción de un álgebra
 Tenemos que los $R/I^n$ son módulos en R-Mod, por tanto, la cadena siguiente
 tendrá límite. Donde los morfismos serán las inclusiones naturales:

 \[\dots \longrightarrow R/I^3 \longrightarrow R/I^2 \longrightarrow R/I \]

 Ese límite lo llamamos $R_I$, y es el submódulo de secuencias coherentes de $\prod_i R/I^i$.
 Es decir, un elemento suyo es una secuencia tal que cada elemento es la proyección
 del siguiente. Este submódulo es conmutativo porque lo es el producto de todos los módulos.

 Podemos incluir $R$ en $R_I$ llevando el $1$ a $(1,1,1,\dots)$. Y esto conmutará con las
 proyecciones naturales que nos daba la propiedad universal.
 Para que $x$ se anule al incluirlo en $R_I$ desde $R$, necesitamos que todas las proyecciones
 de su imagen sean $0$, así que necesitamos que pertenezca a $I_n$ para cada $n$.

***** 1.19. Enteros p-ádicos
 Llamamos enteros p-ádicos al límite $\mathbb{Z}_p = \varprojlim \mathbb{Z}/p^i\mathbb{Z}$, y números p-ádicos a su cuerpo de fracciones
 $\mathbb{Q}_p$. Por definición, un entero p-ádico es una secuencia de enteros $\{a_i\}$ tales que:

 \[ a_s \equiv a_r  \mod (p^s)\]

 Para cualesquiera $s \leq r$. De otra forma, cada entero tiene una expansión única:

 \[ A = b_0 + b_1 p + b_2 p^2 + b_3 p^3 + \dots\]

 Donde $b_i < p$. Esto es así porque dada una secuencia $(a_i)$, tenemos la igualdad:

 \[b_0 = a_0\]
 \[b_i p^i + a_{i+1} = a_i\]

 Y se puede construir una desde la otra usando que $a_i - a_{i+1} \equiv_{p^i} 0$. 

 A partir de aquí podemos hacer aritmética como usualmente desde estos desarrollos de los
 números p-ádicos.
**** 2. Tensor products, and the Tor functors
***** 2.14. Tor en 0 es el producto tensor
 La definición inicial de Tor es como:

 \[Tor^R_i(M,N) = H_i(M_\bullet \otimes N)\]

 Y como tenemos que el complejo $M_\bullet \otimes N$ es el siguiente,
 siendo $S_0$ una base de $M$, y $S_1$ base de las relaciones de $M$:

 \[ \dots \overset{}\longrightarrow N^{\oplus S_2} 
 \overset{\phi_2}\longrightarrow N^{\oplus S_1} 
 \overset{\phi_1}\longrightarrow N^{\oplus S_0} 
 \overset{}\longrightarrow 0 \]

 Que ha salido de tensar el siguiente complejo exacto:

 \[ \dots \overset{}\longrightarrow R^{\oplus S_1} \overset{\psi_2}\longrightarrow R^{\oplus S_0} \overset{\psi_1}\longrightarrow M \overset{}\longrightarrow 0 \]

 Tenemos que:

 \[H_i(M_\bullet \otimes N) \cong \frac{N^{\otimes S_0}}{im(\phi_1)} \cong 
 \frac{R^{\otimes S_0}}{im(\psi_2)} \otimes N \cong M \otimes N \]

 Donde usamos la exactitud de la segunda secuencia con el primer teorema de isomorfía
 y el hecho de que el functor $\otimes N$ respeta los colímites y por tanto el cociente, que puede
 verse como coecualizador.

* The Catsters
** Adjunctions
Serie de [[https://www.youtube.com/playlist?list=PL54B49729E5102248][vídeos]] sobre funtores adjuntos.

*** Adjuntions 1
Tenemos varias nociones de igualdad entre categorías.

#+begin_definition
*Isomorfismo de categorías*. Ocurre con dos functores:

\[ \begin{tikzcd}
{\cal C} \arrow[bend left]{r}{F} & {\cal D} \arrow[bend left]{l}{G}
\end{tikzcd}
\]

Tales que $1_C = GF$ y $FG = 1_D$.
#+end_definition

#+begin_definition
*Equivalencia de categorías*. Ocurre con dos functores:

\[ \begin{tikzcd}
{\cal C} \arrow[bend left]{r}{F} & {\cal D} \arrow[bend left]{l}{G}
\end{tikzcd}
\]

Tales que $1_C \cong GF$ y $FG \cong 1_D$. Entendiendo la isomorfía en la 
categoría de funtores, es decir, una [[https://ncatlab.org/nlab/show/natural+isomorphism][isomorfía natural]].
#+end_definition

#+begin_definition
*Adjunción*. Ocurre con dos functores:

\[ \begin{tikzcd}
{\cal C} \arrow[bend left]{r}{F} & {\cal D} \arrow[bend left]{l}{G}
\end{tikzcd}
\]

Tales que tenemos transformaciones naturales $1_C \overset{\eta}\Longrightarrow GF$ y 
$FG \overset{\epsilon}\Longrightarrow 1_D$ que cumplen las dos identidades triangulares siguientes:
 
\[ \begin{tikzcd}
F \arrow{r}{\eta} \arrow{dr}{id} & FGF \arrow{d}{\epsilon} \\
 & F
\end{tikzcd}   
\]     \[ \begin{tikzcd}
G \arrow{r}{\eta} \arrow{dr}{id} & GFG \arrow{d}{\epsilon} \\
 & G
\end{tikzcd}
\]
#+end_definition

En este caso escribimos $F \dashv G$, y $F$ es funtor adjunto de $G$.

*** Adjuntions 2
Damos una definición equivalente de funtores adjuntos.

#+begin_definition
*Adjunción*. Una adjunción es un isomorfismo natural:

\[Hom_D(FX,Y) \cong Hom_C(X,GY)\]

Natural sobre $X$ fijado cualquier $Y$ y natural sobre $Y$ fijado 
cualquier $X$. Entendiendo que usamos los funtores contravariantes $Hom(F-,Y)$,
$Hom(-,GY)$ por un lado y los funtores covariantes $Hom(FX,-)$ y $Hom(X,G-)$;
que nos dan los siguientes cuadrados de naturalidad:

\[ \begin{tikzcd}
Hom_D(FX',Y) \arrow{d}[swap]{Hom_D(Ff,Y)} \arrow{r}{\alpha_{X'}} & Hom_C(X',GY) \arrow{d}{Hom_C(f,GY)}\\
Hom_D(FX, Y) \arrow{r}{\alpha_{X}}& Hom_C(X,GY)
\end{tikzcd}
\] 

\[ \begin{tikzcd}
Hom_D(FX,Y) \arrow{d}[swap]{Hom_D(FX,g)} \arrow{r}{\beta_{Y}} & Hom_C(X,GY) \arrow{d}{Hom_C(X,Gf)}\\
Hom_D(FX,Y') \arrow{r}{\beta_{Y'}}& Hom_C(X,GY')
\end{tikzcd}
\] 
#+end_definition

Esta definición es equivalente intuitivamente a la anterior porque podemos crear $\eta$ y $\epsilon$
desde las identidades usando las siguientes transformaciones naturales: 

\[Hom_D(FX,FX) \cong Hom_C(X,GFX)\]

\[Hom_D(FGY,Y) \cong Hom_C(GY,GY)\]

*** Adjuntions 3

Podemos presentar ejemplos de adjunciones.
Los *funtores libres y de olvido* suelen ser adjuntos. Entre $Set$ y $Monoid$ tenemos:

\[ \begin{tikzcd}
{Set} \arrow[bend left]{r}{Free} & {Monoid} \arrow[bend left]{l}{Forget}
\end{tikzcd}
\]

Con la adjunción $Free \dashv Forget$. 

#+begin_theorem
*Mónada de una adjunción*. Cada adjunción da lugar a una mónada.
#+end_theorem

Tenemos un funtor $T = GF : {\cal C}  \longrightarrow {\cal C}$. Podemos definir la unidad de
la mónada como la unidad de la adjunción $\eta : 1_C \Longrightarrow T$ y la
multiplicación podemos definirla usando $id \ast \epsilon \ast id : GFGF \Longrightarrow GF$.

Ahora debemos comprobar que cumple los axiomas de mónada. El primero
se obtiene directamente desde los triángulos de la adjunción:

\[ \begin{tikzcd}
T \arrow{r}{T\eta} \arrow{dr}{id} & T^2 \arrow{d}{\mu} \\
 & T
\end{tikzcd}   
\]   \[ \begin{tikzcd}
GF \arrow{r}{GF\eta} \arrow{dr}{id} & GFGF \arrow{d}{G \epsilon F} \\
 & GF
\end{tikzcd}   
\]

Donde el segundo es resultado de aplicar el funtor $G$ a uno de los triángulos conmutativos
de la adjunción. Comprobamos el segundo axioma:

\[ \begin{tikzcd}
T^2 \arrow{d}{\mu} & T \arrow{dl}{id} \arrow{l}[swap]{\eta T} \\
T
\end{tikzcd}   
\]   \[ \begin{tikzcd}
GFGF \arrow{d}{G \epsilon F} & GF \arrow{dl}{id} \arrow{l}[swap]{\eta GF} \\
GF
\end{tikzcd}   
\]

Donde tenemos el resultado de aplicar $F$ por la derecha al otro triángulo conmutativo.

Y finalmente el axioma de conmutatividad de la mónada se comprueba como:

\[ \begin{tikzcd}
T^3 \arrow{d}{T \mu} \arrow{r}{\mu T} & T^2 \arrow{d}{\mu} \\
T^2 \arrow{r}{\mu} & T
\end{tikzcd} \]  \[ \begin{tikzcd}
GFGFGF \arrow{d}{GFG \epsilon F} \arrow{r}{G \epsilon FGF} & GFGF \arrow{d}{G\epsilon F} \\
GFGF \arrow{r}{G \epsilon F} & GF
\end{tikzcd} \] 

Donde el segundo diagrama se obtiene desde la naturalidad de $\epsilon$ aplicando funtores.

*** Adjuntions 4
Vamos a probar la igualdad entre las dos definiciones de adjunción.
Supongamos primero que tenemos el isomorfismo natural entre los dos 
conjuntos de morfismos, es decir, tenemos:

\[ (-) : Hom_D(FX,Y) \cong Hom_C(X,GY) \]

Si tomamos ahora los dos cuadrados naturales que teníamos por este 
isomorfismo y tomamos en ellos los casos particulares $Y = FX$ primero,
y $X = GY$ después:


\[ \begin{tikzcd}
Hom_D(FX,FX) \arrow{d}[swap]{\_ \circ Ff} \arrow{r}{(-)} & Hom_C(X,GFX) \arrow{d}{\_\circ f}\\
Hom_D(FX', FX) \arrow{r}{(-)}& Hom_C(X',GFX)
\end{tikzcd}
\]

Si tomamos la identidad $1_{FX}$ y llamamos $\eta_X = \overline{1_{FX}}$, tenemos que
\(\eta \circ f = \overline{Ff}\). Ahora, si damos la vuelta al isomorfismo $(-)$ en este 
diagrama a la vez que hacemos $X = GY$:

\[ \begin{tikzcd}
Hom_D(FGY,Y) \arrow{d}[swap]{\_ \circ Ff}  & Hom_C(GY,GY) \arrow{l}[swap]{(-)} \arrow{d}{\_\circ f}\\
Hom_D(FGY',Y) & Hom_C(GY',GY) \arrow{l}[swap]{(-)}
\end{tikzcd}
\]

Volviendo a tomar la identidad $1_{GY}$ y llamando $\epsilon_Y = \overline{1_{GY}}$, tenemos
$\epsilon \circ Ff = \overline{f}$.

Ahora tomamos el segundo cuadrado natural, y repetimos el mismo
proceso.

\[ \begin{tikzcd}
Hom_D(FX,FX) \arrow{d}[swap]{g \circ \_} \arrow{r}{(-)} & Hom_C(X,GFX) \arrow{d}{Gg\circ \_}\\
Hom_D(FX,FX') \arrow{r}{(-)}& Hom_C(X,GFX')
\end{tikzcd}
\] 

Obteniendo desde la identidad en $FX$ la ecuación $\overline{g} = Gg \circ \eta$. Y volviendo
a dar la vuelta a los isomorfimos llegamos a:

\[ \begin{tikzcd}
Hom_D(FGY,Y) \arrow{d}[swap]{g \circ \_}  & Hom_C(GY,GY) \arrow{l}[swap]{(-)} \arrow{d}{Gg \circ \_}\\
Hom_D(FGY,Y') & \arrow{l}[swap]{(-)} Hom_C(GY,GY')
\end{tikzcd}
\]

Obteniendo finalmente $\overline{Gg} = g \circ \epsilon$. De este proceso hemos obtenido finalmente
las siguientes ecuaciones:

\[ \begin{aligned}
\eta \circ f &= \overline{Ff} \\
\epsilon \circ Ff &= \overline{f} \\
Gg \circ \eta &= \overline{g} \\
g \circ  \epsilon &= \overline{Gg} 
\end{aligned} \]

Con ellas podemos probar la naturalidad de $\eta$ y la naturalidad de
$\epsilon$:

\[ \begin{tikzcd}
GFX  \arrow{r}{GFf} & GFY \\
X \arrow{u}[swap]{\eta_X} \arrow{r}[swap]{f} & Y \arrow{u}{\eta_Y}
\end{tikzcd}
\]   \[ \begin{tikzcd}
FGX \arrow{d}[swap]{\epsilon_X} \arrow{r}{FGg} & FGY \arrow{d}{\epsilon_Y}\\
X \arrow{r}[swap]{g} & Y
\end{tikzcd}
\]

Ya que $\eta \circ f = \overline{Ff} = GFf \circ \eta$ y $f \circ \epsilon = \overline{Gf} = \epsilon \circ FGf$. Y además podemos probar
los dos triángulos de naturalidad.

\[ \begin{tikzcd}
F \arrow{r}{F \eta_X} \arrow{dr}{id} & FGF \arrow{d}{\epsilon_{FX}} \\
 & F
\end{tikzcd}   
\]     \[ \begin{tikzcd}
G \arrow{r}{\eta_{GX}} \arrow{dr}{id} & GFG \arrow{d}{G\epsilon_X} \\
 & G
\end{tikzcd}
\]

Teniendo finalmente que:


\[ \begin{aligned}
\epsilon \circ F\eta &= \overline{\eta} = 1 \\
G\epsilon \circ \eta &= \overline{\epsilon} = 1
\end{aligned} \]

El otro sentido de la demostración se tiene llegando primero a las cuatro ecuaciones,
y usándolas para definir el isomorfismo $(-)$. Falta entonces demostrar su naturalidad.
* Harpreet Bedi's channel
** Sheaves and coho
*** Preseaves and sheaves
**** Preseaf definition
#+begin_definition
*Preseaf*. A preseaf ${\cal F}$ of abelian groups on a topological space $X$ consists of:

- For each open set $U$, an abelian group ${\cal F}(U)$, whose elements are called *sections*.
- For each inclusion $V \subseteq U$, a *restriction map*, homomorphism of the form:
  
 
\[p_{U,V} : {\cal F}(U) \longrightarrow {\cal F}(V)\]

such that $p_{U,W} = p_{V,W} \circ p_{U,V}$.
#+end_definition

We can write the restriction of an element $u \in U$ to a set $V \subseteq U$ as
$u|_V = p_{U,V}(u)$.

**** Sheaf definition
 #+begin_definition
 *Gluability axiom*. Given $U = \bigcup U_i$ with sections $s_i \in {\cal F}(U_i)$, if we have:

 \[ s_\alpha|_{U_\alpha \cap U_\beta} = s_\beta|_{U_\alpha \cap U_\beta} \]

 then there exists $s \in {\cal F}(U)$ such that $s|_U_\alpha = s_\alpha$.
 #+end_definition
 #+begin_definition
 *Uniqueness axiom*. Given $U = \bigcup U_i$ with sections $s,t \in {\cal F}(U)$ such that:

 \[\forall U_\alpha:\ s|_U_\alpha = t|_U_\alpha\]

 then $s=t$.
 #+end_definition
 #+begin_definition
 *Sheaves*. A presheaf satisfiying gluability and uniqueness.
 #+end_definition
** Homological Algebra
*** 2. Chain Complex and Homology
*** 4. Homology Theorem
**** Setting
Given a SES of chain complexes $0 \longrightarrow {\cal A}
\longrightarrow{\cal B}
\longrightarrow{\cal C}
\longrightarrow 0$, we have a long exact
sequence like:

\[ \begin{tikzcd}
 & \dots\rar & H_{n+1}({\cal C}) \arrow[out=355,in=175,swap]{dll}{\delta_{n+1}} \\
H_{n}({\cal A})\rar & H_{n}({\cal B}) \rar & H_{n}({\cal C}) \arrow[out=355,in=175,swap]{dll}{\delta_n}\\
H_{n-1}({\cal A})\rar & \dots & 
\end{tikzcd} \]

**** Naturality
When we have two SES of chain complexes:

\[ \begin{tikzcd}
0 \rar & {\cal A}\rar\dar & {\cal B}\rar\dar & {\cal C}\rar\dar & 0 \\
0 \rar & {\cal A}'\rar & {\cal B}'\rar & {\cal C}'\rar & 0 \\
\end{tikzcd} \]

where it hols for every $n$ that:

\[ \begin{tikzcd}
H_n({\cal C}) \rar\dar & H_{n-1}({\cal A})\dar \\
H_n({\cal C}') \rar & H_{n-1}({\cal A}')
\end{tikzcd} \]

*** 8. Proj, inj and flat modules
**** Definitions
An $R$-module $D$ is:

 1. *Projective* if $Hom(D, -)$ is exact.
 2. *Injective* if $Hom(-,D)$ is exact.
 3. *Flat* if $D \otimes -$ is exact.

**** Considerations
We know that $Hom(D,-)$ and $Hom(-,D)$ are left-exact and that
$D\otimes -$ is right-exact; so for them to be exact, we only need:

 - A module $D$ is *projective* when $B \longrightarrow C$ surjective induces
   $Hom(D,B) \longrightarrow Hom(D,C)$ surjective.

   \[ \begin{tikzcd}
               & B \dar[two heads] \\
   D \rar\urar[dashed]{\exists} & C
   \end{tikzcd} \]

 - A module $D$ is *injective* when $A \longrightarrow B$ surjective induces
   $Hom(B,D) \longrightarrow Hom(A,D)$ surjective.

   \[ \begin{tikzcd}
     & A \dar[two heads]\dlar \\
   D & B \lar[dashed]{\exists}
   \end{tikzcd} \]

 - A module $D$ is *flat* when $A \longrightarrow B$ injective induces 
   $D\otimes A \longrightarrow D \otimes B$ injective.

*** 9. Resolutions: projective, injective and flat
**** Definitions
***** Resolutions
Resolutions are *exact sequences*.

***** Projective resolution
A resolution, with $d_i$ maps:

\[\dots\longrightarrow P_2\longrightarrow P_1\longrightarrow P_0
\longrightarrow M \longrightarrow 0\]

where $P_i$ is projective.

***** Injective resolution
A resolution:

\[0 \longrightarrow M \longrightarrow E_0\longrightarrow E_1
\longrightarrow E_2 \longrightarrow \dots\]

where $E_i$ is injective.

***** Flat resolution
A resolution:

\[\dots\longrightarrow F_2\longrightarrow F_1\longrightarrow F_0
\longrightarrow M \longrightarrow 0\]

where $F_i$ is flat.

**** How to form a resolution
It is important to notice that, given a module $M$, you can always find a surjection
from a proyective module (we have /enough projectives/). So we can construct a
projective resolution as follows:

\[ \begin{tikzcd}
&\ker f_2 \drar&&&&\ker \pi\drar &&& \\
\dots&&P_2 \drar[two heads]{f_2}&&P_1 \urar[two heads]{f_1} && P_0 \rar[two heads]{\pi} & M \rar & 0\\
&&&\ker f_1 \urar&&&&
\end{tikzcd} \]

We can reverse the arrows to obtain an injective resolution.

*** TODO 10. Homotopic projective resolutions
**** Extending a morphism
Given two projective resolutions of two $R$ modules, $A$ and $A'$, and a morphism
between them, $f$. We can extend it to $f_n \in Hom(P_n,P_n')$.

\[ \begin{tikzcd}
\dots\rar & P_{n+1}\rar & P_n\rar& \dots
 \rar & P_1\rar{d_1} & P_0\rar{d_0}& A \dar{f} \rar& 0 \\
\dots\rar & P_{n+1}'\rar & P_n'\rar&\dots
 \rar & P_1'\rar{d_1¡} & P_0'\rar{d_0'}& A' \rar& 0 \\
\end{tikzcd} \]

**** Extending the morphism, base case
We use that $P_0$ is projective to construct:

\[ \begin{tikzcd}
     & P_0 \arrow[ddl,"f_0",dashed,swap] \dar\\
     & A \dar{f} \\
P_0' \rar[two heads] & A'
\end{tikzcd} \]

**** Extending the morphism, inductive case
We are going to show that $f_n(\im d_{n+1}) \subset \im d_{n+1}' = \ker d_n'$. That is, 
$d_n' \circ f_n \circ d_{n+1} = 0$. And that follows from diagram chasing. We use
again the projectivity of $P_{n+1}$.

\[ \begin{tikzcd}
     & P_{n_+1} \arrow[ddl,"f_{n+1}",dashed,swap] \dar\\
     & \im d_{n+1} \dar{f_n} \\
P_{n+1}' \rar[two heads] & \im d_{n+1}'
\end{tikzcd} \]


**** TODO Homotopic resolutions
*** 11. Derived functors Ext and Tor
**** Right derived functors
Let $F$ be additive, covariant and left-exact. Let 
$0 \longrightarrow M \longrightarrow E^\bullet$ be an injective resolution with $M$ deleted; then $F(E^\bullet)$ is a complex,
and we define:

\[R^i F(M) = H^i(F(E^\bullet)) = 
\frac{\ker \{F(E_i) \longrightarrow F(E_{i+1})\}}
{\im\{ F(E_{i-1}) \longrightarrow F(E_i)\}}\]

That is, if we take the injective resolution:

\[ 0 \longrightarrow M \longrightarrow E_0 \longrightarrow E_1 
\longrightarrow \dots\]

Delete $M$ and apply $F$ to get a (non neccesarily exact) complex where we can compute 
the homology:

\[ 0 \longrightarrow F(E_0) \longrightarrow F(E_1)
\longrightarrow F(E_2) \longrightarrow \dots\]

**** Left derived functors
Let $F$ be additive, contravariant and left-exact. Let 
$P^\bullet \longrightarrow M \longrightarrow 0$ be a projective resolution with $M$ deleted; then $F(E^\bullet)$ is a complex,
and we define:

\[R^i F(M) = H^i(F(P^\bullet)) = 
\frac{\ker \{F(P_i) \longrightarrow F(P_{i+1})\}}
{\im\{ F(P_{i-1}) \longrightarrow F(P_i)\}}\]

That is, if we take the injective resolution:

\[\dots \longrightarrow P_2\longrightarrow P_1\longrightarrow P_0
\longrightarrow M \longrightarrow 0\]

Delete $M$ and apply $F$ to get a (non neccesarily exact) complex where we can compute 
the homology:

\[ 0 \longrightarrow F(P_0) \longrightarrow F(P_1)
\longrightarrow F(P_2) \longrightarrow \dots\]
* Jara - Apuntes
** XIII. Homología de Hochschild
*** 3. Cohomología de Hochschild
**** Resolución proyectiva
***** R;R módulo
      Sea $R$ una $K\text{-álgebra}$; un $(R;R)$ *módulo* es un $R$ módulo a izquierda y derecha 
      verificando la *relación de compatibilidad*:

      \[r_1(mr_2) = (r_1m)r_2\]

      En particular, se tiene,

      \[km = mk \quad \forall k \in K\]

      Un *homomorfismo de R;R-módulos* es un homomorfismo de R-módulos a izquierda y
      *R-módulos* a derecha. Forman la categoría $(R;R)\mathtt{-Mod}$.

***** Álgebra envolvente
Sea $R$ una $K\text{-álgebra}$, llamamos *álgebra envolvente* a $R^e = R \otimes R^{op}$.
Con el producto:

\[ (r_1 \otimes s_1)(r_2 \otimes s_2) = (r_1r_2) \otimes (s_2s_1)\]

***** Caracterización de R;R-módulos
Para cada $K\text{-álgebra}$, $R$, las categorías siguientes son isomorfas:

  - $(R;R)\text{-Mod}$
  - $R^e\text{-Mod}$
  - $\text{Mod-}R^e$

**** Cohomología de Hochschild
***** Definición 
Sea $R$ una $K\text{-álgebra}$ y $M$ un $(R;R)\text{-módulo}$, llamamos:

  - *cohomología de Hochschild* de $R$ en $M$ a 
    $HH^{\bullet}(R,M) = \operatorname{Ext}^\bullet_{R^e}(R,M)$.
  - *homología de Hochschild* de $R$ en $M$ a 
    $HH_{\bullet}(R,M) = \operatorname{Tor}_\bullet^{R^e}(R,M)$.
* Pierce - Associative Algebras
** 10. Separable Algebras
*** 10.1. Bimodules
**** Opposite algebra
If $A$ is an R-algebra, the *opposite algebra* of $A$ is $A^\ast$; where
multiplication is defined as $x \circ y = yx$.

**** Enveloping algebra
The *enveloping algebra* of an R-algebra is:

\[ A^e = A^\ast \otimes A\]
* Rotman - An introduction to homological algebra
** 1. Introduction
*** 1.1. Simplicial Homology
**** Motivation: Green's Theorem
***** Original statement
Let $C$ be a positively oriented, smooth and simple closed curve in
a plane; being $D$ the region bounded by $C$. If $L,M$ have continuous
partial derivatives in $D$, then:

\[ \oint_C (L dx + M dy) = 
\iint_D \left(
  \frac{\partial M}{\partial x} - \frac{\partial L}{\partial y}
\right) dx dy\]

***** A rewrite
If we have some "bad points" that we want to delete from $C$.
We can define multiple $\gamma_i$ around them and have our integral to be:

\[ \oint_C (L dx + M dy) +
\sum^n_{i=1} \left( \int_{\gamma_i} L dx + Q dy \right) 
= \iint_D \left(
  \frac{\partial M}{\partial x} - \frac{\partial L}{\partial y}
\right) dx dy\]

As the diagram is:

[[./images/greentheorem.png]]

In this setting, the notion of $\mathbb{Z}$ linear combinations of paths
makes sense. We can take the free abelian group $G[Y]$ with $Y$ being
the set of paths $\gamma : [0,1] \longrightarrow X$.

***** An equivalence relation
For functions satisfying $\frac{\partial Q}{\partial x} = \frac{\partial P}{\partial y}$, the double integral dissapears,
and we have:

\[ \int_{m\gamma + \sum_i m_i\gamma_i} P dx + Q dy = 0\]

Here we can define an equivalence relation between pairs of paths,
where $\beta \sim \beta'$ if:

\[ \int_\beta P dx + Q dy = \int_{\beta'} P dx + Q dy \]

The equivalence class of $\beta$ is called its *homology class*.

**** Boundaries
If we take the simplices to form abelian groups, the boundaries
are homomorphisms.

[[./images/rectangle.png]]

For instance, if we can take this rectangle and compute its boundary.
We use free abelian groups of $n\text{-simplexes}$, called $C_n(X)$.

***** Boundary of a triangle
We use the minus sign to denote the inverse path, and we have:

\[ \delta([a,b,c]) = [a,b] + [b,c] - [a,c]\]

***** Boundary of the boundary of a triangle
As the double boundary is the boundary of a sphere, it is 
automatically null:

\[
\delta(\delta([a,b,c])) = (a - b) + (b - c) - (a - c) = 0
\]

***** Boundary of the rectangle
Now, we can compute the boundary of the rectangle; assuming that
the boundary function is a homomorphism preserving the union:

\[\begin{aligned}
\delta(\square) &=  \delta[a,b,c] + \delta[a,c,d] \\ 
&= [a,b]+[b,c]-[a,c]+[a,c]+[c,d]-[a,d] \\
&= [a,b]+[b,c]+[c,d]-[a,d]
\end{aligned}\]

**** Simplicial boundary maps
Let $X$ be a finite simplicial complex. We define:

\[ \delta_n [v_0,\dots,v_n] 
= \sum^n_{i=0} (-1)^i [v_0,\dots,\hat{v_i},\dots,v_n]\]

being a map from $C_n(X)$ to $C_{n-1}(X)$. We define $\delta_0 = 0$ as a convention.

**** Boundary maps are exact
For all $n > 0$, 

\[\delta_{n-1}\delta_n = 0\]

***** Proof
We can see that, for every pair of indexes, we have the same term 
twice, depending on whether we take the two indexes ordered or using
an inverse order:

\[ 
[x_0,\dots,\hat{x_i},\dots,\hat{x_j},\dots,x_n](-1)^{i+(j-1)} +
[x_0,\dots,\hat{x_i},\dots,\hat{x_j},\dots,x_n](-1)^{j+i} = 0
\]

**** Simplicial cycles and boundaries
The elements in $Z_n(X) = \ker \delta_n \subset C_n(X)$ are called *simplicial cycles*.
The elements in $B_n(X) = \im \delta_{n+1} \subset C_n(X)$ are called *simplicial 
boundaries*.

**** Exactness for cycles and boundaries
For all $n$,

\[ B_n(X) \subseteq Z_n(X)\]

***** Proof
It is trivial knowing that boundary maps are [[*Boundary maps are exact][exact]].

**** Simplicial homology group
The nth simplicial homology group of a finite simplicial complex is:

\[ H_n(X) = Z_n(X) / B_n(X) \]

What survives in this group are the cycles that are not boundaries;
that is, the boundaries of punctured sections.

**** Two modifications
We can consider *homology* with coefficients in $G$ by tensoring the
sequence of chain groups by $G$ and taking homology groups. We can
consider the *cohomology* with coefficients in $G$ applying $Hom(-,G)$
to the chain of groups and then taking homology groups.

*** 1.2. Categories and Functors
**** 1.2.1. Russell's paradox
The Russell paradox is solved in with the Zermelo-Fraenkel axioms,
specifically, the *axiom of comprehension*. It says that any definable
subclass of a set is a set; restricting the comprehension to only
already defined sets.

**** 1.2.2. Classes and sets
A class in ZFC is called *small* if it has a cardinal number. A *set*
is only a small class. In this book, we only worry about classes and
sets that are not a member of themselves.

# A cardinal number?
# More details in Mac Lane, Categories for the working mathematician.

**** 1.2.3. Categories
A category ${\cal C}$ consists of:

 - $obj({\cal C})$, a class of objects.
 - $Hom(A,B)$, a set of morphisms for every ordered pair $(A,B)$.
 - $\circ : Hom(A,B) \times Hom(B,C) \longrightarrow Hom(A,C)$, composition of functions.

**** 1.2.4. Axioms of categories
A category has disjoint $Hom$ sets, and there must be an identity element
$1_A \in Hom(A,A)$ for every morphism, following these rules:

 - The identity is a neutral element: $f \circ 1_A = f$ and $1_B \circ f = f$.
 - Composition is associative: $f \circ (g \circ h) = (f \circ g) \circ h$

**** 1.2.5. Examples of categories
***** Sets
***** Groups
***** Partially ordered sets
***** Inclusion of open sets
***** Topological spaces
***** Abstract simplicial complexes
****** Abstract simplicial complexes
We denote =Abs= the category of abstract simplicial complexes.
An abstract simplicial complex $K$ is a set of *vertices* $Vert(K)$ and
a family of nonempty finite subsets called *simplexes* 
$\sigma \subseteq Vert(K)$ such that:

 1. $\{v\}$ is a simplex for every $v \in Vert(K)$.
 2. Every subset of a simplex is a simplex.

****** Simplicial maps
A *simplicial map* is a function $\phi : Vert(K) \longrightarrow Vert(L)$ 
such that, if $\sigma$ is a simplex in $K$, then $\phi(\sigma)$ is a simplex
in $L$.

****** Dimension
A simplex with $|\sigma| = n+1$ is called a *n-simplex*. Simplicial
maps don't have to preserve dimension.

***** Nerves
If ${\cal U} = \{U\}_{i\in I}$ is the cover of a topological space, we define an 
abstract simplicial complex ${\cal N}({\cal U})$ having vertices $Vert({\cal N}({\cal U})) = {\cal U}$
and simplexes $\{U_0,\dots,U_n\} \subseteq {\cal U}$ such that:

\[ \bigcap_{k=0}^n U_k = \varnothing\]

***** Monoids
***** Homotopy category
**** 1.2.6. Algebraic examples of categories
***** Abelian groups
***** Rings (unital)
***** Commutative rings
**** 1.2.7. Modules
A left R-module, where $R$ is a ring, is an additive abelian group $M$
with a scalar multiplication $R \times M \longrightarrow M$, such that:

 1. $r(m+m') = rm+rm'$
 2. $(r+r')m = rm + r'm$
 3. $(rr')m = r(r'm)$
 4. $1m = m$

A right module is defined anagously.

**** 1.2.8. Examples of modules
***** Vector spaces over a field
***** Abelian groups over Z
***** Every ring over itself
***** Every ring over its center

**** 1.2.9. Homomorphisms of R-modules
A function $f : M \longrightarrow N$ such that:

 1. $f(m+m') = f(m)+f(m')$
 2. $f(rm) = rf(m)$

In the case of right modules, we can define them anagously.

***** The composite and inverse of homomorphisms is an homomorphism
Trivial.

**** 1.2.10. Examples of homomorphisms
***** Linear transformations in vector spaces
***** Homomorphisms of abelian groups for Z-modules
***** Homothety
Let $M$ be an R-module, and $r \in Z(R)$; multiplication by $r$, $\mu_r$, is
an homomorphism because:

\[ \mu_r(am) = r(am) = a(rm) = a\mu_r(m)\]

**** 1.2.11. Opposite rings
If $R$ is a ring, its opposite ring $R^{op}$ is the same ring with the
opposite multiplication, defined by:

\[ \mu^o(r,t) = \mu(t,r)\]

**** 1.2.12. Categories of modules
We call $_RMod$ the category of *left* R-modules, and $Mod_R$ to the 
category of *right* R-modules.

**** 1.2.13. Subcategories
A category ${\cal S}$ is a subcategory of ${\cal C}$ when:

 1. $obj({\cal S}) \subseteq obj({\cal C})$.
 2. $Hom_S(A,B) \subseteq Hom_C(A,B)$.
 3. Identities and compositions are the same.

**** 1.2.14. Full subcategories
A full subcategory has $Hom_S(A,B) = Hom_C(A,B)$ for every $A,B \in obj({\cal S})$.

**** 1.2.15. Functors
A functor $T : {\cal C} \longrightarrow {\cal D}$ is a function such that:

 1. $T : obj({\cal C}) \longrightarrow obj({\cal D})$.
 2. $T : Hom(A,B) \longrightarrow Hom(TA,TB)$.
 3. Preserves composition: $T(f \circ g) = Tf \circ Tg$.
 4. Preserves identities: $T(1_A) = 1_{T(A)}$.

**** 1.2.16. Examples of functors
***** Subcategories as inclusion functors
***** Identity functor
***** Hom(A,-) functor
***** Chains as functors from the partially ordered integers
***** Forgetful functors

**** 1.2.27. Diagrams
A diagram is a functor whose domain is a *small category*; that
is $T : {\cal D} \longrightarrow {\cal C}$, where $obj({\cal D})$ is a set.

**** 1.2.28. Paths
A path is a functor $P : n+1 \longrightarrow {\cal C}$, where the domain is the partial 
ordering of integers $0,\dots,n+1$. A path is *simple* if the functor is
injective.

**** 1.2.29. Commutativity of diagrams
A diagram commutes if the composites of the labels on any two simple path
are equal.

**** TODO 1.2.30. Contravariant functors
**** TODO 1.2.31. Examples of contravariant functors
***** Hom(-,B) functor
***** The dual space functor
\[( )^\ast = Hom_k(-,k) : \sideset{_k}{}{Mod} \longrightarrow \sideset{_k}{}{Mod}\]
***** Order-reversing functions on partially ordered sets

***** Presheaves
If ${\cal U}$ is a topology with the inclusion, a contravariant functor 
${\cal P} : {\cal U} \longrightarrow {\cal C}$ is a presheaf.

**** 1.2.32. Faithful functors
A functor is faithful if all the functions 
$Hom(A,B) \longrightarrow Hom(TA,TB)$ are injective.
**** 1.2.33. Concrete categories
A category is concrete if there is a faithful functor ${\cal C} \longrightarrow \mathtt{Set}$.

**** 1.2.33. Opposite category
We define ${\cal C}^{op}$ to be the category with:

 - $obj({\cal C}^{op}) = obj({\cal C})$
 - $Hom_{{\cal C}^{op}}(A,B) = Hom_{\cal C}(B,A)$
 - $g \circ_{op} f = f \circ g$

**** 1.2.34. Isomorphisms
A morphism $f : A \longrightarrow B$ such that exists $g : B \longrightarrow A$ with
$f \circ g = 1$ and $g \circ f = 1$.

**** 1.2.35. Functors preserve isomorphisms
Let $T$ be a functor, if $f$ is an isomorphism, then $T(f)$ is an isomorphism.

***** Proof
If $g$ is its inverse, then:

\[ T(f)T(g) = T(fg) = 1\]
\[ T(g)T(f) = T(gf) = 1\]

If $T$ is a contravariant functor, the proof remains the same.

**** 1.2.36. Natural transformations
Let $F,G : {\cal A} \longrightarrow {\cal B}$ be covariant functors. A natural transformation
$\tau : F \Longrightarrow G$ is a family of morphisms $\tau_A : S A \longrightarrow T A$, making the following
diagram commute for every $f \in Hom(A,B)$:

\[ \begin{tikzcd}
FA \rar{\tau_A} \dar{Ff} & GA \dar{Gf} \\
FB \rar{\tau_B} & GB
\end{tikzcd} \]

We write the natural transformations as $Nat(F,G)$.

**** 1.2.37. Natural isomorphisms
A natural transformation $\tau$ for which each $\tau_A$ is an isomorphism.

**** 1.2.38. Composition of natural transformations
If $\tau : F \Longrightarrow G$ and $\sigma : G \Longrightarrow H$ are natural transformations, then the
composition is a natural transformation.

***** Proof
Composing the two commutative diagrams gives us the proof.

**** 1.2.39. Identity natural transformation
For any functor $F : {\cal A} \longrightarrow {\cal B}$, we can describe an identity natural 
transformation using the identity morphisms.

**** TODO 1.2.40. Examples of natural transformations
**** TODO 1.2.41. Natural transformations are proper classes
**** 1.2.42. Yoneda Lemma
Let $A \in obj({\cal C})$ and $G : {\cal C} \longrightarrow \mathtt{Set}$ be a covariant functor. 
There is a bijection:

\[ y : Nat(Hom_C(A,-), G) \longrightarrow G(A)\]

given by $y : \tau \longrightarrow \tau_A(1_A)$.

***** Proof
****** Every choice of p determines a natural transformation
Given $p \in GA$, we can create an unique natural transformation having
$\eta_A(1_A) = p$. A natural transformation has to obey the following 
commutative diagram:

\[\begin{tikzcd}
Hom(A,A) \rar{f \circ \_}\dar{\eta}& Hom(A,B)\dar{\eta} \\
GA \rar{Gf}& GB
\end{tikzcd}\]

Then, the image of $\eta_B(f)$ is determined.

\[\begin{tikzcd}
id \rar{f \circ \_}\dar{\eta}& f\dar{\eta} \\
p \rar{Gf}& (Gf)(p)
\end{tikzcd}\]

****** Every choice gives us a natural transformation
This gives us, in fact, a natural transformation which makes every
natural square to commute:

\[\begin{tikzcd}
Hom(A,B) \rar{g \circ \_}\dar{\eta}& Hom(A,C)\dar{\eta} \\
GB \rar{Gg}& GC
\end{tikzcd}\]

Given any element $f \in Hom(A,B)$, we can check the commutativity:

\[\begin{tikzcd}
f \rar{g \circ \_}\dar{\eta}& g \circ f\dar{\eta} \\
(Gf)(p) \rar{Gg}&  G(g \circ f)(p)
\end{tikzcd}\]

Knowing that $G(g \circ f)(p) = (Gg \circ Gf) (p)$.

**** 1.2.43. Representable functors
A covariant functor $F: {\cal C} \longrightarrow \mathtt{Set}$ is representable if $F \cong Hom(A,-)$
for some $A$.

**** 1.2.44. Yoneda Corollary 
For $A,B \in obj({\cal C})$:

  1. If $\eta \in Nat(Hom(A,-),Hom(B,-))$, then $\eta = (\_ \circ \psi)$ for some unique $\psi$.
  2. If $\eta = (\_ \circ \psi)$ and $\tau = (\_\circ\phi)$, then $\tau\circ\eta = (\_ \circ \psi\circ\phi)$.
  3. $\eta = (\_\circ\psi)$ is a natural isomorphism iff $\psi$ is an isomorphism.

***** Proof
****** Corollary 1
If we apply Yoneda Lemma, every transformation is defined by
$\eta(id_A) = \psi$. The transformation has to be $(\_ \circ\psi)$ because of commutativity:

\[\begin{tikzcd}
Hom(A,A) \rar{f \circ \_}\dar{\eta}& Hom(A,C)\dar{\eta} \\
Hom(B,A) \rar{f \circ\_}& Hom(B,C)
\end{tikzcd}\]

So, given any element $f \in Hom(A,C)$, we have $\eta(f) = f \circ \psi$:

\[\begin{tikzcd}
id \rar{f \circ \_}\dar{\eta}& f\dar{\eta} \\
\psi \rar{f \circ\_}& f \circ \psi
\end{tikzcd}\]

****** Corollary 2
Trivial consequence of the first corollary.

****** Corollary 3
It is trivial given the previous corollaries and:

\[(\_\circ\psi^{-1})\circ \psi = (\_\circ id)\]

**** TODO Examples
**** TODO Yoneda Imbedding
*** 1.3. Singular Homology
**** 1.3.1. Hilbert spaces and euclidean spaces
A *Hilbert space* is the set ${\cal H}$ of all sequences $(x_i) \in \mathbb{R}$ such that
$\sum x_i^2 < \infty$. A *Euclidean space*, $\mathbb{R}^n$ is a subset of ${\cal H}$ consisting of
all sequences of the form $(x_0,x_1,\dots,x_{n-1},0,\dots)$.

**** 1.3.2. Standard n-simplex
The standard n-simplex is the set of all convex combinations:

\[\Delta^n = [e_0,e_1,\dots,e_n]\]

Where $e_i$ form an orthogonal basis.

**** 1.3.3. Singular n-simplex
Given a topological space $X$, a singular n-simplex is a continuous map
$\sigma : \Delta^n \longrightarrow X$.

**** 1.3.4. Singular n-chains
We define $S_n(X)$ as the free group with singular n-simplexes as basis.
By convention, $S_{-1}(X) = \{0\}$. The elements on this group are called
singular n-chains.

**** TODO 1.3.5. Face maps
The ith face map $\epsilon^n_i : \Delta^{n-1} \longrightarrow \Delta^n$ is defined by:

*** Exercises
**** Exercise 1.1
#+begin_statement
1. Prove, in every category ${\cal C}$, that each object $A \in {\cal C}$ has a unique identity
   morphism.
2. If $f$ is an isomorphism in a category, prove that its inverse is unique.
#+end_statement

We have $id = id \circ id' = id'$ and $\varphi^{-1} = \varphi' \circ \varphi \circ \varphi^{-1} = \varphi'$.

** 2. Hom and Tensor
** 5. Setting the stage
*** 5.4. Sheaves
**** Protosheaves
 #+begin_definition
 *Local homeomorphism*. Continuous map $p : E \longrightarrow X$ such that for each $e \in E$ there is
 an open neighboorhood $S$ of $e$ such that $p|_S$ is an isomorphism.
 #+end_definition
 #+begin_definition
 *Protosheaf*. Surjective local homeomorphism.
 #+end_definition

**** Etale-sheaves
 #+begin_definition
 *Etale-sheaf of abelian groups*. A *protosheaf* such that:

 - The stalk $E_x$ is an abelian group.
 - Inversion and adition are continuous.
 #+end_definition

 #+begin_definition
 *Etale-map*. Given two etale-sheaves $E$ and $E'$, a map $\phi : E \longrightarrow E'$ such
 that $p'\phi = p$, and each $\phi|_{E_x}$ is a homomorphism.
 #+end_definition

 Here, etale-sheaves of abelian groups over a topological space X form an
 abelian category $\mathtt{Sh}_{et}(X,\mathtt{Ab})$.

*** 5.5. Abelian categories
**** Additive category
 #+begin_definition
 *Additive category*. ${\cal C}$ is additive if:

 - $Hom(A,B)$ is an *abelian group*.
 - *Distributivity* holds: $b \circ (f+g) = b\circ f + b \circ g$ and $(f+g)\circ a = f\circ a + g\circ a$.
 - Has a *zero object*.
 - Has finite *products* and *coproducts*.

 A functor $T$ between two additive categories is additive if $T(f+g) = Tf+Tg$.
 #+end_definition

 #+begin_theorem
 *Sums and products are the same*. Products and coproducts are isomorphic:

 \[A \mathbin{\Pi} B \cong A \amalg B\]

 So we call them *direct sums*, $A \oplus B$. And there are canonical morphisms:

 \[ \begin{tikzcd}
 & A \oplus B \dlar[bend right,swap]{\pi_A} \drar[bend left]{\pi_B} $ \\
 A \urar[bend right,swap]{i_A} & & B \ular[bend left]{i_B}
 \end{tikzcd} \]

 Such that: \(i_A \circ \pi_A + i_b \circ \pi_B = id\) and \(\pi_B \circ i_A = \pi_A \circ i_B = 0\).
 #+end_theorem

**** Monomorphisms and epimorphisms
 #+begin_definition
 *Monomorphism*. A morphism $u$ such that:
 \[u \circ f = u \circ g \quad \Rightarrow \quad f = g\]
 #+end_definition
 #+begin_definition
 *Epimorphism*. A morphism $u$ such that:
 \[f \circ u = g \circ u \quad \Rightarrow \quad f = g\]
 #+end_definition

 We have that $u : B \longrightarrow C$ is *monomorphism* iff the induced 
 $u^\ast : Hom(A,B) \longrightarrow Hom(A,C)$ is injective. And $v : B \longrightarrow C$ is *epimorphism* 
 iff the induced $v^* : Hom(B,D) \longrightarrow Hom(C,D)$ is surjective.

**** Kernels and cokernels
 #+begin_definition
 *Kernel*. The kernel of $u$ is the equalizer of $u$ and $0$. In a diagram:

 \[ \begin{tikzcd}
 & C \dar[dashed] \arrow[ddr, bend left] \arrow[ddl,bend right] &\\
 & \ker(u) \dlar[swap]{i} \drar{0} & \\
 A \arrow[shift left]{rr}{u} \arrow[shift right]{rr}[swap]{0} & & B
 \end{tikzcd} \]
 #+end_definition
 #+begin_definition
 *Cokernel*. The cokernel of $u$ is the coequalizer of $u$ ans $0$. In a diagram

 \[ \begin{tikzcd}
 & C &\\
 & \ker(u) \uar[dashed]   & \\
 A \urar{0} \arrow[uur, bend left]
 \arrow[shift left]{rr}{u} \arrow[shift right]{rr}[swap]{0} & & 
 B \ular[swap]{\pi} \arrow[uul,bend right]
 \end{tikzcd} \]
 #+end_definition

 #+begin_theorem
 *Monomorphisms and kernels*.
 - If $\ker(u)$ exists, $u$ is monomorphism iff $ker(u) = 0$.
 - If $coker(v)$ exists, $v$ is epimorphism iff $coker(v) = 0$.
 #+end_theorem
**** Abelian category
 #+begin_definition
 *Abelian category*. ${\cal C}$ is abelian if

 - Every morphism has *kernel* and *cokernel*.
 - Every monomorphism is a *kernel*.
 - Every epimorphism is a *cokernel*.
 #+end_definition

 Abelian categories are /self-dual/, if ${\cal A}$ is an abelian category, then
 ${\cal A}^{op}$ is an abelian category.

 #+begin_definition
 *Image*. Given $f : A \longrightarrow B$ in an abelian category, its image is:

 \[img(f) = ker(coker(f))\]
 #+end_definition

* Carlos Ivorra - Álgebra conmutativa
** I. Funtores Derivados
*** 1.1. Haces
**** Prehaces
Un *prehaz* sobre un espacio topológico $X$ es un par $({\cal F},\rho)$, donde cada abierto $U$
tiene un grupo asociado ${\cal F}(U)$ y cada inclusión $U \subset V$ tiene asociado un homomorfismo
llamado *restricción*, $\rho_U^V : {\cal F}(V) \longrightarrow {\cal F}(U)$ cumpliendo:

  - ${\cal F}(\varnothing) = 0$
  - $\rho_U^U$ es la identidad
  - Si $U\subset V\subset W$, entonces $\rho_V^W \circ \rho_U^V = \rho_U^W$

Cuando los grupos ${\cal F}(U)$ son anillos o módulos tenemos un *prehaz de anillos* o un
*prehax de módulos*.

# Categóricamente, un funtor contravariante desde los conjuntos del espacio
# topológico con la inclusión a los grupos, o módulos, o álgebras...

**** Notación de restricción
Normalmente escribiremos $f|_{U}$ para llamar a la restricción de $f$ a $U$, esto 
es $\rho_U^V(f)$.

**** Haces
Un *haz* es un prehaz tal que si $U = \bigcup U_i$ es el recubrimiento de un abierto:

  - Si $f|_{U_i} = 0$ para todos los $i$, entonces $f = 0$.
  - Para una familia de elementos $f_i \in {\cal F}(U_i)$ cumpliendo que 
    $f_i|_{U_i \cap U_j} = f_j|_{U_i \cap U_j}$, se tiene que hay un $f \in {\cal F}(U)$ tal que $f|_{U_i} = f_i$.

**** Grupo de gérmenes o grupo local
Dado un prehaz ${\cal F}$ sobre $X$, con $P \in X$, llamamos *grupo de gérmenes* en $P$ al grupo
${\cal F}_P$, formado por las clases de equivalencia de pares $(U,f)$ con $P\in U$, $f \in {\cal F}(U)$;
respecto de la relación dada por $(U,f) \sim (V,g)$ ssi hay un abierto $W \subset U \cap V$
tal que $P \in W$ y además $f|_W = g|_W$. Teniendo como operación de grupo a:

\[ [(U,f)]+[(V,g)] = [(U\cap V, f|_{U\cap V} + g|_{U\cap V})] \]

**** Homomorfismo de prehaces
Un *homomorfismo de prehaces* $\alpha : {\cal F} \longrightarrow {\cal G}$, asigna a cada abierto $U$ un homomorfismo
de grupos $\alpha_U : {\cal F}(U) \longrightarrow {\cal G}(U)$, tal que:

\[ \begin{tikzcd}
{\cal F}(V) \rar{\alpha_V} \dar[swap]{\rho_U^V} & {\cal G}(V) \dar{\rho_U^V} \\
{\cal F}(U) \rar{\alpha_U} & {\cal G}(U)
\end{tikzcd} \]

# Categóricamente son transformaciones naturales.
* Álgebra III
** 1. Polinomios simétricos
*** Motivación: La cúbica
**** Polinomios cúbicos
Toda ecuación cúbica polinómica puede escribirse en la forma
\(Y^3 + pY + q\), tomando un cambio de variable desde la original
\(X \mapsto - \frac{1}{3} b\). Esto se llama una cúbica deprimida.

***** Método de Vieta
El método de Vieta toma \(t = w - \frac{p}{3w}\), y llega a la ecuación:

\[w^3 + q - \frac{p^3}{27w^3} = 0\]

Ahora podemos resolver esa cuadrática y resolver luego la ecuación
en $w^3$.

*** 1.1. Polinómios simétricos
**** Polinomios simétricos
Un *polinomio simétrico* es aquel invariante por $f_\sigma$ para cualquier $\sigma \in S_r$, 
donde $f_\sigma (X_i) = X_{\sigma i}$. Llamamos $Sim(A[X_1\dots X_n])$ al subanillo de polinomios 
simétricos.

**** Componentes homogéneas
Llamamos *componente homogénea* a cada sumando homogéneo maximal de un 
polinomio. Un polinomio es simétrico si y sólo si cada una de sus componentes 
lo es.

**** Polinomios simétricos elementales
Los polinomios simétricos elementales son aquellos de la forma:

\[e_i = \sum_{i_1 < \dots < i_i} X_{i1} X_{i2} \dots X_{ii}\]

**** Teorema fundamental de los polinomios simétricos
Los polinomios elementales generan cada polinomio $Sim(A[X_1\dots X_n])$ 
de forma única. En particular,

\[\omega : A[X_1,\dots,X_r] \longrightarrow Sim(A[X_1,\dots,X_r])\]

con $\omega(a) = a$ y $\omega(X_i) = e_i$ es un isomorfismo.

***** Demostración
Damos una relación de orden lexicográfica entre los monomios de un
polinomio simétrico homogéneo. Al mayor de ellos, llamado 
$X_1^{k_1} \dots X_r^{k_r}$ le restamos $e^{b1}_1 e^{b2}_2 \dots e^{br}_r$, donde
$b_i = k_i - k_{i+1}$. Nos quedará $0$ u otro polinomio simétrico de
igual grado pero menor en el orden lexicográfico. Este proceso debe
ser finito.

La unicidad se obtiene con $0 = h(e_1\dots e_r) - k(e_1\dots e_r) =
l(e_1 \dots e_r)$.

*** 1.2. Polinomios alternados
**** Polinomio alternado
Un polinomio $f$ es alternado cuando para toda permutación se tiene
$\sigma(f) = sign(\sigma) f$.

*** 1.3. La resultante
**** Resultante
Dados dos polinomios $f,g$ en un cuerpo $K$ en el que descomponen 
podemos escribirlos como:

\[ f = a_n(X-\alpha_1)\dots(X-\alpha_n) = a_n \prod^n_{i=1}(X-\alpha_i)\]
\[ g = b_n(X-\beta_1)\dots(X-\beta_n) = a_n \prod^n_{i=1}(X-\beta_i)\]

La *resultante* busca ser una expresión que se anula cuando tienen
raíz común, y se define como:

\[ R(f,g) = a_n^m b_m^n \prod^n_{i=1} \prod^m_{j=1} (\alpha_i - \beta_j)\]

**** TODO Propiedades de la resultante
La resultante de dos polinomios $f,g$ cumple:

 1. $R(f,g) = 0$ ssi tienen una raíz común.
 2. $R(g,f) = (-1)^{nm}R(f,g)$, siendo $nm$ el producto del número de raíces.
 3. $R(f,g) = a^m_n \prod^n_{i=1} g(\alpha_i)$
 4. $R(fg,h) = R(f,h)R(g,h)$, $R(f,gh) = R(f,g)R(f,h)$
 5. Si $m=0$, entonces $R(f,k) = k^n$
 6. $R(X^k,f) = a_0^k$; con $R(f,X^k) = (-1)^{nk}a_0^k$

*** 1.4. Discriminante
**** Raíces múltiples
Podemos usar la resultante para caracterizar los polinomios
con raíces múltiples, que son aquellos que comparten raíz con
su derivada.
# Duda: ¿Una raíz doble se comparte con la derivada siempre?

\[ R(f,f') = a_n^{n-1} \prod f'(\alpha_j)\]

**** El discriminante
El *discriminante* de un polinomio con raíces
$\alpha_1, \dots, \alpha_n$ en una clausura algebraica es:

\[\text{Discr}(p) = a^{2n-2} \prod_{i>j}(\alpha_i-\alpha_j)^2\]

**** Relación con la resultante
\[R(p,p') = (-1)^{\frac{n(n-1)}{2}}a_n \text{Discr}(p)\]

*** 1.5. Métodos de cálculo
**** Método modular
**** Por el algoritmo de Euclides
**** Resultante de Euler-Sylvester-Cayley
Definimos la resultante de Euler-Sylvester-Cayley:

\[
R(f,g) = \left| \begin{matrix}
a_n & a_{n-1} & \dots & a_0 & 0 & \dots &\\
0   & a_n & \dots & a_{1} & a_0 & 0 & \dots \\
0   &   0 & a_n & \dots & a_1 & a_0 & \dots \\
&      &     &\vdots & & & \\
b_m & b_{m-1} & \dots & b_0 & 0 & \dots &\\
0   & b_m & \dots & b_1 & b_0 & 0 & \dots \\
0   &   0 & b_m & \dots & b_1 & b_0 & \dots \\
\end{matrix} \right|
\]

***** Origen
La resultante se obtiene como la determinante de la
matriz del sistema de ecuaciones que dan:

\[ \begin{aligned}
X^{m-1} f &= 0 \\
X^{m-2} f &= 0 \\
& \vdots \\
1f &= 0 \\
X^{n-1}g &= 0 \\
X^{n-2}g &= 0 \\
& \vdots \\
1g &= 0 \\
\end{aligned}\]

Por Teorema de Rouché, este sistema tiene solución ssi 
el determinante de los coeficientes es cero.

**** Resultante como determinante
La *resultante* de dos polinomios $p,q$ es el determinante solución de 
$pq' - qp' = 0$ dados $p$ y $q$.

\[R(p,q) = \left| \begin{matrix}
a_0 & a_1 & \dots & a_n & 0 & \dots &\\
0   & a_0 & \dots & a_{n-1} & a_n & 0 & \dots \\
0   &   0 & a_0 & \dots & a_{n-1} & a_n & \dots \\
&     &     &\dots & & & \\
b_0 & b_1 & \dots & b_m & 0 & \dots &\\
0   & b_0 & \dots & b_{m-1} & b_m & 0 & \dots \\
0   &   0 & b_0 & \dots & b_{m-1} & b_m & \dots \\
\end{matrix} \right|
\]

Y llamamos *matriz resultante* a la matriz de la que es determinante.

** 2. Series de grupos y grupos solubles
*** 2.1. Series de composición
**** 2.1.1. Factor
Sea $G$ grupo, llamamos factor a cualquier $H/H'$ donde $G > H \trianglerighteq H'$.

**** 2.1.2. Proyección
Llamamos proyección de $H/H'$ sobre $K/K'$, ambos factores, a:

\[\frac
{K'(H\cap K)}
{K'(H'\cap K)}\]

**** 2.1.3. Serie
Llamamos serie a toda cadena finita:

\[ G > G_1 > G_2 > \dots > G_r = 1\]

Donde llamamos a $r$ la longitud del grupo.

**** 2.1.4. Refinamiento de una serie
Dadas dos series,

\[ G > G_1 > G_2 > \dots > G_r = 1\]
\[ G > G'_1 > G'_2 > \dots > G'_r = 1\]

llamamos a la segunda refinamiento si todo grupo suyo aparece en
la primera. Es refinamiento propio si además son distintas.

**** 2.1.5. Serie normal
Una serie es *normal* cuando se verfica $G_i \trianglerighteq G_{i+1}$. Llamamos a $G_{i-1}/G_i$
los *factores* de la serie.

**** 2.1.5. Serie propia
Una serie propia tiene sólo inclusiones propias $G_i \gneq G_{i+1}$.

**** 2.1.5. Isomorfismo de series
Dos series son isomorfas cuando existe una permutación que hace 
isomorfos sus factores:

\[\exists \sigma \in S_r : \quad 
G_{i-1}/G_i \cong H_{\sigma(i)-1}/H_{\sigma(i)}\]

**** 2.1.5. Serie de composición
Una *serie de composición* es una serie normal propia sin 
refinamientos normales. Llamamos *factores de composición* a sus
factores.

**** 2.1.6. Grupo simple
Un grupo simple es aquel que no admite subgrupos normales propios.

**** 2.1.7. Grupos abelianos finitos simples
Un grupo abeliano, finito y simple es isomorfo a $\mathbb{Z}_p$ para algún $p$ primo.

***** TODO Demostración

**** 2.1.8. Los factores de composición son simples
Los factores de cualquier serie de composición son simples.

***** TODO Demostración

**** 2.1.9. Existencia de la serie de composición
Todo grupo finito posee una serie de composición.

**** 2.1.10. Teorema de refinamiento de Schreier
Dos series normales de un grupo tienen refinamientos isomorfos.

**** 2.1.11. Teorema de Jordan-Holder
Si un grupo admite serie de composición, toda serie normal propia puede
refinarse a una serie de composición. Las series de composición son 
isomorfas.

*** 2.2. El programa de Holder
**** TODO 2.2.1. Teorema de clasificación de grupos simples finitos
**** 2.2.2. Teorema de Abel
El grupo $A_n$ es simple para $n \geq 5$.

***** TODO Demostración

**** 2.2.3. Teorema de Feit-Thompson
Si $G$ es simple de orden impar, entonces $G \cong \mathbb{Z}_p$ con $p$ primo.

***** TODO Demostración

*** 2.3. Grupos solubles
**** 2.3.1. Serie derivada
Dado $G$, definimos la serie derivada de $G$ como:

\[G = G^0 > G' > G'' > \dots \]

donde $G^{(i+1} = [G^{(i}, G^{(i}]$ es el grupo derivado. Nótese que no tiene por
qué ser finita.

**** 2.3.2. Caracterización de grupos solubles
Para $G$ grupo finito, equivalen:

 1. Los factores de composición son cíclicos de orden primo.
 2. $G$ tiene serie normal con factores cíclicos.
 3. $G$ tiene serie normal con factores abelianos.
 4. Se tiene $G^{(i} = 1$.

***** TODO Demostración

**** 2.3.3. Grupo soluble
Un grupo es soluble si tiene una serie normal con factores cíclicos.

**** 2.3.4. Subgrupos de solubles
Son solubles:

 1. Los subgrupos de un grupo soluble.
 2. Los cocientes de un grupo soluble.
 3. Si $N$ y $G/N$ son solubles, $G$ es soluble.

***** TODO Demostración

**** 2.3.5. Producto de solubles
Todo producto finito de grupos solubles es soluble.

***** TODO Demostración

**** 2.3.6. Teorema de Hall
Sea $G$ soluble de orden $mk$ cumpliendo $mcd(m,k) = 1$. Entonces:

 1. $G$ posee un grupo de orden $m$.
 2. Dos subgrupos cualesquiera de orden $m$ son conjugados.
 3. Todo subgrupo de orden $m' \mid m$ está contenido en uno de orden $m$.
 4. El número de subgrupos de orden $m$, $r_m$ es producto de factores
    congruentes a $1$ módulo algún factor primo de $m$. Es además potencia
    de primo y divide a alguno de los factores de $G$.

***** TODO Demostración

**** 2.3.7. Caracterización de grupo soluble
Dado $G$ grupo finito, es soluble ssi para cualquier descomposición $|G|=mk$
con $mcd(m,k) = 1$, existe un subgrupo de orden $m$.

** 3. Extensiones de cuerpos
*** 3.1. Generalidades
**** 3.1.1. Extensiones de cuerpos
Una *extensión de cuerpos* es un subcuerpo $K$ de $F$, se nota por $F/K$. 

**** 3.1.2. Grado de la extensión
Llamamos *grado* a la dimensión de $F$ como espacio vectorial.
Notamos por $[F : K]$.

**** 3.1.3. Cuerpo intermedio
Un cuerpo intermedio entre $F$ y $K$ es cualquier subcuerpo de $F$ 
conteniendo a $K$.

**** 3.1.4. Torre de cuerpos
Una torre es una sucesión de subcuerpos:

\[F_0 \subset F_1 \subset \dots \subset F_n\]

**** 3.1.5. Extensiones finitas
Una extensión es finita ssi $[F:K]$ es finito.

**** 3.1.6. Base de una torre de inclusiones
Sea $K \supset F \supset E$ una torre de inclusiones. Sean $\{u_i\}_{i\in I}$ una base de $E$
sobre $F$ y $\{v_j\}_{j\in J}$ una base de $F$ sobre $K$. Entonces $\{u_iv_j\}$ es una base
de $E$ sobre $K$.

***** Demostración
****** Es sistema de generadores
Si tenemos ambos sistemas de generadores, podemos escribir cada
elemento de $E$ como:

\[ e 
= \sum u_i f_i 
= \sum u_i \left(\sum v_j k_{ij}\right) 
= \sum u_iv_ik_{ij}\]

****** Son linealmente independientes
Aplicando la independencia lineal de cada una de las bases:

\[ \sum u_iv_jk_{ij} 
= \sum u_i \left( \sum v_jk_{ij}\right) = 0\]

Tenemos que $\sum v_jk_{ij} = 0$, luego $k_{ij} = 0$.

**** 3.1.7. Teorema del grado
Sean $K \subset F \subset E$, extensiones de cuerpos, se tiene que:

\[ [E:K] = [E:F][F:K] \]

***** Demostración
Teniendo una base de cada uno de ellos, calculamos la base
de la [[*3.1.6. Base de una torre de inclusiones][torre de inclusiones]], que nos da la dimensión.

**** 3.1.8. Corolario al Teorema del grado: finitud
Sean $K \subset F \subset E$, la extensión $E/K$ es finita ssi las extensiones
$E/F$ y $F/K$ lo son.

***** Demostración
Si ambas son finitas, podemos aplicar el [[*3.1.7. Teorema del grado][teorema del grado]]. Cuando
$E/K$ es finita, tenemos que $E/F$ tiene como sistema generador a la
base y $F/K$ es un subespacio de $E/K$.

**** 3.1.9. Corolario al Teorema del grado: torres de cuerpos
Sea $F_0 \subset F_1 \subset \dots \subset F_n$ torre de longitud $n$, entonces:

\[ [F_n : F_0] =
[F_n:F_{n-1}] \dots [F_2:F_1][F_1 : F_0]
\]

***** Demostración
Por inducción sobre la longitud de la torre y aplicando el teorema
del grado a cada paso.

**** 3.1.10. Corolario al Teorema del grado: extensiones primas
Sea $F/K$ una extensión tal que $[F:K] = p$ es primo. Entonces no
existe ningún cuerpo intermedio propio.

***** Demostración
Usando el teorema del grado, tenemos que debería tener grado $p$, en
cuyo caso sería un subespacio de la misma dimensión que $F$, y por
tanto $F$. O debería tener grado $1$, en cuyo caso sería $K$.

*** 3.2. Elementos algebraicos y extensiones algebraicas
**** 3.2.1. Homomorfismo unital
Para todo anillo $A$ existe un único homomorfismo de anillos
$1_\mathbb{Z} : \mathbb{Z} \longrightarrow A$, llamado *homorfismo unital*.

**** 3.2.2. Característica del anillo
La característica de $A$ es el entero no negativo que genera
al ideal $ker(1_\mathbb{Z})$.

**** 3.2.3. Característica en dominios de integridad
Si $A$ es dominio de integridad, $car(A)$ es primo o $0$.

***** Demostración
Trivialmente desde el homomorfismo unital. Si no fuera así,
tendríamos $ab = 0$ enteros.

**** 3.2.4. Caracterización de la característica
$car(A)=n$ ssi $n$ es el menor entero positivo tal que $na = 0$ para
todo $a \in A$.

***** Demostración
Si hubiera otro menor, debería pertenecer al núcleo del homomorfismo
unital, y no podría ser generado por $n$. Si cumple la condición
y es el menor, todo el resto de elementos del núcleo deben ser 
múltiplos, porque si no lo fueran, podríamos crear un menor con 
Bezout.

**** 3.2.5. Intersección de anillos
Sea $A$ un anillo y sea $\{B_i\}_{i\in I}$ una familia de subanillos. Entonces
$\bigcap B_i$ es subanillo. Análogo para cuerpos y subcuerpos.

***** Demostración
Si dos elementos pertenecen a todos los $B_i$, tenemos que su suma
y su producto pertenece a cada uno de ellos.

**** 3.2.6. Anillo primo
Llamamos subanillo primo de $A$ a la intersección de todos los 
subanillos de $A$.

**** 3.2.7. Clasificación de anillos primos
El subanillo primo de un $A$ es isomorfo a $\mathbb{Z}$ si $car(A) = 0$ y
a $\mathbb{Z}/n\mathbb{Z}$ si $car(A) = n \neq 0$.

***** Demostración
En ambos casos, ellos son subanillos por ser imágenes del 
homomorfismo unital, como se comprueba por primer teorema de
isomorfía.

**** 3.2.8. Subcuerpo primo
Llamamos subcuerpo primo de $K$ a la intersección de todos los
subcuerpos de $K$.

**** 3.2.9. Clasificación de subcuerpos primos
El subcuerpo primo de un cuerpo $K$ es isomorfo a $\mathbb{Q}$ cuando
$car(K)=0$ y a $\mathbb{Z}/p\mathbb{Z}$ cuando $car(K) = p \neq 0$.

***** Demostración
De nuevo, vuelve a tenerse una inyección de ambos por el 
homomorfismo unital. Cualquier subanillo contendrá a $1$ y por
tanto a este subcuerpo.

**** 3.2.10. Subanillo generado
Sea $F/K$ extensión con $S\subseteq F$; llamamos *subanillo generado*
$K[S]$ a la intersección de todos los subanillos de $F$ conteniendo
a $K$ y a $S$.

**** 3.2.10. Subcuerpo generado
Sea $F/K$ extensión con $S \subseteq F$; llamamos *subcuerpo generado*
$K(S)$ a la intersección de todos los subcuerpos de $F$ conteniendo
a $K$ y a $S$.

**** 3.2.11. Propiedades de subanillos y subcuerpos generados
Para $S,T \subseteq F$ extensión de $K$, tenemos:

 - $K[S \cup T] = K[S][T] = K[T][S]$
 - $K(S \cup T) = K(S)(T) = K(T)(S)$

***** Demostración
En cualquiera de los dos casos la definición es la intersección
de todos los que contienen a $K$, $T$ y $S$.

**** 3.2.12. Subcuerpo compuesto
Dados $K \subset E,F \subset L$, definimos el subcuerpo compuesto
$EF = E(F) = F(E)$.

***** Demostración
Son iguales trivialmente desde la definición.

**** 3.2.13. Conjunto de generadores
Sea $F/K$ con $S \subseteq F$, es un subconjunto de generadores si
$F = K(S)$.

**** 3.2.14. Extensión finitamente generada
Una extensión $F/K$ es finitamente generada cuando tiene un
conjunto finito de generadores. $F = K(u_1,u_2,\dots,u_n)$.

**** 3.2.15. Extensiones simples y elementos primitivos
Una extensión $F/K$ se llama simple cuando $F = K(u)$. Al $u$
se le llama *elemento primitivo* para la extensión.

**** 3.2.16. Elementos algebraicos
$\alpha \in F$ es *algebraico* sobre $K$ si existe polinomio $f \in K[x]$ tal 
que $f(\alpha) = 0$. 

Un no algebraico es *trascendente* y una extensión es *algebraica* 
si lo son todos sus elementos.

**** 3.2.16. Polinomios irreducibles
Dado $F/K$ con $\alpha \in F$ algebraico. Existe un único polinomio 
irreducible del que $\alpha$ es raíz salvo asociados, llamado $Irr(\alpha)$.
   
***** Existencia y unicidad del polinomio irreducible
Tomo el núcleo del homomorfismo que evalúa un polinomio en $\alpha$. 
Por ser un ideal en PID, estará generado por algún polinomio $f$ 
no nulo y no constante.

Este será irreducible, porque si no lo fuera, con $f = g_1g_2$ se 
tendría:

\[0 = f(\alpha) = g_1(\alpha)g_2(\alpha)\]

Un polinomio de grado mínimo debería estar dentro del ideal, 
y por tanto ser asociado de $f$, que lo genera.

**** 3.2.16. Propiedades de los polinomios irreducibles
Sea $F/K$ extensión con $u \in F$ algebraico. Se cumple:

 1. $K(u) = K[u]$
 2. $K[u] \cong K[X]/(Irr(u,K))$
 3. $[K(u):K]$ es igual al grado de $Irr(u,K)$.
 4. $\{1,u,u^2,\dots,u^{n-1}\}$ es una base de $K[u]$ sobre $K$.
 5. $f(u)=0$ ssi $Irr(u,K) \mid f$.

Llamamos *grado* del elemento $u$ al grado de $Irr(u,K)$.

***** Demostración
****** Punto 1
Sabemos que el anillo generado está dentro del cuerpo generado,
y además, $u^{-1}$ está en el anillo generado porque, si su polinomio
irreducible nos da $\sum a_iu^i = 0$, tenemos:

\[ u \left(a_nu^{n-1} + a_{n-1}u^{n-2} + \dots a_1 \right)\frac{1}{a_0} = 1\]

****** Punto 2
Aplicando el primer teorema de isomorfía al morfismo evaluación,
tenemos el resultado.

****** Punto 3
Tenemos que $1,u,u^2,\dots,u^{n-1}$ son linealmente independientes porque
una relación lineal entre ellos daría un polinomio menor que el
mínimo. Además son base trivialmente porque $u^{-1}$ puede expresarse
linealmente como polinomio suyo como mostramos [[*Punto 1][antes]] y porque
cuaquier expresión polinómica de grado mayor a $n$ puede dividirse 
por el polinomio irreducible para obtener otra de grado menor.

****** Punto 4
La misma demostración [[*Punto 3][anterior]].

****** Punto 5
Un polinomio verificando $f(u)=0$ está dentro del núcleo del
homomorfismo evaluación.

**** 3.2.17. Algebraicos en una torre de cuerpos
Sea $K \subset F \subset E$ con $u \in E$ algebraico sobre $K$, entonces $u$ es
algebraico sobre $F$ y $Irr(u,F)$ divide a $Irr(u,K)$.

***** Demostración
Notamos que $Irr(u,K)$ es también un polinomio sobre $F$ que anula
a $u$, así que, por las propiedades de los polinomios irreducibles,
se debe tener $Irr(u,F) \mid Irr(u,K)$.

**** 3.2.18. Extensiones algebraicas
Una extensión se llama *algebraica* si todos sus elementos lo son.
Es *trascendente* en otro caso.

**** 3.2.19. Elementos algebraicamente independientes
Los elementos $\{u_i \mid i\in I\}$ son algebraicamente independientes si el
homomorfismo de evaluación sobre el cuerpo de polinomios en varias
variables $K[X_i \mid i\in I]$ es inyectivo.

**** 3.2.20. Extensiones puramente trascendentes
Una extensión $F/K$ se llama puramente trascendente si $F = K(S)$
donde $S$ un conjunto de algebraicamente independientes.

**** 3.2.21. Generación finita de elementos
Para $F/K$ extensión cualquiera $S \subseteq F$, se tiene:

 1. Para $u \in K[S]$ existe un subconjunto $\{u_1,\dots,u_n\} \subset S$ tal que
    $u \in K[u_1,\dots,u_n]$.
 2. Para $u \in K(S)$ existe un subconjunto $\{u_1,\dots,u_n\} \subset S$ tal que
    $u \in K(u_1,\dots,u_n)$.

***** Demostración
Tener $u \in K[S]$ nos da una expresión polinómica finita como elementos
de $S$. Los elementos involucrados en esa expresión crean una extensión
finita en la que está $u$. Análogo en el caso de cuerpos.

**** 3.2.22. Generación del compuesto
Sean $K \subset E,K(S) \subset L$, entonces $EK(S) = E(S)$.

***** Demostración
Por definición del cuerpo compuesto, será $EK(S) = K(E)(S) = E(S)$.

**** 3.2.23. Grado de una extensión compuesta
Sean $K \subset E,F \subset L$. Entonces:

\[ [EF:K] \leq [E:K][F:K]\]

***** Demostración
En el caso finito, el cuerpo generado por las bases de $E$ y
de $F$ multiplicadas contiene a todo elemento de $E$ y de $F$, por 
lo que es sistema de generadores de $EF$.

**** 3.2.24. Extensiones primas relativas
Sean $K \subset E,F \subset L$ con $n = [E:K]$ y $m = [F:K]$ primos relativos.
Entonces $[EF:K] = [E:K][F:K]$.

***** Demostración
Sea $\{f_i\}$ base de $F$ sobre $K$. Tenemos que es sistema de generadores
de $F$ sobre $E$, y por tanto, de $EF$ sobre $E$. Así $[EF:E] \leq [F:K]$
y análogamente $[EF:F] \leq [E:K]$.

Por otro lado, por teorema del grado tenemos:

\[[EF:K] = [EF:F][F:K] = [EF:F]m\]
\[[EF:K] = [EF:E][E:K] = [EF:E]n\] 

Así, por ser primos relativos, tenemos $n \mid [EF:E]$ y $m \mid [EF:F]$; 
teniéndose finalmente:

\[ [EF:F] = [E:K] \]
\[ [EF:E] = [F:K] \]

**** 3.2.25. Extensión finitamente generada por algebraicos es finita
Una extensión $F = K(u_1,\dots,u_n)$ finitamente generada por $u_i$ algebraicos
es finita.

***** Demostración
Todo elemento algebraico cumple una relación polinómica. Así,
todo elemento de grado igual o mayor a esta relación, puede
expresarse como elementos de grado menor.

Si tenemos $e_i$ como el exponente mayor al que puedo elevar $u_i$ sin
que pueda ser reescrito, tenemos un sistema de generadores de $F$ 
finito como:

\[\{ 1, u_1^1, u_1^2, \dots u_1^{e_i}, u_2^1, \dots, u_2^{e_j}, u_3^1,\dots\}\]

**** 3.2.26. Extensión generada por algebraicos es algebraica
Una extensión $K(S)/K$ es algebraica sobre $K$ ssi todo $u \in S$ es 
algebraico sobre $K$.

***** Demostración
Si es algebraica, en particular lo es cada elemento de $S$.
Si lo son los elementos de $S$, podemos ver que cualquier 

**** 3.2.27. Finita es algebraica y finitamente generada
Una extensión es finita ssi es algebraica y finitamente generada

***** Demostración
Tenemos que extensión finitamente generada por algebraicos es
[[*3.2.25. Extensión finitamente generada por algebraicos es finita][finita]]. Por otro lado, si es finita, tendrá una base finita que
la genera; y para cada elemento de la base, $\{1,u,\dots,u^n\}$ no
será linealmente independiente. Luego será finita.

**** 3.2.28. Caracterización de elementos algebraicos
Un elemento $u \in F$ es algebraico sobre $K$ ssi existe una extensión
finita intermedia $E/K$ donde $u \in E$.

***** Demostración
Si es algebraico de grado $n$, tenemos $K(u)$ algebraica y finitamente
generada, [[*3.2.27. Finita es algebraica y finitamente generada][luego finita]]. Si existe una extensión finita intermedia, 
será algebraica.

**** 3.2.29. Torre algebraica
Sean $K \subset F \subset E$, $E/K$ es algebraica ssi $E/F$ y $F/K$ son ambas 
algebraicas.

***** Demostración
****** Si es algebraica, lo son sus partes
Un elemento algebraico sobre $K$ lo será sobre $F$. Y todo elemento
de $F$ está en $E$, luego será algebraico sobre $K$.

****** Si las partes son algebraicas, es algebraica
Todo elemento $e \in E$ es algebraico sobre $F$, luego cumple algún
polinomio con elementos en $F$. Los elementos que generan el polinomio
en $F$ son todos algebraicos sobre $K$, luego $K$ extendido con esos
elementos es finito. Si lo extiendo con $e$, que es algebraico sobre
ellos, llego a otra extensión finita. Toda finita es [[*3.2.27. Finita es algebraica y finitamente generada][algebraica]].

**** 3.2.30. Clausura algebraica relativa
Dada $F/K$ extensión, el conjunto de elementos algebraicos forman un
subcuerpo de $F$. Llamado *clausura algebraica relativa* de $K$ en $F$.

***** Demostración
Sean $a,b \in F$ algebraicos; entonces $K(a,b)$ es finito, luego $a+b$ y
$ab$ son también algebraicos.

***** Demostración constructiva para la suma
Se puede [[http://mathoverflow.net/a/81640/45365][encontrar constructivamente]] un polinomio que tenga como
raíz a la suma de dos algebraicos.

**** DONE Existencia de clausura
*Teorema de Steinitz*. Todo cuerpo tiene una extensión algebraicamente 
cerrada.

**** DONE Homomorfismos sobre un cuerpo
     Un *homomorfismo sobre cuerpos* $K,K'$ es un homomorfismo $\phi$ sobre extensiones
     $F,F'$ con un isomorfismo $\omega : K \longrightarrow K'$ debe cumplir: $\phi|_K = \omega$. 
     Cuando no se especifica, se asume la identidad.

     \[ \phi : F/K \longrightarrow F'/K' \]

**** DONE Automorfismos entre extensiones
     Un automofismo de extensiones es un homomorfismo sobre el cuerpo $K$, 
     $\phi : F/K \longrightarrow F/K$ que es isomorfismo.

** 4. Cuerpos de descomposición
*** DONE Extensión de homomorfismos
*Extensión de un homomorfismo*. $\tau : F_1 \longrightarrow F_2$ es extensión de 
$\sigma : K_1 \longrightarrow K_2$ cuando son dos extensiones $F/K$ y se cumple
que $\tau |_K_1 = \sigma$.

Cuando $\sigma = 1$, llamamos a $\tau$ *homomorfismo sobre K*.

**** Automorfismos de una extensión
*Automorfismos de una extensión*. Sea $\sigma : F/K \longrightarrow F/K$, entonces,
$\sigma$ es automorfismo.

***** Demostración
Para $u\in F$, tomamos $K(u_1,\dots,u_k)$ la extensión finita generada por todas 
las raíces del irreducible sobre $u$. Como $\sigma$ respeta raíces, puede restringirse
a esta extensión; y será inyectivo en ella por ser morfismo de cuerpos.

Como esta extensión es finita y esto es una aplicación lineal, la aplicación 
restringida es sobreyectiva.

**** Número de extensiones
#+begin_theorem
*Número de extensiones*. Teniendo $u_1$ de irreducible a $f_1$, hay tantas
extensiones $\tau : K_1[u_1] \longrightarrow F_2$ como raíces tenga su imagen $f_2$; ya que están 
completamente determinadas por la imagen de $u_1$.
#+end_theorem
#+begin_proofs
Existe un único isomorfismo llevando $\tau(u_1) = u_2$, tomando este diagrama de
isomorfismos:

\[ \begin{tikzcd}
K_1(u) \rar{\tau} & K_2(u) \\
\frac{K_1[X]}{(f_1)} \uar{p_1} \rar{\overline\sigma} &
\frac{K_2[X]}{(f_2)} \uar{p_2}
\end{tikzcd} \]

Donde $\sigma$ es inducido por el isomorfismo de extensión a polinomios.
#+end_proofs

*** 4.1. Cuerpo de descomposición
**** 4.1.1. Teorema de Kronecker
Sea $f$ de grado no nulo sobre $K$, entonces existe
una extensión $F/K$ tal que existe $u \in F$ con $f(u) = 0$.

***** Demostración
Puedo descomponer en irreducibles $f = f_1f_2\dots f_m$; y tener una 
extensión cumpliendo lo pedido:

\[ F = \frac{K[X]}{(f_1)}\]

Para el elemento $u = x + (f_1)$.

**** 4.1.2. Extensión de un homomorfismo
Dadas extensiones $F_1/K_1, F_2/K_2$, decimos que $\tau : F_1 \longrightarrow F_2$ 
es una extensión de $\sigma : K_1 \longrightarrow K_2$, ambos homomorfismos de 
cuerpos, cuando $\tau|_{K_1} = \sigma$.

**** 4.1.3. Isomorfismo extendido a polinomios
Sea $\sigma : K_1 \longrightarrow K_2$ isomorfismo de cuerpos. Existe una única extensión a
un isomorfismo $\sigma : K_1[X] \longrightarrow K_2[X]$ cumpliendo que $\sigma(X) = X$.

***** Demostración
Por la propiedad universal por el anillo de polinomios. Las imágenes
de todos los elementos están fijas excepto la de $X$ y sus múltiplos.

**** 4.1.4. Isomorfismos respetan irreducibilidad
Sea $f_1 \in K_1[X]$ irreducible sobre $K_1$, entonces $\sigma(f)$ es irreducible sobre
$K_2$; donde $\sigma$ es la [[*4.1.3. Isomorfismo extendido a polinomios][extensión]] a polinomios de un isomorfismo.

***** Demostración
Si tuviéramos $f_1 = gh$ dos polinomios no triviales, su grado se 
conservaría al aplicar el isomorfismo y tendríamos
$\sigma(f)=\sigma(g)\sigma(h)$.

**** 4.1.5. Isomorfismo de raíces de polinomios
Sea $\sigma : K_1 \longrightarrow K_2$ isomorfismo de cuerpos y sean $F_1/K_1, F_2/K_2$ 
extensiones algebraicas. Dado un homomorfismo $\tau : F_1 \longrightarrow F_2$ sobre $\sigma$;
si $u$ es raíz de $p$ entonces $\tau(u)$ es raíz de $\sigma(p)$.

***** Demostración
Por simple cálculo tomando $p(x) = a_nx^n + \dots + a_1x + a_0$:

\[ \begin{aligned}
\sigma(p)(\tau(u)) &= \sigma(a_n)\tau(u)^n + \dots + \sigma(a_1)\tau(u) + \sigma(a_0) \\ 
                   &= \tau(a_n)\tau(u)^n + \dots + \tau(a_1)\tau(u) + \tau(a_0) \\
                   &= \tau(a_nu^n + \dots + a_1u + a_0) \\
                   &= \tau(0) = 0
\end{aligned} \]

**** 4.1.6. Los endomorfismos de extensiones algebraicas son automorfismos
Sea $F/K$ una extensión algebraica y $\tau : F/K \longrightarrow F/K$ un endomorfismo
sobre $K$. Entonces $\tau$ es un automorfismo.

***** Demostración
Tenemos que es una extensión de la identidad y que preserva [[*4.1.5. Isomorfismo de raíces de polinomios][raíces]].
Por eso, dado un elemento $u \in F$, tomamos su $f = Irr(u,K)$. Y tenemos
que $\{\tau^n(u)\}_{n\in \mathbb{N}}$ es una sucesión de raíces del polinomio que, por 
inyectividad, deberá repetir los elementos en algún momento.

Tendremos $\tau^m(u)=u$ y será sobreyectiva. Nótese que estamos usando
la inyectividad de todo homomorfismo de cuerpos.

**** 4.1.7. Isomorfismo intercambiando conjugadas
Sea $\sigma : K_1 \longrightarrow K_2$ isomorfismo de cuerpos. Sea $p$ irreducible
y $u_1,u_2$ raíces de $p$ y $\sigma(p)$ en extensiones $F_1,F_2$. Entonces existe un 
único isomorfismo $\tau : K_1(u_1) \longrightarrow K_2(u_2)$ sobre $\sigma$ tal que $\tau(u_1) = u_2$.

***** Demostración
El isomorfismo buscado sale como composición:

\[K_1(u_1) \cong 
  \frac{K_1[X]}{(f_1)} \cong 
  \frac{K_2[X]}{(f_2)} \cong
  K_2(u_2)\]

**** 4.1.8. Número de extensiones
El número de extensiones $\tau : K_1[u_1] \longrightarrow F_2$ sobre $\sigma$ es el número de
raíces distintas de $\sigma(p)$ en $F_2$.

***** Demostración
Por la [[*4.1.7. Isomorfismo intercambiando conjugadas][proposición anterior]], una para cada raíz de $\sigma(p)$. Nótese
que no puede haber más porque la imagen de $u_1$ determina completamente
el morfismo y porque la imagen de raíz [[*4.1.5. Isomorfismo de raíces de polinomios][debe ser]] una raíz.

**** 4.1.9. Cuerpo de descomposición
Un $E/K$ es un cuerpo de descomposición de $f$ ssi existen $u_1,\dots,u_n \in E$ 
tales que $f = (X-u_1)\dots(X-u_n)$ y $E = K(u_1,\dots,u_n)$.

***** Caracterización
Nótese que es el mínimo en el que factoriza linealmente. Cualquier
otro en el que factorice linealmente necesita contar con sus raíces.

**** 4.1.10. Cuerpo de descomposición en una torre
Sean $K \subset F \subset E$. Si $E$ es cuerpo de descomposición de $f$ sobre $K$, 
también lo es de $f$ sobre $F$.

***** Demostración
Se cumple trivialmente:

\[ E = K(u_1,\dots,u_n) \subset F(u_1,\dots,u_n) \subset E\]

**** 4.1.11. Existencia del cuerpo de descomposición
Cualquier $f \in K[X]$ de grado $n$ tiene un cuerpo de descomposición, 
que además verifica $[F:K] \leq n!$

***** Demostración
****** Inducción: caso base
Cuando $n=1$, tenemos una raíz en el cuerpo.

****** Inducción: caso inductivo
En otro caso, por [[*4.1.1. Teorema de Kronecker][Kronecker]], tenemos que existe una extensión
en la que hay una raíz del polinomio. Tomamos esa raíz para crear
$K(u)$. Por hipótesis de inducción, hay un cuerpo de descomposición
de $f/(X-u)$ sobre $K(u)$, llamado $F$. Por último, podemos construir 
un cuerpo de descomposición con sus raíces.

Tenemos además que la raíz tiene menos grado que el polinomio:

\[ [F:K] = [F:K(u)][K(u):K] \leq (n-1)!n = n! \]

**** 4.1.12. Isomorfismo entre cuerpos de descomposición
Sean $F_1/K_1, F_2/K_2$ cuerpos de descomposición de $f \in K_1[X]$ y 
$\sigma(f) \in K_2[X]$; para $\sigma : K_1 \longrightarrow K_2$ isomorfismo. Entonces son
isomorfos.

***** Demostración
****** Caso base
Si ambos son de grado $1$ tenemos extensiones triviales y 
hemos terminado.

****** Caso inductivo
Sea $u \in F_1$ raíz de $f$. Como $Irr(u,K) \mid f$, tenemos que 
$\sigma(Irr(u,K)) \mid \sigma(f)$. Si tomamos una raíz $v$ de $\sigma(Irr(u,K))$ y 
aplicamos el [[*4.1.7. Isomorfismo intercambiando conjugadas][isomorfismo intercambiando conjugadas]] anterior,
tenemos una extensión $\tau : K_1(u) \longrightarrow K_2(v)$ que lleva una en 
otra. Ahora tomamos $f=g(X-u)$ y por inducción tenemos
un isomorfismo extendiendo hasta el cuerpo de descomposición.

**** 4.1.13. Unicidad del cuerpo de descomposición
Dos cuerpos de descomposición de $f \in K[X]$ sobre $K$ son isomorfos.

***** Demostración
Trivial aplicando lo [[*4.1.12. Isomorfismo entre cuerpos de descomposición][anterior]] al isomorfismo igualdad.

**** 4.1.23. Cuerpo de descomposición de una familia
Sea ${\cal P} \subseteq K[X]$ una familia de polinomios no constantes. Una
extensión $E/K$ es cuerpo de descomposición suyo si todo polinomio
factoriza linealmente y es además se tiene $E = K(S)$ con:

\[ S = \{ u \in E \mid \exists f \in {\cal P}: f(u)=0\} \]

**** 4.1.24. Existencia del cuerpo de descomposición de una familia
Para toda familia de polinomios existe un cuerpo de descomposición.

***** Demostración
****** Caso finito
En el caso finito, multiplicamos toda la familia para aplicar
la [[*4.1.11. Existencia del cuerpo de descomposición][existencia del cuerpo de descomposición]] al producto.

****** Caso infinito
Cuando tenemos una familia $\{ f_\lambda \mid \lambda \in \Lambda\}$. Si tomamos $I \subset \Lambda$ finito, 
podemos asignarle un cuerpo de descomposición $F_I$ tal que $I\subset J$ 
implique $F_I \subset F_J$.

Tomamos:

\[F = \bigcup_{J\text{ finito}} F_J \]

Las operaciones entre dos elementos de $F$ se definen en el menor
cuerpo que contenga a los dos.

Esto es un cuerpo de descomposición porque todo polinomio ya
descompone linealmente en cualquier $F_J$ que lo contenga; y cada
$F_J$ era ya cuerpo de descomposición de los polinomios que contenía,
así que el cuerpo de descomposición debe al menos contener a todos
los $F_J$.

**** 4.1.25. Unicidad (esencial) del cuerpo de descomposición de una familia
El cuerpo de descomposición de una familia de polinomios es único
salvo isomorfismos.

***** Demostración
****** Caso finito
Aplicamos que los cuerpos de descomposición de un polinomio
[[*4.1.13. Unicidad del cuerpo de descomposición][son isomorfos]] al polinomio producto.

****** Caso infinito
Sean $F_1,F_2$ dos cuerpos de descomposición sobre $K$ de una familia
de polinomios.

Ordenamos el siguiente conjunto por inclusión y por extensión del
isomorfismo. 

\[ (E,\tau) \leq (F,\psi) \Leftrightarrow 
(E \subset F) \wedge (\psi|_E = \tau)\]

Es una ordenación inductiva porque la unión arbitraria da una 
cota maximal de cualquier cadena:

\[ {\cal E} = 
\left\{ (E,\tau) 
\mid F_1 \supset E \supset K;\;
\tau : E/K \longrightarrow F_2/K
\right\}\]

Que sabemos no vacío por el caso finito. Sea $(F,\sigma)$ maximal. Y 
supongamos que $F \subsetneq F_1$, entonces existe alguna raíz de alguno
de los polinomios que no está en $F$. Creando un [[*4.1.7. Isomorfismo intercambiando conjugadas][isomorfismo]]
sobre $F$ que la llevara a su conjugada, contravendríamos maximalidad.

Ahora, todo $f$ de la familia descompondría en $F$ y por $\sigma$, se las
llevarían a $F_2$.

**** DONE Descomposición
Un polinomio $f \in K[X]$ *descompone* en una extensión $E$ si
factoriza como polinomios lineales en $E[X]$. Llamamos *cuerpo de
descomposición* a un cuerpo extensión de $K$ minimal en el que
descompone.

Propiedades:

 - Sea $E$ cuerpo de descomposición, entonces $E = K(\alpha_1,\alpha_2,\dots,\alpha_n)$, 
   siendo una extensión finita con grado acotado por $n!$.
 - Todo polinomio tiene cuerpo de descomposición sobre $K$, ya que 
   podemos tomar una clausura algebraica y crear $K(\alpha_1,\dots,\alpha_n)$ con
   sus raíces.

*** 4.2. Clausura algebraica
**** 4.2.1. Algebraicamente cerrado
Un cuerpo tal que toda extensión algebraica suya sea trivial
es un cuerpo algebraicamente cerrado.

**** 4.2.2. Caracterización de los algebraicamente cerrados
Equivalen las siguientes propiedades:

 1. Todo polinomio no constante tiene raíz en $K$.
 2. Todo polinomio descompone linealmente en $K$.
 3. Un polinomio es irreducible en $K$ ssi es de grado $1$.
 4. Toda extensión algebraica de $K$ es trivial.

***** Demostración
****** Implicación 1 a 2
Como $f$ tiene raíz en $K$, podemos dividirlo por $(x-u)$, para
obtener un nuevo polinomio de grado menor.

****** Implicación 2 a 3
Trivialmente.

****** Implicación 3 a 4
Sea un elemento en la extensión algebraica, su irreducible
debe ser de grado $1$, luego debe estar en el cuerpo base.

****** Implicación 4 a 1
Si algún polinomio no constante no tuviera raíz, aplicamos
[[*4.1.1. Teorema de Kronecker][Teorema de Kronecker]] para crear una extensión algebraica
no trivial.

**** 4.2.3. Infinitud de algebraicamente cerrados
Todo cuerpo algebraicamente cerrado es infinito.

***** Demostración
Si tengo un cuerpo finito $K$ formo el polinomio irreducible
siguiente, que no tiene raíces en $K$:

\[ 
f(x) = \prod_{k \in K} (x-k) + 1
\]

**** 4.2.4. Cuerpo algebraicamente cerrado de elementos algebraicos
Sea $E/K$ con $E$ algebraicamente cerrado. Los elementos algebraicos
de $E$ forman un cuerpo algebraicamente cerrado.

***** Demostración
Sabemos que [[*3.2.30. Clausura algebraica relativa][forman un cuerpo]]. Para ver que es algebraicamente cerrado
vemos que todo polinomio sobre ellos tiene una raíz en $E$, por ser
este algebraicamente cerrado. Como una raíz es algebraica, tiene
una raíz en el subcuerpo de los algebraicos.

**** 4.2.5. Clausura algebraica absoluta
Una extensión algebraica $E/K$ es la clausura algebraica (absoluta) 
si es una extensión algebraica y $E$ es algebraicamente cerrado.

**** 4.2.6. Caracterización de la clausura algebraica
Equivalen:

 1. $E/K$ clausura algebraica.
 2. $E/K$ algebraica y todo polinomio no constante $f \in K[X]$ 
    descompone en factores lineales en $E[X]$.
 3. $E$ es cuerpo de descomposición de todos los polinomios no 
    constantes de $K$.
 4. $E/K$ algebraica y todo no constante tiene una raíz en $E$.

***** Demostración
****** Implicación 1 a 2
Como $E$ es algebraicamente cerrado, [[*4.2.2. Caracterización de los algebraicamente cerrados][sabemos que]] todos sus polinomios
descomponen en factores lineales en $E[X]$.

****** Implicación 2 a 3
Todo polinomio descompone. Además, todo elemento de $E$ es algebraico;
así que $K(S) = E$.

****** Implicación 3 a 1
$E$ está generado por elementos algebraicos, luego es algebraico.
Además, todo polinomio no constante descompone en él, luego
es algebraicamente cerrado por la [[*4.2.2. Caracterización de los algebraicamente cerrados][caracterización]].

****** TODO Equivalencia con 4
**** 4.2.7. Transitividad de la clausura algebraica
Sean $K \subset F \subset E$ torre de cuerpos, con $F/K$ algebraica. 
Entonces $E$ es clausura algebraica de $F$ ssi lo es de $K$.

***** Demostración
Ser algebraicamente cerrado es independiente del cuerpo base de
la extensión. Ser algebraico [[*3.2.29. Torre algebraica][equivale]] a que lo sean las dos partes.

**** 4.2.8. Teorema de Steinitz
Para todo cuerpo existe una clausura algebraica.

***** Demostración
Sabemos que [[*4.1.24. Existencia del cuerpo de descomposición de una familia][existe]] el cuerpo de descomposición de todos los polinomios
no constantes. Por la caracterización de [[*4.2.6. Caracterización de la clausura algebraica][clausura algebraica]] sabemos
que lo es.

**** 4.2.9. Unicidad esencial de la clausura algebraica
Dos clausuras algebraicas $E_1,E_2$ del mismo cuerpo $K$ son isomorfas 
sobre $K$.

***** Demostración
Tenemos unicidad de esencial de los cuerpos de descomposición,
y estos son cuerpos de descomposición de todos los polinomios
no constantes.

**** 4.2.10. Extensión de homomorfismos a algebraicas
Sea $K \subset F \subset E$ con $E/K$ algebraica. Entonces todo $\sigma : F \longrightarrow \overline{K}$ tiene
una extensión $\tau : E \longrightarrow \overline{K}$.

***** Demostración
Aplicamos Zorn sobre el siguiente conjunto ordenado para la inclusión,
sabiendo que toda cadena de cuerpos está acotada por su unión y que cada
$\sigma_i$ es extensión del anterior:

\[{\cal S} = \{(E_i,\sigma_i) \mid 
F \subset E_i \subset E;\; \sigma_i : E_i \longrightarrow \overline{K};\;
\sigma_i|_F = \sigma\}\]

Esto nos da el maximal $E_1$. Si $E_1 \subsetneq E$, tomo $u \in E - E_1$; y busco un
[[*4.1.7. Isomorfismo intercambiando conjugadas][isomorfismo]] intercambiando $u$ por una conjugada también raíz de $Irr(u,K)$.
Esto me da $(E_1,\sigma_1) \leq (E_1(u),\tau)$.

**** 4.2.11. Cardinalidad de la clausura algebraica
Sea $K$ cuerpo y $\overline{K}$ su clausura.

 1. Si $K$ es finito, $\overline{K}$ es infinito numerable
 2. Si $K$ es infinito, $\#K = \#\overline{K}$.

***** Demostración
****** Caso finito
Cuando $K$ es finito, el número de polinomios irreducibles
sobre él es infinito numerable.
****** Caso infinito
En el caso infinito, como máximo se tendrá la acotación que
da el número de polinomios, que es una unión numerable:

\[ \#\overline{K} \leq \#\left(\bigcup K^n\right) = \#K \]

** 5. Extensiones normales y separables
*** 5.1. Elementos conjugados y extensiones conjugadas
**** 5.1.1. Elementos conjugados
Sean $u,v \in \overline{K}$, clausura algebraica. Equivalen:

  1. $Irr(u,K) = Irr(v,K)$
  2. $\exists \tau : K(u) \longrightarrow K(v)$ *isomorfismo* con $\tau(u) = v$.
  3. $\exists\sigma : K(u) \longrightarrow \overline{K}$ *homomorfismo* con $\sigma(u) = v$.
  4. $\exists \sigma : \overline{K} \longrightarrow \overline{K}$ *automorfismo* con $\sigma(u) = v$.

Morfismos manteniendo $K$. Estos elementos se llaman 
*elementos conjugados*.

***** Demostración
****** Implicación 1 a 2
Supongamos que tienen el mismo polinomio irreducible $f(X)$, 
entonces podemos construir un isomorfismo que lleve $u,v$ a 
$X + (f(X))$ para tener:

\[K(u) \cong \frac{K[X]}{(f(X))}\cong K(v)\]

****** Implicación 2 a 3 y 4
Dado el isomorfismo, lo podemos prolongar a un homomorfismo.
Y dado un homomorfismo, lo podemos [[*4.2.10. Extensión de homomorfismos a algebraicas][prolongar]] a un automorfismo 
por ser una extensión algebraica.

****** Implicación 4 a 1
Supongamos que existe el automorfismo de $\overline{K}$. Sea $f(X) = Irr(u,K)$,
y tenemos $0 = \phi(f(u)) = f(\phi(u)) = f(v)$; luego $Irr(u,K) = Irr(v,K)$.

**** 5.1.3. Extensiones conjugadas
Sean $F_1/K$, $F_2/K$ extensiones algebraicas, equivalen:

 1. $\exists \sigma: F_1 \longrightarrow F_2$ *isomorfismo* sobre $K$.
 2. $\exists \sigma : F_1 \longrightarrow \overline{K}$, *homomorfismo* sobre $K$ con $\sigma(F_1) = F_2$.
 3. $\sigma : \overline{K} \longrightarrow \overline{K}$, *isomorfismo* tal que $\sigma(F_1) = F_2$.

Estas extensiones se llaman *extensiones conjugadas*.

***** Demostración
****** Implicación 1 a 2
Extendiendo el isomorfismo se pasa de 1 a 2.

****** Implicación 2 a 3
Dado el homomorfismo, lo podemos [[*4.2.10. Extensión de homomorfismos a algebraicas][prolongar]] a un homomorfismo
por ser $\overline{K}$ algebraica. Tenemos entonces un endomorfismo de un
cuerpo algebraico, que [[*4.1.6. Los endomorfismos de extensiones algebraicas son automorfismos][debe ser]] un automorfismo.

****** Implicación 3 a 1
La restricción a $F_1$ es isomorfismo.

*** 5.2. Extensiones normales
**** 5.2.1. Extensiones normales
Sea $F/K$ extensión algebraica, subcuerpo de $\overline{K}$, equivalen:

  - $\sigma : F \longrightarrow \overline{K}$ sobre $K$, me da $\sigma(F) = F$.
  - Todo irreducible de $K[X]$ con una raíz en $F$ descompone en 
    lineales en $F[X]$.
  - $F$ es cuerpo de descomposición de una familia de polinomios
    sobre $K[X]$.

 A una extensión de este tipo se le llama *extensión normal*.

***** Demostración
****** Implicación 1 a 2
Dos raíces del mismo irreducible son conjugadas, luego existe
un [[*5.1.1. Elementos conjugados][homomorfismo]] que lleva una en otra, como debe llevar $F$ en $F$,
la otra debe estar en $F$.

****** Implicación 2 a 3
Para cada elemento de $F$ puedo tomar su irreducible, como tiene
una raíz en $F$ tiene todas. $F$ es el cuerpo de descomposición de la
familia de todos los irreducibles de sus elementos.

****** Implicación 3 a 1
Tenemos que $F = K(\alpha_1,\alpha_2,\dots)$, raíces de los polinomios. La imagen
de la raíz de un polinomio sobre $K$ debe ser raíz de ese mismo 
polinomio porque este debe quedar invariante sobre $\sigma$. Así tenemos
que $\sigma(F) \subset F$, y por ser algebraico, todo [[*4.1.6. Los endomorfismos de extensiones algebraicas son automorfismos][endomorfismo es 
automorfismo]].

**** 5.2.3. Propiedades de las extensiones normales
Sea $E$ extensión normal. Cumple:

 1. Si $A/K$ es algebraica, $EA/A$ es normal.
 2. Si $K \subset F \subset E$, entonces $E/F$ es normal.
 3. Si $E_1/K, E_2/K$ son normales, $E_1E_2/K$ es normal.
 4. Sea $E_\lambda$, familia de extensiones normales; $F = \bigcap E_\lambda$ es normal.

***** Demostración de 1
Dado $\sigma : EA/A \longrightarrow \overline{K}/A$, tengo que $\sigma(EA) = \sigma(E)\sigma(A) = EA$.

***** Demostración de 2
Sea $\sigma : E/F \longrightarrow \overline{K}/F$, como deja fijo $K$, debe tenerse $\sigma(E)=E$.

***** Demostración de 3
Sea $\sigma: E_1E_2/K \longrightarrow \overline{K}/K$, las restricciones dejan fijos ambos cuerpos
y $\sigma(E_1E_2) = \sigma(E_1)\sigma(E_2) = E_1E_2$.

***** Demostración de 4
Si un homomorfismo de la intersección lo extiendo y lo restrinjo a
cada uno, debe dejar todos los cuerpos fijos. Por tanto, un elemento
en la intersección debe quedarse en la intersección.

***** Contraejemplo: subcuerpo de normal no es normal
El último es cuerpo de descomposición de $x^3-2$,
pero el primero no es normal, porque no están todas las
raíces del polinomio irreducible de $\sqrt[3]{2}$.

$\mathbb{Q} 
\subset \mathbb{Q}(\sqrt[3]{2}) 
\subset \mathbb{Q}(\sqrt[3]{2}, i)$

**** 5.2.4. Clausura normal
Llamamos clausura normal de $F/K$ a:

\[ E = \bigcap \{ H \mid H \supset F;\; H/K\text{ normal}\}\]

**** 5.2.5. Existencia de la clausura normal
Para toda extensión algebraica existe una clausura normal. 

***** Demostración
Trivial porque la clausura algebraica es normal.

**** 5.2.6. Unicidad de la clausura normal
La clausura normal es única salvo isomorfismos.

***** Demostración
Sean las dos clausuras sobre la clausura algebraica absoluta.
Como son intersección de normales y ambas lo son, deben ser
la misma.

**** 5.2.7. Extensión de homomorfismos a extensión normal
Sea $K \subset F \subset E$ con $E/K$ normal. Todo $\tau : F \longrightarrow E$ extiende a
un $\tau : E \longrightarrow E$. 

***** Demostración
Tenemos que extiende a $\tau : F \longrightarrow \overline{K}$ y de ahí, por ser $E$ algebraica,
se [[*4.2.10. Extensión de homomorfismos a algebraicas][prolonga]] a $\tau : E \longrightarrow \overline{K}$. Por ser normal, $\tau(E) = E$.

**** 5.2.8. Clausura de una extensión finita
Sea $F = K(u_1,u_2,\dots,u_n)$ y $f_i = Irr(u_i,K)$; entonces la clausura normal
es el cuerpo de descomposición de $f = f_1f_2\dots f_n$.

***** Demostración
Es normal por ser cuerpo de descomposición de un polinomio, es
la mínima porque debe contener las raíces de $f_i = Irr(u_i,K)$
para ser normal, y si las contiene, debe contener al cuerpo de
descomposición de $f$.

**** 5.2.9. La clausura normal de extensión finita es finita
Sea $F/K$ finita, su clausura normal es finita.

***** Demostración
El cuerpo de descomposición anterior es finito porque puedo
crearlo insertando las raíces de cada polinomio.

**** 5.2.10. Polinomio normal
Un polinomio irreducible es normal si en toda extensión
algebraica $F/K$ con una raíz de $f$, descompone en factores 
lineales.

**** 5.2.11. Caracterización de polinomios normales
Sea $f$ un polinomio en $K[X]$, equivalen:

 1. $f$ es normal sobre $K$.
 2. El cuerpo de descomposición de $f$ es $K(u)$, una raíz de $f$.
 3. Todas las raíces de $f$ es expresan como polinomios de una de ellas.

***** Demostración
****** Implicación 1 a 2
Tenemos que en $K(u)$, $f$ descompone en factores lineales,
luego es cuerpo de descomposición.

****** Implicación 2 a 3
Trivial.

****** Implicación 3 a 1
Una extensión con una raíz $u$ contendría a $K(u)$, y como todas
las raíces se expresan como polinomios de $u$, contendría a todas
las raíces y $f$ descompondría en polinomios lineales.

**** DONE Caracterización de extensiones normales en torres
 #+begin_theorem
 Sea $K\subset F \subset E$ extensiones finitas, $E$ extensión normal. Equivalen:

   - $F/K$ es normal.
   - Para cada $\sigma : E/K \longrightarrow E/K$, se tiene $\sigma(F) = F$.
 #+end_theorem

 Sea $F/K$ normal, podemos cambiar el dominio y codominio para tener un
 $\sigma : F/K \longrightarrow \overline{K}/K$. Por ser $F$ normal, $\sigma(F) = F$.

 Sea $\sigma : F/K \longrightarrow \overline{K}/K$, podemos extenderla finitamente hasta $E$ como $\overline\sigma$. Como $E/K$ es
 normal, $\overline\sigma(E) = E$; y así tengo un $\overline\sigma : E/K \longrightarrow E/K$, que me da $\sigma(F)=\overline\sigma(F) = F$.

*** 5.3. Extensiones separables
**** 5.3.1. Elemento separable
Un elemento algebraico $u$ es separable en $K$ si $Irr(u,K)$ no tiene 
raíces múltiples.

**** 5.3.2. Extensiones separables
Una extensión algebraica $F/K$ es *separable* si todos sus elementos 
lo son.

***** Ejemplo de extensión normal no separable
Existen [[http://math.stackexchange.com/questions/982702/example-of-a-non-separable-normal-extension][ejemplos]] de extensiones normales no separables.

**** 5.3.3. Torres separables
Si $E \supset F \supset K$ es extensión separable, lo son $E/F$ y $F/K$.

***** Demostración
Que $F/K$ es separable es trivial. Y $E/F$ es separable porque
$Irr(u,F) \mid Irr(u,K)$, y si el segundo no tiene raíces múltiples,
no puede tenerlas el primero.

**** 5.3.4. Grado separable
El *grado separable* es cardinal del conjunto de homomorfismos de
$F/K \longrightarrow \overline{K}/K$.

\[ [F : K]_s = \#\{F/K \longrightarrow \overline{K}/K\}\]

**** 5.3.5. Grado separable en torres
Sea $K \subset F \subset E \subset \overline{K}$ entonces $[E:K]_s = [E:F]_s[F:K]_s$.

***** Demostración
****** Con dos homomorfismos construyo el mayor
Dados $\sigma : F/K \longrightarrow \overline{K}/K$ y $\psi : E/F \longrightarrow \overline{K}/F$, puedo extender $\sigma$ al
algebraico $E$ para tener $\sigma^\ast : \overline{K}/K \longrightarrow \overline{K}/K$. Ahora, la composición
$\sigma^\ast \circ \psi$, me da el homomorfismo buscado.

****** Y es único
Supongamos que $\sigma^\ast \circ \psi = \sigma'^\ast \circ \psi'$; como deben ser iguales para 
cualquier $f \in F$, se tiene $\sigma = \sigma'$. Ahora, si tomamos la misma extensión
para cada elemento, $\sigma^\ast = \sigma'^\ast$ y entoces por inyectividad $\psi = \psi'$.

Así tenemos ya:

\[ [E:K]_S \geq [E:F]_S[F:K]_S \]

****** Con el mayor construyo los dos menores
Dado un $\sigma : E/K \longrightarrow \overline{K}/K$, para cada $\sigma|_F$ construyo una extensión
a la clausura, $\tau : \overline{K}/K \longrightarrow \overline{K}/K$, que es isomorfismo. Como 
es isomorfismo podemos construirle inversa para tener 
$\tau^{-1} : \overline{K}/K \longrightarrow \overline{K}/K$. A la vez, podemos extender todos los $\sigma$ a
la clausura algebraica como $\sigma^\ast$.

Ahora bien, como $\tau|_F = \sigma|_F$, tenemos que $\sigma^\ast \circ \tau^{-1}$ deja fijo a $F$. 
Así, hemos partido $\sigma$ en $\sigma^\ast \circ \tau^{-1}|_E$ y $\sigma|_F$.

****** Y son únicas
Supongamos que tenemos $\sigma|_F = \sigma'|_F$, entonces las dos extensiones $\tau$
las hemos tomado iguales. Si tenemos $\sigma \circ \tau^{-1}|_E = \sigma' \circ \tau^{-1}|_E$, como $\tau^{-1}$
es sobreyectiva, tenemos $\sigma^\ast|_E = \sigma'^\ast|_E$, y por tanto $\sigma = \sigma'$.

Así tenemos que:

\[ [E:K]_S \leq [E:F]_S[F:K]_S \]

**** 5.3.6. Relación de grado y grado separable
Sea $F/K$ extensión finita, entonces $[F:K]_s \mid [F:K]$.

***** Demostración
****** Caso simple
Sea $K(u)$ la extensión, con polinomio $Irr(u,K)$ de grado $n$. 
Si la raíz $u$ tiene multiplicidad $m$ en el polinomio, todas las
raíces del polinomio tienen la misma multiplicidad y hay
$n/m$ raíces distintas.

Cada homormofismo quedará determinado por la imagen de $u$, y
tenemos $n/m$ imágenes distintas para $u$.

****** Caso compuesto
Ahora procedemos por inducción sobre el grado de la extensión. 
Tomamos un elemento de la base y hacemos:

\[ [F:K(u)]_S[K(u):K]_S  \mid  [F:K(u)][K(u):K] \]

Lo primero es divisible por el caso simple y lo segundo por
hipótesis de inducción.

**** 5.3.7. Igualdad de grados en torres
Sea $K \subset F \subset E$, con $E/K$. Entonces $[E:K]_s = [E:K]$ ssi 
$[E:F]_s = [E:F]$ y $[F:K]_s = [F:K]$.

***** Demostración
Tenemos que deben tenerse ambos casos de igualdad en:

\[
[E:K]_S = [E:F]_S[F:K]_S \leq [E:F][F:K] = [E:K]
\]

**** 5.3.8. Caracterización de extensión separable
La extensión finita $E/K$ es separable ssi $[E:K]_s = [E:K]$.

***** Demostración
Usamos la idea de la demostración de la relación con el grado.
En el caso simple tenemos $[K(u):K]_S = [K(u):K]$ solo cuando la
multiplicidad de cada raíz es uno. En el caso compuesto exigimos
eso a cada paso.

**** 5.3.9. Extensión por un conjunto separable
Para $K(S)/K$ algebraica es separable ssi todo elemento de $S$ es
separable sobre $K$.

***** Demostración
La suma o producto de elementos separables [[http://math.stackexchange.com/a/82837/85067][es separable]].

**** 5.3.10. Propiedades de extensiones separables
Las extensiones separables cumplen:

 1. Para $K \subset F \subset E$, se tiene $E/K$ separable ssi 
    $E/F$ y $F/K$ separables.
 2. Sea $E/K$ algebraica separable y $H/K$ extensión, entonces $EH/H$ 
    es separable.
 3. Sean $E/K$ y $F/K$ separables, entonces $EF/K$ es separable.

***** Demostración
****** Punto 1
Simplemente usar que la igualdad de grados de separabilidad
se da en [[*5.3.7. Igualdad de grados en torres][torres]] y que equivale a la [[*5.3.8. Caracterización de extensión separable][separabilidad]].

****** Punto 2
Tenemos $EH/H = H(E)/H$. Que sea separable [[*5.3.9. Extensión por un conjunto separable][equivale]] a que
cada elemento de $E$ lo sea. Pero $Irr(e,H) \mid Irr(e,K)$, y si uno
tiene sólo raíces simples, el otro las tendrá también.

****** Punto 3
Tenemos $K(E,F)/K$ separable por serlo todos los elementos en 
$E,F$.

**** 5.3.11. La clausura normal de una separable es separable
Sea $F/K$ separable y $E/K$ su clausura normal. Entonces $E/K$ es
separable.

***** Demostración
Si extiendo $F$ con todas las raíces de los irreducibles de sus
elementos, tengo la clausura normal; porque debe contenerlas
y es normal, así que es la mínima. Como cada una de ellas es
separable porque tiene como irreducible el mismo irreducible
de un elemento de $F$, la [[*5.3.9. Extensión por un conjunto separable][extensión entera]] es separable.

**** 5.3.12. Clausura separable
El conjunto de todos los elementos de $\overline{K}$ separables sobre $K$ forman
un subcuerpo $K^{sep}$ que se llama *clausura separable*.

***** Demostración
La suma o producto de elementos separables es separable, como
demostramos [[*5.3.9. Extensión por un conjunto separable][anteriormente]].

**** 5.3.13. Teorema del elemento primitivo
Sea $E/K$ una extensión finita. Es simple ssi el conjunto de
cuerpos intermedios $\{ F \mid K \subset F \subset E\}$ es finito.

***** Demostración
****** Primera implicación
Sea $K(\alpha)$ simple, como es finita es algebraica, y $Irr(a,K)$ tiene 
finitos divisores en la clausura. 

Para cada divisor del polinomio irreducible creo $K[|p|]$, el subcuerpo
generado por los coeficientes del polinomio. Todo cuerpo intermedio $E$,
en el que el irreducible de $\alpha$ sea $p$ contendrá a $K[|p|]$, pero como:

\[ [K(\alpha): E] = [K(\alpha) : K[|p|]] \]

Se tendrá forzosamente $E = K[|p|]$.

****** Segunda implicación
******* Cuerpo base finito
Como la extensión es finita, tenemos que hay finitos elementos.
El grupo multiplicativo de un cuerpo finito es [[http://mathoverflow.net/a/54741/45365][cíclico]], luego es 
simple.

******* Cuerpo base infinito
Siendo $E = K(a_1,a_2,\dots,a_n)$, nos limitamos a probar $K(a,b)$ simple.
Consideramos las $K(a+xb)$ para $x \in F$. Como los elementos de $F$ son 
infinitos y las extensiones intermedias finitas, se tienen $x \neq y$
tales que $K(a+xb) = K(a+yb)$, y por tanto:

\[
b = \frac{ a +bx - (a + by)}{x-y} \in K(a+bx)
\]

***** Contraejemplo:
Hay extensiones finitas de cuerpos que no son simples

**** 5.3.13. Finita y separable es simple
Una extensión finita y separable es simple.

***** Demostración
Si es finita y separable, podemos tomar su clausura normal.
La clausura normal de una extensión finita es [[*5.2.8. Clausura de una extensión finita][finita]], así que
tengo una extensión de Galois finita. Habrá finitas subextensiones
porque habrá finitos subgrupos de Galois.

***** Contraejemplo: cuerpo finito no simple
Tenemos [[https://en.wikipedia.org/wiki/Primitive_element_theorem#Counterexamples][contraejemplos]] en característica $p$ con cuerpos de
dimensión $p^2$.

**** 5.3.14. Endomorfismo de Frobenius
Sea $K$ de característica de $p$. Llamamos *endomorfismo de Frobenius* 
a $\phi(u) = u^p$.

**** 5.3.15. Cuerpos perfectos
Para $K$ cuerpo equivalen:

 1. Todo $f \in K[X]$ irreducible tiene raíces simples.
 2. Toda $E/K$ algebraica es separable.
 3. Toda $E/K$ finita es separable.
 4. $car(K)=0$ ó $car(K)=p$, y el endomorfismo de Frobenius es 
    sobreyectivo.

Y en ese caso, llamamos a $K$ *cuerpo perfecto*.

***** Demostración
****** Implicación 1 a 2
Todo elemento de la extensión cumple algún polinomio,
y son todos separables, luego es separable.

****** Implicación 2 a 3
Trivial

****** Implicación 3 a 4
Supongamos que no fuera sobreyectivo, existe $y \neq x^p$.
Si tomamos $(x^p-y)$, tenemos que es irreducible. Y si creamos
entonces $z^p = y$ tendríamos una extensión no finita no
separable.

# TODO: ¿Por qué es irreducible? Por Eisenstein en algún cuerpo 
# raro podría tenerse.

****** Implicación 4 a 1 en característica 0
En característica $0$, un polinomio no puede dividir a su derivada,
que será de grado menor, así que un irreducible no puede tener raíces
dobles.

****** Implicación 4 a 1 en característica p
Para que un irreducible divida a la derivada, que debe ser de grado
menor, se debe tener que sea $0$. El polinomio original debe ser
de la forma $f(x^p)$ para que al derivarlo se anule.

Cuando Frobenius es automorfismo, podemos escribir:

\[f(x^p) = \sum a_i x^{ip} = \left(\sum \sqrt[p]{a_i} x^i\right)^p\]

contraviniendo irreducibilidad. Todos los polinomios deben tener
raíces simples.

**** 5.3.17. Ejemplos de cuerpos perfectos
Son perfectos:

 1. Todo cuerpo de característica cero.
 2. Todo cuerpo finito.
 3. Todo cuerpo algebraicamente cerrado.
    
***** Demostración
****** Punto 1
Trivial desde la [[*5.3.15. Cuerpos perfectos][caracterización]].
****** Punto 2
En todo cuerpo finito, un endomorfismo es sobreyectivo.
****** Punto 3
En un algebraicamente cerrado, todo irreducible es lineal y
tiene raíces simples.

*** 5.4. Derivada y raíces múltiples
**** 5.4.1. Raíces
Sea $f\in F[X]$ y $u \in F$. Es raíz de multiplicidad $k$ cuando $f = (X-u)^kf_0$,
con $f_0(u) \neq 0$.

**** 5.4.2. Derivada
Se define la derivada de $f$ como:

\[ f' = \sum_{i=1}^n ia_iX^{i-1} = na_nX^{n-1} + \dots + a_1\]

**** 5.4.3. Propiedades de la derivada
La derivada verifica:

 1. $(f+g)' = f'+g'$
 2. $(f \cdot g)' = f' \cdot g'$
 3. $(f^m)' = mf^{m-1}\cdot f'$

**** 5.4.4. Condición de raíces simples
Las raíces de $f$ son simples ssi $mcd(f,f') = 1$.

**** 5.4.5. Condición de raíces simples en irreducibles
Sea $f$ irreducible con $f' \neq 0$, las raíces de $f$ son simples.

**** 5.4.6. Propiedades de las raíces simples
Se cumple:

 1. En característica $0$, todo irreducible tiene raíces simples.
 2. En característica $p$ prima, un irreducible tiene raíces múltiples
    ssi $f(x) = g(x^p)$.

***** TODO Demostración
**** 5.4.7. Polinomio separable
Un polinomio $f \in K[X]$ se llama separable $K$ si sus factores 
irreducibles tienen sólo raíces simples.

** 6. Teoría de Galois Finita
*** 6.1. Grupos de automorfismos
**** 6.1.1. Espacio vectorial de las aplicaciones de un conjunto
Sea $S$ un conjunto. Las aplicaciones $Fun(S,F)$ con la suma y producto
de escalares elevados desde $F$ forman un espacio vectorial de dimensión
$|S|$.

***** Demostración
Simplemente comprobar que cumplen las propiedades de espacio 
vectorial.

**** 6.1.2. Proposición al lema de Dedekind
Sean $\sigma_1,\dots, \sigma_m : G \longrightarrow F^\times$ homomorfismos desde un grupo $G$. 
Son distintos ssi son linealmente independientes sobre $F$.

***** Demostración
****** Caso base
Procedemos por inducción. Cuando $n=1$, es trivial.

****** Caso inductivo
Tomemos un subconjunto mínimo de linealmente dependientes, 
$\sigma_1,\dots,\sigma_s$. Tendríamos $b_i \in F^\times$:

\[\sigma_s = b_1\sigma_1 + \dots + b_{s-1}\sigma_{s-1}\]

Si tomamos ahora $y$ tal que $\sigma_1(y) \neq \sigma_s(y)$, evaluamos en $xy$ y 
multiplicamos por $\sigma_s(y)$ obtenemos dos ecuaciones que restadas
dan:

\[0 = b_1(\sigma_1(y)-\sigma_s(y))\sigma_1 + \dots + b_{s-1}(\sigma_{s-1}(y) - \sigma_s(y)) \sigma_{s-1}\]

Relación de dependencia no nula menor que la anterior.

**** 6.1.3. Lema de Dedekind
Un conjunto de homomorfismos de cuerpos $F_1 \longrightarrow F_2$ distintos
son linealmente independientes sobre $F_2$.

***** Demostración
Desde el lema anterior, tenemos que son linealmente independientes 
una vez restringidos a $F_1^\times \longrightarrow F_2^\times$, el añadirles el $0$ no los vuelve 
dependientes.

**** 6.1.4. Acotación del número de homomorfismos sobre K
Existen como máximo $[F:K]$ morfismos distintos sobre $K$ 
hacia cualquier otro cuerpo:

\[|Hom(F/K,E/K)| \leq [F:K]\]

***** Demostración
Sea $\{u_1,\dots,u_n\}$ base de $F$, y supongamos $n+1$ homomorfismos
distintos. El siguiente sistema de ecuaciones tiene solución 
no trivial porque tiene $n+1$ incógnitas y tiene $n$ ecuaciones.
      
\[ X_1\sigma_1(u_j) + \dots + X_{n+1}\sigma_{n+1}(u_j) = 0 
\qquad j = 1,\dots,n\]
      
Pero una solución es una relación de dependencia sobre toda la
base de $F$. Si son dependientes, por Dedekind son [[*6.1.3. Lema de Dedekind][iguales]].

**** 6.1.5. Grupo de extensión
Para toda extensión finita $F/K$ llamamos *grupo de la extensión* a:

\[ G(F/K) = \{ \sigma \in  Aut(F) \mid \forall u \in K : \sigma(u) = u\}\]

**** 6.1.6. Acotación de elementos del grupo
Para toda extensión finita $F/K$ se verifica que $|G(F/K)| \leq [F : K]$.

***** Demostración
Caso particular de la [[*6.1.4. Acotación del número de homomorfismos sobre K][acotación]] del número de homomorfismos
sobre el cuerpo.

**** 6.1.7. Cuerpo fijo
Sea $G < Aut(E)$, llamamos *cuerpo fijo* por $G$ al conjunto al que 
dejan fijos todos los elementos de $G$:

\[ E^G = \{ u \in E \mid \forall\sigma\in G: \sigma(u) = u\}\]

Es un *subcuerpo* de $E$.

***** Demostración: es un subcuerpo
Trivialmente desde la definición de automorfismo de cuerpos.

**** 6.1.8. Teorema de Artin
Para $G < Aut(E)$ finito, $[E : E^G] = |G|$.

***** Demostración
Ya tenemos $n = |G| \leq [E : E^G]$. Supongamos la desigualdad estricta 
con $u_1,\dots,u_{n+1} \in E$ independientes sobre $E^G$. Y tenemos el sistema 
de $n+1$ incógnitas y $n$ ecuaciones, sobre los $\sigma_j$ de $G$:

\[ X_1\sigma_j(u_1) + \dots + X_{n+1}\sigma_j(u_{n+1}) = 0 \qquad
j = 1,\dots,n\]
      
Sea $a_1,\dots,a_{n+1}$ una solución no trivial con número mínimo de 
elementos no nulos. Suponemos s.p.g. que $a_1 \neq 0$ y despejamos para 
tener:

\[\sigma_j(u_1) = b_2\sigma_j(u_2) + \dots + b_n\sigma_j(u_{n+1}) 
\qquad j = 1,\dots,n\]
      
En particular, en el caso $\sigma_j = id$, tenemos:

\[u_1 = b_2u_2 + \dots + b_{n+1}u_{n+1}\]

que obliga a que uno de los coeficientes no esté en $E^G$. Supongamos 
s.p.g. que $b_2 \notin E^G$, y sea $\tau \in G$ tal que $\tau(b_2) \neq b_2$. Si aplicamos ahora
$\tau$ a cada una de las ecuaciones y restamos tenemos:

\[0 = (b_2-\tau(b_2))\sigma_j(u_2) + \dots + (b_n-\tau(b_n)\sigma_j(u_{n+1}))
\qquad j = 1,\dots,n\]

Esta solución es no trivial porque $(b_2-\tau(b_2)) \neq 0$, pero tiene más 
elementos nulos que la anterior.

**** 6.1.9. Extensión de Galois
Una extensión finita $E/K$ es *de Galois* cuando:
     
\[\exists Gal(E/K) < Aut(E): E^{Gal(E/K)} = K\]

Llamamos a $Gal(E/K)$ el *grupo de Galois* de la extensión.

**** 6.1.10. Caracterización de extensión de Galois
Una extensión finita es de Galois ssi es normal y separable.

***** Demostración
Sea $Gal(E/K) = G$, entonces cada automorfismo se extiende a un 
homomorfismo $\sigma' : E/K \longrightarrow \overline{K}/K$, luego $[E:K]_S \geq |G| = [E:K] \geq [E:K]_S$, 
y por tanto la extensión es separable. Como además el número total 
de homomorfismos es $[E:K]_S = |G|$, son todos automorfismos y la 
extesión es normal.

Sea $E/K$ normal y separable. Tenemos $n = [E:K]_S = [E:K]$ 
homomorfismos $\tau : E \longrightarrow \overline{K}$ sobre $K$, con $\tau(E) = E$. Entonces 
$G = G(E/K)$ tiene orden $n$. Por Teorema de Artin, 
$[E:E^G] = n = [E:K]$, luego $[E^G:K] = 1$.

**** 6.1.11. Caracterización para extensiones finitas
Sea $F/K$ una extensión separable finita y sea $E/K$ su clausura 
normal. Entonces $E/K$ es una extensión finita de Galois.

***** Demostración
La clausura normal de una extensión separable es [[*5.3.11. La clausura normal de una separable es separable][separable]].

*** 6.2. Correspondencia de Galois, caso finito
**** Correspondencia
Definimos una correspondencia entre los subgrupos de una 
extensión de Galois y los cuerpos intermedios como:

\[ H^\ast = E^H = \{u \in E \mid \forall\sigma\in H: \sigma(u)=u\}\]
\[F^\ast = Gal(E/F) = \{\sigma\in G \mid \forall u\in F: \sigma(u) = u\}\]

**** 6.2.1. Contenidos de cuerpos
Sean $F_i$ cuerpos intermedios de $E/K$ y $H_i$ subgrupos de $Gal(E/K)$.
Se cumple:

 1. Si $F_1 \subset F_2$, entonces $F_1^\ast \supset F_2^\ast$.
 2. Si $H_1 \subset H_2$, entonces $H_1^\ast \supset H_2^\ast$.
 3. $F \subset F^\ast^\ast$; $H < H^\ast^\ast$.
 4. $F^\ast = F^\ast^\ast^\ast$; $H^\ast = H^\ast^\ast^\ast$.

***** Demostración
1. Trivial.
2. Trivial.
3. Trivial.
4. Componiendo el apartado 3 con el 2 y el 1.

**** 6.2.2. Correspondencia de Galois
El par de aplicaciones $\ast$ se llama *correspondencia de Galois*.

**** 6.2.3. Teorema fundamental
Sea $E/K$ una extensión de Galois finita con $G = Gal(E/K)$:

  1. La correspondencia es biyección, ${\cal F}(E/K) \cong {\cal S}(G)$.
  2. $A \supset B$ ssi $B^\ast \subset A^\ast$.
  3. La correspondencia es un antiisomorfismo de retículos, 
     $(F_1 \cdot F_2)^\ast = F_1^\ast \cap F_2^\ast$ y $(F_1 \cap F_2)^\ast = F_1^\ast \vee F_2^\ast$.
  4. Las extensiones $F_1/K$ y $F_2/K$ son conjugadas ssi los subgrupos
     $F_1^\ast$ y $F_2^\ast$ son conjugados en $G$.
  5. La extensión $F/K$ es normal ssi $F^\ast$ es un subgrupo normal de $G$.
     En este caso $Gal(F/K) \cong G/F^\ast$.
  6. Para $H<G$ se verifica $|H| = [E:H^\ast]$ y $[G:H]=[H^\ast:K]$. 
     Para $F \in {\cal F}(E/K)$ se verifica $[E:F] = |F^\ast|$ y $[F:K] = [G:F^\ast]$.
 
***** Demostración de 6 para grupos
Por [[*6.1.8. Teorema de Artin][teorema de Artin]] tenemos $|G| = [E:K]$ y $|H| = [E : H^\ast]$.
Por teorema de Lagrange y teorema del grado tenemos:

\[ |G| = [G:H] |H| \]
\[ [E:K] = [E:H^\ast][H^\ast : K] \]

Simplificando obtenemos $[G:H] = [H^\ast : K]$.

***** Demostración de 6 para cuerpos intermedios
Como $E/F$ es de Galois, $|F^\ast| = [E:F]$ y sabemos $|G| = [E:K]$.
Volvemos a aplicar Lagrange y teorema del grado.

***** Demostración de 1
Tenemos la torre $G > H^\ast^\ast > H$ y:

\[ [G : H^\ast^\ast] = [H^\ast^\ast^\ast : K] = [H^\ast : K] = [G : H] \]

Tenemos la torre $E \supset F^\ast^\ast \supset F$ y:

\[ [E:F] = |F^\ast| = |F^\ast^\ast^\ast| = [E : F^\ast^\ast] \]

***** Demostración de 2 y 3
Se cumple por ser biyección y la proposición anterior. Trivial
desde esto el antiisomorfismo de retículos.

***** Demostración 4
Sean $F_2 = \sigma(F_1)$, para $\tau \in F_1^\ast$, tenemos $\sigma\tau\sigma^{-1} \in F_2^\ast$.
Luego $\sigma F_1^\ast \sigma^{-1} \subset F_2^\ast$. Aplicando lo mismo sobre $\sigma^{-1}$ llegamos
a la otra igualdad. Dando la vuelta al razonamiento, tenemos
que $\sigma F_1^\ast \sigma^{-1} = F_2^\ast$ nos da $F_2 = \sigma(F_1)$.

***** Demostración 5
Desde el cuarto apartado, se conserva normalidad.

Si aplicamos primer Teorema de Isomorfía a la restricción
$\Phi : Gal(E/K) \longrightarrow Gal(F/K)$:

\[ \frac{Gal(E/K)}{F^\ast} 
= \frac{Gal(E/K)}{\ker(\Phi)} 
\cong \im(\Phi) 
= Gal(F/K) \]

El que $\im(\Phi) = Gal(F/K)$ usa la normalidad de $F$.

*** 6.4. Propiedades de las extensiones de Galois
**** 6.4.1. Subgrupos en Galois
Sean $E \supset F \supset K$ con $E/K$ Galois finita. Entonces $E/F$ es Galois
finita y $Gal(E/F)$ es subgrupo de $Gal(E/K)$.

***** Demostración
La finitud se tiene trivialmente. La normalidad se tiene
sobre cuerpos [[*5.2.3. Propiedades de las extensiones normales][intermedios]] y la separabilidad [[*5.3.10. Propiedades de extensiones separables][también]]. Y sabemos
que normal y separable es de [[*6.1.10. Caracterización de extensión de Galois][Galois]].

Que uno es subgrupo de otro está claro por las propiedades de la
[[*6.2.3. Teorema fundamental][correspondencia]].

**** 6.4.2. Extensiones abelianas, cíclicas y solubles
Una extensión finita se dice *abeliana, cíclica o soluble* si es
de Galois y su grupo lo es.

**** 6.4.3. Subgrupos abelianos, cíclicos y solubles
Sea $E\supset F\supset K$ con $E/K$ finita y *abeliana, cíclica o soluble*,
entonces $E/F$ también es abeliana, cíclica o soluble, respectivamente.

***** Demostración
Tenemos que el subgrupo de un abeliano, cíclico o soluble
es también abeliano, cíclico o soluble.

**** 6.4.4. Subextensiones finitas abelianas y cíclicas
Sean $K \subset F \subset E$ torre de extensiones *finitas*:

 1. Si $E/K$ es Galois abeliana, $F/K$ es Galois abeliana.
 2. Si $E/K$ es Galois cíclica, $F/K$ es Galois cíclica.

***** TODO Demostración

**** 6.4.5. Galois para cuerpos compuestos
Sea $E/K$ Galois finita y $F/K$ extensión con $E,F \subset L$.
Entonces $EF/F$ y $E/(E\cap F)$ son extensiones finitas de Galois.
Además la aplicación restricción $\sigma \mapsto \sigma|_E$ define un isomorfismo:

\[ \bullet|_E : Gal(EF/F) \longrightarrow Gal(E/(E\cap F)) < Gal(E/K) \]

***** TODO Demostración

**** 6.4.6. Relación de Galois con el grado
Sea $E/K$ extensión finita de Galois y sea $F/K$ con $E,F \subset L$.
Entonces $[EF:F] \mid [F:K]$.

***** TODO Demostración

**** 6.4.8. Composición de extensiones de Galois
Sean $E_1/K$, $E_2/K$ extensiones Galois finitas con $E_1,E_2 \subset L$.
Entonces $E_1E_2/K$ es extensión finita de Galois y existe un
monomorfismo restricción:

\[
\lambda : Gal(E_1E_2/K) 
\longrightarrow 
Gal(E_1/K) \times Gal(E_2/K)
\]

Cuando además tenemos $E_1 \cap E_2 = K$, $\lambda$ es un isomorfismo.

***** TODO Demostración
**** 6.4.9. Extensión del producto
Sean $E_i/K$ extensiones contenidas en un $L$ con grupos de Galois
$G_1,G_2,\dots,G_n$. Si cumplena demás $E_i \cap (E_1E_2\dots E_{i-1}) = K$, entonces:

\[Gal(E_1E_2\dots E_n/K) \cong G_1 \times G_2 \times \dots \times G_n\]

***** TODO Demostración
**** 6.4.10. Cuerpos fijos del producto
Sea $E/K$ una extensión finita de Galois con grupo $G = G_1 \times \dots \times G_n$.
Sea $E_i$ el cuerpo fijo de $G_1 \times \dots \times \{1\} \times \dots \times G_n$. Entonces $E_i/K$ es
de Galois con grupo $Gal(E_i/K) = G_i$, $E_i \cap (E_1\dots E_{i-1})$ y $E=E_1\dots E_n$.

***** TODO Demostración

** 7. Cuerpos finitos
*** 7.1. Estructura de los cuerpos finitos
**** 7.1.1. Propiedades de un cuerpo finito
Sea $F$ cuerpo finito con $|F| = q$,

  1. $car(F) = p$ es un primo.
  2. El cuerpo primo es $\mathbb{Z}/p\mathbb{Z}$.
  3. $F/\mathbb{Z}_p$ es extensión finita.
  4. $[ F : \mathbb{Z}_p] = n$, entonces $|F| = p^n$.
  5. $F^\times$ es cíclico de orden $|F|-1$.
 
***** Demostración
****** Punto 1
No puede tener característica nula por ser finito, luego debe
ser un primo.

****** Punto 2
Ya que tiene característica prima.

****** Punto 3
Ya que $F$ es finito.

****** Punto 4
Si tiene una base de $n$ elementos, debe tener $p^n$ combinaciones
de elementos básicos.

****** Punto 5
Todo subgrupo finito del grupo multiplicativo de un cuerpo es 
cíclico.

**** 7.1.2. Clasificación de cuerpos finitos
Dos cuerpos finitos del mismo cardinal son isomorfos. De hecho,
son el cuerpo de descomposición de $X^{|F|} - X$ sobre $\mathbb{F}_p$.

***** Demostración
Al ser [[*7.1.1. Propiedades de un cuerpo finito][cíclico]] $u^{q-1} = 1$ nos da $u^q-u = 0$ con todo el cuerpo
como raíces.

**** 7.1.3. Existencia de cuerpos finitos
Dado $p$ primo, existe cuerpo de $p^n$ elementos.

***** Demostración
Sea $f(x) = x^{p^n}-x$ polinomio en $\mathbb{Z}_p$. Su derivada, $-1$, no tiene raíces,
luego tiene sólo raíces simples. Veamos que con sólo añadir esas
raíces del polinomio, llega a ser cuerpo de descomposición.

Sean $u,v$ raíces:

 - $(u+v)^{p^n} - (u+v) = u^{p^n}-u+v^{p^n}-v = 0$
 - $(uv)^{p^n}-uv = u^{p^n}v^{p^n} - uv = 0$
 - $(-u)^{p^n} - (-u) = 0$
 - $(u^{-1})^{p^n} - u^{-1} = 0$

**** 7.1.4. Teorema de Moore
Para cada $p^n$ existe exactamente un cuerpo con $p^n$ elementos; 
que es el cuerpo de descomposición de $x^{p^n}-x$ sobre $\mathbb{Z}_p$. 
No existen otros cuerpos finitos.

***** Demostración
Sabemos los cuerpos [[*7.1.1. Propiedades de un cuerpo finito][deben]] tener cardinal $p^n$ y que dos cuerpos
con el mismo cardinal son [[*7.1.2. Clasificación de cuerpos finitos][isomorfos]]. Además, sabemos que
[[*7.1.3. Existencia de cuerpos finitos][existe]].

**** 7.1.5. Cuerpos de Galois
Notamos por $GF(p^n)$ o $\mathbb{F}_{p^n}$ al único cuerpo con esa cardinalidad,
lo llamamos cuerpo de Galois de orden $p^n$.

**** 7.1.6. Cuerpo extensión
Para $\mathbb{F}_q$ cuerpo finito, exíste un único cuerpo de extensión de grado $n$,
que es $\mathbb{F}_{q^n}$.

***** Demostración
Por el teorema de Moore, $q = p^m$, y sólo hay uno de $p^{nm}$ elementos.

**** 7.1.7. Grupo de automorfismos
El grupo $Aut(\mathbb{F}_{p^n}) \cong \mathbb{Z}_n$ es cíclico y está generado por el [[*5.3.14. Endomorfismo de Frobenius][Endomorfismo de 
Frobenius]].

***** Demostración
El cuerpo fijo bajo el endomorfismo de Frobenius son los $p$ 
elementos cumpliendo $a^p = a$, es decir, el cuerpo base $\mathbb{F}_p$.

El generado debe ser su grupo de Galois, ya que tiene orden $n$.

**** 7.1.8. Grupo de automorfismos relativo
Un $\mathbb{F}_{p^n}$ es subcuerpo de $\mathbb{F}_{p^m}$ ssi $n\;|\;m$. En este caso, $\mathbb{F}_{p^m}/\mathbb{F}_{p^n}$ es cíclica
con $Gal(\mathbb{F}_{p^m}/\mathbb{F}_{p^n}) = \langle \phi^n \rangle$.

***** Demostración
****** Si es subcuerpo, divide
Por Lagrange, $[\mathbb{F}_{p^n} : F] | [\mathbb{F}_{p^m} : F]$.

****** Si divide, es subcuerpo
El $Gal(\mathbb{F}_{p^m}/\mathbb{F}) \cong \mathbb{Z}_m$ tiene un único subgrupo de orden $n$. Y debe
ser el grupo de Galois de un cuerpo de orden $m/n$, que tiene por
Moore que ser $\mathbb{F}_{p^n}$.

*** 7.2. Factorización de polinomios
**** 7.2.1. Listado de polinomios irreducibles
Los factores irreducibles de $X^{p^n} - X$ son exactamente los polinomios
irreducibles de $\mathbb{F}_p[X]$ con grado divisor de $n$.

***** Demostración
****** Los factores irreducibles tienen grado n
Cuando $g(\alpha) = 0$, por ser factor tenemos $\alpha^{p^n} = \alpha$, luego $\alpha \in \mathbb{F}_{p^n}$.
Así, $\mathbb{F}_{p^n} \supseteq \mathbb{F}_p(\alpha) \supseteq \mathbb{F}_p$, y por teorema del grado, $gr(g) = [\mathbb{F}_p(\alpha) : \mathbb{F}_p]$
divide a $[\mathbb{F}_{p^n} : \mathbb{F}_p]$.

****** Los irreducibles de grado divisor de n son factores
Sea $g(\alpha) = 0$, tomamos $m = [\mathbb{F}_p(\alpha) : \mathbb{F}_p] = gr(g)$, y [[*7.1.8. Grupo de automorfismos relativo][sabemos]] que
debe tenerse $\mathbb{F}_{p^m} \supset \mathbb{F}_p(\alpha)$. Por Moore $f(\alpha) = 0$ y $g \mid f$.

**** 7.2.2. Número de mónicos irreducibles
Para $n$ primo, el número de mónicos irreducibles de $\mathbb{F}_p[X]$ de grado $n$
es $(p^n-p)/n \neq 0$.

***** TODO Demostración

**** 7.2.3. Raíces simples
Para $f \in \mathbb{F}_p[X]$, $f_1 = f / mcd(f,f')$ tiene todas las raíces simples y
$f(\alpha) = 0 \iff f_1(\alpha) = 0$.

***** Demostración
Calculando vemos que $f = \prod_i(X-\alpha_i)^{k_i}$ da $f_1 = \prod_{i} (X- \alpha_i)$.

**** 7.2.4. Producto de factores irreducibles de grado n
El producto de todos los factores irreducibles distintos de un $f$
y cuyo grado divida a $n$ es $mcd(f, X^{p^n} - X)$.

***** Demostración

*** TODO 7.3. Ilustraciones
** 8. Extensiones ciclotómicas
*** 8.1. Raíces de la unidad
**** 8.1.1. Subgrupos finitos del grupo multiplicativo
Todo subgrupo finito del grupo multiplicativo $K^\times$ es cíclico.

***** Demostración
Si $n = mcm\{ord(\alpha) \mid \alpha \in G\} = \max\{ord(\alpha) \mid \alpha \in G\}$, tenemos que
debe ser $n = |G|$. En caso contrario se tendría $X^n-1$ con más de
$n$ raíces.

**** 8.1.2. Raíces n-ésimas
Si llamamos $\mu_n(K) = \{ \zeta \in K \mid \zeta^n = 1 \}$, $\mu_n(K)$ es un grupo cíclico finito
con $|\mu_n(K)| \leq n$.

***** Demostración
Trivial por el orden del polinomio $\zeta^n-1$.

**** 8.1.3. Grupo de raíces n-ésimas
Llamamos *grupo de raíces n-ésimas* de la unidad al grupo siguiente. 
Cualquier generador del grupo se llama una *raíz primitiva* de la 
unidad.

\[ \mu_n(\overline{K}) = \{\zeta\in \overline{K} \mid \zeta^n = 1\} \]

**** 8.1.4. Lema de división
Tenemos $d\mid n$ ssi $\mu_d \subset \mu_n$.

***** TODO Demostración
*** 8.2. Polinomios ciclotómicos
**** Definición
 Se llama *polinomio ciclotómico* al polinomio:

 \[\Phi_n = \prod_{\zeta \text{ primitiva}} (X -\zeta)\]

 Se cumple que $\operatorname{grad}(\Phi_n) = \phi(n)$.

**** Cálculo de los polinomios ciclotómicos
 Tenemos que:

 \[\Phi_n  = \frac{X^n-1}{\prod_{d|n, d\neq n} \phi_d}\]

**** Función de Möbius
 Se define $\mu : \mathbb{N} \longrightarrow \mathbb{Z}$ como:

 \[\mu(n) = \threepartdef
 {0}{\exists p: \text{ primo con } p^2|n}
 {(-1)^r}{n = p_1p_2\dots p_n \text{ primos distintos}}
 {1}{n=1}\]

*** 8.3. Extensiones ciclotómicas
** 10. Extensiones cíclicas y radicales
*** 10.1. Extensiones cíclicas
**** 10.1.1. Extensión cíclica
Una extensión es cíclica si es de Galois con grupo cíclico.

**** 10.1.2. Teorema de Lagrange
Sea $K$ cuerpo y $n$ un primo relativo a $car(K)$. Supongamos que existe
una raíz n-ésima de la unidad en $K$:

  1. Dada $E/K$ extensión cíclica de grado $n$, existe $\alpha \in E$ tal que
     $E = K(\alpha)$ y $Irr(\alpha,K) = X^n-a$ para algún $a \in K$.
  2. Para $a \in K$, con $\alpha$ raíz de $X^n-a$, se tiene $K(\alpha)/K$ cíclica
     de grado $d \mid n$ y $\alpha^d \in K$.

*** 10.2. Extensiones solubles y radicales
**** 10.2.1. Extensión soluble
Una extensión separable $F/K$ es soluble si hay una extensión $E/K$ de 
Galois con grupo soluble y $K < F < E$.

***** Definición equivalente
Una extensión separable es soluble si su clausura normal tiene grupo
de Galois soluble.

**** 10.2.2. Extensión soluble por radicales
Una extensión $F/K$ finita separable es soluble por radicales cuando
$mcd([F:K],car(K)) = 1$ y hay una torre:

\[K = E_0 < E_1 < \dots < E_m = E\]

cumpliendo $F < E$ y siendo cada $E_{i+1}/E_i$ de una de estas dos formas:

  1. $E_{i+1} = E_i(\zeta)$ raíz de la unidad.
  2. $E_{i+1} = E_i(\alpha)$ raíz de un polinomio $X^n-a \in E_i[X]$, con 
     $mcd(n,car(K)) = 1$.

**** 10.2.3. Propiedades de las solubles por radicales
Sea $F/K$ soluble por radicales:

  1. Dada $L > K$, $FL/L$ es soluble por radicales.
  2. Dada $L > F > K$, $L/K$ soluble por radicales ssi $F/K, L/F$ solubles
     por radicales.
  3. $F/K, L/K$ solubles por radicales da $FL/K$ soluble por radicales.

***** TODO Demostración

**** 10.2.4. Caracterización de solubilidad por radicales
Sea $F/K$ separable finita. Es soluble por radicales ssi existe:

\[L_0 < L_1 < \dots < L_m = L > F\]

Con cada paso soluble por radicales y $L/K$ Galois.

***** TODO Demostración

**** 10.2.5. Teorema de Galois
Sea $F/K$ separable finita. Es soluble por radicales ssi es soluble.

***** TODO Demostración

**** 10.2.6. Propiedades de las solubles
Cumplen:

  1. Dada $L > F > K$, $L/K$ soluble ssi $F/K,L/F$ solubles.
  2. Dada $F/K$ soluble $L/K$ arbitraria, $FL/L$ es soluble.
  3. Dadas $F/K,L/K$ solubles, $FL/K$ es soluble.

***** TODO Demostración
Aplicando el [[*10.2.5. Teorema de Galois][Teorema de Galois]] a las propiedades de [[*10.2.3. Propiedades de las solubles por radicales][solubles por 
radicales]].

** Lista de temas de teoría
*** 1. Galois es normal y separable
Si $E/K$ es una extensión finita, son equivalentes:

  1. $E/K$ extensión de Galois.
  2. $E/K$ extensión normal y separable.

**** Demostración
***** Primera implicación
Como cada $\sigma \in G = Gal(E/K)$ nos da un $\sigma : E/K \longrightarrow \overline{K}/K$, se tiene, por 
Teorema de Artin:

\[
[E:K]_S \geq |G| = [E:K] \geq [E:K]_S
\]

Por tanto, es separable. Además, cada homomorfismo de ese tipo está
en $G$ luego es un automorfismo y el cuerpo queda fijo, siendo una
extensión normal.

***** Segunda implicación
Sea $n = [E:K]_S = [E:K]$ por separabilidad. Cada uno de esos 
homomorfismos nos da $\sigma : E/K \longrightarrow E/K$, luego $Gal(E/K) = G$ tiene
orden $n$. Por Teorema de Artin:

\[ [E : E^G] = n = [E:K]\]

luego $[E^G : K] = 1$.

*** 2. Teorema del elemento primitivo de Steinitz
En $F/K$ extensión finita equivalen:

  1. $F/K$ tiene elemento primitivo.
  2. Existe un número finito de cuerpos intermedios.

**** Demostración
***** Primera implicación
Sea $F = K(\alpha)$. $Irr(\alpha,K)$, tiene un número finito de factores. Para 
cada uno de ellos, $p$, definimos el subcuerpo generado por sus 
coeficientes $K[|p|]$. Cualquier cuerpo intermedio $E$ en el que $Irr(\alpha,E)$
contendrá a los coeficientes, $E \supset K[|p|]$, pero además:

\[ [K(\alpha) : K[|p|] = [K(\alpha) : E]\]

Luego $E = K[|p|]$ y sólo hay finitos cuerpos intermedios.

***** Segunda implicación
****** Caso de cuerpo base finito
Como la extensión es finita, sólo habrá finitos elementos en ella.
El grupo multiplicativo de cualquier cuerpo es simple, así que tendrá
un elemento primitivo.

****** Caso de cuerpo base infinito
Nos limitamos a probar $K(a,b)$ simple. Si consideramos los subcuerpos
de la forma $K(a+bx)$ para cada $x\in F$, como sólo habrá finitos,
deberán coincidir algunos dos $K(a+bx) = K(a+by)$ con $x\neq y$. 

Entonces:

\[
b = \frac{(a+bx) - (a+by)}{x-y} \in K(a+bx) = K(a,b)
\]

*** 3. Caracterizaciones de extensiones normales
Para $E/K$ extensión finita equivalen:

  1. $E/K$ es una extensión normal. Es cuerpo de descomposición de un
     polinomio.
  2. Para cada $\sigma : E/K \longrightarrow \overline{K}/K$, donde $\overline{K}$ es una clausura algebraica,
     se tiene $\sigma(E) = E$.
  3. Todo polinomio irreducible $f \in K[X]$ con una raíz en $E$ descompone
     en $E$.

**** Demostración
*** 4. Caracterización de la separabilidad
Sea $F/K$ una extensión finita y $\overline{K}$ una clausura algebraica de $K$ conteniendo
a $F$, entonces son equivalentes:

  1. $F/K$ es separable.
  2. $|Hom(F/K,\overline{K}/K)| = [F:K]$.

**** Demostración
Llamamos $[F:K]_S = |Hom(F/K,\overline{K}/K)|$.

***** Caso simple
En un caso simple $K(\alpha) / K$ cada homomorfismo a la clausura queda
determinado por la imagen de $\alpha$, que debe ser a un elemento conjugado.
Tenemos que todas las raíces de $Irr(u,K)$ tienen la misma multiplicidad
$m$, luego si es de grado $n$ habrá $n/m$ raíces distintas.

Se da la igualdad sólo si cada uno de los elementos es distinto,
esto es, si la extensión es separable.

***** Caso compuesto
Procedemos por inducción sobre el grado. Si tomamos un elemento en la
extesión $F \supseteq K(\alpha) \supseteq K$, sabemos:

\[
[F : K]_S = [F : K(\alpha)]_S [K(\alpha) : K]_S
\]

Sabemos que una extensión es separable si lo son sus subextensiones. 
Por hipótesis de inducción $[F : K(\alpha)]_S = [F : K(\alpha)]$ y por el caso base
$[K(\alpha) : K]_S = [K(\alpha) : K]$, por ser ambas separables.
*** 5. Teorema de Artin
Sea $E$ cuerpo y $G \subseteq Aut(E)$ un subgrupo finito, prueba que
$E^G = \{e \in E \mid \forall \sigma \in G: \sigma(e) = e\}$ es un subcuerpo y $[E : E^G] = |G|$.

**** TODO Demostración

*** 6. Lema de independencia de Dedekind
Sea $F/K$ y $E/K$ extensiones de cuerpos, para cada familia no vacía ${\cal F}$ de
elementos de $Hom(F/K,E/K)$ prueba que son equivalentes:

  1. ${\cal F}$ es linealmente independiente en $Hom_K(F,E)$ sobre $E$.
  2. Todos los elementos de ${\cal F}$ son distintos.

**** TODO Demostración

*** 7. Caracterización de cuerpo algebraicamente cerrado
Para $K$ cuerpo, equivalen:

  1. Todo polinomio no constante $f \in K[X]$ tiene al menos una raíz en $K$.
  2. Todo polinomio no constante $f \in K[X]$ descompone en $K$.
  3. Los polinomios no constantes irreducibles en $K[X]$ son de grado 1.
  4. $K$ no tiene extensiones algebraicas propias.

Los cuerpos que lo cumplen son *algebraicamente cerrados*.

**** Demostración
***** Primera implicación
Si el polinomio tiene una raíz, puede descomponerse como $f = (X-\alpha)f'$.
Si $f'$ es constante, tenemos una descomposición de $f$, si no lo es, podemos
descomponerlo a su vez.

***** Segunda implicación
Un polinomio de grado distinto de $1$ descompone linealmente y por tanto
no puede ser irreducible.

***** Tercera implicación
Sea $\alpha \in F/K$ algebraica. Como $Irr(\alpha,K)$ es de grado $1$, $\alpha \in K$. No puede
ser una extensión propia.

***** Cuarta implicación
Si algún polinomio no tuviera ninguna raíz en $K$, entonces él o un
divisor suyo serían irreducibles sin raíz en $K$. Con ellos se genera
una extensión algebraica propia.
*** 8. Teorema de Kronecker
Sea $f \in K[X]$ un polinomio no constante, entonces existe una extensión
$F/K$ en la que $f(X)$ tiene al menos una raíz.

**** Demostración
Podemos descomponer en polinomios irreducibles $f = f_1 f_2\dots f_{n}$ y crear
la extensión siguiente con la inclusión trivial de $K$, que es cuerpo
por ser $(f_1)$ un ideal maximal:

\[
F = \frac{K[X]}{(f_1)} \supset K
\]

Y donde $X + (f_1)$ es raíz del polinomio original por ser raíz de la
inclusión de $f_1$:


\[
f_1(X+(f_1)) = f_1 + (f_1) = 0
\]
*** 9. Extensiones ciclotómicas de Galois
Sea $n$ entero positivo, $K$ un cuerpo y $F/K$ una extensión ciclotómica, cuerpo
de descomposición del polinomio $X^n-1$, prueba que se verifica:

  1. $F/K$ es una extensión de Galois.
  2. $Gal(F/K)$ es isomorfo a un subgrupo del grupo multiplicativo de las
     unidades de $\mathbb{Z}_n$, por lo tanto su orden es un divisor de $\varphi(n)$.

**** TODO Demostración

*** 10. Teorema de Moore
Para cada $p^n$ potencia de primo, existe un cuerpo con $p^n$ elementos;
que es el cuerpo de descomposición de $x^{p^n}-x$ sobre $\mathbb{F}_p$. Además,
todo cuerpo finito de $p^n$ elementos es isomorfo a él.

**** Demostración
Dos cuerpos finitos con el mismo cardinal son isomorfos y que además
existe siempre un cuerpo de $p^n$ elementos.

***** Dos cuerpos finitos del mismo cardinal son isomorfos
Todo subgrupo finito del grupo multiplicativo de un cuerpo es cíclico,
luego $F^\times$ será cíclico de orden $p^n-1$, y sus elementos cumplen el 
polinomio:

\[x^{p^n-1} - 1 = 0\]

Así, $x^{p^n} - x$ tiene exactamente como raíces los $p^n$ elementos de $F$.

***** Existe un cuerpo con ese número de elementos
El polinomio $x^{p^n}-x$ tiene derivada $-1$, y por tanto, sólo raíces
simples. Añadiéndolas a $\mathbb{F}_p$, se tiene ya un cuerpo de descomposición.
Sean $u = u^{p^n}$ y $v = v^{p^n}$:

  - $(u+v)^{p^n} - (u+v) = 0$
  - $(uv)^{p^n} - uv = 0$
  - $(-u)^{p^n} - (-u) = 0$
  - $(u^{-1})^{p^n} - u^{-1} = 0$

*** 11. Teorema 90 de Hilbert
Sea $E/K$ extensión cíclica de grado $n$ con grupo $G = Gal(E/K) = \langle \sigma\rangle$, y
sea $\beta \in E$, prueba que son equivalentes:

  1. $N_{E/K}(\beta) = 1$
  2. Existe $0 \neq \alpha \in E$ tal que $\beta = \frac{\alpha}{\sigma(\alpha)}$.

**** Demostración
***** Primera implicación
Los automorfismos $1,\sigma,\dots,\sigma^n$ son distintos y por tanto linealmente
independientes, luego no es la aplicación cero:

\[
\tau 
= 
1 + \beta\sigma + (\beta \sigma(\beta))\sigma^2 + 
\dots +
(\beta \sigma(\beta)\dots \sigma^{n-2}\beta) \sigma^{n-1}
\]

Y existe $\tau(\theta) \neq 0$. Evaluando $\sigma(\tau(\theta))$ y multiplicando por $\beta$ nos queda
que $\beta \sigma(\tau(\theta)) = \tau(\theta)$.

***** Segunda implicación
Usando que la norma es homomorfismo:

\[
N_{E/K}(\beta) = \frac{N_{E/K}(\alpha)}{N_{E/K}(\sigma(\alpha))} = 1
\]

*** 12. Raíces simples y derivada
Sea $f \in K[X]$ no constante. Equivalen:

  1. Todas las raíces de $f$ son simples.
  2. $f$ y $Df$ son primos relativos.

**** Demostración
***** Primera implicación
En el cuerpo de descomposición de $f$ podemos escribir:

\[Df(X) = a \sum 
(X-\alpha_1)\dots(X-\alpha_{i-1})(X-\alpha_{i+1})\dots(X-\alpha_n)\]

Que claramente no comparte ningún factor primo $(X-\alpha_i)$ de $f$.

***** Segunda implicación
En el cuerpo de descomposición de $f$ podemos tomar una raíz de 
multiplicidad $m > 1$. Y entonces $f = (X-\alpha)^m g$ mientras:

\[ Df = (X-\alpha)^m Dg+ m(X-\alpha)^{m-1}g\]

Por lo que no serían primos relativos en el cuerpo de descomposición,
y por tanto, tampoco en $K$.
# ¿Cómo se traspasa el no ser primos relativos arriba a abajo?

*** 13. Teorema de Lagrange
Sea $K$ un cuerp, $n$ un entero positivo que es primo con la característica
de $K$, si ésta es no nula, y existe una raíz n-ésima primitiva de la unidad
$\xi$ en $K$, prueba que se verifica:

  1. Si $E/K$ es una extensión cíclica de grado $n$, existe $\alpha \in E$ tal que
     $E = K(\alpha)$ e $Irr(\alpha,K) = X^n-a$ para algún $a \in K$.
  2. A la inversa, sea $a \in K$. Si $\alpha$ es una raíz de $X^n-a$, entonces $K(\alpha)/K$
     es una extensión cíclica de grado $d$, con $d\mid n$ y $a^d \in K$.

**** TODO Demostración

*** 14. Automorfismo de Frobenius
Sea $K$ cuerpo de característica $p \neq 0$, prueba que son equivalentes:

  1. Todo polinomio irreducible no constante $f \in K[X]$ tiene todas sus 
     raíces simples.
  2. El endomorfismo de Frobenius es automorfismo.

**** Demostración
***** Primera implicación
Dado $a \in K$. Sea $X^p-a$, con una raíz $\alpha$ en un cuerpo de descomposición.
Tenemos $X^p-a = (X-\alpha)^p$. Como todos los irreducibles tienen raíces
simples, el único irreducible factor del polinomio puede ser $X-\alpha$.

Así $\alpha \in K$ y $a = \alpha^p$, siendo Frobenius sobreyectivo.

***** Segunda implicación
Para que un irreducible tenga raíz múltiple, debe dividir a su derivada,
que debe ser de grado menor, luego debe ser $0$. El polinomio debe ser
entonces de la forma $f(x^p)$ para que al derivarlo se anule.

Cuando Frobenius es automorfismo, podemos escribir:

\[f(x^p) = \sum a_i x^{ip} = \left( \sum \sqrt[p]{a_i} x^i \right)^{p}\]

Lo que contraviene irreducibilidad. Todos los polinomios deben tener
raíces simples.

*** 15. Galois es descomposición de separable
Sea $E/K$ una extensión finita, prueba que son equivalentes:

  1. $E/K$ extensión de Galois.
  2. $E$ cuerpo de descomposición de un polinomio separable sobre $K$.

**** Demostración
***** Primera implicación
Galois es normal y separable. Luego es cuerpo de descomposición de
algún polinomio y este debe ser separable. Si no fuera separable,
tendría algún factor con alguna raíz que no sería separable.

***** Segunda implicación
El cuerpo de descomposición de un polinomio separable debe ser normal
por cuerpo de descomposición y separable porque todos los elementos
que lo generan lo son y la suma y producto de separables es separable.

*** DONE Correspondencia de Galois
Sea $E/K$ una extensión de Galois, y sea $G = Gal(E/K)$. Si $H_1,H_2$ son los
subgrupos de $G$ que corresponden a los cuerpos intermedios $F_1$ y $F_2$ 
respectivamente. Son equivalentes:

  1. $H_1,H_2$ subgrupos de $G$ conjugados.
  2. $F_1,F_2$ cuerpos conjugados con $\sigma \in Gal(E/K)$ tal que $F_1 = \sigma(F_2)$.

Como consecuencia si $F$ es un cuerpo intermedio equivalen:

  1. $F/K$ extensión de Galois.
  2. $Gal(E/F)$ subgrupo normal de $G$.

Además, existe un isomorfismo $Gal(F/K) \cong G/ Gal(E/F)$.

**** Demostración
***** Primera implicación
Sea $H_2 = \sigma^{-1} H_1 \sigma$. Para $x \in F_2$ se tiene $\sigma(x) = h\sigma(x)$, $\sigma(F_2) \subseteq F_1$; 
análogamente se tiene $\sigma^{-1}(F_1) \subseteq F_2$, llegando a $\sigma(F_2) = F_1$.

***** Segunda implicación
Sea $F_1 = \sigma(F_2)$. Para $x\in F_2, h \in H_1$ tenemos $h(\sigma(x)) = \sigma(x)$, luego
$\sigma^{-1}H_1 \sigma \subseteq H_2$. Análogamente $\sigma H_2 \sigma^{-1} \subseteq H_2$, por lo que son conjugados.

***** TODO Corolarios

* Álgebra Conmutativa y Computacional
** 1. Anillos e ideales
*** La categoría CRing
**** Categoría
Consideramos la categoría de los *anillos conmutativos*, que consta de
los anillos conmutativos como objetos y de los homomorfismos de
anillos; respetando suma, producto y unidad; como morfismos.

**** Z es objeto inicial
El anillo $\mathbb{Z}$ es inicial en =CRing=. El homomorfismo único
queda unívocamente definido con $f(1) = 1$ y $f(n) = nf(1)$.

**** Subanillos
*Subanillo*. Subconjunto cerrado para la suma y el producto
conteniendo a 1.

**** Monomorfismos y epimorfismos
En =CRing= coinciden la inyectividad con ser monomorfismo y la
sobreyectividad con ser epimorfismo.

*** Ideales
**** Definición
Un *ideal* es un subconjunto cerrado para la suma y el producto de cualquier 
elemento desde $R$.

**** Retículo de ideales
Los ideales forman un retículo con la suma y la intersección.
Dos ideales son *primos relativos* cuando suman el anillo.

**** Generación de ideales
Llamamos $(X)$ al *ideal generado* por $X$; el menor ideal que 
contiene a $X$:

\[ (X) = \bigcap_{X \subset \alpha \text{, ideal}} \alpha\]

Lo llamamos *ideal finitamente generado* cuando $X$ es finito,
cumpliéndose:

\[ (X) = \left\{ \sum^{finita} r_ix_i \mid r_i \in R, x_i \in X\right\}\]

E *ideal principal* cuando $X$ tiene un sólo elemento.

**** Producto de ideales
Se define para $\alpha, \beta$ ideales como:

\[ \alpha\beta = \left\{ xy \mid x\in\alpha, y\in\beta \right\}\]

**** Ideales primos relativos
Dos ideales son *primos relativos* cuando $\alpha+\beta = R$. Cuando son primos relativos
se cumple que $\alpha\beta = \alpha \cap \beta$.

*** Anillo cociente
**** Definición
Sea $R$ anillo y $\alpha \subset R$ ideal, tomamos la relación de equivalencia
$x \sim y \Leftrightarrow x-y \in \alpha$, para obtener:

\[ R/\alpha = \{x+\alpha \mid x\in R\}\]

**** Ideales del anillo cociente
Los ideales del anillo cociente sobre $\alpha$ están en correspondencia biyectiva
con los ideales que lo contienen, $\beta \supset \alpha$. Son siempre de la forma $\beta/\alpha$.

**** Primer Teorema de Isomorfía
Para cualquier homomorfismo de anillos $f$:

\[ R/\ker(f) \cong \im(f)\]

Y además, los ideales están en correspondencia biyectiva por $f_\ast$ y $f^{-1}$:

\[ \{ \alpha \mid \ker(f)\subset\alpha \} 
\longleftrightarrow 
\{ \beta \mid \beta \subset \im(f)\}\]

***** Demostración
Trivial desde la descomposición de morfismos en una categoría arbitraria.
Además, se comprueba que $f^{-1}$ preserva ideales y que $f_\ast$ preserva ideales en su 
imagen.

*** Ideales primos y maximales
**** Definición
$P$ es ideal *primo* si no es el total y $xy\in P \Rightarrow x \in P \vee y \in P$.
$P$ es ideal *maximal* si $M \neq R$ y es maximal en el retículo de ideales sin $R$.

**** Caracterización de ideales primos y maximales
En relación a su cociente en el anillo:

 - $P$ es primo ssi $R/P$ es un dominio de integridad no trivial.
 - $M$ es maximal ssi $M/P$ es un cuerpo no trivial.

***** Demostración trivial
**** Preservación de ideales primos y maximales
Dado un homomorfismo $f$,

 1. Si $\Pi$ es ideal primo, entonces $f^{-1}(\Pi)$ es ideal primo.
 2. La imagen y preimagen de ideales preserva primos y maximales 
    entre el núcleo y sobre la imagen del anillo.

Como consecuencia los ideales primos (resp. maximales) de un
anillo $R/\alpha$, son los ideales de la forma $\Pi/\alpha$ con $\alpha\subset\Pi$ primo (resp.
maximal).

***** Demostración
*1* es trivial. *2* tenemos que demostrarlo en cuatro pasos:

 - Si $M$ es maximal en $\im f$, entonces $f^{-1}(M)$ es maximal entre los 
   ideales que contienen a $\ker f$.
 - Si $M$ es maximal, entonces $f(M)$ es maximal en $\im f$.
 - Si $\Pi$ es primo en $\im f$, entonces $f^{-1}(\Pi)$ es primo, ya demostrado.
 - Si $\ker f \subset \Pi$ es primo, entonces $f(\Pi)$ es primo en $\im f$.

*** Teorema de Krull
**** Subconjunto multiplicativamente cerrado
Es un subconjunto $S$ con:
 - $1 \in S$
 - $x,y\in S \Rightarrow xy \in S$

**** Teorema de Krull
Sea $\alpha \cap S = \varnothing$, entonces existe un ideal $M \supset \alpha$ tal que $M \cap S = \varnothing$ y maximal respecto
a esta condición. Además, $M$ es un ideal primo.

***** Demostración
Dada una cadena de ideales cumpliendo la condición su unión también la cumple
y es cota de la cadena. Aplicando lema de Zorn obtenemos un maximal.

Para ver que es primo tengamos $xy\in M$, los dos no pueden estar en $S$. Si $x \notin S$;
entonces $xz \notin S$, ya que se tiene $xzy \in M$; tomamos $M + (x) \supset M$, y contravendríamos
la maximalidad de $M$.

**** Corolario al teorema de Krull
Tomando $S=\{1\}$ tenemos que; dado un ideal, existe un ideal maximal que lo contiene.
En particular, todo elemento no unidad está contenido en un ideal maximal,
tomando $S = (x)$.

*** Anillos locales
**** Inclusión en ideales primos
Sean ideales $\alpha_1,\dots,\alpha_n$ y $\pi$ un ideal primo. Si $\bigcap \alpha_i \subset \pi$, entonces

$\exists i: \alpha_i \subset \pi$.

***** Demostración
Supongamos que $\forall i: \alpha_i \nsubseteq \Pi$; entonces tenemos $x_i \in \alpha_i - \Pi$ tales que ninguno
está en $\Pi$, pero su producto debe estar, contraviniendo que sea primo.

**** Inclusión de ideales primos
Sean ideales primos $\pi_1,\dots,\pi_n$, (salvo quizá 2) y $\alpha$ un ideal. Si $\alpha \subset \bigcup \pi_i$, entonces,

$\exists i: \alpha \subset \pi_i$.

***** Demostración
En el caso $n=2$, supongamos $\alpha \subset \pi_1 \cup \pi_2$; y tomemos $x \in \alpha, x\in\pi_1$, $y\in\alpha, y\in\pi_2$.
Entonces tendría $x+y \in \alpha$, pero no estaría en $\pi_1 \cup \pi_2$. Nótese que no usamos
todavía que sean primos.

En el caso inductivo, aplico la hipótesis de inducción para obtener, para cada $k$:

\[\exists x_k \in \alpha : x_k \notin \bigcup_{i\neq k} \pi_i\]

Luego debe tenerse $x_k \in \alpha_k$; sea ahora $x = x_1x_2\dots x_{n-1}+x_n \in \alpha$; 
luego $\exists r: x\in\alpha_r$. Si $r=n$, tendríamos $x_1x_2\dots x_{n-1} \in \alpha_r$, y por primalidad debería
estar alguno; si no, tendríamos $x_n \in \alpha_r$.

**** Definición de anillo local
Un *anillo local* es aquel con un único ideal maximal. A $R/M$ se le llama 
*cuerpo residual*.

**** Caracterización de anillos locales
Un anillo $R$ es local ssi $\{x\in R \mid x \text{ no unidad}\}$ es un ideal.

Sea $M$ ideal propio:

 - $R$ es local con maximal $M$ ssi $R-M \subset {\cal U}(R)$.
 - Si $M$ es maximal y $\{1+x \mid x\in M\}\subset {\cal U}(R)$ entonces es $R$ local y $M$ su maximal.

***** Demostración
1. Una no unidad debe estar contenida en el único maximal que hay, que no contiene
   a las unidades y además es ideal.
   Por otro lado, por Krull, el ideal de las no unidades debería estar contenido
   en un ideal maximal que tampoco tuviera unidades, luego debe ser él mismo.
2. Por la caracterización anterior tenemos una implicación. Sea $R-M \subset {\cal U}(R)$,
   si tenemos $M \not\subset \beta$, entonces tendríamos un $x \in \beta,x \notin M$, luego $x \in {\cal U}(R)$
   y entonces $\beta = R$. Si tenemos otro $M'$ maximal, entonces $\exists x\in M': x \notin M$,
   pero eso me vuelve a dar $M' = R$. Luego $M$ es el único ideal y maximal.
3. Por la caracterización anterior tenemos una implicación. Sea $x \notin R-M$,
   tenemos por maximalidad: $rx+m = 1$, luego $rx = 1-m \in {\cal U}(R)$.
   En conclusión, $R-M \subset {\cal U}(R)$ y es local.

*** Radicales
**** Nilradical
Sus elementos se llaman *nilpotentes*:

\[\operatorname{Nil}(R) = \{x \in R \mid \exists n: x^n = 0\}\]

El nilradical es un ideal.

**** Anillo reducido
Un anillo es *reducido* si $\operatorname{Nil}(R) = 0$. Los dominios de integridad son reducidos. 
Además, podemos reducir un anillo dividiendo por su nilradical $R/\operatorname{Nil}(R)$.

**** Espectro
El *espectro* de un anillo R es la intersección de sus ideales primos:

\[\spec(R) = \{\pi\in R \mid \pi \text{ es un ideal primo}\}\]

**** Caracterización del nilradical
El nilradical de $R$ es la intersección de los ideales del espectro:

\[ \operatorname{Nil}(R) = \bigcap_{\pi \in \operatorname{Spec}(R)} \pi\]

***** Demostración
Sea $x^n = 0$, entonces $x^n \in \pi, \forall \pi \in \operatorname{Spec}(R)$; y, por primalidad, $x \in \pi$.
Sea $x \notin \operatorname{Nil}(R)$, entonces $S = \{1,x,x^2,\dots\}$ es multiplicativamente cerrado con
$S \cap \operatorname{Nil}(R) = \varnothing$. Por Krull, tenemos un $\pi$ tal que $\pi \cap S = \varnothing$.

**** Radical de un ideal
Se define como:

\[\sqrt{\alpha} = \{x \in R \mid \exists n \geq 1 : x^n \in \alpha\}\]

Tenemos que $\operatorname{Nil}(R/\alpha) = \sqrt{\alpha}/\alpha$. Cuando $\alpha = \sqrt{\alpha}$ decimos que es *ideal radical*.
Se caracteriza como:

\[\sqrt{\alpha} = \bigcap_{\alpha \subset \pi \in Spec(R)} \pi\]

***** Demostración
Tenemos claramente $\pi^{-1}(\operatorname{Nil}(R/\alpha)) = \sqrt{\alpha}$, pero entonces:

\[\sqrt{\alpha} = 
\pi^{-1}(\operatorname{Nil}(R/\alpha))=
\pi^{-1} \left( 
\bigcap_{\alpha \subset \pi \in \operatorname{Spec}(R/\alpha)} \pi/\alpha 
\right) = \bigcap_{\alpha \subset \pi \in \operatorname{Spec}(R)} \pi\]

**** Radical de Jacobson
Se define el *radical de Jacobson* como:

\[{\cal J}(R) = \bigcap_{{\cal M} \text{ maximal}} {\cal M}\]

Tenemos que $x \in {\cal J}(R)$ ssi $1-xy \in U(R)$ para cualquier $y$.

***** Demostración
Un elemento $1-xy$ para $x \in {\cal J}(R)$ no puede estar en ningún ideal maximal, porque
estaría entonces el $1$. Por corolario de Krull, debe ser unidad.

Supongamos $x \notin M$, entonces $(x) + M = R$, y por tanto $1-xy \in M$. Pero un maximal
no puede contener una unidad.

*** Ideales residuales y anulador
**** Definición
Definimos el *ideal residual* (a veces llamado *cociente*) de dos ideales como:

\[ (\alpha : \beta) = \{x\in R\mid x\beta \subset\alpha\}\]

**** Anulador
\[\operatorname{Ann}(\beta) = \{x \in R \mid x\beta = 0\} = (0 : \beta)\]

*** Ideales contraídos y extendidos
**** Ideal extendido
Dado un homomorfismo $f : R \longrightarrow S$ llamamos *ideal extendido* de $\alpha$ al ideal:

\[ \alpha^e = (f(\alpha)) = \left\{ \sum s_i f(x_i) \mid s_i \in S, x_i \in \alpha\right\}\]

**** Ideal contraído
Dado un homomorfismo $f$ llamamos *ideal contraído* de $\beta$ al ideal:

\[ \beta^c = f(\beta) \]

**** Biyección entre ideales
Para $f : S \longrightarrow R$ homomorfismo y $\alpha,\beta$ ideales:

  1. $\alpha \subset \alpha^e^c$, y $\beta \supset \beta^c^e$.
  2. $\alpha^e = \alpha^e^c^e$, y $\beta^c = \beta^c^e^c$
  3. Hay una biyección con $(-)^e,(-)^c$ entre ideales contraídos y extendidos, que 
     además pueden escribirse como $\{\alpha \subset R \mid \alpha = \alpha^e^c\}$
     y $\{\beta \subset S \mid \beta = \beta^c^e\}$.

***** Demostración
Pueden escribirse así porque si tengo $\beta = \alpha^e$, entonces $\beta^c^e = \alpha^e^c^e = \alpha^e = \beta$. La biyección
es trivial desde la definición y las proposiciones anteriores.

*** Producto directo de anillos
**** Definición
Para $R_1,R_2,\dots,R_n$ tomamos como su producto directo a:

\[R_1\times \dots \times R_n = \prod_{i=1}^n R_i\]

con las operaciones definidas componente a componente.

**** Proyecciones e inclusiones
Las *proyecciones*, $p_k$, a cualquier factor son homomorfismos.
Las *inclusiones*, $u_k$, *no* son homomorfismos, ya que no respetan
el uno del anillo, que en este caso es $(1,\dots,1)$. Cumplen además:

 - $p_k \circ u_k = \delta_{kj}id$
 - $\sum u_i \circ p_i = id$
 - $\ker(p_j) = \sum \im(u_j)$

**** Propiedad universal
El producto con las proyecciones es el *producto categórico* de la
categoría de los anillos:

\[ \begin{tikzcd}
& & S \dar[dashed]{\exists!} \arrow[bend right]{ddll} \arrow[bend right]{ddl} \arrow[bend left]{ddr} \arrow[bend left]{ddrr} & &\\
& & \prod R \arrow{dll}[swap]{\pi_1} \arrow{dl}{\pi_2} \arrow{dr}[swap]{\pi_3} \arrow{drr} & & \\
R_1 & R_2 &  & R_3 & \dots
\end{tikzcd} \]

**** Teorema Chino del Resto
En la situación la propiedad universal sobre el cociente por unos
ideales $\alpha_1,\dots,\alpha_n$:

\[ \begin{tikzcd}
\prod_{i=1}^n R/\alpha_i \rar{\pi_i} &  R/\alpha_i \\
R \uar{\exists! f} \urar{p_i}
\end{tikzcd} \]

Tenemos que:

 1. Si los $\alpha_i$ son primos entre sí, $\prod \alpha_i = \bigcap \alpha_i$.
 2. La $f$ es sobreyectiva ssi los $\alpha_i$ son primos entre sí.
 3. La $f$ es inyectiva ssi $\bigcap \alpha_i = 0$. De hecho, $\ker(f) = \bigcap \alpha_i$.

***** Demostración
1. El caso $n=2$ es conocido. En el caso $n>2$, aplicamos la hipótesis
   de inducción a $\alpha_1\alpha_2\dots\alpha_{n-1}$ y a $\alpha_n$, que se demuestran primos relativos.
2. Doble implicación:
   - Si $f$ es sobreyectiva, existe $f(x) = (1,0,0,\dots)$, que me da $x \in \alpha_i$
     para cualquier $i$, y además, $x-1 \in \alpha_1$; luego $1 \in \alpha_i+\alpha_1$.
   - Si son primos relativos, existen $x_i + y_i = 1$ con $x_i \in \alpha_1$, $y_i \in \alpha_i$.
     $y = y_2y_3\dots y_n = 1 + x$, con $x \in \alpha_1$; luego $y \equiv_{\alpha_1} 1$ pero $y \equiv_{\alpha_i} 0$; luego
     puedo crear una base del anillo.
3. Trivial.

** 2. Bases de Gröbner
*** R-álgebras
**** R-módulo
Dado $R$ anillo. Un *R-módulo* (izquierdo) es un grupo abeliano $M$ junto
a una operación $\cdot : (R,M) \longrightarrow M$ verificando:

  - $r(x+y) = rx+ry$
  - $(r+s)x = rx+sx$
  - $r(sx) = (rs)x$
  - $1x = x$

**** R-álgebras
Una *R-álgebra*, $S$ es un anillo con estructura de R-módulo, tal que:

\[\forall r\in R, x,y\in S:\; (rx)y = r(xy) = x(ry)\]

**** Homomorfismo de estructura
Equivalentemente, una R-álgebra es un anillo $S$ junto a un *homomorfismo 
de estructura* $\lambda : R \longrightarrow S$. 

***** Equivalencia
Nótese que puedo pasar de una a otra definición tomando $\lambda(r) = r1$.

**** Homomorfismos de R-álgebras
Un homormorfismo de R-álgebras $f : S_1 \longrightarrow S_2$ es un homomorfismo de anillos
que sea también homomorfismo de R-módulos.

\[ f(rs) = rf(s) \]

**** Anillo de polinomios
Definimos el anillo de polinomios en varias variables recursivamente:

\[ R[X_1,X_2,\dots,X_n] = R[X_1,X_2,\dots,X_{n-1}][X_n] \]

Y forma una R-álgebra con la inclusión desde $R$.

**** Propiedad universal del anillo de polinomios
Sea $S$ anillo y $f : R \longrightarrow S$ homomorfismo de anillos. Sean $s_1,\dots,s_n \in S$
elementos arbitrarios; entonces existe un único homomorfismo de 
R-álgebras $f_{s_1,\dots,s_n} : R[X_1,\dots,X_n] \longrightarrow S$ tal que:

\[ \begin{tikzcd}
R \rar[hook]{i} \drar[swap]{f} & R[X_1,X_2,\dots,X_n] \dar[dashed]{f_{s_1,\dots,s_n}} \\
  & S
\end{tikzcd} \]

Llevando $f(X_i) = s_i$.

***** TODO Demostración

**** R-álgebras finitamente generadas
Una R-álgebra $S$ es finitamente generada si existe un epimorfismo de
R-álgebras $f : R[X_1,\dots,X_n] \longrightarrow S$.

*** Órdenes monomiales
**** Representación recursiva de un polinomio
Llamamos representación recursiva a la siguiente:

\[
F = \sum_{j=0}^t F_j X^j_n
\]

donde $F_j \in K[X_1,\dots,X_{n-1}]$. Nótese que es la representación natural una
vez asumimos la definición recursiva del anillo de polinomios.

**** Representación distributiva de un polinomio
Llamamos representación distributiva a la siguiente:

\[ p = \sum a_{(\alpha_1,\dots,\alpha_n)} 
X_1^{\alpha_1} X_2^{\alpha_2} \dots X_n^{\alpha_n} \]

Si escribimos los monomios como $X^{\alpha}$ para cada $\alpha \in \mathbb{N}^n$, nos
queda:

\[p = \sum_{\alpha \in \mathbb{N}^n} a_\alpha X^\alpha\]

**** Base de los polinomios
Los monomios forman una K-base vectorial del espacio de polinomios:

\[\{ X^\alpha \mid \alpha \in \mathbb{N}^n \}\]

***** Demostración
Son claramente sistema de generadores y, por definición, un polinomio
con algún coeficiente no nulo no puede ser nunca nulo. Nótese que puede
haber cuerpos donde los polinomios evalúen a cero en cualquier punto
del cuerpo, como $X(X-1)$ en $\mathbb{F}_2$, pero ese polinomio no se considera 
nulo.

**** Grado de un monomio
El grado de un monomio $X^\alpha$ con $\alpha \in \mathbb{N}^n$ es la suma:

\[gr(X^\alpha) = \sum^n_{i=1} \alpha_i\]

**** Órdenes compatibles
Un orden $\leq$ en $\mathbb{N}^n$ es compatible si:

\[\alpha \leq \beta \Longrightarrow \alpha + \gamma \geq \beta + \gamma\]

**** Órdenes monótonos
Un orden $\leq$ es monótono si:

\[ 0 \leq \alpha \]

**** Órdenes monomiales
Un orden monomial es compatible, monótono y total.

**** Orden lexicográfico
Definimos $\alpha \geq_{lex} \beta$ cuando para el primer $\alpha_i \neq \beta_i$, se tiene $\alpha_i \geq \beta_i$.

**** Orden lexicográfico graduado
Definimos $\alpha \geq_{grlex} \beta$ cuando $\sum \alpha > \sum \beta$ ó se da la igualdad
y se tiene $\alpha \geq_{lex} \beta$.

**** Orden lexicográfico graduado inverso
Definimos $\alpha \geq_{invgrlex} \beta$ cuando $\sum \alpha > \sum \beta$ ó se da la igualdad
y para el primer $\alpha_i \neq \beta_i$ a la derecha, se tiene $\alpha_i < \beta_i$.

**** Preórdenes
Un preorden es una relación binaria transitiva y reflexiva. 
Equivalentemente, es un orden sin la antisimetría.

**** Relación de equivalencia en preódenes
Dado un preorden $\sqsubseteq$, se define la relación de equivalencia $x \equiv y$,
que se tiene cuando $x \sqsubseteq y \wedge y \sqsubseteq x$.

**** Producto lexicográfico de preórdenes
Definimos el producto lexicográfico de dos preórdenes $\sqsubseteq_1,\sqsubseteq_2$
como:

\[x \sqsubseteq_{12} y = \left\{
\begin{array}{l} 
x \sqsubseteq_1 y \wedge y \not\sqsubseteq_1 x \\ 
\text{  ó} \\
x \equiv_1 y \wedge x \sqsubseteq_2 y
\end{array}\right.\]

**** Propiedades del producto
El producto de preórdenes cumple:

 1. $\sqsubseteq_{12}$ es un preorden.
 2. $\sqsubseteq_2$ orden $\Rightarrow$ $\sqsubseteq_{12}$ orden
 3. $\sqsubseteq_1,\sqsubseteq_2$ totales $\Rightarrow$ $\sqsubseteq_{12}$ total
 4. $\sqsubseteq_1,\sqsubseteq_2$ compatible $\Rightarrow$ $\sqsubseteq_{12}$ compatible
 5. $\sqsubseteq_1,\sqsubseteq_2$ monótono $\Rightarrow$ $\sqsubseteq_{12}$ monótono

***** Demostración
****** Punto 1
Es reflexivo trivialmente. La transitividad se obtiene analizando 
por casos.

****** Punto 2
Cuando $x \equiv_{12} y$, se tiene $x \equiv_1 y$ y por tanto $x \equiv_2 y$; lo que llevaría
a $x = y$.

****** Punto 3
Si ambos son totales, suponemos s.p.g. que $x \sqsubseteq_1 y$. Si no tuviéramos
que $y \sqsubseteq_1 x$, entonces $x \equiv_1 y$ y como son totales, podemos suponer s.p.g
que $x \sqsubseteq_2 y$, llgando a $x \sqsubseteq_{12} y$.

****** Punto 4
# No parece obvio si no son órdenes. Además, tenemos definido lo que
# es ser compatible o monótono sólo para órdenes.

****** Punto 5
Tenemos $0 \sqsubseteq_1 x$; si tuviéramos $x \sqsubseteq_1 0$, entonces $x \equiv_1 0$; pero como
sabemos que $0 \sqsubseteq_2 x$, tenemos finalmente $0 \sqsubseteq_{12} x$.

**** Los órdenes son monomiales
Los órdenes $\leq_{lex},\leq_{grlex},\leq_{invgrlex}$ son monomiales.

***** Demostración
****** El orden lexicográfico es monomial
Una forma de definir el orden lexicográfico es con el signo del primer
elemento de la resta. Sabemos que es total. La monotonía y la 
compatibilidad se tienen por:

\[(\alpha+\gamma)-(\beta+\gamma) = (\alpha-\beta)\]

Tenemos que $\alpha - 0 = \alpha$, positivo.

****** El resto de órdenes son monomiales
Simplemente notando que el grado es un preorden y que son [[*Propiedades del producto][producto]]
de preorden con el lexicográfico o con un lexicográfico inverso.

*** Lema de Dickson
**** Lema de Dickson
Para $S \subseteq \mathbb{N}^n$ no vacío, existe $G \subseteq S$ finito tal que $S \subseteq G + \mathbb{N}^n$.

***** Demostración
****** Caso base
Cuando $n=1$, como los naturales están bien ordenados, podemos tomar
el mínimo

****** Caso inductivo
Tomamos un $y \in S$, y tenemos dos casos, o bien $x \in \{y\} + \mathbb{N}^n$, o bien
se tiene $x \in S_{i|j}$ para $j < y_i$. Donde definimos:

\[
S_{i|j} 
= 
\{ x \in S \mid x_i = j\}
\]

Y una familia de conjuntos:

\[
S_{i|j}'
=
\{ 
x \in \mathbb{N}^n
\mid
x_i=0, (x_1,\dots,j,\dots,x_n) \in S
\}
\]

Que por hipótesis de inducción dejando nula a cada paso una de las
coordenadas, dan lugar a $G_{i|j}' \subseteq S_{i|j}'$ finito con $S'_{i|j} = G_{i|j}'+\mathbb{N}^{n-1}$.

\[
G_{i|j} = 
\{x \in S_{i|j} \mid (x_1,\dots,0,\dots,x_n) \in G'_{ij} \}
\]

Sea ahora $x \in S_{i|j}$. Si hacemos un cero en $i$, se tiene 
$(x_1,\dots,0,\dots,x_n) \in S'_{i|j} \subseteq G_{i|j}'+ \mathbb{N}^{n-1}$. Luego

\[\begin{aligned}
(x_1,\dots,0,\dots,x_n) &= z + \alpha \\
(x_1,\dots,j,\dots,x_n) &= (z_1,\dots,j,\dots,z_n) + (\alpha_1,\dots,0,\dots,\alpha_n)
\end{aligned}\]

Por lo tanto, $S_{i|j} \subseteq G_{i|j} + \mathbb{N}^{n}$; y tenemos finalmente $S \subseteq G + \mathbb{N}^n$ si
definimos:

\[G = \{y\} \cup \bigcup_{i,j<y_i} G_{i|j}\]

Tenemos que cada uno de ellos es finito.

**** Orden monomial es buen orden
Todo orden monomial en $\mathbb{N}^n$ es buen orden.

***** Demostración
Por Dickson, cualquier subconjunto tiene un $G$ finito con $S \subseteq G + \mathbb{N}^n$.
El mínimo de $G$ existe por finitud y ser orden total. Es el mínimo de
$S$ porque cualquier otro $s \in S$ cumple $s = g + \gamma$ para $g \in G$, lo que lleva
por monotonía y compatibilidad, a $s \geq g$.

**** Monoideales
Un subconjunto $E \subseteq \mathbb{N}^n$ es monoideal cuando $E = E + \mathbb{N}^n$.

**** Sistemas de generadores
Si $E$ es monoideal, existe $G \subset E$ finito con $E = G + \mathbb{N}^n$.
Llamamos a $G$ sistema de generadores de $E$.

***** Demostración
Por Dickson tenemos $E \subset G + \mathbb{N}^n$, luego $E = E + \mathbb{N}^n = G + \mathbb{N}^n$. 

**** Sistema de generadores minimal
Un sistema de generadores es minimal si ningún subconjunto
suyo es sistema de generadores.

**** Unicidad del sistema de generadores minimal
El sistema de generadores minimal de un monoideal es único.

***** Demostración
Supongamos que hubiera dos $G,G'$, con $\beta \in G' \setminus G$. Entonces tendría una
representación con $g \in G, g' \in G', \gamma \neq 0$ como:

\[
\beta = g + \gamma = g' + \delta + \gamma
\]

Con lo cual, $\beta \in G'\setminus \{\beta\} + \mathbb{N}^n$, contraviniendo minimalidad.

*** División de polinomios
**** Diagrama de Newton
El conjunto de exponentes para un polinomio $p = \sum a_\alpha x^\alpha$:

\[N(p) = \{\alpha\in\mathbb{N}^n \mid a_\alpha \neq 0\}\]

**** Exponente
El exponente de un polinomio, fijado un orden monomial, es el máximo
exponente de su diagrama:

\[exp(p) = \max \{\alpha\in\mathbb{N}^n \mid a_\alpha \neq 0\} \]

**** Grado total
Definimos el grado total, fijado un orden monomial, como el máximo
grado de los exponentes:

\[Grtot(p) = \max \{gr(\alpha) \mid a_\alpha \neq 0\} \]

**** Término líder
Llamamos término líder al que aporta el exponente, $a_{Exp(p)}X^{Exp(p)}$.
Su coeficiente líder es $a_{Exp(p)}$ y su monomio líder, $X^{Exp(p)}$.

**** Propiedades del exponente
Dados $F,G \in K[X_1,\dots,X_n]$ no nulos: 

  1. $exp(FG) = exp(F) + exp(G)$.
  2. $exp(F+G) \leq \max\{exp(F),exp(G)\}$.
  3. Si $exp(F) < exp(G)$; entonces $exp(F+G) = exp(G)$.

***** Demostración
****** Punto 1
Primero notamos que si estamos en un cuerpo, el producto de dos
polinomios tendrá en su diagrama de Newton a la suma de cualesquiera
exponentes de ambos polinomios. Supongamos la suma máxima $\gamma + \delta$, y
la suma de los máximos $\alpha+\beta$. Usamos que son máximos y orden monomial
para tener:

\[\alpha + \beta \geq \gamma + \delta\]

****** Punto 2
Si un exponente no aparece en $F$ ni en $G$, tendrá coeficiente nulo
también en $F+G$.

****** Punto 3
La suma tendrá como mucho los exponentes de $F$ y de $G$. Pero además,
conserva los exponentes que sólo estuvieran en uno de los dos con los
coeficientes intactos.

En el fondo, parte sólo de la observación de que son K-espacios 
vectoriales y tienen de base a los distintos monomios.

**** Partición de generadores
Dada una lista de elementos $a_1,\dots,a_k$, tenemos una partición que
definimos inductivamente como:

  1. Los elementos que genera el primer generador: 

     \[\Delta^1 = a_1 + \mathbb{N}^n\]

  2. Los elementos nuevos que aporta cada nuevo generador:

     \[\Delta^i = (a_i + \mathbb{N}^n) \setminus \bigcup_{j < i} \Delta^j \]

  3. Todos los demás elementos

     \[ \overline{\Delta} = \mathbb{N}^n \setminus \bigcup_{j \leq k} \Delta^j\]

**** Teorema de la división
Dado un orden monomial y una lista de polinomios $G_i$; consideramos la
partición $\Delta_1,\dots,\overline{\Delta}$ dada por los exponentes $exp(G_i)$. Tenemos que para
cada $F \in K[X_1,\dots,X_n]$, existen $Q_1,\dots,Q_t,R$ únicos tales:

  1. $F = Q_1G_1 + \dots + Q_tG_t + R$.
  2. $R = 0$ ó $N(R) \subseteq \overline\Delta$.
  3. $exp(G_i) + N(Q_i) \subseteq \Delta^i$.

***** Demostración
****** Caso base
Aplicamos inducción a $exp(F)$ aprovechando el [[*Orden monomial es buen orden][buen orden]]. Sea 
$exp(F) = (0,\dots,0)$.

******* Aparece en algún elemento de la partición
Si $exp(F) \in \Delta^i$, entonces forzosamente $exp(G_i)=0$. Entonces tomamos
$Q_i = {F}/{G_i}$, y $Q_j=0$ para $j \neq i$.

******* Sólo aparece en el resto de la partición
Simplemente tomamos $R = F$.

****** Caso inductivo
Sabiendo que se tiene el resultado para todo $G$ con $exp(G) < exp(F)$,
tenemos de nuevo dos casos.

******* Aparece en algún elemento de la partición
Si $exp(F) \in \Delta^i$, entonces $exp(F) = exp(G) + \gamma$. Tomando $H=X^\gamma G$,
aplicamos inducción sobre:

\[F - \frac{cl(F)}{cl(H)} H 
=
F'
= 
\sum Q'_iG_i + R'
\]

Pero si tomamos $Q_i = Q_i' + \frac{cl(F)}{cl(H)} X^\gamma$ y $Q_j = Q_j'$ para todos los demás:

\[F = \sum Q_i G_i + R\]

******* Sólo aparece en el resto de la partición
Aplicamos hipótesis de inducción sobre:

\[F-tl(F) = F' = \sum Q_i'G_i + R'\]

Entonces tomamos $R = R' + tl(F)$ y se tiene:

\[F = \sum Q_i'G_i + R\]

**** Ejemplo de división
Dividimos $F = X^4Y^2+X^2Y^3Z-2XY^2Z^3-3X^2YZ^4$ entre los polinomios:

  - $G_1 = X^3Y-2X^2Z^2$
  - $G_2 = X^2Y^3+XZ^3$
  - $G_3 = XY^2Z - X^2YZ - 3XYZ^2$

Usando el orden lexicográfico.

***** Exponentes
Con el orden dado, tenemos exponentes:

  - $exp(G_1) = (3,1,0)$
  - $exp(G_2) = (2,3,0)$
  - $exp(G_3) = (2,1,1)$

Con ellos creamos las particiones $\Delta_i$.

***** Desarrollo
A cada paso tomamos el exponente mayor, lo encuadramos en un subconjunto
de la partición y dividimos para el siguiente elemento.

\[F = X^4Y^2+X^2Y^3Z-2XY^2Z^3-3X^2YZ^4\]

Tenemos $(4,2,0) \in \Delta_1$, así que restamos $XYG_1$:

\[F = 2X^3YZ^2+X^2Y^3Z-2XY^2Z^3-3X^2YZ^4\]

Tenemos $(3,1,2) \in \Delta_1$, así que restamos $2Z^2G_1$:

\[F = 4X^2Z^4+X^2Y^3Z-2XY^2Z^3-3X^2YZ^4\]

Tenemos $(2,3,1) \in \Delta_2$, así que restamos $ZG_2$:

\[F = 4X^2Z^4 - 2XY^2Z^3 - 3X^2YZ^4 - XZ^4\]

Tenemos $(2,1,4) \in \Delta_3$, así que restamos $3Z^3G_3$:

\[F = 4X^2Z^4 - 2XY^2Z^3 - XZ^4 - 3XY^2Z^4 + 9XYZ^5\]

Tenemos $(2,0,4) \in \overline\Delta$, así que tomamos lo demás como resto. Nos acabará
quedando que:

\[R = 4X^2Z^4 - 2XY^2Z^3 - XZ^4 - 3XY^2Z^4 + 9XYZ^5\]

Por lo tanto:

\[F = (XY+2Z^2)G_1 + ZG_2 + 3Z^3G_3 + R\]

***** Cálculo en Sage
Calculamos el resto de la división en sage. Nótese cómo se ve afectado
por el orden de los polinomios que escojamos para la división.

#+BEGIN_SRC sage
  R.<x,y,z> = PolynomialRing(QQ, 3, 'xyz', order='lex')
  f = x^4*y^2 + x^2*y^3*z - 2*x*y^2*z^3 - 3*x^2*y*z^4
  g1 = x^3*y - 2*x^2*z^2
  g2 = x^2*y^3 + x*z^3
  g3 = x*y^2*z - x^2*y*z - 3*x*y*z^2
  f.reduce(Ideal([g1])).reduce(Ideal([g2])).reduce(Ideal([g3]))
  f.reduce(Ideal([g3])).reduce(Ideal([g2])).reduce(Ideal([g1]))
#+END_SRC

#+RESULTS:
: 4*x^2*z^4 - 3*x*y^2*z^4 - 2*x*y^2*z^3 + 9*x*y*z^5 - x*z^4
: x^2*y^3*z - 3*x^2*y*z^4 + 4*x^2*z^4 - 2*x*y^2*z^3

*** Ideales monomiales
**** Ideales monomiales
Un ideal es monomial si está generado por monomios. Es decir, si es de la 
forma:

\[ I = (X^\alpha \mid \alpha\in A)\]

Para algún $A \subset \mathbb{N}^n$.

**** Pertenencia a ideal monomial
Si $X^\beta \in (X^\alpha \mid \alpha\in A)$ es de la forma: $X^\beta = FX^\alpha$.

***** Demostración
Los monomios forman una K-base del espacio. Como:

\[X^\beta = \sum F_iX^\alpha\]

Todo monomio de la expresión de la derecha es divisible por algún $X^\alpha$,
y en particular, $X^\beta$ debe serlo.

**** Monomios en ideal monomial
Sea $I = (X^\alpha \mid \alpha\in A)$ monomial, equivalen:

 1. $F \in I$.
 2. Todo monomio de $F$ está en $I$.
 3. $F$ es combinación lineal de monomios de $I$.

Y además, si para cualquier polinomio todos sus monomios están en
el ideal, es monomial.

***** Demostración
Los monomios forman una K-base del espacio. Como:

\[F = \sum F_iX^\alpha\]

Todo monomio de $F$ debe ser múltiplo de algún $X^\alpha$.

El resto de implicaciones son triviales. Nótese que podemos escribir
el ideal como $(X^\alpha \mid \alpha \in Exp(I))$.

**** Exponente de un ideal
Dado un ideal $I$ no nulo, definimos su exponente como el subconjunto:

\[Exp(I) = \{Exp(F) \mid 0\neq F \in I\} \subseteq \mathbb{N}^n\]

**** El exponente es monoideal
$Exp(I)$ es un monoideal de $\mathbb{N}^n$.

***** Demostración
Sea $F \in I$, tenemos $X^\alpha F \in I$ para cualquier $\alpha$ y:

\[exp(X^\alpha F) = \alpha + exp(F)\]

Gracias a que los órdenes son compatibles.

**** Lema de Dickson para ideales monomiales
Todo ideal monomial tiene un sistema de generadores finito y formado
por monomios.

***** Demostración
Como $Exp(I)$ es [[*Monoideales][monoideal]], tiene [[*Sistemas de generadores][sistema de generadores]] $Exp(I) = G + \mathbb{N}^n$.
Dado un exponente $\alpha \in Exp(I)$, [[*Monomios en ideal monomial][tenemos]] $X^\alpha \in I$, luego tomamos como sistema
de generadores:

\[ (X^\alpha \mid \alpha \in G) \]

Dado cualquier $F \in I$, sus monomios estarán en $I$ y serán múltiplo
de ellos.

**** Corolario de generación de ideales
Sean $I,J \subseteq K[X_1,\dots,X_n]$ ideales monomiales:

\[I=J \iff Exp(I)=Exp(J)\]

***** Demostración
Si tienen el mismo exponente, tienen el mismo generador.

**** Unicidad del sistema de generadores minimal
Sea $I$ monomial no nulo. Existe un único sistema de generadores minimal
formado por monomios, es decir, ningún subconjunto suyo es generador.

***** Demostración
Dado $G$ el [[*Unicidad del sistema de generadores minimal][único]] sistema generador minimal de $Exp(I)$. Entonces, sus
monomios generan al ideal y si:

\[H \subseteq (X^\alpha\mid \alpha \in G)\]

genera al ideal, en particular se tendría $Exp(I) = H + \mathbb{N}^n$, contraviniendo
minimalidad.

**** Otros sistemas de generadores
Sea $G = \{\alpha_1,\dots,\alpha_n\}$ sistema de generadores de $Exp(I)$. Si $exp(F_i)=\alpha_i$,
entonces $\{F_1,\dots,F_n\}$ es sistema de generadores de $I$.

***** Demostración
Para $F\in I$, por [[*Teorema de la división][división]] tenemos:

\[F = \sum Q_iF_i + R\]

Como $R\in I$, $exp(R) \in Exp(I)$ y debe tenerse $R = 0$.

*** Bases de Gröbner
**** Bases de Gröbner
Sea $I \subseteq K[X_1,\dots,X_n]$ un ideal no nulo. Una base de Gröbner es un conjunto
$\mathbb{G} = \{G_1,\dots,G_n\} \subseteq I$ cumpliendo $Exp(I) = \{exp(G_1),\dots,exp(G_n)\} + \mathbb{N}^n$.

**** Propiedades de bases de Gröbner
Las bases de Gröbner en $K[X_1,\dots,X_n]$ cumplen:

  1. Todo ideal no nulo tiene una base de Gröbner.
  2. Toda base de Gröbner de un ideal es base de generadores del ideal.
  3. *Teorema de la base de Hilbert*: todo ideal es finitamente generado.

***** Demostración 
****** Punto 1
Sabemos que $Exp(I)$ es [[*El exponente es monoideal][monoideal]] y por tanto tiene un sistema de
[[*Sistemas de generadores][generadores]]. Existen entonces polinomios cumpliendo:

\[Exp(I) = \{exp(G_1),\dots,exp(G_n)\} + \mathbb{N}^n\]

Que forman una base de Gröbner

****** Punto 2
Por el algoritmo de la [[*Teorema de la división][división]], tenemos que todo polinomio del ideal
se divide entre ellos dando un resto tal que $exp(R) \in \overline{\Delta} \cap Exp(I) = \varnothing$.
Por tanto, $R=0$.

****** Punto 3
Todo ideal está generado por su base de Gröbner, que es finita.

**** Resto en bases de Gröbner
Sea $I$ ideal con bases de Gröbner $\mathbb{G},\mathbb{G}'$. Para $F \in K[X_1,\dots,X_n]$:

\[R(F;\mathbb{G}) = R(F;\mathbb{G}')\]

***** Demostración
Tenemos que, al coincidir los exponentes:

\[Exp(I) = \bigcup_{i=1}^t \Delta^i\]

Por lo tanto, $\overline{\Delta} = \overline{\Delta}'$, y tenemos ${\cal N}(R-R') \subseteq {\cal N}(R) \cup {\cal N}(R') \subseteq \overline{\Delta}$.
Pero como $R-R' \in I$, y tenemos $exp(R-R') \in Exp(I)$, debe ser nulo.

**** Caracterización de bases de Gröbner
Sea $I$ ideal no nulo, equivalen:

  1. $\mathbb{G}$ es base de Gröbner de $I$.
  2. $R(F,\mathbb{G}) = 0$, para todo $F \in I$.

***** Demostración
****** Primer punto al segundo
Tenemos $exp(R) \in Exp(I) \cap \overline{\Delta}$, luego debe ser $exp(R) = 0$.

****** Segundo punto al primero
Por la división, cualquier $F \in I$ es de la forma:

\[ F = \sum_{i=0}^n Q_iG_i\]

Donde $exp(Q_iG_i) \in \Delta^i$, y como forman una partición disjunta, se tiene 
que el $exp(F) = max\{exp(Q_iG_i)\} \notin \overline{\Delta}$. Por tanto $Exp(I) \cap \overline{\Delta} = \varnothing$.

**** Semizigia
Sean $F,G \in K[X_1,\dots,X_n]$ no nulos. Definimos el S-polinomial o *semizigia*
como el siguiente polinomio:

\[{\cal S}(F,G) 
= \frac{1}{cl(F)}X^{\gamma-\alpha}F - \frac{1}{cl(G)}X^{\gamma-\beta}G\]

donde $\alpha = exp(F)$, $\beta = exp(G)$, y $\gamma_i = \max\{\alpha_i,\beta_i\}$, para $\gamma = (\gamma_1,\dots,\gamma_n)$.

**** Teorema de Buchberger
Sea $I$ ideal no nulo de $K[X_1,\dots,X_n]$ y $\mathbb{G} = \{G_1,\dots,G_n\}$ un sistema de
generadores. Equivalen:

 1. $\mathbb{G}$ es base de Gröbner.
 2. Para cualquier ordenación de $\mathbb{G}$, se tiene $R({\cal S}(G_i,G_j); \mathbb{G}) = 0$
    para cualesquiera $i \neq j$.
 3. Para alguna ordenación de $\mathbb{G}$, se tiene $R(S(G_i,G_j); \mathbb{G}) = 0$.

***** Demostración
****** Primera implicación
Trivialmente por la [[*Caracterización de bases de Gröbner][caracterización]] una vez que vemos que las 
semizigias son combinaciones lineales.

****** Tercera implicación
No es trivial. Puede consultarse [[http://people.math.aau.dk/~diego/Libro.pdf][aquí]].

**** Algoritmo de Buchberger
Sea $I$ ideal no nulo y $\mathbb{G} = (G_1,\dots,G_n)$ sistema de generadores. Es posible 
construir una base de Gröbner con los siguientes pasos:

  1. $\mathbb{G}_0 = \{G_1,\dots,G_n\}$
  2. $\mathbb{G}_{n+1} = \mathbb{G}_n \cup \{R(S(F,G);\mathbb{G}_n) \neq 0 \mid F,G \in \mathbb{G}_n, F \neq G\}$

Entonces cuando $\mathbb{G}_i = \mathbb{G}_{i+1}$, podemos asegurar que $\mathbb{G}_i$ es base de Gröbner del
ideal $I$.

***** Demostración
Cuando el algoritmo termina, la base que tenemos es claramente de 
Gröbner debido a la caracterización que nos da [[*Teorema de Buchberger][Buchberger]].

Hay que demostrar que el algoritmo termina en algún punto. Esto se
deduce de el hecho de que, dado un monoideal, el conjunto de monoideales
que lo contienen es finito. Pero si un elemento es resto de una división
por $\mathbb{G}$ no nulo, no puede estar en el monoideal generado por los exponentes.
Así, al añadirlo tendremos un monoideal generado mayor, y esto sólo puede
hacerse un número finito de pasos.

**** Retirando un polinomio de una base de Gröbner
Sea $\mathbb{G}$ una base de Gröbner de un ideal no nulo $I \subseteq K[X_1,\dots,X_n]$ y sea
$F \in \mathbb{G}$ tal que $exp(F) \in \{exp(G) \mid G \in \mathbb{G}, F \neq G \}+\mathbb{N}^n$. Entonces, $\mathbb{G}\setminus\{F\}$
es también una base de Gröbner de $I$.

***** Demostración
Si $R(F;\mathbb{G}\setminus \{F\})$ está en $\overline\Delta$, que es el mismo que generarían
con $F$. Pero como está en el ideal, debería ser $0$.

Por lo tanto $F$ está generado por $\mathbb{G}$, que es generadora y por tanto,
base de Gröbner.

**** Base de Gröbner minimal
Una base de Gröbner de un ideal no nulo $I \subseteq K[X_1,\dots,X_n]$ se dice minimal
si:

  1. $cl(F) = 1,\quad\forall F\in\mathbb{G}$.
  2. $exp(F) \notin \{exp(G) \mid G \in \mathbb{G}, G \neq F\} + \mathbb{N}^n$.

Es claro que todo ideal tiene una base de Gröbner minimal, simplemente
[[*Retirando un polinomio de una base de Gröbner][retirando]] polinomios.

**** Caracterización de bases minimales
Sea $\mathbb{G}$ un sistema de generadores de $I$. Equivalen:

  1. $\mathbb{G}$ es una base de Gröbner minimal de $I$.
  2. $\{exp(G_1),\dots,exp(G_t)\}$ es sistema minimal de generadores de $Exp(I)$
     y se tiene $cl(G_i) = 1$.

Los términos líderes de los polinomios de una base de
Gröbner minimal están determinados de forma única y, además, dos bases
de Gröbner minimales tienen el mismo número de elementos.

***** Demostración
****** Primera implicación
Si no fuera sistema minimal, un subconjunto suyo lo sería y generaría
también $Exp(I)$. Pero entonces, podemos quitar elementos de la base
de Gröbner y seguirían generando lo mismo; contraviniendo minimalidad.

****** Segunda implicación
Si no fuera minimal, algún $exp(F)$ sería generado por los demás,
y por tanto los exponentes no formarían un sistema mnimal.

Nótese que hay que considerar los coeficientes líderes para que sean
$1$.

****** Unicidad
Como el sistema minimal de generadores de $Exp(I)$ es único, los
términos líderes de los polinomios de una base de Gröbner minimal
deben ser únicos.

****** Cardinalidad invariante
Dos bases minimales darían lugar a dos sistemas minimales de 
generadores, que deben ser iguales y tener la misma cardinalidad.

**** Base de Gröbner reducida
Una base de Gröbner $\mathbb{G}$ de $I$ es reducida si para cualquier $\forall F \in \mathbb{G}$:

  1. $cl(F) = 1$.
  2. ${\cal N}(F) \cap \{exp(G) \mid G \in \mathbb{G}, G \neq F\} + \mathbb{N}^n = \varnothing$.

**** Una base de Gröbner reducida es minimal
Toda base de Gröbner reducida es minimal.

***** Demostración
Trivialmente, si todo el diagrama de Newton está fuera de lo que
generan los demás; el exponente está fuera de lo que generan los demás.

**** Existencia y unicidad de la base reducida
Todo ideal no nulo $I$ tiene una única base de Gröbner reducida

***** Demostración
****** Existencia
Dada una base de Gröbner minimal, $F \in \mathbb{G}$, veremos que podemos tomar
otra base minimal en la que ${\cal N}(F)$ no esté en los exponentes que 
generan los demás. Si dividimos $F$ entre los demás polinomios
de la base de Gröbner:

\[
F = \sum Q_iG_i + F'
\]

Como $exp(F) = \max(\max\{Q_iG_i\},exp(F'))$ y sabemos que por ser minimal
tiene que ser distinto del exponente de los $Q_iG_i$; luego
$exp(F) = exp(F')$.

Entonces sustituyendo $F$ por $F'$ tenemos otra base de Gröbner minimal
en la que $F$ está reducido. Podemos repetir esto para todos los 
elementos obteniendo una base reducida.

****** Unicidad
Sean bases de Gröbner reducidas $\mathbb{G}$ y $\mathbb{G}'$. Sea $F \in \mathbb{G}$ y sea $F' \in \mathbb{G}'$ el
que tiene el mismo exponente. Tenemos que si intentamos dividir
por $\mathbb{G}$, por ser ambas reducidas:

\[{\cal N}(F-F') \subseteq \overline{\Delta}\]

Entonces $R(F-F';\mathbb{G}) = F-F'$, pero como $F - F' \in I$, debe 
ser $F - F' = 0$.

*** Teoría de eliminación
**** Ideal de eliminación
Sea $I$ ideal no nulo. Definimos el j-ésimo ideal de eliminación como:

\[ I_j = I \cap K[X_{j+1},\dots,X_n]\]

**** Base del ideal de eliminación
Sea $I$ ideal no nulo y $\mathbb{G}$ base de Gröbner del orden lexicográfico
dado por $X_1 > X_2 > \dots > X_n$. Entonces:

\[\mathbb{G}_j = \mathbb{G} \cap I_j\]

es base de Gröbner de $I_j$.

***** Demostración
Sea $F \in I_j$, veremos que $exp(F) = exp(G) + \gamma$ para algún $G \in \mathbb{G}_j$.
Tenemos ya $exp(F) = exp(G) + \gamma$ para $G \in \mathbb{G}$. Como el exponente de $F$ es
nulo en las $j$ primeras variables, entonces $exp(G)$ también lo hace.
Como estamos usando orden lexicográfico ${\cal N}(G)$ entero se anula en las
$j$ primeras variables. Luego $G \in \mathbb{G}$.

**** Extensión de un ideal
Sea $I$ ideal de $K[X_1,\dots,X_n]$. Un sistema de generadores suyo es
también sistema de generadores de:

\[
I^e = \left\{
\sum_{i=1}^k Q_iF_i \;\middle|\; Q_i \in K[T,X_1,\dots,X_n], F_i \in I
\right\}
\]

en el espacio $K[T,X_1,\dots,X_n]$.

***** Demostración
Trivialmente por ser generador de $I$.

**** Cálculo de la intersección
Sean $I,J$ dos ideales no nulos de $K[X_1,\dots,X_n]$. Sea:

\[ H = TI^e + (1-T)J^e \subseteq K[T,X_1,\dots,X_n]\]

Entonces $I\cap J = H \cap K[X_1,\dots,X_n]$, primer ideal de eliminación de $H$.
Esto nos permite calcular la intersección usando bases de Gröbner

***** TODO Demostración
Si está en $I\cap J$ tenemos $TF + (1-T)F = F \in H$. Si está en 
$H \cap K[X_1,\dots,X_n]$, entonces es de la forma:

\[TF+(1-T)G = G + (F-G)T\]

Y por tanto debe tenerse $F = G \in I \cap J$.

**** Cociente de ideales
Dados $I,J$ ideales no nulos, definimos el ideal cociente como:

\[(I : J) 
= 
\{F \in K[X_1,\dots,X_n] \mid FJ \subset I\}
=
\bigcap_{i=1}^n (I : G_i)\]

Siendo $J = (G_1,\dots,G_n)$.

***** Demostración
Trivialmente, si incluye al ideal $J$ incluye a todos sus generadores.
Si está en la intersección incluye a todos los generadores por tanto
a todo el ideal.

**** Caracterización del cociente
Para $G \in K[X_1,\dots,X_n]$ se verifica que $G(I:G) = I \cap (G)$. Luego:

\[(I:G) = \frac{1}{G}(I \cap (G))\]

**** Máximo común divisor y mínimo común múltiplo
Sean $F,G \in K[X_1,\dots,X_n]$ con $D = \operatorname{mcd}(F,G)$ y $M = \text{mcm}(F,G)$. Entonces:

  1. $(F) \cap (G) = (M)$
  2. $D = \frac{FG}{M}$

Nótese que la intersección puede calcularse como el primer ideal de
eliminación de:

\[
H = T(F)^e + (1-T)(G)^e = (TF,(1-T)G)
\]

** 3. Variedades afines
*** Variedades afines
**** Espacio afín de un álgebra
Llamamos $\mathbb{A}^n(K)$ al espacio afín sobre $K^n$ con la función afín
$\varphi : K^n \times K^n \longrightarrow K^n$ dada por $\varphi(u,v) = v-u$.

**** Funciones polinómicas
A partir de cada polinomio $F \in K[X_1,\dots,X_n]$, tenemos definida una función
polinómica $F^\ast : \mathbb{A}^n(K) \longrightarrow K$.

**** Álgebra de funciones polinómicas
Al conjunto de funciones polinómicas lo denotamos por $P(\mathbb{A}^n(K))$.
Forma una K-álgebra con las operaciones usuales:

\[\begin{aligned}
(F^\ast+G^\ast)(a_1,\dots,a_n) 
&= 
F^\ast(a_1,\dots,a_n)+G^\ast(a_1,\dots,a_n)
\\
(F^\ast G^\ast)(a_1,\dots,a_n) 
&= 
F^\ast(a_1,\dots,a_n)G^\ast(a_1,\dots,a_n)
\\
(\alpha F^\ast)(a_1,\dots,a_n) 
&= 
\alpha F^\ast(a_1,\dots,a_n)
\end{aligned}\]

**** Epimorfismo de los polinomios a las funciones polinómicas
Por definición se tiene un epimorfismo $\Delta : K[X_1,\dots,X_n] \longrightarrow P(\mathbb{A}^n(K))$ 
dado por:

\[\Delta(F) = F^\ast\]

***** No es inyectivo en general
La función dada por un polinomio no nulo puede ser nula. Por ejemplo:

\[F = X(X+1)\]
\[G = 0\]

Dan lugar a la misma función en $\mathbb{F}_2$, pero son polinomios distintos.

**** Isomorfismo en cuerpos infinitos
Sea $K$ cuerpo infinito. Sus polinomios verifican:

  1. $F^\ast = 0 \iff F = 0$.
  2. $F^\ast=G^\ast \iff F = G$.

***** TODO Demostración
**** Variedad de un polinomio
Dado $F \in K[X_1,\dots,X_n]$, denotamos por $\mathbb{V}(F)$ al conjunto de sus ceros:

\[\mathbb{V}(F) = \Big\{(a_1,\dots,a_n) \in \mathbb{A}^n(K) \;\Big|\; F(a)=0 \Big\}\]

Dado un ideal ${\cal F}$, denotamos por $\mathbb{V}({\cal F})$ al conjunto de sus ceros:

\[\mathbb{V}({\cal F})
=
\Big\{(a_1,\dots,a_n) \in \mathbb{A}^n(K) \;\Big|\; F(a)=0\; \forall F \in {\cal F} \Big\}\]

**** Variedad algebraica afín
Un conjunto es una *variedad algebraica afín* cuando existe
${\cal F} \subseteq K[X_1,\dots,X_n]$ tal que es de la forma $\mathbb{V}({\cal F})$.

**** Variedad de un ideal
Sea ${\cal F} \subseteq K[X_1,\dots,X_n]$ y sea ${\cal I} = ({\cal F})$ el ideal generado. Se tiene:

  1. $\mathbb{V}({\cal F}) = \mathbb{V}({\cal I})$
  2. $\exists F_1,\dots,F_t : \mathbb{V}({\cal F}) = \mathbb{V}(F_1,\dots,F_t)$

***** Demostración
****** Punto 1
Si los generadores se anulan en un punto, sus combinaciones lineales
también.

****** Punto 2
Todo ideal en el anillo de polinomios es finitamente [[*Propiedades de bases de Gröbner][generado]]
gracias a las bases de Gröbner.

**** Variedad de una familia de ideales
Las variedades dadas por ideales cumplen:

  1. \[\mathbb{V}\left(
     \sum_{\lambda \in \Lambda} J_\lambda
     \right) = \bigcap_{\lambda \in \Lambda} \mathbb{V}(J_\lambda)\]

  2. $\mathbb{V}(J_1J_2) = \mathbb{V}(J_1) \cup \mathbb{V}(J_2) = \mathbb{V}(J_1 \cap J_2)$

  3. $\mathbb{V}(0) = \mathbb{A}^n(K)$

  4. $\mathbb{V}(K[X_1,\dots,X_n]) = \varnothing$

***** Demostración
****** Punto 1
Si un punto se anula para todos los polinomios de cada $J_\lambda$, en
particular está en cada $\mathbb{V}(J_\lambda)$. Si está en cada $\mathbb{V}(J_\lambda)$, se anula
para todos sus polinomios y por tanto para sus combinaciones
lineales.

****** Punto 2
Si $x \notin \mathbb{V}(J_1) \cup \mathbb{V}(J_2)$, entonces existirían polinomios en cada ideal
para los que no sería cero, y no sería cero de su producto, luego
$x \notin \mathbb{V}(J_1J_2)$.

El resto de los contenidos son triviales, viendo:

\[\mathbb{V}(J_1) \cup \mathbb{V}(J_2) \subseteq
\mathbb{V}(J_1\cap J_2) \subseteq
\mathbb{V}(J_1J_2)\]

****** Punto 3
Todos los puntos son raíces del constante $0$.

****** Punto 4
Ningún punto es raíz de todos los polinomios, porque existen los
polinomios constantes no nulos en cualquier cuerpo.

**** Topología de Zariski
Las variedades son los cerrados de una topología sobre $\mathbb{A}^n(K)$.

\[\{
V \subseteq \mathbb{A}^n(K) 
\mid
V \text{ es variedad algebraica afín}
\}\]

***** Demostración
Desde las propiedades de una [[*Variedad de una familia de ideales][familia de ideales]] tenemos que la 
intersección arbitraria y la unión finita de variedades son variedad.
Además, lo son el vacío y el total.

**** Ejemplos
***** Puntos discretos
Dado un conjunto discreto de puntos:

\[\{(a_1,\dots,a_n)\} = \mathbb{V}(X_1-a_1,\dots,X_n-a_n)\]

***** Hipersuperficies
Toda variedad generada por un polinomio no constante:

\[
\mathbb{V}(F) = \Big\{ 
\alpha \in \mathbb{A}^n(K) \mid F(\alpha) = 0
\Big\}
\]

Toda variedad afín es una intersección finita de hipersuperficies.

***** Hiperplano
La variedad de un polinomio de grado total 1 es un hiperplano.
Para $F = a_0 + a_1X_1 +a_2X_2 + \dots + a_nX_n$, tenemos:

\[
\mathbb{V}(F) = \Big\{
\alpha \in \mathbb{A}^n(K) 
\mid 
a_0 + a_1\alpha_1 + a_2\alpha_2 + \dots + a_n\alpha_n = 0
\Big\}
\]

La intersección finita de hiperplanos es una variedad afín lineal.

**** Representaciones paramétricas
Una *representación paramétrica racional* de $\mathbb{V}(F_1,\dots,F_t)$ es un conjunto
de funciones $G_i,H_i \in K[X_1,\dots,X_n]$ cumpliendo:

\[\left\{ 
\frac{G_1}{H_1}(t_1,\dots,t_n),
\frac{G_2}{H_2}(t_1,\dots,t_n),
\dots,
\frac{G_n}{H_n}(t_1,\dots,t_n)
\;\middle|\;
t_1,\dots,t_n \in \mathbb{K}
\right\}
\subseteq
V\]

Cuando $H_i = 1$, la llamamos *representación polinomial*.

***** Ejemplos
****** Representación no racional del círculo
El círculo es una variedad de la que puede darse una representación
no paramétrica.

\[V = \{(sen(t), cos(t)) \midt \in \mathbb{R}\}\]

Sabemos que es variedad porque puede expresarse como:

\[ V = \mathbb{V}(X^2+Y^2-1) \]

Y podemos darle además una representación paramétrica racional
no trivial:

**** Ideal de una variedad
Sea $S \subseteq \mathbb{A}^n(K)$. Definimos el ideal asociado a $S$ como:

\[
\mathbb{I}(S)
=
\Big\{F \in K[X_1,\dots,X_n] \mid \forall a \in S: F(a) = 0\Big\}
\]

***** Es ideal
Trivialmente sabiendo que se conservan los ceros por suma y producto
externo.

**** Propiedades de variedades e ideales
Los ideales y sus variedades cumplen:

  1. $S_1 \subseteq S_2 \implies \mathbb{I}(S_1) \supseteq \mathbb{I}(S_2)$.
  2. $\mathbb{I}(\varnothing) = K[X_1,\dots,X_n]$.
  3. $S \subseteq \mathbb{V}\mathbb{I}(S)$ y $J \subseteq \mathbb{I}\mathbb{V}(J)$.
  4. $\mathbb{I}(S) = \mathbb{I}\mathbb{V}\mathbb{I}(S)$ y $\mathbb{V}(J) = \mathbb{V}\mathbb{I}\mathbb{V}(J)$.
  5. $\mathbb{I}(S)$ es ideal radical.
  6. Cuando $V \subseteq \mathbb{A}^n(K)$ es variedad afín, $V = \mathbb{V}\mathbb{I}(V)$.
  7. $V_1 \subseteq V_2 \iff \mathbb{I}(V_1) \supseteq \mathbb{I}(V_2)$ y $V_1 \subsetneq V_2 \iff \mathbb{I}(V_1) \supsetneq \mathbb{I}(V_2)$.
  8. $\mathbb{I}(V_1 \cup V_2) = \mathbb{I}(V_1) \cap \mathbb{I}(V_2)$
  9. $V_1 \cup V_2 = \mathbb{V}(\mathbb{I}(V_1)\mathbb{I}(V_2)) = \mathbb{V}(\mathbb{I}(V_1) \cap \mathbb{I}(V_2))$.
  10. \[\bigcap_{\lambda \in \Lambda} V_\lambda = \mathbb{V}\left(\sum_{\lambda\in\Lambda} \mathbb{I}(V_\lambda)\right)\]

***** TODO Demostración

**** El ideal de una variedad es radical
Para cualquier $S$, tenemos $\sqrt{\mathbb{I}(S)} = \mathbb{I}(S)$.

***** Demostración

**** TODO Todo ideal radical es de esa forma
La función $\mathbb{{I}}$ considerada como:

\[ \mathbb{I} : \{ V \in \mathbb{A}^n(K) \mid V \text{ es v.a.}\}
\longrightarrow
\{ J \subseteq K[X_1,\dots,X_n] \mid J = \sqrt{J}\}\]

Es inyectiva, se tiene $\mathbb{V}\mathbb{I} = 1$ y en general no se tiene $\mathbb{I}\mathbb{V} = 1$.

*** DONE Anillos de coordenadas
**** Teorema de los ceros de Hilbert
Sea $K$ algebraicamente cerrado. Entonces para cualquier ideal
$J \subseteq K[X_1,\dots,X_n]$, se verifica que:

\[\mathbb{I}\mathbb{V}(J) = \sqrt{J}\]

Y por tanto hay una biyección entre ideales radicales y variedades.

\[ \{ V \in \mathbb{A}^n(K) \mid V \text{ es v.a.}\}
\cong
\{ J \subseteq K[X_1,\dots,X_n] \mid J = \sqrt{J}\}\]

***** TODO Demostración
**** Morfismos de variedades afines
Un *morfismo entre variedades* de $\mathbb{A}^n$ y $\mathbb{A}^m$ es una aplicación $f : V \longrightarrow W$ tal
que existen polinomios $F_1,\dots,F_n$ tales que:

\[f(a) = (F_1(a),F_2(a),\dots,F_n(a)) \quad \forall a \in V\]

Los llamamos también *aplicaciones polinómicas*.

**** Isomorfismos de variedades afines
Un isomorfismo entre variedades afines es un morfismo entre variedades
cuya inversa es un morfismo entre variedades.

**** Anillo de coordenadas
Sea $V \subset \mathbb{A}^n(K)$ una variedad algebraica afín. Definimos el anillo de 
coordenadas de $V$ como:

\[
K[V] = \frac{K[X_1,\dots,X_n]}{\mathbb{I}(V)}
\]

Estos anillos son K-álgebras.

**** Ejemplos de anillo de coordenadas
Sea $V = \mathbb{V}(X^3-y^2) \subseteq \mathbb{A}^2(K)$. 

***** En característica 0
Si $car(K)=0$, entonces $\mathbb{I}(V) = (X^3-Y^2)$.
Entonces:

\[K[V] = \frac{K[X_1,\dots,X_n]}{(X^3-Y^2)\]

***** En característica 2
En característica 2 tenemos $V = \{(0,0),(1,1)\}$, luego
$\mathbb{I}(V) = \mathbb{I}(\{(0,0\} \cup \{(1,1)\}) = (X,Y) \cap (X-1,Y-1)$, y en este caso:

\[\mathbb{F}_2[V]
= 
\frac{\mathbb{F}_2[X,Y]}{(X,Y) \cap (X-1,Y-1)}
= 
\frac{\mathbb{F}_2[X,Y]}{(X,Y)} +
\frac{\mathbb{F}_2[X,Y]}{(X-1,Y-1)}
=
\mathbb{F}_2 \times \mathbb{F}_2
\]

**** Propiedades de los morfismos de variedades
Sea $V \subseteq \mathbb{A}^n(K)$ y $W \subseteq \mathbb{A}^m(K)$ variedades algebraicas afines.

  1. Toda $f : V \longrightarrow W$ aplicación polinómica define un homomorfismo de
     K-álgebras $\tilde{f} : K[W] \longrightarrow K[V]$.
  2. Para cada homomorfismo de K-álgebras $h : K[W] \longrightarrow K[V]$ existe una
     única aplicación polinómica $f : V \longrightarrow W$ única tal que $\tilde{f} = h$.
  3. Si $V_1 \overset{f}\longrightarrow V_2 \overset{g}\longrightarrow V_3$ son aplicaciones polinómicas, tenemos que
     la composición se respeta: $\widetilde{f} \circ \widetilde{g} = \widetilde{g \circ f}$.
  4. Dada una aplicación polinómica entre variedades, $f$ es isomorfismo
     ssi $\widetilde{f}$ es isomorfismo.

Es decir, hay un funtor contravariante entre ambas categorías.

***** DONE Demostración
****** Punto 1
Sea $f(a) = (F_1(a),\dots,F_m(a))$.

\[\begin{tikzcd}
K \rar[hook]\drar[hook]& K[Y_1,\dots,Y_n] \dar{\exists! f'} \\
& K[X_1,\dots,X_n]
\end{tikzcd}\]

donde $f'$ es el único morfismo de K-álgebras tal que $f'(Y_j) = F_j$.

Supongamos que $G \in \mathbb{I}(W)$, veamos que $f'(G) \in \mathbb{I}(V)$. Como sabemos que
$V = \mathbb{V}\mathbb{I}(V)$. Sea $a \in V$, entonces $f(a) \in W = \mathbb{V}\mathbb{I}(W)$ y se anula en todos
los polinomios de $\mathbb{I}(W)$, en particular $G(f(a))=0$.

\[ f'(G)(a) = G(F_1(a),\dots,F_n(a)) = G(f(a)) = 0\]

Acabamos de ver que está bien definido con:

\[\widetilde{f}(G + \mathbb{I}(W)) = G(F_1,\dots,F_n)+\mathbb{I}(V)\]
****** Punto 2
******* Existencia
Dada $h$, tenemos que:

\[\begin{aligned}
h(Y_1+\mathbb{I}(W)) &= F_1 + \mathbb{I}(V) \\
h(Y_2+\mathbb{I}(W)) &= F_2 + \mathbb{I}(V) \\
\dots\\
h(Y_m+\mathbb{I}(W)) &= F_m + \mathbb{I}(V) \\
\end{aligned}\]

Y definimos $f : V \longrightarrow \mathbb{A}^m(K)$ como:

\[f(a) = (F_1(a),\dots,F_m(a))\]

Si $a \in V$, veremos que $f(a) \in W$. Sea $G \in \mathbb{I}(W)$, entonces 
$G+\mathbb{I}(W) = 0 + \mathbb{I}(W)$, luego $0 = h(G+\mathbb{I}(W)) = G(F_1,\dots,F_n) + \mathbb{I}(V)$.
Pero $G(F_1,\dots,F_n)(a) = G(f(a)) = 0$.

Por tanto, tengo una $f: V\longrightarrow W$ polinómica por definición.

Si $h(y_j + \mathbb{I}(W) = F_j'+\mathbb{I}(V)$, entonces $F_j + \mathbb{I}(V) = F_j' + \mathbb{I}(V)$ ssi
$F_j - F_j' \in \mathbb{I}(V)$, lo que da $(F_j-F_j')(a) = 0$ y $F_j(a) = F_j'(a)$ para cualquier
$a$. Es claro por tanto que $\widetilde{f} = h$.

******* Unicidad
Supongamos una $g : V \longrightarrow W$ tal que $\widetilde{g} = h$. Sean
$G_1,\dots,G_n \in K[X_1,\dots,X_n]$ tales que $g(a) = (G_1(a),\dots,G_m(a))$. Entonces
$\widetilde{g} : K[W] \longrightarrow K[V]$:

\[\tilde{g}(Y_j + \mathbb{I}(W)) = G_j + \mathbb{I}(V)\]
\[h(Y_j + \mathbb{I}(W)) = F_j + \mathbb{I}(V)\]

Por lo tanto $G_j - F_j \in \mathbb{I}(V)$ para cualquier $j$.

**** Ejemplo de polinómica biyectiva no isomorfismo
Sea $V = \mathbb{A}^1(\mathbb{R})$ y $W = \mathbb{V}(X^3-Y^2) \subseteq \mathbb{A}^2(\mathbb{R})$. Tenemos una aplicación
del tipo $f : \mathbb{A}^1(\mathbb{R}) \longrightarrow W$:

\[ f(a) = (a^2,a^3)
\]

Que es claro que es polinómica. Tenemos $f$ biyectiva. Pero vemos que no
es homomorfismo de variedades.

\[\widetilde{f} : \frac{K[X,Y]}{(X^3-Y^2)} \longrightarrow K[T]\]

Pero $\tilde{f}$ no es sobreyectiva porque $T \notin \im(\tilde{f})$.
**** Calculando núcleos e imágenes de morfismos de anillos de coordenadas
Sea $h : K[W] \longrightarrow K[V]$ un morfismo de K-álgebras.
Supongamos $h(y_i + \mathbb{I}(W)) = F_j+\mathbb{I}(V)$ y $h(G + \mathbb{I}(W)) = G(F_1,\dots,F_n) + \mathbb{I}(V)$.

1. Sea $A = K[X_1,\dots,X_n]$ y sea $C$ el ideal de $A$ generado por:

   \[\{Y_1-F_1,\dots,Y_m-F_m\} \cup \{\text{sistema de generdaores de } \mathbb{I}(V)\}\]

   Entonces $\ker(h) = ((C \cap K[Y_1,\dots,Y_m]) + \mathbb{I}(W)) / \mathbb{I}(W)$.

2. Sea $\mathbb{G}$ una base de Gröbner reducida de $C$ con orden lexicográfico.

   \[F + \mathbb{I}(V) \in \im(h) 
   \iff
   R(F;\mathbb{G}) \in K[Y_1,\dots,Y_n]
   \]

   Además, en tal caso, $F+\mathbb{I}(V) = h(R(F;G) + \mathbb{I}(W))$.

** Ejercicios
*** Relación 1
**** Ejercicio 1
#+begin_statement
Sea $R$ un anillo conmutativo. Demostrar:

 1. Los elementos $0$ y $1$ están determinados de forma única.
 2. Para cada elemento $x\in R$, el opuesto $-x$ y el inverso si existe $x^{-1}$, están
    determinados de forma única.
 3. El conjunto ${\cal U}(R)$ de las unidades de $R$ es un grupo abeliano.

$\quad$
#+end_statement
***** Punto 1
Supongamos que hubiera dos elementos neutros de cualquier tipo:

\[e = e \otimes e' = e'\]

***** Punto 2
Supongamos que hubiera dos inversos $x,y$ de cualquier tipo:

\[x = x \otimes (a \otimes y) = (x \otimes a) \otimes y = y\]

***** Punto 3
El anillo es conmutativo. Así que el grupo de las unidades con el producto será
abeliano.

**** TODO Ejercicio 2
#+begin_statement
Sea $R$ anillo conmutativo. Demostrar:

  1. $x0=0$ para todo $x\in R$.
  2. $R$ tiene más de un elemento ssi $0\neq 1$.
  3. $(-x)y = -(xy) = x(-y)$ para cualesquiera $x,y \in R$.
  4. $(nx)y = n(xy) = x(ny)$ para cualesquiera $x,y \in R$ y todo $n \in \mathbb{Z}$.
  5. $(nx)(my) = (nm)(xy)$ para cualesquiera $x,y \in R$ y $n,m \in \mathbb{Z}$.
  6. $\left(\sum_{i=1}^n x_i\right) \left(\sum^m_{j=1} y_j\right) = \left(\sum^{n,m}_{i=1,j=1} x_iy_j\right)$, para $x_i,y_j \in R$ y $n,m > 0$.
  7. $(x+y)^n = \sum_{i=0}^n {n \choose i} x y^{n-i}$, para cualesquiera $x,y \in R$ y $n,m \geq 0$.
  8. $(xy)^n = x^ny^n$ y $(x^n)^m = x^{nm}$, para cualesquiera $x,y\in R$ y $n,m \geq 0$.
$\quad$
#+end_statement
**** Ejercicio 3
#+begin_statement
Sea $X$ un conjunto, en ${\cal P}(X)$ se consideran las opearciones

\[A+B := (A\cup B) \setminus (A\cap B)\]
\[AB := A \cap B\]

para cualesquiera $A,B \in {\cal P}(X)$.

Prueba que ${\cal P}(X)$, con las operaciones anteriores y elemento uno igual a $X$, es un
anillo conmutativo. ¿Cuál es el elemento cero?. Observa que este anillo es un 
*anillo de Boole*, es decir $A^2=A$ para $A\in{\cal P}(X)$ y que por tanto $2A = 0$.
#+end_statement

Demostramos que ${\cal P}(X)$ con la suma forma un grupo abeliano. Cada conjunto es su
inverso, es conmutativo y tiene al conjunto vacío como neutro. La asociatividad
se comprueba viendo que pertenecer a $A+B+C$ es pertenecer a uno o a los tres.

Que es conmutativo se tiene por:

\[0 = (A+B)^2 - (A+B) = AB + BA\]
\[0 = A+A\]

**** Ejercicio 4
#+begin_statement
Dado un anillo $R = (R,+,\times,1)$, definir sobre $R$ dos operaciones $\oplus,\otimes$ de forma
que $(R,\oplus,\otimes,0)$ sea un anillo con elemento $1$ como cero.
#+end_statement
Nos sirve tomar:

\[a \oplus b = a+b-1\]
\[a \otimes b = a + b - ab\]

Debemos comprobar las propiedades.

**** TODO Ejercicio 7
**** Ejercicio 8
#+begin_statement
¿Se deduce la condición $f(1) = 1$ en la definición de homomorfismo de anillos de 
las dos condiciones $f(x+y) = f(x)+f(y)$ y $f(xy) = f(x)f(y)$?
#+end_statement
Una inclusión en la suma directa de dos anillos cumple lo pedido pero no cumple
que $i(1) = 1$.

\[i : R \longrightarrow R \oplus S,\quad i(r) = (r,0)\]

**** Ejercicio 9
#+begin_statement
Prueba que los elementos nilpotentes de un anillo forman un ideal.
#+end_statement
Sean $n^p = 0$ y $m^q = 0$, dos nilpotentes. Tenemos que $(n+m)^{p+q} = 0$, por binomio de 
Newton, y que $(rn)^p = 0$ por conmutatividad.
**** Ejercicio 10
#+begin_statement
Demuestra que todo dominio de integridad finito es un cuerpo.
#+end_statement
Dado $x \in R$, considero el endomorfismo $(\lambda a. xa)$. Por ser dominio de integridad, es
inyectivo, y siendo inyectivo y finito, es sobreyectivo. Luego $\exists a : xa = 1$.
**** Ejercicio 11
#+begin_statement
Demuestra que todo dominio de integridad con un número finito de ideales es un
cuerpo.
#+end_statement
Dado $x\in R$, considero una aplicación que lleva un ideal $I$ en $(x)I$. Tenemos que es
inyectiva por ser dominio de integridad. De hecho, sean $i \in I$ con $(x)I = (x)J$:

\[xi = rxj = xrj \Rightarrow i = rj\]

Luego $I\subset J$, simétricamente $I =J$. Por ser inyectiva y ser de número finito, es
biyectiva, luego $\exists I: (x)I = (1)$.
**** Ejercicio 12
Sea una cadena de ideales $\Pi \subset \beta\subset R$, con $x \in \beta$, $x \notin \Pi$.
Entonces $x(x^{n-1}-1) = 0 \in \Pi$, y debe tenerse $x^{n-1}-1 \in \Pi \subset \beta$.
Con eso, debe ser $\beta = R$.

**** Ejercicio 13
 Por definición de *radical*, tenemos que cuando es radical es intersección de 
 anillos primos.

 Sea $\alpha$ intersección de ideales primos, será en particular intersección de ideales
 primos más algunos que lo contienen.

**** Ejercicio 14
 Sea $x$ idempotente y sea $M$ el maximal de $R$. 

 - Sea $x \notin M$, entonces debe ser $x$ una
   unidad; por ser $R$ local. Siendo unidad $x^2 = x$ nos da $x=1$.

 - Sea $x \in M$. Sabemos ${\cal J}(R) = M$, luego $x$ está en el radical de Jacobson.
   Esto quiere decir que $1-xy \in U(R)$ para cualquier $y \in R$. En particular $1-x$
   está en las unidades del anillo. Como $x(1-x) = 0$, se tiene $x = 0$.

**** Ejercicio 15
 Aplicaremos Zorn, viendo que todo conjunto totalmente ordenado tiene cota inferior.

 Sea una cadena de ideales primos $\Pi_i$, entonces sea $ab \in \bigcap \Pi_i$, entonces, supongamos que
 $a$ no perteneciera a la intersección, entonces, por primalidad, si $b \notin \Pi_j$, tampoco
 pertenecería a ninguno por debajo de él; y $a$ debería pertenecer a todos ellos y
 por tanto a la intersección.

**** Ejercicio 16
***** Punto 1
 Tenemos que $0 = (2x)^2 - 2x = 4x - 2x= 2x$.

***** Punto 2
 Si $\pi$ es primo, entonces $R/\pi$ es dominio de integridad. Sea $m \in R/\pi$, tenemos que
 $m(m-1) = 0$, luego $m=0$ ó $m=1$. Así, sólo puede ser isomorfo a $\mathbb{Z}_2$
 y cuerpo. $\pi$ es maximal.

 Además, la primera parte se obtiene también por caso particular del ejercicio 12.

***** Punto 3
 Definimos la operación $a \oplus b = a+b+ab$ y comprobamos que $(a,b) = (a \oplus b)$, ya que
 $a (a\oplus b) =a$ y $b(a\oplus b) = b$. Por inducción, cada ideal generado por varios lo podemos
 generar por un elemento.

**** Ejercicio 17
Tenemos que los divisores de cero ya forman un ideal primo.
**** TODO Ejercicio 18
 Esto es equivalente a decir, ya que estamos en un anillo de ideales principales,
 que $X^3-Y^2$ es irreducible.

**** Ejercicio 19
 Vemos que $\alpha$ es ideal. Supongamos que fuera principal, debería estar generado
 por uno de mínimo grado. Si está generado por una constante, como contiene a $(2)$,
 debe estar generado por $(2)$, pero no es el caso porque no contendría a $x+2$.

**** TODO Ejercicio 21
**** Ejercicio 24
1. => 2. Sea $R$ con un ideal primo, y sea $a \in R$ no unidad. Tengo $a \in M$ para algún 
   maximal, que debe ser el único ideal primo que hay. Aplicando Krull a  
   $S = \{1,a,a^2\dots\}$ contra el ideal $(0)$ tendría un ideal no conteniendo 
   a $S$ pero primo, lo que es imposible, así que $S$ tiene intersección no vacía 
   con $(0)$.
2. => 3. Trivial.
3. => 1. Si $R/{\cal N}$ es un cuerpo, ${\cal N}$ es maximal. Si hubiera otro ideal primo, 
   lo meteríamosen su maximal ${\cal M}$ y; si hubiera $m \in {\cal M}-{\cal N}$, se 
   tendría $(m) \cup {\cal M} = R$. Entonces $km+n = 1$, luego $km$ es unidad y ${\cal M} = R$.

**** TODO Ejercicio 25
**** Ejercicio 26
 Nótese que si $x$ es nilpotente, también lo es $ux$ para $u$ unidad.
 Sea $x^n = 0$. Tenemos que:

 \[(1+x)(1-x+x^2-\dots+x^{n-1}) = 1 + (-x)^n = 1\]

 Luego es unidad. Dada suma de unidad y nilpotente, podemos escribirla como:

 \[(u+x) = u(1+u^{-1}x)\]

 Producto de unidades.

**** Ejercicio 27
***** Punto 1
 Por un lado, si todos los $a_i$ fueran nilpotentes se tendrían $a_iX^i$ nilpotentes.
 Y como la suma de unidad por nilpotente es unidad, la suma total es unidad.

 Sea $\sum b_iX^i$ el inverso de un polinomio $f(x) = \sum a_iX^i$. Es obvio que $a_0$ es unidad
 porque $a_0b_0 = 1$. Veamos por inducción que  $a^{r+1}_nb_{m-r} = 0$.

  - *Caso base:* $a_nb_m = 0$ por ser coeficiente del grado máximo.
  - *Caso de inducción*: El coeficiente de grado $n+m-1$ sería:
    $a_nb_{m-1} + a_{n-1}b_n = 0$, luego $a_n(a_nb_{m-1} + a_{n-1}b_m) = a_n^2b_{m-1} = 0$; y aplicaríamos
    inducción en los siguientes casos de forma similar.

 En particular, para $r=n$ tenemos que $a_n^{n+1}b_0 = 0$, luego $a_n$ es nilpotente.
 Ahora hacemos inducción sobre el grado. También es nilpotente $a_nX^n$, y 
 entonces tenemos que el polinomio siguiente también es unidad, pero de menor grado 
 que el original:

 \[f - a_nX^n = \sum^{n-1} a_iX^i \in {\cal U}(R[X])\]

***** Punto 2
 Tenemos que las $a_iX^i$ son nilpotentes; y la suma de nilpotentes es trivialmente
 nilpotente. 

 Hacia el otro lado, hacemos inducción sobre $grd(f)$:

  - Si $grd(f) = 0$, entonces $f = a_0$.
  - Sea $f = a_0 + \dots + a_nX^n$, tenemos que que si $f$ es nilpotente a la potencia $m$:
    \[ 0 = f^m = \sum_{j=0}^m {m \choose j}(a_0+\dots+a_n-1X^{n-1})^j(a_nX^n)^{m-j} = a_n^mX^{nm} + \dots\]
    Luego $a^m_n = 0$. El polinomio total es suma de esto y un polinomio de grado menor,
    que por inducción es nilpotente.

***** Punto 3. Teorema de MaCoy.
 Una implicación es trivial por definición.

 Sea $f$ divisor de cero. Tomamos un polinomio $g = \sum b_iX^i$ de grado mínimo con

 $fg = 0$. Entonces $a_nb_m = 0$, y por tanto $a_ng$ anularía también a $f$ pero tendría grado
 menor que $m$, luego debería ser $a_ng = 0$. Ahora procedemos por inducción, y se 
 volvería a tener $a_{n-r}g = 0$.

 Si $a_{n-r}g = 0$ para cualquier $r$, entonces:

 \[ 0 = \sum a_{n-r}b_i X^i\]

 Así que $a_{n-r}b_0 = 0$ y se concluye $fb_0 = 0$.

**** Ejercicio 30
#+begin_statement
Calcular el radical de cualquier ideal de $\mathbb{Z}$.
#+end_statement
Dado $(n\mathbb{Z})$ y escribiendo $n = p_1^{e_1}\dots p_n^{e_n}$, podemos ver que un número que perteneciera
a su radical debería ser tal que:

\[ p_1^{e_1}\dots p_n^{e_n} | (q_1^{f_1}\dots q_n^{f_n})^k\]

Para algún $k$, lo que equivale a que $e_i \leq kf_i$. Es decir, necesitamos sólo $f_i \neq 0$.
En conclusión, $\sqrt{n\mathbb{Z}} = (p_1p_2\dots p_n)\mathbb{Z}$, ideal del producto de sus factores primos.

**** Ejercicio 31
#+begin_statement
Demostrar los siguientes resultados para radicales de ideales de un anillo $R$:

  1. $\sqrt{\sqrt{\alpha}} = \sqrt{\alpha}$.
  2. $\sqrt{\alpha\beta} = \sqrt{\alpha \cap \beta} = \sqrt{\alpha} \cap \sqrt{\beta}$.
  3. $\sqrt{\alpha} = R \Leftrightarrow \alpha = R$.
  4. $\sqrt{\alpha+\beta} = \sqrt{\sqrt{\alpha}+\sqrt{\beta}}$.
  5. Si $\pi$ es un ideal primo, entonces $\sqrt{\pi} = \pi$.
  6. Si $\sqrt{\alpha} + \sqrt{\beta} = R$, entonces $\alpha+\beta = R$.

$\quad$
#+end_statement
***** Punto 1
Sea $y \in \sqrt{\sqrt{\alpha}}$, entonces $y^n \in \sqrt\alpha$, y entonces $(y^n)^m \in \alpha$, luego $y \in \sqrt{\alpha}$.
***** Punto 2
Sea $y \in \sqrt{\alpha \cap \beta}$, entonces $y^n \in \alpha \cap \beta$, y entonces $y^ny^n \in \alpha\beta$, luego 
$y \in \sqrt{\alpha\beta}$.
***** Punto 3
Sea $\sqrt{\alpha} = R$, entonces $1 = 1^n \in\alpha$.
***** Punto 4
Sea $x \in \sqrt{\sqrt\alpha+\sqrt\beta}$, entonces $x^n = u+v$, donde $u^p \in \alpha$, $v^q \in \beta$. Tengo entonces que
$(x^n)^{p+q} = (u+v)^{p+q} \in \alpha+\beta$, donde aplicamos Binomio de Newton.
***** Punto 5
Si fuera $x^n \in \pi$ para $n>1$, por primalidad, debería tenerse $x^{n-1} \in \pi$. Así que $x\in\pi$.
***** Punto 6
Si $1 = a+b$ con $a^n\in \alpha$, $b^m\in\beta$, entonces, por Binomio de Newton tenemos que 
$1^{n+m} = (a+b)^{n+m} \in \alpha+\beta$.

**** Ejercicio 32
#+begin_statement
Sean $\alpha,\beta$ ideales de un anillo $R$ tales que $\sqrt{\alpha},\sqrt{\beta}$ son primos entre sí. Demostrar que
entonces $\alpha,\beta$ también son primos entre sí.
#+end_statement
Trivial por el punto 6 del ejercicio 31.

**** Ejercicio 33
#+begin_statement
Sea $R$ un anillo y $\alpha,\beta$ ideales. Demostrar que si $(\alpha)^n\subseteq\beta$ para algún $n\geq 0$, entonces
$\sqrt\alpha \subseteq \sqrt\beta$.
#+end_statement
Tengo trivialmente que $\alpha \subseteq \sqrt\beta$, puedo tomar 
raíces para tener $\sqrt{\alpha} \subseteq \sqrt{\sqrt{\beta}}$.

**** Ejercicio 34
#+begin_statement
Sea $\alpha\subseteq R$ un ideal tal que $\sqrt\alpha$ es finitamente generado. Demostrar que existe
$n \in \mathbb{N}$ tal que $(\sqrt{\alpha})^n\subseteq\alpha$.
#+end_statement
Sea $(\sqrt{\alpha}) = (x_1,\dots,x_m)$ tales que $x_i^{e_i} \in \alpha$. Entonces se tiene por binomio de Newton:

\[(\sqrt\alpha)^{e_1+\dots+e_m} \subset \alpha\]

Ya que cada sumando tiene algún $x_i$ elevado a más que $e_i$.

**** Ejercicio 35
#+begin_statement
En el anillo de polinomios $\mathbb{F}_2[X,Y]$, con $\mathbb{F}_2$ cuerpo finito de dos elementos, sean
$\alpha_1 = (X,Y)$ y $\alpha_2 = (X-1,Y-1)$. Haciendo uso del ejercicio anterior, demuestra que el
ideal producto $\alpha = \alpha_1\alpha_2$ es un ideal radical.
#+end_statement
Primero vemos que $\alpha_1$ y $\alpha_2$ son radicales. $\alpha_1$ lo forman todos los polinomios con
término independiente $0$, y ningún polinomio con término independiente $1$ puede
elevarse hasta tener término $0$. $\alpha_2$ es la imagen de $\alpha_1$ por el homomorfismo de 
anillos que lleva la indeterminada $X$ en $X+1$, así que también lo es.

Sabemos que $\alpha_1$,$\alpha_2$ son primos entre sí. Luego $\alpha_1\alpha_2 = \alpha_1 \cap \alpha_2$. Ahora tenemos
que:

\[\sqrt{\alpha_1\alpha_2} = \sqrt\alpha_1 \cap \sqrt\alpha_2 = 
\alpha_1\cap\alpha_2 = \alpha_1\alpha_2\]

**** Ejercicio 36
Sea $x \in \sqrt{\alpha}$, entonces $x^n \in \alpha \subset \bigcap \pi_i$, pero $x^n \in \pi_i$ me da $x \in \pi_i$, luego $x \in \bigcap \pi_i$.

**** Ejercicio 37
**** Ejercicio 38
**** Ejercicio 39
**** Ejercicio 40
**** Ejercicio 41
***** Punto 1
 Veamos que la aplicación que va del producto de ideales a $R$ es un homomorfismo
 de grupos abelianos multiplicativo biyectivo.

 \[ f((x_1,\dots,x_n)) = x_1+\dots+x_n\]

 Por la definición de *conjunto independiente*, sabemos que dado $x\in R$ existen únicos
 $x_1 \in \alpha_1, x_2 \in \alpha_2,\dots, x_t \in \alpha_t$ tales que $x = x_1 + \dots + x_t$. Esto en el caso $2$ es trivial, y
 se puede ampliar por inducción.

***** Punto 2
 Por el apartado primero, sabemos que existen $e_1+e_2+\dots+e_t = 1$. Puedo tomar
 $\alpha_i$ como anillo sobre la suma y el producto, pero tomando $e_i$ como unidad.

 Sea $x_i \in \alpha_i$, tenemos que $x_i = x_i(e_1+e_2+\dots+e_t)$, así que por unicidad de la 
 descomposición, debe ser $x_i = e_ix_i$.

***** Punto 3
 Tenemos un conjunto de elementos que suman $1$, son idempotentes y ortogonales.

**** Ejercicio 43
***** Punto 1
 Tenemos $X \times \mathbb{Z}$ grupo abeliano con la suma por serlo $X$ y $\mathbb{Z}$. La asociatividad se 
 tiene por:

 \[(x_1,n_1)(x_2,n_2)(x_3,n_3) 
 = (x_1x_2x_3 + n_1x_2x_3+x_1n_2x_3+x_1x_2n_3+x_1n_2n_3+n_1x_2n_3+n_1n_2x_3, 
 n_1n_2n_3)\]

 Y la distributividad:

 \[\begin{aligned}
 (x,y)((a,b)+(c,d)) &= (x,y)(a+c,b+d) = (x(a+c)+y(a+c)+x(b+d)), y(b+d)) \\
 &= (xa+ya+xb,yb) + (xc+yc+xd,yd)
 \end{aligned}\]

***** Punto 2
 Vemos que es trivialmente cerrado para la suma y el producto. Cualquier
 elemento de $X\times \mathbb{Z}$ puede expresarse como $(x,0)+(0,n)$ así que tomamos el isomorfismo
 entre $X\times \mathbb{Z}/ X$ y $\mathbb{Z}$ siguiente:

 \[\phi(x,n) = n\]

 Bien definido porque tiene a $X$ como núcleo.

***** Punto 3
 El valor de $f'(x,0) = f(x)$ está fijado por la condición, y por ser homomorfismo
 de anillos debe tener $f'(0,1) = 1$; por tanto, para preservar suma, $f'(x,n) = f(x)+n$.

 Ahora, para comprobar que es homomorfismo vemos que respeta las sumas, la unidad
 y los productos:

 \[\begin{align*}
 f'((a,b)(c,d)) &= f(ac+bc+da) + bd = f(a)f(c)+bf(c)+df(a)+bd \\
		&= (f(a)+b)(f(c)+d) = f'(a,b)f'(c,d)
 \end{align*}\]

**** Ejercicio 44
 $S,T$ son R-Módulos, así que entendemos por $S\times T$ la suma directa como módulos.
 Tomamos como definición de $R \cong S \times T$ el que:

 \[\forall r \in R: \exists! s\in S, t\in T:\quad s + t = r\]

***** Descompone con un idempotente
 Primero vemos que $\forall r \in R: re + r(1-e) = r$, y es forma única, porque si existieran
 dos formas de expresar $r$:

 \[\begin{align*}
 r &= s + t \\
 r &= s' + t'
 \end{align*}\]

 Entonces $(s-s') + (t-t') = 0$, y no es posible salvo que
 sean iguales, porque $s + t = 0$, con $ea + (1-e)b = 0$ conduce a:

 \[\begin{align*}
 0 &= eea + e(1-e)b &=& ea \\
 0 &= (1-e)ea + (1-e)(1-e)b &=& (1-e)b
 \end{align*}\]


***** Toda descomposición es por idempotente
 Supongamos $R \cong S \times T$. Tenemos la única descomposición de $1$ como $u+v = 1$.
 Hacemos otra descomposición de $1$ como:

 \[1 = (u+v)(u+v) = u^2+v^2+2uv\]

 Aquí tenemos que $uv \in S$ y $uv \in T$, así que $uv = 0$ (si no, tendría dos 
 descomposiciones); por tanto $1 = u^2 + v^2$, y por unicidad $u=u^2$ y $v=v^2$.

 Ahora veamos $S = (u)$, si tengo $s \in S$, entonces $su+sv = s$, y como $sv \in S$ y
 además $sv \in T$, debe ser nulo y tenerse $s = su$.
**** Ejercicio 45
***** Punto 1
 El producto directo de ideales es trivialmente ideal.

 Sea $\alpha$ un ideal del producto directo, tomamos los siguientes ideales
 \[\beta_i = \{ e_ix \med| x \in \alpha\}\]. Siendo $\pi_i$ la proyección canónica, tomamos:

 \[ \alpha_i = \pi_i(\beta_i) \]

 Por ser sobreyectivo $\pi$, se tiene que es ideal. Queda probar:

 \[\alpha = \prod \alpha_i\]

***** Punto 2
 Vemos que los ideales primos son de la forma $R_1 \times \dots \times P_i \times \dots R_n$, para algún
 $P_i$ primo en $R_i$.

 Sea un ideal primo del producto, será producto de ideales 
 \[P = \alpha_1\times\alpha_2\dots\times\alpha_n\]. Veremos que son todos el total salvo uno. Supongamos que 
 tuviéramos dos ideales propios $\alpha_i,\alpha_j$, con $x_i \in \alpha_i$ y $x_j \in \alpha_j$. Tengo:

 \[x = (0,\dots,x_i,0,\dots,1,0,\dots,0) \notin \Pi\]
 \[y = (0,\dots,1,0,\dots,x_j,0,\dots,0) \notin \Pi\]

 Y sin embargo, $xy \in \pi$.

 Para maximales, la demostración es análoga.

***** Punto 3
 Por el apartado primero, tiene $2^n$ ideales.

**** Ejercicio propuesto
 Veamos que si $x \in J(R)$, entonces $1-xy$ es unidad. Tenemos que $yx \in J(R)$. Si 
 $1-xy$ no fuera unidad, habría un maximal conteniéndolo, luego ese maximal contendría
 a la vez a $1-xy$ y a $xy$.

 Ahora, sea $1-xy$ unidad para cualquier $y$. Si un maximal no contuviera a $x$, entonces
 contendría a $1-xy$. Tendría que necesariamente al añadir $x$ a ese maximal obtendría
 todo el anillo. Luego $m + xy = 1$ y entonces $m = 1-xy$ sería unidad y pertenecería
 al ideal maximal, lo que es imposible.

*** Relación 2
**** DONE Ejercicio 8
**** Ejercicio 16
#+begin_statement
Sea $\leq$  un orden en $\mathbb{N}^n$ que es total y compatible. Haciendo uso de la teoría
de ideales monomiales, probad que $\leq$ es un buen orden si, y sólo si, es
monótono.
#+end_statement

Si es monótono, entonces es monomial, y los monomiales son buenos [[*Sistemas de generadores][órdenes]].

Si es buen orden, todo $\mathbb{N}^n$ tiene un mínimo. Si fuera $a$, se tendría
que $a \leq 0$ y por tanto $2a \leq a$, llegando a $a = 2a$, lo que da $a = 0$.

**** Ejercicio 17
#+begin_statement
Sean $I,J \subset K[X_1,\dots,X_n]$ ideales monomiales generados por $\{A_1,\dots,A_s\}$ y
$\{B_1,\dots,B_n\}$, respectivamente:

  1. Demuestra que $I \cap J$ es un ideal monomial.
  2. Demuestra que $\{M_{i,j} \mid i=1,\dots,s;\;j=1,\dots,t\}$, $M_{i,j}$ es un m.c.m. de
     $A_i$ y $B_j$, es un sistema de generadores de $I \cap J$.
  3. Calcula la intersección de los ideales $I = (X,Y^2Z,YZ^2)$ y
     $J = (X^3YZ, X^2Y, Y^2Z^3)$ en el anillo $K[X,Y,Z]$.
#+end_statement

***** Punto 1 y punto 2
Un monomio $X^\mu \in I \cap J$ debe cumplir $A_i \mid X^\mu$, $B_j\mid X^\mu$ y por tanto
$M_{ij}\mid X^\mu$ para algunos $i,j$. Todo monomio del ideal es generado por 
los $M_{ij}$.

Pero dado un $F \in I \cap J$, sus monomios deben estar en $I \cap J$ también,
así que todo polinomio del ideal es generado por los $M_{i,j}$, y es monomial.

***** TODO Punto 3
Como ambos son ideales monomiales, tenemos que calcular sólo sus
$M_{ij}$.
 
**** Ejercicio 19
#+begin_statement
Demuestra que si $\{J_i \mid i \in I\}$ es una cadena de ideales monomiales, entonces
la unión $\bigcup_{i} J_i$ es un ideal monomial.
#+end_statement

Sea un polinomio que está en la unión. Sus monomios están en algún $J_i$,
así que el ideal es monomial.

**** Ejercicio 20
#+begin_statement
Demostrad que la intersección de ideales monomiales es un ideal monomial.
#+end_statement

Si un polinomio pertenece a la intersección, todos sus monomios pertenecen
a cada ideal y a la intersección. Por lo tanto, la intersección es monomial.

**** Ejercicio 22
#+begin_statement
Demuestra que:

  1. Un ideal monomial es primo ssi está generado por un subconjunto 
     de $\{X_1,\dots,X_n\}$.
  2. El número de ideales monomiales primos es finito, y cada uno de ellos
     es finitamente generado.
  3. $(X_1,\dots,X_n)$ es el único ideal maximal que es monomial.
#+end_statement

***** Punto 1
Si está generado de esa forma, debe ser primo, ya que es imposible que
el producto de dos polinomios que no contienen a una incógnita contenga
a la incógnita o sea nulo.

Si tengo un ideal monomial primo:

\[ I = (X^\alpha \mid \alpha \in A \subseteq \mathbb{N}^n)\]

Tengo que si $gr(\alpha) > 1$, entonces podría escribirse como $\alpha = \beta + \gamma$
y debería tenerse a $X^\beta$ o $X^\gamma$ en el ideal, generando a $X^\alpha$. Por
descenso infinito tengo todos los generadores de grado $1$.

***** Punto 2
Como son de la forma dada, debe tenerse.

***** Punto 3
Tenemos que es un cuerpo su cociente, luego debe ser un ideal
maximal:

\[ \frac{K[X_1,\dots,X_n]}{(X_1,\dots,X_n)} \cong K\]

Ahora bien, todo ideal maximal es primo, y por tanto de la forma
anterior, y por tanto está contenido en este, que debe ser el único
maximal.

**** Ejercicio 26
#+begin_statement
Da un ejemplo de dos polinomios $F,G \in K[X_1,\dots,X_n]$ tales que
$Exp((F,G)) \not\subseteq \{exp(F), exp(G)\} + \mathbb{N}^n$. Observar que la inclusión contraria
es siempre cierta.
#+end_statement

Incluso en una variable podemos tener $F = X^2+X$ y $G = X^2-X$, que
cumplen:

\[Exp((F,G)) = \{1\}+\mathbb{N}^n\]
$\{exp(F),exp(G)\} + \mathbb{N}^n = \{2\} + \mathbb{N}^n$

La inclusión contraria es cierta porque podemos multiplicar por monomios
como $X^\gamma$ para cualquier $\gamma$.

**** Ejercicio 32
Vemos que en el primer caso queda invariante en el algoritmo de Buchberger
y en el segundo no. Es decir, las semizigias dan un resto distinto de cero
sólo en el segundo caso.

** Prácticas
*** Práctica 1: Anillos e ideales
**** Anillos básicos
#+BEGIN_SRC sage
  ZZ in Fields
  ZZ in EuclideanDomains
#+END_SRC

#+RESULTS:
: False
: True

***** Extensiones algebraicas
 #+BEGIN_SRC sage
 K = NumberField(x^2+1, 's')
 OK = K.ring_of_integers()
 OK
 SS = NumberField(x^2-5,'s').ring_of_integers()
 SS.0
 SS
 #+END_SRC

 #+RESULTS:
 : Gaussian Integers in Number Field in s with defining polynomial x^2 + 1
 : 1/2*s + 1/2
 : Maximal Order in Number Field in s with defining polynomial x^2 - 5

***** Anillos de enteros módulo n
 #+BEGIN_SRC sage
 Z7 = Integers(7)
 Z7.is_field()
 Z8 = Integers(8)
 Z8.cardinality()
 #+END_SRC

 #+RESULTS:
 : True
 : 8

***** Anillos de polinomios
 #+BEGIN_SRC sage
 P = QQ['x']
 P
 P2 = QQ['x','y','z']
 P2
 #+END_SRC

 #+RESULTS:
 : Univariate Polynomial Ring in x over Rational Field
 : Multivariate Polynomial Ring in x, y, z over Rational Field

**** Cuerpos finitos
#+BEGIN_SRC sage
K = GF(5)
a = K.0
a+a+a+a
K.characteristic()
#+END_SRC

#+RESULTS:
: 4
: 5

***** Cuerpos de fracciones
 #+BEGIN_SRC sage
 P.<x> = QQ[]
 K = P.fraction_field()
 1/x in K
 #+END_SRC

 #+RESULTS:
 : True

**** Producto de anillos
#+BEGIN_SRC sage
CZQ = ZZ.cartesian_product(QQ)
CZQ
CZQ.one()
#+END_SRC

#+RESULTS:
: The Cartesian product of (Integer Ring, Rational Field)
: (1, 1)

**** Ideales
#+BEGIN_SRC sage
P.<x,y> = QQ[]
I = Ideal(P,[x+y,x^2+1])
I
ZZ8 = ZZ.quotient(ZZ.ideal(8))
ZZ8 == Integers(8)
#+END_SRC

#+RESULTS:
: Ideal (x + y, x^2 + 1) of Multivariate Polynomial Ring in x, y over Rational Field
: True

***** Inclusión de ideales
 Definimos la inclusión de ideales y sobrecargamos el método de 
 orden para expresarla.
 #+BEGIN_SRC sage
   I = 2*ZZ
   J = 4*ZZ
   def contenido(I,J):
       return I+J == J

   contenido(I,J)
   contenido(J,I)
   sage.rings.ideal.Ideal_pid.__lt__=contenido
   I < J
   J > I
 #+END_SRC

 #+RESULTS:
 : False
 : True
 : False
 : True

***** Operaciones con ideales
 #+BEGIN_SRC sage
   # Suma de ideales
   4*ZZ + 6*ZZ

   # Producto de ideales
   (4*ZZ)*(6*ZZ)

   # Intersección de ideales
   def intersection(I,J):
       a = I.gen()
       b = J.gen()
       q = (a*b).quo_rem(gcd(a,b))
       return Ideal(q[0])
   sage.rings.ideal.Ideal_pid.__and__=intersection

   (4*ZZ)&(6*ZZ)

   # Cociente de ideales
   def cocienteideales(I,J):
       if not (J<I):
           raise "El cociente necesita de inclusión"
       return I.gens()*I.ring().quo(J)
   sage.rings.ideal.Ideal_pid.__div__=cocienteideales

   (2*ZZ)/(4*ZZ)

   # Operaciones con ideales
   6*ZZ/((6*ZZ)&(4*ZZ))
 #+END_SRC

 #+RESULTS:
 : Principal ideal (2) of Integer Ring
 : Principal ideal (24) of Integer Ring
 : Principal ideal (12) of Integer Ring
 : Principal ideal (2) of Ring of integers modulo 4
 : Principal ideal (6) of Ring of integers modulo 12

***** Ideales primos y maximales
 #+BEGIN_SRC sage :file images/idealpoly.png :output both
 P.<x,y> = QQ[]
 I = (x^3-y^2)*P
 I.is_prime()
 implicit_plot(x^3-y^2, (x,-1,2), (y,-1,1))
 #+END_SRC

 #+RESULTS:
 [[file:images/idealpoly.png]]

***** Ideales radicales
 #+BEGIN_SRC sage
 R.<x,y> = GF(2)[]
 I = (x,y)*R
 J = (x-1,y-1)*R
 K = I*J
 K.radical() == K
 #+END_SRC

 #+RESULTS:
 : True

**** Homomorfismos de anillos
#+BEGIN_SRC sage
# Inclusión 
H = Hom(ZZ,QQ)
inc = H([1])
inc(1)

# Homomorfismo al cociente
f = ZZ.hom([1],ZZ.quo(4*ZZ))
f(1) == f(5)
f(6)

# Composición de homomorfismos
R.<x,y,z> = QQ[]
S.<t> = QQ[]
f = R.hom([t^3,t^5,t^7],S)
g = S.hom([t^2],S)
g*f
#+END_SRC

#+RESULTS:
#+begin_example
1
True
2

Ring morphism:
  From: Multivariate Polynomial Ring in x, y, z over Rational Field
  To:   Univariate Polynomial Ring in t over Rational Field
  Defn: x |--> t^6
        y |--> t^10
        z |--> t^14
#+end_example

*** Práctica 2: Anillos de polinomios
**** Anillos de polinomios
    Para poder usar las variables del anillo de polinomios en 
    sage debemos insertarlas

#+BEGIN_SRC sage
P = PolynomialRing(QQ,['x','y','z','t'])
P.inject_variables()
x in P
#+END_SRC
#+RESULTS:
: Defining x, y, z, t
: True

**** Factorización
#+BEGIN_SRC sage
P.<x,y> = QQ[]
c = x^3-y^2
c.factor()

f = x*y-1
g = x^2+y^2-4
#+END_SRC
#+RESULTS:
: (-1) * (-x^3 + y^2)

**** Polinomios en una variable
#+BEGIN_SRC sage
R = Zmod(2)['x']
R.inject_variables()
filter(is_prime,list(R.monics(of_degree=5)))
#+END_SRC
#+RESULTS:
: Defining x
: 
: [x^5 + x^2 + 1,
:  x^5 + x^3 + 1,
:  x^5 + x^3 + x^2 + x + 1,
:  x^5 + x^4 + x^2 + x + 1,
:  x^5 + x^4 + x^3 + x + 1,
:  x^5 + x^4 + x^3 + x^2 + 1]

**** Ejemplo: Cuerpo de 256 elementos
Vamos a tomar un cuerpo de 256 elementos y vamos a multiplicar en él usando 
logaritmos. Es decir, vamos a representar cada polinomio como un número binario
y vamos a sumarlos para multiplicar.

#+BEGIN_SRC sage
p = R.irreducible_element(8)
Q = R.quo(p*R,'a')
Q.is_field()
a = Q.0

# Potencias de a, son todo elementos de Q
l = [a^i for i in range(2**8-1)]
l.index(a^2+1)
#+END_SRC
#+RESULTS:
: True
: 50

**** TODO Ejercicio 1
    #+begin_statement
    Demuestra que la clase de $x+1$ genera $\mathbb{Z}_2[x]/(x^8+x^4+x^3+x+1)$.
    #+end_statement

**** Órdenes monomiales
    #+BEGIN_SRC sage
      P = PolynomialRing(QQ,x,3,order='lex')
      P.inject_variables()

      ds = list(WeightedIntegerVectors(2,[1,1,1]))+list(WeightedIntegerVectors(1,[1,1,1]))
      ms=[P({tuple(l):1}) for l in ds]
      sorted(ms)

      P=PolynomialRing(QQ,x,3,order='degrevlex')
      P.inject_variables()

      ds = list(WeightedIntegerVectors(2,[1,1,1]))+list(WeightedIntegerVectors(1,[1,1,1]))
      ms=[P({tuple(l):1}) for l in ds]
      sorted(ms)
    #+END_SRC

    #+RESULTS:
    : Defining x0, x1, x2
    : [x2, x2^2, x1, x1*x2, x1^2, x0, x0*x2, x0*x1, x0^2]
    : Defining x0, x1, x2
    : [x2, x1, x0, x2^2, x1*x2, x0*x2, x1^2, x0*x1, x0^2]

***** Ejercicio
     Ordena mediante el orden lexicográfico y lexicográfico graduado todos los 
     monomios en tres variables de grado 3.

     #+BEGIN_SRC sage
       P=PolynomialRing(QQ,x,3)
       P.inject_variables()

       ds = list(WeightedIntegerVectors(3,[1,1,1]))
       ms=[P({tuple(l):1}) for l in ds]
       sorted(ms)
     #+END_SRC

     #+RESULTS:
     #+begin_example
     Defining x0, x1, x2

     [x2^3,
      x1*x2^2,
      x0*x2^2,
      x1^2*x2,
      x0*x1*x2,
      x0^2*x2,
      x1^3,
      x0*x1^2,
      x0^2*x1,
      x0^3]
     #+end_example

**** Algoritmo de la división
*** Práctica 3: Bases de Gröbner
**** Bases de Gröbner
    #+BEGIN_SRC sage
      P = PolynomialRing(QQ, ['x','y','z'], order='lex')
      I = (x^4-y^4+z^3-1, x^3+y^2+z^2-1)*P
      len(I.groebner_basis())
    #+END_SRC

    #+RESULTS:
    : 5

**** Pertenencia de polinomios
    #+BEGIN_SRC sage
      P.<x,y>=QQ[]
      I = (x^2-y^3,x)*P
      I.groebner_basis()
      y**3 in I
    #+END_SRC

    #+RESULTS:
    : [y^3, x]
    : True

***** Ejercicio
     #+BEGIN_SRC sage
       P.<x,y,z>=QQ[]
       g1=x^2*y*z+y^2*z+1
       g2=x*y^2*z+y*z^2-2
       g3=x*y*z^2+z+3
       I = (g1,g2,g3)*P
       len(I.groebner_basis())
       P.quo(I).()
     #+END_SRC

     #+RESULTS:
     : 8
     : Rational Field

**** Cúpside
    #+BEGIN_SRC sage
      P = PolynomialRing(QQ,["t","x","y"],order="lex")
      P.inject_variables()
      I = (x-t^2,y-t^3)*P
      I.groebner_basis()
      I.elimination_ideal([t])
    #+END_SRC

    #+RESULTS:
    : Defining t, x, y
    : [t^2 - x, t*x - y, t*y - x^2, x^3 - y^2]
    : Ideal (x^3 - y^2) of Multivariate Polynomial Ring in t, x, y over Rational Field

    
***** Ejercicio
     #+BEGIN_SRC sage
       P = PolynomialRing(QQ,["t","x","y","z","u"],order="lex")
       P.inject_variables()
       I = (x-t-u, y-t^2-2*t*u, z-t^3-3*t^2*u)*P
       I.elimination_ideal([t,]u)
     #+END_SRC

     #+RESULTS:
     : Defining t, x, y, z, u
     : Ideal (4*x^3*z - 3*x^2*y^2 - 6*x*y*z + 4*y^3 + z^2) of Multivariate Polynomial Ring in t, x, y, z, u over Rational Field

* Análisis Funcional
** 1. Espacios normados
*** Espacios normados
**** Norma y seminorma
*Norma*. Función $\|\cdot\| : X \longrightarrow \mathbb{R}$ verficando:

  - $\|x\| = 0 \Leftrightarrow x = 0$
  - $\|ax\| = |a| \|x\|$
  - $\|x+y\| \leq \|x\|+\|y\|$

***** Seminorma
Cuando $\|x\| = 0$ no implica $x = 0$, se llama *seminorma*. Define
una norma en un espacio cociente.

  - $\|ax\| = |a| \|x\|$
  - $\|x+y\| \leq \|x\|+\|y\|$

***** Sublineal
Cuando además $\|\alpha x\| = \alpha\|x\|$ sólo se cumple para reales positivos, 
se llama funcional *sublineal*.

  - $\|ax\| =  a \|x\|$ para $a \in \mathbb{R}^+$
  - $\|x+y\| \leq \|x\|+\|y\|$

***** Distancia de la norma
Desde la norma se puede definir una *distancia* asociada 
$d(x,y) = \|x-y\|$, que hace a $X$ un *espacio métrico*. La distancia 
cumple:

  - $d(x+a,y+a) = d(x,y)$
  - $d(\lambda a) = |\lambda| d(a)$

***** Topología de la norma
La distancia hace a un espacio normado un *espacio topológico*
con abiertos:

\[\tau = \{G \subset X \;|\; \forall a \in G: \exists r > : B(a,r) \subset G\}\]

Dos normas que generan el mismo espacio topológico son 
*equivalentes*.

***** Equivalencia proporcional
Dos normas $\|.\|$ y $\|.\|_\ast$ generan topologías equivalentes cuando:

\[\exists m,M \in \mathbb{R^+}:\; m \|x\| \leq \|x\|_\ast \leq M \|x\|\]

****** Demostración
Se demuestra por mutua inclusión de bolas.

**** Espacios vectoriales topológicos
Cualquier espacio vectorial sobre $\mathbb{R}$ o $\mathbb{C}$ es normado.

***** Demostración
Dada una base \(\{e_i\}\) del espacio, podemos escribir $x = \sum \alpha_i e_i$ 
y definirla como:

\[ \|x\| = \sum |\alpha_i|\]

La suma es finita por definición de base.

**** Continuidad de la norma, suma y producto
La norma es continua en su espacio por ser lipschitziana:

\[ |\|x\| -  \|y\|| \leq \|x-y\| \]

***** Continuidad de suma y producto
La suma y el producto por escalares son continuos, usando que la
convergencia en el producto equivale a la convergencia por
coordenadas.

***** Continuidad de homotecias y translaciones
Como corolario, lo son las *homotecias* y *translaciones*, todas las
bolas cerradas son homeomorfas a la bola unidad.

**** Operaciones sobre conjuntos
Para $X$ espacio normado:

  1. $A$ abierto $\Rightarrow$ $A+B$ abierto.
  2. $A$ cerrrado, $B$ compacto $\Rightarrow$ $A+B$ cerrado.
  3. $A,B$ compactos $\Rightarrow$ $A+B$ compacto.
  4. $M$ subespacio $\Rightarrow$ $\overline{M}$ subespacio.

***** Demostración de 1
Es la unión de abiertos, $A + B = \bigcup_{b \in B} (b + A)$.

***** Demostración de 2
Sea $x \in \overline{A+B}$, $\exists \{a_n,b_n\} : \{a_n,b_n\} \longrightarrow x$, por compacidad
tenemos $\{b_{\sigma_n}\} \longrightarrow b \in B$ y por tanto $\{a_{\sigma_n}\} \longrightarrow x-b \in A$.

***** Demostración de 3
Se tiene $A\times B$ compacto, y la suma es continua, luego
$A+B$ es compacto.

***** Demostración de 4
Usando la continuidad de la suma y del producto por 
escalares:

\[(+)(\overline{M}\times\overline{M}) 
= (+)\overline{(M\times M)}
\subset \overline{(+)(M \times M)}\]
\[(*)(\mathbb{K}\times\overline{M})
= (*)\overline{(\mathbb{K}\times M)}
\subset \overline{(*)(\mathbb{K} \times M)}\]
      
***** Contraejemplo de suma de cerrados
La suma de dos cerrados puede no ser cerrado:

\[\left\{n + \frac{1}{n} \mid n \in \mathbb{N}\right\} + 
\left\{-n \mid n \in \mathbb{N}\right\} = 
\left\{\frac{1}{n} \mid n \in \mathbb{N}\right\}\]

**** Conexión de espacios normados
Todo espacio normado es *conexo* y *localmente arcoconexo*;
por tanto *arcoconexo*. De hecho, la bola unidad es *convexa*.

**** Espacios de Banach
Un *espacio de Banach* es un espacio normado completo.

*** Desigualdades básicas
**** Desigualdad de Young
Para $a,b\in\mathbb{R}^+$ y $p>1$ con $\frac{1}{p}+\frac{1}{q} = 1$ se tiene:

\[ab \leq \frac{a^p}{p}+\frac{b^q}{q}\]

***** Demostración
Se demuestra aplicando desigualdad de Taylor al logaritmo con 
pesos $1/p$ y $1/q$.

\[\log(ab) = \frac{1}{p}\log(a^p) + \frac{1}{q}\log(b^q) \leq 
\log\left(\frac{a^p}{p} + \frac{b^q}{q}\right)\]

**** Desigualdad de Hölder
Para $a_1\dots a_nb_1\dots b_n \in \mathbb{R}^+_0$ con $\frac{1}{p} +\frac{1}{q} = 1$ se verifica:

\[\sum a_kb_k \leq \left(\sum a_k^p\right)^{1/p}\left(\sum b_k^q\right)^{1/q}\]

***** Demostración
Se demuestra aplicando Young a la división de ambos lados y
cuidando el caso $0$. Llamamos $\alpha = \left(\sum_k a^p_k\right)^{1/p}$, $\beta = \left(\sum_k \beta^q_k\right)^{1/q}$:

\[\frac{a_kb_k}{\alpha\beta}
\leq \frac{a_k^p}{p\alpha^p} + \frac{b_k^q}{q\beta^q}\]

Sumando cada desigualdad tenemos:

\[\frac{1}{\alpha\beta} \sum a_kb_k \leq 
\frac{1}{p\alpha^p}\sum a_k^p +
\frac{1}{q\beta^q}\sum b_k^q = 1\]

**** Desigualdad de Minkowski
Para $a_1\dots a_nb_1\dots b_n \in \mathbb{R}^+_0$, $p>1$, se verifica:

\[\left(\sum_{k=1}^n (a_k+b_k)^p \right)^{1/p} \leq 
\left(\sum_{k=1}^n a_k^p \right)^{1/p} + 
\left(\sum_{k=1}^n b_k^p \right)^{1/p} \]

Dicho de otra forma:

\[\|a+b\|_p \leq \|a\|_p + \|b\|_p\]

***** Demostración
Aplicando Hölder con $p$, $1 - 1/p$ para tener:

\[\begin{aligned}
\left( \sum_{k=1}^n (a_k+b_k)^p \right)^{1/p} 
&=
\left( \sum_{k=1}^n (a_k+b_k)(a_k+b_k)^{p-1} \right)^{1/p}
\\&=
\left( \left( \sum_{k=1}^n a_k^p \right)^{1/p} + \left( \sum_{k=1}^n b_k^p \right)^{1/p} \right)
\left( \sum_{k=1}^n (a_k+b_k)^{\frac{p(p-1)}{p-1}} \right)^{1-1/p}
\end{aligned}\]

*** Ejemplos de espacios normados
**** Espacios de dimensión finita
Solemos notar por ${l}_p^n = (\mathbb{K}^n,\|.\|_p)$ al espacio de Banach sobre $\mathbb{R}^n$ o $\mathbb{C}^n$ 
que da la norma:

\[\|x\|_p = \left(\sum |x_{(k)}|^p \right)^{1/p}\]

Nótese el caso especial $l^n_\infty$ que da la norma del máximo.

***** Normas
Todas estas normas lo son gracias a la [[*Desigualdad de Minkowski][desigualdad de Minkowski]].

***** Equivalencia
Todas las normas son equivalentes y generan el mismo espacio de
Banach:

\[ \|x\|_\infty \leq \|x\|_p \leq \|x\|_1 \leq N \|x\|_\infty\]

****** Demostración
Aplicamos la desigualdad de las medias.

**** Espacios de sucesiones
Las *sucesiones* tales que su p-suma es convergente,
con las normas $\|.\|_p$, dan los siguientes espacios de Banach:

\[\ell_p = \left\{ x : \mathbb{N} \longrightarrow \mathbb{K} \,\middle|\,
\sum_{n=1}^\infty |x(n)|^p < \infty \right\}\]

siendo un caso particular el de la norma del supremo
sobre *sucesiones acotadas*:

\[{\cal \ell}_\infty = \left\{ x : \mathbb{N} \longrightarrow \mathbb{K}\ \left|\ x(n) \text{ acotada} \right\}\]

***** Forman un subespacio vectorial
Pasando la desigualdad de Minkowski al límite, tenemos:

\[\left(\sum^\infty_{k=1} (a_k+b_k)^p \right)^{1/p} \leq 
\left(\sum^\infty_{k=1} a_k^p \right)^{1/p} + 
\left(\sum^\infty_{k=1} b_k^p \right)^{1/p} \]

Por tanto, es un subespacio vectorial y se obtiene una norma
como:

\[\|x\|_p = \left(\sum_{n=1}^\infty |x(n)|^p \right)^{1/p}\]

***** Son espacios de Banach
Como tenemos $|x_n(k)-x_m(k)| \leq \|x_n-x_m\|$, cuando $\{x_n\}$ es 
Cauchy en $\ell_p$, también es Cauchy $\{x_n(k)\}$. Y por tanto, es
convergente por componentes $x(k) = \lim_{n\to\infty}x_n(k)$.

Usamos $\{x_n\}$ de Cauchy para tener:

\[\exists n_0 : \forall m,n\geq n_0 :
\|x_n-x_m\| < \varepsilon\]

Es decir,

\[\sum_{k=1}^N |x_n(k)-x_m(k)|^p \leq (\|x_n-x_m\|_p)^p < \varepsilon^p\]

Tomando $m \to \infty$, y luego tomando $N \to \infty$:

\[\sum_{k=1}^\infty |x_n(k)-x(k)|^p \leq \varepsilon^p\]

Así, tenemos que $x = x_n - (x_n-x) \in \ell_p$, y como $\|x_n-x\|_p \leq \varepsilon$,
tenemos $\{x_n\} \to x$.

**** Subespacios del espacio de sucesiones
El espacio de sucesiones cuenta con subespacios usando la misma 
norma:

***** Sucesiones convergentes
Es un subespacio de $\ell_\infty$ cerrado, y por tanto, de Banach.

\[c = \left\{ x : \mathbb{N} \longrightarrow \mathbb{K}\ 
\left|\ \{x(n)\} \text{ convergente } \right\}\]
 
***** Sucesiones nulas
Otro subespacio de $\ell_\infty$, también cerrado y por tanto, de Banach.

\[c_0 = \left\{ x : \mathbb{N} \longrightarrow \mathbb{K}\ 
\left|\ \{x(n)\} \longrightarrow 0 \right\}\]

***** Sucesiones casi-nulas o de soporte finito
Es un subespacio para todo $\ell_p$.

\[c_{00} = \left\{ x : \mathbb{N} \longrightarrow \mathbb{K}\ 
\left|\ \exists m: \forall n \geq m:\  x(n) = 0 \right\}\]

Este es un subespacio denso ya que toda sucesión es límite de
sucesiones de soporte finito. Pero no es el total, así que no
será completo.

**** Espacios de funciones continuas acotadas
Dado $T$ espacio topológico, tomamos el espacio de funciones
continuas y acotadas:

\[{\cal C}_b(T) = \left\{f : T \longrightarrow \mathbb{K} \mid
f \text{ continua, acotada}\right\}\]

Y lo dotamos de la *norma del supremo*:

\[ \|f\|_\infty = \sup\{ |f(t)| \mid t \in T\}\]

Que da la *convergencia uniforme*.

***** Es espacio de Banach
Si tenemos $\{f_n\}$ de Cauchy, $\{f_n(x)\}$ es de Cauchy y converge a $f(x)$.
Como tenemos algún $n$ para el que $\forall p\geq n: \|f_n-f_p\|_\infty \leq \varepsilon$, entonces:

\[|f_n(x)-f_p(x)| \leq \|f_n-f_p\|_\infty \leq \varepsilon\]

Y tomando límite en $p$ se tiene $|f_n(x) - f(x)| \leq \varepsilon$, luego
$\|f_n-f\|_{\infty} \leq \varepsilon$.

***** Anuladas en infinito
Sea $L$ compacto y separado. Una función se *anula en el infinito*
cuando:

\[\forall \varepsilon: 
\{t\in L \mid |f(t)|\geq\varepsilon\} 
\text{ es compacto}\]

Las funciones continuas que se anulan en el infinito forman 
${\cal C}_0(L)$, subespacio de ${\cal C}_b(L)$. Es espacio cerrado 
y por tanto de Banach.

***** Funciones de soporte compacto
El soporte de $f : L \longrightarrow \mathbb{K}$ para $L$ localmente compacto 
separado es:

\[sop(f) = 
\overline{\{t \in L \mid f(t) \neq 0\}} \subset
L \]

Las funciones con soporte compacto forman ${\cal C}_{00}(L)$, subespacio
vectorial de ${\cal C}_0(L)$.

***** Relación entre ambas
Tenemos que ${\cal C}_{00}(L)$ no es completo en general y que:

\[\overline{{\cal C}_{00}(L)} = {\cal C}_0(L)\]

**** Espacios de funciones derivables
Consideraremos el espacio de funciones sobre un intervalo que sean $d$
veces derivables con derivadas continuas, ${\cal C}^n([a,b],\mathbb{K}^d)$. Escritas:

\[f^{k)} = \left(f^{k)}_1,f^{k)}_2,\dots,f^{k)}_d\right)\]

Sobre él defimos una norma del supremo sobre cada derivada
$\|f^{k)}\| = max \{\|f^{k)}_i\|_\infty\}$. La norma del espacio es la suma de la de 
cada una de las derivadas.

\[ \|f\|_\infty = \sum \|f^{k)}\|_\infty\]

***** Es espacio de Banach
Esto, por el *teorema de la convergencia uniforme* nos lleva a que una
sucesión de Cauchy converja de manera que respete la derivada. Este
será un espacio de Banach.

**** Espacios de funciones integrables
Consideramos el *espacio de funciones p-integrables* como:

\[ L_p(\Omega) =
\left\{ f \in L(\Omega) \;\middle|\; \int_\Omega |f(t)|^p dt < \infty \right\}
\]

Normándolas con:

\[ \|f\|_p =
\left( \int_\Omega |f(t)|^p dt \right)^{1/p}\]

Debemos /identificar funciones que coinciden c.p.d./ para
deducir $\|f\|_p = 0 \Rightarrow f = 0$. Estos espacios son siempre completos.

***** Desigualdades integrales de Hölder y Minkowski
A partir de la desigualdad de Young llegamos
a la *desigualdad integral de Hölder* para funciones
tales que $|f|^p, |g|^p$ son Lebesgue-integrables:

\[\int_\Omega |f(t)g(t)| dt \leq
\left( \int_\Omega |f(t)|^p dt \right)^{1/p}
\left( \int_\Omega |g(t)|^q dt \right)^{1/q}\]

Y desde ella, la *desigualdad integral de Minkowski*:

\[\left( \int_\Omega |f(t) + g(t)|^p dt \right)^{1/p} \leq
\left( \int_\Omega |f(t)|^p dt \right)^{1/p} +
\left( \int_\Omega |g(t)|^p dt \right)^{1/p}\]

Esto nos da la naturaleza de norma.

***** Complitud en el caso real
Usando el Teorema de Riesz-Fisher.

**** Espacios de funciones esencialmente acotadas
Una función es *esencialmente acotada* cuando es $f : [0,1] \longrightarrow \mathbb{K}$:

\[\exists M: |f| \leq M \text{ c.p.d.}\]

Al espacio de funciones esencialmente acotadas lo llamamos ${\cal L}_\infty[0,1]$ y 
le damos una seminorma:

\[\phi_\infty(f) = \inf\{ M
 \mid |f|\leq M \text{ c.p.d.}\}\]

***** Naturaleza de seminorma
Se cumple por un lado que:

\[\phi_\infty(\alpha f) = |\alpha|\phi_\infty(f)\]

Y por otro lado que:

\[ \phi_\infty(f+g) \leq \phi_\infty(f) + \phi_\infty(g) \]

***** Estructura de espacio normado
Podemos convertirlo en espacio normado si tomamos cociente sobre:

\[ N = \{ f \in {\cal L}_\infty[0,1] \mid
\phi_\infty(f)=0 \} \]

Esto es espacio de Banach con la norma $\phi_\infty$.

*** Categoría de espacios normados
**** Homomorfismos topológicos
Los morfismos de la categoría de espacios normados son los
*homomorfismos topológicos*, operadores lineales y continuos que
además son abiertos en su imagen. Hablamos igualmente de
*monomorfismos topológicos*, *epimorfismos topológicos* o de
*isomorfismos topológicos*.

**** Producto de espacios normados
Dados $X_1,\dots,X_n$ espacios normados, podemos definir normas 
sobre su producto cartesiano $\prod X_i$:

 - *Norma del máximo*: $\|x\|_\infty = \max\{\|x_i\|\}$
 - *Norma p*: $\|x\|_p = (\sum \|x_i\|^p)^{1/p}$

***** Topología del producto
La convergencia es trivialmente coordenada a coordenada, y
las topologías asociadas son equivalentes a la topología
producto. El espacio es *Banach* ssi lo son las componentes.

**** Cociente de un espacio normado
Sea $M$ subespacio vectorial cerrado de $X$. Podemos hacer a $X/M$ 
normado con:

\[ \|x+M\| 
= \inf\left\{ \|x - m\| \mid m \in M \right\} 
= d(x,M)\]

***** Topología del cociente
Este espacio es de Banach ssi $X$ es de Banach y $M$ completo. 
La topología coincidirá con la topología cociente.

***** Proyecciones
La proyección $Q: X \longrightarrow X/M$ es lineal, sobreyectiva, abierta
y continua.

*** Operadores y funcionales lineales
**** Operadores lineales continuos
Para $T : X \longrightarrow Y$ lineal entre espacios normados, equivalen:

- $T$ lipschitziana
- $T$ uniformemente continua
- $T$ continua
- $T$ continua en $0$
- $\exists M: \|Tx\| \leq M\|x\|$
- $T$ preserva acotación, $A$ acotado da $TA$ acotado
- $TB_X$ acotado
- $TS_X$ acotado

Y lo llamamos *operador lineal continuo*, $T \in L(X,Y)$.

***** Demostración
****** Lipschitzianidad
La lipschitzianidad implica hasta la continuidad en $0$.

****** Continuidad en 0 implica acotación
Si hay continuidad en $0$ existe $\|x\| < \delta \implies \|Tx\| \leq 1$. Tenemos
entonces:

\[ \left\|\frac{\delta}{\|x\|}x\right\| = \delta \implies
T\left( \frac{\delta}{\|x\|}x \right) \leq 1\]

Luego $\|Tx\| \leq \|x\|/\delta$.

****** Acotación
La acotación implica todo lo demás excepto lipschitzianidad.

****** Acotación de la esfera implica lipschitzianidad.
Como tenemos $\frac{x-y}{\|x-y\|} \in S_X$, lo tenemos acotado por algún $\alpha$ y:

\[T(x-y) \leq \alpha\|x-y\|\]

Por lo tanto, es lispchiztiano.
***** Norma de operadores
Se define la *norma de operadores* como:

\[\begin{aligned}
\|T\| =& \sup_{x \in B_X}\left\{\|Tx\|\right\} \\
=& \sup_{x \in S_X}\left\{\|Tx\|\right\} \\
=& \min\{k \mid \|Tx\| \leq k\|x\| \}
\end{aligned}\]

Y cumple que $\|Tx\| \leq \|T\|\|x\|$.

****** TODO Está bien definida
**** Cuatro teoremas sobre la norma de operadores
Dados $X,Y$ espacios normados:

 1. $(L(X,Y),\|.\|)$ es espacio normado.
 2. $\{T_n\}\longrightarrow T$ ssi $\{T_n\}\longrightarrow T$ uniformemente en $B_X$.
 3. Si $Y$ es de Banach, $L(X,Y)$ es de Banach.
 4. Para $X \overset{T}\longrightarrow Y \overset{S}\longrightarrow Z$, se tiene $\|S \circ T\| \leq \|S\|\|T\|$.

***** Demostración
****** Primer punto
La norma de operadores es norma porque hereda la desigualdad
triangular y la linealidad de la norma del espacio. Nótese
que si $\sup_{x \in B_X} \|Tx\|=0$, es porque $T = 0$.

****** Segundo punto
Nótese que la norma de operadores mide el supremo en la bola
unidad y por homotecias se extiende al espacio.

\[\begin{aligned}
\{T_n\} \longrightarrow T 
&\iff \{\|T_n-T\|\} \longrightarrow 0 
\\&\iff 
\sup_{x \in B_X}\{\|T_n(x) - T(x)\|\} \longrightarrow 0 
\\&\iff 
\sup_{x \in X}\left\{ \left\|T_n\left(\frac{x}{\|x\|}\right) - T\left(\frac{x}{\|x\|}\right) \right\|\right\}
\longrightarrow 0
\end{aligned}\]

****** Tercer punto
Sea $\{T_n\}$ Cauchy. Tenemos $\|T_p(x) - T_q(x)\| \leq \|T_p - T_q\|\|x\|$, por lo que
sabemos $\{T_n(x)\}$ Cauchy; por complitud  $\{T_n(x)\} \longrightarrow T(x)$. Es lineal:

\[T(\alpha x + \beta y) = 
\lim \left( \alpha T_n(x) + \beta T_n(y) \right)
\longrightarrow
\alpha T(x) + \beta T(y)
\]

Tomando límites en la condición de Cauchy, vemos que es acotada
la función $T_p - T$:

\[\|T_p(x) - T(x)\| \leq \varepsilon\]

Luego $T$ es lineal y continua. Y además, $\{T_n\} \longrightarrow T$.

****** Cuarto punto
$\|S \circ T (x)\| \leq \|S\|\|T\|\|x\|$

**** Espacio dual topológico
Sea $X$ normado, su *dual topológico* es el espacio de funciones al
cuerpo con la norma de operadores:

\[ X^\ast = 
L(X,\mathbb{K}) 
= \left\{ f : X \longrightarrow \mathbb{K} \mid
f \text{ lineal y continua} \right\}
\]

**** Extensión desde un subespacio denso
Sea $M$ subespacio denso en $X$, para cada $T \in L(M,Y)$ existe
un $S \in L(X,Y)$ tal que $S|_M = T$ y $\|S\| = \|T\|$

***** Demostración
Podemos extenderla por continuidad, y comprobamos que es lineal:

\[\begin{aligned}
S(\alpha x_n + \beta y_n) = 
T(\alpha x_n + \beta y_n) = 
\alpha Tx_n + \beta Ty_n 
\longrightarrow \alpha Sx_n + \beta Ty_n
\end{aligned}\]

Como la norma es continua y el supremo invariante a clausuras,
hay igualdad entre las normas.

**** Caracterización de operadores abiertos
Sea $T : X\longrightarrow Y$ lineal. Equivalen:

 - $T$ es abierta.
 - $T(B_X)$ es entorno de $0$.

***** Sobreyectividad
Una función lineal y abierta debe ser sobreyectiva ya que la imagen
es subespacio vectorial abierto, y por tanto el total.

***** Demostración
Si es abierta, trivialmente $T(B_X)$ es abierto.

Sea $O \subseteq X$ abierto. Sea $x \in O$, con $B(x,r) \subseteq O$. Como $T(B_X)$ es entorno 
de $0$, tenemos $T(x) + T(B_X)r = T(B(x,r)) \subseteq T(O)$ entorno de $x$, por ser
la translación y homotecia [[*Continuidad de homotecias y translaciones][homeomorfismos]].

**** Caracterización de operadores abiertos sobre la imagen
Sea $T : X \longrightarrow Y$ lineal. Equivalen:

 - $T$ abierta sobre $TX$.
 - $\exists r>0:\quad TX \cap rB_Y \subset TB_X$.
 - $\exists\alpha>0: \forall y\in TX: \exists x\in X: 
  \quad \|x\| \leq \alpha\|y\|$, cumpliendo $Tx = y$.

***** Demostración
Aplicando la caracterización anterior a $TX$ tenemos que
equivalen el primer y segundo apartado.

Por el apartado 2, tengo que dado un $y$, $y\frac{\delta}{\|y\|} \in \delta B_Y$.
Por tanto, $\exists x: Tx = y \frac{\delta}{\|y\|}$. Tomamos $x' = x \frac{\|y\|}{\delta}$, y tenemos
que $T(x') = y$, y además que $\|x'\| = \|x\|\frac{\|y\|}{\delta} \leq \frac{\|y\|}{\delta}$.

**** Descomposición canónica: proyección al cociente
Sea $X$ un espacio normado, $M$ subespacio cerrado y $\pi$ la proyección.
Entonces $\pi \in L(X,X/M)$ es sobreyectiva y abierta, con $\|\pi\| = 1$ cuando
$M \neq X$.

***** Demostración
****** Es continua
Por caracterización de [[*Operadores lineales continuos][operadores lineales continuos]]:

\[ \|\pi(x)\| = \|x+M\| \leq \|x\|\]

****** Tiene norma unidad
Para ver que tiene norma 1, tomamos $x_0 \notin M$.

\[\forall m \in M: \|x+M\| = \|\pi(x+m)\| \leq \|\pi\|\|x+m\|\]

En particular,

\[ \|x+M\| \leq \|\pi\| \inf\{\|x+m\|\} = \|\pi\|\|x+M\| \]

****** Sobreyectiva y abierta
Trivialmente es sobreyectiva. Usamos la caracterización de 
[[*Caracterización de operadores abiertos][operadores abiertos]], comprobando que:

\[\pi^{-1}(B(r,0)) = \{x \in X \mid \|x+m\| < r\} = \bigcup_{m \in M} B(r,m)\]

Por tanto, $B(r,0) \subseteq \pi(B(1,0))$ es un entorno de $0$ por contener un 
abierto.

**** Descomposición canónica: isomorfismo
Sea $T: X\longrightarrow Y$ lineal con $\ker(T)$ cerrado. Se define:

\[\begin{tikzcd}
X \rar[two heads]{\pi} & X/\ker T \rar{\widehat T}[swap]{\cong} & \im T \rar[hook]{i} & Y
\end{tikzcd}\]

Y se tiene:

  - $\hat{T}$ continua ssi $T$ continua. En cuyo caso $\|T\| = \|\hat{T}\|$.
  - $T$ abierta en $TX$ ssi $\hat{T}$ abierta en $TX$.

***** TODO Demostración
*** Teorema de Tychonoff. Dimensión finita
**** Lema a Tychonoff
Toda aplicación lineal desde $\ell_2^n$ es continua.

***** Demostración
Comprobamos que está acotada. Dada una base finita y las coordenadas
sobre ella:

\[
\|Tx\|
=
\left\|\sum_{k=1}^n T(e_k)x_k \right\| 
\leq 
\sum_{k=1}^n |x_k| \|T(e_k)\|
\leq
\|x\| \sum_{k=1}^n \|T(e_k)\|
\]

**** Teorema de Tychonoff
Sea $X$ espacio normado. Toda biyección lineal de $\ell^n_2$ sobre $X$ es 
isomorfismo topológico.

***** Demostración
Por el lema es continua. La esfera de $\ell^n_2$ es compacta; y podemos 
aplicar la caracterización de aplicaciones abiertas anterior.

**** Corolarios al teorema de Tychonoff
Se cumple que:

  1. $T:X\longrightarrow Y$ lineal con $dim(X) < \infty$ nos da $T$ lipschiztiana.
  2. Dos espacios de dimensión finita son isomorfos ssi tienen igual
     dimensión.
  3. En un espacio de dimensión finita, todas las normas son
     equivalentes.
  4. Todo espacio de dimensión finita es Banach.
  5. Todo subespacio de dimensión finita de espacio normado es cerrado.
  6. Un subconjunto de un espacio normado de dimensión finita es
     compacto ssi es cerrado y acotado.

***** Demostración
****** Punto 1
Tenemos $X \cong \ell^n_2 \longrightarrow Y$, [[*Lema a Tychonoff][continua]].

****** TODO Punto 2

**** Dual topológico en dimensión finita
Sea $X$ normado de dimensión finita, su *dual topológico* es:

\[X^\ast =
\left\{ f:X \longrightarrow \mathbb{K} \mid
f \text{ lineal } \right\}\]

***** Demostración
Toda lineal es continua si sale de dimensión finita.

**** Compacidad relativa y precompacidad
Llamamos $A$ *relativamente compacto* cuando $\overline{A}$ es compacto.
Llamamos $A$ *precompacto* cuando, dado un $\varepsilon$, existen $x_1,\dots,x_n$:

\[ A \subset \bigcup_{k=1}^n B(x_n,\varepsilon) \]

***** Cadena de implicaciones
Compacidad implica compacidad relativa, que a su vez implica
precompacidad, que implica acotación.

***** Corolario de Tychonoff de compacidad
En un espacio normado de dimensión finita, un subconjuto es
relativamente compacto ssi es acotado y ssi es precompacto.

**** Corolario de caracterización de continuas
Sea $T : X \longrightarrow Y$ lineal con $TX$ de dimensión finita.
Equivalen:

  1. $T$ es continua.
  2. $\ker T$ cerrado en $X$.

***** Demostración
Cuando $\ker T$ es [[*Descomposición canónica: isomorfismo][cerrado]], $X/\ker T \cong TX$ dimensión finita. $\widehat T$ será
continua.

**** Corolario de caracterización de abiertas
Sea $T : X \longrightarrow Y$ lineal con $X$ de dimensión finita.
Equivalen:

  1. $T$ es abierta.
  2. $T$ es sobreyectiva.

***** Demostración
****** Primera implicación
$TX$ sería abierto y [[*Corolarios al teorema de Tychonoff][cerrado]] a la vez.

****** Segunda implicación
$T$ es continua, luego $\ker T$ [[*Corolario de caracterización de continuas][cerrado]]. $\widehat T : X/\ker T \cong Y$ biyección lineal,
que es por tanto isomorfismo topológico y abierta.

**** Corolario de caracterización de la dimensión finita.
Equivalen:

  1. Todo cerrado y acotado es compacto.
  2. Bola unidad compacta.

*** Teorema de Riesz
**** Lema al teorema de Riesz
Sea $X$ espacio normado con $M$ subespacio propio cerrado. Si
$\varepsilon \in (0,1)$, existe $x \in \mathbb{S}_X$ tal que:

\[ \|x+M\| = d(x,M) > 1-\varepsilon \]

***** Demostración
Sea $x_0 \notin X-M$. Por ser $M$ cerrado $d(x_0,M)>0$. Por ser
el ínfimo, tengo que existe $m_0$ tal que:

\[\frac{1}{1-\varepsilon}\| x_0 - M\| > \| x_0-m_0 \| \]

Por tanto, tomando $x = \frac{x_0-m_0}{\|x_0-m_0\|} \in \mathbb{S}_X$, tenemos:

\[ \| x + M \| 
=  \left\| \frac{x_0-m_0}{\|x_0-m_0\|} + M \right\|
= \frac{\|x_0-M\|}{\|x_0-m_0\|} > 0\]

**** Teorema de Riesz
Son equivalentes:

1. $X$ de dimensión finita.
2. $X$ es localmente compacto.
3. $B_X$ es compacta.
4. $B_X$ es [[*Compacidad relativa y precompacidad][precompacta]].

***** Demostración
1. Cuando la dimensión es finita, $X \cong \mathbb{K}^n$, que es localmente
   compacto.
2. Sea $U$ entorno compacto de $0$, $\exists r>0: \overline{B}(0,r) \subset U$. Por ser un cerrado
   en compacto, es compacto. Por homeomorfismo, lo es $B_X$.
3. Compacidad implica precompacidad.
4. Por ser $B_X$ precompacta,

   \[B_X \subseteq \bigcup B\left(x_i,\frac{1}{2}\right)\]
   
   Como $M = \langle x_1,x_2,\dots,x_k \rangle$ es de dimensión finita, es un subespacio 
   cerrado y propio en $X$. Por el lema de Riesz, existe $x_0 \in \mathbb{S}_X$ 
   tal que:

   \[ \|x_0 - x_i\| \leq d(x_0,M) > \frac{1}{2} \]
   
   Teniendo entonces $x \notin \bigcup B(x_i,\frac{1}{2})$, que nos lleva a 
   contradicción.

** 2. Principios fundamentales del análisis funcional
*** Teorema de Hahn-Banach
**** Versión analítica de Hahn-Banach
Sea $M \subseteq X$ subespacio con $p$ sublineal y $g : M \longrightarrow \mathbb{K}$ lineal 
verificando:

\[Re(g(m)) \leq p(m)\]

Entonces existe $f : X \longrightarrow \mathbb{K}$ lineal extendiéndolo y verificando:

\[Re(f(x)) \leq p(x)\]

Cuando $p$ es [[*Seminorma][seminorma]], se tiene además que $|f(x)|\leq p(x)$.

***** Demostración
****** Primera extensión en los reales
En un primer caso, sea $\mathbb{K} = \mathbb{R}$. Podemos tomar $x_0 \notin X-M$, 
crear $Y = M\oplus x_0\mathbb{R}$ y extender como:

\[ f(m + \lambda x_0) = g(m) + \lambda\alpha\]

****** Elegir el coeficiente de la extensión
Nos falta elegir el $\alpha$. Sabemos que debe cumplir:

\[\alpha \leq \frac{1}{\lambda}\left( p(m+\lambda x_0) - g(m) \right)\]

Tomando un $\lambda$ positivo y negativo llegamos a dos 
condiciones:

\[ g(v) - p(v-x_0) 
\leq \alpha 
\leq p(u+x_0) - g(u)\]

Y tenemos un $\alpha$ cumpliendo esta condición por ser 
equivalente a:

\[ g(u+v) \leq p(u+v) \leq p(u+x_0) + p(v-x_0)\]

Y lo sacamos partiendo la desigualdad, minimizando
y maximizando cada lado de la desigualdad, y dando
la vuelta a todas las desigualdades:

\[ g(u) - p(v-x_0) \leq \alpha \leq p(u+x_0) - g(u)\]

****** Lema de Zorn
Puedo ordenar las extensiones por inclusión, teniendo
además que una cadena de extensiones tiene por maximal a
la unión de todos los espacios, con la función definida
por el primer conjunto en el que aparece el primer elemento.

Si $Y \neq X$ fuera el maximal, podría añadir $x_0 \in X-Y$ y
contravenir la maximalidad de $Y$ extendiendo una dimensión.

****** Caso complejo
Como todo espacio sobre los complejos lo es sobre los reales,
aplicamos el caso real a $g_0 = Re(g)$, y obtenemos $f_0$ cumpliéndolo
y siendo lineal en los reales.

Creo $f$ siendo lineal en los complejos como:

\[f(x) = f_0(x) - if_0(xi)\]

Que cumple las condiciones

****** Caso de la seminorma
Cuando $p$ es seminorma tengo, para $|\alpha|=1$ dando el giro
apropiado:

\[f(\alpha x) = |f(x)| = Re(f(\alpha x)) \leq p(\alpha x) = p(x)\]

**** Extensión equinórmica de Hahn-Banach
Sea $M \subseteq X$ subespacio vectorial, con $g \in M^\ast$. 
Existe $f\in X^\ast$ tal que $f|_M = g$ y $\|f\| = \|g\|$.

***** Demostración
Sea $p(x) = \|g\|\|x\|$, es una seminorma y cumple $Re(g(m)) \leq p(x)$.
Por *Hahn-Banach*, tenemos una extensión $f$, cumpliendo $\|f\| \geq \|g\|$
por ser extensión y:

\[ \|f\| 
= \sup\left\{ \frac{|f(x)|}{\|x\|} \mid x\in X-\{0\}\right\} 
\leq \|g\|\]

**** Separación en el dual topológico
Sea $x_0 \in X$, entonces existe $f \in \mathbb{S}_{X^\ast}$, tal que $f(x_0) = \|x_0\|$.
En consecuencia:

 1. Si $x \neq y$, existe $f \in X^\ast: f(x) \neq f(y)$.
 2. $\forall x \in X: \|x\| = max_{f \in B_{X^\ast}} \{ |f(x)| \}$

***** Demostración
Podemos aplicar Hahn-Banach a $g : x_0\mathbb{K} \longrightarrow \mathbb{K}$ con $g(\lambda x_0) = \lambda \|x_0\|$,
para obtener una extensión de norma $1$.

***** Corolario 1
Aplicamos el resultado para $f(x-y) = \|x-y\| = 0$.

***** Corolario 2
Tenemos $|f(x)| \leq \|x\|$. El mínimo se alcanza en un $f$ dado por
la proposición.

**** Corolario para subespacios finitos
Sea $X$ un espacio normado $\{x_1,\dots,x_n\} \subseteq X$ linealmente independientes
y $\alpha_1,\dots,\alpha_n \in \mathbb{K}$, entonces existe $f \in X^\ast$ tal que $f(x_i) = \alpha_i$.

***** Demostración
Puedo crear una función lineal, sobre $\langle x_1,\dots,x_n \rangle$ que lo cumpla.
Por venir de dimensión finita será continua, así que podemos
aplicar Hahn-Banach para obtener una extensión.

**** Corolario: L(X,Y) es Banach ssi Y es Banach
El espacio $L(X,Y)$ con la norma de operadores es Banach ssi
el espacio $Y$ es Banach.

***** Demostración
****** Primera implicación
[[*Cuatro teoremas sobre la norma de operadores][Cuatro teoremas sobre la norma de operadores]]

****** Segunda implicación
[[http://math.stackexchange.com/questions/1023681/y-is-a-banach-space-if-bx-y-is-a-banach-space][Y is a Banach space if B(X,Y) is a Banach spacea]]

*** Inyección canónica e isometrías
**** Inyección canónica
Se define $J_X(x_0) : X^\ast \longrightarrow \mathbb{K}$ como:

\[J_X(x_0)(f) = f(x_0)\]

***** La inyección es isométrica
Se verifica:

  1. $\forall x \in S_X: J_X(x)$ es lineal y de módulo $1$.
  2. $J_X : X \longrightarrow X^{\ast\ast}$ es isométrica y lineal.

****** TODO Demostración
**** Completación de un espacio
$X^\ast$ es completo para cualquier espacio normado $X$. Cuando $X$ no es 
completo, $J_X$ no es sobreyectivo y podemos completarlo como:

\[ X \subset \overline{J_X(X)} \]

Que lo será por ser cerrado en $X^{\ast\ast}$, que sí es completo.

**** Polar de un subespacio
Dado $M \subset X$, el *polar* de $M$ se define como:

\[M^0 = \left\{ f\in X^\ast \mid f(M) = \{0\} \right\}\]

***** Definición equivalente
Para la restricción $S : X^\ast \longrightarrow M^\ast$, $M^0 = \ker S$.

**** Primer teorema de isometría
Sea $M \subseteq X$ subespacio, \[\cdot|_M : {X^\ast}/{M^0} \longrightarrow M^\ast \] es biyección lineal 
isométrica.

***** Demostración
Tenemos $\|f|_M\| \leq \|f+M^0\|$, y hay igualdad por extensión 
equinórmica.

**** Segundo teorema de isometría
Sea $M\subseteq X$ subespacio vectorial cerrado. Para $\pi_{X/M}$ proyección, 
$\_ \circ \pi : (X/M)^\ast \longrightarrow M^0$ es una biyección lineal isométrica.

***** Demostración
Claramente es lineal. Tenemos que es lipschitziana por:

\[ \|T(f)\| = \| f \circ \pi \| \leq \|f\|\|\pi\| = \|f\| \]

Y por otro lado,

\[ \|T(f)\|\|x+m\| \geq 
\|T(f)(x+m)\| = 
\|f(x+M)\|\]

Por tanto, $\|T(f)\| \geq \|f\|$.

**** Función de aproximación
Sea $M \subseteq X$ subespacio con $x_0 \in X-\overline{M}$. Existe $f\in X^\ast$ con $\|f\|=1$,
tal que $f \in M^0$ y $f(x_0) = d(x_0,\overline{M}) = d(x_0,M)$.

***** Demostración
Como $\overline{M}$ es subespacio cerrado, tenemos $g \in (X/M)^\ast$ con $\|g\|=1$ y
$g(x_0+\overline{M}) = \|x_0+\overline{M}\|$. Entonces $T(g) \in \overline{M}^0$ y $T(g)(x) = g(x+\overline{M})$.
Tenemos $\|T(g)\|= \|g\|=1$ y $f(x_0) = g(x_0+\overline{M}) = \|x_0+\overline{M}\|$.

**** Clausura desde el polar
Sea $M \subseteq X$ subespacio. Entonces:

\[ \overline{M} = \bigcap_{f \in M^0} \ker(f)\]

**** Distancia a un kernel
Sea $X$ espacio normado, $f \in X^\ast - \{0\}$ y $x_0 \in X$. Entonces,

\[d(x_0,\ker(f)) = \frac{|f(x_0)|}{\|f\|}\]

***** Demostración
Por el [[*Función de aproximación][teorema de aproximación]] con $M = \ker(f)$, tenemos una $g$ con
$\|g\| = 1$ tal que $g(x_0) = d(x_0,M)$; tenemos $\ker(f) \subseteq \ker(g)$.

\[\exists u\in X: f(u)=1\]. Para $x\in X$, tenemos $x -f(x)u \in \ker(f)$ y entonces:

\[ 0 = g(x-f(x)u) = g(x) - f(x)g(u)\]

Aplicando esto en $x_0$ tenemos $g(x_0) = g(u)f(x_0)$, que tomando módulos,
nos da $\|g\| = \|f\| |g(u)|$.

*** Funcional de Minkowski
**** Funcional de Minkowski
Se define $p_U : X \longrightarrow \mathbb{R}^+$ para $U$ entorno de $0$ como:

\[ p_U(x) = \inf\{ \lambda \in \mathbb{R}^+_0 \mid x \in \lambda U\} \]

***** Sublinealidad
Para $U$ convexo, $p_U$ es sublineal.

**** Separación de un punto
Sea $U$ entorno de $0$ convexo con $x_0 \notin U$, existe $f \in X^\ast$ tal que 
$Re(f(x)) \leq 1$ para todo $x \in U$; mientras $Re(f(x_0)) \geq 1$.

Se cumple además:

\[ \{x \in X \mid p_U(x)<1\} \subset
U \subset
\{ x \in X \mid p_U(x) \leq 1\}\]

***** Demostración
Tomamos $g : x_0\mathbb{R} \longrightarrow \mathbb{R}$ definido por $g(\alpha x_0) = \alpha p_U(x_0)$.
Aplicamos [[*Versión analítica de Hahn-Banach][Hahn-Banach]] sobre $x_0\mathbb{R}$ y tenemos un $f$ extensión de $g$
verificando que $f(x_0) = p_U(x_0) \geq 1$, y que para $x \in U$ se tiene 
$f(x) \leq p_U(x) \leq 1$.

Ahora para el caso complejo, tenemos $f_0$ lineal y continuo
cumpliendo que $f_0(x_0)\geq 1$, pero $f_0(x) \leq 1$ para todo $x \in U$.
Definimos $f(x) = f_0(x) - if_0(ix)$, y entonces es lineal en los
complejos cumpliendo lo pedido.

**** Separación de convexos (para un abierto)
Sean $A,B \subset X$ convexos con $A \cap B = \varnothing$ con $A$ abierto. Existe $f \in X^\ast$ 
con $\alpha \in \mathbb{R}$ tal que:

\[ Re(f(a)) < \alpha \leq Re(f(b)) \quad \forall a \in A, b \in B\]

**** Existencia de funcionales de soporte
Sea $X$ normado, $A \subset X$ convexo cerrado con $\mathring{A} \neq \varnothing$. Para cada 
$x_0 \in Fr(A)$; existe $f \in X^\ast$ tal que:

  - $\|f\| = 1$
  - $Re(f(x_0)) = \max\{Re(f(x)) \mid x \in A\}$

***** TODO Demostración

**** Separación de convexos (para un compacto)
Sean $A,B \subset X$ convexos con $A \cap B = \varnothing$ con $A$ compacto y 
$B$ cerrado. Existe $f \in X^\ast$ con $\alpha \in \mathbb{R}$ tal que:

\[ Re(f(a)) < \alpha < Re(f(b)) \quad \forall a \in A, b \in B\]

***** TODO Demostración

*** Lema de categoría de Baire
**** Teorema de Baire
Sea $E$ espacio métrico completo y $G_n \subset E$ abiertos densos.
$\bigcap_{n \in \mathbb{N}} G_n$ es denso.

***** Demostración
Empezando con un abierto $G$ y con $G_1$, puedo a cada paso tomar el 
abierto anterior, tomar un abierto dentro de él como 
$\overline{B}(a_i,r_i) \subset G_i \cap B(a_{i-1},r_{i-1})$, y construir una sucesión $\overline{B}(a_n,r_n)$.

Esta sucesión podemos tomarla para que cumpla $\{r_n\} \to 0$. Desde
aquí tenemos que converge $\{a_n\} \to a \in \bigcap \overline{B}(a_n,r_n) \cap G$ por ser de 
Cauchy.

**** Corolario al teorema de Baire
Sea $E$ espacio métrico completo y $F_n \subset E$ cerrados con:

\[E = \bigcup_{n \in \mathbb{N}} F_n\]

Entonces, $\exists n \in \mathbb{N}$ tal que $\mathring{F}_N \neq \varnothing$.

***** Demostración
Aplicando el teorema de Baire en sus complementos.

**** Dimensión en espacios de Banach
Todo espacio de Banach tiene dimensión finita o no numerable.

***** Demostración
Si fuera $X$ espacio de Banach con base numerable, cualquier
subespacio de dimensión finita sería cerrado, pero entonces,
tomando $F_n = \langle e_1,\dots,e_n \rangle$:

\[ X = \bigcup F_n \]

Luego para algún $n$, se tiene $\mathring{F_n} \neq \varnothing$; así que debe ser 
$X=F_n$.

*** Teorema de la aplicación abierta
**** Teorema de la aplicación abierta
Sean $X,Y$ Banach con $T \in L(X,Y)$ sobreyectiva. 
Entonces $T$ epimorfismo topológico (abierta).

***** Demostración
****** La imagen de bola tiene interior no vacío
Como $X = \bigcup_{n \in \mathbb{N}} n B_X$, tenemos que:

\[ Y 
= T\left(\bigcup_{n \in \mathbb{N}} n B_X \right)
= \bigcup_{n \in \mathbb{N}} n T(B_X) 
\subseteq \bigcup_{n \in \mathbb{N}} \overline{n T(B_X)}
= Y
\]

Aplicando corolario a Baire, $\exists N: \mathring{\overline{NT(B_X)}} \neq \varnothing$, luego
$\mathring{\overline{T(B_X)}} \neq \varnothing$. 

****** La imagen de la bola es entorno de 0
Sea ahora, $y_0 \in \mathring{\overline{T(B_X)}}$, se tendrá que:

\[ 0 \in \mathring{\overline{T(B_X)}} - y_0
\subset \overline{T(B_X)} - \overline{T(B_X)}
\subset 2\overline{T(B_X)}\]

Siendo por tanto $\overline{T(B_X)}$ un entorno de 0.

****** Acotación de la bola
Tenemos $\exists\delta > 0: \delta B_Y \subset \overline{T(B_X)}$, y en general:

\[ \forall n \in \mathbb{N}: \frac{\delta}{2^n}B_Y \subseteq \overline{T\left(\frac{1}{2^n}B_X\right)}\]

****** Sucesión
Tomamos $x_0 = 0$, $y \in \overline{T(\frac{1}{2}B_X)}$, y construimos sabiendo:

\[ y - T(x_i) \in
\frac{\delta}{2^i} B_Y \subseteq
T\left(\frac{1}{2^i} B_X\right)\]

Luego existe un $x_{i+1}$ verificando $\|x_{i+1}\|\leq \frac{1}{2^{i+1}}$ y que:

\[ \left\| y - \sum_{k=1}^{i+1} T(x_k) \right\| < \frac{\delta}{2^{i+2}} \]

****** La suma converge
Definimos la suma de la sucesión:

\[ S_n = \sum_{k=1}^n x_k \in X\]

Es de Cauchy por ser convergente $\sum_{n=1}^\infty \frac{1}{2^n}$. Por complitud,
converge, $S_n \to x$, con:

\[ \|S_n\| \leq \sum \|x_k\| \leq \sum \frac{1}{2^n} = 1 \]

Luego $\|x\| \leq 1$, $x \in B_X$. Como además se tiene:

\[\| y - T(S_n) \| \leq  
\|y - \sum T(x_k) \| < 
\frac{\delta}{2^{n+1}} \]

Tenemos $\lim\{T(S_n)\} = T(x)$ y concluimos $y \in T(B_X)$.

****** Conclusión
Hemos probado $\overline{T(\frac{1}{2} B_X)} \subseteq T(B_X)$, y finalmente,

\[ \frac{\delta}{2} B_Y \subset \overline{T\left(\frac{1}{2} B_X\right)} \subset T(B_X)\]

Así que $T(B_X)$ es un entorno de $0$ y $T$ es abierta.

**** Teorema de los isomorfismos de Banach
Sean $X,Y$ Banach con $T \in L(X,Y)$ biyectiva.
Entonces $T$ es isomorfismo topológico.

***** Demostración
Por [[*Teorema de la aplicación abierta][teorema de la aplicación abierta]] $T$ y $T^{-1}$ son abiertas;
luego $T^{-1}$ y $T$ son continuas.

**** Teorema del homomorfismo de Banach
Sean $X,Y$ espacios de Banach con $T \in L(X,Y)$. Será homomorfismo 
topológico ssi $TX$ es cerrado en $Y$.

***** TODO Demostración
**** Equivalencia de normas en espacios de Banach
Sean $\|\cdot\|_1, \|\cdot\|_2$ dos normas en un espacio de Banach. Si cumplen que:

\[\exists M>0 : \|x\|_1 \leq M \|x\|_2\]

Entonces son equivalentes.

***** Demostración
Sea $T(x)=x$ biyección lineal entre las dos normas. Es lipschitziana
por la condición. Por el [[*Teorema de los isomorfismos de Banach][teorema de los isomorfismos de Banach]], es 
isomorfismo topológico.

*** Teorema de la gráfica cerrada
**** Gráfica de una función
La *gráfica* de una función $f$ se define como:

\[ Graf(f) = 
\{(x,f(x)) \mid x \in A\} \subseteq
A \times B\]

Una $T$ es lineal ssi $Graf(T)$ es subespacio vectorial, y
cuando $f$ es continua en Hausdorff, $Graf(f)$ es cerrada.

**** Teorema de la gráfica cerrada
Sean $X,Y$ Banach con $T : X \longrightarrow Y$ lineal. Si la gráfica 
de $T$ es cerrada, $T$ es continua.

***** Demostración
Si tomamos $\|x+y\| = \|x\|+\|y\|$, que genera la topología
producto en $X \times Y$, tenemos un Banach. Como $T$ es lineal,
$G(T)$ es subespacio lineal de $X \times Y$, y como $G(T)$ es cerrado,
es de Banach con la norma inducida.

Sea $\Phi : GT \longrightarrow X$ definida por:

\[ \Phi(x,Tx) = x\]

Como $\Phi$ es lineal, su restricción es continua, lineal y biyectiva.
Por [[*Teorema de los isomorfismos de Banach][teorema de isomorfismo de Banach]], $\Phi^{-1}$ es continua; y entonces
$T = \pi_2 \circ \Phi^{-1}$ es continua.

**** Caracterización de la gráfica cerrada en espacios normados
Sean $X,Y$ normados con $T: X \longrightarrow Y$ lineal. Equivalen:

  - $T$ con gráfica cerrada.
  - Si $\{x_n\} \longrightarrow 0$ y $\{Tx_n\}\longrightarrow y$; entonces $y=0$. Cuasicontinuidad en 0.
 
***** TODO Demostración

*** Teorema de Banach-Steinhaus
**** Teorema de Banach-Steinhaus para funcionales
Sea ${\cal A} \subset L(X,Y)$ para $X$ de Banach e $Y$ normado; una familia de 
operadores acotada puntualmente:

\[ \forall x : \exists M(x): \forall T \in A: \quad \|T(x)\| \leq M(x)\]

Entonces está acotada:

\[\exists M : \forall T \in A: \quad \|T\| \leq M \]

***** Demostración
Tomamos $F_n$ como intersección de conjuntos que son cerrados
por la continuidad de $T$:

\[F_n = \bigcap_{T \in {\cal A}} \{ x \in X \mid \|Tx\| \leq n\}\]

Como está acotada puntualmente, $\bigcup F_n = X$; así que aplicamos
el [[*Corolario al teorema de Baire][corolario a Baire]] para tener un $\mathring{F_N} \neq \varnothing$. Eso quiere decir
que $\exists a: \exists r: a + rB_X \subseteq F_n$. Para $T \in {\cal A}$ se tiene:

\[\begin{aligned}
\|Tx\| =& \frac{1}{r} \| T(a+rx) - Ta\| \\
     \leq& \frac{1}{r} (\| T(a+rx) \| + \|Ta\|) \\
     \leq& \frac{N}{r} + \|Ta\|\frac{1}{r} \\ 
     \leq& \frac{N}{r} + M(a)\frac{1}{r}
\end{aligned}\]

Acotación independiente de $X$.

**** Teorema del cierre de Steinhaus
Sea $X$ de Banach, $Y$ normado, y una sucesión $\{T_n\} \in L(X,Y)$ 
convergiendo puntualmente. La convergencia puntual da un operador 
lineal y continuo:

\[ T(x) = \lim_{n \longrightarrow \infty} T_n(x) \in L(X,Y)\]

***** Demostración
La linealidad se tiene trivialmente:

\[ T(\alpha x_1 + \beta x_2) 
= \lim T_n (\alpha x_1 + \beta x_2)
= \alpha T(x_1) + \beta T(x_2) \]

Como $\{T_n\}$ es una familia acotada puntualmente por converger
puntualmente, se tiene por [[*Teorema de Banach-Steinhaus para funcionales][Banach-Steinhaus]] que está acotada.

Entonces para $x \in B_X$, tenemos $\|T_n(x)\| \leq M$, así que:

\[ \|\lim T_n(x)\| =
\lim \|T_n(x)\| \leq M\]

Luego $\|T(x)\| \leq M$, y por estar acotada en la bola unidad
y ser lineal, $T$ es continua.

**** Corolario a Banach-Steinhaus para el dual
Sea $X$ espacio de Banach y $A \subseteq X^\ast$, equivalen:

 1. $A$ acotado, $\exists M>0: \forall f \in A: \|f\| \leq M$
 2. $A$ puntualmente acotado, $\forall x\in X: \{f(x) \mid f \in A\}$ acotado.

***** Demostración
Por [[*Teorema de Banach-Steinhaus para funcionales][teorema Banach-Steinhaus]] con $X^\ast = L(X,\mathbb{K})$ se tiene
la segunda implicación. La primera se tiene simplemente por
tenerse:

\[ \|f(x)\| \leq \|f\|\|x\| \leq M \|x\| \]

**** Corolario a Banach-Steinhaus para el doble dual
Sea $X$ espacio normado con $A \subseteq X$. Equivalen:

 1. $A$ acotado.
 2. $\{ f(x) \mid x \in A\}$ acotado para cualquier $f \in X^\ast$.

***** Demostración
Sabemos $J_X$ isometría, luego $J_X(A)$ está acotado. Como 
la acotación equivale a la acotación puntual, para cualquier
punto del espacio $f \in X^\ast$ se tiene acotado:

\[ \{J_X(x)(f) \mid x \in A \} \]

** 3. Espacios de Hilbert I
*** Espacios prehilbertianos
**** Producto escalar
Sea $H$ un K-espacio vectorial. Un producto escalar es: $\langle \cdot,\cdot\rangle : H \times H \longrightarrow \mathbb{K}$
cumpliendo:

  1. $\langle \alpha u + \beta v, w\rangle = \alpha\langle u,w \rangle + \beta\langle v,w \rangle$, lineal en la primera variable.
  2. $\langle u,\alpha v + \beta w\rangle = \overline{\alpha}\langle u,v\rangle + \overline{\beta}\langle u,w\rangle$, conjugadalineal en la segunda variable.
  3. $\langle u,v \rangle = \overline{\langle v,u \rangle}$, hermítica.
  4. $\langle u,u \rangle \geq 0$, definida positiva.
  5. $\langle u,u \rangle = 0$ ssi $u=0$, no nula.

***** Observaciones
Cuando $\mathbb{K}=\mathbb{R}$, 3 es conmutatividad; cuando $\mathbb{K}=\mathbb{C}$, implica que 4 está 
bien definido por ser $\langle u,u \rangle$ real.

**** Espacio prehilbertiano
Llamamos espacio prehilbertiano a un espacio vectorial dotado de un 
producto escalar.

**** Ejemplos de espacios prehilbertianos
***** Espacio euclídeo complejo
Para el espacio $\mathbb{C}^n$:

\[\langle (x_1,\dots,x_n), (y_1,\dots,y_n) \rangle =
\sum_{i=0}^n x_i\overline{y_i} \]

***** Espacio de sucesiones
Para el espacio $\ell^2$, de sucesiones de cuadrado sumable:

\[\langle \{x_i\},\{y_i\} \rangle = \sum^\infty_{n=0} x_n\overline{y_n}\]

Nótese que es sumable por tenerse $2|x_n||y_n| \leq |x_n|^2+|y_n|^2$.

***** Espacio de funciones continuas
Para ${\cal C}([0,1],\mathbb{K})$ funciones continuas:

\[
\langle f,g \rangle = \int_{[0,1]} f\overline{g}
\]

***** Espacio de funciones de cuadrado integrable
Para funciones de cuadrado integrable $L^2(\mu)$, tenemos:

\[\langle f,g \rangle = \int_\Omega f\overline{g} \;d\mu\]

Donde por Hölder tenemos la integrabilidad:

\[
\int_\Omega |f\overline{g}| \;d\mu \leq
\sqrt{
\int_\Omega |f|^2 d\mu
}
\sqrt{
\int_\Omega |g|^2 d\mu
}
\]

**** Desigualdad de Cauchy-Schwarz
Para $H$ prehilbertiano, si notamos $\|u\| = \sqrt{\langle u,u \rangle}$,

\[ |\langle u,v \rangle| \leq \|u\|\|v\|
\]

Con caso de igualdad $u = v$.

***** Demostración
Elevando al cuadrado los dos números positivos:

\[\begin{aligned}
0 
&\leq 
\|u\|^2\|v\|^2 - 2|\langle u,v \rangle|^2  + |\langle u,v \rangle|^2
\\ 0 &\leq
\|v\|^2 - \frac{2|\langle u,v \rangle|^2}{\|u\|^2}  + \frac{|\langle u,v \rangle|^2}{\|u\|^2}
\\ 0 &\leq
\left\langle 
\frac{\overline{\langle u,v \rangle}}{\|u\|^2}u + v,
\frac{\overline{\langle u,v \rangle}}{\|u\|^2}u + v
\right\rangle
\end{aligned}\]

**** Desigualdad de Minkowski
Para $H$ prehilbertiano, si notamos $\|u\| = \sqrt{\langle u,u \rangle}$,

\[
\| u + v \| \leq \|u\| + \|v\|
\]

***** Demostración
Desarrollando llegamos a $\langle u,v \rangle + \langle v,u \rangle \leq 2\|u\|\|v\|$, que es cierto por:

\[
\langle u,v \rangle + \langle v,u \rangle \leq
2Re(\langle u,v \rangle) \leq 
2|\langle u,v \rangle| \leq
2 \|u\|\|v\|
\]

Aplicando Cauchy-Schwarz en la última desigualdad.

**** Espacio prehilbertiano es normado
Todo espacio prehilbertiano es normado con norma:

\[
\| u \| = \sqrt{\langle u,u \rangle}
\]

***** Cumple propiedades de la norma
Tenemos trivialmente:

  1. $\|u\| = 0 \iff u =0$
  2. $\|\alpha u\| = |\alpha| \|u\|$
  3. $\|u+v\| \leq \|u\|+\|v\|$

Donde la última se deduce de la desigualdad de Minkowski.

**** El producto escalar es continuo
En un espacio prehilbertiano:

\[\{u_n\} \longrightarrow u, \{v_n\} \longrightarrow v 
\implies
\{ \langle u_n, v_n \rangle\} \longrightarrow \langle u,v \rangle\]

***** Demostración
Se tiene:

\[\begin{aligned} |\langle u_n,v_n \rangle - \langle u,v \rangle| 
&\leq |\langle u_n-u,v \rangle| + |\langle u,v_n-v \rangle| \\
&\leq \|u_n-u\|\|v\| + \|u\|\|v_n-v\| \longrightarrow 0
\end{aligned}\]

*** Identidades de polarización
**** Identidades de polarización
Sea $H$ prehilbertiano:

  1. $\langle u,v \rangle = \frac{1}{4}\left( \|u+v\|^2 - \|u-v\|^2 \right)$, cuando $\mathbb{K} = \mathbb{R}$.
  2. $\langle u,v \rangle = \frac{1}{4}\left( \|u+v\|^2 - \|u-v\|^2 \right) + \frac{i}{4}\left( \|u+iv\|^2 - \|u-iv\|^2 \right)$, cuando $\mathbb{K} = \mathbb{C}$.

***** Demostración
La segunda es trivial calculando y la primera es un caso particular.

**** Identidad del paralelogramo
Sea $H$ normado, es prehilbertiano ssi se verifica:

\[
\|u+v\|^2 + \|u-v\|^2 = 2\left( \|u\|^2 + \|v\|^2\right)
\]

Con el producto escalar dado por la [[*Identidades de polarización][identidad de polarización]]:

\[ \langle u,v\rangle = 
\frac{1}{4}\left(\|u+v\|^2-\|u-v\|^2 \right) +
\frac{i}{4}\left(\|u+iv\|^2-\|u-iv\|^2 \right)
\]

***** Demostración
Cuando es prehilbertiano, se verifica la ecuación trivialmente.
Cuando se verifica la ecuación, podemos ver que la identidad de 
polarización nos da un producto escalar que es conjugadolineal,
hermítico, definido positivo y no nulo.

# ¿En cuál de estas comprobaciones se usa paralelogramo?
# Parecen largas de comprobar.

**** Ejemplos de normados prehilbertianos
***** Contraejemplo: funciones continuas con el máximo
El espacio ${\cal C}[0,1]$ con la norma del máximo no es prehilbertiano.
Hay un contraejemplo a la identidad del paralelogramo en $f(t) = 1$ y
$g(t) = t$.

***** Espacio de sucesiones de cuadrado sumable
El espacio $\ell_p$ es prehilbertiano ssi $p=2$, con:

\[\|x\| = \left(\sum_{i=1}^\infty |x_n|^2 \right)^{1/2}\]

****** Demostración
Se cumple que:

\[
\sum_{n=1}^k |a_n + b_n|^2 + \sum_{n=1}^k |a_n-b_n|^2
= 2\left(\sum_{n=1}^k |a_n|^2+|b_n|^2\right)
\]

Y tomando límites tenemos lo pedido.

*** Espacios de Hilbert
**** Espacios de Hilbert
Un espacio prehibertiano completo es un espacio de Hilbert.
Equivalentemente, un espacio de Banach con norma asociada a un producto
escalar.

**** Hilbert de dimensión finita
Todo prehilbertiano de dimensión finita es Hilbert.

***** Demostración
Todo espacio normado de dimensión finita es de Banach.

**** Compleción de prehilbertianos
La completación de un espacio prehilbertiano es espacio de Hilbert.

***** Demostración
La [[*Completación de un espacio][completación]] restringida al espacio orginal tiene su norma. Y la
norma es [[*Continuidad de la norma, suma y producto][continua]]. Por tanto, será prehilbertiano al cumplir la
[[*Identidad del paralelogramo][identidad del paralelogramo]]:

\[
\lim_{n \to \infty} \|u_n+v_n\|^2 + \|u_n-v_n\|^2
=
2\left(\|\lim_{n \to \infty} u_n\|^2+\|\lim_{n \to \infty} v_n\|^2\right)
\]

*** Ortogonalidad
**** Ley de los cosenos
La ley de los cosenos puede reinterpretarse como una definición del
ángulo para espacios distintos de $\mathbb{R}^2$.

\[
cos(\theta) = \frac{\langle u,v \rangle}{\|u\|\|v\|}
\]

**** Ortogonalidad
Dos vectores se dicen *ortogonales* $u \perp v$ cuando su producto escalar 
es nulo:

\[\langle u,v \rangle = 0\]

**** Espacio ortogonal
Para $H$ hilbertiano, $S \subseteq H$; definimos el ortogonal de $S$ como:

\[
S^\perp = \left\{
u \in H \mid \forall s \in S: u \perp s
\right\}
\]

**** Propiedades del espacio ortogonal
Para $0 \subset S \subset H$, tenemos:

  1. $0 \in S^\perp$.
  2. $S \cap S^\perp \subseteq \{0\}$.
  3. $\{0\}^\perp = H$, $H^\perp = \{0\}$.
  4. $S_1 \subseteq S_2 \implies S_1^\perp \supseteq S_2^\perp$.
  5. $S^\perp$ es subespacio vectorial cerrado.
  6. $S \subseteq S^{\perp\perp}$.
 
***** Demostración
Triviales. La quinta se tiene por núcleo de una función lineal y
continua.

**** Suma directa
Sea $X$ normado con $M,N$ subespacios. Se dice que hay suma directa
$X = M \oplus N$, cuando:

  1. $X = M + N$
  2. $M \cap N = \{0\}$

**** Suma directa topológica
Se dice que hay suma directa topológica cuando $M \oplus N$ cumplen que
$x_n = m_n + n_n$ respeta la convergencia $x = m + n$ con $m \in M, n \in N$.

***** Suma directa topológica en Banach
En un espacio de Banach, la suma directa es topológica cuando
ambos espacios $M,N$ son cerrados.

**** Lema de aproximación óptima
Sea $S$ un cerrado y convexo de $H$ prehilbertiano. Hay un sólo elemento
en el conjunto que realiza la mínima norma.

\[\exists! s_0 \in S:\quad \|s_0\| = \min\{\|s\| \mid s\in S\}\]

***** Demostración
****** Existencia
Sea $t$ el ínfimo. Por convexidad tenemos: $\|\frac{1}{2}(u+v)\| \geq t$. Dada una
sucesión $\{\|s_n\|\} \longrightarrow t$; vemos que es de Cauchy:

\[\begin{aligned}
\|s_n-s_m\|^2 &\leq \|s_n+s_m\|^2 + \|s_n-s_m\|^2 - 4t^2 \\&=
2(\|s_n\|^2 -t^2) + 2(\|s_m\|^2 - t^2) \longrightarrow 0
\]

Luego converge en el cerrado.

****** Unicidad
Si hubiese dos mínimos, se tendría:

\[
\|s+s'\|^2 + \|s-s'\|^2 = 2\left(\|s\|^2 + \|s'\|^2 \right) 
= 4t^2 \leq \|s+s'\|^2
\]

Por lo que $\|s-s'\| = 0$.

**** Teorema de la aproximación óptima
Sea $H$ Hilbert, $M \subseteq H$ subespacio cerrado y $u \in H$. Entonces, existe 
una única mejor aproximación a $M$, esto es:

\[\exists! \pi_M(u) \in M:\quad d(u, \pi_M(u)) = d(u,M) \]

***** Demostración
Aplicaremos el [[*Lema de aproximación óptima][lema de aproximación óptima]] a $u+M$. Tenemos que probar
que es convexo, y para ello:

\[\lambda (u+m) + (1-\lambda)(u+m') = u + m\lambda + m'(1-\lambda) \in u+M\]

Sea $s_0 \in u+M$ la mínima norma en $u+M$:

\[ \|s_0\| = \min\{\| u + m \| \mid m \in M\}\]

Tomamos $\pi_M(u) = u - s$, y tenemos:

\[ \| u - \pi_M(u)\| = \|s \| \leq \|u + m\|\]

La unicidad la da la unicidad en el lema de aproximación óptima.

*** Proyecciones y proyección ortogonal
**** Proyecciones
Sea $H$ Hilbert y $p : H \longrightarrow H$ lineal. Se llama proyección cuando $p \circ p = p$.

**** Suma directa de una proyección
Sea $p:H \longrightarrow H$ proyección, entonces $H = \ker(p) \oplus \im(p)$.

***** Demostración
Para $h \in H$ tenemos la descomposición $p(h) + (h-p(h))$. Dado $p(g) \in \ker(p)$,
se tiene $p(g) = p(p(g)) = 0$.

**** Proyecciones ortogonales
Se dice proyección ortogonal a una proyección $p$ en la que $\ker(p) \perp \im(p)$.

**** Lemas al teorema de la proyección ortogonal
Sea $H$ Hilbert y $M$ subespacio cerrado. Entonces:

  1. $u-\pi_M(u) \in M^\perp$.
  2. $\pi_M(\alpha u) = \alpha \pi_M(u)$.
  3. $\pi_M(u + v) = \pi_M(u)+\pi_M(v)$.
  4. $\pi_M(\pi_M(u)) = \pi_M(u)$.

***** Demostración
****** Punto 1
Para cualquier $t \in \mathbb{R}$ y $m \in M$ tenemos:

\[
0 \leq 
\| u - \pi u + tm \| - \| u - \pi u \| \leq
2t\; Re \langle u-\pi u, m\rangle + t^2 \|m\|^2
\]

Pero para que esto sea cierto, debe ser $Re \langle u-\pi u, m \rangle = 0$.
Tomando $im$ se tiene la parte imaginaria también nula, luego
debe ser $\langle u-\pi u, m \rangle = 0$.

****** Punto 2
Tenemos:

\[
\| \alpha u - m \| 
= |\alpha| \left\|u - \frac{m}{\alpha}\right\| \geq |\alpha| \|u- \pi u\|
\]

Dándose la igualdad con $m = \alpha \pi u$.

****** Punto 3
La ortogonalidad del primer punto:

\[
\|u + v - m\| = 
\|(u -\pi u) + (v - \pi v) - \widetilde m\| =
\|u - \pi u+  v - \pi v \| + \|\widetilde m\|
\]

Para el mínimo debe tenerse $\widetilde m = 0$.

****** Punto 4
Usando de nuevo la ortogonalidad del primer punto:

\[
\pi_M(u) - \pi_M\pi_M(u) \in M^\perp \cap M = \{0\}
\]

**** Teorema de la proyección ortogonal
Para $H$ Hilbert y $M$ subespacio cerrado:

  1. $H = M \oplus M^\perp$.
  2. La proyección a $M$ es la aproximación óptima.
  3. $\|u\|^2 = \|\pi_M(u)\|^2 + \| u - \pi_M(u) \|^2$.

Análogamente, $\pi_{M^\perp}$ da la aproximación óptima a $M^\perp$.

***** Demostración
Por el [[*Lemas al teorema de la proyección ortogonal][lema]] sabemos que $\pi_M$ es una proyección. Como además tiene 
$\ker(\pi_M) = M^\perp$ e $\im(\pi_M) = M$, se tiene que es la buscada.

Por ser ortogonales:

\[
\|u\|^2 = 
\|u - \pi_M(u) + \pi_M(u)\|^2 =
\|u-\pi_M(u)\|^2 + \|\pi_M(u)\|^2
\]

**** Nota: Unicidad de la descomposición ortogonal
Sea $H = M \oplus N$ con $\langle m, n \rangle = 0$ para $m \in M,\; n \in N$. Se tiene que $N = M^\perp$.

***** Demostración
Tenemos $N \subseteq M^\perp$ y además, para $m+n \in M^\perp$, se tiene 
$0 = \langle m, m+n \rangle = \|m\|^2$, luego $m = 0$.

**** Corolario: clausura del doble ortogonal
Para $H$ Hilbert, $M$ subespacio, $M^{\perp\perp} = \overline{M}$.

***** Demostración
El espacio puede partirse de dos formas distintas como suma ortogonal 
de cerrados:

\[ H = \overline{M} \oplus \overline{M}^\perp \]
\[ H = M^{\perp\perp} \oplus M^{\perp}\]

Como $M^\perp = \overline{M}^\perp$, debe ser $\overline{M} = M^{\perp\perp}$.

**** Corolario: caracterización de la densidad
Para $H$ Hilbert, $M$ subespacio, $M$ es denso ssi $M^\perp = \{0\}$.

***** Demostración
Si es denso, $M^\perp = \overline{M}^\perp = \{0\}$. 
Si $M^\perp = \{0\}$, tenemos $H = \overline{M} \oplus \{0\}$.

**** Teorema de Lindestrauss-Tzafriri
Un espacio de Banach es Hilbert ssi todo subespacio cerrado suyo admite
un complemento topológico. Es decir, para cada $M$ cerrado hay un $N$ cerrado
tal que:

\[
X = M \overset{t}{\oplus} N
\]

***** TODO Demostración

*** Teorema de Riesz-Frechet
**** Recordatorio: por Teorema de Hahn-Banach
Sea $X$ espacio normado sobre $\mathbb{K}$. Entonces $\exists f: X \longrightarrow \mathbb{K}$ lineal y continua
no nula. Además, dado $x \in X\setminus\{0\}$, tenemos $\exists f \in X^\ast: f(x) \neq 0$. De hecho,

\[
\|x\| = \sup\{ |f(x)| \mid f \in X^\ast \}
\]

***** Demostración
Hemos reenunciado la [[*Separación en el dual topológico][separación en el dual topológico]], que era 
consecuencia de la [[*Versión analítica de Hahn-Banach][versión analítica de Hahn-Banach]].

***** Relación en el caso prehilbertiano
Cada vector tiene asociada una función lineal y continua en el dual
dada por su producto escalar: $v \mapsto \langle \cdot,v \rangle$.

**** Teorema de Riesz-Fréchet
Sea $H$ Hilbert y $f : H \longrightarrow \mathbb{K}$ lineal y continuo. Existe un único $v \in H$ 
tal que:

\[f(u) = \langle u,v \rangle\]

De otra forma, $v \mapsto \langle \cdot,v \rangle$ es una biyección conjugada-lineal de $H$ en $H^\ast$.

***** Demostración
****** Existencia: caso nulo
En el caso $f=0$, simplemente tomamos $v=0$.

****** Existencia: caso general
Dado $f$, $\ker(f)$ será propio, luego necesitamos $\ker(f)^\perp$ espacio propio
para que la suma directa sea el total. Sea $w \in \ker(f)^\perp$ no nulo, tenemos:

\[
0 = \langle f(u)w - f(w)u , w \rangle = \|w\|^2f(u) - f(w)\langle u,w \rangle
\]

Por lo que tenemos:

\[
f(u) = \left\langle u, \frac{f(w)}{\|w\|^2} w \right\rangle
\]

****** Unicidad: caso nulo
Debe ser un vector en $H^\perp = \{0\}$.

****** Unicidad: caso general
Simplemente notando que $f(u) = \langle u,v \rangle = \langle u,w \rangle$ nos daría $\langle u,v-w \rangle = 0$.
Un vector perpendicular a todo el espacio es nulo.

**** Corolario: el dual es de Hilbert
Si $H$ es Hilbert, $H^\ast$ con la norma de operadores es de Hilbert.

***** Demostración
Tomamos como producto escalar:

\[
\langle f_v,f_w \rangle = \langle w,v \rangle
\]

Y comprobamos que cumple los axiomas. Nótese que es necesario invertir
el orden para que sea hermítico. Por otro lado, la norma es la misma
que la norma de operadores:

\[ \sqrt{\langle f_v,f_v \rangle} = \|v\|
\]

mientras que si $\|u\| = 1$, por Cauchy-Schwarz hay caso de igualdad en:

\[ |f_v(u)| = |\langle u,v \rangle| \leq \|v\|\]

**** Corolario: el doble dual es Hilbert
Si $H$ es Hilbert, $H^{\ast\ast}$ es Hilbert.

***** Demostración
Componemos dos veces lo que hemos hecho con el dual. Tenemos una
biyección lineal en este caso.

**** Corolario: completación de prehilbertianos
Si $H$ es prehilbertiano, $H^{\ast\ast}$ es su completación.

***** Demostración
Veremos que si $\widehat H$ es su completación, $H^\ast \cong \widehat{H}^\ast$, por lo que tendrá que
tenerse $H^{\ast\ast} \cong \widehat{H}^{\ast\ast} \cong \widehat{H}$.

Pero $H^\ast \cong \widehat{H}^\ast$ es cierto simplemente porque la única extensión continua y
la restricción serán inversas.

**** Corolario: extensión única
Sea $H$ Hilbert con $M \subset H$ subespacio y $f \in M^\ast$. Existe una única extensión
lineal y continua cumpliendo:

\[ \|f_H\| = \|f\| \]

***** Demostración
****** Existencia
Podemos extender la función de $M$ a $\overline{M}$ por continuidad. Como es cerrado
y subespacio de Hilbert, será Hilbert. Entonces aplicamos Riesz-Frechet
para tener que la función será de la forma $f(x) = \langle x,m \rangle$ para algún
$m \in M$. Ahora, $f_m = \langle \cdot,m \rangle$ es extensión y cumple:

\[
\|f_m\| = \|m\| = \|f\|
\]

****** Unicidad
Si hubiera otra extensión $\langle \cdot,u \rangle$, se tendría $\langle \cdot,m \rangle - \langle \cdot,u \rangle = 0$ en $M$. 
Y entonces, $m - u \in M^\perp$, lo que implicaría:

\[ \|u\|^2 = \|m\|^2 + \|m-u\|^2 \geq \|m\|^2\]

Con caso de igualdad sólo si $\|m-u\| = 0$.

 - [[http://math.stackexchange.com/questions/332350/hilbert-spaces-and-unique-extensions-of-linear-functions][functional analysis - Hilbert spaces and unique extensions of
   linear functions. - Mathematics Stack Exchange]]

** 4. Espacios de Hilbert II
*** Convergencia débil
**** Convergencia débil
En $H$ Hilbert, se dice que $\{u_n\}$ converge débilmente a $u$ cuando:

\[\{u_n\} \overset{w}\longrightarrow u 
\iff \forall v \in H: \{\langle u_n,v \rangle\} \longrightarrow \langle u,v \rangle \]

De otra forma, $\forall f \in H^\ast: \{f(u_n)\} \longrightarrow f(u)$.

***** Unicidad del límite débil
La unicidad se tiene porque si $\forall v: \langle u,v \rangle = \langle u',v \rangle$, entonces $f_u = f_{u'}$,
que por [[*Teorema de Riesz-Frechet][Riesz-Frechet]] nos da $u = u'$.

**** Convergencia implica convergencia débil
En $H$ Hilbert, la convergencia implica la convergencia débil: 

\[\{u_n\} \longrightarrow u \implies \{u_n\} \overset{w}\longrightarrow u\]

***** Demostración
Trivial por continuidad del producto escalar.

***** Contraejemplo del recíproco
En el espacio de sucesiones cuadrado sumables $\ell_2$, sabemos que los
términos de toda sucesión tienden a $0$, por eso:

\[ \{e_n\} \overset{w}\longrightarrow 0\]

Pero no se tiene $\{e_n\} \longrightarrow 0$.

**** Compacidad débil
Un conjunto es débilmente compacto si toda sucesión suya tiene una
parcial débilmente convergente.

**** Compacidad de la bola unidad
Sea $H$ Hilbert, entonces la bola $\overline{B(0,1)}$ es débilmente compacta.

***** TODO Demostración

**** Espacio vectorial topológico
Un espacio vectorial topológico es un espacio vectorial con una topología
que hace continuos a la norma y el producto por escalares.

*** Ortonormalidad
**** Ortogonalidad y ortonormalidad
Sea dice $S \subset H$ ortogonal cuando $\forall u,v \in S: \; u \perp v$. Se dice que es además
ortonormal cuando $\forall u \in S : \|u\| = 1$.

**** Independencia de ortogonales
Si hay un conjunto ortogonal $S$, es linealmente independiente.

***** Demostración
Supongamos que tenemos $e_1,\dots,e_n \in S$ y una combinación lineal suya.
Entonces para cada $e_k$:

\[
0 = \left\langle \sum \alpha_i e_i, e_k \right\rangle
= \alpha_k \|e_k\| = \alpha_k
\]

**** Gram-Schmidt
Sea $H$ prehilbertiano de dimensión $n$, finita:

  1. $\{e_1,\dots,e_n\}$ ortogonal $\implies$ $\{e_1,\dots,e_n\}$ base
  2. Existe una base ortonormal.

***** Demostración
****** Punto 1
Son linealmente independientes y generan un espacio de dimensión $n$,
que debe ser el total.

****** Punto 2
Sabemos que existe una base $u_1,\dots,u_n$, podemos generar una base
ortonormal tomando a cada paso:

\[ e_i = u_i - \sum_{j < i} \langle u_i,e_j \rangle e_j\]

Para tener una base ortogonal. Dividiendo por la norma para tener una
base ortonormal.

**** Base ortonormal finita
Sea $e_1,\dots,e_n$ una base ortonormal de un Hilbert. Cada elemento puede
escribirse en coordenadas de sus productos escalares:

\[
u = \sum_{i=1}^n \langle u,e_i \rangle e_i
\]

Y su norma será:

\[
\|u\| = \sqrt{\sum^n_{i=1} |\langle u,e_i \rangle|^2}
\]

***** Demostración
Si escribimos las coordenadas $u = \sum \alpha_ie_i$ tenemos que $\alpha_i = \langle u,e_i \rangle$.
La norma se obtiene desde la descripción de coordenadas por 
ortonormalidad.

*** Familias sumables
**** Familia sumable
Sea $X$ normado y $\{x_i\}_{i\in I}$ familia; se dice sumable si:

\[\exists x \in X: 
\forall \varepsilon > 0:
\exists J_\varepsilon:
\forall J \text{ finito} \supseteq J_\varepsilon: 
\quad
\left\|\; \sum_{i \in J} x_i - x \;\right\| < \varepsilon
\]

Llamamos suma de la familia a $\sum_{i \in I} x_i = x$.

***** Redes
Nótese que esto es una generalización del concepto de sucesión.
Las [[https://es.wikipedia.org/wiki/Red_(matem%25C3%25A1tica)][redes]] son una generalización de las secuencias para una
cantidad no numerable de elementos.

# Quizá podríamos ver que toda red es Cauchy ssi es convergente.
# Eso nos ahorraría las demostraciones posteriores de familias sumables.

**** Unicidad de la suma
La suma de una familia sumable es única.

***** Demostración
Si tuviera dos sumas $x$ y $x'$, tomaríamos los $J_\varepsilon, J_\varepsilon'$ para tener:

\[
\| x - x' \| \leq
\left\| x - \sum_{x_i \in J_\varepsilon \cup J_\varepsilon'} x_i \right\| +
\left\| \sum_{x_i \in J_\varepsilon \cup J_\varepsilon'} x_i - x' \right\|
\leq 2\varepsilon
\]

**** Propiedades de las familias sumables
Sea $X$ normado con $\{x_i\}_{i \in I}$ familia con suma $x$:

  1. $\sum_{i \in I} x_{\sigma(i)} = x$, para cualquier permutación $\sigma$.
  2. $\sum_{i \in I} \alpha x_i + \beta y_i = \alpha x + \beta y$, siendo la suma lineal.
  3. $\sum_{i \in I} Tx_i = Tx$, para $T$ lineal continua.

***** Demostración
Nótese que cuando coinciden en subsumas finitas, deben coincidir
en la suma total, por definición.

****** Punto 1
Trivial por la definición.

****** Punto 2
Tomando el conjunto $J_{\frac{\varepsilon}{2\alpha}}^x \cup J_{\frac{\varepsilon}{2\beta}}^y = K$, tenemos que:

\[ \left\| \alpha x + \beta y - \left(\sum_{i \in K} \alpha x_i + \beta y_i \right)\right\| 
\leq |\alpha| \left\| x - \sum_{i \in K} x_i \right\| + |\beta| \left\|y - \sum_{i \in K} y_i \right\| 
\leq \varepsilon\]

****** Punto 3
Si tomo unos $\varepsilon \longrightarrow 0$ tendré:

\[
\left\| Tx - \sum_{i \in J_\varepsilon} Tx_i \right\| = 
\left\| T\left( x - \sum_{i \in J_\varepsilon} x_i \right) \right\| \leq
\|T\|\varepsilon \longrightarrow 0
\]

**** Caracterización de familia sumable real
En los reales positivos, una familia $\{r_i\}_{i \in I} \in \mathbb{R}^+$ es sumable ssi:

\[\sup\left\{\;
\sum_{i \in J} r_i \;\middle|\; J \;\mtext{ finito } \subset I
\;\right\} < \infty\]

donde además, $\sum_{i \in I} r_i$ es el supremo.

***** Demostración
Por la definición de supremo, dado cualquier $\varepsilon$ podemos encontrar:

\[s \geq \sum_{J} r_i \geq \sum_{J_\varepsilon} r_i\]

Cumpliendo por tanto para $J_\varepsilon \subset J$:

\[ 
\left|s - \sum_J r_i\right| \leq 
\left|s - \sum_{J_\varepsilon} r_i \right| \leq
\varepsilon\]

**** Condición de Cauchy en familias sumables
Una familia $\{x_i\}_{i \in I}$ verifica la condición de Cauchy cuando:

\[\forall \varepsilon > 0:
\exists J_\varepsilon \text{ finito}:
\forall J \text{ finito}: J \cap J_\varepsilon = \varnothing \implies
\left\|\; \sum_{i \in J} x_i \;\right\| < \varepsilon\]

**** Toda sumable es Cauchy
Si $\{x_i\}_{i \in I}$ es sumable, verifica la condición de suma de Cauchy.

***** Demostración
Suponiendo que suman $s$, podemos tomar $J_\varepsilon$ cumpliendo que, dado $J \cap J_\varepsilon = \varnothing$:

\[
\left\|\; s - \sum_{J_\varepsilon \cup J} x_i \;\right\| < \varepsilon
\]

Y por tanto, aplicando Minkowski:

\[
\left\|\; \sum_{J} x_i \;\right\|
\leq
\left\|\; \left(s - \sum_{J_\varepsilon} x_i \right) - \sum_J x_i \;\right\| +
\left\|\; s - \sum_{J_\varepsilon} x_i \; \right\|
\leq
2\varepsilon
\]

**** Toda Cauchy en un Hilbert es sumable
Si $\{x_i\}_{i \in I} \in H$ Hilbert verifica la condición de suma de Cauchy, 
es sumable.

***** Demostración
Primero tomamos la sucesión de Cauchy siguiente, que por complitud
del espacio es convergente:

\[
\left\{
\sum_{i \in J_{\frac{1}{n}}} x_i
\right\}
\longrightarrow
s
\]

Tenemos, para $J \supseteq J_{\frac{1}{n}}$, para $n$ suficientemente grande, que:

\[
\left\|\sum_{i \in J} x_i - s \right\| \leq
\left\|\sum_{i \in J} x_i - \sum_{i \in J_{\frac{1}{n}}} x_i \right\| +
\left\|\sum_{i \in J_{\frac{1}{n}}} x_i - s \right\| \leq 
\frac{1}{n} + \varepsilon
\]

Siendo por tanto sumable.

**** Numerabilidad de familias de Cauchy
Toda familia de Cauchy tiene $\{ i \in I \mid x_i \neq 0\}$ numerable.

***** Demostración
Si verifica Cauchy, para cada $n$ podemos tomar, $J_n$ tal que 
para $J \cap J_n =\varnothing$:

\[\left\| \sum_{J} x_i \right\| \leq \frac{1}{n}\]

Si tenemos un $x \notin J_n$ para todo $n$, debe cumplir $\|x\| < \frac{1}{n}$, luego $x = 0$.
Como $\bigcup_{n \in \mathbb{N}} J_n$ es numerable. El conjunto de elementos no nulos es 
numerable.

**** Sumable es esencialmente numerable
En un espacio normado cualquiera equivalen:

  1. $\{x_i\}_{i \in I}$ sumable.
  2. $I_0 = \{ i \in I \mid x_i \neq 0\}$ numerable y para toda biyección $G : \mathbb{N} \longrightarrow I_0$:

     \[\sum_{i \in I_0} x_i = \sum_{n \in \mathbb{N}} x_{G(n)}\]

***** Demostración
****** Primera implicación
Si es sumable cumple la condición de Cauchy y por tanto,
su conjunto de elementos no nulos es numerable.

Además, si suma $s$, fijado $\varepsilon$, tengo un conjunto finito $J$.
Como $\{0,1,\dots,\max_{j \in J}\{G(j)\},\dots,m\} \supseteq G(J)$, se tiene:

\[
\left\| s - \sum_{i=0}^m x_{G(i)} \right\| \leq \varepsilon
\]

Por lo que la suma converge a $s$ para cualquier biyección.

****** TODO Segunda implicación
# Me gustaría probar que la convergencia incondicional da la convergencia
# absoluta, y entonces usar directamente la convergencia absoluta para
# probar que es sumable.

**** Corolario: convergencia conmutativa
Cuando $I = \mathbb{N}$, ser sumable equivale a converger conmutativamente,
esto es:

\[
\sum_{k \in \mathbb{N}} x_k = \sum_{k \in \mathbb{N}} x_{\sigma k}
\]

***** Demostración
Por el [[*Sumable es esencialmente numerable][teorema]] anterior.

**** Corolario: suma de particiones
En $X$ Banach, $I = \bigcup_{\lambda \in \Lambda} I_\lambda$ partición arbitraria nos da que si $\{x_i\}_{i \in I}$
es sumable, $\{x_i\}_{i \in I_\lambda}$ es sumable; además:

\[ \sum_{i\in I} x_i = \sum_{\lambda \in \Lambda} \left(\sum_{i \in I_\lambda} x_i \right)\]

***** TODO Demostración

*** Familias absolutamente sumables
**** Familia absolutamente sumable
Una familia $\{x_i\}_{i \in I}$ es absolutamente sumable cuando $\{\|x_i\|\}_{i \in I}$ es sumable
en $\mathbb{R}^+$:

\[
\sup_{J \subseteq I} 
\left\{ 
\sum_J \|x_i\| \;\middle|\; J \text{ finito}
\right\} < \infty
\]

**** Criterio de Abel
Sea $X$ Banach, $\{x_i\}_{i \in I} \in X$ y $\|x_i\| < |\alpha_i|$ cumpliendo $\sum |\alpha_i| < \infty$. Entonces
$\{x_i\}$ es sumable con:

\[
\left\|\sum_{i \in I} x_i\right\| \leq \sum_{i \in I} |\alpha_i|
\]

***** TODO Demostración
**** Absolutamente sumable implica sumable
En particular, absolutamente sumable implica sumabilidad en Banach, con:

\[
\left\|\sum x_i\right\| \leq \sum \|x_i\|
\]

***** Demostración
Trivialmente desde el [[*Criterio de Abel][criterio de Abel]].

*** Familias ortonormales
**** Suma ortogonal
Sea $\{e_i\}_{i\in I}$ familia ortogonal en un espacio de Hilbert $H$. Entonces
$\{e_i\}_{i \in I}$ es sumable ssi $\{\|e_i\|^2\}_{i \in I}$ es sumable en $\mathbb{R}^+$, en cuyo caso:

\[
\left\| \sum_{i \in I} e_i \right\| = \sqrt{\sum_{i \in I} \|e_i\|^2}
\]

***** Demostración
Coinciden en cualquier suma finita:

\[
\left\|\; \sum_{i \in I} e_i \;\right\|^2 = \sum_{i \in I} \|e_i\|^2
\]

Por lo tanto, coinciden sobre la condición de Cauchy.

**** Corolario: suma ortogonal con coeficientes
Sea $\{e_i\}_{i \in I}$ familia ortonormal con $f : H \longrightarrow \mathbb{K}$ aplicación. Entonces
$\{f(e_i)e_i\}$ es sumable ssi $\{|f(e_i)|^2\}$ es sumable en $\mathbb{R}^+$; en cuyo caso:

\[
\left\| \sum_{i \in I} f(e_i) e_i \right\| =
\sqrt{\sum_{i \in I} |f(e_i)|^2}
\]

***** Demostración
Trivial desde lo anterior viendo $\{f(e_i)e_i\}$ como familia ortogonal.

**** Corolario: suma ortogonal con productos escalares
Sea $H$ Hilbert, $\{e_i\}_{i \in I}$ familia ortonormal. Para $u \in H$ se tiene que
$\{\langle u,e_i \rangle e_i\}$ es sumable ssi $\{|\langle u,e_i \rangle|^2\}$ es sumable en $\mathbb{R}^+$.

***** Demostración
Caso particular de lo [[*Suma ortogonal][anterior]] con $f(x) = \langle u,x \rangle$.

**** Desigualdad de Bessel
Sea $\{e_i\}_{i \in I}$ ortonormal en $H$ Hilbert, entonces existe la suma siguiente
y está acotada:

\[
\sum_{i \in I} |\langle u,e_i \rangle|^2 \leq
\|u\|^2
\]

***** Demostración
En el caso finito:

\[
0 \leq
\left\| u - \sum_{J} \langle u,e_i \rangle e_i \right\|^2 =
\|u\|^2 - \sum_J \langle u,e_i \rangle^2 - \sum_J |\langle u,e_i \rangle|^2  + \sum_{J} \langle u,e_i \rangle^2
\]

Por tanto:

\[\sum_J |\langle u,e_i \rangle|^2 \leq \|u\|^2\]

Pero como estamos estudiando sumabilidad en los reales, basta haber
encontrado una cota sobre el [[*Caracterización de familia sumable real][supremo]] para acotar la suma.

**** Corolario de Bessel
Sea $\{e_i\}_{i \in I}$ ortonormal en $H$ Hilbert, y sea $M$ el subespacio cerrado 
generado: $M = \overline{lin\{e_i \mid i \in I\}}$. Dado $u \in H$, la mejor aproximación de $u$ a $M$ 
es:

\[ \pi_M(u) = \sum_{i \in I} \langle u,e_i \rangle e_i
\]

En consecuencia se tiene:

\[
\|u\| 
= 
\sqrt{\;\sum_{i \in I} |\langle u,e_i \rangle|^2 + 
\left\|u - \sum_{i \in I} \langle u,e_i \rangle e_i\right\|^2\;}
\]

Y además, equivalen:

  1. \[u \in M\]
     
  2. \[u = \sum \langle u,e_i \rangle e_i\]
     
  3. \[\|u\|^2 = \sum_{i \in I} |\langle u,e_i \rangle|^2\]

***** Demostración
****** Existe la suma
Por desigualdad de Bessel, comprobando la igualdad de ambas sumas
en los casos finitos, tenemos que existe la suma:

\[
\left\|\; \sum_{i \in I} \langle u,e_i \rangle e_i \;\right\|= 
\sqrt{\sum_{i \in I} |\langle u,e_i \rangle|^2} \leq \|u\|
\]

Ya que es una suma de positivos acotada. Ambas sumas cumplen
la misma condición de [[*Corolario: suma ortogonal con productos escalares][Cauchy]].

****** Hay ortogonalidad
Tomamos $m = \sum_{i \in I} \langle u,e_i \rangle e_i$, y comprobamos que $u - m \in M^\perp$. Como la
familia ortonormal genera el espacio, basta comprobar que es 
ortonormal a ella:

\[
\langle u-m,e_k \rangle = 0
\]

Por tanto, tenemos una descomposición $u = m + (u-m)$ y por teorema
de la [[*Teorema de la proyección ortogonal][proyección ortogonal]], $m$ es la mejor aproximación, y se tiene
la igualdad dada.

****** Equivalencias
Cuando $u \in M$, él mismo es su mejor aproximación y su norma puede
calcularse directamente. La igualdad de normas implica que la
norma de $u-m$ sea $0$, haciendo $u \in M$.
**** Existencia de familias ortonormales maximales
Existen sistemas ortonormales maximales.

***** Demostración
Lema de Zorn.

**** Caracterización de bases ortonormales
En $H$ Hilbert equivalen:

  1. $u = \sum \langle u,e_i \rangle e_i$ para cualquier $u$.
  2. $\langle u,v \rangle = \sum \langle u,e_i \rangle \langle e_i,v \rangle$, identidad de Parseval.
  3. $\|u\|^2 = \sum_{i \in I} |\langle u,e_i \rangle|^2$.
  4. $\{e_i\}$ sistema ortonormal maximal.
  5. $\forall e_i : v \perp e_i \implies v =0$.
  6. $H = \overline{lin\{e_i\}}$

***** Demostración
Directamente desde el corolario de Bessel en el caso de $M$ denso,
donde no hay ningún ortonormal a él. Podemos comprobar la implicación
en cada uno de los puntos.

*** Bases de Hilbert
**** Base de Hilbert
Se llama base de Hilbert a una familia ortonormal maximal.

***** Desarrollo en serie de Fourier
Una familia ortonormal maximal debe tener un subespacio cerrado
generado que sea [[*Corolario: caracterización de la densidad][denso]], ya que si no fuera así, tendría un $M^\perp$ no 
nulo. Por tanto cumple el corolario a Bessel y se tiene:

\[ u = \sum_{i \in I} \langle u,e_i \rangle e_i\]

llamada *Serie de Fourier*.

**** Dimensión Hilbertiana
El cardinal de las bases de Hilbert de un espacio es inveriante y
se llama *dimensión Hilbertiana*.

***** Demostración
[[http://math.stackexchange.com/questions/232166/showing-the-basis-of-a-hilbert-space-have-the-same-cardinality][Showing the basis of a Hilbert Space have the same cardinality]].

**** Isomorfía entre espacios de igual dimensión
Dos espacios de Hilbert con la misma dimensión Hilbertiana son
topológicamente isomorfos.

***** Demostración
Dado un isomorfismo entre las bases, definimos la aplicación lineal
que extiende el isomorfismo. Por el desarrollo en serie de Fourier,
sabemos que es equinórmica y por tanto continua.

Por el Teorema de los [[*Teorema de los isomorfismos de Banach][isomorfismos de Banach]], son isomorfos 
topológicamente.

*** Operadores adjuntos
**** Operadores adjuntos
Dado $T \in L(H_1,H_2)$ entre espacios de Hilbert, existe:

\[\exists! T^\ast \in L(H_2,H_1):  \langle Tx,y \rangle = \langle x,T^\ast y\rangle\]

Llamado el *operador adjunto*.

***** Demostración
Por Riesz-Fréchet, tenemos una aplicación $T^\ast y$ única cumpliendo:

\[\langle T \cdot, y \rangle = \langle \cdot , T^\ast y \rangle\]

****** Es lineal
La función es lineal ya que, aplicando unicidad de Riesz-Fréchet:

\[
\langle \cdot, T^\ast( \alpha y + y') \rangle =
\langle T \cdot, \alpha y + y' \rangle =
\overline{\alpha} \langle T \cdot, y \rangle + \langle T \cdot, y' \rangle =
\langle \cdot, \alpha T^\ast y + T^\ast y' \rangle
\]

****** Es continuo
La continuidad se tiene por acotación en la bola unidad:

\[
\| T^\ast y \|^2 \leq \|y\| \|TT^\ast y\| \leq \|T\| \|T^\ast y\|
\]

**** Propiedades de operadores adjuntos
Los adjuntos cumplen:

  1. $T^{\ast\ast} = T$.
  2. $\|T\| = \|T^\ast\| = \|TT^\ast\|^{1/2} = \|T^\ast T\|^{1/2}$.
  3. $(T_1+T_2)^\ast = T_1^\ast+T_2^\ast$
  4. $(\alpha T)^\ast = \overline{\alpha}T^\ast$.
  5. $(RT)^\ast = T^\ast R^\ast$.

***** Demostración
****** Punto 1
Aplicando unicidad de Riesz-Frechet a:

\[\overline{\langle y, T\cdot \rangle} = \overline{\langle y, T^{\ast\ast} \cdot \rangle}\]

****** Punto 2
Tenemos $\|T\| = \|T^{\ast\ast}\| \leq \|T^\ast\| \leq \|T\|$, como acotamos anteriormente.

Además, tenemos doble acotación para los dos operadores:

\[\|TT^\ast\| \leq \|T\|\|T^\ast\| = \|T\|^2\]
\[\|Tx\|^2 \leq \|x\|^2 \|TT^\ast\|\]

****** Puntos 3, 4 y 5
Trivialmente por linealidad, usando la unicidad de Riesz-Frechet.

**** Relación con el adjunto
Sea $T \in L(H,H)$; se cumple:

  1. $\ker T^\ast = T(H)^\perp$.
  2. $\ker T = T^\ast(H)^\perp$.
  3. $T^\ast$ inyectivo $\iff$ $T(H)$ denso.

***** Demostración
****** Punto 1 y 2
Trivial por doble inclusión y por reflexividad del adjunto.

****** Punto 3
Uniendo las condiciones de densidad y ortogonalidad con la 
caracterización de inyectividad por núcleo nulo.

**** Operador autoadjunto
Un operador $T \in L(H,H)$ es autoadjunto si $T^\ast = T$.

**** Propiedades de los autoadjuntos
Para $T \in L(H)$:

  1. $TT^\ast,T^\ast T, T+T^\ast$ son autoadjuntos.
  2. $T$ autoadjunto da $\alpha T$ autoadjunto.
  3. $\{ T = T^\ast\}$ es cerrado.
  4. Todo operador se divide en dos partes real e imaginaria:

     \[R = \frac{T+T^\ast}{2}\qquad S = \frac{T-T^\ast}{2}\]

*** Espectro y operadores compactos
**** Espectro
El espectro de un operador es el conjunto de valores propios,
llamamos:

***** Espectro

\[G(T) = \{\lambda \in \mathbb{C} \mid T - \lambda I \mbox{ invertible}\}\]

***** Espectro puntual

\[
G_p(T) =
\{
\lambda \in \mathbb{C} 
\mid
T - \lambda I \text{ no inyectivo}
\}
\]

***** Espectro comprimido

\[G_{com}(T) 
= 
\{\lambda \in \mathbb{C} \mid T - \lambda I \mbox{ con imagen no densa}\}
\]

***** Espectro aproximado

\[G_{ap}(T) =
\{\lambda \in \mathbb{C} \mid T-\lambda I \mbox{ no acotado por debajo}\}
\]

***** Relación
Equivalen ser invertible a tener imagen densa y estar acotado por 
debajo. Así,

\[G(T) = G_{com}(T) \cup G_{ap}(T)\]

Además, en *dimensión finita* y en compactos, equivalen inyectividad, 
sobreyectividad y biyectividad, luego:

\[G(T) = G_p(T)\]

****** TODO Demostración

**** Rango de un operador
El rango de $T$ es $n$ cuando puede escribirse con $u_i,w_i \in H$:

\[T = \sum u_i \otimes w_i\]

Es decir, como una matriz finita de ese rango.

***** Operadores de rango finito son compactos
Los operadores de rango finito son compactos.

****** Demostración
En dimensión finita las bolas son compactas. Al ser continuo,
la sucesión imagen es siempre acotada y con parcial convergente.

**** Operador compacto
Si $T \in L(H)$ es compacto si para cualquier acotada, la $\{T(u_n)\}$ tiene
una parcial convergente.

***** Caracterización de compactos
Un $T$ es compacto ssi $T(\overline{B(0,1)})$ es compacto.

***** Compactos como límite de los de rango finito
Los operadores de rango finito son compactos. De hecho, son su clausura.
Si tenemos:

 - \[KL(H) = \{T: H\longrightarrow H \mid \mbox{ compacto}\}\]
 - \[FL(H) = \{T : H\longrightarrow H \mid \mbox{ rango finito}\}\]

Se cumple $\overline{FL(H)} = KL(H)$.

****** TODO Demostración

***** El adjunto de un compacto es compacto
Si tenemos $T = \lim T_n$, con $T_n = \sum u_i \otimes w_i$. Podemos comprobar que
el adjunto es límite de $T_n^\ast = \overline{\sum w_i \otimes u_i}$, de rango finito.

**** Teorema de la aplicación espectral
Para $H$ Hilbert, un polinomio no constante puede aplicarse a operadores
para tener:

\[G(p(T)) = \{p(\lambda) \mid \lambda \in G(T)\}\]

**** Teorema del núcleo
Si $T \in L(H)$ compacto, $\ker(T - \lambda I)$ tiene dimensión finita.

***** TODO Demostración
**** Teorema del rango
Si $T \in L(H)$ compacto, $\im(T-\lambda I)$ es cerrado.

***** TODO Demostración
**** Biyectividad en compactos
Si $T \in L(H)$ compacto, para $\lambda \neq 0$, $T-\lambda I$ es inyectivo ssi es 
sobreyectivo ssi es biyectivo.

\[G(T) \setminus \{0\} 
=
G_p(T) \setminus \{0\}
= 
G_{ap}(T) \setminus \{0\}
\]

**** Alternativa de Fredholm
Sea $T \in L(H)$ compacto y $\lambda \neq 0$. Consideramos las ecuaciones:

  1. $(T - \lambda I)x = 0$.
  2. $(T^\ast - \overline{\lambda} I)z = 0$.
  3. $(T-\lambda I)x = y$.
  4. $(T^\ast - \overline{\lambda} I)z = w$.

Y sabemos que se cumple una de estas dos alternativas:

  - O bien $x=0,z=0$ son las únicas soluciones de 1 y 2; en
    cuyo caso 3 y 4 tienen solución única, que además depende 
    continuamente.
  - O bien hay soluciones no nulas de 1 y 2 y entonces 3 tiene
    solución si $y \perp \ker(T^\ast - \overline{\lambda} I)$ y 4 tiene solución si $w \perp \ker(T-\lambda I)$.

***** Alternativamente
En resumen, para $T$ compacto:

  - $img(T - \lambda I) = \ker(T^\ast - \lambda I)^\perp$.
  - $img(T^\ast - \lambda I) = \ker(T-\lambda I)^\perp$.

Y si uno es nulo ambos lo son.

***** Demostración
****** Caso sin valor propio
Si $\lambda \notin G(T)$, entonces es invertible, así como su adjunta.

****** Caso con valor propio
Si $\lambda \in G(T)$, entonces $\ker(T-\lambda I) \neq 0$ y $\ker(T^\ast-\lambda I) \neq 0$, porque
para compactos coinciden los espectros. Se tiene además:

  - $y \in img(T - \lambda I) = (\ker(T^\ast-\lambda I)^\perp)$
  - $w \in img(T^\ast - \lambda I) = (\ker(T-\lambda I)^\perp)$

**** Diagonalización de autoadjuntos compactos
Sea $T \in L(H)$, compacto y autoadjunto, entonces es *diagonalizable*.
Hay una base ortonormal con \[\lambda_n \longrightarrow 0\] de vectores propios, teniendo
convergencia uniforme sobre los compactos:

\[Tu = \sum \lambda_i \langle u,e_i \rangle e_i\]

Teniendo $G_p(T) \setminus \{0\} = \{\lambda_1,\dots,\lambda_n\}$, y coincide la dimensión del 
espacio propio y el número de veces que aparece $\lambda_i$.

*** Extra
**** Extra: El espectro de un autoadjunto es real
**** Extra: El espectro del adjunto es el conjugado en caso finito
***** Contraejemplo caso infinito
Pero en el caso general no. Un ejemplo es el siguiente:

\[
T(a_1,a_2,\dots) = (a_2,a_3,\dots)
\]

Que tiene cualquier valor en el espectro mientras su adjunto
no tiene ningún valor propio.

**** Extra: En el caso finito, el adjunto es la conjugada de la traspuesta
**** Extra: [[https://en.wikipedia.org/wiki/Spectral_theorem][Teorema espectral]]
** Ejercicios
*** 1. Espacios normados
**** Ejercicio 3
La sucesión no puede tener ninguna parcial convergente a $0$, porque si no, 
al ser de Cauchy, convergería a $0$. Por tanto, a partir de un cierto $n$, 
todos los términos deben alejarse de $0$ más de un determinado $\alpha$.

Sean ahora $\|x - y\| \leq \epsilon$, por desigualdad triangular inversa tenemos:

\[ \bigg|\|x\|-\|y\|\bigg| \leq \|x-y\| \leq \epsilon\]

Y por tanto:

\[1 - \frac{\epsilon}{\|x\|} \leq \frac{\|x\|}{\|y\|} \leq 1 + \frac{\epsilon}{\|x\|}\]

Ahora, por otro lado, comprobaremos que podemos demostrar a la función 
$f(x) = \frac{x}{\|x\|}$ uniformemente continua:

\[ 
\bigg| \frac{x}{\|x\|} - \frac{y}{\|y\|} \bigg| =
\frac{1}{\|x\|} \|(x-y) + \left(1 - \frac{\|x\|}{\|y\|}y\right) \leq
\frac{\epsilon}{\|x\|} + \frac{\|y\|}{\|x\|} \left|1-\frac{\|x\|}{\|y\|}\right|
\]

Pero como tenemos acotaciones uniformes de $\|x\|^{-1}$ y de $\frac{\|y\|}{\|x\|}$, hemos 
terminado.
**** Ejercicio 4
#+begin_statement
Sea $X$ espacio normado. Probar que equivalen:

  1. $X$ completo.
  2. $B_X$ completo.
  3. $S_X$ completo.
#+end_statement

***** Primera y segunda implicaciones
Cerrados dentro de un completo.

***** Tercera implicación
Sea $\{x_n\}$ una sucesión de Cauchy. Descartamos el caso $\{\|x_n\|\} \longrightarrow 0$, 
que lleva a la convergencia a $0$. Podemos asumir $\|x_n\| \geq 0$ para
alguna cola de la sucesión.

La sucesión $\left\{\frac{x_n}{\|x_n\|}\right\}$ es de Cauchy (puede comprobarse acotando en el
caso en el que hemos descartado el $0$). Por tanto converge. Nótese
que las normas también son de Cauchy y también convergen. Así,
podemos escribir un $x/\|x\|$ al que converja la sucesión sobre $S_X$.

La distancia de cada elemento queda acotada por la distancia sobre
la bola unidad y la distancia en norma:

\[
\|x_n-x\| \leq
\|x_n\| 
\left( 
\left\| \frac{x_n}{\|x_n\|} - \frac{x}{\|x\|} \right\| +
\left\| \frac{x}{\|x\|} - \frac{x}{\|x_n\|} \right\|
\right)
\leq
\varepsilon
\]

El teorema es que si algo converge en la bola unidad y converge en
norma a distinto de $0$, converge a eso.

**** Ejercicio 7
#+begin_statement
Probar que, en un espacio normado, el interior de un subespacio
vectorial propio es vacío.
#+end_statement

Simplemente notando que si $B(m,r) \subseteq M$, entonces $B(0,1) \subseteq M$, y eso
lleva a $X = M$.

**** Ejercicio 16
***** Punto a
     Es de hecho una isometría por tenerse: 

     \[\|Tx\| = \left(\sum_{n=0} |Tx_n|^p\right)^{1/p} = 
     0 + \left(\sum_{n=1} |x_n|^p\right)^{1/p} =
     \|x\|\]

     Así que es continua y su norma es $1$.

***** Punto b
     Vemos que es lipschitziana trivialmente con $\|Tx\| \leq \|x\|$. Como además realiza la cota
     sobre la bola unidad al tener: $\|T(0,1,0,\dots)\| = \|(1,0,\dots)\| = 1$.

***** Punto c
     Vemos que es isometría $\|Tx\| = \|x\|$, por lo que es continua y de norma $1$.
*** 2. Hahn-Banach
**** Ejercicio 1
#+begin_statement
Sea $X$ espacio vectorial sobre $\mathbb{K}$, y sean $p_1,p_2 : X \longrightarrow \mathbb{R}$ seminormas.
Probar que si $f : X \longrightarrow \mathbb{K}$ es un funcional lineal verificando que 
$|f(x)|\leq p_1(x)+p_2(x)$ para todo $x\in X$, entonces existen $f_1,f_2 : X\longrightarrow\mathbb{K}$
funcionales lineales tales que $f = f_1+f_2$, y $|f_1(x)|\leq p_1(x)$, $|f_2(x)|\leq p_2(x)$
para todo $x\in X$.
#+end_statement

Sobre el espacio $X \times X$ definimos una seminorma desde las
dos seminormas anteriores:

\[ p(x,y) = p_1(x) + p_2(x)\]

Por otro lado, consideramos el subespacio diagonal:

\[ \Delta = \{(x,x) \mid x \in X\} \]

Y definimos sobre él un funcional lineal:

\[ h(x,x) = f(x) \leq p(x,y)\]


Ahora, podemos aplicar Hahn-Banach para obtener una extensión
de $h$ definida para todo el espacio cumpliendo:

\[ |h(x,y)| \leq p(x,y)\]

Ahora, si definimos $f_1(x) = h(x,0)$ y $f_2(x) = h(0,x)$, las 
desigualdades se obtienen trivialmente desde la anterior.

**** Ejercicio 2
#+begin_statement
Sean $X$ un espacio normado, $M$ un subespacio vectorial de $X$, y
$u \in X$. Probar que existe $f \in X^\ast$ tal que $|f(x)| \leq dist(x,M)$ para todo
$x \in X$ y $f(u) = dist(u,M)$.
#+end_statement

Sobre el espacio $\langle u \rangle$ definimos el funcional $g(x) = dist(x,M)$, que es
lineal y continuo. Y por otro lado, definimos la seminorma $p(x) = dist(x,M)$
en todo el espacio. Por Hahn-Banach, existe un funcional que extiende
a $g$ y que cumple además:

\[ |f(x)| \leq dist(x,M) \]

**** Ejercicio 3
#+begin_statement
Para cada $n \in \mathbb{N}$, sea $T_n : \ell_\infty \longrightarrow \mathbb{K}$ definido por $T_n(x) = \frac{1}{n}(x_1+\dots+x_n)$.
Sea $M = \{x \in \ell_\infty : \{T_n(x)\}\text{ converge} \}$ y definamos $T(x) = \lim\{T_n(x)\}$ sobre él.

 1. Probar que $T_n \in (l_\infty)^\ast$ y que $\|T_n\| = 1$ para todo $n \in \mathbb{N}$.
 2. Probar que $M$ es un subespacio vectorial de $\ell_\infty$ que contiene al espacio
    $c$ de las sucesiones convergentes.
 3. Probar que $T \in M^\ast$ con $\|T\| = 1$ y que $T(x) = \lim\{x_n\}$ para todo $x \in c$.
 4. Sea $\tau(x) = (x_2,x_3,\dots)$ para todo $x \in l_\infty$. Probar que 
    $x - \tau(x) \in \ker(T) \subseteq M$ para todo $x \in l_\infty$.
 5. Deducir que existe $S \in (l_\infty)^\ast$, extensión de $T$ tal que $\|S\| = 1$ y
    $S(x) = S(\tau^n(x))$ para todo $x \in l_\infty$ y para todo $n \in \mathbb{N}$.
 6. Probar que $S(0,\frac{1}{2},0,\frac{1}{2},\dots) = \frac{1}{4}$.
#+end_statement

***** Punto 1
Tenemos que demostrar que es lineal y continua. Pero sabemos
que es suma y multiplicación por escalar de las proyecciones, que
lo son. Por otro lado, por desigualdad de las medias sabemos:

\[ \frac{1}{n}(x_1+\dots+x_n)
\leq \max\{x_1,\dots,x_n\}
\leq \|x_n\|_\infty\]

Por tanto $x \in B_{\ell_\infty}$ implica $T(x) \leq 1$. Y la desigualdad se realiza
en el caso $(1,1,1,\dots)$.

***** Punto 2
Tenemos que es subespacio vectorial porque si $T_n(x)$ y $T_n(y)$ convergen,
también lo hace $T_n(x+\alpha y) = T_n(x) + \alpha T_n(y)$ por ser lineal.

***** Punto 3
El $T$ es el límite puntual de los $T_n$. Por teorema del cierre de
Steinhaus, $T$ es lineal y continuo. Veamos que tiene norma unidad.
Por desigualdad de las medias la norma no puede ser mayor que $1$.
Tenemos para $x \in S_M$:

\[ T_n(x) \leq 1 \Rightarrow T(x) \leq 1\]

Y además, para $u = (1,1,1,\dots)$ se tiene que $T_n(u) \to 1 = T(u)$.

***** Punto 4
Se ve que está en el núcleo.

***** Punto 5
Por extensión equinórmica de Hahn-Banach.

***** Punto 6
Sale desde la $T$.

**** Ejercicio 4
#+begin_statement
Fijado $n \in \mathbb{N}$, probar que existe un funcional lineal y continuo $f$ en
${\cal C}[0,1]$ tal que $f(p) = p'(0)$ para todo polinomio $p$ de grado menor o igual
que $n$. Probar que no existe un funcional lineal y continuo $f$ en ${\cal C}[0,1]$
tal que $f(p) = p'(0)$ para todo polinomio $p$.
#+end_statement

Fijado $n \in \mathbb{N}$ podemos crear una base del subespacio de polinomios
de grado menor o igual que $n$ y definir un $f$ sobre ella que cumple
lo pedido. Por Hahn-Banach, lo extenderemos a todo ${\cal C}[0,1]$. Es decir,

\[ \{1,x,x+x^2,x+x^3,\dots,x+x^n\} \overset{f}\longrightarrow \{0,1,1,\dots,1\}\]

Supongamos que existiera el funcional que lo cumple para todo polinomio.
Comprobamos que no es continuo, ya que si lo fuera debería dejar acotada
la bola unidad. Sin embargo tenemos,

\[ \frac{d}{dx}(x-1)^n|_{x=0} = n\]

Mientras que $(x-1)^n \leq 1$ para $x \in [0,1]$; lo que nos da $\|(x-1)^n\| \leq 1$.

**** Ejercicio 5
#+begin_statement
Sean $X$ un espacio normado y $M$ un subespacio vectorial de $X$. Probar que 
para cada $T \in L(M,l_\infty)$, existe $S \in L(M,l_\infty)$ tal que $S|_M = T$ y $\|S\| = \|T\|$.
#+end_statement

Si aplico la extensión equinórmica a cada una de las $\pi_i \circ T$, obtenemos
funciones $S_i \in X^\ast$ que extienden $T$ y tienen su misma norma. Ahora, la
función $S(x_1,x_2,\dots) = (S_1(x_1),S_2(x_2),\dots)$ es continua y lineal por serlo por
componentes; su restricción a $M$ es trivialmente $T$, y además, su
norma debe ser:

\[ \|S\| = \max\{ (S_1(x_1),S_2(x_2),\dots) \mid x \in B_X\} 
         = \max\{ \|S_1\|, \|S_2\|, \dots\} = \|T\| \]

**** Ejercicio 6
#+begin_statement
Sean $A$ y $B$ subconjuntos no vacíos, abiertos, convexos y disjuntos de un 
espacio normado $X$. Probar que existen $f \in X^\ast$ con $\|f\| = 1$ y $\alpha \in \mathbb{R}$ tales
que $Re(f(a)) < \alpha < Re(f(b))$ para todo $a \in A$ y $b \in B$. Mostrar con un ejemplo
que, en general, no es posible encontrar $f$ tal que 
$\sup Re(f(A)) < \inf Re(f(B))$.
#+end_statement

Por el lema de separación de convexos tenemos que existen con
$\|f\|$ no necesariamente $1$. Dividiendo por la norma obtenemos el $f$
buscado.

Podemos tomar $A$ y $B$ como los dos semiplanos de $\mathbb{R}^2$ dados por
$\{x > 0\}$ y por $\{x < 0\}$. Por continuidad de $f$ se tendría que:

$\sup Re(f(A)) \geq f(0) \leq \inf Re(f(B))$

Por lo que se tendría la igualdad.
*** 3. Teoremas fundamentales
**** Ejercicio 2
#+begin_statement

#+end_statement
**** Ejercicio 3
#+begin_statement
Sean $X$ e $Y$ espacios de Banach y $T : X\longrightarrow Y$ una aplicación lineal y 
continua. Probar que $T$ es inyectiva y $T(X)$ es cerrado en $Y$ si y sólo
si, existe $m > 0$ tal que $\|T(x)\| \geq m \|x\|$ para todo $x \in X$.
#+end_statement

***** TODO Primera implicación
Si $T$ es inyectiva y además $TX$ es cerrado en $Y$, entonces tenemos
que es un monomorfismo topológico.

Si tomamos $\| x \|_2 = \|T x\|$, podemos observar que es norma porque cumple
la desigualdad triangular y la inyectividad nos da la condición en
$0$.

***** Segunda implicación 
Si tenemos que se cumple lo segundo, el núcleo es trivial porque
para todo $x \neq 0$, se tiene $\|T(x)\| \geq m \|x\| > 0$. Es inyectiva.

Ahora, como $T$ es inyectiva la aplicación $T : X \longrightarrow TX$ es
biyectiva, luego es isomorfismo topológico por el teorema de los
isomorfismos de Banach. Por el teorema del homomorfismo de
Banach, $TX$ es cerrado.

**** Ejercicio 4
#+begin_statement
Sea $M$ un subespacio cerrado de $l_p$ y de $l_q$. Probar que las normas inducidas
en $M$ por $l_p$ y $l_q$ son equivalentes.
#+end_statement

Tenemos $M$ un espacio normado y cerrado dentro de Banach, luego Banach.
Dentro de este espacio podemos usar equivalencia de normas en espacios
de Banach para tener que ambas son equivalentes a la norma inducida por
la norma del máximo.

\[ \| x\|_p 
= \sqrt[p]{\sum^\infty x_i^p} 
\geq \sqrt[p]{\max\{x_i\}^p}
= \| x\|_\infty \]

**** Ejercicio 5
#+begin_statement
Sean $X,Y$ espacios de Banach, y $A \subset Y^\ast$ tal que $A$ separa los puntos de $Y$.
Probar que si $T : X \longrightarrow Y$ es una aplicación lineal tal que $f \circ T \in X^\ast$ para
todo $f \in A$, entonces $T$ es continua.
#+end_statement

Comprobaremos que la gráfica de $T$ es cerrada, y por teorema de la gráfica
cerrada, tendremos que es continua. Sean $(x_i,Tx_i) \to (x,y)$; si fueran
distintos tendríamos que existe alguna función en $A$ que separe $f(y) \neq f(Tx)$.

Pero como $f \circ T$ es continua y $f$ es continua, tenemos:

\[ f(T(x_i)) \longrightarrow f(T(x))\]
\[f(Tx_i) \to f(y)\]

Por lo que deben ser iguales, contraviniendo separación.

**** Ejercicio 6
#+begin_theorem
Sea $X$ un espacio de Banach real. Dada una aplicación lineal 
$T: X \longrightarrow L_1([0,1])$ se considera, para cada $A \subset [0,1]$ medible, el funcional
lineal $T_A : X \longrightarrow \mathbb{R}$ definido por:

\[ T_A(x) = \int_A T(x)\]

Probar que si $T_A \in X^\ast$ para todo $A \subset [0,1]$ medible, entonces $T$ es continua.
#+end_theorem

***** Familia de funcionales que separan
Definimos $i_A \in L_1[0,1]^\ast$ para cualquier $A \subset [0,1]$ medible como:

\[ i_A(f) = \int_A f \]

Y comprobamos que separa las funciones de $L_1[0,1]$, ya que si dos funciones
integran igual en cualquier conjunto medible, su diferencia integra $0$ en
todo conjunto medible. Cuando esto ocurre, si fuera distinta de $0$ en un
conjunto de medida no nula, sería mayor que algún $\varepsilon$ en un conjunto de medida
no nula, luego su integral no sería nula.

***** Desarrollo
Ahora aplicamos el ejercicio anterior, siendo $i_A$ la familia que separa
los puntos de $L_1[0,1]$. Como $i_A \circ T$ son todas lineales continuas, entonces
$T$ es continua.

**** Ejercicio 7
#+begin_statement
Sean $X$ un espacio de Banach sobre $\mathbb{K}$ e $I$ un conjunto no vacío. Dada una
aplicación lineal $T: X \longrightarrow l_\infty(I)$ se considera, para cada $i \in I$, el funcional
lineal $T_i : X \longrightarrow \mathbb{K}$ definido por:

\[ T_i(x) = T(x)(i)\]

Probar que si $T_i \in X^\ast$ para todo $i \in I$, entonces $T$ es continua.
#+end_statement

***** Familia de funcionales que separan
Llamamos $e_i \in l_\infty(I)^\ast$ a los funcionales lineales continuos siguientes,
definidos para cada $i \in I$:

\[ e_i(x) = x(i) \]

Trivialmente, si $x \neq y$, deben ser distintas en algún $x(i) \neq y(i)$.

***** Aplicación del ejercicio anterior
Aplicamos el [[*Ejercicio 5][ejercicio anterior]] sabiendo $l_\infty(I)$ de Banach. Como
$e_i \circ T$ es siempre continua, se tiene $T$ continua.

**** Ejercicio 8
#+begin_statement
Sean $X$ un espacio de Banach real y $T : X \longrightarrow C([0,1],\mathbb{R})$ una aplicación
lineal. Se considera, para cada $n \in \mathbb{N} \cup \{0\}$, el funcional lineal 
$T_n : X \longrightarrow \mathbb{R}$ definido por:

\[ T_n(x) = \int_0^1 t^n T(x)(t) dt\]

Probar que si $T_n \in X^\ast$ para todo $n \in \mathbb{N} \cup \{0\}$, entonces $T$ es continua.
#+end_statement

***** Separación
Definimos los $e_n$ para cada natural como:

\[ e_n(f) = \int_0^1 t^n f(t) dt\]

Si una función fuera nula bajo todos los $e_n$ debería ser ortogonal
a todos los polinomios, que son densos en $C([0,1],\mathbb{R})$; por lo que
debería ser $0$ casi por doquier.

**** Ejercicio 9
#+begin_statement
Sean $X$ un espacio de Banach, $A \subset X$ tal que $X = \overline{Lin(A)}$, y $\{f_n\}$ una
sucesión de elementos de $X^\ast$. Probar que equivalen:

 1. $\{f_n(x)\} \longrightarrow 0$ para todo $x \in X$
 2. $\sup \{ \|f_n\| \mid n \in \mathbb{N} \} < \infty$ y $\{f_n(a)\} \longrightarrow 0$ para todo $a\in A$.
#+end_statement

***** Primera implicación
Los $f_n$ forman una familia de operadores acotada puntualmente. Aplicando
el Teorema de Banach-Steinhaus a $X$ Banach, sabemos que debe estar 
acotada. Particulariza para los elementos de $a \in A$.

***** Segunda implicación
La convergencia a cero se mantiene por combinaciones lineales finitas,
así que se tiene para cualquier $a \in Lin(A)$. Ahora, para $b \in \overline{Lin(A)}$, 
sea $a_n \longrightarrow b$; tenemos:

\[ \|f_n(b)\| 
\leq \|f_n(b - a_m)\| + \|f_n(a_m)\|
\leq M \|b - a_m\| + \|f_n(a_m)\| \to 0
\]

Puedo tomar un $m$ que haga suficientemente pequeño el primer sumando
y luego tomar un $n$ que haga suficientemente pequeño el segundo.

**** Ejercicio 10
#+begin_statement
Sea $\{x_n\}$ una sucesión de escalares tal que la serie $\sum x_n y_n$ es convergente
para toda sucesión $\{y_n\} \in c_0$. Probar que $\{ x_n \} \in l_1$.
#+end_statement

Definimos los funcionales $f_n \in c_0^\ast$ tales que:

\[ f_n(\{y_i\}) = \sum^n_{k=0} |x_k|y_k \leq \sum^\infty_{k=0} x_k \left(y_k \frac{x_k}{|x_k|} \right)\]

Donde usamos que si $y_k$ es convergente a $0$ también lo será si la 
multiplicamos por escalares de valor absoluto $1$.

Como están acotados puntualmente, se tiene por Banach-Steinhaus que están
acotados. Esto es:

\[ \sup\left\{ \sum^n_{k=0} |x_k|y_k \middle| \|\{y_i\}\|_\infty = 1 \right\} 
= M < \infty\]

Y ahora, tenemos que las sucesiones con los $n$ primeros términos iguales
a $1$ y el resto nulos, están en la bola unidad y hacen que:

\[ \sum^n_{k=1} |x_k| \leq M < \infty\]

Dando así,

\[ \sum^\infty_{k=1} |x_k| < \infty\]

**** Ejercicio 11
#+begin_statement
Sea $\{x_n\}$ una sucesión de escalares tal que la serie $\sum x_ny_n$ es convergente 
para toda sucesión $\{y_n\} \in l_1$. Probar que $\{x_n\} \in l_\infty$.
#+end_statement

Tenemos funcionales $f_n \in l_1^\infty$ definidos como:

\[ f_n(\{ y_n \}) = \sum_{k=0}^n x_ky_k \leq \sum_{k=0}^\infty x_ky_k < \infty \]

Que por estar acotados puntualmente y ser $l_1$ un espacio de Banach, se
tiene por Banach-Steinhaus que están acotados. Esto es:

\[ \sup\left\{ \sum^n_{k=0} x_ky_k \middle| \|\{y_i\}\|_\infty = 1 \right\}
= M < \infty\]

En particular, si tomamos $g_i$ sucesiones con todos los elementos
nulos pero $g_{ii} = \frac{\overline{x_i}}{|x_i|}$, como $g_i \in \mathbb{S}_{l_\infty}$ tenemos que:

\[ |x_i| < \| f_n(g_n) \| \leq M \]

Teniéndose así que $|x_i|$ está acotada.

**** Ejercicio 12
#+begin_statement
Sea $\{x_n\}$ una sucesión de escalares tal que la serie $\sum x_ny_n$ es
convergente para toda sucesión $\{y_n\} \in l_p$ $(1<p<+\infty)$. Probar
que $\{x_n\} \in l_q$, siendo $\frac{1}{p} + \frac{1}{q} = 1$.
#+end_statement

Tomamos los funcionales $f_n \in l_p^\ast$ definidos por:

\[f_n(\{y_k\}) = \sum_{k=0}^n x_ky_k < \sum_{k=0}^\infty x_ky_k \]

Que están acotados y vienen de espacio de Banach, por lo que, por
Banach-Steinhaus, se tiene que:

\[ \sup\left\{ \|f_n\|_p \right\}
= M < \infty\]

Por desigualdad de Hölder, tenemos una cota para la norma de los
operadores, sea $\{y_i\} \in S_{l_p}$:

\[ \|f_n\| \leq \sum^{n}_{k=0} |x_k||y_i| \leq \left(\sum^n_{k=0} |x_k|^q\right)^{1/q} \| \{y_i\}\|_p
 = \left(\sum^n_{k=0} |x_k|^q\right)^{1/q} \]

Y comprobamos que se realiza tomando el vector siguiente:

\[
\frac{1}{\left( \sum^n_{k=0} |x_k|^q \right)^{1/p}}
( |x_1|^{q-1}, |x_2|^{q-1}, \dots, |x_n|^{q-1}, 0,0,\dots )
\]

Que tiene imagen de norma:

\[ \left( \sum_{k=0}^n |x_k|^q  \right)^{1/q}\]

Mientras que él tiene norma $1$.

*** 4. Espacios de Hilbert I
**** Ejercicio 2
#+begin_statement
Demuéstrese que si $H$ es un espacio prehiilbertiano respecto de dos productos
escalares $\langle \cdot,\cdot\rangle_1$ y $\langle \cdot,\cdot\rangle_2$ entonces ambos productos coinciden salvo conjugación
ssi sus normas asociadas coinciden.
#+end_statement

***** Si coinciden, coinciden las normas
Si llamamos a las normas $\|\cdot\|_1$ y $\|\cdot\|_2$, tenemos:

\[\|u\|_1 = \sqrt{\langle u,u \rangle_1} 
= \sqrt{\overline{\langle u,u \rangle_2}} = \|u\|_2\]

Donde usamos que el producto escalar es hermítico.

***** Si coinciden las normas, coinciden
# ¿Por qué salvo conjugación?
Por la identidad de polarización, tenemos:

\[
\langle u,v \rangle_1 = 
\frac{1}{4}\left( \|u+v\|^2-\|u-v\|^2+i\|u+iv\|^2-i\|u-iv\|^2 \right) =
\langle u,v \rangle_2
\]

**** Ejercicio 3
#+begin_statement
Sea $H$ un espacio prehilbertiano real. Probar que si $\|u+v\|^2 = \|u\|^2+\|v\|^2$,
entonces $u$ y $v$ son ortogonales. ¿Se verifica esta propiedad en todo espacio
prehilbertiano complejo?
#+end_statement

En un espacio real, esto implica $2\langle u,v \rangle = 0$. En un espacio complejo,
sólo tenemos $\langle u,v \rangle + \langle v,u \rangle = 0$, así que podemos buscar un ejemplo en el que
no se cumpla:

\[2 = \|1+i\|^2 = \|1\|^2 + \|i\|^2 \]

Pero $\langle 1,i \rangle = -i \neq 0$.

**** Ejercicio 4
#+begin_statement
Sea $H$ un espacio prehilbertiano sobre $\mathbb{{K}}$. Sean $u,v \in H$ y $\alpha \in \mathbb{K}$. Probar que
$u$ y $v$ son ortogonales ssi, $\|u+\alpha v\| = \|u-\alpha v\|$.
#+end_statement

Sea $\alpha \neq 0$, tenemos que $u \perp v \iff u \perp \alpha v$. Así, podemos demostrar que son
ortogonales ssi $\|u+v\| = \|u-v\|$. Pero esto sólo ocurre en $\mathbb{R}$, donde el ser
hermítico da simetría al producto escalar, en $\mathbb{C}$ tenemos un contraejemplo
trivial en $u=1,v=i$, que no son ortogonales.

**** Ejercicio 15
#+begin_statement
Demostrar que el espacio ${\cal C}[-1,1]$ es suma directa del espacio de las funciones
pares y del espacio de las funciones impares. ¿Son ortogonales dichos 
subespacios? Encontrar los complementos ortogonales de los siguientes 
conjuntos:

  - las funciones que se anulan en $[-1,0]$.
  - las funciones que se anulan en $x = 0$.
#+end_statement

***** Es suma directa
Sea $f \in {\cal C}[-1,1]$. Podemos escribirla como:

\[
f(x) = \frac{f(x) + f(-x)}{2} + \frac{f(x) - f(-x)}{2}
\]

Siendo cada sumando par e impar. Supongamos un $f$ par e impar, entonces se
tiene $f(x) = f(-x) = -f(-x) = 0$.

***** Es ortogonal
Usando que el producto de par e impar es impar:

\[
\int_{-1}^1 f(x)g(x) dx = \int_0^1 fg - \int_0^1 fg = 0x
\]

***** Complemento de las anuladas en [-1,0]
****** Sólo son ortogonales si se anulan en [0,1]
Para cada intervalo definimos las funciones:

\[
u_{[a,b]}(x) = \left\{\begin{array}{ll} 
(x-a)\frac{2}{b-a}& \mbox{if } a \leq x \leq \frac{a+b}{2} \\
(b-x)\frac{2}{b-a}& \mbox{if } \frac{a+b}{2} \leq x \leq b \\
0 & \mbox{otherwise}
\end{array} 
\right.
\]

Una $f$ ortogonal a las que se anulan en $[-1,0]$ debe ser nula en $(0,1)$. Si
no lo fuera en $x \in (0,1)$, existiría un intervalo $[a,b] \subset (0,1)$ donde la función
preservaría el signo. Y entonces,

\[
\int f(x)u_{[a,b]}(x) \;dx \neq 0
\]

contraviniendo ortogonalidad.

****** Si se anulan en [0,1] son ortogonales
Por otro lado, una función que se anulara en $(0,1)$ sería ortogonal a
cualquiera que se anulara en $[-1,0]$.
***** Complemento de las anuladas en 0
Cualquier función ortogonal a las anuladas en $0$ debe anularse en todo $x \neq 0$.
Se tiene que si no se anulara en algún punto distinto de $0$, existiría
un intervalo $[a,b]$ en el que preservaría el signo:

\[
\int^1_{-1} f(x)u_{[a,b]}(x) \;dx \neq 0
\]

contraviniendo ortogonalidad. Debe anularse en todo punto distinto de $0$,
y, por continuidad, también en $0$.
*** 5. Espacios de Hilbert II
**** Ejercicio 1
#+begin_statement
Demostrar que un funcional lineal sobre un espacio de Hilbert es continuo si
y sólo si su núcleo es cerrado. ¿Es cierto esto para espacios de Banach en
general?
#+end_statement
***** Si es continua, tiene núcleo cerrado
Un funcional lineal continuo debe tener siempre un núcleo cerrado 
trivialmente.

***** TODO Si tiene núcleo cerrado, es continua
En el caso de tener el núcleo cerrado, [[*Descomposición canónica: isomorfismo][se tiene]] $\widehat{T} : H/\ker(T) \cong Im(T)$. 
Entonces $H/\ker(T)$ es de dimensión finita y un isomorfismo entre espacios 
de dimensión finita es continuo.

Por último $T = \widehat{T} \circ \pi$.

***** Otra solución
Viendo que hay suma topológica $H = \ker(f) \oplus \mathbb{K}x_0$, ya que podemos escribir:

\[ u = (u - f(u)x_0) + f(u)x_0\]

exigiendo sólo $f(x_0) = 1$.

**** Ejercicio 2
#+begin_statement
Sean $f,g \in l_2 \longrightarrow \mathbb{K}$ los funcionales dados por $f(x) = \alpha_3+\alpha_4$ y $g(x) = 4\alpha_5$,
para cada $x = \{\alpha_n\}_{n \in \mathbb{N}} \in l_2$. Demostrar que son lineales y continuos. 
¿Son inyectivos? Calcular $\|f\|$ y $\|g\|$. Determinar $v,w \in l_2$ tales que
$f = \langle \cdot,g \rangle$ y $g = \langle \cdot,w \rangle$. Dado $n \in \mathbb{N}$, ¿define $h_n(x) = \sum_{k=1}^n \alpha_k$ un funcional
lineal de $l_2$?; ¿y $h(x) = \sum^\infty_{k=1} \alpha_k$?
#+end_statement

***** Continuas
Son trivialmente lineales. Son continuos porque están acotados ambos
en la bola unidad. Sabemos que debe tenerse $|\alpha_i| \leq 1$ para que esté en la
bola unidad, porque en caso contrario, la suma de cuadrados sería mayor
que $1$:

\[ |f(x)| = |\alpha_3+\alpha_4| \leq 2\]
\[ |g(x)| = 4|\alpha_5| \leq 4\]

Son trivialmente no inyectivas.

De otra forma, las proyecciones, producto y suma son continuas.

***** Calcular la norma
****** Primer caso
Tenemos por desigualdad cuadrática-aritmética que $|\alpha_3| + |\alpha_4| \leq 2\sqrt{\frac{1}{2}}$. 
Y se alcanza la cota con la sucesión $f(0,0,0,\sqrt{1/2},\sqrt{1/2},0,\dots)$.

Podemos ver además que $f = \langle \cdot,(0,0,0,1,1,0,\dots)\rangle$.

****** Segundo caso
Tenemos por $g(0,0,0,0,1,0,\dots) = 4$ que la cota anterior era correcta.
Es además el vector por el que multiplicar para tener $g = \langle \cdot,w \rangle$.

***** Otros funcionales
****** Caso finito
Tenemos un funcional que es lineal trivialmente y que es continuo por
acotarse en la bola unidad por la desigualdad aritmético-cuadrática:

\[
\left| \sum^n_{k=1} \alpha_k \right| \leq
\sum_{k=1}^n |\alpha_k| \leq
n \sqrt{\frac{1}{n}\sum^n_{k=1} |\alpha_n|^2} \leq \frac{n}{\sqrt{n}}
\]

****** Caso infinito
No tiene ni por qué estar definido, la sucesión $\{1/n\}$ es cuadrado 
sumable pero no es sumable.

**** Ejercicio 3
#+begin_statement
Sea $f : \mathbb{C}^3 \longrightarrow \mathbb{C}$ el funcional $f(\alpha_1,\alpha_2,\alpha_3) = 3i\alpha_1 + 2\alpha_2 - \alpha_3$. Demostrar que $f$
está en el dual topológico de $\mathbb{C}^3$. Calcular $v \in \mathbb{C}^3$ tal que $f = \langle \cdot,v \rangle$ y
determinar $\|f\|$.
#+end_statement

Es suma y producto por escalares de las proyecciones, así que es continua
y lineal. Comprobamos $f = \langle \cdot,(-3i,2,-1) \rangle$, y por Cauchy-Swarchz sabemos
la norma será:

\[\|f\| = \|(3i,2,-1)\| = \sqrt{9+4+1} = \sqrt{14}\]

**** Ejercicio 4
#+begin_statement
#+end_statement

**** Ejercicio 5
#+begin_statement
Sea ${\cal P}(x)$ el espacio vectorial de los polinomios $p(x) :\mathbb{R} \longrightarrow \mathbb{R}$ con el 
producto interno dado por:

\[
\langle p,q \rangle = \int_0^1 p(t)q(t)\;dt
\]

Dar un ejemplo de un funcional lineal y continuo $\varphi : {\cal P}(x) \longrightarrow \mathbb{R}$ para el que
no exista $v(x) \in {\cal P}(x)$ tal que $\varphi = \langle \cdot,v \rangle$. ¿Contradice este hecho el teorema
de Riesz-Fréchet?
#+end_statement

Un ejemplo es:

\[
\varphi(p) = \int^1_0 e^tp(t) \;dx
\]

Es trivialmente lineal, está acotado en la bola unidad y por tanto es
continuo, de hecho, se tiene:

\[
\left| \int^1_0 e^tp(t) \;dx \right| \leq
\int^1_0 |e^tp(t)| \;dx \leq
e\int^1_0 |p(t)| \;dx = e \langle p,1 \rangle \leq e\|p\| \]

Sin embargo, no puede tenerse $\varphi = \langle \cdot,v \rangle$, porque si se tuviera, se tendría
en el espacio de las funciones un polinomio que contravendría Riesz-Fréchet:

\[\int_0^1(e^t-v(t)) p(t) \;dt = 0
\]

Implicando que $e^t-v(t)$ es ortogonal a todos los polinomios. Como los
polinomios son densos en las continuas, esto implica que es ortogonal
a todas las funciones y por tanto $0$. $e^t = v(t)$, y no tenemos un polinomio
que cumpla eso.

No contradice Riesz-Fréchet por no ser el espacio de los polinomios 
completo.

**** Ejercicio 6
#+begin_statement
Considérese el espacio complejo $C[0,1]$ dotado con la norma del máximo.
Sean $\varphi_1,\varphi_2,\varphi_3$ los funcionales dados por:

\[\varphi_1(f) = \int_0^1 x|f(x)|\;dx \]

\[\varphi_2(f) = \int^1_0 f(x)\;dx\]

\[ \varphi_3(f) = f\left(\frac{1}{2}\right)
\]

respectivamente, para $f \in C[0,1]$. ¿Cuáles de ellos son funcionales lineales
y continuos? Cuando lo sean, determinar su norma. Repetir el ejercicio
considerando la norma dada por $\|f\| = \int_0^1 |f(x)|^2\;dx$. ¿En qué casos existe
$g \in C[0,1]$ tal que el funcional dado es de la forma $\langle \cdot,g \rangle$?
#+end_statement

***** Con la norma del máximo
El primero no es lineal porque no cumple $\varphi_1(if) = i\varphi_1(f)$. El segundo y
el tercero son trivialmente lineales. Se comprueban continuos acotándolos
por la norma en la bola unidad. Calculamos su norma viendo que cumplen
esa acotación en la constante:

\[\varphi_2(1) = 1;\quad \varphi_3(1) =1;\]

***** Con la norma euclídea
Por Hölder tenemos un funcional acotado en la bola unidad:

\[
\left| \int^1_0 f(x)\;dx\right| \leq
\int^1_0 |f(x)|\;dx \leq
\sqrt{\int^1_0 |f(x)|^2\;dx}
\]

Pero el otro no está acotado; podemos tomar una familia $\psi_n$ de funciones
que sean nulas excepto en $[\frac{1}{2} - \frac{1}{2n^2}, \frac{1}{2} + \frac{1}{2n^2}]$, donde crecen hasta llegar
a $\psi_n\left(\frac{1}{2}\right) = n$ y decrecen. Las podemos construir con líneas considerando
su parte imaginaria nula. Tenemos a $\varphi_3(\psi_n) = n$, arbitrariamente grande, 
mientras:

\[
\int_0^1 |\psi_n(t)|^2 \;dt \leq \frac{1}{n^2}n^2 = 1
\]

***** Aplicamos Fréchet en el resto de casos
Para tener que $\varphi_2 = \langle \cdot,1 \rangle$.

**** Ejercicio 7
#+begin_statement
Sea $\varphi : L^2(\mathbb{R}) \longrightarrow \mathbb{R}$ el funcional dado por $\varphi(g) = \int_0^1 3xg(x)\;dx$. Demostrar
que $\varphi$ es un funcional lineal y acotado. Determinar $f \in L^2(\mathbb{R})$ tal que
$\varphi = \langle \cdot,f \rangle$ y calcular $\|f\|$.
#+end_statement

Es lineal trivialmente. Podemos acotarlo en la bola unidad como:

\[
\left|
\int^1_0 3xg(x)\;dx
\right| \leq 
3 \int^1_0 |x||g(x)|\;dx \leq 
3\sqrt{\int_0^1 |g(x)|^2\;dx} \leq
3\sqrt{\int_{-\infty}^\infty |g(x)|^2\;dx} \leq 3
\]

Por otro lado, tenemos que $\varphi = \langle \cdot,\psi \rangle$, siendo:

\[\psi = \left\{\begin{array}{ll} 
3x& \mbox{if } 0 \leq x \leq 1  \\
0 & \mbox{otherwise }  
\end{array} 
\right.\]

La norma de $f$ será la de $\psi$, donde:

\[\|f\| = \int_{-\infty}^\infty \psi(x)\;dx = \frac{3}{2}\]

**** Ejercicio 10
#+begin_statement
Demostrar que los siguientes conjuntos forman una base ortonormal del 
espacio de Hilbert real $L^2[0,\pi]$.

  1. $B := \{ e_n \mid n \in \mathbb{N}_0\}$, donde $e_0 = \frac{1}{\sqrt{\pi}}$ y $e_n = \frac{\sqrt{2}}{\sqrt{\pi}} cos (nx)$.
  2. $B := \{ e_n \mid n \in \mathbb{N}\}$ donde $e_n = \frac{\sqrt{2}}{\sqrt{\pi}} sin(nx)$.

Obtener una base ortonormal del espacio de Hilbert complejo $L^2[0,\pi]$.
#+end_statement

***** Primer punto
****** Generan el espacio
Sabemos que los polinomios son densos en el espacio de funciones
continuas en $[0,1]$, y que la función arcocoseno es una biyección en
ese intervalo. Dado un $f$, tenemos un polinomio $p$ que aproxima a
la función $f \circ arccos$:

\[ 
\left\| f(x) - p(cos(x)) \right\|_2 \leq
\left\| f(x) - p(cos(x)) \right\|_\infty =
\left\| f(arccos(x)) - p(x) \right\|_\infty
\]

Ahora, un polinomio sobre $cos(x)$ puede reescribirse como una 
combinación lineal de los vectores de la base:

\[ cos(nx)cos(mx) = 
\frac{1}{2}\Big( cos((n+m)x) + cos((n-m)x)
\Big)\]

De esta forma, la clausura del espacio que generan los cosenos es
el espacio de las continuas. Si además las continuas son densas
en $L_2[0,1]$, tenemos lo pedido.

****** Son una familia ortonormal
Como además son familia ortonormal, forman una base ortonormal del 
espacio. Cuando $m \neq n$:

\[
\int_0^\pi cos(nx)cos(mx) \;dx = 
\frac{1}{n+m}[sen((n+m)x)]^\pi_0 +
\frac{1}{n-m}[sen((n-m)x)]^\pi_0 = 0
\]

Y cuando $m = n$, se tiene:

\[
\int_0^\pi cos(nx)^2 \;dx
=
\frac{1}{2}\int_0^\pi cos(2nx) - 1 \;dx
= \frac{\pi}{2}
\]

***** Segundo punto
****** Generan el espacio
Usaremos la derivación. Por el teorema anterior, tenemos un $p\circ cos$ que 
aproxima con precisión $\varepsilon$ a la siguiente función:

\[
g(x) = \left\{\begin{array}{ll} 
\frac{f(x)}{sin(x)} & \mbox{if } x \in [0+\varepsilon,\pi+\varepsilon]  \\
\psi(x) & \mbox{otherwise } 
\end{array} 
\right.
\]

Donde $\psi(x)$ la podemos construir con rectas para que haga continua
a la función e integre menos de $\varepsilon$, algo como:

[[./images/epsilonint.png]]

Sea una primitiva suya el polinomio $P$:

\[\begin{aligned} 
\|f(x) - \partial (P\circ cos)(x))\|_2 
&\leq
K + \int_{0-\varepsilon}^{\pi-\varepsilon} 
\left|f(x) - \partial (P\circ cos)(x) \right|^2\;dx \\
&\leq 
K + \int_{0-\varepsilon}^{\pi-\varepsilon} 
\left|\frac{f(x)}{sin(x)} - \frac{\partial (P\circ cos)(x)}{sin(x)} \right|^2\;dx \\
&=
K + \int_{0-\varepsilon}^{\pi-\varepsilon} 
\left|\frac{f(x)}{sin(x)} - p(cos(x)) \right|^2\;dx < \varepsilon + K\\
\end{aligned}\]

Por otro lado, tenemos que:

\[\begin{aligned}
K &= 
\int_0^\varepsilon |f(x) - \partial(P \circ cos)(x)|^2 \;dx
\\&\leq
\int_0^\varepsilon |f(x)|^2\;dx + \int_0^\varepsilon |sin(x)p(cos(x))|^2\;dx
\\&\leq
\int_0^\varepsilon |f(x)|^2\;dx + \int_0^\varepsilon |p(cos(x))|^2\;dx
\\&\leq 
\varepsilon \|f\|_\infty + \int_0^\varepsilon |p(cos(x)) - \psi(x)|^2\;dx + \int_0^\varepsilon |\psi(x)|^2\;dx
\\&\leq
\varepsilon \|f^2\|_\infty + \varepsilon + \varepsilon
\end{aligned}\]

Como $\varepsilon$ es arbitrario, se tiene lo pedido. Nótese que $\partial (P \circ cos)$ es la
derivada de una función polinómica en los cosenos que se puede escribir
como combinación lineal de la base anterior. Y nótese que la derivada
lleva cada elemento de la base anterior en uno de la nueva.

****** Son una familia ortonormal
Por último, como son ortonormales, forman una base ortonormal:

\[
\int^\pi_0 sin(nx)sin(mx) \;dx
= 
\int^\pi_0 cos((n-m)x) - cos((n+m)x)\;dx = 0
\]

***** Tercer punto
Toda función puede escribirse como:

\[
f(x) = \Re(f(x)) + i \Im(f(x))
\]

Y cada una de esas partes puede aproximarse como suma de cosenos o de
senos. Así, cualquier base ortonormal del espacio real que hemos 
construido anteriormente es también base del espacio complejo.

**** Ejercicio 11
#+begin_statement
Demostrar que:

\[B:= \left\{
e_0(x) = \frac{1}{\sqrt{2\pi}},\;
e_n(x) = \frac{1}{\sqrt{\pi}} cos(nx),\;
e_{-n}(x) = \frac{1}{\sqrt{\pi}} sin(nx) 
\mid n \in \mathbb{N}
\right\}\]

define una base ortonormal en un espacio de Hilbert real $L^2[-\pi,\pi]$.
#+end_statement

***** Es ortogonal
Comprobamos integrando la ortonormalidad de la base.

***** Genera el espacio
Las funciones pares pueden aproximarse por la misma función que las
aproximaba en $[0,\pi]$ con los cosenos; las impares pueden aproximarse
por la función que las aproximaba en $[0,\pi]$ con senos.

Toda función es suma de par y de impar.

\[f(x) = \frac{f(x)-f(-x)}{2}+\frac{f(x)+f(-x)}{2}\]

Así que toda función puede aproximarse por suma de senos y cosenos.

**** Ejercicio 12

**** Ejercicio 13
#+begin_statement
En el espacio $L^2[-\pi,\pi]$, en función de la base de Hilbert dada en el 
ejercicio 11, calcular el desarrollo en serie de Fourier de la función
$f(x) = |x|$ y deducir mediante la indentidad de Parseval que:

\[\sum^\infty_{n=1} \frac{1}{(2n-1)^4} = \frac{\pi^4}{96}\]
#+end_statement

***** Desarrollo en serie de Fourier
Usando que es función par

\[
\int_{-\pi}^\pi |x| \frac{1}{\sqrt{2\pi}} \;dx = \frac{\pi^2}{\sqrt{2\pi}}
\]

Usando que es una función par e integrando por partes:

\[
\int_{-\pi}^\pi |x| \frac{1}{\sqrt{\pi}} cos(nx) \;dx
=
\frac{2}{\sqrt{\pi}}\int_{0}^\pi x cos(nx) \;dx 
=
\frac{2}{\sqrt{\pi}n^2}((-1)^n-1)
\]

Usando que es una función impar:

\[
\int_{-\pi}^\pi |x| \frac{1}{\sqrt{\pi}} sin(nx) \;dx 
=
0
\]

***** Identidad de Parseval
Calculamos la norma de la función:

\[
\int_{-\pi}^\pi x^2 \;dx = \frac{2}{3} \pi^3
\]

Y tenemos finalmente, sumando cuadrados de los productos escalares
anteriores:

\[\begin{aligned}
\frac{\pi^3}{2} + \sum_{i=0}^\infty \frac{4}{\pi n^4}((-1)^n-1)^2
&=
\frac{2}{3} \pi^3
\\
\sum_{i=0}^\infty \frac{4}{n^4}((-1)^n-1)^2
&=
\frac{1}{6} \pi^4
\\
\sum_{i=1}^\infty \frac{1}{(2n-1)^4}
&=
\frac{1}{96} \pi^4
\end{aligned}\]

Considerando sólo los términos impares.

**** TODO Ejercicio 14
#+begin_statement
En el espacio $L^2[-\pi,\pi]$, en función de la base de Hilbert dada en el 
ejercicio 11, obtener el desarrollo en serie de Fourier de la función
$f(x) = x^2$. Usar dicho desarrollo para calcular:

\[\sum_{n=1}^\infty \frac{1}{n^2}\] y \[\sum_{n=1}^\infty \frac{1}{n^4}\]
#+end_statement

**** TODO Ejercicio 18
#+begin_statement
Encontrar $min_{\alpha,\beta,\gamma \in \mathbb{C}} \int_{-1}^1 |x^3-\alpha-\beta x -\gamma x^2|^2 \;dx$.
#+end_statement

Buscar la mejor aproximación en el espacio de los polinomios de grado
menor que 2. Hay que buscar primero una ortonormalización de la base
con Gram-Schmitd

*** 6. Espacios de Hilbert III
**** Ejercicio 1
#+begin_statement
Sea $H$ un espacio de Hilbert y $P \in L(H)$. Demostrar que las siguientes
afirmaciones son equivalentes:

  1. $P$ es la proyección ortogonal de $H$ sobre un subespacio cerrado $M$.
  2. $P$ es idempotente y autoadjunto.
  3. $P$ es idempotente y $H = P(H) \oplus (I-P)(H)$ siendo los subespacios
     $P(H)$ y $(I-P)(H)$ ortogonales.
  4. $P$ es idempotente y $P(H)^\perp = \ker P$.
#+end_statement

***** Primera implicación
Trivialmente idempotente. Es autoadjunto por tenerse:

\[\begin{aligned}
\langle u,pv \rangle &= \langle pu,v \rangle \\
\langle u-pu,pv \rangle &= \langle pu,v - pv \rangle \\
0 &= 0
\end{aligned}\]

Donde usamos que $pu \in M$, pero $u - pu \in M^\perp$.

***** Segunda implicación
Tenemos $u = p(u) + (u - p(u))$ y son ortogonales por:

\[\langle p(u),v-p(v) \rangle = \langle u , p(v-p(v)) \rangle = 0\]

***** Tercera implicación
Comprobamos que son iguales $(I-P)(H) = \ker P$. Tenemos que $g = g - p(g)$
para un caso y $p(g -p(g)) = p(g)-p(g) = 0$ para el otro.

***** Cuarta implicación
Es una proyección sobre $P(H)$ y es ortogonal por definición.

**** Ejercicio 2
#+begin_statement
Sea $H$ un espacio de Hilbert y $\{e_n\}$ una base ortonormal de $H$. Sea
$\{\alpha_n\}$ una sucesión acotada de números complejos y:

\[\alpha = \sup_{n \in \mathbb{N}} |\alpha_n|\]

Probar que existe un único $T\in L(H)$ tal que $Te_n = \alpha_ne_n$, para cada $n \in \mathbb{N}$,
y que $\|T\| = \alpha$. Calcular $T^\ast$ y $\|T^\ast\|$. Demostrar que $T$ es normal. ¿Qué
condición ha de cumplir la sucesión dada para que el operador $T$ sea
autoadjunto?¿y para que $T$ sea invertible?
#+end_statement

Expresando $u$ en serie de Fourier.

Autoadjunto cuando $\alpha_i = \overline{\alpha_i}$ e invertible cuando $\alpha_i \neq 0$.

**** Ejercicio 2.1
#+begin_statement
Sea $H = \mathbb{C}^3$ y sea $T \in L(H)$ el operador dado por:

\[T(\alpha_1,\alpha_2,\alpha_3) = (\alpha_1+\alpha_2,\alpha_1+\alpha_3,\alpha_3+2\alpha_1)\]

¿Es unitario?¿Es autoadjunto? Determinar el espectro de $T$.
#+end_statement

**** Ejercicio 3
#+begin_statement
Sea $H$ un espacio de Hilbert sobre $\mathbb{K}$ y $T \in L(H)$ un operador tal que
$\langle Tu,u \rangle = 0$ para cada $u \in H$. Demostrar que $T = 0$ si $\mathbb{K}=\mathbb{C}$, pero que no
puede decirse lo mismo si $\mathbb{K}=\mathbb{R}$, y buscar una condición suficiente para
que se verifique dicha propiedad en el caso real.
#+end_statement

***** Caso complejo
Desarrollando:

\[\begin{aligned}
0
&=& 
\langle T(u+v),u+v \rangle
&=&
\langle Tu,v \rangle + \langle Tv,u \rangle\\
0
&=& 
\langle T(u+iv),u+iv \rangle
&=&
(-i)\langle Tu,v \rangle + i\langle Tv,u \rangle
\end{aligned}\]

Por tanto, $\langle Tu,v \rangle = 0$ y debe tenerse $Tu = 0$.

***** Caso real
Hay contraejemplos en el caso real. En $\mathbb{R}^2$ se tiene:

\[T(x,y) = (-y,x)\]

cumpliendo lo pedido. En general, cuando se tiene $T^\ast = -T$, tenemos:

\[\langle Tu,u \rangle = -\langle u,Tu \rangle = -\langle Tu,u \rangle = 0\]

siendo una condición suficiente.

**** Ejercicio 4
#+begin_statement
Sea $H = \mathbb{C}^2$. Calcular el espectro y la norma del operador $T \in L(H)$ dado,
respectivamente, por cada una de las siguientes matrices:

  1. \[\begin{pmatrix} 0 & 1+i \\ 1 & 2+2i \end{pmatrix}\]

  2. \[\begin{pmatrix} 
     cos \theta & e^{i\phi} sen \theta \\
     e^{i\phi} sen \theta & -cos \theta
     \end{pmatrix}\]
#+end_statement

Usaremos que la [[http://math.stackexchange.com/a/586835/85067][norma de la matriz]] es la raíz del mayor valor propio
de $M\overline{M^T}$.

***** Primera matriz
Reduciendo la matriz, tenemos como valores propios:

\[\begin{aligned}
\lambda_1 &= 1+i+\sqrt{1+3i}\\
\lambda_2 &= 1+i-\sqrt{1+3i}
\end{aligned}\]

Calculamos:

\[M\overline{M^T} = 
\begin{pmatrix} 
2 & 4 \\ 4 & 9 
\end{pmatrix}\]

A la que le podemos encontrar los valores propios:

\[\lambda_1 = \frac{1}{2}(11-\sqrt{113})\]

\[\lambda_2 = \frac{1}{2}(11+\sqrt{113})\]

#+BEGIN_SRC sage
M = Matrix([[0,1+i],[1,2+2*i]])
(M*(M.transpose().conjugate())).eigenvalues()
#+END_SRC

#+RESULTS:
: [-1/2*sqrt(113) + 11/2, 1/2*sqrt(113) + 11/2]
: a^2 - 11*a + 18

***** Segunda matriz
Reduciendo la matriz, llegamos a los valores propios
$\lambda_1=1,\lambda_2 = -1$.

Y podemos aplicar lo mismo que en la anterior.

#+BEGIN_SRC sage
t,f = var('t f')
assume(t,'real')
assume(f,'real')
M = Matrix([[cos(t), e^(i*f)*sin(t)],[e^(i*f)*sin(t),-cos(t)]])
expand((M*(M.transpose().conjugate())).eigenvalues())
#+END_SRC

#+RESULTS:
: 
: [(cos(t)^2*e^(I*f) + (-I*e^(2*I*f) + I)*cos(t)*sin(t) + e^(I*f)*sin(t)^2)*e^(-I*f),
:  (cos(t)^2*e^(I*f) + (I*e^(2*I*f) - I)*cos(t)*sin(t) + e^(I*f)*sin(t)^2)*e^(-I*f)]

**** Ejercicio 5
#+begin_statement
Sea $T \in L(H)$ donde $H$ es un espacio de Hilbert de dimensión 3. 
Calcúlese el espectro de $T$ sabiendo que $T$ es autoadjunto,
que $\|T\| = 4$, que $T$ no tiene inverso, y que el rango de $T-2I$ es $2$.
#+end_statement

Sabemos que un valor propio es $2$, que otro valor propio es $0$ por no
tener inversa. Como la norma es la raíz 

**** Ejercicio 6
#+begin_statement
Sea $H$ un espacio de Hilbert complejo de dimensión $n+1$, y sea
$B = \{e_0,\dots,e_n\}$ una base ortonormal. Sea $T \in L(H)$ el operador determinado
por las igualdades:

   - \[T(e_0) = 0\]
   - \[T(e_j) = \sqrt{j} e_{j-1}\]
 
Obtener los operadores $T^\ast$ y $T^\ast T$. Probar que $T^{n+1} = 0$. Calcular el espectro
de los operadores $T$, $T^\ast$ y $T^\ast T$ así como $\|T\|$ y $\|T^\ast T\|$.
#+end_statement

La solución es:

  - $T^\ast T(e_j) = je_j$.
  - $G_p(T^\ast T) = \{0,1,\dots,n\}$.
  - $G_p(T) = \{0\}$.
  - $\|T\| = \sqrt{n}$, $\|T^\ast T\| =n$.

**** Ejercicio 7
#+begin_statement
Diagonalizar (si es posible) los operadores dados (respectivamente) por:

  1. \[\begin{pmatrix} 
     7 & -2 & 1 \\
     -2 & 10 & 2 \\
     -1 & -2 & 7
     \end{pmatrix}\]

  2. \[\begin{pmatrix} 
     2 & -2 & 3 \\
     1 & 1 & 1 \\
     1 & 3 & 1 \\
     \end{pmatrix}\]

  3. \[\begin{pmatrix} 
     2 & 2 & 1 \\
     1 & 3 & 1 \\
     1 & 2 & 2 \\
     \end{pmatrix}\]
#+end_statement
* Inferencia Estadística
** DONE Apuntes en clase
*** Introducción
**** Estadísticos
 *Estadístico*. Función medible sobre variables aleatorias $f(X_1,X_2,\dots,X_n)$.
 Se dice que es un *estimador consistente* de un parámetro cuando converge 
 en probabilidad a él.

*** Distribuciones continuas
**** Distribución uniforme
 *Distribución uniforme*. Sobre un intervalo $[a,b]$, definida por:

 \[f(x|a,b) = \frac{1}{b-a}\]

 \[EX = \int^b_a \frac{x}{b-a}dx = \frac{b+a}{2}\]
 \[Var X = \int_a^b \frac{(x-\frac{b+a}{2})^2}{b-a} dx = \frac{(b-a)^2}{12}\]

**** Distribución gamma
 #+begin_definition
 *Función gamma*. La siguiente integral converge para $\alpha > 0$:

 \[\Gamma(\alpha) = \int_0^\infty t^{\alpha-1}e^{-t}dt\]
 #+end_definition

 Cumple que: $\Gamma(\alpha+1) = \alpha\Gamma(\alpha)$, de esta forma, generaliza al factorial
 con $\Gamma(n) = (n-1)!$.

 #+begin_definition
 *Distribución gamma*. Sobre $[0,\infty)$, dada $\alpha$, se tiene la función de distribución:

 \[f(x|\alpha,\beta) = 
 \frac{1}{\Gamma(\alpha)\beta^\alpha} x^{\alpha-1}e^{-x/\beta}\]
 #+end_definition

**** Distribución de Dirichlet
 #+begin_definition
 *Distribución de Dirichlet*. 

 \[f(x_1\dots x_n| \alpha_1, \dots \alpha_k,\alpha_{k+1}) = 
 \frac{\Gamma(\alpha_1+\dots+\alpha_{k+1})}
 {\Gamma(\alpha_1)\dots \Gamma(\alpha_{k+1})}
 x_1^{\alpha_1-1} \dots x_{k}^{\alpha_{k-1}-1}
 \]
 #+end_definition

 # Esperanza
 # Integral de dirichlet
 # Subvector
 # Dirichlet ordenada

*** Máxima verosimilitud
 #+begin_definition
 *Máxima verosimilitud*. Sean $X_1,\dots,X_n$ v.as. independientes extraídas de una
 función de probabilidad perteneciente a una familia 
 $\{f(\bullet | \theta), \theta \in \Theta\}$ llamada *modelo*, pero con $\theta$ desconocida

 Llamamos *estimador de máxima verosimilitud* de $\theta$ al $\hat\theta$ que maximiza 

 \[{\cal L}(\hat\theta | x_1,\dots,x_n) = \prod_{i=1}^n f(x_i|\theta)\]

 llamada *función de verosimilitud*.
 #+end_definition

 La idea del método es tomar la función de densidad conjunta asumiendo independencia:

 \[f(x_1,\dots,x_n | \theta) = f(x_1|\theta) f(x_2|\theta) \dots f(x_n|\theta)\]

 Y, suponiendo que los valores fueran fijos, estimar $\theta$ con la función de
 la función de verosimilitud o de su logaritmo:

 \[\hat l (\hat\theta | x_1,\dots,x_n) = \sum_{i=1}^n \ln f(x_i|\theta)\]


***** Ejemplo de una distribución binomial

 # Conjuntos creíbles

** Prerrequisitos
*** Varianza
**** Varianza
La varianza se define equivalentemente como:

\[Var(X) = E\Big[(X-EX)^2\Big] = E[X^2] - E[X]^2\]

**** Covarianza
La covarianza se define equivalentemente como:

\[cov(X,Y) = E[(X-EX)(Y-EY)] = E[XY] - E[X]E[Y]\]

Nótese que $cov(X,X) = Var(X)$. Nótese además se comporta como el 
[[https://en.wikipedia.org/wiki/Covariance#Relationship_to_inner_products][producto interno]] de un espacio prehilbertiano.

**** Varianza de la suma
La varianza de una suma cumple:

\[
Var(X+Y) = Var(X) + Var(Y) + 2cov(X,Y)
\]

En el caso general:

\[Var\left(\sum X_i\right) = \sum_i\sum_j cov(X_i,X_j)\]

**** Cauchy-Schwarz para la covarianza
Se tiene la desigualdad:

\[cov(X,Y)^2 \leq Var(X)Var(Y)
\]

***** Demostración
Sabiendo que la varianza es siempre no negativa:

\[
0 \leq Var\left(X - \frac{cov(X,Y)}{Var(Y)} Y\right) =
Var(X) - \frac{\left(cov(X,Y)\right)^2}{Var(Y)}
\]

***** Demostración por Cauchy-Schwarz
Se comprueba que la covarianza da un producto escalar que genera
un [[https://en.wikipedia.org/wiki/Covariance#Relationship_to_inner_products][espacio cociente]] prehilbertiano. Aplicamos Cauchy-Schwarz.

*** Esperanza condicional
**** Esperanza condicional en caso discreto
Definimos la esperanza condicional de dos variables discretas como:

\[\mathbb{E}[X|Y] = \sum_x xP(X=x\mid Y=y) = \sum_x x\frac{P(X=x, Y=y)}{P(Y=y)}\]

**** Esperanza condicional en el caso continuo
Más generalmente se define para el caso continuo:

\[
\mathbb{E}[X|Y] = \int_X x f_{X|Y}(x|y) dx = \int_X x \frac{f_{X,Y}(x,y)}{f_Y(y)} dx
\]

**** Ley de esperanza total
La esperanza condicional cumple:

\[\mathbb{E}[X] = \mathbb{E}[\mathbb{E}[X|Y]]\]

***** Demostración en el caso discreto
Se tiene:

\[\begin{aligned}
E[E[X|Y]] &= \int_Y f(y)  \left(\int_X x \frac{f(x,y)}{f(y)} dx \right) dy \\ñ
&= \int_X x \int_Y f(x,y) dy dx \\&= \int_X x f(x) dx = E[X]
\end{aligned}\]

Nótese que asumimos una conmutatividad de las integrales discretas.

***** Demostración en el caso continuo
Puede consultarse la [[https://en.wikipedia.org/wiki/Law_of_total_expectation#Proof_in_the_general_case][Ley de la esperanza total]].

** 1. Introducción a la inferencia estadística. Estadísticos muestrales.
*** Planteamiento de un problema de inferencia
**** Modelo estadístico
Un modelo estadístico $(X,{\cal P})$ consta de:

  - $X : (\Omega, {\cal A},{\cal P}) \longrightarrow (\mathbb{R},{\cal B},P_X)$ variable aleatoria que describe el 
    objeto de estudio.
  - ${\cal P}$ familia de distribuciones que pueden ser la de $X$.

**** Modelo estadístico paramétrico
Cuando se conoce la forma funcional de $P_X$ y sólo desconocemos un 
parámetro tenemos una familia paramétrica de distribuciones $F(x,\theta)$ 
para $\theta$.

**** Modelo estadístico no paramétrico
Cuando la forma funcional de $P_X$ es desconocida.

**** Muestra aleatoria simple
Una muestra aleatoria simple es un vector $(X_1,\dots,X_n)$
de variables independientes idénticamente distribuidas. 

***** Realización muestral
Una realización muestral a un valor concreto obtenido al 
observar la muestra.

***** Espacio muestral
Conjunto de todas las posibles realizaciones.

*** Función de distribución empírica
**** Función de distribución muestral
La *función de distribución empírica* es una función de 
distribución razonable que podemos obtener desde una 
realización muestral.

 \[F^\ast_{X_1,\dots,X_n}(x) = \frac{1}{n} \sum_{i=1}^n \mathbf{1}_{(X_i < x)} \]

**** Propiedades de la función de distribución empírica
Fijado un $x \in \mathbb{R}$, $F^\ast(x)$ es una variable aleatoria siguiendo por 
definición una binomial:

\[ nF^\ast(x) \longrightarrow {\cal B}(n, F(x))\]

Calculamos su *esperanza* y *varianza* desde Bernoulli como:

 - Esperanza: $E[F^\ast(x)] = F(x)$
 - Varianza: $Var[F^\ast(x)] = \frac{F(x) (1-F(x))}{n}$

Aplicando entonces el Teorema Central del Límite:

\[ \frac{F^\ast(x) - F(x)}{\sqrt{\frac{F(x)(1-F(x))}{n}}} \leadsto {\cal N}(0,1) \]

**** Teorema de Glivenko-Cantelli
Las funciones de distribución muestrales convergen 
casi seguramente y uniformemente a la teórica.

\[ P\left\{ \lim_{n \rightarrow \infty} 
\sup_{x \in \mathbb{R}} |F^\ast_n(x) - F(x)| = 0\right\} = 1\]

***** Equivalentemente
Con probabilidad 1 se tiene que, al tomar sucesivas observaciones 
independientes y considerar las correspondientes funciones de 
distribución muestrales:

\[\forall x \in \mathbb{R}: \forall \epsilon>0: \exists n_\epsilon : \forall n \geq n_\epsilon:
\quad F^\ast_n(x) - \epsilon < F_X(x) < F^\ast_n(x) + \epsilon\]

***** Demostración
[[http://matematicas.unex.es/~nogales/estadisticamatematica/TGC.pdf][Teorema de Glivenko-Cantelli]].

*** Estadístico muestral
**** Estadístico muestral
Dada una muestra aleatoria simple, un *estadístico muestral* es una 
función sobre ella $T : (\mathbb{R}^n,{\cal B}^n)\longrightarrow (\mathbb{R}^k,{\cal B}^k)$ medible e independiente 
de cualquier parámetro desconocido.

**** Estadísticos de interés
***** Momentos muestrales no centrados
Para cada $k \in \mathbb{N}$:

\[A_k = \frac{1}{n}\sum_{i=1}^n X_i^k\]

***** Momentos muestrales centrados
Para cada $k \in \mathbb{N}$:

\[B_k = \frac{1}{n}\sum_{i=1}^n(X_i - \overline{X})^k\]

***** Media muestral
Caso particular,

\[A_1 = \frac{1}{n}\sum_{i=1}^n X_i = \overline{X}\]

***** Varianza muestral
Caso particular,

\[B_2 = \frac{1}{n}\sum_{i=1}^n(X_i - \overline{X})^2\]

***** Cuasivarianza muestral

1\[S^2 = \frac{1}{n-1} \sum_{i=1}^n (X_i-\overline{X})^2\]

** 2. Distribuciones. Muestreo de poblaciones normales
*** Distribución normal
**** Definición
Definimos la distribución normal ${\cal N}(\mu,\sigma^2)$ como aquella con función de
densidad:

\[f(x) = \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(x-\mu)^2}{2\sigma^2}}\]

***** Imagen de la distribución
#+BEGIN_SRC R :file images/normal.png :results graphics
  library(ggplot2)
  library(ggfortify)
  gg = NULL
  for (i in c(1,2,3,4,5)) {
      gg = ggdistribution(dnorm, seq(-3, 3, 0.1),
                          mean = 0, sd = 1+0.1*i,
                          colour=topo.colors(5)[i], p=gg)
  }
  print(gg + labs(title = "Distribución normal, variando σ²."))
#+END_SRC

#+RESULTS:
[[file:images/normal.png]]

***** Es una distribución
Tenemos que comprobar que integra la unidad sobre los reales, y
de hecho, tomando cambio de variable $y = (x-\mu)/\sqrt{2\sigma^2}$ queda:

\[\begin{aligned}
\int^{+\infty}_{-\infty} 
\frac{1}{\sqrt{2\pi\sigma^2}}e^{-\left(\frac{x-\mu}{\sqrt{2\sigma^2}}\right)^2} =
\frac{1}{\sqrt{\pi}}\int^{+\infty}_{-\infty} 
e^{-y^2} = 1
\end{aligned}\]

Que es la [[https://en.wikipedia.org/wiki/Gaussian_integral][integral de Gauss]].

**** Función característica
La función característica de ${\cal N}(\mu,\sigma^2)$ es:

\[\varphi_X(t) = e^{it\mu - t^2\sigma^2/2}\]

***** TODO Demostración
Usamos la definición de función característica y completamos
cuadrados para tener:

\[\begin{aligned}
\varphi_X(t) &= 
\mathbb{E}\left[e^{itX}\right] &= 
\int_{-\infty}^{+\infty}
e^{itx}\frac{1}{\sqrt{2\pi\sigma^2}} 
e^{-\frac{(x-\mu)^2}{2\sigma^2}}dx \\&=
\frac{1}{\sqrt{2\pi\sigma^2}} 
\int_{-\infty}^{+\infty}
e^{it\mu}
\end{aligned}\]

**** Suma de normales
Sean $X \leadsto {\cal N}(\mu_1,\sigma_1^2)$ e $Y \leadsto {\cal N}(\mu_2,\sigma_2^2)$. Entonces $X+Y\leadsto {\cal N}(\mu_1+\mu_2,\sigma_1^2+\sigma_2^2)$.

***** TODO Demostración
**** Teorema de Cramer
Sean $X,Y$ independientes. Si $X+Y$ es normal, $X$ e $Y$ son normales.

***** TODO Demostración

*** Distribución exponencial
**** Distribución exponencial
Dado un $\lambda>0$, definimos la distribución exponencial, $\operatorname{Exp}(\lambda)$, como aquella
con función de densidad:

\[f(x) = \lambda e^{-\lambda x}\qquad \forall x \in \mathbb{R}^+_0\]

***** Es una distribución
Trivialmente integrando:

\[
\int_0^\infty \lambda e^{-\lambda x} = 
-\left[ e^{-\lambda x} \right]^\infty_0 = 1
\]

*** Distribución Gamma
**** Función Gamma
Se define la función gamma $\Gamma : (0,\infty) \longrightarrow (0,\infty)$ como:

\[\Gamma(\alpha) = \int^\infty_0 t^{\alpha-1}e^{-t} dt\]

***** La integral existe
Por un lado, $t^{a-1}e^{-t} < t^{a-1}$, integrable en $[0,b]$. Por otro lado,

\[\lim_{t \to \infty} \frac{t^{\alpha-1}e^{-t}}{e^{-t/2}} = 0\]

Por lo que $t^{\alpha-1}e^{-t} < e^{-t/2}$ integrable, a partir de algún punto.
Partimos la integral como:

\[\int_0^b t^{\alpha-1}e^{-t}dt + \int^{\infty}_b t^{\alpha-1}e^{-t}dt
< \infty\]

**** Propiedades de la función Gamma
Sea $\alpha > 0$, se verifica:

  1. $\Gamma(1) = 1$.
  2. $\Gamma(\alpha+1) = \alpha\Gamma(\alpha)$.
  3. $\Gamma(n+1) = n!$ para $n \in \mathbb{N}$.
  4. $\Gamma(\alpha)\Gamma(1-\alpha) = \frac{\pi}{\sin(\alpha\pi)}$ para $0<\alpha<1$.
  5. $\Gamma(1/2) = \sqrt{\pi}$.
  6. $\Gamma(\alpha) = \beta^\alpha \int^\infty_0 t^{\alpha-1}e^{-\beta t} dt$ para $\beta > 0$.

***** Demostración
****** Punto 1
Trivial.
****** Punto 2
Integral por partes.
****** Punto 3
Inducción sobre los dos primeros apartados.
****** TODO Punto 4
****** Punto 5
Trivial desde el punto anterior.
****** Punto 6
Cambio de variable $\varphi(t) = \beta t$.

**** Distribución Gamma
Dados $\alpha,\beta > 0$, definimos la distribución Gamma $\Gamma(\alpha,\beta)$ como aquella con
función de densidad:

\[f(x) = \frac{\beta^\alpha}{\Gamma(\alpha)}x^{\alpha-1}e^{-\beta x}\]

para $x>0$.

***** Imagen de la distribución
#+BEGIN_SRC R :results graphics :file images/gamma.png
  library(ggplot2)
  library(ggfortify)
  gg = NULL
  for (i in c(1,2,3,4,5)) {
      gg = ggdistribution(dgamma, seq(0, 4, 0.05),
                          shape = i, rate = 1,
                          colour=topo.colors(5)[i], p=gg)
  }
  print(gg + labs(title = "Distribución gamma, variando α."))
#+END_SRC

#+RESULTS:
[[file:images/gamma.png]]
**** Propiedades de la distribución Gamma
La función de densidad de una distribución $\Gamma(\alpha,\beta)$ verifica:

  1. Cuando $0<\alpha<1$, $f$ es decreciente y $\lim_{x\to 0} f(x) = \infty$.
  2. Cuando $\alpha = 1$, $f$ es decreciente y $f(0)=1$.
  3. Cuando $\alpha>1$, $f$ es creciente en $[0,(\alpha-1)/\beta]$ y decreciente 
     en $[(\alpha-1)/\beta,\infty]$.

Y sobre convexidad y concavidad se tiene:

  1. Si $0<\alpha\leq 1$, es convexa.
  2. Si $1 < \alpha \leq 2$, es cóncava en $[0,(\alpha-1+\sqrt{\alpha+1})/\beta]$ y convexa
     en $[(\alpha-1+\sqrt{\alpha+1})/\beta,\infty]$.
  3. Si $2 < \alpha$, es cóncava en $[(\alpha-1-\sqrt{\alpha+1})/\beta,(\alpha-1+\sqrt{\alpha+1}/\beta)]$ y
     convexa en todo el resto del dominio.

***** TODO Demostración

*** Distribución Beta
**** Función Beta
Se define la función beta $\beta : (0,\infty) \longrightarrow (0,\infty)$ como:

\[\beta(x,y) = \int^1_0 t^{x-1}(1-t)^{y-1}dt\]

***** Está bien definida
Por la [[*Relación con la función Gamma][relación con la función Gamma]] sabemos que debe estar
bien definida.

**** Relación con la función Gamma
Para cada $x,y$ se tiene:

\[\frac{\Gamma(x)\Gamma(y)}{\Gamma(xy)} = \beta(x,y)\]

***** TODO Demostración

**** Distribución Beta
Dados $p,q>0$, definimos la distribución Beta $\beta(p,q)$ como aquella con 
función de densidad:

\[f(x) = \frac{1}{\beta(p,q)} x^{p-1}(1-x)^{q-1}\]

*** Distribución χ² de Pearson
**** Distribución chi cuadrado
Es un caso particular de la distribución gamma, $X \leadsto \chi^2(k) = \Gamma(k/2,1/2)$.
Al parámetro $k$ se le llama *número de grados de libertad*.

**** Función de densidad

 \[f(x) = \frac{1}{\Gamma(\frac{k}{2})2^{k/2}} x^{k/2-1}e^{-x/2}\]

***** TODO Demostración
**** Función generatriz de momentos

\[M_X(t) = \frac{1}{(1-2t)^{n/2}}\], para $t < 1/2$.

***** TODO Demostración
**** Esperanza y varianza

 - $E[X] = k$
 - $Var[X] = 2k$

***** TODO Demostración

**** Propiedad de reproductividad
Si tengo una serie de variables independientes distribuidas 
por $X_i \leadsto \chi^2(k_i)$, entonces:

\[\sum_{i=1}^n X_i \leadsto \chi^2 \left(\sum_{i=1}^n k_i \right)\]

**** Relación con la distribución normal
Dadas variables independientes $X_i \leadsto {\cal N}(0,1)$,

 \[\sum_{i=1}^n X^2_i \leadsto \chi^2(n)\]

***** TODO Demostración

**** Aproximación
Para valores pequeños, pueden usarse tablas. Para valores grandes
de $n$, podemos aproximarla mediante el Teorema Central del Límite
como:

\[ \chi^2(x) \approx {\cal N}(n,2n)\]

***** TODO Demostración

**** TODO Gráfica de la función de densidad
*** Distribución t de Student
**** T de Student
Dadas dos variables independientes $X \leadsto {\cal N}(0,1)$ e $Y \leadsto \chi^2(n)$, 
tenemos:

\[ T = \frac{X}{\sqrt{Y/n}} \leadsto t(n) \]

**** Función de densidad

\[ f(t) 
= \frac
{\Gamma\left(\frac{n+1}{2}\right)}
{\Gamma\left(\frac{n}{2}\right) \sqrt{n\pi}} 
\left(
1 + \frac{t^2}{n}
\right)^{-\frac{n+1}{2}}
\], $t \in \mathbb{R}$

***** TODO Demostración

**** Momentos
Tenemos que $\exists E[T^k] \iff k < n$. Cuando existen, se tiene

 - $E[T] = 0$
 - $Var[T] = \frac{n}{n-2}$

***** TODO Demostración

**** Aproximación
Tabulada para $n$ pequeños y aproximada por ${\cal N}(0,1)$ para valores
grandes.

**** TODO Gráfica de la función de densidad
*** Distribución F de Snedecor
**** Definición
*F de Snedecor*. Dadas dos variables independientes $X \leadsto \chi^2(n)$ e
$Y \leadsto \chi^2(m)$, su cociente nos da:

\[F = \frac{X/m}{Y/n} \leadsto F(m,n)\]

**** Función de densidad

\[g(t)
= \frac
{\Gamma(\frac{m+n}{2})}
{\Gamma(\frac{m}{2})\Gamma(\frac{n}{2})}
\left(\frac{m}{n}\right)^{\frac{m}{2}}
t^{m/2-1}
\left(1+\frac{m}{n}t\right)^{-\frac{m+n}{2}}\], para $t>0$.

***** TODO Demostración

**** Momentos
Tenemos que $\exists E[T^k] \iff k < n/2$.

 - $n > 2 \Rightarrow \exists E[F] = \frac{n}{n-2}$
 - $n > 4 \Rightarrow \exists Var[F] = \frac{n^2(2m+2n-4)}{m(n-2)^2(n-4)}$

***** TODO Demostración

**** Propiedades
\[ F \leadsto F(m,n) \iff F^{-1} \leadsto F(n,m)\]
\[T \leadsto t(n) \iff T^2 \leadsto F(1,n)\]

**** Aproximación
La distribución está tabulada y las tablas incluyen aproximaciones 
para valores grandes de $n$ y $m$.

**** TODO Gráfica de la función de densidad
*** Muestreo de la normal
**** Lema de Fisher
Sea $(X_1,\dots,X_n)$ una muestra aleatoria simple con $X \leadsto {\cal N}(\mu,\sigma^2)$.
Los estadísticos $\overline{X}$ y $S^2$ son independientes.

***** TODO Demostración 
**** Distribuciones del muestreo de una normal unidimensional
***** Inferir la media con varianza conocida

\[\frac
{\overline{X}-\mu}
{\sigma/\sqrt{n}}
\leadsto
{\cal N}(0,1)\]

***** Inferir la media con varianza desconocida

\[\frac
{\overline{X} - \mu}
{S/\sqrt{n}}
\leadsto
t(n-1)\]

***** Inferir la varianza con media conocida

\[\frac
{\sum^n_{i=1}(X_i - \mu)^2}
{\sigma^2}
\leadsto
\chi^2(n)\]

***** Inferir la varianza con media desconocida

\[\frac
{(n-1)S^2}
{\sigma^2}
\leadsto
\chi^2(n-1)\]

*** Muestreo de dos normales
**** Extensión del lema de Fisher
Sean $X \leadsto {\cal N}(\mu_1,\sigma_1^2)$ y $Y \leadsto {\cal N}(\mu_2,\sigma_2^2)$ independientes.
Los vectores $(\overline{X},\overline{Y})$ y $(S^2_1,S^2_2)$ son independientes.

***** TODO Demostración
**** TODO Distribuciones del muestreo de dos normales unidimensionales

** 3. Suficiencia y completitud
*** Estadísticos suficientes y completos
**** Estadístico suficiente
Un estadístico $t$ es *suficiente* para un parámetro $\theta$ cuando una vez 
conocido no puede obtenerse más información de sobre $\theta$ de los datos;
esto es:

 \[\Pr(\theta| t,x) = \Pr(\theta|t)\]

***** Definición equivalente
De forma equivalente, es *suficiente* si la distribución condicionada 
al estadístico es independiente del parámetro $\theta$:

 \[\Pr(x|t,\theta) = \Pr(x|t)\]

**** Teorema de factorización de Fisher-Neyman
*Teorema de factorización de Fisher-Neyman*. $T$ es suficiente para $\theta$
ssi existen funciones no negativas $g$,$h$ tales que:

\[f_\theta(x) = h(x)g_\theta(T(x))\]

Donde $g_\theta$ sólo depende de $x$ a través de $T$ y $h$ no depende de $\theta$.

***** TODO Demostración
**** Propiedades de los estadísticos suficientes
*Propiedades de los estadísticos suficientes*.

  1. Si $T$ es suficiente para $\{P_\theta \mid \theta \in \Theta\}$, lo es para $\{P_\theta \mid \theta \in \Theta' \subset \Theta\}$.
  2. Si $T$ es suficiente y $T = h(U)$, $U$ es suficiente.
  3. Toda transformación biunívoca de suficiente es suficiente.

***** TODO Demostración
**** Estadístico completo
Un estadístico es *completo* cuando para cualquier función medible $g$,
se tiene:

\[ E_\theta [g(T)] = 0 \; \forall\theta\in\Theta \quad \Rightarrow \quad
    P_\theta(g(T) = 0) = 1\; \forall\theta\in\Theta\]

*** Suficiencia y completitud en familias exponenciales
**** Familia exponencial k-paramétrica
Una familia $\{P_\theta : \theta \in \Theta\}$ es exponencial k-paramétrica si:

 1. $\Theta$ es intervalo de $\mathbb{R}^k$.
 2. Los valores de la variable no dependen de $\theta$, esto es:
    $\{{ x \mid f_{\theta}(x) > 0 \} = \{{ x \mid f_{\theta'}(x) > 0 \}$ para cualesquiera $\theta,\theta' \in \Theta$.
 3. La familia es de la forma:

    \[f_\theta(x) = exp\left\{\sum_{h=1}^k {Q_h(\theta) T_h(x) + S(x) + D(\theta)}\right\}\]

**** Teorema de suficiencia y complitud
Si una familia $\{P_\theta : \theta \in \Theta\}$ es exponencial k-paramétrica, cualquier muestra
aleatoria simple también lo es:

\[
f^n_\theta(x_1,\dots,x_n) = 
exp\left\{
\sum^k_{h=1} Q_h(\theta) \left(
\sum^n_{i=1} T_h(x_i)
\right) +
\sum^n_{i=1} S(x_i) + nD(\theta)
\right\}
\]

Teniéndose además:

 1. $(\sum_i T_1(X_i), \dots \sum_i T_k(X_i))$ estadístico *suficiente* para $\theta$.
 2. Para $k \leq n$, cuando $(Q_1(\Theta), \dots Q_k(\Theta))$ contiene un abierto; entonces
    $(\sum_i T_1(X_i), \dots \sum_i T_k(X_i))$ es *completo*.

***** TODO Demostración
** 4. Estimación puntual
*** Planteamiento del problema de estimación
**** Estimador puntual
Un *estimador puntual* de $\theta$ es un estadístico $T$ tomando valores en el 
dominio del parámetro, $\Theta$.

**** Función de pérdida y de riesgo
La *función de pérdida*, $L(\theta,T)$, nos dice la pérdida asociada a estimar 
un parámetro si su verdadero valor es otro.

**** Función de riesgo
La *función de riesgo* es la que asocia a cada valor del parámetro la 
pérdida media asociada al estimador.

\[ R^L_T(\theta) = E_\theta [L(\theta,T)]\]

**** Estimador óptimo
El *estimador óptimo*, $T$, dada una función de pérdida, es el que minimiza 
uniformemente la función de riesgo:

\[ R^L_T(\theta) \leq R^L_{T''}(\theta),\quad \forall \theta \in \Theta,\; \forall T''\]

*** Estimación de menor error cuadrático
**** Función de pérdida cuadrática
La función de pérdida cuadrática, ${\cal L}(\theta, t) = (t - \theta)^2$, hace a la función de 
riesgo de un estimador su error cuadrático medio:

\[R^L_T(\theta) = E_\theta[(T - \theta)^2]\]

Nótese que en el caso de $E[T] = \theta$, se tiene $R^L_T(\theta) = Var_\theta[T]$.

*** Estimación insesgada de mínima varianza
**** Estimador insesgado
Un estimador $T$ de $g(\theta)$, es *insesgado* o *centrado* si:

 $E_\theta[T] = g(\theta)$

**** UMVUE: Estimador insesgado uniformemente de mínima varianza
Un estimador $T$ insesgado y de segundo orden es *UMVUE* para $g(\theta)$ si para 
cualquier otro estimador insesgado $T'$ se tiene que:

\[ Var_\theta[T] \leq Var_\theta[T']\]

***** De segundo orden
# ¿Seguro? No parece estar escrito en ningún sitio.
Lo llamamos de segundo orden cuando existe la varianza.

**** Propiedades del UMVUE
El estimador UMVUE cumple:

 - Unicidad: El UMVUE de cualquier función paramétrica, si existe, es único.
 - Linealidad: Si $T,Q$ son UMVUE para $g,h$; $aT+bQ$ es UMVUE para $ag+bh$.

***** Unicidad
Si existieran dos UMVUE con $Var(T) = Var(T')$, tendríamos:

\[\begin{aligned}
Var\left(\frac{1}{2}(T+T')\right) &= 
\frac{1}{4}
\left(
Var(T) + Var(T') + 2cov(T,T')
\right) \\& \leq
\frac{1}{4}
\left(
Var(T) + Var(T') + 2\sqrt{Var(T)Var(T')}
\right) \\& = Var(T)
\end{aligned}\]

La igualdad se da por ser UMVUE, y entonces, $cov(T,T') = Var(T)$.
De aquí $cov(T-T',T-T') = 0$, haciendo constante la diferencia entre los
dos. La diferencia entre ellos debe ser constantemente $0$ por ser ambos 
insesgados.

***** TODO Linealidad
**** Teorema de Raó-Blackwell
Si $T$ es suficiente para $\theta$ y $S$ es un estimador insesgado de $g(\theta)$ de 
segundo orden:

  - $E[S \mid T]$ es estimador insesgado de $g(\theta)$ de segundo orden.
  - $Var_\theta[E[S \mid T]] \leq Var_\theta[S]$

Es decir, $E[S \mid T]$ será normalmente mejor estimador y nunca peor que $S$.

***** Demostración
Sabemos $E[S|T] = E[S] = \theta$ por la [[*Ley de esperanza total][ley de esperanza total]]. La desigualdad
entre varianzas la vemos como:

\[\begin{aligned}
E\Big[(E[S|T] - \theta)^2 \Big] &= 
E\Big[E[S-\theta | T]^2 \Big] \leq
E\Big[E[(S-\theta)^2|T] \Big] = E\Big[(S-\theta)^2\Big]
\end{aligned}\]

Donde volvemos a usar la ley de esperanza total. La desigualdad viene
de que la varianza es positiva, o de la desigualdad de Jensen para el
cuadrado.

**** Teorema de Lehmann-Scheffé
Para $T$ suficiente y completo para $\theta$; si $g(\theta)$ admite un estimador insesgado 
de segundo orden $S$, entonces existe el UMVUE de $g(\theta)$ y está dado por:

\[ \mathbb{E} [S \mid T]\]

De otra forma, un estimador insesgado que es función de estimador completo
y suficiente es el UMVUE.

***** Demostración
Por [[*Teorema de Raó-Blackwell][Raó-Blackwell]], sabemos que es un estimador insesgado; y que, dado
cualquier otro estimador insesgado $Q$, tenemos que:

\[ Var[E[Q|T]] \leq Var[Q]\]

Ahora bien, dado otro, tendríamos:

\[
E\Big[ E[S|T] - E[Q|T] \Big] = 0
\]

Y como $T$ es completo y ambos son dependientes de $T$, eso implica que:

\[P\Big(
E[S|T] - E[Q|T] = 0
\Big) = 1\]

Por lo tanto, ambos son el UMVUE.

*** Estimación eficiente
**** Condiciones de regularidad de Fréchet-Cramer-Rao
Una familia de distribuciones es *regular en el sentido de 
Fréchet-Cramer-Rao* si cumple que, siendo $\{P_\theta \; \theta\in\Theta\}$:

 - $\Theta$ es intervalo abierto de $\mathbb{R}$.
 - $\forall \theta,\theta'\in\Theta : \{x \mid f_\theta(x) > 0\} = \{x \mid f_{\theta'}(x) > 0\}$
 - Tenemos $f_\theta(x)$ derivable respecto a $\theta$ para todo $x\in\chi$ con:

   \[ \int_\chi \frac{d f_\theta(x)}{d\theta} dx = 
   \frac{d}{d\theta} \int_\chi f_\theta(x) dx = 
   0, \quad \forall \theta\in\Theta\]
   
   O, cuando la distribución es discreta:
   
   \[\sum_\chi \frac{d f_\theta(x)}{d\theta} = \frac{d}{d\theta}\sum_\chi f_\theta(x) = 0\]

**** Función de información de Fisher
Si $\{P_\theta : \theta \in \Theta\}$ es regular, definimos la *función de información* asociada
a $X$ como:

\[I_X(\theta) = E_\theta\left[\left( \frac{d}{d\theta} \ln(f_\theta(X))
\right)^2\right]\]

Y la función de información asociada a una muestra como:

\[
\[I_{X_1,\dots,X_n}(\theta) = 
E_\theta\left[\left( \frac{d}{d\theta}\ln(f_\theta(X_1,\dots,X_n))
\right)^2\right]\]

**** Propiedades de la función de información
La función de información tiene como propiedades:

  1. $I_X(\theta) \geq 0$.
  2. En el caso $I_X(\theta) = 0$, $f_\theta(X)$ no depende de $\theta$.
  3. \[E_\theta \left[\frac{d}{d\theta} \ln f_\theta(X) \right] = 0\].
  4. \[ Var_\theta \left[\frac{d}{d\theta} \ln f_\theta(X) \right] = I_X(\theta) \].
  5. \[E_\theta \left[\frac{d}{d\theta} \ln f^n_\theta(X_1,\dots,X_n) \right] = 0\].
  6. \[ Var_\theta \left[\frac{d}{d\theta} \ln f_\theta(X_1,\dots,X_n) \right] = I_{X_1,\dots,X_n}(\theta) \].
  7. Aditividad, $I_{X_1,\dots,X_n}(\theta) = nI_X(\theta)$.
 
***** TODO Demostración

**** Estadístico regular
Un estadístico $T$ es regular en el sentido de Fréchet-Cramer-Raó, si
siendo una distribución discreta:

\[\begin{aligned}
\frac{d}{d\theta}
E_\theta[T] &=
\frac{d}{d\theta} 
\sum_{x \in \chi^n} T(x)f_\theta(x) \\&= 
\sum_{x \in \chi^n} T(x) \frac{d}{d\theta} f_\theta(x)
\end{aligned}\]

O, siendo una distribución continua:

\[\begin{aligned}
\frac{d}{d\theta}
E_\theta[T] &=
\frac{d}{d\theta} 
\int_{x \in \chi^n} T(x)f^n_\theta(x) \;dx \\&= 
\int_{x \in \chi^n} T(x) \frac{d}{d\theta} f^n_\theta(x) \;dx
\end{aligned}\]

**** Cota de Fréchet-Cramer-Raó
Si $\{P_\theta \mid \theta \in \Theta\}$ es *regular*, la función de información se 
acota $0 < I_X(\theta) < \infty$, y $T$ es un estadístico regular, de segundo orden e
insesgado en una función derivable $g(\theta)$, se tiene:

  1. \[Var_\theta[T] \geq \frac{g'(\theta)^2}{I_{X_1,\dots,X_n}(\theta)}\]
  2. Para todo $\theta \in \Theta$ tal que $g'(\theta) \neq 0$:

     \[Var_\theta[T] = \frac{g'(\theta)^2}{I_{X_1,\dots,X_n}(\theta)}\]
     
     ssi existe $a(\theta) \neq 0$ tal que:

     \[P_\theta\left(
     \frac{d}{d\theta} \ln f^n_\theta(X_1,\dots,X_n) = 
     a(\theta)[T(X_1,\dots,X_n) - g(\theta)]
     \right) = 1\]

***** TODO Demostración
**** Estimador eficiente
Sea $\{P_\theta \mid \theta \in \Theta\}$ regular, con la función de información acotada 
$0 < I_X(\theta) < \infty$ y $g(\theta)$ función paramétrica derivable. Un estimador $T$ de $g(\theta)$ 
es eficiente si es insesgado, regular, y su varianza alcanza la
cota de Fréchet-Cramer-Raó en todo punto:

\[Var_\theta[T] = \frac{(g'(\theta))^2}{I_{X_1,\dots,X_n}(\theta)},
\qquad \forall\theta \in \Theta\]

**** Caracterización de estimadores eficientes
Sea $\{P_\theta \mid \theta \in \Theta\}$ regular, con $0 < I_X(\theta) < \infty$ y $g(\theta)$ función paramétrica
derivable y no constante. Un estimador $T$ es eficiente ssi existe un $a(\theta)$
cumpliendo:

  1. \[P_\theta\left(\frac{d}{d\theta} \ln f^n_\theta(X_1,\dots,X_n) = a(\theta)[T(X_1,\dots,X_n) - g(\theta)]\right) = 1\]
  2. \[I_{X_1,\dots,X_n}(\theta) = a(\theta)g'(\theta)\]

***** Demostración
*** Estimación de máxima verosimilitud
**** Función de verosimilitud
Para cada realización muestral se define la función de verosimilitud
de la realización, $L_{x_1,\dots,x_n} : \Theta \longrightarrow \mathbb{R}^+_0$, como:

\[L(\theta) = f_\theta^n(x_1,\dots,x_n)\]

**** Estimador de máxima verosimilitud
Tenemos $\hat\theta$ estimador de máxima verosimilitud de $\theta$ cuando la estimación
asociada a cada realización muestral maximiza la verosimilitud:

\[L_{x_1,\dots,x_n}\left(\hat\theta(x_1,\dots,x_n)\right)
= \max_{\theta \in \Theta} L_{x_1,\dots,x_n}(\theta)\]

**** Relación con estadísticos suficientes
Si $\{P_\theta \mid \theta \in \Theta\}$ admite estadístico suficiente $T$, entonces $\hat\theta$ es función
de $T$.

***** TODO Demostración
**** Relación con estimadores eficientes
Si $T$ es estimador eficiente de $\theta$, entonces $T$ es el único estimador 
máximo verosímil de $\theta$.

***** TODO Demostración

**** Función de verosimilitud de una función paramétrica
Se define la función de verosimilitud de $g : \Theta \longrightarrow \Lambda$ asociada a
una realización, $M_{x_1,\dots,x_n} : \Theta \longrightarrow \mathbb{R}^+_0$, como:

\[M_{x_1,\dots,x_n}(\lambda)
= \sup_{\theta \in g^{-1}(\lambda)} L_{x_1,\dots,x_n}(\theta) \]

**** Estimador de máxima verosimilitud de una función paramétrica
Será $\hat\lambda$ estimador máximo verosímil de $\lambda$ cuando:

\[M_{x_1,\dots,x_n}(\hat\lambda(x_1,\dots,x_n)) 
= \max_{\lambda \in \Lambda} M_{x_1,\dots,x_n}(\lambda) \]

**** Teorema de invarianza de Zenha
Si $\hat\theta$ es estimador máximo verosímil de $\theta$, entonces $g(\hat\theta)$ es estimador
máximo verosímil de $g(\theta)$.

***** TODO Demostración

*** Método de los momentos
**** Descripción
El estimador máximo verosímil de una función dependiente en los momentos
poblacionales es el mismo dependiendo en los momentos muestrales.

\[g(\theta) = h(m_{\theta,1},\dots,m_{\theta,k}) 
\quad\Rightarrow\quad
\widehat{g(\theta)}(X_1,\dots,X_n) = h(A_1,\dots,A_k)\]

***** Momentos poblacionales
Definimos los momentos poblacionales como:

\[m_{\theta,j} = E_\theta[X^j]\]

***** Momentos muestrales
Definimos los momentos muestrales como:

\[A_j = \frac{1}{n}\sum_{i=1}^n X^j_i\]

***** TODO Demostración
*** Método de mínimos cuadrados
**** Descripción
Si $X_i$ son las observaciones aleatorias de una magnitud $\varphi(t,\theta)$ con
errores $\varepsilon_i$; es decir:

\[X_i = \varphi(t_i,\theta) + \varepsilon_i\]

Entonces el estimador de mínimos cuadrados de $\theta$ es el que minimice
la suma de cuadrados de los errores:

\[\sum^n_{i=1}(X_i - \varphi(t_i,\theta))^2\]

** 5. Estimación por intervalos de confianza
*** Definiciones y métodos de construcción
**** Intervalo de confianza
Para $X \leadsto P_\theta$, un intervalo de confianza $\alpha$ para $\theta$ es un intervalo 
aleatorio $(I_1,I_2)$ tal que para cualquier $\theta \in \Theta$:

\[P_\theta\left(
I_1(X_1,\dots,X_n) \leq \theta \leq I_2(X_1,\dots,X_n)
\right)
\geq 1 - \alpha\]

**** Intervalo de confianza de menor longitud esperada uniformemente
Un interavlo $(I_1,I_2)$ es el de menor longitud esperada uniformemente 
si para cualquier otro $(I_1',I_2')$ al mismo nivel, se tiene:

\[
E_\theta[I_2(X_1,\dots,X_n) - I_1(X_1,\dots,X_n)]
\leq
E_\theta[I_2'(X_1,\dots,X_n) - I_1'(X_1,\dots,X_n)]
\]

**** Intervalos obtenidos mediante desigualdad de Chevychev
Si $T$ es estimador insesgado de $\theta$ con varianza uniformemente acotada:

  - $E_\theta[T(X_1,\dots,X_n)] = \theta$
  - $Var_\theta[T(X_1,\dots,X_n)] \leq c$

Por lo que por Chevychev tenemos, dado $k>0$, un intervalo de confianza
para $\theta$ al nivel de confianza $1 - c/k^2$:

\[(T(X_1,\dots,X_n) - k,\  T(X_1,\dots,X_n) + k)\]

***** TODO Demostración

**** Pivote para un parámetro
Un pivote es una función $T(X_1,\dots,X_n,\theta)$ tal que fijado cualquier $\theta$,
$T(X_1,\dots,X_n,\theta)$ es una variable con distribución independiente de $\theta$.

**** Intervalos obtenidos mediante el método pivotal
Dado un pivote estrictamente monótono respecto a $\theta$, y dos valores $\lambda_1,\lambda_2$,
tales que para cualquier $\theta$:

\[P_\theta(\lambda_1 < T(X_1,\dots,X_n) < \lambda_2) \geq 1 - \alpha\]

Tomamos las soluciones $\hat\theta_1, \hat\theta_2$, cumpliendo $T(X_1,\dots,\hat\theta_1) = \lambda_1$ y
$T(X_1,\dots,\hat\theta_2) = \lambda_2$; y ellas forman un intervalo de confianza:

  - $P_\theta(\hat\theta_1 < \theta < \hat\theta_2) \geq 1 - \alpha$, para $T$ creciente.
  - $P_\theta(\hat\theta_2 < \theta < \hat\theta_1) \geq 1 - \alpha$, para $T$ decreciente.

***** TODO Demostración

**** Un pivote en distribuciones continuas
Si $X$ es continua con $F_\theta$ función de distribución, un pivote es:

\[ T(X_1,\dots,X_n,\theta) = -2 \sum_{i=1}^n \ln F_\theta(X_i) \leadsto \chi^2(2n)\]

***** TODO Demostración
**** Un pivote dado un estadístico
Sea $S$ un estadístico de distribución continua con $F^S_\theta$ función de 
distribución. Un pivote es:

\[T(X_1,\dots,X_n,\theta) = F^S_\theta(S(X_1,\dots,X_n)) \leadsto U(0,1)\]

*** Ejemplos de intervalos de confianza
**** Intervalo para la media de una normal con varianza conocida
Sea $X \leadsto {\cal N}(\mu,\sigma^2_0)$. Un intervalo de confianza para $\mu$ de menor longitud
media uniforme a nivel de confianza $1-\alpha$ será:

\[\left(
\overline{X}-z_{\alpha/2}\frac{\sigma_0}{\sqrt{n}},
\overline{X}+z_{\alpha/2}\frac{\sigma_0}{\sqrt{n}}
\right)\]

Siendo $z_{\alpha/2}$ el que cumple, con $Z \leadsto {\cal N}(0,1)$, que \[P\left(Z \leq z_{\alpha/2}\right) = \alpha/2\].

***** Pivote
Usamos como pivote a la normalizada:

\[T(X_1,\dots,X_n,\mu) = \frac{\overline{X} - \mu}{\sigma / \sqrt{n}} \leadsto {\cal N}(0,1)\]

***** Intervalos candidatos
Usando el pivote, tenemos el siguiente candidato a intervalo de
confianza:

\[
1 - \alpha > 
P_\mu\left(
\lambda_1 < 
\frac{\overline{X} - \mu}{\sigma_0 / \sqrt{n}} <
\lambda_2
\right)
=
P_\mu\left(
\overline{X} - \lambda_2\frac{\sigma_0}{\sqrt{n}} <
\mu <
\overline{X} - \lambda_1\frac{\sigma_0}{\sqrt{n}}
\right)
\]

Debiendo tenerse que, si $\Phi$ es la función de distribución de la
normal $\Phi(\lambda_2)-\Phi(\lambda_1) = 1 - \alpha$.

***** Longitud media
Buscamos el que minimice la longitud media:

\[E_\mu \left[
\left( \overline{X} - \lambda_1\frac{\sigma_0}{\sqrt{n}} \right) -
\left( \overline{X} - \lambda_2\frac{\sigma_0}{\sqrt{n}} \right)
\right] 
= (\lambda_2-\lambda_1)\frac{\sigma_0}{\sqrt{n}}\]

Por lo que tratamos de minimizar $(\lambda_2-\lambda_1)$.

***** Minimización
Usamos multiplicadores de Lagrange para definir:

\[F(\lambda_1,\lambda_2) = \lambda_2-\lambda_1 + \lambda(\Phi(\lambda_2) - \Phi(\lambda_1) - (1-\alpha))\]

Calculando las derivadas parciales tenemos:

\[\begin{aligned}
-1-\lambda\Phi'(\lambda_1) &= 0\\
1 + \lambda\Phi'(\lambda_2) &= 0
\end{aligned}
\]

Luego debe tenerse $\Phi'(\lambda_1) = \Phi'(\lambda_2)$. Sabiendo que $\Phi'$ es la función
de distribución de la normal, tenemos $\lambda_1 = \pm \lambda_2$. Como deben ser
distintos para cumplir la restricción, tenemos $\lambda_1 = -\lambda_2$.

***** Conclusión
La restricción nos fuerza a $\Phi(\lambda_2) - \Phi(-\lambda_2) = 1 - \alpha$, luego estamos
buscando el $z_{\alpha/2}$ que cumple, para una normalizada $Z$, $P(Z > z_{\alpha/2}) = \alpha/2$.

**** TODO Intervalo para la media de una normal con varianza desconocida
**** TODO Intervalo para la varianza de una normal con media conocida
**** TODO Intervalo para la varianza de una normal con varianza conocida
**** TODO Intervalo para la diferencia de medias de normales de varianza dada
**** TODO Intervalo para la diferencia de medias de normales de varianza igual
**** TODO Intervalo para el cociente de varianzas de normales de media dada
** 6. Contraste de hipótesis
*** Planteamiento del problema
**** Problema de contraste de hipótesis
Dada $(X_1,\dots,X_n)$ una muestra aleatoria simple de $X \leadsto P_\theta$, para
$\theta \in \Theta_0 \cup \Theta_1$, llamamos:

 - *Hipótesis nula*: $H_0 : \theta \in \Theta_0$
 - *Hipótesis alternativa*: $H_1 : \theta \in \Theta_1$

a dos hipótesis posibles.

**** Test de hipótesis
El *test de hipótesis* es un estadístico $\varphi$ tomando valores en $[0,1]$, que 
da la posibilidad de rechazar $H_0$ dada una realización muestral. Se 
llama:

 - *Test no aleatorizado*, si toma valores $0,1$.
 - *Test aleatorizado*, si toma valor distinto de $0,1$.

**** Tipos de errores de un test de hipótesis
Hay dos tipos de erorres:

 - *Error de tipo 1*: Rechazar $H_0$ siendo cierta. Falso negativo.
 - *Error de tipo 2*: Aceptar $H_0$ siendo falsa. Falso positivo.

**** Función de potencia de un test
Dado un test $\varphi$, su función de potencia $\beta_\varphi : \Theta \longrightarrow [0,1]$ se define:

\[\beta_\varphi(\theta) = E_\theta[\varphi(X_1,\dots,X_n)]\]

Que es la probabilidad media de rechazar $H_0$ bajo $P_\theta$.

**** Tamaño del test
El tamaño del test es $\sup_{\theta \in \Theta_0} \beta_\varphi(\theta)$, la máxima probabilidad media de
cometer un error de tipo 1.

**** Nivel de significación de un test
Un test $\varphi$ tiene nivel de significación $\alpha$ si su tamaño es menor o igual
que $\alpha$. Es decir,

\[
\forall \theta \in \Theta_0, \quad
\beta_\varphi(\theta) =
E_\theta[\varphi(X_1,\dots,X_n)] \leq
\alpha
\]

**** Test uniformemente más potente
Un test con nivel de significación $\alpha$ es uniformemente más potente a 
dicho nivel si para cualquier otro test $\varphi'$ con nivel de significación
$\alpha$, se tiene:

\[\beta_{\varphi'}(\theta) \leq \beta_\varphi(\theta)
\quad \forall \theta \in \Theta_1\]

*** Lema de Neyman-Pearson
**** El problema de contraste
Fijado un nivel de significación, encontrar el test uniformemente más
potente a dicho nivel.

**** Lema de Neyman-Pearson
Sea $X \longrightarrow \{P_{\theta_0}, P_{\theta_1}\}$ y $(X_1,\dots,X_n)$ una muestra aleatoria simple
con funciones de densidad $f_0,f_1$. Consideramos el problema de contraste 
con $H_0 : \theta = \theta_0$ y $H_1 : \theta = \theta_1$.

  1. Cualquier test de la forma:

     \[
     \varphi(X_1,\dots,X_n) = 
     \threepartdef
     {1}
     {f_1^n(X_1,\dots,X_n) > kf_0^n(X_1,\dots,X_n)}
     {\gamma(X_1,\dots,X_n)}
     {f_1^n(X_1,\dots,X_n) = kf_0^n(X_1,\dots,X_n)}
     {0}
     {f_1^n(X_1,\dots,X_n) < kf_0^n(X_1,\dots,X_n)}
     \]
     
     con $k \in \mathbb{R}^+_0$ y $\gamma(X_1,\dots,X_n) \in [0,1]$, es de máxima potencia entre todos
     los de nivel de significación $\alpha = E_{\theta_0}[\varphi(X_1,\dots,X_n)]$, su tamaño.
     
  2. Para todo $\alpha \in (0,1]$ existe un test de la forma anterior con
     $\gamma(X_1,\dots,X_n) = \gamma$ constante y tamaño $\alpha$.

  3. Si $\varphi'$ es de máxima potencia al nivel de significación
     $\alpha = E_{\theta_0}[\varphi'(X_1,\dots,X_n)]$, entonces $\varphi'(X_1,\dots,X_n)$ es de la forma anterior
     con probabilidad 1 bajo $P_{\theta_0}$ y $P_{\theta_1}$.

  4. El test de máxima potencia entre todos los de nivel de significación
     0 es:
     
     \[
     \varphi_0(X_1,\dots,X_n) = \twopartdef
     {1}{f^n_0(X_1,\dots,X_n) = 0}
     {0}{f^n_0(X_1,\dots,X_n) > 0}
     \]

***** TODO Demostración

*** Test de la razón de verosimilitudes
**** Test de la razón de verosimilitudes
Sea $(X_1,\dots,X_n) \in \chi^n$ una muestra aleatoria simple de $X \leadsto \{P_\theta \mid \theta \in \Theta_0 \cup \Theta_1\}$.
El test de razón de verosimilitudes para el problema de contraste con
$H_0 : \theta \in \Theta_0$ y $H_1 : \theta \in \Theta_1$; se define como:

\[
\varphi(X_1,\dots,X_n) = \twopartdef
{1}{\lambda(X_1,\dots,X_n) < c}
{0}{\lambda(X_1,\dots,X_n) \geq c}
\]

donde se define:

\[\lambda(x_1,\dots,x_n) = \frac
{\sup_{\theta \in \Theta_0} L_{x_1,\dots,x_n}(\theta)}
{\sup_{\theta \in \Theta} L_{x_1,\dots,x_n}(\theta)}
\]

siendo $L$ la función de verosimilitud y $c$ una constante que se determina
imponiendo el tamaño o nivel de significación requerido.

*** TODO Dualidad entre tests de hipótesis y regiones de confianza
** 7. Teoría general de modelos lineales
*** Modelo lineal general y modelo de Gauss Markov
**** Modelo lineal general
El modelo general lineal queda descrito por:

\[\mathbf{Y = X\beta + \varepsilon}\]

***** Vector observable
$Y = (Y_1,\dots,Y_n)$ es un vector aleatorio observable.

***** Matriz de diseño
Una matriz conocida $X$ de dimensión $n \times k$, cuyo rango determina el 
rango del modelo.

***** Vector de efectos
Un vector desconocido $\beta = (\beta_1,\dots,\beta_k)$.

***** Vector de errores
Un vector aleatorio no observable $\varepsilon = (\varepsilon_1,\dots,\varepsilon_n)$ representando el 
error entre $Y$ y $X\beta$.

**** Modelo de Gauss-Markov
Modelo lineal donde las componentes del vector de errores son variables
aleatorias de segundo orden, centradas, homocedásticas (igual varianza)
e incorreladas:

  - $E[\varepsilon_i] = 0$
  - $E[\varepsilon_i^2] = \sigma^2$
  - $E[\varepsilon_i\varepsilon_j] = 0$

***** Enunciado vectorial
Las condiciones sobre el vector de errores equivalen a exigir:

  - $E[\varepsilon] = 0$
  - $E[\varepsilon\varepsilon^T] = \sigma^2 I_{n \times n}$

**** Objetivo del modelo
Inferir $\beta$ y $\sigma^2$ a partir de observaciones del vector $Y$.

*** Estimación de mínimos cuadrados del vector de efectos
**** Modelo
Partimos del modelo de Gauss-Markov, y queremos minimizar la suma de
cuadrados de los errores:

\[S^2(\beta) = 
\sum^n_{i=1} \varepsilon^2_i =
\|Y - X\beta\|^2\]

***** Minimización
Para minimizarlo, calculamos la derivada:

\[\frac{\partial}{\partial \beta_h} S^2(\beta) = 
-2 \sum^n_{i=1} \left(
Y_i - \sum^k_{j=1} x_{ij}\beta_j
\right) x_{ih} = 0
\]

Y obtenemos las ecuaciones normales siguientes:

\[
\sum^n_{i=1} Y_i x_{ih} = \sum^n_{i=1}\sum^k_{j=1} x_{ij}x_{ih}\beta_j
\]

Que pueden expresarse matricialmente como:

\[X^TY = (X^TX)\beta\]

**** Estimador de mínimos cuadrados de beta
Llamamos $\widehat\beta$ al estimador de mínimos cuadrados de $\beta$.

  - Existencia: existe al menos un estimador de mínimos cuadrados de $\beta$.
  - Unicidad: garantizada cuando el modelo es de rango máximo por tenerse
    la solución \[\widehat\beta(Y) = (X^TX)^{-1}X^TY\].

**** Función lineal estimable
Una $\psi(\beta) = a_1\beta_1 + \dots + a_k\beta_k$ es estimable si admite un estimador insesgado,
lineal en las componentes de $Y$. Es decir:

\[\exists \widehat\psi(Y) = c_1Y_1 + \dots + c_nY_n\]

tal que $E[\widehat\psi(Y)] = \psi(\beta)$.

**** Teorema de Gauss-Markov
Si $\psi(\beta) = a_1\beta_1 + \dots + a_k\beta_k$ es estimable, admite un único estimador lineal
insesgado uniformemente de mínima varianza en la clase de estimadores
lineales insesgados. Dicho estimador es:

\[\widehat\psi(Y) = a_1\widehat\beta_1(Y) + \dots + a_k\widehat\beta_k(Y) \]

Donde $\widehat{\beta}(Y)$ es un estimador de mínimos cuadrados de $\beta$.

***** TODO Demostración

**** Propiedades del estimador de mínimos cuadrados en modelos de rango máximo
Sea $\widehat\beta(Y) = (X^TX)^{-1}X^TY$ el estimador de mínimos cuadrados en un modelo 
de rango máximo.

  1. $\widehat\beta_j(Y)$ es el estimador lineal insesgado de mínima varianza de $\beta_j$.
  2. Las varianzas y covarianzas vienen dadas: $Cov(\widehat\beta(Y)) = \sigma^2(X^TX)^{-1}$.
  3. Toda función lineal de las componentes de $\beta$ es estimable con 
     estimador lineal insesgado de mínima varianza
     $\widehat\psi(Y) = a_1\widehat\beta_1(Y) + \dots + a_k\widehat\beta_k(Y)$.

***** TODO Demostración

** Ejercicios
*** Tema 1. Introducción a la inferencia estadística
**** Ejercicio 1
#+begin_statement
Sea $(X_1,\dots,X_n)$ una muestra aleatoria simple de una variable $X$. Dar el espacio
muestral y calcular la función masa de probabilidad de $(X_1,\dots,X_n)$ en cada uno de
los siguientes casos:

  1. $X \longrightarrow \{{\cal B}(k_0,p); p \in (0,1)\}$ binomial
  2. $X \longrightarrow \{{\cal P}(\lambda); \lambda\in\mathbb{R}^+\}$ Poisson
#+end_statement

***** Punto 1
El espacio muestral es $\{0,1,\dots,k_0\}^n$, una palabra $k_0\text{-aria}$ de $n$ letras. 
Usando independencia:

\[P(x_1,\dots,x_n) = \prod P(x_i) 
= \prod_{i=1}^n \left({k_0 \choose x_i} p^{x_i}(1-p)^{k_0-x_i} \right)\]
***** Punto 2
El espacio muestral es $\mathbb{N}^n$, palabras en los naturales.
Usando independencia:

\[P(x_1,\dots,x_n) = \prod P(x_i) = \prod_{i=0}^n e^{-\lambda}\frac{\lambda^{x_i}}{x_i!}\]

**** Ejercicio 2
#+begin_statement
Sea $(X_1,\dots,X_n)$ una muestra aleatoria simple de una variable $X$. Dar el espacio
muestral y calcular la función masa de probabilidad de $(X_1,\dots,X_n)$ en cada uno de
los siguientes casos:

  1. $X \longrightarrow \{U(a,b); a,b\in\mathbb{R}; a < b\}$ uniforme
  2. $X\longrightarrow \{{\cal N}(\mu,\sigma^2)\}$ normal
#+end_statement
***** Punto 1
El espacio muestral aquí es $[a,b]^n$, donde por independencia tengo como función
de densidad:

\[f(x_1,\dots,x_n) = \prod f(x_i) = \left(\frac{1}{b-a}\right)^n\]

***** Punto 2
El espacio muestral es $\mathbb{R}^n$, siendo la función de densidad:

\[f(x_1,\dots,x_n) = 
\prod_{i=0}^n \frac{1}{\sigma\sqrt{2\pi}} 
e^{-\frac{1}{2}\left(\frac{x_i-\mu}{\sigma}\right)^2}\]

**** Ejercicio 4
#+begin_statement
Se dispone de una muestra aleatoria simple de tamaño 40 de una
distribución exponencial de media 3, ¿cuál es la probabilidad de que
los valores de la función de distribución muestral y la teórica, en
$x=1$, difieran menos de 0.01?  Aproximadamente, ¿cuál debe ser el
tamaño muestral para que dicha probabilidad sea como mínimo 0.98?
#+end_statement

***** Probabilidad de que difieran
Tenemos que $nF^\ast_X(1) \leadsto {\cal B}(n,F(1))$, luego podemos calcular la probabilidad
como:

\[\begin{aligned}
P\Big( F(1) - 0.01 < F^\ast(1) < F(1) + 0.01 \Big) = \\
P\Big( 10.93 < 40F^\ast(1) < 11.73 \Big) = \\
P\Big(10 < 40F^\ast(1) < 12) =\\
P\Big(11 = 40F^\ast(1)) =\\
{40 \choose 11} F(1)^{11}(1-F(1))^{40-11} \approx\\
0.1318
\end{aligned}\]

Sabiendo que $F(1) = 1 - e^{-1/3} \approx 0.283$ y que $F^\ast$ es variable discreta.

****** Cálculos
#+BEGIN_SRC R :results output
f1 = 1-exp(-1/3)
f1
n = 40
n*(f1 + 0.01)
n*(f1 - 0.01)
dbinom(11,n,0.3)
#+END_SRC

#+RESULTS:
: [1] 0.2834687
: [1] 11.73875
: [1] 10.93875
: [1] 0.1318644

***** TODO Tamaño muestral
Llamamos $\sqrt{\frac{1}{n}F(1)(1-F(1))} = \sigma_n$, y esta vez aplicamos el Teorema 
Central del Límite para tener que:

\[\frac{F^\ast(1) - F(1)}{\sigma_n} \leadsto {\cal N}(0,1)\]

Lo que buscamos es que:

\[\begin{aligned}
P\Big( -0.01 < F^\ast(1)-F(1) < 0.01 \Big) > 0.98 \\
P\Big( \frac{-0.01}{\sigma_n} < \frac{F^\ast(1)-F(1)}{\sigma_n} < \frac{0.01}{\sigma_n} \Big) > 0.98 \\
\end{aligned}\]

Dada $\Phi$ función de distribución de la normal tipificada, 
tenemos que:

\[\begin{aligned}
\Phi\left(\frac{0.01}{\sigma_n}\right) -
\Phi\left(\frac{-0.01}{\sigma_n}\right) > 0.98 \\
2\Phi\left(\frac{0.01}{\sigma_n}\right) > 0.98 +1 \\
1 -\Phi\left(\frac{0.01}{\sigma_n}\right) < 0.01
\end{aligned}\]

Usando la tabla de la normal, tenemos:

\[\frac{0.01}{\sigma_n} \geq 2.33\]

Desde donde calculamos:

\[n = 10978\]

# Esto debe estar mal

****** Cálculos
#+BEGIN_SRC R :results output
# Lookup on the normal distribution table
qnorm(1-0.01)
#+END_SRC

#+RESULTS:
: [1] 2.326348

*** Tema 2. Distribuciones en el muestreo de poblaciones normales
**** Ejercicio 1
#+begin_statement
Se toma una muestra aleatoria simple de tamaño $5$ de una variable aleatoria
con distribución ${\cal N}(2.5, 36)$. Calcular:

  1. Probabilidad de que la cuasivarianza muestral esté comprendida entre
     $1.863$ y $2.674$.
  2. Probabilidad de que la media muestral esté comprendida entre $1.3$ y $3.5$,
     supuesto que la cuasivarianza muestral está entre $30$ y $40$.
#+end_statement

***** Probabilidad de la Cuasivarianza
Buscamos:

\[\begin{aligned}
P\Big(1.863 \leq S^2 \leq 2.674 \Big) &\leq 
P\Big(\frac{n-1}{\sigma^2}1.863 \leq \frac{n-1}{\sigma^2}S^2 \leq \frac{n-1}{\sigma^2}2.674 \Big)
\end{aligned}\]

Y sabiendo que $\frac{n-1}{\sigma^2}S^2 \leadsto \chi^2(n-1)$, sea $\phi$ la función de distribución para
tener que la probabilidad será:

\[\phi\left(\frac{n-1}{\sigma^2}2.674\right) - 
\phi\left(\frac{n-1}{\sigma^2}1.863\right) =
0.010 - 0.005 = 0.005
\]

Consultando la tabla de Poisson.

****** Cálculos
#+BEGIN_SRC R
n = 5
s2 = 36
pchisq((n-1)/s2 * 2.674, df=n-1) - pchisq((n-1)/s2 * 1.863, df=n-1)
#+END_SRC

#+RESULTS:
: 0.00499959549303851

***** Probabilidad de la Media Muestral
La suposición de que la cuasivarianza muestral está entre 30 y 40 no
aporta nada porque la media y ella son estadísticos independientes por
el Lema de Fisher.

Buscamos:

\[P\Big(  
1.3 \leq \overline{X} \leq 1.5
\Big) = 
P\Big(  
\frac{1.3 - \mu}{\sigma/\sqrt{n}} \leq 
\frac{\overline{X} - \mu}{\sigma/\sqrt{n}} \leq 
\frac{1.5 - \mu}{\sigma/\sqrt{n}}
\Big)
\]

Y como $\frac{\overline{X} - \mu}{\sigma/\sqrt{n}} \leadsto {\cal N}(0,1)$, siendo $\phi$ la distribución de la normal, calculamos
la probabilidad usando las tablas de la normal.

\[
\phi(-0.3726) - \phi(-0.4472) = 0.3557 - 0.3300 = 0.0257
\]

****** Cálculos
#+BEGIN_SRC R
n = 5
m = 2.5
s2 = 36
s = sqrt(36)
pnorm((1.5-m)/(s/sqrt(n))) - pnorm((1.3-m)/(s/sqrt(n)))
#+END_SRC

#+RESULTS:
: 0.0273336344978247

**** Ejercicio 3
#+begin_statement 
¿De qué tamaño mínimo habría que seleccionar una muestra de una variable
con distribución normal ${\cal N}(\mu,4)$ para poder afirmar, con probabilidad mayor
que $0.9$, que la media muestral diferirá de la poblacional menos de $0.1$?
#+end_statement

Buscamos:

\[P\Big(
\frac{-0.1}{\sigma/\sqrt{n}} \leq 
\frac{\overline{X} - \mu}{\sigma/\sqrt{n}} \leq
\frac{0.1}{\sigma/\sqrt{n}}
\Big)\]

Sabiendo que $\frac{\overline{X} - \mu}{\sigma/\sqrt{n}} \leadsto {\cal N}(0,1)$, calculamos:

\[\begin{aligned}
1 - 2\phi\left(\frac{-0.1}{\sigma/\sqrt{n}}\right) &\geq 0.9 \\
\phi\left(\frac{-0.1}{\sigma/\sqrt{n}}\right) &\leq 0.05 \\
\end{aligned}\]

Usando la tabla de la distribución, tenemos que:

\[\frac{0.1}{2/\sqrt{n}} = 1.65\]

Desde donde: $n = 1089$.

***** Cálculos
#+BEGIN_SRC R
s2 = 4
s = sqrt(s2)
q = qnorm(1-0.05)
((s*q)/0.1)^2
#+END_SRC

#+RESULTS:
: 1082.21738163816

*** Tema 3. Suficiencia y complitud
**** Ejercicio 1
#+begin_statement
Sea $(X_1,\dots,X_n)$ una muestra aleatoria simple de una variable $X \leadsto B(k,p)$
y sea $T(X_1,\dots,X_n) = \sum^n_{i=1} X_i$. Probar, usando la definición y aplicando el
teorema de factorización, que $T$ es suficiente para $p$.
#+end_statement

***** Usando la definición
Llamamos $S = \sum^n_{i=1} X_i$. Veremos que $P(x_1,\dots,x_n\mid S)$ no depende de $p$.
En el caso $x_1+\dots+x_n \neq S$, la probabilidad es $0$ y claramente 
independiente de $p$. En el otro caso, tenemos:

\[\begin{aligned}
P(x_1,\dots,x_n\mid S) = 
\frac{P(x_1,\dots,x_n)}{P(S)} =
\frac
{\prod {k \choose x_i} p^{x_i}(1-p)^{k-x_i}}
{{nk \choose S} p^{S}(1-p)^{nk-S}} =
\frac
{\prod {k \choose x_i}}
{{nk \choose S}}
\end{aligned}\]

Que no depende de $p$. Hemos usado que $S = \sum_{i=1}^n X_i \leadsto {\cal B}(nk,p)$ para 
calcular la probabilidad de que valga un valor concreto.

***** Usando el teorema de factorización
Factorizamos la función de densidad como:

\[
f(x_1,\dots,x_n) =
\prod_{i=1}^n {k \choose x_i} p^{x_i}(1-p)^{k-x_i} =
\left(p^{\sum x_i}(1-p)^{nk - \sum x_i}\right)
\left(\prod^{k}_{i=1} {k\choose x_i}\right)
\]

El primer factor sólo depende de los datos a través de la suma y el
segundo factor no depende de la probabilidad.

**** Ejercicio 3
#+begin_statement
Sea $(X_1,X_2,X_3)$ una muestra aleatoria simple de una variable $X \leadsto B(1,p)$.
Probar que el estadístico $X_1+2X_2+3X_3$ no es suficiente.
#+end_statement

Llamamos $S=X_1+2X_2+3X_3$. Vamos a calcular $P(1,1,0\mid S=3)$ y 
comprobaremos que depende de $p$. Nótese que puede llegarse a $S=3$ de dos
formas, como $1+2+0$ y como $0+0+3$.

\[
P(1,1,0\mid S=3) =
\frac{P(1,1,0)}{P(S=3)} =
\frac{p^2(1-p)}{p^2(1-p)+p(1-p)^2}=
p
\]

*** Tema 4. Estimación puntual. Métodos de estimación
**** Ejercicio 2
#+begin_statement
Sea $(X_1,\dots,X_n)$ una muestra aleatoria simple de $X \leadsto B(1,p)$ y sea 
$T = \sum_{i=1}^n X_i$.

  1. Probar que si $k \in \mathbb{N}$ y $k\leq n$ el estadístico

     \[\frac{T(T-1)\dots(T-k+1)}{n(n-1)\dots(n-k+1)}\]

     es un estimador insesgado de $p^k$. ¿Es este estimador el UMVUE?
  2. Probar que si $k>n$, no existe ningún estimador insesgado para $p^k$.
  3. ¿Puede afirmarse que $\frac{T}{n}\left(1-\frac{T}{n}\right)^2$ es insesgado para $p(1-p)^2$?
#+end_statement

***** Punto 1. Es insesgado.
Llamamos $M = \frac{T(T-1)\dots(T-k+1)}{n(n-1)\dots(n-k+1)}$. Comprobamos que es insesgado calculando 
la esperanza. Dividimos entre los casos $i\leq k$ que son nulos y los demás.
Usamos $P(T = i) = {n \choose i}p^i(1-p)^{n-i}$.

\[\begin{aligned}
\mathbb{E}[M] &=
\sum_{i=1}^n {n \choose i} p^i (1-p)^{n-i}
\frac{i(i-1)\dots(i-k+1)}{n(n-1)\dots(n-k+1)} \\&=
\sum_{i=1}^n p^i (1-p)^{n-i}
\frac{(n-k)!}{(i-k)!((n-k)-(i-k))!} \\&=
p^k \sum_{i=1}^n p^{i-k} (1-p)^{(n-k)-(i-k)}
{n-k \choose i-k} \\&= p^k
\end{aligned}\]

Usando binomio de Newton en el último paso.

***** Punto 1. Es el UMVUE.
Usaremos el teorema de Lehmann-Scheffé, sabiendo que $M$ es un estimador
insesgado de $p^k$; y que $T$ es suficiente y completo para $p$.

Para ver que $T$ es completo, calculamos:

\[\begin{aligned}
\mathbb{E}[g(T)] 
&= \sum_{t=0}^n g(t) {n \choose t} p^t(1-p)^{n-t} \\
&= (1-p)^n \sum_{t=0}^n g(t) {n \choose t} \left(\frac{p}{1-p}\right)^t \\
\end{aligned}\]

Para que se anule siempre, debe anularse el polinomio
$\sum g(t) {n \choose t}r^t$ para $r \in \mathbb{R}^+$, lo que implica $g(t) = 0$.

Pero ahora, por Lehmann-Scheffé, tenemos que el UMVUE será:

\[\mathbb{E}[M\mid T] = \frac{T(T-1)\dots(T-k+1)}{n(n-1)\dots(n-k+1)}\]

Que es un UMVUE.
***** Punto 2.
Supongamos un estimador $Q$ que fuera insesgado para $p^q$. Tendríamos:

\[\mathbb{E}[Q(X)] = p^q\]

Es decir, llamando $R(T) = \sum_{\sum x_i = T} Q(X)$,

\[
\sum^n {n \choose k} R(t) p^t(1-p)^{n-t} = p^q
\]

Pero esto nos daría un polinomio de grado $q$ sobre $p$, que no puede ser 
nulo.

***** TODO Punto 3.
No. Si calculamos la esperanza usando linealidad obtenemos algo distinto.

#+BEGIN_SRC sage
n,p = var('n p')
m1 = n*p
m2 = m1*(1-p+m1)
m3 = m1*(1-3*p+3*m1+2*p^2 - 3*n*p^2 + n^2*p^2)
(p - 2*m2/n^2 + m3/n^3).normalize()
#+END_SRC

#+RESULTS:
: (n^2*p^3 - 2*n^2*p^2 - 3*n*p^3 + n^2*p + 5*n*p^2 + 2*p^3 - 2*n*p - 3*p^2 + p)/n^2

* Topología II
** 1. El grupo fundamental
*** 1. Espacios conexos por arcos
**** Arcoconexión
*Arcoconexión*. Las curvas definen relación de equivalencia cuando unen dos puntos.

 \[\exists f\ \text{arco}: f(0) = x, f(1) = y \Rightarrow x \sim y\]

Cada componente de esta partición es una *componente arcoconexa*. Un espacio es
*arcoconexo* cuando tiene una sola componente.

**** Operaciones en arcos y arcoconexión como equivalencia
Las propiedades de la relación de equivalencia se cumplen por:

 - 1. *Reflexividad*. Arco constante, $f(t) = x$, lleva a $x \sim x$.
 - 2. *Simetría*. Arco inverso, $\widetilde f(t) = f(1-t)$, lleva a $x\sim y \Rightarrow y \sim x$.
 - 3. *Transitividad*. Composición de arcos $f \ast g$.

La composición de arcos se define como:

\[f \ast g = \twopartdef{f(2t)}{t \leq \frac{1}{2}}{g(2t-1)}{t \geq \frac{1}{2}}\]

**** Arcoconexión y conexión
Un espacio *arcoconexo es conexo*. Un espacio *conexo localmente arcoconexo 
es arcoconexo*, que es conexo y donde todo punto posee un entorno arcoconexo.

***** Demostración
Dado un punto en un espacio arcoconexo, los caminos a los demás serán conexos y
compartirán un punto, luego su unión será conexa. Por otro lado, en un localmente
arcoconexo, todo punto está dentro de un abierto (tiene un entorno arcoconexo),
luego cada componente arcoconexa será abierta y si hubiera varias, contravendría
la conexión.

***** Contraejemplo del recíproco
Hay un contraejemplo de espacio conexo no arcoconexo en el
[[https://es.wikipedia.org/wiki/Seno_del_top%25C3%25B3logo][seno del topólogo]].

*** 2. Grupo fundamental
**** Homotopía de lazos
Un arco con $f(0) = f(1) = x$ es un *lazo* alrededor de $x$. Dos lazos son *homotópicos*
y escribimos $f \sim g$ cuando $\exists H: [0,1] \times [0,1] \longrightarrow X$, cumpliendo:

  - $H$ continua.
  - $H(t,0) = f(t)$
  - $H(t,1) = g(t)$
  - $H(0,s) = H(1,s) = x$

lo escribimos como $H : f \simeq g$.

**** Clases de homotopía
La homotopía es una relación de equivalencia entre lazos:

 - *Reflexividad*. Definiendo $H(t,s) = f(t)$, tenemos $H : f \simeq f$.
 - *Simetría*. Dada $G : g \simeq f$, definimos $H(t,s) = G(t,1-s)$, tenemos $H : f \simeq g$.
 - *Transitividad*. Dadas $F : f \simeq g$, $G : g \simeq h$, definimos
    \[H(t,s) = \twopartdef{F(t,2s)}{0\leq s \leq 1/2}{G(t,2s-1)}{1/2 \leq s \leq 1}\]
    Y tenemos $H : f \simeq h$.

Llamamos *clase de homotopía* $[f]$ a la clase de equivalencia de un lazo $f$.

**** Producto de clases de homotopía
El producto de lazos está bien definido entre las clases de homotopía. Sean 
$H : f_1 \simeq f_2$ y $G: g_1 \simeq g_2$; entonces definimos $F: f_1 \ast g_1 \simeq f_2 \ast g_2$ como:

\[ F(t,s) = \twopartdef{H(2t,s)}{0\leq t \leq 1/2}{G(2t-1,s)}{1/2 \leq t \leq 1}\]

**** El grupo fundamental
Comprobamos que las clases de homotopía sobre un $x$ forman un grupo con el producto:

\[\Pi(X,x) = \{[f] \mid f \text{ lazo alrededor de } x\}\]

***** Asociatividad
Para la *asociatividad*, definimos $H : (f \ast g) \ast h \simeq f \ast (g \ast h)$:

\[H(t,s) = \threepartdef
{f\left(t \frac{4}{1+s}\right)}{0\leq t\leq \frac{1+s}{4}}
{g\left(4t-1-s\right)}{\frac{1+s}{4}\leq t \leq \frac{2+s}{4}}
{h\left(t\frac{4}{2-s}-1\right)}{\frac{2+s}{4}\leq t\leq 1}\]

***** Elemento neutro
Como *elemento neutro* tomaremos el lazo constante $f_x(t)=x$. Y definimos  
$H : f_x \ast f \simeq f$:

\[ H(t,s) = \twopartdef
{f(t\frac{2t}{1+s})}{0\leq t\leq \frac{1+s}{2}}
{x}{\frac{1+s}{2}\leq t \leq 1}\]

***** Elemento inverso
Como *elemento inverso* tendremos el lazo $\hat{f}(t) = f(1-t)$. Y definimos 
$H : f \ast \hat{f} \simeq f$:

\[H(t,s) = \threepartdef
{f(2t)}{0\leq t\leq\frac{1-s}{2}}
{f(1-s)}{\frac{1-s}{2}\leq t\leq \frac{1+s}{2}}
{\hat{f}(2t-1)}{\frac{1+s}{2}\leq t\leq 1}\]

**** El grupo fundamental como funtor
Sea $\Phi : (X,x) \longrightarrow (Y,y)$ /continua/, entonces tenemos una aplicación bien definida 
por:

\[\Phi_\ast ([f]) = [\Phi \circ f] \]

Que es un homomorfismo de grupos. Podemos comprobar fácilmente que $Id_\ast = Id$ y que
$(\Psi\circ\Phi)_\ast = \Psi_\ast\circ\Phi_\ast$. Es decir, el grupo fundamental es un funtor de la categoría de 
los espacios topológicos punteados a la de los grupos.

***** Demostración
Sean $H: f \simeq g$, veamos que $\Phi\circ H: \Phi f \simeq \Phi g$. Tenemos que:

  - $\Phi\circ H$ continua
  - $\Phi\circ H(t,0) = \Phi\circ f(t)$
  - $\Phi\circ H(t,1) = \Phi\circ g(t)$
  - $\Phi \circ H(0,s) = \Phi \circ H(1,s) = y$

El que respeta el producto se tiene por $\Phi\circ (f \ast g) = \Phi\circ f \ast \Phi\circ g$.

**** Homotopía de arcos
Decimos que dos arcos cumpliendo $f(0)=g(0)$, $f(1)=g(1)$ son homotópicos cuando 
existe una función continua con características similares a la dada para lazos.

***** Propiedades
De demostración similar al caso de lazos:

  - Hay un arco simétrico $\tilde{f}$ tal que $f\ast \tilde{f} \simeq f_x$.
  - El producto es asociativo por homotopía $f \ast (g \ast h)\simeq (f\ast g)\ast h$-
    
**** Isomorfismo entre grupos fundamentales en distintos puntos
Sea un arco $\gamma : [0,1] \longrightarrow X$ cumpliendo $\gamma(0) = x$, $\gamma(1)=y$. Entonces se tiene un 
isomorfismo entre $\Pi(X,x)$ y $\Pi(X,y)$:

\[ F_\gamma([f]) = [\tilde\gamma\ast f\ast\gamma]\]

Por tanto, el grupo fundamental es el mismo en cualquier punto de la componente
arcoconexa.

***** Demostración
Para ver que está bien definido basta notar:

\[f \simeq g \Rightarrow 
\gamma\ast f\ast\tilde\gamma\simeq \gamma\ast g\ast\tilde\gamma\]

Que es homomorfismo se tiene viendo $F([f]\ast [g]) = F([f]) \ast F([g])$, y que es biyectivo
porque tiene inversa $G_\gamma([f]) = [\gamma\ast f\ast \tilde\gamma]$.

**** El grupo fundamental del producto
Dado el producto de dos espacios topológicos $X\times Y$ con proyecciones $\pi_1,\pi_2$. Tenemos
un isomorfismo entre grupos fundamentales:

\[F: \Pi(X\times Y, (x,y)) \longrightarrow \Pi(X,x)\times\Pi(Y,y)\]

Dado por:

\[F([f]) = (\pi_1([f]), \pi_2([f]))\]

*** 3. El grupo fundamental del círculo
**** Cálculo del grupo fundamental del círculo
Usaremos la teoría de recubridores que se probará luego.

Probamos que $\pi : \mathbb{R} \longrightarrow \mathbb{S}$ es un recubridor con $\pi(t) = e^{it}$; podemos tomar como entorno
fundamental de $p$ a $\mathbb{S}-\{p\}$, que tiene en la preimagen componentes arcoconexas 
homeomorfas a él. Siendo $t_0 \in \pi^{-1}(p)$:

\[V_m = (t_0 + 2\pi m, t_0 + 2\pi(m+1))\]

Definimos ahora el grado de un lazo en el círculo como:

\[\operatorname{deg}(f) = \frac{\hat{f}(1) - \hat{f}(0)}{2\pi} \]

Y comprobamos que está bien definido entre las clases de homotopía levantando
las homotopías y viendo que debe ser constante el punto final para que se proyecte
en un punto constante. Es decir $f \simeq g \Rightarrow \hat{f}(0) = \hat{g}(0)
\Rightarrow \hat{f}(1) = \hat{g}(1)$.

Como el levantamiento de la composición es la composición de levantamientos
y levantando de forma que $\hat{g}(0) = \hat{f}(1)$:

\[ \operatorname{deg}(f \ast g) =
   \frac{\widehat{f\ast g}(1) - \widehat{f\ast g}(0)}{2\pi} = 
   \frac{\hat{f}(1) - \hat{g}(0) + \hat{g}(1) - \hat{f}(0)}{2\pi} =
   \operatorname{deg}(f) + \operatorname{deg}(g) \]

Siendo un homomorfismo del grupo fundamental del círculo con $\mathbb{Z}$.

**** Teorema fundamental del álgebra
*Teorema fundamental del álgebra*. Todo polinomio con coeficientes
en $\mathbb{C}$ de grado $n$ tiene $n$ raíces en $\mathbb{C}$.

***** Demostración
Supongamos un $P$ que no tuviera raíz en $\mathbb{C}$.

Fijado un $r$, restringimos el polinomio desde la circunferencia de
radio $r$ a la circunferencia unidad, girándolo
además para que en $0$ valga $1$.

\[f_r(t) = \frac{|P(r)|}{P(r)} \frac{P(re^{2\pi it})}{|P(re^{2\pi it})|}\]

Tenemos una homotopía de este lazo al constante, definida como:

\[H(t,s) = f_{(1-s)r}(t)\]

Y por tanto, $deg(f_r) = 0$.

Por otro lado, sea ahora $R > 1, \sum |a_i|$, y tomemos $|z| = R$, tenemos
por un lado:

\[|z^n| 
 = R^n > R^{n-1}\left(\sum |a_i|\right) 
 \geq |a_1z^{n-1} + \dots + a_n|\]

Y por otro lado, si tomo un $t \in [0,1]$, puedo definir una familia
de polinomios $P_s(z) = z^n + t(a_1z^{n-1} + \dots + a_n) = 0$, que no tienen raíces
porque, por otro lado:

\[|z^n| = |t||a_1z^{n-1} + \dots + a_n| \leq |a_1z^{n-1} + \dots + a_n|\]

Luego esta familia de polinomios no tiene raíces en el círculo 
de radio $R$. Podemos ahora definir otra homotopía:

\[H(t,s) = \frac{P_s(Re^{2\pi it})}{|P_s(Re^{2\pi it})|}  \frac{|P_s(R)|}{P_s(R)}\]

Que es homotopía entre $e^{2\pi int}$ y $f_R(t)$. Luego $deg(f_R) = n$.

**** Lema al punto fijo de Brower
No existe aplicación continua $f : D^2\longrightarrow \mathbb{S}$ tal que $f|_\mathbb{S} = id$.

***** Demostración
Estamos buscando una aplicación cumpliendo:

\[ \begin{tikzcd}
\mathbb{S} \rar[hook]{i} & D^2 \rar{f} & \mathbb{S}
\end{tikzcd} \]

Aplicando el funtor obtendríamos:

\[ \begin{tikzcd}
\mathbb{Z} \rar[hook] & 0 \rar & \mathbb{Z}
\end{tikzcd} \]

Pero así es imposible obtener la identidad como composición.

**** Teorema del punto fijo de Brower
Toda función continua $f : D^2 \longrightarrow D^2$ tiene un punto fijo.

***** Demostración
Si no lo hubiera, para cada $x$ tomo $f(x)$ y la intersección de la recta que los une
con el círculo más cercana a $x$. Tengo una aplicación cuya restricción es la 
identidad.

**** Grupos topológicos
Un grupo topológico es un grupo en la categoría de espacios punteados. Esto es,
tal que la función producto y la función inverso son continuas.
**** Grupos topológicos y grupo fundamental
El producto en un grupo topológico respeta clases de homotopía:

\[ [f]\cdot [g] = [f\cdot g]\]

Y además, actúa sobre ellas igual que la composición:

\[ [f]\ast [g] = [f] \cdot [g]\]

*** 4. Tipo de homotopía. Equivalencias homotópicas
**** Aplicaciones homotópicas
Sean $F,G : X \longrightarrow Y$ continuas. Las decimos *homotópicas* si existe 
$H : X \times [0,1] \longrightarrow Y$ tal que $H(x,0) = F(x)$ y $H(x,1) = G(x)$. Lo notamos
por $H: F\simeq G$.

**** Grupo fundamental entre dos puntos
Entre cualesquiera puntos de dos funciones homotópicas $F(x_0)$, $G(x_0)$; tenemos un 
arco $\gamma = H(x_0,t)$. Se cumple que:

\[ \begin{tikzcd}
& \Pi(Y,F(x_0)) \arrow[leftrightarrow]{dd}{F_\gamma}\\
\Pi(X,x_0) \urar{F_\ast}\drar{G_\ast} \\
& \Pi(Y,G(x_0))
\end{tikzcd} \]

***** Demostración
Sea $f \in \Pi(X,x_0)$. Si defino la función $\hat{H}(t,s) = H(f(t),s)$ tengo una homotopía como
la siguiente:

\begin{tikzpicture}
\draw (A) -- node [above] {$G f$} ++ (-1, 0)
-- node [left]  {$\gamma$} ++ (0, -1)
-- node [below] {$F f$} ++ (1, 0)
-- node [right] {$\gamma$} ++ (0, 1);
\end{tikzpicture}

Rotándola obtengo:

\begin{tikzpicture}
\draw (A) -- node [above] {$G f \circ \gamma$} ++ (-1, 0)
-- node [left]  {$F(x_0)$} ++ (0, -1)
-- node [below] {$\gamma \circ F f$} ++ (1, 0)
-- node [right] {$G(x_0)$} ++ (0, 1);
\end{tikzpicture}

Lo que me da $[Gf \circ \gamma] = [\gamma \circ Ff]$, y por tanto $[Gf] = [\gamma \circ Ff \circ \tilde{\gamma}]$.

**** Equivalencia homotópica
Una *equivalencia homotópica* es una aplicación continua $F$, para la que
existe $G$ cumpliendo $F \circ G \simeq G \circ F \simeq Id$.

**** Propiedades de la equivalencia homotópica
Cumple:

1. Los homeomorfismos son equivalencias homotópicas.
2. La inversa de una equivalencia homotópica es equivalencia homotópica.
3. La composición de equivalencias homotópicas es equivalencia homotópica.

**** Conservación del grupo fundamental por equivalencia homotópica
Sea $F: X\longrightarrow Y$ equivalencia homotópica:

\[\forall x\in X : F_\ast : \Pi(X,x) \longrightarrow \Pi(Y,F(x))\]

Es un isomorfismo

***** Demostración
Por ser equivalencia homotópica tengo que $F \circ G \simeq Id$, luego se cumple:

\[ \begin{tikzcd}
& \Pi(X,F\circ G(x_0)) \arrow[leftrightarrow]{dd}{\cong}\\
\Pi(X,x_0) \urar{(F\circ G)_\ast}\drar{Id} \\
& \Pi(X,x_0)
\end{tikzcd} \]

Así, $(F\circ G)_\ast$, y de la misma forma $(G\circ F)_\ast$ son isomorfismos. Tenemos por tanto:

\[ \begin{tikzcd}
\Pi(X,x) \rar{F_\ast} \arrow[bend left=20]{rr}{\cong}
& \Pi(Y,F(x)) \rar{G_\ast} \dlar{\cong}
& \Pi(X,(G\circ F)(x)) \dlar{\cong}
\\
\Pi(Y,F(x)) \rar{F_\ast} \arrow[bend right=20]{rr}{\cong}
& \Pi(X,(G\circ F)(x)) \rar{F_\ast}
& \Pi(X,(G\circ F)(x))
\end{tikzcd} \]

Demostrando ambas filas que $F_\ast$ y $G_\ast$ son isomorfismos.

**** Lema a Borsuk-Ulam
No existe $F: \mathbb{S}^2 \longrightarrow \mathbb{S}^1$ continua respetando antípodas.

\[F(-x) = -F(x)\]

***** TODO Demostración
**** Teorema de Borsuk-Ulam
Sea $F:\mathbb{S}^2 \longrightarrow \mathbb{R}^2$ continua, entonces:

\[\exists x\in\mathbb{S}^2 : F(-x) = F(x)\]

***** Demostración
Supongamos que no se cumpliera, definimos:

\[G(x) = \frac{F(x)-F(-x)}{|F(x)-F(-x)|}\]

Y entonces $G$ sería continua respetando antípodas.

**** Teorema del sandwich de jamón
Sean $A,B\subset \mathbb{R}^2$ compactos y conexos. Existe una recta dividiendo a ambos en dos
trozos de igual área.

***** TODO Demostración
**** Espacio proyectivo
En $\mathbb{S}^n$ defino la ralación de equivalencia $p \sim q$ ssi $p = \pm q$. Definimos el 
espacio proyectivo como el cociente bajo esta relación:

\[\mathbb{RP}^n = \mathbb{S}^n}/\sim\]

*** 5. Teorema de Seifert-Van Kampen
**** Producto libre de grupos
Si definimos el *producto libre* de grupos en términos de palabras; podemos 
llamar *grupo libre sobre un conjunto de generadores* al producto libre del 
grupo libre generado por cada uno de ellos.

**** Subgrupo normal generado
El *subgrupo normal generado* por un subgrupo $B$ o por un conjunto de 
generadores es:

\[ \{g \cdot b \cdot g^{-1} \mid g\in G, b\in B\}\]

**** Producto libre amalgamado
Sean tres grupos $A$, $G_1$, $G_2$ y dos proyecciones de $A$ en ellos, llamadas 
$\Phi_1,\Phi_2$. Definimos el *producto libre amalgamado* como:

\[G_1 \ast_{A} G_2 =
\frac{G_1 \cdot G_2}{N} = \frac{G_1 \cdot G_2}{\{\Phi_1(a)=\Phi_2(a)\}}\]

Donde estamos dividiendo por $N$, el subgrupo normal generado por 
$\{\Phi_1(a)\Phi_2(a)^{-1} \mid a \in A\}$. Es decir, imponemos la relación $\Phi_1(a) = \Phi_2(a)$.

**** Teorema de Seifert-Van Kampen
Sea $X$ espacio topológico con $U,V$ abiertos arcoconexos no vacíos de $X$ tales 
que $X = U \cup V$ y $U\cap V$ son arcoconexos. Existe un isomorfismo:

\[\Theta : \Pi(U,x) \ast_{\Pi(U\cap V,x)} \Pi(V,x) \longrightarrow \Pi(X,x)\]

donde se amalgama usando $i_\ast$, $j_\ast$, homomorfismos dados por las inclusiones.

**** Seifert-Van Kampen para intersección simplemente conexa
En las condiciones del teorema, con $U\cap V$ simplemente conexo, se tiene:

\[\Pi(X,x) \cong \Pi(U,x)\ast\Pi(V,x)\]

**** Seifert-Van Kampen para abierto simplemente conexo
En las condiciones del teorema, con $V$ simplemente conexo, se tiene:

\[\Pi(X,x) \cong \Pi(U,x)/N\]

Con $N$ es el subgrupo normal generado por $i_\ast(\Pi(U\cap V,x))$.

*** Extra: Teoría de categorías
**** El grupo fundamental como funtor
El grupo fundamental $\Pi$ es un funtor entre las categorías:

- =Top.= de los espacios topológicos con un punto base, usando como morfismos
  las funciones continuas respetando punto base.
- =Grp= de los grupos con los homomorfismos de grupos.

Estamos llamando $f_\ast$ a los morfismos creados por el funtor, $\Pi(f)$.

**** Producto categórico
El producto de dos espacios con un punto base es, usando la topología producto:

\[(X,x) \times (Y,y) \cong (X\times Y, (x,y))\]

El funtor lo lleva al producto de grupos.

**** Coproducto categórico
El coproducto de dos espacios con un punto es la suma directa de los espacios
identificando el punto. Intuitivamente, consiste pegar los dos espacios por ese
punto.

\[ X \wedge Y \cong (X \amalg Y)/(x\sim y)\]

Cuando además tenemos espacios localmente contractibles, el coproducto se lleva
al coproducto de grupos, esto es, al producto libre:

\[\Pi(X \wedge Y) \cong \Pi(X) \ast \Pi(Y)\]

Nótese que esto es un caso particular de Seifert-Van Kampen.

**** TODO Seifert-Van Kampen
** 2. Recubridores
*** 1. Introducción
**** Localmente arcoconexo
Un espacio es *localmente arcoconexo* si todo punto posee una base de 
entornos arcoconexos.

/Durante este tema tomamos los espacios como arcoconexos y localmente 
arcoconexos/.

**** Recubridores
Un *recubridor* de $X$ es un par $(Y,p)$ donde $p : Y \longrightarrow X$ es continua; 
cumpliendo que todo $x\in X$ tiene un entorno abierto $U$, llamado *entorno 
fundamental* tal que toda componente arcoconexa de $p^{-1}(U)$ se aplica 
homeomórficamente por $p$ sobre $U$.

**** Ejemplos de recubridores
Ejemplos básicos de recubridores son:

- Cualquier homeomorfismo $p : Y \longrightarrow X$
- $p : \mathbb{S}^1\longrightarrow\mathbb{S}^1$, con $p(z) = z^n$

**** Homeomorfismos locales
Un *homeomorfismo local* es una aplicación continua $f : Y \longrightarrow X$ tal que para 
todo $y\in Y$ existe $y \in V\in\tau_Y$ tal que $f|_V$ es homeomorfismo.

**** Propiedades de un recubridores
Sea $(Y,p)$ recubridores de $X$. Entonces:

1. $p$ es sobreyectiva.
2. $p$ es una aplicación abierta.
3. $p$ es un homeomorfismo local.

***** Demostración
La sobreyectividad es trivial por la definición. Dado un abierto $y\in O$; 
tengo $y \in V_y \cong U_x$ su entorno abierto, luego $p(O\cap V_y)$ es abierto. De esta 
forma,

\[p(O) = \bigcup_{y\in O} p(O \cap V_y)\]

es abierto.

*** 2. Grupo fundamental y levantamiento de aplicaciones al recubridor
**** Levantamiento de arcos
Sea $(Y,p)$ recubridor con $x_0\in X$ y $y_0 \in p^{-1}(x_0)$. Sea $f : [0,1]\longrightarrow X$ arco 
continuo con $f(0) = x_0$, entonces existe un único arco continuo $\check{f}$ cumpliendo:

  - $\check{f}(0) = y_0$
  - $p \circ \check{f} = f$

    Llamado el *levantamiento* de $f$.

***** Existencia
Tomo $\{f^{-1}(U^x) \mid x\in X\}$, que recubre por abiertos a $[0,1]$. Sabemos que 
existirá una partición del intervalo cumpliendo:

\[\exists 0 < t_1 <\dots < t_n < 1: f([t_i,t_{i+1}]) \subseteq U^{x_i}\]

La correspondiente $y_i \in V^{y_i}$ nos da un isomorfismo $p_i$ que nos 
deja definir $\check{f} : [t_i,t_{i+1}] \longrightarrow V^{y_i}$ mediante $\check{f} = (p|_{V^{y_i}})^{-1} \circ f$. Nótese que para 
tomar cada $y_i$ necesitamos usar la componente arcoconexa de la última $\check{f}(t_{i-1})$.

***** Unicidad
Sean dos levantamientos $g_1,g_2$. Su conjunto ecualizador es cerrado:

\[ A = \{ t \mid g_1(t) = g_2(t)\} \neq \varnothing\]

Pero también es abierto porque dado un punto donde coincidan, puedo tomar la 
componente arcoconexa que es isomorfa por $p$ a un entorno abierto; y las 
curvas deben coincidir en él.

**** Levantamiento de homotopías
Sea $(Y,p)$ recubridor con $x_0\in X$ y $y \in p^{-1}(x_0)$. Sea $H : [0,1]\times[0,1] \longrightarrow X$ 
continua con $H(0,0) = x_0$, entonces existe una única aplicación
continua $\check{H} : [0,1]\times [0,1] \longrightarrow Y$ cumpliendo:

  - $p \circ \check{H} = H$
  - $\check{H}(0,0) = y_0$

    Llamada el *levantamiento* de $H$.

***** Existencia
Tomamos las $\{ H^{-1}(U^x) \mid x \in X \}$ y tenemos recubrimiento por abiertos de $[0,1]^2$. 
Tendremos alguna partición cumpliendo:

\[\exists 0 < t_1 < \dots < t_n < 1 : 
H([t_i,t_{i+1}]\times[s_i,s_{i+1}]) \subset U^{x_i}\]

En la correspondiente $y_i \in V^{y_i}$ podemos definir 
$\check{H} = (p|_{V^{y_i}}^{-1})\circ H$. Nótese que tenemos que usar en cada paso la componente arcoconexa
del último lado unido a nuestro cuadrado, que no puede salirse de esa componente
por ser arcoconexa.

***** TODO Unicidad
**** Hojas del recubridor
Sea $p : Y\longrightarrow X$ recubridor. Los cardinales de los $p^{-1}(x)$ son un invariante 
llamado el *cardinal de hojas del recubridor*.

***** Demostración
Puedo definir una biyección entre $p^{-1}(x_1)$ y $p^{-1}(x_2)$ tomando un arco entre 
ellas $\gamma$, y levantándolo en cada componente. Los arcos arriba me relacionan 
los dos conjuntos. La biyección se obtiene levantando $\tilde\gamma$, que sé que es $\tilde{g}$ 
porque ella ya es un levantamiento y es único.

**** Los recubridores crean monomorfismos
Sea $p: Y \longrightarrow X$ recubridor, entonces $p_\ast : \Pi(Y,y) \longrightarrow \Pi(X,x)$ es monomorfismo.

***** Demostración
Supongamos $p_\ast[h] = 0$; tengo una homotopía $H : p \circ h \simeq f_x$ que puedo levantar tomando
$\check{H}(0,0)=y$ y sabiendo $p \circ \check{H} = H$. Tengo:

\[ p \circ \check{H} (t,0) = H(t,0) = (p\circ h)(t)\]
\[ p \circ \check{H} (t,1) = H(t,1) = f_x(t) = x\]

Luego $\check{H}(t,0) = h(t)$ porque son levantamientos de lo mismo y $\check{H}(t,1) = y$ para poder
ser levantamiento. Esto me da $\check{H} : h \simeq f_y$.

**** Conjugación y recubridores
Si $p : Y \longrightarrow X$ es recubridor y $x\in X$, entonces la familia de subgrupos:

\[ \left\{p_\ast(\Pi(Y,y)) \mid y\in p^{-1}(x)\right\}\]

forma exactamente una clase de conjugación de subgrupos de $\Pi(X,x)$.

***** Demostración
Sea $\gamma$ camino entre $y_1,y_2 \in p^{-1}(x)$ con el isomorfismo $F_\gamma([f]) = [\tilde\gamma \ast f \ast \gamma]$, construimos 
el diagrama:

\[ \begin{tikzcd}
\Pi(Y,y_1) \rar{F_\gamma} \dar{p_\ast} & \Pi(Y,y_2) \dar{p_\ast} \\
\Pi(X,x) \rar{F_{p \circ \gamma}}& \Pi(X,x)
\end{tikzcd} \]

Que es conmutativo:

\[ \begin{tikzcd}
\math{[f]} \rar{F_\gamma} \dar{p_\ast} & 
\math{[\tilde\gamma \ast f \ast\gamma]} \dar{p_\ast} \\
\math{[p\circ f]} \rar{F_{p \circ \gamma}} & 
\math{[p(\tilde\gamma) \ast p(f) \ast p(\gamma)]}
\end{tikzcd} \]

Y que nos da por tanto:

\[ p_\ast(\Pi(Y,y_2)) = 
F_{p\circ\gamma}(\Pi(Y,y_1)) =
[p(\tilde\gamma)] \ast \Pi(Y,y_1) \ast [p(\gamma)]
\]

Ahora, sea una clase de conjugación de la proyección de un grupo fundamental
$H = [g]^{-1} \ast p_\ast(\Pi(Y,y)) \ast [g]$. El levantamiento $\check{g}$ da un camino entre dos puntos de 
$p^{-1}(x)$, y vemos que:

\[ \begin{aligned}
H &= \{[g]^{-1} \ast [p\circ h] \ast g \mid [h] \in \Pi(Y,y)\} \\
&= \{[p\circ \tilde{\check{g}} \ast p\circ h \ast p \circ \check{g}] \mid [h] \in \Pi(Y,y)\} \\
&= p_\ast(F_{\check{g}}(\Pi(Y,y))) = p_\ast(\Pi(Y,y'))
\end{aligned} \]

**** Levntamiento de aplicaciones
Sea $\Phi : Z \longrightarrow X$ continua con $x_0 = \Phi(z_0)$, $y_0 \in p^{-1}(x_0)$. Tenemos que
$\exists! \Psi : Z \longrightarrow Y$ continua cumpliendo:

- $\Psi(z_0) = y_0$
- $p \circ \Psi = \Phi$

ssi $\Phi_\ast(\Pi(Z,z_0)) \subset p_\ast(\Pi(Y,y_0))$.

***** Demostración
Definimos:

\[\check\Phi(z) = \widehat{\Phi \circ f}(1)\]

Siendo el levantamiento de la imagen de una curva que tenía $f(1)=z$, $f(0)=z_0$.
Esta es una función que lo cumple; debemos demostrar que está *bien definida* y
que es continua. Esto es, $\widehat{\phi \circ g}(1) = \widehat{\phi\circ f}(1)$, para otro $g$ cumpliendo lo mismo que $f$.

Como tenemos por la condición que $\phi_\ast[f \ast\tilde{g}] = p_\ast(\alpha)$, tenemos que ambas
$H : \phi(f \ast \tilde{g}) \simeq p\circ \alpha$. Tomamos $[f \circ \tilde{g}]$ para ver:

\[ p(\widehat{\phi\circ f} \ast \widehat{\phi\circ g}) = 
\phi\circ f \ast \widetilde{\phi\circ g}\]

Y usando eso, levantamos la homotopía, para tener 
$\check{H} : \widehat{\phi\circ f} \ast \widehat{\phi \circ \tilde{g}} 
\simeq \alpha$. Pero como $\alpha$ es lazo, tengo que es lazo lo primero.

Para ver que es *continua*, sea $\check{\Phi}(z) \in O$, abierto. Tenemos $p(O)$ abierto y tomamos
$W$ como la arcocomponente de la preimagen de $U^{\Phi(z)}$ en la que está $\check{\Phi}(z)$. Ahora
sea $\Phi(z) \in p(W \cap O)$, abierto por homeomorfismo; y sea

$\Phi(\hat{O}) \subset p(W \cap O)$, que existe por continuidad de $\Phi$ y es abierto arcoconexo. 

Veamos que $\Phi(\hat{O}) \subset \check{\Phi}^{-1}(O)$. Si $\hat{z} \in \hat{O}$, entonces hay un arco $g$ que une $z$ y $\hat{z}$; y tenemos
$\Phi(g) \subset p(W\cap O)$; como hay homeomorfismo, su levantamiento está en $W \cap O$, y
se tiene:

\[\check{\Phi}(z) = \widehat{\Phi(g)}(1) \in O\]

**** Estructura de grupo topológico
Sea $G$ un grupo topológico con neutro $e$. Sea $(\check{G},p)$ un recubridor y 
$\check{e} \in p^{-1}(e)$. Entonces $\check{G}$ admite una estructura de grupo topológico que tiene
a $\check{e}$ como elemento neutro y a $p$ como homomorfismo de grupos.

*** 3.1. Isomorfismos de recubridores
**** Homomorfismos
Sean $(Y_1,p_1)$, $(Y_2,p_2)$ recubridores. Un *homomorfismo de recubridores* es
$\Phi : (Y_1,p_1) \longrightarrow (Y_2,p_2)$ continua con $p_2 \circ \Phi = p_1$.

\[ \begin{tikzcd}
Y_1 \drar[swap]{p_1} \arrow{rr}{\Phi} & & Y_2 \dlar{p_2} \\
& X &
\end{tikzcd} \]

**** Propiedades de los homomorfismos de recubridores
Los homomorfismos de recubridores cumplen:

   1. La composición de homomorfismos es homomorfismo.
   2. La identidad $Id : Y \longrightarrow Y$ es homomorfismo.
   3. El inverso de isomorfismo es isomorfismo.

      Llamamos $Aut(Y,p)$ al *grupo de automorfismos* de un recubridor.
      # ¡Forman una categoría! Debe ser algo como una "slice category".

**** Puntos fijos de los automorfismos de recubridores
Sean dos homomorfismos de recubridores $\Phi,\Psi$ con $\Phi(y) = \Psi(y)$ en algún punto; 
entonces $\Phi = \Psi$. Por tanto, todo automorfismo distinto de la identidad actúa 
sin puntos fijos.

**** Existencia de homomorfismos
Existe un homomorfismo de recubridores $\Phi : (Y_1,p_1) \longrightarrow (Y_2,p_2)$ con $\Phi(y_1) = y_2$ ssi
$p_1_\ast(\Pi(Y_1,y_1)) \subseteq p_2_\ast(\Pi(Y_2,y_2))$. Es isomorfismo en el caso de igualdad.

**** Existencia de isomorfismos
Dos recubridores son isomorfos ssi las clases de conjugación asociadas a sus 
proyecciones al grupo fundamental son iguales:

\[\{ p_1_\ast(\Pi(Y_1,y)) \mid y\in p_1^{-1}(x)\}
= \{ p_2_\ast(\Pi(Y_2,y)) \mid y\in p_2^{-1}(x)\}\]

**** Ejemplos de recubridores
***** Espacios simplemente conexos
Sólo se admiten a sí mismos como recubridores.
***** Circunferencia unidad
Grupo fundamental isomorfo a $\mathbb{Z}$ y abeliano. Sus subgrupos son de la forma $m\mathbb{Z}$,
así que, salvo isomorfismos, sus recubridores son de la forma:

\[ p_0 : \mathbb{R} \longrightarrow \mathbb{S}^1,\ p(t) = e^{it} \]
\[p_m : \mathbb{S}^1 \longrightarrow \mathbb{S}^1,\ p_m(z) = z^m\]

***** Espacio proyectivo
Como $\mathbb{R}\mathbb{P}^n$ tiene grupo fundamental $\mathbb{Z}_2$, tiene sólo a $(\mathbb{RP}^n,Id)$ y a $(\mathbb{S}^n,p)$ 
como recubridores.

**** Recubridores de recubridores
Sean $(Y_1,p_1)$, $(Y_2,p_2)$ dos recubridores, y sea $\Phi : Y_1 \longrightarrow Y_2$ un homomorfismo de 
recubridores. Entonces $(Y_1,\Phi)$ es un recubridor de $Y_2$.

**** Recubridores universales
Un recubridor $(\check{X},p)$ de $X$ es *universal* si $\check{X}$ es simplemente conexo.

*** 3.2. Automorfismos de recubridores
**** Acción del grupo fundamental
Sea $(Y,p)$ un recubridor y $x$ punto de $X$ definimos la acción

\[ (\cdot) : p^{-1}(x) \times \Pi(X,x) \longrightarrow p^{-1}(x) \]

construyendo $y \cdot \alpha$ como sigue: sea $\alpha = [f]$, tomamos $\check{f}(0) = y$ y llamamos 
$y \cdot \alpha = \check{f}(1)$.

***** TODO Está bien definida
***** TODO Es una acción transitiva
***** TODO Espacios homogéneos.
**** Índice y hojas del recubridor
Sea $(Y,p)$ recubridor; su número de hojas es el índice del subgrupo  $p_\ast(\Pi(Y,y))$ 
en $\Pi(X,x)$; donde $y \in p^{-1}(x)$.

**** Automorfismos del espacio homogéneo
Un *automorfismo del espacio homogéneo* $p^{-1}(x)$ es una biyección
$\varphi : p^{-1}(x) \longrightarrow p^{-1}(x)$ tal que:

\[ \varphi(y \cdot \alpha) = \varphi(y) \cdot \alpha\]

**** Automorfismos del espacio homogéneo y automorfismos de recubridores
Como dado un automorfismo de recubridores $\Phi\in Aut(Y,p)$, tenemos que 
$\Phi(y\cdot \alpha) = \Phi(y)\cdot\alpha$, tenemos $\Phi|_{p^{-1}(x)}$ un automorfismo del espacio homogéneo.
De hecho, es isomorfismo de grupos:

\[ ( \bullet |_{p^{-1}(x)}) : Aut(Y,p) \longrightarrow Aut(p^{-1}(x))\]

***** Demostración
****** La restricción es automorfismo en el espacio homogéneo
Sea $y\in p^{-1}(x)$, tenemos $p(\Phi(y)) = p(y) = x$, luego $\Phi(y) \in p^{-1}(x)$.

****** Los automorfismos de recubridor respetan la acción de grupos
Sea $[f]=\alpha$, y sea $\check{f}$ su levantamiento en $y$; si considero $\Phi(\check{f})$ puedo 
comprobar que $\Phi(\check{f})(0) = \Phi(y)$ y que $p \circ \Phi (\check{f}) = f$, luego es el levantamiento
de $f$ en $\Phi(y)$. Así:

\[\Phi(y)\cdot\alpha = \Phi(\check{f})(1) = \Phi(y \cdot \alpha)\]

****** Es inyectiva
Llamamos $F = (\bullet |_{p^{-1}(x)})$. Sea $\Phi\in\ker(F)$, entonces $\Phi|_{p^{-1}(x)} = Id$; pero dos
homomorfismos de recubridores coindiciendo en un punto son iguales.

****** Es sobreyectiva
Sea $\varphi\in Aut(p^{-1}(x))$. Por el lema de existencia:
       
\[\exists \phi\in Aut(Y,p): \phi(y) = \varphi(y) \Leftrightarrow
p_\ast(\Pi(Y,y)) = p_\ast(\Pi(Y,\varphi(y))\]
       
Pero tenemos la igualdad de estos dos grupos de isotropía por:
       
\[\begin{aligned}
H_{\varphi(y)} 
&= \{\alpha\in\Pi(X,x) \mid \varphi(y)\cdot\alpha = \varphi(y)\} \\
&= \{\alpha\in\Pi(X,x) \mid \varphi(y\cdot\alpha) = \varphi(y)\} \\
&= \{\alpha\in\Pi(X,x) \mid y\cdot\alpha = y\} = H_y\\
\end{aligned}\]
       
**** Identificación de automorfismos de un espacio homogéneo
Dado $E$ espacio homogéneo sobre $G$, existe el isomorfismo:

\[ Aut(E) \cong N(H)/H \]

donde $H = \operatorname{Stab}(y)$ y $N(H)$ es su normalizador, el mayor 
grupo en el que es normal.

**** Identificación de automorfismos del recubridor
Aplicando las dos identificaciones anteriores:

\[Aut(Y,p) \cong N(p_\ast(\Pi(Y,y))) / p_\ast(\Pi(Y,y))\]

**** Recubridores regulares
Un recubridor es *regular* cuando $p_\ast(\Pi(Y,y))$ es subgrupo normal de 
$\Pi(X,x)$ siendo $y \in p^{-1}(x)$. Equivalen, por conjugación:

- $\exists x\in X, y \in Y: p_\ast(\Pi(Y,y))$ subgrupo normal en $\Pi(X,x)$.
- $\forall x\in X, y \in Y: p_\ast(\Pi(Y,y))$ subgrupo normal en $\Pi(X,x)$.

**** Propiedades de recubridores regulares
Sea $(Y,p)$ un recubridor regular:

1. $Aut(Y,p) \cong \Pi(X,x)/p_\ast(\Pi(Y,y))$
2. Si es el universal, $Aut(Y,p) \cong \Pi(X,x)$. Y el número de hojas es 
   el orden de $\Pi(X,x)$.

**** Ejemplos de recubridores
***** Circunferencia, recubridor universal
Tenemos el recubridor $(\mathbb{R},p)$ de $\mathbb{S}$, que tiene como automorfismos:

\[Aut(\mathbb{R},p) = \{\Phi_n(t) = t + 2\pi n \mid n \in \mathbb{N}\}\]

***** Espacio proyectivo
Siendo $(\mathbb{S}^n,p)$ un recubridor de dos hojas de $\mathbb{RP}^n$, sus automorfismos 
vienen dados por:

\[Aut(\mathbb{RP}^n,p) = \{Id, -Id\}\]

***** Circunferencia, otros recubridores
Sean los recubridores $(\mathbb{S}^1,p_n)$ de $\mathbb{S}^1$. Sus grupos de automorfismos son:

\[Aut(\mathbb{S}^1,p_n) = \left\{\Phi_k(z) = e^{\frac{2\pi k}{n}i}z 
\mid k = 0,1,\dots,n-1 \right\}\]

**** Teorema de Borsuk-Ulam
No existe una aplicación continua $F : \mathbb{S}^2 \longrightarrow \mathbb{S}^1$ respetando antípodas, es decir,
$F(-x) = -F(x)$.

*** 4. Recubridores regulares y espacios cocientes
**** Acción transitiva de automorfismos de recubridores regulares
$Aut(Y,p)$ actúa transitivamente sobre $p^{-1}(x)$ ssi $(Y,p)$ es regular.

**** Acciones discontinuas
Un $G \subset Homeo(Y)$ *actúa discontinuamente* si:
 
\[\forall y\in Y: \exists V_y\text{ entorno}: \forall \Phi \in G:\quad
\Phi \neq Id \Rightarrow \Phi(V) \cap V = \varnothing\]

**** Recubrimiento de cocientes
Sea $G \subset Homeo(Y)$ actuando propia y discontinuamente sobre $Y$. Si
$p : Y \longrightarrow Y/G$ es proyección al cociente, $(Y,p)$ es recubridor regular de $Y/G$, 
con $Aut(Y,p) = G$.

**** Espacios lente
Sean las aplicaciones $\Phi_k : \mathbb{S}^{2n+1} \longrightarrow \mathbb{S}^{2n+1}$ definidas por:

\[\Phi_k(z) = e^{\frac{2\pi ik}{p}}z\]

Entonces $G_p = \{\Phi_0,\Phi_1,\dots,\Phi_{p-1}\}$ actúa discontinuamente. Llamamos *espacio 
lente* al cociente:

\[ L_p^{2n+1} = \mathbb{S}^{2n+1}/G_p\]

*** 5. Existencia de espacios recubridores
**** Caso del recubridor universal
Si $X$ admite recubridor universal, toda clase de conjugación de subgrupos de
$\Pi(X,x)$ está asociada a un recubridor.

**** Espacios semilocalmente simplemente conexos
Todo $x$ posee un entorno abierto y arcoconexo $U_x$ tal que el homomorfismo 
inducido por la inclusión $\Pi(U_x,x) \longrightarrow \Pi(X,x)$ es trivial.

***** Contraejemplo
El espacio formado por infinitos círculos de radio cada vez menor y unidos 
en un punto:

\[ X = \bigcup_{n>0} \left\{(x,y) \in \mathbb{R}^2 \mid 
\left(x-\frac{1}{n}\right)^2 + y^2 = \frac{1}{n^2} \right\}\]

cumple que cualquier entorno del $(0,0)$ contiene un lazo no trivial.

**** Existencia del recubridor universal
Un espacio semilocalmente simplemente conexo tiene recubridor universal.

**** Teorema de existencia de recubridores
Sea $X$ semilocalmente simplemente conexo. Para toda clase de conjugación de 
subgrupos de $\Pi(X,x)$, existe un recubridor que la tiene asociada.

***** Demostración
Sea $C$ clase de conjugación de algún $H < \Pi(X,x)$. Sea $Y$ recubridor universal 
de $X$, que existe por ser semilocalmente simplemente conexo, cumpliendo 
$Aut(Y,p) \cong \Pi(X,x)$; puedo tomar $G < Aut(Y,p)$ cumpliendo $G \cong H$.

Los automorfismos del recubridor actúan discontinuamente, así que $Y/G$ es un 
espacio del que es $Y$ recubridor. Induciendo la siguiente aplicación:

\[ \begin{tikzcd}
Y \rar{p} \dar{q} & X \\
Y/G \urar{\hat{p}} &
\end{tikzcd} \]

Que está bien definida por respetar la relación y es continua. Veamos que es 
un recubridor. Sea $U^x$ entorno fundamental, las arcocomponentes de su 
preimagen cumplen:

\[ p^{-1}(U) = \bigcup_{\phi\in Aut(Y,p)} \phi(V) \]

Si tenemos en cuenta que $\forall \phi \in G: q(\phi(V)) = q(V)$, tendremos:

\[\hat{p}^{-1}(U)
= \bigcup_{\phi \in Aut(Y,p)/G} q(\phi(V)) \]

Donde hay $[G:H]$ componentes. Ahora intentamos ver que $\hat{p}_\ast(\Pi(Y/G,-))$ genera
la clase de conjugación de $C$. Recordando cómo actuaban los caminos en el 
espacio base sobre los puntos del recubridor, buscamos los $\alpha\in\Pi(X,x)$ que 
cumplan $q(y)\cdot\alpha = q(y)$, es decir $\exists \phi\in G: y\cdot\alpha = \phi(y)$; luego tenemos $\alpha\in H$. Si 
tengo otro $\beta \in H$, debe cumplir $\phi(y) = y\cdot\beta$ para algún $\phi\in G$, y entonces
$q(y)\cdot\alpha = q(y)$, siendo de los buscados. Tenemos:

\[\hat{p}(\Pi(Y/G, q(y)) = \operatorname{Stab}(q(y)) = H\]

**** Clasificación de recubridores del círculo
El círculo $\mathbb{S}^1$ tiene como grupo fundamental a $\mathbb{Z}$, que es abeliano y tiene como 
subgrupos a $n\mathbb{Z}$.

- $0$ tiene a la *recta* como recubridor universal $\mathbb{R}$ con $p(t) = e^{2\pi it}$.
- $n\mathbb{Z}$ tiene al *círculo* como recubridor $\mathbb{S}^1$ de $n$ hojas con $p(z) = z^n$.
- $\mathbb{Z}$ tiene al recubridor *identidad*.

**** Clasificación de recubridores del toro
El toro $\mathbb{S}^1\times\mathbb{S}^1$ tiene como grupo fundamental a $\mathbb{Z}\times\mathbb{Z}$, que tiene como subgrupos 
a los generados por un generador $<(a,b)>$ o a los generados por dos, de la 
forma $<(a,b),(0,d)>$.

- $0$ tiene al *plano* como recubridor universal $\mathbb{R}^2$ con $p(x,y) = (e^{2\pi ix},e^{2\pi iy})$.
- $<(a,b)>$ tiene al *cilindro* como recubridor $\mathbb{S}\times\mathbb{R}$ con $p(z,y) = (az, bze^{2\pi iy})$.
- $<(a,b),(0,d)>$ tienen al *toro* como recubridor $\mathbb{S}\times\mathbb{S}$ con
  $p(z,w) = (z^a,z^bw^d)$.

**** Clasificación de recubridores del cilindro
El cilindro $\mathbb{S}\times\mathbb{R}$ tiene como grupo fundamental a $\mathbb{Z}$, que es abeliano y tiene 
como subgrupos a $n\mathbb{Z}$.

- $0$ tiene al *plano* como recubridor universal $\mathbb{R}^2$ con $p(x,y) = (e^{2\pi ix},y)$.
- $n\mathbb{Z}$ tiene al *cilindro* como recubridor universal con $p(z,y) = (e^{2\pi inz},y)$.
- $\mathbb{Z}$ tiene al recubridor *identidad*.

**** Clasificación de recubridores de la cinta de Möbius.
La cinta de Möbius tiene tipo de homotopía del círculo y por tanto grupo 
fundamental $\mathbb{Z}$. 

- $0$ tiene al *plano* como recubridor universal $\mathbb{R}^2$ sobre el que actúa el grupo
  $\phi_n(x,y) = (x+n, (-1)^ny)$ discontinuamente.
- $n\mathbb{Z}$ con $n = 2m$ par tiene al *cilindro* recubriéndose a sí mismo $m$ veces y 
  un recubrimiento de dos hojas del *cilindro* a la banda de Möbius.
- $n\mathbb{Z}$ con $n$ impar tiene a la *banda de Möbius* como recubridor.
- $\mathbb{Z}$ tiene al recubridor *identidad*.
** 3. Superficies compactas
*** 3.0. Clasificación de variedades 1-dimensionales
**** Variedad 1-dimensional
Una variedad topológica 1-dimensional es un espacio topológico que
sea:

  - Conexo.
  - $T_2$, [[https://en.wikipedia.org/wiki/Hausdorff_space][Hausdorff]].
  - 2AN, [[https://en.wikipedia.org/wiki/Second-countable_space][segundo axioma de numerabilidad]].

y tal que:

\[\forall x \in X : \exists x \in U_x \in \tau:\quad
U_x \cong\: ]a,b[\]

**** Ejemplos
***** Los reales y el círculo
$\mathbb{R}$ es variedad trivialmente. El círculo $\mathbb{S}^1$ es también una variedad.

***** Contraejemplo: lemniscata
Un espacio que se cruza consigo mismo formando una lemniscata
es un contraejemplo. No hay abierto homeomorfo a un entorno del cruce.

[[file:./images/lemniscata.svg]]

***** Contraejemplo: folium
Una curva inyectiva y continua que se aproxima a un punto sin contenerlo.
Ninguno de los entornos del punto crítico tiene un entorno abierto
homeomorfo a un intervalo.

#+begin_center
#+attr_latex: :width 50px
[[./images//folium.png]]
#+end_center

***** Contraejemplo de 2AN
No existe una base numerable para el punto $(0,0)$ si usamos la
topología que une la recta izquierda con cada una de las rectas
derechas de forma separada, no podemos encontrar una base
numerable.

\[
X
=
\{(x,0) \mid x<0\}
\cup
\left(
\bigcup_{y \in \mathbb{R}\setminus\{0\}}
\{(x,y) \mid x \geq 0\}
\right)\]

#+begin_center
#+attr_latex: :width 50px
[[./images//2an.png]]
#+end_center

**** Clasificación de variedades topológicas en dimensión 1
Toda variedad topológica 1-dimensional es homeomorfa a $\mathbb{R}$ o a $\mathbb{S}^1$.

*** 3.1. Variedades topológicas
**** Espacio localmente euclídeo
Un espacio $X$ es localmente euclídeo cuando cada punto admite un
entorno abierto homeomorfo a un abierto de $\mathbb{R}^n$.

***** Definición equivalente
Cada punto admite un entorno abierto homeomorfo a una bola 
abierta de $\mathbb{R}^n$.

***** Carta
Cada entorno con su homeomorfismo forma una carta local $(U_x,\phi)$.

***** Bola euclídea
Carta homeomorfa a la bola unidad euclídea.

**** Variedad topológica
Una variedad topológica es un espacio topológico cumpliendo:

  1. Localmente euclídeo.
  2. Hausdorff $T_2$.
  3. Segundo axioma de numerabilidad 2AN.

A una variedad de dimensión 2 la llamamos *superficie*.

**** Ejemplos de variedades topológicas
***** Los espacios euclídeos
***** Las esferas n-dimensionales
***** Recubridores de espacios localmente euclídeos
***** Recubiertos por espacios localmente euclídeos

**** Teorema de la invarianza de la dimensión
Si $U \subseteq \mathbb{R}^n$ y $V \subseteq \mathbb{R}^m$ son abiertos homeomorfos, $n=m$.
Por tanto cada variedad tiene una dimensión asignada.

***** TODO Demostración
# Necesita de invariantes distintos al grupo fundamental.
# Homologías seguramente. (?)

**** Base de las cartas
Los dominios de las cartas forman una base de la topología.

***** Demostración
Usamos simplemente que la intersección de un abierto con
una carta es una carta con el homeomorfismo restricción.

Dado un abierto, cada punto suyo tiene un entorno que es
una carta. Al intersecarlo con el abierto da otra carta,
y finalmente el abierto inicial es unión de todas las
cartas en cada punto.

**** Bola regular euclídea
Sea $B \subseteq X$ una bola euclídea, es regular cuando:

  1. Existe $B' \subseteq X$ bola euclídea con $\overline{B} \subseteq B'$.
  2. Existe $r > 0$ y una carta $\phi : B' \longrightarrow B(0,2r)$ tal que $\phi(\overline{B}) = \overline{B(0,r)}$.

***** Contraejemplos
Una esfera sin un punto es una bola euclídea pero no una bola
regular euclídea.

**** Base de las bolas regulares euclídeas
Las bolas regulares euclídeas forman una base de la topología de una
variedad topológica.

***** Existencia de bola regular euclídea
En una variedad topológica sea $p \in S$ y $U \subseteq S$ entorno de $p$ abierto.
Existe una bola regular euclídea con $p \in B \subseteq U$.

****** Demostración
Es localmente euclídeo, luego localmente habrá una bola centrada
en la imagen de $p$ y otra de mitad de radio. Su preimagen será
regular euclídea.

***** Demostración
En cualquier entorno existe una bola regular euclídea entre
el punto y el entorno.

**** Autohomeomorfismo de superficies conexas
Sea $S$ superficie conexa con $p,q \in S$. Entonces existe $f : S \overset{\cong}\longrightarrow S$
con $f(p) = q$.

***** Lema al endomorfismo
Existe una constante $\varepsilon \in ]0,1]$ tal que dado $x \in B(0,\varepsilon)$, existe
un $F : \mathbb{R}^2 \overset{\cong}\longrightarrow \mathbb{R}^2$ con:

  1. $F(0) = x$.
  2. $F|_{\mathbb{R}^2\setminus D(0,2)}$ es la identidad.

****** TODO Demostración

***** Demostración
Consideremos la relación de equivalencia $pRq$ cuando $\exists f : S \cong S$
con $f(p) = q$. Veamos que $[p]$ es abierta por $p$ arbitrario y por
tanto, $[p] = S$.

****** La clase de equivalencia es abierta
Dado $p$, tenemos $O$ disco [[*Base de las bolas regulares euclídeas][regular]] centrado en él y $O'$ disco 
euclídeo cubriendo su clausura y cumpliendo:

\[
\exists \phi : O' \overset{\cong}\longrightarrow D(0,\varepsilon)
\]

con $\phi(O) = \overline{D(0,\varepsilon/2)}$. El lema nos da una $F_x(0) = x$.

Definimos $D_0 = \phi^{-1}(D(0,\varepsilon)) \subset D'$, abierto cubriendo a $p$. Y para
cualquier $y \in D_0$, definimos la función $G_y : S \cong S$ como:

\[
G_y(z) = \left\{\begin{array}{ll} 
z & \mbox{if } z \notin O'  \\
\phi^{-1} \circ F_{\phi(y)} \circ \phi& \mbox{if } z \in O'
\end{array} 
\right.
\]

Lo que nos da $D_0 \subseteq [p]$, haciéndolo abierto.

**** Recubridor de una superficie
Sea $\pi : \widetilde{X} \longrightarrow X$ recubridor:

  1. Si $\widetilde X$ es una superficie y $A_\pi = \{(x,y) \in \widetilde{X} \times \widetilde{X} \mid \pi(x) = \pi(y) \}$
     es cerrado, entonces $X$ es superficie.
  2. Si $X$ es superficie, $\widetilde{X}$ es superficie.

***** TODO Demostración

*** 3.2. Complejos simpliciales
**** P-símplice
Sean $v_1,\dots,v_p \in \mathbb{R}^n$ afínmente independientes. Se define el *p-símplice*
generado como:

\[
\langle v_0,\dots,v_p \rangle
=
\left\{\;
\sum_{j=0}^p \lambda_jv_j 
\;\middle|\;
0 \leq \lambda_j \leq 1, \sum_{j=0}^p \lambda_j = 1
\;\right\}
\]

Llamamos a los $v_i$ *vértices* del p-símplice y al entero $p$ se le llama
*dimensión* del p-símplice.

***** P-símplice abierto
Se define el *p-símplice abierto* como:

\[
{\cal O}(\langle v_0,\dots,v_p \rangle)
=
\left\{
\sum_{j=0}^p \lambda_jv_j 
\;\middle|\;
0 < \lambda_j \leq 1, \sum_{j=0}^p \lambda_j = 1
\right\}
\]

Observemos que en general no es igual al interior de un p-símplice,
que puede ser vacío en una dimensión alta.

***** Caras de un p-símplice
Las *caras* de un p-símplice $\sigma$ son los k-símplices generados por $k+1$ 
de sus vértices. Se notan por $\tau < \sigma$.

Llamamos *aristas* a las caras de dimensión 1 y *triángulos* a las 
caras de dimensión 2.

**** Complejo simplicial
Colección de símplices $K$ en algún $\mathbb{R}^n$ cumpliendo:

  1. $\tau < \sigma, \sigma \in K \implies \tau \in K$.
  2. $\sigma,\tau \in K,\; \sigma \cap \tau \neq \varnothing$ $\implies$ $\sigma \cap \tau < \sigma$ y $\sigma \cap \tau < \tau$.
  3. Todo punto en el símplice tiene un entorno abierto que corta a
     una cantidad finita de símplices en $\bigcup_{\tau \in K}\tau \subseteq \mathbb{R}^n$.

Llamamos *dimensión* de $K$ a la dimensión del mayor símplice que 
contiene.

***** Subcomplejo simplicial
Llamamos subcomplejo simplicial a $K' \subseteq K$ complejo simplicial.

**** Poliedro
Dado $K$ complejo simplicial, llamamos *poliedro* de $K$ al espacio
topológico formado por la unión de todos los símplices de $K$ con 
la topología inducida:

\[|K| = \bigcup_{\tau \in K} \tau \subseteq \mathbb{R}^n\]

**** Un compacto corta una cantidad finita de símplices
Sea $G \subseteq |K|$ compacto, entonces $G$ corta a una cantidad finita de
símplices de $K$. En particular $|K|$ compacto tiene una cantidad 
finita de símplices.

***** Demostración
Supongamos $\{\tau_n\}$, tomamos $\{p_n\} \in G \cap \tau_n$. Por compacidad habría 
una parcial convergente $\{p_n\} \longrightarrow p_\infty \in G \subseteq |K|$.

Pero por definición de complejo simplicial, este $p_\infty$ tiene un
entorno que corta sólo a una cantidad finita de símplices y por
tanto, de los $p_n$.

**** Aplicaciones simpliciales
Una $f : |K|\longrightarrow |L|$ entre complejos simpliciales es *aplicación simplicial* 
si:

  1. $f$ lleva símplices de $K$ en símplices de $L$.
  2. La restricción de $f$ a cada símplice es afín $Ax+b$.

***** Homeomorfismos simpliciales
Una aplicación simplicial homeomorfismo la llamamos 
*homeomorfismo simplicial*.

***** Categoría de las aplicaciones simpliciales
La inversa de un homeomorfismo simplicial es homeomorfismo simplicial;
así como la identidad y la composición de funciones. Las aplicaciones
simpliciales forman una categoría.

****** TODO Demostración

**** Superficies triangulables
Una superficie topológica $S$ se dice *triangulable* si existe algún 
complejo simplicial de dimensión $2$ con $S \cong |K|$.

**** Teorema de Radó
Toda superficie admite una triangulación por un complejo simplicial
euclídeo de dimensión 2 donde cada 1-símplice es cara de exactamente
dos símplices.

***** Recíproco falso
No todo complejo simplicial es triangulación de una superficie.

**** Caracterización de triangulaciones
Un complejo simplicial $K$ de dimensión 2 es triangulación de una
superficie ssi:

  1. Todo símplice es cara de un 2-símplice.
  2. Todo 1-símplice es cara de exactamente dos 2-símplices.
  3. Si $\forall v \in K^{(0)}$ definimos $st(v) = \{ \tau \in K \mid v < \tau \}$ y

     \[ L(v) = \{ \tau \in K \mid \exists \sigma \in K : v < \sigma, \tau < \sigma, v \not< \tau
     \}
     \]

     y tenemos que $|st(v)| \cong \overline{D}$ y $|L(v)|$ es conexo.

*** 3.3. Suma convexa
**** Curva de Jordan
Una curva de Jordan en $\mathbb{R}^n$ es una curva cerrada y simple.

***** Definición equivalente
Una curva de Jordan es la imagen de $f : \mathbb{S}^1 \longrightarrow \mathbb{R}^n$ que sea
homeomorfismo sobre su imagen.

**** Homeomorfismo que preserva la orientación
Sean $C_1,C_2 \subseteq \mathbb{R}^2$ dos curvas de Jordan y $f : C_1 \overset{\cong}\longrightarrow C_2$ un homeomorfismo.
Decimos que $f$ *preserva la orientación* si $\exists \alpha : [0,1] \longrightarrow C_1$ parametrización
tal que $\alpha$ recorre $C_1$ en el sentido de las agujas del reloj y $f \circ \alpha$
recorre $C_2$ en el sentido de las agujas del reloj.

**** Teorema de Jordan-Schönflies
Sean $C_1,C_2$ curvas de Jordan con $f : C_1 \cong C_2$. Entonces existe una
$F : \mathbb{R}^2 \cong \mathbb{R}^2$ con $F|_{C_1} = f$. Además, 

  1. Si $f$ preserva la orientación y $U \subseteq \mathbb{R}$ es un subconjunto 
     homeomorfo a $\mathbb{D}$ disco, con $U \supseteq C_1 \cup C_2$, entonces existe
     un $F : \mathbb{R}^2 \longrightarrow \mathbb{R}^2$ con $F|_{C_1} = f$ y $F|_{\mathbb{R}^2\setminus U} = Id$.
  2. Si $f$ revierte la orientación y $U \subseteq \mathbb{R}^2$ con $U \supseteq C_1 \cup C_2$
     con $U \cong \mathbb{D}$ disco, puedo tener $F$ con: $F|_{\mathbb{R}^2\setminus U}(x,y) = (x,-y)$.

***** Demostración
No trivial

****** Segundo punto desde el primero
Si tengo $f : C_1 \cong C_2$, revirtiendo la orientación, puedo tomar
la curva reflejada en el eje Y:

\[\widetilde{C_2} = \{(x,y) \mid (x,-y) \in C_2 \}\]

Y definir una $\widetilde{f} : C_1 \cong \widetilde{C_2}$ como $\widetilde{f} = (f_1,-f_2)$, que preserva la 
orientación. El teorema nos da entonces una $\widetilde{F}$ desde la que podemos
definir $F = (\tilde F_1, \tilde F_2)$, la buscada.

**** Teorema de la curva de Jordan
Sea $C$ curva de Jordan en $\mathbb{R}^2$. Entonces, $\mathbb{R}^2\setminus C$ tiene exactamente
dos componentes conexas, una de ellas acotada (*interior* de $C$) y
la otra es no acotada (*exterior* de $C$).

***** Demostración
Dado un $f : C \cong \mathbb{S}^1$ homeomorfismo, por Jordan-Schönflies, tenemos
una $F : \mathbb{R}^2 \cong \mathbb{R}^2$ extendiéndola, lo que nos da $\mathbb{R}^2\setminus C_1 \cong \mathbb{R}^2 \setminus \mathbb{S}^1$.

***** Contraejemplo en dimensiones superiores: esfera de Alexander
La [[https://es.wikipedia.org/wiki/Esfera_cornuda_de_Alexander][esfera cornuda de Alexander]] es una 2-esfera embebida en $\mathbb{R}^3$
cuyo exterior no es homeomorfo al exterior de la 2-esfera en $\mathbb{R}^3$.

**** Teorema de Jordan-Schonflies para la esfera
Sean $C_1,C_2$ dos curvas de Jordan en $\mathbb{S}^2 \subseteq \mathbb{R}^3$ y $f : C_1 \overset{\cong}\longrightarrow C_2$.
Entonces $\exists F : \mathbb{S}^2 \longrightarrow \mathbb{S}^2$ con $F|_{C_1} = f$.

***** Demostración
Si tomamos $p \in \mathbb{S}^2 \setminus \{C_1 \cup C_2\}$, tenemos $\mathbb{S}^2 \setminus \{p\} \cong \mathbb{R}^2$ por la proyección
estereográfica. Tomamos el $F$ que da el teorema de Jordan-Schönflies
y lo componemos con la inversa de la proyección para tener el $F$.

Dividimos en los dos casos para ver que el $F$ es continuo en el
punto impropio.

**** Suma conexa
Sean $S_1,S_2$ dos superficies convexas. Sean $D_1 \subseteq S_1$, $D_2 \subseteq S_2$ discos
regulares euclídeos y sea $\varphi : \partial D_1 \longrightarrow \partial D_2$ homeomorfismo. 

Denotemos $S'_i = S_i \setminus D_i$. En $S'_1 \sqcup S_2'$ definimos $R_{\varphi}$ relación de equivalencia 
entre el borde y su imagen:

\[ x\; R_\varphi \; \varphi(x)\quad \forall x \in \partial D_1\]

Tenemos una superficie topológica conexa que es independiente de los
discos y el homeomorfismo elegidos. La llamamos *suma conexa*:

\[
S_1 \# S_2
=
S_1' \sqcup S_2' / R_\varphi
\]

**** La suma es independiente de los discos
Para $D_1,D_3 \subseteq S'$ discos regulares euclídeos centrados en $p_1$, tenemos
que:

\[S_1 \setminus D_1 \cong S_1 \setminus D_3\]

***** Demostración
Sin pérdida de generalidad, $\overline{D_1} \subset D_3$. Sea $\psi$ el que hace bola [[*Bola regular euclídea][regular]]
a $D_3$. Definimos:

\[ C_3 = \psi(\partial D_3)\]
\[C_1 = \psi(\partial D_1)\]

Tomamos un $f : C_1 \cong C_3$ y Jordan-Schönflies nos da un $F$.

Definimos ahora por partes $\widetilde F$ como:

\[\widetilde{F}|_{D_3'} = \psi^{-1} \circ F \circ \psi\]
\[\widetilde{F}|_{S_1 \setminus D_3'} = Id\]

Comprobamos que está bien definida y es homeomorfismo, por lo que
tenemos $\widetilde F : S_1\setminus D_1 \cong S_3 \setminus D_3$.

**** La suma es independiente de los centros
Los puntos en los que centramos la suma conexa. Tomando $p_1 \neq p_3 \in S_1$,
con $D_1,D_3$ discos regulares euclídeos centrados en ellos:

\[S_1 \setminus D_1 \cong S_3 \setminus D_3\]

***** TODO Demostración
**** La suma es independiente del homeomorfismo
El homeomorfismo no influye. Dados \[
\varphi, \xi : bD_1 \longrightarrow bD_2
\] homeomorfismos,
queremos ver:

\[
S_1 \sqcup S_2 / R_\varphi \cong S_1 \sqcup S_2 / R_\xi
\]

***** TODO Demostración

**** La suma conexa de superficies conexas es superficie conexa
La suma conexa de dos superficies topológicas conexas es una
superficie topológica conexa.

***** TODO Demostración

*** 3.4. Presentación poligonal de superficies
**** Polígono homeomorfo
Toda superficie topológica compacta es homeomorfa a un polígono con lados
identificados 2 a 2.

***** Idea de demostración
Dada $S$ compacta, por un teorema que no demostramos, $S \cong |K|$.
Por [[*Teorema de Radó][Radó]], podemos triangularlo y por compacidad, tiene un número
finito de caras. Ese polígono puede desplegarse.

**** Región poligonal
Un $P \subseteq \mathbb{R}^2$ es región poligonal si:

  1. Es compacta.
  2. Tiene por borde una curva poligonal (complejo de dimensión 1).
  3. Cada $v \in \operatorname{b}(P)$ vértice admite entorno $U \subseteq \mathbb{R}^2$ tal que:

     \[U \cap P = U \cap H_1 \cap H_2\]

     donde $H_1,H_2$ son semiplanos cerrados con $H_1 = H_2$ o $\operatorname{b}H_1 \cap \operatorname{b}H_2 = \{v\}$.

***** TODO Ejemplos

**** Superficie de una región poligonal
Sea $P \subseteq \mathbb{R}^2$ región poligonal con un número de aristas. Si $R$ es relación 
de equivalencia, identificando cada arista con exactamente otra arista
mediante homeomorfismo simplicial, $P/R$ es una superficie topológica 
compacta.

***** TODO Demostración

**** Presentación poligonal
Llamamos presentación a una expresión de la forma:

\[\langle A;\; W_1,\dots,W_n \rangle\]

donde $W_i$ son palabras con todos los símbolos $\langle A \rangle$ de longitud mayor 
que 3. Permitimos además los casos especiales:

  - $\langle \{a\}, aa \rangle$
  - $\langle \{a\}, aa^{-1} \rangle$
  - $\langle \{a\}, a^{-1}a^{-1} \rangle$
  - $\langle \{a\}, a^{-1}a \rangle$

**** Presentación de un complejo simplicial
Dado un complejo simplicial $K$ donde cada símplice es cara de un
2-símplice, tenemos una presentación poligonal asignando a cada
2-símplice una palabra de longitud 3.

***** TODO Ejemplo

**** Realización geométrica de una presentación
Cada $P = \langle A; W_1,\dots,W_n \rangle$ determina $|P|$, una topología de la forma:

  1. Para cada $W_i$ tomamos un polígono $P_i$ de n-lados.
  2. Biyección entre lados y aristas de $P_i$ en sentido antihorario.
  3. Identificamos cada arista con la que tiene el mismo nombre en
     el sentido marcado por la inversa.

Tomamos la unión por esta relación $|P| = \bigsqcup P_i / R$.

**** Extensión a homeomorfismo
Para $P_1,P_2$ polígonos convexos con el mismo número de aristas.
El $f : \operatorname{b}P_1 \longrightarrow \operatorname{b}P_2$ homeomorfismo simplicial se extiende a un homeomorfismo
$F : P_1 \longrightarrow P_2$.

***** TODO Demostración

**** Presentación poligonal de una superficie
Una presentación $\langle A; W_1,\dots,W_n \rangle$ es de una superficie si 
cada símbolo de $A$ aparece exactamente dos veces en los $W_i$.

**** Presentación de una superficie
Si $S$ es superficie compacta y $|P| \cong S$, llamamos a $P$ una
*presentación* de $S$.

**** Presentaciones topológicamente equivalentes
Dos presentaciones $P_1,P_2$ son topológicamente equivalentes si:

\[ |P_1| \cong |P_2|\]

**** Transformaciones elementales de presentaciones poligonales
Dado $\langle A; W_1,\dots,W_n \rangle$, podemos definir las siguientes transformaciones
elementales.

***** 1. Renombrar
Cambiar un símbolo $a \in A$ por $e \notin A$ para cada palabra.

***** 2. Subdividir
Sustituir $a \mapsto ae$ y $a^{-1} \mapsto e^{-1}a^{-1}$.

***** 3. Consolidar
Inversa de subdividir.

***** 4. Reflejar
Cambiar orden de una palabra $a_1\dots a_m \mapsto a_m^{-1}\dots a_1^{-1}$.

***** 5. Rotar
Empezar una palabra en otro vértice $a_1\dots a_m \mapsto a_2\dots a_ma_1$.

***** 6. Cortar
Partir dos palabras $W_1W_2 \mapsto W_1e,e^{-1}W_2$.

***** 7. Pegar
Inversa de cortar.

***** 8. Doblar
Anular dos lados adyacentes $W_1ee^{-1} \mapsto W_1$.

***** 9. Desdoblar
Inversa de doblar.

**** Transformaciones elementales preservan la realización
Las transformaciones elementales de una presentación poligonal
producen una presentación poligonal equivalente.

***** Demostración
****** Renombrar
Trivialmente.
****** TODO Subdividir/Consolidar
****** TODO Reflejar
****** TODO Cortar/Pegar
****** TODO Doblar/Desdoblar

**** Presentación poligonal de la suma
Dadas $S_1,S_2$ con presentaciones $P_1 = \langle A_1; W_1 \rangle$ y $P_2 = \langle A_2;W_2 \rangle$ con
$A_1 \cap A_2 = \varnothing$. Entonces una presentación de $S_1 \# S_2$ es:

\[
\langle A_1 \cup A_2 ; W_1 W_2 \rangle
\]

***** TODO Demostración
**** Presentaciones modelo
***** Esfera
La presentación de la esfera $\mathbb{S}^2$ es:

\[P_0 = \langle a \mid aa^{-1} \rangle\]

***** Suma de toros
La presentación de la suma de toros $\mathbb{T}^{\#n} = \mathbb{T} \# \overset{n}\dots \#\mathbb{T}$ es:

\[
P_n = \langle
a_1,b_1,\dots,a_n,b_n 
\mid 
a_1b_1a_1^{-1}b_1^{-1}\dots a_nb_na_n^{-1}b_n^{-1} 
\rangle
\]

***** Suma de planos proyectivos
La presentación de la suma de planos proyectivos $\mathbb{RP}^{2\#n}$ es:

\[ Q_n =
\langle a_1,\dots,a_n \mid a_1a_1\dots a_na_n \rangle
\]

*** 3.5. Clasificación de superficies compactas I
**** Aristas retorcidas y complementarias
Un par de aristas en una presentación se dicen retorcidas si
aparecen como $a$ y $a$; y complementarias si aparecen como $a$ y $a^{-1}$.

**** Lema: suma de toro y plano proyectivo
La suma conexa de un toro y un plano proyectivo es homeomorfa a la 
suma conexa de 3 planos proyectivos.

***** TODO Demostración
**** Lema: botella de Klein
**** Teorema de clasificación de presentaciones de superficies compactas
Cualquier presentación poligonal de una superficie compacta y conexa
es equivalente a una de las siguientes:

  1. $P_0$, presentación de $\mathbb{S}^2$.
  2. $P_n$, presentación de $\mathbb{T}^{\#n}$.
  3. $Q_n$, presentación de $\mathbb{RP}^{2\#n}$.

***** Demostración
Sea $S$ superficie con presentación $P$.

****** Paso 1: Reducir a una cara
Como el cociente es arcoconexo, si hay más de una palabra, comparten
entre sí alguna letra. Rotamos, reflejamos si es necesario y pegamos
para tener una sola cara.

****** Paso 2: Retirar complementarias adyacentes
Dos lados adyacentes pueden retirarse.

****** Paso 3: Colocar aristas retorcidas adyacentes
Dada una palabra de la forma $WaVa$:

  1. Cortamos: $Wab^{-1},bVa$.
  2. Reflejamos y rotamos: $b^{-1}Wa, a^{-1}V^{-1}b^{-1}$.
  3. Pegamos y rotamos: $b^{-1}b^{-1}WV^{-1}$.

****** Paso 4: Identificar todos los vértices
Fijado un vértice, puedo cortar un triángulo que lo contenga y
volver a pegar por uno de sus lados para identificar otro vértice
con él.

****** Paso 5: Las complementarias tienen complementarias intercaladas
Para un par de complementarias $a,a^{-1}$, hay otro par de complementarias
intercalado como: $a \dots b \dots a^{-1} \dots b^{-1}$.

Si no fuera así, tendríamos $aXa^{-1}Y$ sin forma de relacionar ningún
vértice de $X$ con un vértice de $Y$.

****** Paso 6: Las intercaladas pueden presentarse en bloques
Si tenemos una palabra de la forma $WaXbYa^{-1}Zb^{-1}$:

  1. Cortando antes de $b$ y pegando por $a$: $XcWZb^{-1}c^{-1}bY$.
  2. Cortando antes de $c$ y pegando por $b$: $d^{-1}WZYXcdc^{-1}$.

****** Paso 7: Nos queda suma de planos proyectivos y toros
Nos acaba quedando una palabra de la forma: 

\[aabb\dots cdc^{-1}d^{-1}\dots\]

Suma conexa de toros y planos proyectivos. Por el [[*Lema: suma de toro y plano proyectivo][lema]],
sabemos que será suma de toros o suma de planos proyectivos.

**** Preclasificación de superficies compactas
Toda superficie compacta y conexa es homeomorfa a una de las 
siguientes:

  1. $\mathbb{S}^2$
  2. $\mathbb{T}^{\#n}$
  3. $\mathbb{RP}^{2\#n}$

***** TODO Demostración

*** 3.6. Clasificación de superficies compactas II
**** Grupo fundamental de la presentación
Sea $S$ compacta y convexa determinada por la presentación $P$, entonces
su grupo fundamental tiene la misma presentación de $P$.

Es decir cociente del libre por la clausura normal de las $W$:

\[\Pi(S) = \frac{F(A)}{N_W}\]

***** Demostración
Aplicando Seifert-Van Kampen sobre una cara tenemos las aristas
como generadores y las palabras como relaciones entre ellas.

**** Conmutador
Dado $G$ se define su conmutador $[G,G]$ como el subgrupo normal de $G$ que
contiene las clases de conjugación, de la forma:

\[
[G,G] 
= 
\langle aba^{-1}b^{-1} \mid a,b \in G \rangle\]

**** Abelianizado
El conmutador cumple:

  1. $[G,G] \cong \{e\}$ $\iff$ $G$ abeliano.
  2. $Ab(G) = G/[G,G]$ es abeliano, llamado el *abelianizado* de $G$.

***** Demostración
Primer punto trivial. Para el segundo, comprobamos $ab[G,G] = ba[G,G]$.

**** Abelianizados de los grupos fundamentales de los modelos
Los abelianizados de los grupos de los modelos son:

  1. $Ab(\pi_1(\mathbb{S}^2)) = \{1\}$.
  2. $Ab(\pi_1(\mathbb{T}^{\#n}) \cong \mathbb{Z}^{2n}$.
  3. $Ab(\pi_1(\mathbb{RP}^{2\#n})) \cong \mathbb{Z}^{n-1} \times \mathbb{Z}_2$.

Distintos entre sí.

***** TODO Demostración
***** TODO Los productos de enteros son distintos
***** TODO El producto por el cíclico de orden 2 los hace distintos
**** Clasificación de superficies compactas
Una superficie topológica compacta $S$ es homeomorfa a una sola
de las siguientes:

  1. $\mathbb{S}^2$.
  2. $\mathbb{T}^{\#n}$.
  3. $\mathbb{RP}^{2\#n}$.

Dos superficies compactas son homeomorfas ssi sus grupos 
fundamentales son isomorfos.

*** 3.7. Característica de Euler y orientabilidad
**** Género
Se define el género de $S$ superficie compacta conexa:

\[ g(S) =
\left\{\begin{array}{ll} 
0 & \mbox{if } S \cong \mathbb{S}^2 \\
n & \mbox{if } S \cong \mathbb{T}^{\#n} \mbox{ ó } S \cong \mathbb{RP}^{2\#n}
\end{array} 
\right.
\]

**** Característica de Euler
Se define la característica de Euler de $S$ superficie compacta conexa:

\[\chi(P) = C-A+V\]

donde $C,A,V$ son los números de caras, aristas y vértices.

**** La característica de Euler es invariante a transformaciones
La característica de Euler es invariante a transformaciones
elementales.

***** TODO Demostración
**** Orientabilidad
Una superficie es orientable si admite una presentación orientada.

***** Presentación orientable
Una presentación poligonal es orientable si no tiene ningún par
de aristas retorcidas.

**** La orientabilidad de superficies compactas es un invariante
Una superficie compacta conexa es orientable ssi es homeomorfa a
la esfera o a la suma de planos proyectivos.

**** Bicolorabilidad                                               :extra:
Una presentación es *bicoloreable* si podemos colorear sus palabras
con dos colores de forma que las dos ocurrencias de una arista:

  - tengan distinto color y mismo signo
  - o tengan el mismo color y distinto signo

**** Bicolorabilidad invariante a transformaciones elementales     :extra:
La bicolorabilidad es invariante a transformaciones elementales.

***** Demostración
****** Renombrar
Trivialmente manteniendo la coloración.

****** Subdividir
Trivial por la misma coloración por cumplirlo la subdividida.

****** Consolidar
Trivial por cumplirlo ambas aristas involucradas.

****** Reflejar
Cambiando la coloración de la palabra.

****** Rotar
Trivial, mantiene coloración.

****** Cortar
Manteniendo el mismo color en las dos palabras.

****** Pegar
Ambas palabras deben tener el mismo color.

****** Doblar
Anular dos lados adyacentes no cambia nada.

****** Desdoblar
Las dos partes están en la misma palabra y tienen el mismo color.

**** Bicolorabilidad coincide con orientabilidad                   :extra:
La bicolorabilidad coincide con la orientabilidad.

***** Demostración
Coincide en los modelos y por ende en todas las demás superficies.

**** Algoritmo de bicolorabilidad                                  :extra:
Podemos calcular la bicolorabilidad de una presentación simplemente
eligiendo un color para la primera cara y coloreando a partir de
ella.

***** Demostración
Asignado el color de la primera cara, queda determinado el color
de todas las caras que contengan una arista de ella. Como toda
cara está conectada a la inicial por conexión, toda cara queda
determinada.

Si esta coloración cumple las condiciones de bicolorabilidad,
hemos encontrado una forma de bicolorear. Si no lo cumple, ninguna
bicoloración es posible.
** Ejercicios
*** Relación de problemas 1
**** Ejercicio 1
Trabajando en el grupo fundamental $\Pi(X,x)$.

**** Ejercicio 2
***** Punto 1
Trivial trabajando en el grupo fundamental.
***** Punto 2
La condición es $\gamma\beta \in {\cal Z}(\Pi(X,x))$.

**** Ejercicio 3
Calculamos usando Seifert-Van Kampen.

**** Ejercicio 6
Por Seifert-Van Kampen haciendo tres grupos, uno con equivalencia homotópica al
círculo y otro trivial. Sale $\mathbb{Z}$.

**** Ejercicio 7
Equivalencia homotópica a un círculo en el que se identifican antípodas, que es
homeomorfo a un círculo. Sale $\mathbb{Z}$.

**** Ejercicio 8
Por Van Kampen, teniendo un trozo con equivalencia homotópica a la esfera y otro
que es un simple disco abierto. Grupo fundamental trivial.

**** Ejercicio 9
Por el Van Kampen que aplicamos en estos casos, es $\mathbb{Z}_3$.

**** Ejercicio 10
Homeomorfo al anterior.
*** Relación de problemas 2
**** Ejercicio 1
***** Punto 1
     Trivial
***** Punto 2
     Subiendo la intersección del entorno abierto que es isomorfo a $\mathbb{R}^n$ con el 
     entorno abierto que nos da el recubridor.
***** Punto 3
     Probamos la caracterización, que es ser semilocalmente simplemente conexo. Cada
     punto tiene un entorno homeomorfo a un abierto de $\mathbb{R}^n$, así que puedo tomar una bola
     abierta en el punto y que sea homeomorfa a un abierto en el punto en el que el
     grupo fundamental sea trivial.
***** Punto 4
     Las esferas.

**** Ejercicio 2
    #+begin_statement
    Sea $\{a,b\}$ una base de $\mathbb{R}^2$ y $R$ la relación de equivalencia en $\mathbb{R}^2$ dada por:

    \[ qRq' \text{ si }\ q'-q = ma+nb,\quad m,n\in\mathbb{Z}\]

    Sea $T_{a,b}$ el espacio topológico cociente.
    #+end_statement

***** Punto 1
Usamos el recubrimiento de cocientes que surgen de acciones discontinuas para
el grupo de acciones de los $\phi_{n,m}(z) = z + (n,0) + (0,m)$ con $n,m\in\mathbb{Z}$.

*** Ejercicios de clase
**** Cálculo del espacio proyectivo con Van-Kampen
Para calcular el grupo de $\mathbb{R}\mathbb{P}^2$, lo definimos como una proyección desde la bola 
cerrada $C$ y tomamos abiertos en él.

 #+begin_center
 #+attr_latex: :width 50px
 [[./pinta/rpvankampen.png]]
 #+end_center

Aplicaremos Van Kampen sobre los siguientes abiertos:

 \[ U = \pi(C-\{p\})\]
 \[ V = \pi(B(p,\epsilon))\]
 \[ U \cap V = \pi((C-\{p\}) \cap B(p,\epsilon)) = \pi (B(p,\epsilon)) - \{p\}\]

Y tenemos que el grupo de $V$ es trivial. Para calcular el grupo de $U$ usaré que
tiene el mismo tipo de homotopía que su borde, que es isomorfo a un círculo y
por tanto tiene grupo fundamental $\mathbb{Z}$.

De la intersección tomaremos un generador $f$ y lo llevaremos al borde para tener:

 \[ f \simeq \alpha \ast c \ast a \ast \tilde\alpha\]

Que proyectando mientras sabemos que el generador de $U$ es 
$g = [\pi(\alpha \ast c \ast \tilde\alpha)]$ nos da finalmente que:

\[ [\pi(f)] \simeq 
 [\pi(\alpha\ast c \ast\tilde\alpha \ast \alpha \ast a \ast \tilde\alpha)] \simeq
 [g] \ast [g] \simeq 2[g]\]

Y el cálculo del grupo nos da:

\[\frac{<g>}{<2g>} \cong \mathbb{Z}_2\]

*** Examen 13 enero 2016
***** Ejercicio 3
****** Punto 1     
      Sabemos que todos los $\Phi_n$ son homeomorfismos. Dado un punto $(a,b)$ tomamos un
      disco abierto de radio $1/4$ alrededor de él, y comprobamos que $(a+n,(-1)^nb)$
      está siempre a distancia mayor a $n$ y mayor a $1/2$. Llamando a la bola $V$, 
      tenemos:
      
      \[\phi(V) \cap V = \varnothing\]

****** Punto 2
      Como $G$ actúa propia y discontinuamente sobre $\mathbb{R}^2$, tenemos que es un 
      recubridor regular.

****** Punto 3
      Como $G$ es ahora el grupo de automorfismos de un recubridor regular sobre $M$,
      tenemos que:
      
      \[ G \cong \Pi(M,x)\]

      Con lo que su grupo fundamental es $\mathbb{Z}$.

****** Punto 4
      Trivial desde lo anterior.

****** Punto 5
      Podemos definir una función de $C$ a $M$ desde las representaciones en $\mathbb{R}^2$,
      vemos luego que es identificación y que por tanto hay homeomorfismo entre
      la imagen y el cociente por la relación que define. Comprobamos que ese
      cociente es igual al que define el grupo.

****** Punto 6
      Tengo ya al cilindro como recubridor y al plano. Faltan las cintas de Möbius
      en el caso impar que se realizarán como en el ejercicio 5.
      
*** Relación de problemas 3
**** Ejercicio 1
#+begin_statement
Prueba que un espacio topológico conexo es arco-conexo si y sólo si
cada punto tiene un entorno arco-conexo. Demuestra que todo espacio
topologico localmente euclídeo es conexo si y sólo si es arco-conexo.
#+end_statement

Si es arcoconexo, claramente se tiene localmente arcoconexo.  Si es
localmente arcoconexo, una componente arcoconexa debe ser abierta y
cerrada, porque cada punto al que se pueda llegar tiene un entorno al
que se puede llegar. Y cada punto al que no se pueda llegar tiene un
entorno al que no se pueda llegar.

**** Ejercicio 3
#+begin_statement
Estudia si el subespacio topológico de $\mathbb{R}^3$ dado por:

\[ X = \{(x,y,z) \in \mathbb{R}^3 \mid z^2 = x^2+y^2\}\]

es una superficie topológica.
#+end_statement

Si $z=0$ se tiene $x,y = 0$, así, el único punto en ese plano es 
el $0$. Cualquier entorno suyo, si quitamos ese punto, tiene dos
componentes conexas y no puede ser homeomorfo a un disco.

El espacio no es localmente euclídeo.

**** Ejercicio 4
Ambos son localmente euclídeos.

**** Ejercicio 5
#+begin_statement
Prueba que el p-simplex generado por $\{a_1,\dots,a_n\}$ es la envolvente
convexa del conjunto $\{a_1,\dots,a_n\}$.
#+end_statement

La envolvente convexa debe contener a todos los puntos y a sus
combinaciones convexas, luego debe contener a todo el simplex.

El simplex es convexo trivialmente:

\[
t \sum \lambda_i v_i + (1-t) \sum \lambda_i' v_i =
\sum t \lambda_i v_i + \sum (1-t) \lambda_i' v_i
\]

Y entonces la suma de los coeficientes suma la unidad, usando
que lo cumplen ambos elementos del símplice:

\[
\sum t\lambda_i + \sum (1-t)\lambda_i' = t + (1-t) = 1
\]

**** Ejercicio 6
#+begin_statement
Dado un vértice de un complejo simplicial $K$ se define la estrella 
abierta de $v$ como $ost(v) = \{o(\sigma) \mid \sigma \in st(v)\}$. Prueba que $ost(v)$ es un
entorno abierto de $v$ en $|K|$ y la colección de todas las estrellas 
abiertas es un recubrimiento abierto de $|K|$.
#+end_statement

Todo punto aquí pertenece a algún $x \in o(\sigma), \sigma \in st(v)$. Una bola cerrada
alrededor suya es compacta y sólo contiene a una cantidad finita de
símplices. Un símplice $\tau$ que contenga a $x$ se corta con $\sigma$, nos da
$\sigma \cap \tau < \sigma$. Tenemos dos casos:

  - $\sigma \cap \tau = \sigma$, entonces $v \in \tau$.
  - $\sigma \cap \tau < \sigma$, que daría que $x$ esté en una cara de $\sigma$ y no pueda estar
    en $o(\sigma)$.

Así, no hay ningún vértice que no contenga a $v$ tocando a $x$. Todos están
a distancia mayor que $0$, y puedo tomar el mínimo de las distancias (que
son un conjunto finito) y tener una bola cerrada que sólo corta símplices
de la estrella. La bola abierta sólo cortará a los símplices abiertos.

[[./images/starcomplex.png]]

Imagen de [[http://math.stackexchange.com/questions/633307/definition-of-star-in-a-simplicial-complex][Math.SE: Definition of star in a simplicial complex]].

**** Ejercicio 7
#+begin_statement
Describe una triangulación del toro, el plano proyectivo y la botella
de Klein.
#+end_statement

**** Ejercicio 8
#+begin_statement
Describe una triangulación del espacio topológico cociente que se
obtiene cuando en un toro identificamos un meridiano a un punto.
#+end_statement

**** Ejercicio 9
#+begin_statement
Demuestra que la suma conexa de uno o más planos proyectivos contiene un
subespacio que es homeomorfo a una banda de Möbius.
#+end_statement

**** Ejercicio 10
#+begin_statement
Para cada una de las siguientes presentaciones de superficies calcula
la característica de Euler y determina a cuál de las superficies modelo
es homeomorfa:

  1. $\langle a,b,c \mid abacb^{-1}c^{-1} \rangle$.
  2. $\langle a,b,c \mid abca^{-1}b^{-1}c^{-1} \rangle$.
  3. $\langle a,b,c,d,e,f \mid abc,bde,c^{-1}df,e^{-1}fa \rangle$.
#+end_statement

***** Superficie 1
Calculamos Euler:

\[\chi(S) = 1 - 3 + \]

Y vemos que no es orientable.

***** Superficie 3
Calculamos Euler:

\[\chi(S) = 4 - 5 + 3 = 2\]

Y a la vez que sacamos los vértices comprobamos que es orientable.

**** Ejercicio 12
#+begin_statement
Prueba que la característica de Euler de la suma conexa de dos
superficies compactas es igual a la suma de sus características de
Euler menos dos.
#+end_statement

Si unimos las dos mediante cualquier triangulación razonable:

***** Triangulación 1
Se pierden 2 caras para cortar, se pegan con 3 caras, y 3 aristas.

#+begin_center
#+attr_latex: :width 50px
[[./images//sumatriangulacion1.png]]
#+end_center

***** Triangulación 2
Perdemos dos caras e identificamos 3 aristas y 3 vértices.

#+begin_center
#+attr_latex: :width 50px
[[./images//sumatriangulacion2.png]]
#+end_center
*** Clasificación de superficies compactas
**** Calcular la orientabilidad
Un algoritmo que usa la caracterización de bicolorabilidad para
determinar si una superficie es orientable o no:

#+BEGIN_SRC haskell
  import Text.ParserCombinators.Parsec
  type Letra = (Char,Bool)
  type Palabra = [Letra]
  type Color = Bool
  type Presentacion = [Palabra]
  type Coloracion = [(Palabra,Color)]

  orientable :: Presentacion -> Bool
  orientable presentacion = any esBuenaColoracion (posiblesColoraciones presentacion)

  posiblesColoraciones :: Presentacion -> [Coloracion]
  posiblesColoraciones [] = [[]]
  posiblesColoraciones (w:presentacion) =
    map ([(w,False)] ++) (posiblesColoraciones presentacion) ++
    map ([(w,True)] ++) (posiblesColoraciones presentacion)
  
  esBuenaColoracion :: Coloracion -> Bool
  esBuenaColoracion c = compruebaColores $ concat $ map (\(w,l) -> map (\x -> (x,l)) w) c

  compruebaColores :: [(Letra,Color)] -> Bool
  compruebaColores [] = True
  compruebaColores (vt : xs) = (all (\ut -> buenaArista ut vt) xs) && compruebaColores xs

  buenaArista :: (Letra,Color) -> (Letra,Color) -> Bool
  buenaArista ((x,u),v) ((y,w),z) = (x /= y) || (u == w && v /= z) || (u /= w && v == z)

  main :: IO ()
  main = return ()


  esOrientable :: String -> Bool
  esOrientable s = either undefined orientable (parse pres "" s) 

  pres :: Parser Presentacion
  pres = word `sepBy` (char ',')

  word :: Parser Palabra
  word = many letra

  letra :: Parser Letra
  letra = try letrainvertida <|> do
    l <- letter
    return (l,True)
  
  letrainvertida :: Parser Letra
  letrainvertida = do
    l <- letter
    _ <- char '*'
    return (l,False)
#+END_SRC

