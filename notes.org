#+TITLE: Math Notes
#+AUTHOR: Mario Román
#+EMAIL: mromang08@gmail.com

#+OPTIONS: broken-links:mark num:nil
#+LANGUAGE: es
#+SETUPFILE: essay.setup
#+SETUPFILE: math.setup
#+SETUPFILE: html.setup


* Papers & articles
** TODO Dependent types at work - Ana Bove, Peter Dybjer
*** 1. What are dependent types?
*** 2. Simply Typed Functional Programming in Agda
**** 2.1. Truth Values
**** 2.2. Natural numbers
***** Notion of Inductive type
      /Recursive types/ in Haskell are *inductive types* in constructive type
      theory.
***** Notion of Canonical form
      Elements on canonical form are built up by constructors only. They do not
      contain defined functions. Martin-Löf considers /lazy canonical forms/, where
      it suffices to begin with a constructor:

      #+BEGIN_SRC haskell
      Zero * Zero        -- Not a canonical form
      Succ (Zero + Zero) -- Lazy canonical form
      Succ (Succ Zero)   -- Canonical form
      #+END_SRC
      
**** 2.3. Lambda Notation and Polymorphism
     In Agda we have no type variables, we have families of functions:

     #+BEGIN_SRC 
     id : (A : Set) -> A -> A
     id = \(A : Set) -> \(x : A) -> x
     #+END_SRC

**** 2.4. Implicit Arguments
     Implicit arguments are declared by enclosing their typings within curly 
     braces.

**** 2.5. Gödel System T
     Gödel System T is a system of primitive recursive functionals. All typable
     programs in Gödel System T terminate. We can only use β-reduction and the
     definitions of:

     #+BEGIN_SRC 
     true
     false
     zero
     succ
     if_then_else
     natrec
     #+END_SRC

     We can define all primitive recursive functions, but also others such as the
     Ackermann fuction.

**** 2.6. Parametrised Types
**** 2.7. Termination-checking
     In M-L Type Theory, all recursion is *primitive recursion*; a structural
     recursion on the well-founded data types.

     As the Agda's termination-checker has not yet been documented, if Agda will
     be used as a system for formalising mathematics rigorously, it is advisable to
     stay within a well-specified subset such as Martin-Löf type theory.

     In fact, the termination checker will not recognize calls to non-constructors
     as smaller arguments. =(m-n)= will not be recognized as smaller than =m=,
     for example.

*** 3. Dependent Types
**** 3.1. Vectors of a given length
     We have to alternatives to define vectors of a given length:
     
     - *As a Recursive Family*:
       
       #+BEGIN_SRC 
       Vec : Set -> Nat -> Set
       Vec A zero = Unit
       Vec A (succ n) = A X Vec A n
       #+END_SRC

       Functions must be written by induction on the length of the vector.

     - *As an Inductive Family*:

       #+BEGIN_SRC 
       data Vec (A : Set) : Nat -> Set where
         [] : Vec A zero
	 _::_ : {n : Nat} -> A -> Vec A n -> Vec A (succ n)
       #+END_SRC
       
     We can use type-checking to define functions that work only over non-empty
     vectors, such as =tail= or =head=.

**** 3.2. Finite Sets
     This data type is useful when we want to access the element at a certain
     position in a vector.

**** 3.3. More Inductive Families
*** TODO 4. Propositions as Types
** TODO Monads for functional programming - Philip Wadler
*** 1. Introduction
*** 2. Evaluating monads
**** 2.1. Variation zero: The basic evaluator
**** 2.2. Variation one: Exceptions
**** 2.3. Variation two: State
**** 2.4. Variation three: Output
**** 2.5. A monadic evaluator
**** 2.6. Variation zero, revisited: The basic evaluator
**** 2.7. Variation one, revisited: Exceptions
**** 2.8. Variation two, revisited: State
**** 2.9. Variation three, revisited: Output
*** 3. Monad Laws
    Son equivalentes =return,join= y =return,bind=. Y además, desde cualesquiera
    de ellos, se define =map=.
*** 4. State
**** 4.1. Arrays
**** 4.2. Array transformers
**** 4.3. Array readers
     Conmutative monads.
**** 4.4. Conclusion
*** TODO 5. Parsers
** TODO P?=NP - Scott Aaronson
** Classification of Surfaces - Chen Hui George Tao
*** 1. Introducción
Vamos a demostrar que todas las superficies compactas son homeomorfas
a la esfera, la suma conexa de toros o la suma conexa de planos proyectivos.

*** 2. Superficies
**** Superficies
Una *superficie* es una 2-variedad. Un espacio Hausdorff contable
localmente homeomorfo a $\mathbb{R}^2$.

**** Idea del artículo
Dado un polígono, si identificamos las aristas en pares, tendremos una
superficie. Veremos que toda superficie se construye a partir de un
polígono con las aristas identificadas.

*** 3.1. Triangulaciones. Complejos simpliciales
**** Simplex
Dados $v_0,\dots,v_k$ en posición general, el *simplex* que generan es el
conjunto de combinaciones convexas bajo la topología inducida.

**** Complejo simplicial euclídeo
Un *complejo simplicial* es una colección $K$ de símplices cumpliendo:

  1. Si $\sigma \in K$, cada cara suya está en $K$.
  2. Si $\sigma,\tau \in K$, $\sigma \cap \tau$ es vacía o una cara de ambas.
  3. Cada punto tiene un entorno que interseca a sólo finitos símplices.

**** Poliedro
La unión de todos los símplices de $K$ es un espacio simplicial llamado
su *poliedro*, $|K|$.

**** Homomorfismo simplicial
Función continua entre dos poliedros cuya restricción a cada simplex
es afín. Es *isomorfismo simplicial* cuando es homeomorfismo.

*** 3.2. Triangulaciones
**** Triangulación
Una triangulación es un homeomorfismo entre un espacio topológico
y un espacio simplicial euclídeo.

**** Teorema de Radó
Toda superficie es un poliedro de un complejo simplicial 2-dimensional.
Donde además, cada 1-símplex es cara de dos 2-símplex.

***** Demostración
La demostración es larga. La idea es recubrir toda la superficie con
discos regulares y usar el Teorema de Schonflies.

*** 4.1. Presentación poligonal. Polígonos
**** Región poligonal
Compacto $P$ del plano cuya frontera es un 1-símplex cumpliendo:

  1. Cada $q$ que no es vértice tiene un entorno $U$ tal que $P \cap U$ es
     intersección de $U$ con un plano.
  2. Cada $q$ que es vértice tiene un entorno $U$ tal que $P \cap U$ es
     intersección de $U$ con dos planos con fronteras intersecando en $q$.

**** Una región poligonal relacionada a pares es una superficie compacta
Sea $P$ región poligonal. Dada una relación que identifique cada 
arista con exactamente otra por isomorfismo simplicial, el
espacio cociente resultante es una superficie compacta.

***** Demostración
Sea $M = P/\sim$, con proyección $\pi:P \longrightarrow M$. Por compacidad, $\pi(P) = M$
es compacto. Podemos dividir los puntos de $M$ en:

****** Puntos en una cara
Como la proyección es homeomorfismo local en el interior del polígono,
tenemos que son localmente euclídeos.

****** Puntos en una arista
Claramente, existe un entorno sin vértices. Por definición de la
relación, el punto está identificado con exactamente otro y podemos
usar los entornos $V_1,V_2$ que son discos de intersecciones con planos.

Ahora creamos aplicaciones afines $\alpha_1,\alpha_2$ que peguen las dos partes del 
disco en $\mathbb{R}^2$ y las usamos para construir una proyección de $V_1\cup V_2$ a
$\mathbb{R}^2$. Por tener la misma relación de equivalencia que $\pi$, los espacios
cocientes son homeomorfos, y podemos ver que el punto tiene un
entorno euclídeo en este espacio.

****** Vértices
Repetimos exactamente lo mismo que hemos hecho con la arista pero
sabiendo que cada identificación del vértice nos da un ángulo que
debemos pegar después en $\mathbb{R}^2$.

*** 4.2. Presentación poligonal. Suma conexa de superficies
**** Suma conexa
Dadas superficies $M_1,M_2$, bolas regulares $B_1,B_2$, y un homeomorfismo
$f : dM_2' \longrightarrow dM_1'$. El espacio que identifica cada punto con su imagen
es la *suma conexa*.

**** Suma conexa de superficies conexas
La suma conexa de superficies conexas es una superficie conexa.

***** Demostración
Debemos ver que es localmente euclídea y Hausdorff. Tomamos como
proyección:

\[
\pi : M_1' \sqcup M_2' \longrightarrow M_1\# M_2
\]

Y tenemos dos tipos de puntos.

****** Puntos en el interior
Los puntos que no tocan al disco de unión tienen a la proyección
localmente homeomorfa en ellos y por eso son localmente euclídeos.

****** Puntos en el borde
Tomamos un entorno de ambos puntos tal que contengan los mismos
puntos identificados del borde. Los proyectamos a $\mathbb{R}^2$ pegando
ambos bordes y nos damos cuenta de que es la misma relación de
equivalencia que daría $\pi$, luego son espacios homeomorfos y el
punto en ellos, llevado al $0$, es localmente euclídeo.

*** 4.3. Presentación poligonal
**** Presentación poligonal
Una *presentación poligonal* es un conjunto finito con finitas palabras
$W_1,\dots,W_k$, cada una de longitud 3 o mayor.

**** Realización geométrica de una presentación poligonal
La *realización geométrica* de una presentación poligonal se construye:

  1. Cada palabra $W_i$ da $P_i$, región poligonal de $k$ lados construída del
     polígono regular modelo.
  2. Damos una biyección de cada símbolo con los lados de $P_i$ en orden.
  3. Unimos disjuntamente los $P_i$ e identificamos aristas con el mismo
     nombre y homeomorfismos afines.

**** Presentación de superficie
Presentación poligonal donde cada símbolo ocurre exactamente dos veces.

***** La realización de una presentación de superficie es superficie compacta
Hemos probado antes que en este caso, obteníamos una [[*Una región poligonal relacionada a pares es una superficie compacta][superficie compacta]]
en la realización.

**** Presentaciones topológicamente equivalentes
Dos presentaciones son equivalentes si tienen la misma realización 
geométrica.

**** Toda superficie compacta tiene una presentación de superficie
Toda superficie compacta tiene una presentación de superficie.

***** Demostración
Dada una superficie $M$, por triangulación es homeomorfa a un complejo
simplicial donde cada arista es cara de dos símplices. Dado un complejo
simplicial podemos construir una presentación donde:

  - Cada 2-símplex es una palabra de longitud 3.
  - Dos aristas se llaman igual si vienen del mismo símplex.

La presentación entonces nos da dos proyecciones desde los polígonos
hasta la realización de la presentación y al símplex.

  - $\pi_K : P_1\sqcup\dots\sqcup P_n \longrightarrow |K|$
  - $\pi_{\cal P} : P_1\sqcup\dots\sqcup P_n \longrightarrow |{\cal P}|$

****** Ambas proyecciones identifican los mismos puntos
Es claro que identifican las mismas aristas por construcción.
Debemos comprobar que identifican los mismos vértices. Sea $v$
un vértice, que debe estar en una arista que debe estar en dos 
2-símplex $\sigma,\sigma'$. Definimos una relación entre 2-símplices si
comparten una arista. Para comprobar que los vértices se mantienen
por una proyección entre aristas, comprobaremos que hay una sola
clase de equivalencia.

Si hubiera dos clases de equivalencia $\{\sigma_i\},\{\tau_i\}$, podemos tomar una
bola suficientemente pequeña (por la condición de finitud de los
complejos simpliciales) para que interseque sólo a símplices 
conteniendo a $v$. Esto nos da una bola homeomorfa a $\mathbb{R}^2$, luego
$U \setminus \{v\}$ es conexo. Podríamos quitar el $v$ en los complejos simpliciales
de ambas clases de equivalencia y serían disconexas.

**** Extensión de isomorfismo de bordes
Sean $P_1,P_2$ polígonos convexos con $f : bP_1 \longrightarrow bP_2$ isomorfismo simplicial,
entonces se extiende a un homeomorfismo $F : P_1 \longrightarrow P_2$.

***** Demostración
Cualquier punto en el interior forma uniéndose con los vértices un
complejo simplicial. Los poliedros de ambos son homeomorfos porque
los complejos simpliciales lo son.

**** Las transformaciones elementales dan realizaciones equivalentes
Las transformaciones elementales de las presentaciones dan lugar a
superficies topológicamente equivalentes

***** Reflexión
Claramente una aplicación afín de reflexión nos da lo buscado.

***** Rotación
La rotación es una aplicación afín que nos da lo buscado.

***** Cortar
Tomamos las dos proyecciones de presentación antes y después de
cortar y comprobamos que identifican los mismos puntos.

***** Doblar
Tomamos las dos proyecciones y añadimos las aristas que faltan para
comprobar que identifican los mismos puntos.

**** Presentación de la suma conexa
La presentación de la suma conexa es la unión de las palabras.

***** Demostración
Dadas $W_1,W_2$, cortamos un disco como $W_1c^{-1}b^{-1}a^{-1}$ y $abcW_2$ e 
identificamos las aristas dadas.

*** 5. Teorema de clasificación
**** Lema: Botella de Klein
**** Lema: Suma de toro y plano proyectivo
**** Teorema de clasificación
Toda superficie compacta conexa es homeomorfa a una de las siguientes:

  - $\mathbb{S}^2$
  - $\mathbb{T}^{\#n}$
  - $\mathbb{RP}^{2\#n}$

***** Demostración
Tomamos transformación desde la presentación hasta llegar a la
presentación de un modelo.

****** Paso 1: Una sola cara
****** Paso 2: Sin pares complementarios adyacentes
****** Paso 3: Todos los pares retorcidos adyacentes
****** Paso 4: Identificamos todos los vértices en un punto
****** Paso 5: Comprobamos que los complementarios están entrelazados
****** Paso 6: Llevamos los complementarios juntos
****** Paso 7: Comprobamos que es una presentación modelo
** Koszul Pairs and applications - Pascual Jara, Dragoş Ştefan
*** Introduction
**** Koszul ring
*Koszul ring*. A graded ring $A$ is *Koszul* if $A^0$ is a semisimple ring 
and it has a resolution $P_\ast$ by projective graded left A-modules such 
that each $P_n$ is generated by homogeneous elements of degree $n$.

**** Graded ring
*Graded ring*. A ring that is a direct sum of abelian groups:

\[ A = \bigoplus_{n \in \mathbb{N}} A_n\]

such that $A_iA_j \subset A_{i+j}$.

***** Homogeneous Elements
A *homogeneous element* is an element of any factor $A_i$ of the 
decomposition.

*Example:* A polynomial ring $A = \mathbb{K}[x_1,x_2, \dots]$ is graded with $A_i$ 
being the abelian group of polynomials with only monomials of 
degree $i$.
# QUESTION: Do they admit a different gradation?
# We can take $A_i$ to be the group of polynomials of degree 
# *equal or less* than i!

**** Semisimple group
*Semisimple group*. A group is semisimple if it has no non-trivial 
normal abelian subgroups.

Different uses of this term can be found [[http://planetmath.org/semisimplegroup][here]].
# QUESTION: Which are we interested in?

**** Semisimple module
*Semisimple module*. It is a direct sum of simple modules, that is, 
they have no non-zero proper submodules.

**** Semisimple algebra
An associative finite dimensional algebra $A$ is *semisimple* if
$A$ is a direct product of simple algebras or equivalently, if $A$ has
trivial Jacobson radical.

*** 1. Almost-koszul pairs
**** 1.1. R-rings
***** R-Ring
*R-ring*. Associative and unital algebra. It is an associative and 
unital ring $A$ together with a morphism $u : R \longrightarrow A$.

***** Graded and connected R-rings
*Graded and connected R-rings*. A R-ring is graded if it is equipped 
with a decomposition:

\[A = \bigoplus_{n \in \mathbb{N}} A^n \]

such that multiplicaton $m^{p,q}$ maps $A^p \otimes A^q$ into $A^{p+q}$. It is *connected* 
when $A_0 = R$. It is *strongly graded* when $m^{1,p}$ is surjective. We 
call $\pi^n_A$ to the projection of $A$ onto $A^n$.

**** 1.2. R-corings
***** Definition of coalgebra
A [[https://en.wikipedia.org/wiki/Coalgebra#Formal_definition][coalgebra]] over a field $K$ is a *vector space* $V$ together with linear
maps $\Delta : V \longrightarrow V \otimes V$ and $\varepsilon : V \longrightarrow K$ such that:

 1. $(id \otimes \Delta) \circ \Delta = (\Delta \otimes id) \circ \Delta$
 2. $(id \otimes \varepsilon) \circ \Delta = id 
    = (\varepsilon \otimes id) \circ \Delta$

Sometimes, the coalgebras use [[https://en.wikipedia.org/wiki/Coalgebra#Sweedler_notation][Sweedler notation]].

***** Examples of coalgebras
****** The divided power coalgebra
Consider $K[X]$, the polynomial ring, where we define by linearity:

\[\Delta(X^n) = \sum^n_{k=0} {n \choose k} X^k \otimes X^{n-k}\]

\[\epsilon(X^n) = \twopartdef{1}{n=0}{0}{n>0}\]

When the structures of algebra and coalgebra are compatible, they
are called [[https://en.wikipedia.org/wiki/Bialgebra][bialgebras]].

***** R-coring
*R-coring*. Coassociative and counital coalgebra. It is an R-bimodule 
with a /comultiplication/ $\Delta : C \longrightarrow C \otimes C$ and 
a /counit/ $\epsilon : C \longrightarrow R$.

***** Graded corings
*Graded corings*. Decomposition $C = \bigoplus_{n \in \mathbb{N}} C_n$, 
such that:

\[\Delta(C_n) \subset \bigoplus_{p=0}^n C_p \otimes C_{n-p}\]

**** 1.3. Almost-Koszul pair
*Almost-Koszul pair*. Connected R-ring and R-coring $(A,C)$ with an 
isomorphism $\theta_{C,A} : C_1 \longrightarrow A^1$, that satisfies the relation:

\[ m^{1,1} \circ (\theta_{C,A} \otimes \theta_{C,A}) \circ \Delta_{1,1}
= 0\]

Or, using Sweedler notation, for any $c \in C_2$:

\[ \sum \theta_{C,A}(c_{(1,1)}) \theta_{C,A}(c_{(2,1)}) = 0\]

**** 1.4. Opposite Koszul pair
If $(A,C)$ is a Koszul pair, then $(A^{op},C^{op})$ are Koszul pairs with
respect to:

\[\theta_{C^{op},A^{op}} = \theta_{C,A}\]

**** 1.5. The normalized bar resolution of R
For every strongly graded R-ring A, there is a graded coring C such that
$(A,C)$ is an almost-Koszul pair.

***** The normalized right bar resolution
The exact sequence $\beta_\ast^r(A)$:

\[ 0 \longleftarrow 
R \overset{\delta_0}\longleftarrow 
A \overset{\delta_1}\longleftarrow
\overline{A} \otimes A \overset{\delta_2}\longleftarrow
\overline{A} \otimes \overline{A} \otimes A \overset{\delta_3}\longleftarrow
\overline{A} \otimes \overline{A} \otimes \overline{A} \otimes A \longleftarrow
\dots
\]

is called the *normalized right bar resolution*. Where
the $\delta$ are defined as:

 - $\delta_0 = \pi^0_A$
 - \[ \delta_n(a_1 \otimes \dots \otimes a_n \otimes a_{n+1}) 
      = \sum_{i=1}^n (-1)^i  a_1 \otimes \dots \otimes a_ia_{i+1} \otimes \dots \otimes a_{n+1}\]

***** TODO Normalized bar complex

*** 2. Koszul Pairs

*** 3. Hochschild (co)homology of Koszul rings
**** 3.1. The cyclic tensor product
***** Enveloping algebra of R
The tensor product algebra $R^e = R \otimes_\mathbb{K} R^{op}$ is called the 
*enveloping algebra* of $R$.

*** 4. Almost-Koszul pairs associated to twisted tensor products

*** 5. The Hochschlid cohomology of a twisted tensor product
* The Catsters
** Adjunctions
Serie de [[https://www.youtube.com/playlist?list=PL54B49729E5102248][vídeos]] sobre funtores adjuntos.

*** Adjuntions 1
Tenemos varias nociones de igualdad entre categorías.

#+begin_definition
*Isomorfismo de categorías*. Ocurre con dos functores:

\[ \begin{tikzcd}
{\cal C} \arrow[bend left]{r}{F} & {\cal D} \arrow[bend left]{l}{G}
\end{tikzcd}
\]

Tales que $1_C = GF$ y $FG = 1_D$.
#+end_definition

#+begin_definition
*Equivalencia de categorías*. Ocurre con dos functores:

\[ \begin{tikzcd}
{\cal C} \arrow[bend left]{r}{F} & {\cal D} \arrow[bend left]{l}{G}
\end{tikzcd}
\]

Tales que $1_C \cong GF$ y $FG \cong 1_D$. Entendiendo la isomorfía en la 
categoría de funtores, es decir, una [[https://ncatlab.org/nlab/show/natural+isomorphism][isomorfía natural]].
#+end_definition

#+begin_definition
*Adjunción*. Ocurre con dos functores:

\[ \begin{tikzcd}
{\cal C} \arrow[bend left]{r}{F} & {\cal D} \arrow[bend left]{l}{G}
\end{tikzcd}
\]

Tales que tenemos transformaciones naturales $1_C \overset{\eta}\Longrightarrow GF$ y 
$FG \overset{\epsilon}\Longrightarrow 1_D$ que cumplen las dos identidades triangulares siguientes:
 
\[ \begin{tikzcd}
F \arrow{r}{\eta} \arrow{dr}{id} & FGF \arrow{d}{\epsilon} \\
 & F
\end{tikzcd}   
\]     \[ \begin{tikzcd}
G \arrow{r}{\eta} \arrow{dr}{id} & GFG \arrow{d}{\epsilon} \\
 & G
\end{tikzcd}
\]
#+end_definition

En este caso escribimos $F \dashv G$, y $F$ es funtor adjunto de $G$.

*** Adjuntions 2
Damos una definición equivalente de funtores adjuntos.

#+begin_definition
*Adjunción*. Una adjunción es un isomorfismo natural:

\[Hom_D(FX,Y) \cong Hom_C(X,GY)\]

Natural sobre $X$ fijado cualquier $Y$ y natural sobre $Y$ fijado 
cualquier $X$. Entendiendo que usamos los funtores contravariantes $Hom(F-,Y)$,
$Hom(-,GY)$ por un lado y los funtores covariantes $Hom(FX,-)$ y $Hom(X,G-)$;
que nos dan los siguientes cuadrados de naturalidad:

\[ \begin{tikzcd}
Hom_D(FX',Y) \arrow{d}[swap]{Hom_D(Ff,Y)} \arrow{r}{\alpha_{X'}} & Hom_C(X',GY) \arrow{d}{Hom_C(f,GY)}\\
Hom_D(FX, Y) \arrow{r}{\alpha_{X}}& Hom_C(X,GY)
\end{tikzcd}
\] 

\[ \begin{tikzcd}
Hom_D(FX,Y) \arrow{d}[swap]{Hom_D(FX,g)} \arrow{r}{\beta_{Y}} & Hom_C(X,GY) \arrow{d}{Hom_C(X,Gf)}\\
Hom_D(FX,Y') \arrow{r}{\beta_{Y'}}& Hom_C(X,GY')
\end{tikzcd}
\] 
#+end_definition

Esta definición es equivalente intuitivamente a la anterior porque
podemos crear $\eta$ y $\epsilon$ desde las identidades usando las
siguientes transformaciones naturales:

\[Hom_D(FX,FX) \cong Hom_C(X,GFX)\]

\[Hom_D(FGY,Y) \cong Hom_C(GY,GY)\]

*** Adjuntions 3
Podemos presentar ejemplos de adjunciones.
Los *funtores libres y de olvido* suelen ser adjuntos. Entre $Set$ y $Monoid$ tenemos:

\[ \begin{tikzcd}
{Set} \arrow[bend left]{r}{Free} & {Monoid} \arrow[bend left]{l}{Forget}
\end{tikzcd}
\]

Con la adjunción $Free \dashv Forget$. 

#+begin_theorem
*Mónada de una adjunción*. Cada adjunción da lugar a una mónada.
#+end_theorem

Tenemos un funtor $T = GF : {\cal C}  \longrightarrow {\cal C}$. Podemos definir la unidad de
la mónada como la unidad de la adjunción $\eta : 1_C \Longrightarrow T$ y la
multiplicación podemos definirla usando $id \ast \epsilon \ast id : GFGF \Longrightarrow GF$.

Ahora debemos comprobar que cumple los axiomas de mónada. El primero
se obtiene directamente desde los triángulos de la adjunción:

\[ \begin{tikzcd}
T \arrow{r}{T\eta} \arrow{dr}{id} & T^2 \arrow{d}{\mu} \\
 & T
\end{tikzcd}   
\]   \[ \begin{tikzcd}
GF \arrow{r}{GF\eta} \arrow{dr}{id} & GFGF \arrow{d}{G \epsilon F} \\
 & GF
\end{tikzcd}   
\]

Donde el segundo es resultado de aplicar el funtor $G$ a uno de los triángulos conmutativos
de la adjunción. Comprobamos el segundo axioma:

\[ \begin{tikzcd}
T^2 \arrow{d}{\mu} & T \arrow{dl}{id} \arrow{l}[swap]{\eta T} \\
T
\end{tikzcd}   
\]   \[ \begin{tikzcd}
GFGF \arrow{d}{G \epsilon F} & GF \arrow{dl}{id} \arrow{l}[swap]{\eta GF} \\
GF
\end{tikzcd}   
\]

Donde tenemos el resultado de aplicar $F$ por la derecha al otro triángulo conmutativo.

Y finalmente el axioma de conmutatividad de la mónada se comprueba como:

\[ \begin{tikzcd}
T^3 \arrow{d}{T \mu} \arrow{r}{\mu T} & T^2 \arrow{d}{\mu} \\
T^2 \arrow{r}{\mu} & T
\end{tikzcd} \]  \[ \begin{tikzcd}
GFGFGF \arrow{d}{GFG \epsilon F} \arrow{r}{G \epsilon FGF} & GFGF \arrow{d}{G\epsilon F} \\
GFGF \arrow{r}{G \epsilon F} & GF
\end{tikzcd} \] 

Donde el segundo diagrama se obtiene desde la naturalidad de $\epsilon$ aplicando funtores.

*** Adjuntions 4
Vamos a probar la igualdad entre las dos definiciones de adjunción.
Supongamos primero que tenemos el isomorfismo natural entre los dos 
conjuntos de morfismos, es decir, tenemos:

\[ (-) : Hom_D(FX,Y) \cong Hom_C(X,GY) \]

Si tomamos ahora los dos cuadrados naturales que teníamos por este 
isomorfismo y tomamos en ellos los casos particulares $Y = FX$ primero,
y $X = GY$ después:

\[ \begin{tikzcd}
Hom_D(FX,FX) \arrow{d}[swap]{\_ \circ Ff} \arrow{r}{(-)} & Hom_C(X,GFX) \arrow{d}{\_\circ f}\\
Hom_D(FX', FX) \arrow{r}{(-)}& Hom_C(X',GFX)
\end{tikzcd}
\]

Si tomamos la identidad $1_{FX}$ y llamamos $\eta_X = \overline{1_{FX}}$, tenemos que
\(\eta \circ f = \overline{Ff}\). Ahora, si damos la vuelta al isomorfismo $(-)$ en este 
diagrama a la vez que hacemos $X = GY$:

\[ \begin{tikzcd}
Hom_D(FGY,Y) \arrow{d}[swap]{\_ \circ Ff}  & Hom_C(GY,GY) \arrow{l}[swap]{(-)} \arrow{d}{\_\circ f}\\
Hom_D(FGY',Y) & Hom_C(GY',GY) \arrow{l}[swap]{(-)}
\end{tikzcd}
\]

Volviendo a tomar la identidad $1_{GY}$ y llamando $\epsilon_Y = \overline{1_{GY}}$, tenemos
$\epsilon \circ Ff = \overline{f}$.

Ahora tomamos el segundo cuadrado natural, y repetimos el mismo
proceso.

\[ \begin{tikzcd}
Hom_D(FX,FX) \arrow{d}[swap]{g \circ \_} \arrow{r}{(-)} & Hom_C(X,GFX) \arrow{d}{Gg\circ \_}\\
Hom_D(FX,FX') \arrow{r}{(-)}& Hom_C(X,GFX')
\end{tikzcd}
\] 

Obteniendo desde la identidad en $FX$ la ecuación $\overline{g} = Gg \circ \eta$. Y volviendo
a dar la vuelta a los isomorfimos llegamos a:

\[ \begin{tikzcd}
Hom_D(FGY,Y) \arrow{d}[swap]{g \circ \_}  & Hom_C(GY,GY) \arrow{l}[swap]{(-)} \arrow{d}{Gg \circ \_}\\
Hom_D(FGY,Y') & \arrow{l}[swap]{(-)} Hom_C(GY,GY')
\end{tikzcd}
\]

Obteniendo finalmente $\overline{Gg} = g \circ \epsilon$. De este proceso hemos obtenido finalmente
las siguientes ecuaciones:

\[ \begin{aligned}
\eta \circ f &= \overline{Ff} \\
\epsilon \circ Ff &= \overline{f} \\
Gg \circ \eta &= \overline{g} \\
g \circ  \epsilon &= \overline{Gg} 
\end{aligned} \]

Con ellas podemos probar la naturalidad de $\eta$ y la naturalidad de
$\epsilon$:

\[ \begin{tikzcd}
GFX  \arrow{r}{GFf} & GFY \\
X \arrow{u}[swap]{\eta_X} \arrow{r}[swap]{f} & Y \arrow{u}{\eta_Y}
\end{tikzcd}
\]   \[ \begin{tikzcd}
FGX \arrow{d}[swap]{\epsilon_X} \arrow{r}{FGg} & FGY \arrow{d}{\epsilon_Y}\\
X \arrow{r}[swap]{g} & Y
\end{tikzcd}
\]

Ya que $\eta \circ f = \overline{Ff} = GFf \circ \eta$ y $f \circ \epsilon = \overline{Gf} = \epsilon \circ FGf$. Y además podemos probar
los dos triángulos de naturalidad.

\[ \begin{tikzcd}
F \arrow{r}{F \eta_X} \arrow{dr}{id} & FGF \arrow{d}{\epsilon_{FX}} \\
 & F
\end{tikzcd}   
\]     \[ \begin{tikzcd}
G \arrow{r}{\eta_{GX}} \arrow{dr}{id} & GFG \arrow{d}{G\epsilon_X} \\
 & G
\end{tikzcd}
\]

Teniendo finalmente que:

\[ \begin{aligned}
\epsilon \circ F\eta &= \overline{\eta} = 1 \\
G\epsilon \circ \eta &= \overline{\epsilon} = 1
\end{aligned} \]

El otro sentido de la demostración se tiene llegando primero a las
cuatro ecuaciones, y usándolas para definir el isomorfismo
$(-)$. Falta entonces demostrar su naturalidad.

* Harpreet Bedi's channel
** Sheaves and coho
*** Preseaves and sheaves
**** Preseaf definition
#+begin_definition
*Preseaf*. A preseaf ${\cal F}$ of abelian groups on a topological space $X$ consists of:

- For each open set $U$, an abelian group ${\cal F}(U)$, whose elements are called 
  *sections*.
- For each inclusion $V \subseteq U$, a *restriction map*, homomorphism of the form:
  
 
\[p_{U,V} : {\cal F}(U) \longrightarrow {\cal F}(V)\]

such that $p_{U,W} = p_{V,W} \circ p_{U,V}$.
#+end_definition

We can write the restriction of an element $u \in U$ to a set $V \subseteq U$ as
$u|_V = p_{U,V}(u)$.

**** Sheaf definition
 #+begin_definition
 *Gluability axiom*. Given $U = \bigcup U_i$ with sections $s_i \in {\cal F}(U_i)$, if we have:

 \[ s_\alpha|_{U_\alpha \cap U_\beta} = s_\beta|_{U_\alpha \cap U_\beta} \]

 then there exists $s \in {\cal F}(U)$ such that $s|_U_\alpha = s_\alpha$.
 #+end_definition
 #+begin_definition
 *Uniqueness axiom*. Given $U = \bigcup U_i$ with sections $s,t \in {\cal F}(U)$ such that:

 \[\forall U_\alpha:\ s|_U_\alpha = t|_U_\alpha\]

 then $s=t$.
 #+end_definition
 #+begin_definition
 *Sheaves*. A presheaf satisfiying gluability and uniqueness.
 #+end_definition
** Homological Algebra
*** 2. Chain Complex and Homology
*** 4. Homology Theorem
**** Setting
Given a SES of chain complexes $0 \longrightarrow {\cal A}
\longrightarrow{\cal B}
\longrightarrow{\cal C}
\longrightarrow 0$, we have a long exact
sequence like:

\[ \begin{tikzcd}
 & \dots\rar & H_{n+1}({\cal C}) \arrow[out=355,in=175,swap]{dll}{\delta_{n+1}} \\
H_{n}({\cal A})\rar & H_{n}({\cal B}) \rar & H_{n}({\cal C}) \arrow[out=355,in=175,swap]{dll}{\delta_n}\\
H_{n-1}({\cal A})\rar & \dots & 
\end{tikzcd} \]

**** Naturality
When we have two SES of chain complexes:

\[ \begin{tikzcd}
0 \rar & {\cal A}\rar\dar & {\cal B}\rar\dar & {\cal C}\rar\dar & 0 \\
0 \rar & {\cal A}'\rar & {\cal B}'\rar & {\cal C}'\rar & 0 \\
\end{tikzcd} \]

where it hols for every $n$ that:

\[ \begin{tikzcd}
H_n({\cal C}) \rar\dar & H_{n-1}({\cal A})\dar \\
H_n({\cal C}') \rar & H_{n-1}({\cal A}')
\end{tikzcd} \]

*** 8. Proj, inj and flat modules
**** Definitions
An R-module $D$ is:

 1. *Projective* if $Hom(D, -)$ is exact.
 2. *Injective* if $Hom(-,D)$ is exact.
 3. *Flat* if $D \otimes -$ is exact.

**** Considerations
We know that $Hom(D,-)$ and $Hom(-,D)$ are left-exact and that
$D\otimes -$ is right-exact; so for them to be exact, we only need:

 - A module $D$ is *projective* when $B \longrightarrow C$ surjective induces
   $Hom(D,B) \longrightarrow Hom(D,C)$ surjective.

   \[ \begin{tikzcd}
               & B \dar[two heads] \\
   D \rar\urar[dashed]{\exists} & C
   \end{tikzcd} \]

 - A module $D$ is *injective* when $A \longrightarrow B$ surjective induces
   $Hom(B,D) \longrightarrow Hom(A,D)$ surjective.

   \[ \begin{tikzcd}
     & A \dar[two heads]\dlar \\
   D & B \lar[dashed]{\exists}
   \end{tikzcd} \]

 - A module $D$ is *flat* when $A \longrightarrow B$ injective induces 
   $D\otimes A \longrightarrow D \otimes B$ injective.

*** 9. Resolutions: projective, injective and flat
**** Definitions
***** Resolutions
Resolutions are *exact sequences*.

***** Projective resolution
A resolution, with $d_i$ maps:

\[\dots\longrightarrow P_2\longrightarrow P_1\longrightarrow P_0
\longrightarrow M \longrightarrow 0\]

where $P_i$ is projective.

***** Injective resolution
A resolution:

\[0 \longrightarrow M \longrightarrow E_0\longrightarrow E_1
\longrightarrow E_2 \longrightarrow \dots\]

where $E_i$ is injective.

***** Flat resolution
A resolution:

\[\dots\longrightarrow F_2\longrightarrow F_1\longrightarrow F_0
\longrightarrow M \longrightarrow 0\]

where $F_i$ is flat.

**** How to form a resolution
It is important to notice that, given a module $M$, we can always find
a surjection from a proyective module (if we have /enough
projectives/). So we can construct a projective resolution as follows:

\[ \begin{tikzcd}[column sep=tiny]
&\ker f_2 \drar&&&&\ker \pi\drar &&& \\
\dots&&P_2 \drar[two heads]{f_2}&&P_1 \urar[two heads]{f_1} && P_0 \ar[two heads,rr]{\pi} && M \rar & 0\\
&&&\ker f_1 \urar&&&&
\end{tikzcd} \]

We can also reverse the arrows to obtain an injective resolution.

*** TODO 10. Homotopic projective resolutions
**** Extending a morphism
Given two projective resolutions of two $R$ modules, $A$ and $A'$, and a morphism
between them, $f$. We can extend it to $f_n \in Hom(P_n,P_n')$.

\[ \begin{tikzcd}
\dots\rar & P_{n+1}\rar & P_n\rar& \dots
 \rar & P_1\rar{d_1} & P_0\rar{d_0}& A \dar{f} \rar& 0 \\
\dots\rar & P_{n+1}'\rar & P_n'\rar&\dots
 \rar & P_1'\rar{d_1¡} & P_0'\rar{d_0'}& A' \rar& 0 \\
\end{tikzcd} \]

***** Extending the morphism, base case
We use that $P_0$ is projective to construct:

\[ \begin{tikzcd}
     & P_0 \arrow[ddl,"f_0",dashed,swap] \dar\\
     & A \dar{f} \\
P_0' \rar[two heads] & A'
\end{tikzcd} \]

***** Extending the morphism, inductive case
We are going to show that $f_n(\im d_{n+1}) \subset \im d_{n+1}' = \ker d_n'$. That is, 
$d_n' \circ f_n \circ d_{n+1} = 0$. And that follows from diagram chasing. We use
again the projectivity of $P_{n+1}$.

\[ \begin{tikzcd}
     & P_{n_+1} \arrow[ddl,"f_{n+1}",dashed,swap] \dar\\
     & \im d_{n+1} \dar{f_n} \\
P_{n+1}' \rar[two heads] & \im d_{n+1}'
\end{tikzcd} \]

**** TODO Homotopic resolutions
*** 11. Derived functors Ext and Tor
**** Right derived functors
Let $F$ be additive, covariant and left-exact. Let 
$0 \longrightarrow M \longrightarrow E^\bullet$ be an injective resolution with $M$ deleted; then $F(E^\bullet)$ 
is a complex, and we define:

\[R^i F(M) = H^i(F(E^\bullet)) = 
\frac{\ker \{F(E_i) \longrightarrow F(E_{i+1})\}}
{\im\{ F(E_{i-1}) \longrightarrow F(E_i)\}}\]

That is, if we take the injective resolution:

\[ 0 \longrightarrow M \longrightarrow E_0 \longrightarrow E_1 
\longrightarrow \dots\]

Delete $M$ and apply $F$ to get a (non neccesarily exact) complex where 
we can compute the homology:

\[ 0 \longrightarrow F(E_0) \longrightarrow F(E_1)
\longrightarrow F(E_2) \longrightarrow \dots\]

**** Left derived functors
Let $F$ be additive, contravariant and left-exact. Let 
$P^\bullet \longrightarrow M \longrightarrow 0$ be a projective resolution with $M$ deleted; 
then $F(P^\bullet)$ is a complex, and we define:

\[R^i F(M) = H^i(F(P^\bullet)) = 
\frac{\ker \{F(P_i) \longrightarrow F(P_{i+1})\}}
{\im\{ F(P_{i-1}) \longrightarrow F(P_i)\}}\]

That is, if we take the injective resolution:

\[\dots \longrightarrow P_2\longrightarrow P_1\longrightarrow P_0
\longrightarrow M \longrightarrow 0\]

Delete $M$ and apply $F$ to get a (non neccesarily exact) complex 
where we can compute the homology:

\[ 0 \longrightarrow F(P_0) \longrightarrow F(P_1)
\longrightarrow F(P_2) \longrightarrow \dots\]

*** 12. Computations of some standard Ext and Tor examples
*** 13. Long Exact Sequence for Tor
** Algebraic Geometry
*** 1. Intro to Algebraic Geometry
* Pascual Jara - Apuntes
** Homología de Hochschild
*** R;R módulos
**** R;R módulo
Sea $R$ una $K\text{-álgebra}$; un $(R;R)$ *módulo* es un $R$ módulo a
izquierda y derecha verificando la *relación de compatibilidad*:

\[r_1(mr_2) = (r_1m)r_2\]

En particular, se tiene,

\[km = mk \quad \forall k \in K\]

Un *homomorfismo de R;R-módulos* es un homomorfismo de R-módulos a izquierda y
R-módulos a derecha. Forman la categoría $(R;R)\mathtt{-Mod}$.

**** Álgebra envolvente
Sea $R$ una $K\text{-álgebra}$, llamamos *álgebra envolvente* a $R^e = R \otimes R^{op}$.
Con el producto:

\[ (r_1 \otimes s_1)(r_2 \otimes s_2) = (r_1r_2) \otimes (s_2s_1)\]

**** Caracterización de R;R-módulos
Para cada $K\text{-álgebra}$, $R$, las categorías siguientes son isomorfas:

  - $(R;R)\text{-Mod}$
  - $R^e\text{-Mod}$
  - $\text{Mod-}R^e$

***** Demostración
Nótese primero que a $R^e$ le damos estructura de álgebra con el
producto:

\[
(r_1\otimes s_1)(r_2\otimes s_2) = (r_1r_2\otimes s_2s_1)
\]

****** Primera implicación
Si tenemos $M$ un $(R;R)$ módulo, podemos darle estructura de $R^e$ módulo
con: $(r\otimes s)m = rms$. Que esta estructura es compatible con el producto
se comprueba trivialmente con:

\[
(a\otimes b)(c \otimes d)m = acmdb = (ac \otimes bd)m
\]

****** Segunda implicación
Si tenemos $M$ un $R^e$ módulo, podemos darle estructura de $R;R$ módulo
tomando: $rms = (r\otimes s) m$. La relación de compatibilidad se tiene por
el mismo proceso anterior.

*** Cohomología de Hochschild
**** Definición
Sea $R$ una $K\text{-álgebra}$ y $M$ un $(R;R)\text{-módulo}$, llamamos:

  - *Cohomología de Hochschild* de $R$ en $M$ a $HH^{\bullet}(R,M) = \operatorname{Ext}^\bullet_{R^e}(R,M)$.
  - *Homología de Hochschild* de $R$ en $M$ a $HH_{\bullet}(R,M) = \operatorname{Tor}_\bullet^{R^e}(R,M)$.

**** Notas
1. [[https://sbseminar.wordpress.com/2007/07/22/hochschild-homology/][Hochschild homology | Secret Blogging Seminar]]

**** Resolución estándar
Para cada k-álgebra $R$ se tiene $(P_{\bullet},d_{\bullet})$ resolución proyectiva de $R$ en 
$(R;R)\mathrm{-mod}$. Se llama *resolución estándar* de $R$, definiendo

 - $P = R \otimes (R^{\otimes n}) \otimes R$
 - $d_{n} = \sum_{i=0}^n (-1)^id^i_n$

donde tomamos

\[
d_n^i(a_0 \otimes \dots \otimes a_{n+1}) =
a_0 \otimes \dots \otimes a_ia_{i+1}\otimes \dots \otimes a_{n+1}.
\]

**** Complejo de cocadenas
Para el cálculo de la cohomología tenemos un complejo de cocadenas

\[
\mathrm{Hom}_K(K,M) \overset{b^0} \longrightarrow
\mathrm{Hom}_K(R,M) \overset{b^1} \longrightarrow
\mathrm{Hom}_K(R^{\otimes 2},M) \overset{b^2} \longrightarrow
\dots.
\]

Donde están definidas las $b^{n}$ como

 - $b^0(m)(a) = am-ma$
 - $b^n = \sum^{n+1}_{i=0}(-1)^ib_i^n$

para unas aplicaciones auxiliares $b_i^n$ definidas como

\[
b^n_i(f)(a_1\otimes \dots \otimes a_{n+1}) =
\left\{\begin{array}{ll} 
a_1f(a_2\otimes\dots\otimes a_{n+1})& \mbox{if } i=0  \\
f(a_1\otimes\dots\otimes a_ia_{i+1}\otimes\dots\otimes a_{n+1}}& \mbox{if } i=1,\dots,n \\
f(a_1\otimes\dots\otimes a_n)a_{n+1}& \mbox{if } i=n+1
\end{array} 
\right.
\]

*** Desde Weibel
**** Identidades simpliciales
Las identidades simpliciales son las relaciones entre morfismos cara y
morfismos degenerados en un objeto simplicial.

***** Objeto simplicial
Un conjunto simplicial con morfismos:

 - *Morfismos cara*, $\partial_i : S_n \to S_{n-1}$, que eliminan el vértice $i$.
 - *Morfismos degenerados*, $\sigma_i : S_n \to S_{n+1}$, que duplican el vértice $i$.

***** Identidades simpliciales
Se cumplen:

 1. $\partial_i\circ\partial_j = \partial_{j-1}\partial_i$ cuando $i<j$
 2. $\sigma_i\comp\sigma_j = \sigma_j\circ\sigma_{i-1}$ cuando $i > j$
 3. Se componen como:

    \[
    \partial_i\circ s_j = \left\{\begin{array}{ll} 
    s_{j-1}\circ\partial_i & \mbox{if } i<j \\
    id & \mbox{if } i=j \mbox{ or } i=j+1 \\
    s_j\circ \partial_{i-1}& \mbox{if } i>j+1
    \end{array} 
    \right.
    \]

***** Diferencial alternado
Definimos el morfismo cara alternado como la suma alternada de morfismos
cara:

\[
\partial(x) =
\sum_{k=0}^n (-1)^k \partial_k(x)
\]

Esto nos da un operador de frontera cumpliendo $\partial\circ\partial=0$.

****** Demostración
Usando distributividad de la composición y la primera identidad 
simplicial:

\[\begin{aligned}
\partial\circ\partial
&=
\left(
\sum (-1)^k \partial_k
\right)
\left(
\sum (-1)^t \partial_t
\right)
\\&= 
\sum_{k,t} (-1)^{k+t} \partial_k\partial_t
\\&=
\sum_{k<t} 
\left(
(-1)^{k+t} \partial_k\partial_t +
(-1)^{k+t-1} \partial_{t-1}\partial_k
\right)
\\&= 0
\end{aligned}
\]
**** Módulo simplicial sobre R;R módulo
Sea $R$ una k-álgebra y $M$ un $R;R$ módulo. Tenemos un k-módulo simplicial
en $M\otimes R^{\otimes\ast}$, dado por:

\[
\dots \longrightarrow
M\otimes R\otimes R \longrightarrow
M\otimes R \longrightarrow
M \longrightarrow 
0
\]

Con fronteras:

\[
\partial_i(m\otimes r_1 \otimes \dots \otimes r_n) =
\left\{\begin{array}{ll} 
mr_1 \otimes r_2 \otimes \dots \otimes r_n& \mbox{if } i = 0 \\
m \otimes r_1 \otimes r_2 \otimes \dots \otimes r_ir_{i+1} \otimes \dots \otimes r_n& \mbox{if } 0 < i < n \\
r_nm \otimes r_1 \otimes r_2 \otimes \dots \otimes r_{n-1} & \mbox{if } i = n
\end{array}.
\right.
\]

Y con degeneración

\[
\sigma_i(m \otimes r_1 \otimes \dots \otimes r_n) =
m \otimes \dots \otimes r_i \otimes 1 \otimes r_{i+1} \otimes \dots \otimes r_n.
\]

**** Homología de Hochschild
La homología de Hochschild se define como la de los k-módulos:

\[
HH_n(R,M) = H_nC(M\otimes R^{\otimes\ast})
\]

*** Ejemplos de cálculo de cohomología de Hoschild
**** TODO Derivaciones y derivaciones externas
** Álgebras separables
*** Álgebras separables
**** Dimensión de Hochschild
Definimos $\mathrm{Hdim}(R)$ como el menor $n$ tal que $HH^{n+1}(R,M) = 0$ para cualquier
módulo $M$. Si no existe, decimos que hay dimensión de Hochschild infinita.

**** Álgebras separables
Las álgebras de dimensión de Hochschild $0$ se llaman *separables*. Se
tiene $R$ un $R^e-\mathrm{mod}$ izquierda proyectivo.

**** Caracterización de álgebras separables
Para una k-álgebra R equivalen:

  1) Existen $a_i,b_i \in R$ con $\sum_{i=1}^na_ib_i=1$ y $\sum_{i=1}^n ra_i\otimes b_i = \sum_{i=1}^n a_i \otimes b_ir$.
  2) Dimensión de Hochschild de $R$ cero.
  3) $\mathrm{Der(R,M)} = \mathrm{Der}_{int}(R,M)$ para cada $M$ y $n \geq 1$.

Llamamos $e = \sum_{i=1}^n a_i\otimes b_i \in R^e$ *idempotente de separabilidad*.

**** Teorema de Zelinsky
Toda k-álgebra separable es un k-espacio vectorial de dimensión finita.

*** Álgebras semisimples
**** Álgebra semisimple
Una k-álgebra es semisimple si cada módulo a la izquierda suyo es proyectivo.

**** Separable es semisimple
Toda k-álgebra separable es semisimple.

***** TODO Demostración

**** Álgebras separables sobre cuerpos algebraicamente cerrados
Una k-álgebra separable en un cuerpo de característica cero es de la forma:

\[
R \cong
M_{n_1}(K) \times \dots \times M_{n_t}(K)
\]

**** Traza
Llamamos *traza* de $\varphi \in \mathrm{End}(R)$ a la suma de su diagonal. Tenemos

 - una aplicación $\tau(r) = \mathrm{Tr}(\lambda(r))$ k-lineal.
 - una aplicación $\sigma(r,s) = \tau(rs)$ k-bilineal simétrica.

Cuando $R$ es k-álgebra separable, $\sigma$ es no degenerada.

**** Caracterización de álgebras separables
Para una k-álgebra $R$ equivalen

 1) $R$ una k-álgebra separable.
 2) $\mathrm{dim}_{k}(R) < \infty$ y $\sigma$ es forma bilineal simétrica no degenerada.
 3) Existe un único idempotente de separabilidad simétrico.

*** Álgebras formalmente lisas
**** Extensiones de Hochschild
Para $\pi : S \longrightarrow R$ homomorfismo sobreyectivo con $\ker(\pi)^2=0$,

\[
0 \longrightarrow 
\mathsf{a}= \mathrm{ker}(\pi) \longrightarrow
S \longrightarrow
R \longrightarrow
0
\]

es una *extensión de Hochschild* de $R$ por $\mathsf{a}$.

**** Estructura de R;R-módulo de la extensión
Si $0 \longrightarrow \mathsf{a} \overset{\pi}\longrightarrow S \longrightarrow R \longrightarrow 0$ es una extensión de Hochschild, entonces
$\mathsf{a}$ es un R;R-módulo.

***** Demostración
Consideramos una inversa del homomorfismo sobreyectivo $\pi \circ \psi = id$.
Definimos el producto como

 - $ax = \psi(a)x$
 - $xa = x\psi(a)$

y comprobamos que $a(bx) = (ab)x$. Se tiene en efecto que

\[
\psi(a)\psi(b) - \psi(ab) \in \mathrm{ker}(\pi) = \mathsf{a}
\]

**** Extensiones equivalentes
Dos extensiones de Hochschild son equivalentes si existe un diagrama
conmutativo

\[\begin{tikzcd}
0 \rar & M \arrow[d,equal] \rar & S_1\dar{\varphi}\rar{\pi_{1}} & R \rar\dar[equal] & 0 \\
0 \rar & M \rar & S_2\rar{\pi_{2}} & R \rar & 0
\end{tikzcd}\]

para $\varphi$ un homomorfismo de k-álgebras.

**** Álgebra formalmente lisa
Un álgebra $R$ es formalmente lisa si su dimensión de Hochschild es menor o
igual que 1. Equivalentemente, $HH^2(R,M) = 0$ para cualquier $M$. Como
consecuencia, toda extensión de Hochschild es trivial.

**** Producto de separable y formalmente lisa
Si $S$ es separable y $R$ es formalmente lisa, $R \otimes S$ es formalmente lisa.

** Anillos graduados
*** Álgebra aumentada
Una $K\text{-álgebra}$ $R$ es *aumentada* si existe un $R\text{-módulo}$ $M$ con un 
epimorfismo $\varepsilon\colon R \to M$.

**** Álgebra aumentada tensor
Si $\varepsilon\colon R \to M$ es un álgebra aumentada, $\varepsilon\otimes S\colon R\otimes_K S \longrightarrow M \otimes_K S$ es
un álgebra aumentada.

*** Módulos y álgebras graduadas
**** Módulo graduado
Un $K\text{-módulo}$ graduado es aquel que se escribe como suma directa,

\[
M = \bigoplus_{n \in \mathbb{N}} M_n.
\]

***** Elemento homogéneo
Un elemento es homogéneo de grado $n$ si pertenece a $M_n$.

***** Homomorfismo graduado
Un homomorfismo $f\colon M \to N$ tal que $f(M_n) \subseteq f(N_n)$.

***** Álgebra graduada
Un $K\text{-módulo}$ graduado $R = \bigoplus R_i$ cumpliendo

\[
R_rR_t \subseteq R_{r+t}.
\]

**** Ejemplos de álgebras graduadas
***** Graduación trivial
***** Graduación del anillo de polinomios
***** Graduación del anillo de endomorfismos
**** Homomorfismos graduados
Un homomorfismo graduado de grado $t \in \mathbb{N}$ es aquel homomorfismo $f\colon M \to N$
cumpliendo $f(M_r) \subseteq f(M_{r+t})$.

** Módulos diferenciales
*** Diferencial
Un homomorfismo graduado de grado uno, $\delta\colon M \to M$ se llama *diferencial*
si $\delta\circ\delta = 0$.

*** DG-módulo
Un par $(M,\delta)$ formado por un $K\text{-módulo}$ graduado $M$ y un diferencial $\delta$.

**** Homomorfismo de DG-módulos
Un homomorfismo de DG-módulos $f \colon (M,\delta_1) \to (N,\delta_2)$ es un homomorfismo
de módulos graduados cumpliendo

\[
f\delta_1 = \delta_2 f.
\]

*** Álgebra graduada diferencial
Una $K\text{-álgebra}$ graduada $R$ con un diferencial $\delta\colon R\to R$ que verifica:

  * $(R,\delta)$ es un DG-módulo.
  * $\delta(ab) = \delta(a)b + (-1)^{|b|}a\delta(b)$.

Es lo que conocemos como *álgebra graduada diferencial*, o DG-álgebra.

**** Aritmética en álgebras graduadas I
Dada una DG-álgebra $(R,\delta)$,

 1) Para elementos homogéneos $h_1,\dots,h_n$ se verifica

    \[ \delta(h_1\dots h_n) =
    \sum_{i=1}^t (-1)^{|h_1|+\dots+|h_{i-1}|}h_1\dots \delta(h_i)\dots h_t.
    \]

 2) Para elementos $a_0,\dots,a_n \in R_0$ se verifica

    \[\delta(a_0 \delta(a_1)\dots \delta(a_n)) =
    \delta(a_0)\delta(a_1)\dots\delta(a_n).
    \]

**** TODO Aritmética en álgebras graduadas II

*** Complejo de Hochschild
Definimos el *complejo de Hochschild* como

\[
C_{\bullet}(R,M)\colon \dots 
\longrightarrow M \otimes R^{\otimes n}
\overset{d}\longrightarrow M \otimes R^{\otimes n-1}
\overset{d}\longrightarrow \cdots
\]

donde las diferenciales se definen como $d = \sum (-1)^id_i$ para

\[\begin{aligned}
d_0(m\otimes a_1\otimes\dots\otimes a_n) &= (ma_1)\otimes \dots \otimes a_n \\
d_i(m\otimes a_1\otimes\dots\otimes a_n) &= m \otimes a_1\otimes \dots \otimes a_ia_{i+1} \otimes \dots \otimes a_n \\
d_i(m\otimes a_1\otimes\dots\otimes a_n) &= a_nm \otimes a_1\otimes \dots \otimes \dots \otimes a_{n-1} \\
\end{aligned}
\]

**** Es un diferencial
Se tiene que $d\circ d = 0$.

**** Complejo bar
En el caso particular de $R=M$ tenemos

\[C_{\bullet}(R) = C_{\bullet}(R,R) = 
(\cdots \to R^{\otimes n+1} \to \cdots \to R)\]

Llamamos *complejo bar* a

\[ C^{bar}_{\ast}(R) = (\cdots \to R^{\otimes n} \to \cdots \to R^{\otimes 2}).
\]

**** Complejo bar normalizado
Llamamos $D_n$ al generado por elementos $m\otimes a_1\otimes \dots\otimes a_n$ donde algún $a_i = 1$.
Podemos crear el complejo bar normalizado con módulos de la forma

\[\frac{M\otimes R^{\otimes n}}{D_n} \cong M \otimes \overline{R}^{\otimes n}.
\]

Lo representamos por $\overline{C}(R,M)$.

** La DG-álgebra Omega
*** DG-álgebra omega
Definimos

\[
\Omega_S^nR = 
R \otimes_S \overline{R}^{\otimes n}
\quad\text{ y, en total, }\quad
\Omega_SR = \bigoplus_{n\in \mathbb{N}} \Omega_S^n R.
\]

La diferencial la definimos mediante

\[
\delta(a_0\oplus \overline{a_1} \oplus\dots\oplus \overline{a_r})
=
1 \oplus \overline{a_0} \oplus \dots \oplus \overline{a_r}.
\]

* Categories for the working mathematician
** 1. Categories, Functors and Natural Transformations
*** 1.1. Axioms for categories
**** Metagraph
Objects $a,b,c,\dots$ and arrows $f,g,h,\dots$, with two operations:

  - *Domain*, $dom(f) = a$
  - *Codomain*, $cod(f) = b$

That we write as $f : a \to b$.

**** Metacategory
A metagraph with two additional operations:

  - *Identity*: $id_a : a \to a$
  - *Composition*: for a pair of arrows $dom(g) = cod(f)$, it defines a
    new arrow $g \circ f : dom(f) \to cod(g)$.

    \[\begin{tikzcd}
    & b \drar{g} & \\
    a \arrow{rr}{g\circ f} \urar{f} & & c
    \end{tikzcd}\]

Subject to the following axioms:

  - *Associativity*: Given objects and arrows in this configuration:
    
    $a \overset{f}\to b \overset{g}\to c \overset{k}\to d$

    We have the equality: $k \circ (g \circ f) = (k \circ g) \circ f$.

  - *Unit law*: composition with the identity arrow is neutral.

***** Metacategory of Sets
***** Metacategory of Groups
***** Arrow-only axioms
*** 1.2. Categories
**** Category
An interpretation of a metacategory within set theory.

***** Diagram scheme (directed graphs)
A category is a graph with identity and composition functions.

**** Examples of categories
***** Basic examples
****** The empty category
****** 1, the category with one object and one identity
****** 2, the category a -> b with two objects
****** 3, a triangle category
****** Parallel arrows

***** Discrete categories
Where every arrow is an identity.

***** Monoids and groups
A category with one object.

***** Matrices
Objects: positive integers.
Arrows: $m\times n$ matrices.

***** Sets of sets
***** Preorder
****** Partial orders
****** Linear orders
***** Ordinal numbers
***** Simplicial category
***** Large categories
*** 1.3. Functors
**** Functor
A morphism of categories. A functor $T : {\cal C} \to {\cal B}$ is given by:

  - The *object function*, $T : Obj({\cal C}) \to Obj({\cal B})$.
  - The *arrow function*, $T : (c \to c') \to (Tc \to Tc')$

With the axioms:

  - $T(1_c) = 1_{Tc}$
  - $T(f\circ g) = Tg \circ Tf$

**** Examples
***** The powerset functor
***** Homology groups
***** General linear group
***** Commutators
***** Forgetful functors
**** Composition of functors, the metacategory Cat
We can define composition of functors, and also functors as isomorphisms.

***** Isomorphisms
A functor is an isomorphism iff there is a functor $S : B \to C$ for 
which both composites are the identity $S \circ T = Id = T \circ S$.

***** Full functor
Every $g : c \to c'$ of $B$ is of the form $Tf : Tc \to Tc'$. In other words,
the arrow function (the map!) is injective.

***** Faithful functor
The equality $Tf_1 = Tf_2$ implies $f_1 = f_2$. In other words, the arrow
function is surjective.

***** Subcategories
A subcategory gives us an inclusion functor.

*** 1.4. Natural transformations
**** Natural transformation
Given two functors $S,T : C \to B$, a natural transformation $\tau : S \xrightarrow{.} T$
is a function assigning every $c \in C$ an arrow $Sc \to Tc$ and yielding
a commutative diagram:

\[\begin{tikzcd}
c \dar{f} & & Sc \rar{\tau_c}\dar{Sf} & Tc \dar{Tf} \\
c' & & Sc' \rar{\tau_{c'}} & Tc'
\end{tikzcd}\]

We say that $\tau_c$ is natural in $c$.

***** Translation of pictures
A natural transformation translates a diagram from $S$ to $T$.

\[\begin{tikzcd}
a \arrow{dd}{h}\drar{f} &   & & S a \arrow{dd}{S h}\drar{S f} \arrow{rrr}{\tau a} &     & & T a \arrow{dd}{T h}\drar{T f} &     \\
  & b \dlar{g} & &     & S b \dlar{S g} \arrow{rrr}{\tau b} & &     & T b \dlar{T g} \\
c &   & & S c \arrow{rrr}{\tau c} &     & & T c &     \\
\end{tikzcd}\]

**** Natural isomorphisms
A natural transformation is a morphism of functors. We call 
*natural isomorphism* to a natural transformation where every 
component $\tau_c$ is invertible. We write it as:

$\tau : S \cong T$

The inverses form another natural transformation.

**** Examples
***** Determinant
Natural transformation between two functors
$GL, {\cal U}() : \mathtt{CRng} \longrightarrow \mathtt{Grp}$.

***** Identity and factor-commutator functor

***** Double character group
Defined as $D(G) = Hom(G, \mathbb{R}/\mathbb{Z})$, it is a contravariant functor when 
we define $(Df) t = t \circ f$. But the twice iterated functor $D^2$ is a 
covariant one.

There is a natural transformation between $Id$ and $D^2$.

\[
\tau_G(g) t = t(g)
\]

It is easy (with lambda calculus, for example) to check that this
diagram commutes.

***** Double dual of a finite vectorial space

***** Inclusion and cardinality of ordinals

*** 1.5. Monics, epis and zeros
**** Isomorphism
An arrow $e : a \to b$ is an isomorphism if there is an arrow $e^{-1} : b \to a$
such that $e'e = 1$ and $ee' = 1$.

***** Isomorphic objects
Two objects are isomorphic if there is an isomorphism between them.

**** Monic and epi
An arrow is *monic* if it is left cancellable, it is *epi* if it is
right cancellable.

***** Retractions and sections
A left inverse is called a *retraction*, while a right inverse is
called a *section*.

**** Splits and idempotents
When $gh = 1$, $g$ is a split epi, $h$ is a split monic and the composite
$hg$ is an idempotent. An arrow is *idempotent* if $f^2 = f$, and it is said
to split when there exist arrows $g$ and $h$ such that $f = hg$ and $gh = 1$.

**** Terminal objects and initial objects
An object $t$ is terminal if for every $a$ there is exactly one arrow $a \to t$.
An object $s$ is initial if for every $a$ there is exactly one arrow $s \to a$.
An object $z$ is null if it is both initial and terminal.

***** Zero arrow
There is an unique arrow $a \to z \to b$ called the *zero* arrow. Any 
composite with it is itself a zero arrow.

**** Groupoids
A category where every arrow is invertible.

***** The fundamental groupoid
***** Group of homomorphisms
In a groupoid, each object determines a group, $hom(x,x)$.
If there is an arrow $f : x \to x'$, the groups $hom(x,x)$ and $hom(x',x')$
are isomorphic under conjugation $g \mapsto fgf^{-1}$.

***** Connected groupoid
A *connected groupoid* is deteremined by a group and the set of
all objects.

*** 1.6. Foundations
**** Universe
An universe is a set $U$ with the closure properties:

  1. $x \in u \in U \implies x \in U$.
  2. e$u,v \in U \implies \{u,v\},(u,v),u\times v \in U$.
  3. $x \in U \implies {\cal P}x, \cup x \in U$.
  4. $\omega \in U$ where $\omega = \{0,1,2,\dots\}$.
  5. $f : a \to b$ surjective and $a \in U$, $b \subseteq U$ implies $b \in U$.

**** Small sets
Fixed an universe, we call a set $u \in U$ a *small set*. The universe is
the set of all small sets. $\mathtt{Set}$ denotes the category of small sets.

***** Small structures
A small group is a small set with a group structure. $\mathtt{Grp}$ denotes the
category of small groups.

***** Small categories
A category is small if the set of its arrows and objects are both small
sets. $\mathtt{Set}$ is not a small category.

*** 1.7. Large categories
**** Abelian groups
**** Rings
**** Modules over a ring
**** Bimodules
**** Topological spaces with continuous maps
**** Topological spaces with homotopy classes
**** Pointed sets
**** Binary relations
**** Concrete categories
*** 1.8. Hom-Sets
**** Hom-set
For objects $a,b \in C$, the *hom-set* is the set of all arrows between them:

\[
hom(a,b) = \{ f \mid f : a \to b \}
\]

***** Redefinition of a category
A small category is given by:

  1. Set of objects $a,b,\dots$
  2. Hom-set between two objects $hom(a,b)$
  3. Composition function $hom(b,c)\times hom(a,b) \to hom(a,c)$
  4. Identity function for every object, $id \in hom(a,a)$

The distributivity can be seen as commutativity of the following
diagram:

\[\begin{tikzcd}
hom(c,d)\times hom(b,c)\times hom(a,b) \rar\dar &
hom(b,d)\times hom(a,b) \dar \\
hom(c,d)\times hom(a,c) \rar &
hom(a,d)
\end{tikzcd}\]

**** Preadditive category
A category $A$ where each hom-set $hom(a,b)$ is an additive abelian group
for which composition is bilinear:

\[
(g+g')\circ(f+f') = g\circ f + g\circ f' + g' \circ f + g' \circ f'
\]

**** Preadditive category as an enriched category
A preadditive category is given by:

  1. Set of objects $a,b,\dots$
  2. Hom-set, an abelian group between two objects $hom(a,b)$
  3. A bilinear composition $hom(b,c) \otimes hom(a,b) \to hom(a,c)$
  4. Identity morphism for every object, $\mathbb{Z} \to hom(a,a)$

We can see the similitude with the definition of a category by hom-sets.
Categories created in this way are called *enriched categories*.

** 2. Constructions on categories
*** 2.1. Duality
**** Elementary theory of an abstract category (ETAC)
A theory with statements involving:

  - Domains: $a = dom(f)$
  - Codomains: $b = codom(f)$
  - Composition: $h = g \circ f$

A *sentence* is a statement with all variables quantified, using
the logical connectives and quantifiers.

***** Dual of an statement
A dual is formed by making the following replacements:

  - $a = dom(f)$ changes to $a = codom(f)$
  - $h = g \circ f$ changes to $h = f \circ g$
  - Logic is unchanged.

***** Table of dualities
\begin{tabular}{l|r}
Statement & Dual statement \\
\hline
$f : a \to b$ & $f : b \to a$ \\
$a = \operatorname{dom} f$ & $a = \operatorname{cod} f$ \\
$h = g \circ f$ & $h = f \circ g$ \\
$f$ mono & $f$ epi
\end{tabular}

**** Duality principle
The dual of each of the axioms for a category is also an axiom. Therefore,
if $\Sigma$ is a consequence of the axioms, so is its dual statement.

**** Duality and functors
The elementary theory of one functor has the axioms of two categories
$A,B$, and the properties of a functor $T$ between them. The duality for
a statement involving several categories reverses the arrows in each
category, but does not reverse the functors.

*** 2.2. Contravariance and opposites
**** Opposite category
The objects of $C^{op}$ are the objects of $C$; and, for each arrow $f : a \to b$ of
$C$, the corresponding $f^{op} : b \to a$ is defined with the composition:

\[
f^{op} \circ g^{op} = (g\circ f)^{op}
\]

***** Opposite functors
If $T : C \to B$ is a functor, we can create an opposite functor
$T^{op} : C^{op} \to B^{op}$. The assignment $C \to C^{op}$ defines a covariant functor
$\mathtt{Cat} \to \mathtt{Cat}$.

**** Contravariant functors
A functor $S : C^{op} \to B$ can be seen as a *contravariant* functor $S : C \to B$.

\[
S(f^{op}\circ g^{op}) = (Sf^{op})(Sg^{op}) = S((g\circ f)^{op})
\]

***** Examples: Hom-sets
For each object $a \in C$, the *contravariant hom-functor* $hom(a,-)$ and
the *covariant hom-functor* $hom(-,a)$ are defined.

***** Examples: Sheafs
Given $X$, a topological space. Its open sets define a category by 
inclusion, $\mathtt{Open}(X)$. Let ${\cal C}(U)$ denote the set of continuous functions
$h : U \to \mathbb{R}$, the assignment $h \mapsto h|_V$ is a function ${\cal C}(U)\to{\cal C}(V)$ for
each $V \subset U$; and this gives us a contravariant functor.

***** Examples: R-Modules
$\mathtt{ModR} : \mathtt{Rng} \to \mathtt{Cat}$ is a contravariant functor. If $\rho : R \longrightarrow S$ is a morphism
of rings, given $B$ an S-module, we can define $(Mod\rho) B = B\rho$ by pull-back.

*** 2.3. Products of categories
**** Product of two categories
Given $B,C$ two categories, we construct a category $B \times C$ with:

  - Objects: pairs of objects $(b,c)$
  - Arrows: pairs of arrows $(f,g)$

and the composition is given by the composites in $B$ and $C$:

\[
(f',g') \circ (f,g) = (f' \circ f,g' \circ g)
\]

We can define projection functors $P : B\times C \to B$, $Q : B\times C \to C$. Given
any category $D$ and two functors $B \overset{R}\longleftarrow D \overset{T}\longrightarrow C$, there is an unique 
functor $F : D \to B\times C$ with $PF = R, QF = T$.

\[\begin{tikzcd}
& D \drar{T}\dlar[swap]{R} \dar[dashed]{\exists! F} & \\
B & B\times C \rar[swap]{Q}\lar{P} & C
\end{tikzcd}\]

**** Product of functors
Two functors $U : B \to B'$, $V : C\to C'$ have a product:

\[
U\times V : B\times C \to B'\times C'
\]

That can be described as the unique functor making the following
diagram commutative:

\[\begin{tikzcd}
B \dar{U} &
B \times C  \rar{Q}\lar[swap]{P} \dar[dashed]{U \times V}&
C \dar{V} \\
B' &
B' \times C' \rar[swap]{Q'}\lar{P'}&
C'
\end{tikzcd}\]

***** Product as a functor
The product of categories can be seen as a functor:

\[
\times : \mathtt{Cat} \times \mathtt{Cat} \to \mathtt{Cat}
\]

***** Bifunctors
Our definition of product category gives an automatic definition for
a *bifunctor*, a functor of two variables.

**** Bifunctor determined by its currifications
Let $B,C,D$ be categories. For all objects $c \in C, b \in B$, let $L_c : B \to D$
and $M_b : C \to D$ be functors such that $M_b(c) = L_c(b)$.

There exists a bifuctor $S : B\times C \to D$ such that $S(-,c) = L_c$
and $S(b,-) = M_b$ iff for every pair of arrows:

\[
M_{b'}g \circ L_c f = L_{c'}f \circ M_b g
\]

so we can define the value of $S(f,g)$ uniquely.

***** TODO Proof

**** Natural transformations between bifunctors
Given bifunctors $S,S'$, the function $\alpha$ is a natural transformation
$\alpha : S \Rightarrow S'$ iff $\alpha(b,c)$ is natural in $b$ and natural in $c$.

***** TODO Proof

*** 2.4. Functor categories
**** Composition of natural transformations
Given functors $R,S,T : C \to B$ and natural transformations $\tau : S\to T$
and $\sigma : R \to S$, their compositions define composite arrows which are
the components of the composite natural transformation $\tau \cdot \sigma$.

\[\begin{tikzcd}
Rc \rar{Rf}\dar{\sigma_c}\arrow[dd,bend right=90]{(\tau \circ \sigma)_c} &
Rc' \dar{\sigma_{c'}} \arrow[dd,bend left=90]{(\tau\circ\sigma)_{c'}} \\
Sc \rar{Sf}\dar{\tau_c}  &
Sc' \dar{\tau_{c'}} \\
Tc \rar{Tf}  &  Tc' 
\end{tikzcd}\]

***** Proof
Naturality of the external square follows from the commutativity of the
two internal squares.

**** Functor category
Given categories $B,C$, let $B^C = \mathrm{Funct}(C,B)$ be the *functor category*,
with objects the functors $T\colon C \to B$ and morphisms the natural 
transformations

\[ \mathrm{Nat}(S,T) = \left\{ \tau\mid \tau\colon S \dot\to T \right\}.
\]

***** Example: Category of arrows
The category $\mathrm{Funct}(B,2)$ is called the *category of arrows* of $B$. Its
objects are arrows $f\colon a \to b$ and its morphisms are commutative squares

\[\begin{tikzcd}
a\rar{h} \dar[swap]{f} & a' \dar{f'} \\
b\rar{k} & b'
\end{tikzcd}\]

***** Example: Actions on a set
If $M$ is a monoid, $\mathrm{Funct}(M, \mathtt{Set})$ is the category with objects the actions
of $M$ on some sets and arrows the morphisms of such actions.

***** TODO Example: Group with operators
**** Example: Group representations
Given $K$ a commutative ring, the functor category $\mathrm{Funct}(G, K\mathtt{-mod})$ is the 
category of linear representations of $G$.

***** Objects
Every functor $T \colon G \to K\mathtt{-mod}$ is determined by a $K\text{-module}$ $V$ and
a morphism of groups $T\colon G \to \text{Aut}(V)$.

***** Natural transformations
A natural transformation $\sigma\colon T \to S$ is given by a single module
homomorphism $\sigma\colon V \to V'$, such that

\[\begin{tikzcd}
V\rar{\sigma} \dar[swap]{Tg} & V' \dar{T'g} \\
V\rar{\sigma} & V'
\end{tikzcd}\]

and it is called an *intertwining* operator.

*** 2.5. The category of all categories
**** Horizontal composition of natural transformations
Given functors $S,T \colon C \to B$ and $S',T'\colon B \to A$ and natural transformations

\[\begin{tikzcd}
C 
\rar[shift left=7pt, ""{name=UL, below}]{S} 
\rar[shift right=7pt, ""name=LL][swap]{T\vphantom{'}} &
B 
\rar[shift left=7pt, ""{name=UR, below}]{S'}
\rar[shift right=7pt, ""name=LR][swap]{T'} &
A\\
\ar[from=UL, to=LL, "\tau", shorten <= -2pt, shorten >= -2pt]
\ar[from=UR, to=LR, "\tau\smash{'}", shorten <= -2pt, shorten >= -2pt]
\end{tikzcd}\]

we can define the horizontal composite $\tau' \circ \tau \colon S'S \to T'T$ as the diagonal
of the square

\[\begin{tikzcd}
S'Sc\rar{\tau'_{Sc}} \dar[swap]{S'\tau_c} & T'Sc \dar{T' \tau_c} \\
S'Tc\rar{\tau'_{Tc}} & T'Tc
\end{tikzcd}\]

explicitely, as $\tau' \circ \tau = T' \tau \circ \tau' = \tau' \circ S'\tau$.

***** Naturality of the composition
It is natural as the following diagram is the composition of two
naturality squares

\[\begin{tikzcd}
S'Sc \rar{S'\tau} \dar{S'Sf} &
S'Tc \rar{\tau'}  \dar{S'Tf} &
T'Tc \dar{T'Tf} \\
S'Sb \rar{S'\tau} &
S'Tb \rar{\tau'} &
T'Tb
\end{tikzcd}\]

defined respectively by the naturality of $S'\tau$ and $\tau'$.

**** Identities
The identity functor is the identity for the horizontal and vertical
compositions. We can use the symbol of the functor to denote it like
$S \colon S \dot\to S$.

***** Horizontal composition
With this notation, we can then define the horizontal composition
as

\[
\tau'\circ \tau = 
(T' \circ \tau) \cdot (\tau'\circ S) =
(\tau' \circ T) \cdot (S'\circ \tau).
\]

**** Interchange law
Given three categories and four transformations

\[\begin{tikzcd}
C 
\rar[shift left=15pt, ""{name=UL, below}]{} 
\rar[""name=L]
\rar[shift right=15pt, ""name=LL][swap]{} &
B 
\rar[shift left=15pt, ""{name=UR, below}]{}
\rar[""name=R]
\rar[shift right=15pt, ""name=LR][swap]{} &
A\\
\ar[from=UL, to=L, "\sigma", shorten <= -2pt, shorten >= -2pt]
\ar[from=L, to=LL, "\tau", shorten <= 2pt, shorten >= -2pt]
\ar[from=UR, to=R, "\sigma\smash{'}", shorten <= -2pt, shorten >= -2pt]
\ar[from=R, to=LR, "\tau\smash{'}", shorten <= 2pt, shorten >= -2pt]
\end{tikzcd}\]

the vertical and horizontal composites follow the interchange law

\[
(\tau'\cdot \sigma') \circ (\tau \cdot \sigma) = 
(\tau'\circ \tau) \cdot (\sigma'\circ \sigma).
\]

***** TODO Proof

**** Double category
A *double category* is a set of arrows for two different compositions
which together satisfy the [[*Interchange law][interchange law]].

***** 2-category
A *2-category* is a double category in thich every identity for the
first composition is also an identity for the second one.

***** Example: commutative squares in Set
The category of commutative squares in Set is a double category but
not a 2-category.

**** Interchange law for operations
Two binary operations $\cdot,\circ$ are said to satisfy the interchange law when

\[
(a' \cdot b') \circ (a \cdot b) = (a' \circ a) \cdot (b'\circ b).
\]

***** Example: matrices
The usual product of matrices $\circ$ satisfies the interchange law with the
square-composition of matrices

\[
\tau \cdot \sigma = \begin{pmatrix}
\tau & 0\\
0 & \sigma
\end{pmatrix}.
\]

****** Proof
Trivial by definition.

**** Functor category as a functor
The functor category can be regarded as a functor

\[\mathrm{Func} \colon \mathtt{Cat}^{op}\times \mathtt{Cat} \to \mathtt{Cat}.
\]

sending an arrow, consisting of two functors $F,G$, to $F^{G}$, a functor
defined as

  * $F^GS = F \circ S \circ G$, on objects.
  * $F^{G}\tau = F \circ \tau \circ G$, on arrows.

***** Analogue with the hom-functor
Note that this is the categorical analogue of the hom-functor

\[\mathrm{Hom} \colon \mathtt{Set}^{op}\times \mathtt{Set} \to \mathtt{Set}.
\]

*** 2.6. Comma categories
**** Category of objects under an object
Given $b \in C$, the category of *objects under* it, $(b \downarrow C)$, is the category
with objects all pairs $(f\colon b \to c, c)$, and arrows $h\colon (f,c) \to (f',c')$ for those
arrows such that $h\circ f = f'$.

***** Displayed notation
Objects are of the form

\[\begin{tikzcd}
b \rar{f} & c
\end{tikzcd}\]

morphisms are of the form

\[\begin{tikzcd}
& c \arrow[dd, "h"] \\[-15pt]
b \urar{f}\drar[swap]{f'}& \\[-15pt]
& c'
\end{tikzcd}\]

and the composition is the composition of two commutative triangles
in that form.

**** Category of objects over an object
The category of *objects over* $a$, $(C \downarrow a)$ can be defined similarly in
displayed notation as objects of the form

\[\begin{tikzcd}
c \rar{f} & a
\end{tikzcd}\]

and morphisms

\[\begin{tikzcd}
c \arrow[dd, "h"] \drar{f} &  \\[-15pt]
& b \\[-15pt]
c' \urar[swap]{f'} &
\end{tikzcd}\]

**** Comma category
Given categories and functors $E \overset{T}\longrightarrow C \overset{S}\longleftarrow D$, the comma category
$(T\downarrow S)$ has objects

\[\begin{tikzcd}
Te \rar{f} & Sd
\end{tikzcd}\]

and arrows commutative squares

\[\begin{tikzcd}
Te\rar{Tk} \dar[swap]{f} & Te' \dar{f'} \\
Sd\rar{Sh} & Sd'
\end{tikzcd}\]

The composite is the yuxtaposition of squares.

***** Categories of objects under/over and object
Those are particular cases when the object is seen as a functor
from the unital category $b \colon 1 \to C$.

*** 2.7. Graphs and free categories
**** TODO Forgetful functor from categories to graphs
**** Free category
Let $G$ be a small graph. There is a small category $C$ called its free
category satisfying the following universal property

\[\begin{tikzcd}
G \rar{P} \drar[swap]{D} & UC\dar[dashed]{\exists! UD'} \\
& UB
\end{tikzcd}\]

which is equivalent to $P\colon G \to UC$ being initial in $(G \downarrow U)$.

*** TODO 2.8. Quotient categories
** 3. Universals and Limits
*** 3.1. Universal arrows
*** 3.2. The Yoneda lemma
**** Univesality with hom-sets
**** Universal elements, universal arrow, representable functor
* Algebra: chapter 0
** III. Anillos y módulos
*** 7. Complejos y homología
**** 7.1. Complejos y secuencias exactas.
 #+begin_definition
 *Complejo*. Un complejo es una serie de morfismos $d_i$ entre R-Módulos:

 \[\dots \longrightarrow M_{i+1} \longrightarrow M_i \longrightarrow M_{i-1} \longrightarrow \dots\]

 tales que $d_i \circ d_{i+1} = 0$.
 #+end_definition

 Además lo llamamos *exacto* cuando $im (d_{i+1}) = ker (d_i)$.

 #+begin_proposition
 *Exactitud de monomorfismos y epimorfismos*. Dos complejos de la forma:

 \[ \dots \longrightarrow 0 \longrightarrow L \overset{\alpha}\longrightarrow M \longrightarrow \dots \]
 \[ \dots \longrightarrow M \overset{\beta} \longrightarrow N \longrightarrow 0 \longrightarrow \dots \]

 Son exactos en $L$ y $N$ ssi $\alpha$ y $\beta$ son monomorfismo y epimorfismo, 
 respectivamente.
 #+end_proposition

 #+begin_definition
 *Secuencia exacta corta*. Una secuencia exacta corta es un complejo de la forma:

 \[ 0 \longrightarrow L \overset{\alpha}\longrightarrow M \overset{\beta}\longrightarrow N \longrightarrow 0 \]
 #+end_definition

 El primer teorema de isomorfía nos dice que $N \cong \frac{M}{ker(\beta)} = \frac{M}{im(\alpha)}$ lo que nos 
 lleva a identificar   $N \cong \frac{M}{L}$. De hecho, cada monomorfismo da lugar a una 
 secuencia exacta corta:

 \[ 0 \longrightarrow \ker(\phi) \longrightarrow M \longrightarrow im(\phi) \longrightarrow 0 \]

**** 7.2. Secuencias exactas escindidas
 #+begin_definition
 *Secuencia escindida*. Una secuencia exacta corta:

 \[ 0 \longrightarrow M_1 \longrightarrow N \longrightarrow M_2 \longrightarrow 0 \]

 es escindida si es isomorfa a una secuencia de la forma siguiente:

 \[ \begin{tikzcd}
 0   \arrow{r}{} & 
 M_1 \arrow{d}{\sim}\arrow{r}{} & 
 N   \arrow{d}{\sim}\arrow{r}{} & 
 M_2 \arrow{d}{\sim}\arrow{r}{} & 
 0 \\
 0   \arrow{r}{} & 
 M_1 \arrow{r}{} & 
 M_1 \oplus M_2   \arrow{r}{} & 
 M_2 \arrow{r}{} & 
 0
 \end{tikzcd} \]

 Es decir, hay un isomorfismo entre secuencias.
 #+end_definition

 #+begin_theorem
 *Relación entre secuencias escindidas e inversas*. Sea $\phi$ un homomorfismo;
 entonces tiene inversa izquierda ssi la secuencia siguiente escinde:

 \[ 0 \longrightarrow M \overset{\phi}\longrightarrow N \longrightarrow coker(\phi) \longrightarrow 0 \]

 Y tiene inversa derecha si la secuencia siguiente escinde:

 \[ 0 \longrightarrow ker(\phi) \longrightarrow M \overset{\phi}\longrightarrow N \longrightarrow 0 \]
 #+end_theorem

**** 7.3. Homología, y el lema de la serpiente
 #+begin_definition
 *Homología*. La i-ésima homología de un complejo,

 \[ \dots \longrightarrow M_{i+1} \overset{d_{i+1}}\longrightarrow M_i \overset{d_i}\longrightarrow M_{i-1} \longrightarrow \dots \]

 es el R-módulo:

 \[H_i(M) = \frac{ker(d_i)}{im(d_{i+1})}\]
 #+end_definition

 La homología mide lo que se aleja de ser exacto en un punto determinado, y
 es $0$ cuando el complejo es exacto. Puede verse como una generalización de
 kernel y cokernel; que los realiza en este caso extremo:

 \[ 0 \longrightarrow M_1 \overset{\phi}\longrightarrow M_0 \longrightarrow 0 \]

 En el que $H_1(M) \cong ker(\phi)$ y $H_0(M) \cong coker(\phi)$.

 #+begin_theorem
 *Lema de la serpiente*. Teniendo dos secuencias exactas en el diagrama 
 conmutativo siguiente:

 \[ \begin{tikzcd}
 0 \rar & L_1 \rar{\alpha_1}\arrow{d}{\lambda} & M_1 \rar{\beta_1}\arrow{d}{\mu} & N_1 \rar\arrow{d}{\eta} & 0 \\
 0 \rar & L_0 \rar{\alpha_0}                   & M_0 \rar{\beta_0}               & N_0 \rar                & 0
 \end{tikzcd} \]

 Existe una secuencia exacta de la forma:

 \[ 0 \overset{}\longrightarrow 
 ker(\lambda) \overset{}\longrightarrow 
 ker(\mu) \overset{}\longrightarrow 
 ker(\eta) \overset{\delta}\longrightarrow 
 coker(\lambda) \overset{}\longrightarrow 
 coker(\mu) \overset{}\longrightarrow 
 coker(\eta) \overset{}\longrightarrow 
 0\]
 #+end_theorem

 El diagrama desde el que se deduce todo esto, con columnas exactas, es
 el siguiente:

 \[ \begin{tikzcd}
	& 0 \dar              & 0 \dar            & 0 \dar           &   \\
 0 \rar & ker(\lambda) \rar \dar  & ker(\mu) \rar \dar    & ker(\eta) \dar \ar[out=355, in=175,looseness=1, overlay, swap]{dddll}{\delta}       &   \\
 0 \rar & L_1 \rar{\alpha_1} \dar{\lambda}  & M_1 \rar{\beta_1} \dar{\mu} & N_1 \rar \dar{\eta}        & 0 \\
 0 \rar & L_0 \rar{\alpha_0} \dar & M_0 \rar{\beta_0} \dar & N_0 \rar \dar        & 0 \\
	& coker(\lambda) \rar \dar & coker(\mu) \rar \dar  & coker(\eta) \rar \dar & 0 \\
	& 0                   & 0                 & 0                &
 \end{tikzcd} \]

** IV. Álgebra lineal
*** 4. Presentaciones y resoluciones
**** 4.1. Torsión
 #+begin_definition
 *Torsión*. Un elemento $m \in M$ módulo de $R$ es de *torsión* si $\{m\}$ es linealmente
 dependiente. Es decir,

   \[ \exists r \in R,\ r \neq 0\ :\ rm = 0 \]

 El conjunto de elementos de torsión se llama $Tor(M)$. Un módulo es *libre de torsión*
 si $Tor(M) = 0$ y *de torsión* si $Tor(M)=M$.
 #+end_definition

 Un anillo conmutativo es libre de torsión sobre sí mismo si y sólo si es dominio de
 integridad. Cuando esto ocurre, $Tor(M)$ es siempre submódulo de $M$. Submódulos o
 sumas de módulos libres de tensión serán libres de torsión, y por todo esto, los módulos
 libres sobre dominios de integridad serán libres de torsión.

 #+begin_definition
 *Cíclico*. Un módulo es *cíclico* cuando es generado por un elemento. Es decir,
 cuando $M \cong R/I$ para algún ideal.
 #+end_definition

 Cuando en un dominio de integridad todos sus
 módulos cíclicos son libres de torsión, es un cuerpo. Otra forma de pensar sobre un módulo
 cíclico es como aquel que admite un epimorfismo:

 \[ R \longrightarrow M \longrightarrow 0 \]

**** 4.2. Módulos finitamente presentados y resoluciones libres
 #+begin_definition
 *Anulador.* El anulador de un módulo $M$ es:

 \[Ann_R(M) = \{ r \in R\ |\ \forall m \in M, rm = 0 \}\]
 #+end_definition

 Es un ideal de $R$. Cuando $M$ es finitamente generado y $R$ es dominio de integridad,
 $M$ es de torsión si y sólo si $Ann(M) \neq 0$.

 #+begin_definition
 *Módulos finitamente generados y presentados*. Sabemos que todos los módulos admiten un
 epimorfismo de la forma:

 \[ R^{\oplus A} \longrightarrow M \longrightarrow 0\]

 Cuando lo admiten con $A$ finito, se tiene $M$ *finitamente generado*. Un módulo se dice
 *finitamente presentado* si hay una secuencia exacta de la forma:

 \[R^n \overset{\phi}\longrightarrow R^m \longrightarrow M \longrightarrow 0\]

 .
 #+end_definition

 Si $R$ es Noetheriano, todo módulo finitamente generado es finitamente presentado.

 #+begin_definition
 *Resolución*. Una resolución de $M$ mediante módulos libres finitamente generados es
 un complejo exacto:

 \[ \dots \rightarrow R^{m_3} \rightarrow R^{m_2} \rightarrow R^{m_1} \rightarrow R^{m_0} \rightarrow M \rightarrow 0 \]
 #+end_definition

 Aquí podemos entender que $R^{m_0}$ contiene los generadores, $R^{m_1}$ las relaciones
 entre los generadores, $R^{m_2}$ las relaciones entre relaciones, y así sucesivamente.

 Un dominio de integridad es *cuerpo si y sólo si todos sus módulos son finitamente generados*,
 esto es equivalente a tener:

 \[ 0 \longrightarrow R^m \longrightarrow M \longrightarrow 0 \]

 para cualquier módulo.

 Un dominio de integridad es *PID si todas las resoluciones como finitamente generado 
 extienden a finitamente presentado*, de la forma:

 \[0 \longrightarrow R^{m_1} \longrightarrow R^{m_0} \overset{\pi}\longrightarrow M \longrightarrow 0\]

 esto equivale a pedir que $\ker(\pi)$ sea libre.

**** 4.3. Leyendo una presentación
 Hemos visto que podemos estudiar un módulo finitamente presentado por un
 morfismo $\phi: R^n \longrightarrow R^m$, donde $M = coker(\phi)$. Esto quiere decir que 
 podemos asignarle una matriz explícita.

 #+begin_theorem
 *Producto de módulos en matrices*. Sean $M,N$ módulos con matrices $A,B$.
 Tenemos $M \oplus N$ con matriz:

 \[\left(\begin{array}{c|c}
 A & 0 \\ \hline 0 & B 
 \end{array}\right)\]
 #+end_theorem

 Además nótese que las *matrices equivalentes* representan el mismo 
 homeomorfismo, y por tanto el mismo módulo.

 #+begin_theorem
 *Transformaciones de matrices de módulos*. Una matriz representa el mismo módulo
 tras las transformaciones de:
  - Permutar filas o columnas
  - Añadir filas o columnas linealmente dependientes
  - Multiplicar filas o columnas por una unidad
  - Quitar una fila y columna en la que sólo queda una unidad
 #+end_theorem

 Las primeras son consecuencia de la equivalencia. La última puede colocarse como
 una parte de identidad en una matriz de la forma:

 \[A = \left(\begin{array}{c|c}
 u & 0 \\ \hline 0 & A' 
 \end{array}\right)\]

 Que no afecta al cokernel.

** VII. Cuerpos
*** 1. Extensiones de cuerpos I
**** 1.1. Definiciones básicas
***** Categoría de los cuerpos
Los cuerpos forman la *categoría $\mathtt{Fld}$* con los homomorfismos de 
anillos entre ellos. Todo homomorfismo de anillos entre cuerpos
es inyectivo y todo morfismo en esta categoría es monomorfismo.

Así, todo morfismo entre cuerpos en $Hom(k,K)$ es una extensión $K/k$.

***** Característica de un cuerpo
      La *característica* de $K$ es el generador de $ker(i)$ para 
      $i : \mathbb{Z} \longrightarrow K$. Las extensiones preservan la 
      característica, así que podemos particionar la categoría en categorías 
      $\mathtt{Fld}_p$.

***** Cuerpos primos
      El inicial de $\mathtt{Fld}_0$ es $\mathbb{Q}$, y el de $\mathtt{Fld}_p$ es $\mathbb{F}_p = \mathbb{Z}/p\mathbb{Z}$. Todos los
      cuerpos son extensiones de uno de estos llamados *cuerpos primos*.

***** Grado de una extensión
El *grado*, $[F : K]$, de una extensión es su dimensión como espacio
vectorial sobre la base. Es *finita* o *infinita* si lo es su grado.

**** 1.2. Extensiones simples
***** Extensión simple
Una extensión es *simple* si es de la forma $K(\alpha)$ donde 
$K(\alpha)$ es la intersección de todos los subcuerpos de algún
$F$ conteniendo al cuerpo $K$ y el elemento $\alpha$.

***** Polinomio irreducible mínimo
Dada una extensión simple $K(\alpha)$, consideramos la evaluación
$\epsilon : K[X] \longrightarrow K(\alpha)$ por casos:

 - Es *inyectiva* ssi es una *extensión infinita*. En este
   caso $K(\alpha) \cong K(X)$ es el cuerpo de funciones racionales.
 - No es *inyectiva*. Existe un único polinomio mónico
   irreducible $p$ que genera el núcleo,

   \[ K(\alpha) \cong \frac{K[t]}{(p(t))}\]

   Se le llama *polinomio mínimo*.

***** TODO Extensión de isomorfismos a extensiones simples
Proposition 1.5
***** Automorfismos de una extensión
El *grupo de automorfismos* de una extensión $Aut_K(F)$, es el
grupo de los automorfismos de cuerpos que dejan fijo $K$.
***** Automorfismos y raíces
Sea $K(\alpha)$ con $p$ polinomio mínimo. Entonces $p$ tiene $|Aut_K(K(\alpha))|$ raíces
distintas en $K(\alpha)$. En particular,

\[ |Aut_K(K(\alpha))| \leq [K(\alpha):K] \]

y el caso de igualdad se tiene con $p$ factorizando en factores 
lineales sobre $F$.
**** 1.3. Extensiones finitas y algebraicas
***** Elementos algebraicos y trascendentes
Sea $F/K$ una extensión con $\alpha \in F$, entonces $\alpha$ es *algebraico*
cuando $K(\alpha)/K$ es finita, y *trascendente* si no. Una extensión
es *algebraica* si todos sus elementos lo son.

*** 6. Un poco de teoría de Galois
**** 6.1. Correspondencia de Galois y extensiones de Galois
***** Cuerpo fijo
Sea $F/k$ extensión y $G \subseteq Aut_k(F)$. Llamamos *cuerpo fijo* de $G$ a:

\[ F^G = \{ \alpha\in F \mid \forall g \in G, g\alpha=\alpha\}\]

***** Correspondencia de Galois
Hay correspondencia entre los cuerpos intermedios de la extensión
y los subgrupos del grupo de automorfismos.

Dado $E$ cuerpo intermedio, lo enviamos a $Aut_E(F)$. Dado $G$ lo enviamos
a $F^G$.

***** Inclusión y correspondencia
Para cualesquiera subgrupo $G$ y cuerpo intermedio $E$:

 - $E \subseteq F^{Aut_E(F)}$
 - $G \subseteq Aut_{F^G}(F)$

Si llamamos $E_1E_2$ al menor subcuerpo de $F$ conteniendo $E_1,E_2$ y llamamos
$<G_1,G_2>$ al menor subgrupo de los automorfismos conteniendo $G_1,G_2$:

 - $Aut_{E_1E_2}(F) = Aut_{E_1}(F) \cap Aut_{E_2}(F)$
 - $F^{<G_1,G_2>} = F^{G_1} \cap F^{G_2}$

***** Extensiones de Galois
Sea $F/k$ extensión, equivalen:

 - $F$ es cuerpo de descomposición de algún $f \in k[t]$.
 - $F/k$ es normal y separable.
 - $|Aut_k(F)| = [F : k]$.
 - La correspondencia de Galois es biyección.
 - $F/k$ separable y, si $E/F$ es algebraica con $\sigma \in Aut_k(E)$, $\sigma(F)=F$.

Llamamos a esto una *extensión de Galois*.
** VIII. Vuelta al álgebra lineal
*** 1. Preliminares
**** 1.1. Funtores
 #+begin_definition
 *Funtor*. Un funtor covariante:

 \[{\cal F} : C \longrightarrow D\]

 Asigna a cada $A \in C$ un ${\cal F}(A) \in D$ y mapea los morfismos entre cada par de objetos:

 \[Hom_C(A,B) \rightarrow Hom_D({\cal F}(A),{\cal F}(B))\]

 Respetando la identidad y la composición de morfismos. 

 Un *funtor contravariante* es un funtor desde la categoría opuesta:

 \[{\cal F} : C^{op} \longrightarrow D\]
 #+end_definition

 Los funtores preservan los diagramas conmutativos. Llamamos *prehaz* a un funtor
 contravariante $C \longrightarrow \mathtt{Set}$.

 #+begin_definition
 *Funtor aditivo*. Llamamos a un funtor 
 ${\cal F}: R-\mathtt{Mod} \longrightarrow S-\mathtt{Mod}$ *aditivo* cuando
 la función $Hom_{R}(A,B) \rightarrow Hom_{S}({\cal F}(A),{\cal F}(B))$ es homomorfismo de grupos.
 #+end_definition

**** 1.3. Equivalencia de categorías
 #+begin_definition
 *Funtores plenamente fieles*. Dada la función inducida:
 \[Hom_C(A,B) \rightarrow Hom_D({\cal F}(A),{\cal F}(B))\]
 Un funtor es *fiel* si es inyectiva, *pleno* si es sobreyectiva y *plenamente fiel*
 si es biyectiva.
 #+end_definition

 #+begin_definition
 *Equivalencia de categorías*. Un funtor es una equivalencia de categorías si 
 es plenamente fiel y esencialmente sobreyectivo, es decir, para cada $Y \in D$,
 existe un $X \in C$ tal que $F(X) \cong Y$.
 #+end_definition

**** 1.4. Límites y colímites

 #+begin_definition
 *Límite*. Para un funtor ${\cal F}: {\cal I} \longrightarrow C$, su límite es
 un objeto $L \in C$ con morfismos $\lambda_I: L \longrightarrow {\cal F}(I)$ tales que

 - Conmuta el siguiente diagrama para cualquier $\alpha : I \longrightarrow J$:

 \[ \begin{tikzcd}[column sep=1.5em]
  & L \arrow{dr}{\lambda_J} \arrow{dl}[swap]{\lambda_I} \\
 {\cal F}(I) \arrow{rr}{{\cal F}(\alpha)} && {\cal F}(J)
 \end{tikzcd} \]

 - $L$ es final en este diagrama.
 #+end_definition

 Será esencialmente único y puede notarse por $\varprojlim {\cal F}$.

 #+begin_theorem
 *Límites sobre cadenas en R-Mod*. En R-Mod siempre existe un límite llamado \(\varprojlim {\cal A}_i\) sobre una
 cadena de la forma:

 \[ \begin{tikzcd}
 & & A 
 \arrow{lld}[swap]{\phi_5}
 \arrow{ld}{\phi_4}
 \arrow{d}{\phi_3}
 \arrow{rd}[swap]{\phi_2}
 \arrow{rrd}{\phi_1} 
 & & \\
 \dots \arrow{r}[swap]{\phi_{45}}  &
 A_4 \arrow{r}[swap]{\phi_{34}} &
 A_3 \arrow{r}[swap]{\phi_{23}} &
 A_2 \arrow{r}[swap]{\phi_{12}} &
 A_1
 \end{tikzcd} \]
 #+end_theorem

 Este límite es el submódulo de las /secuencias coherentes/ en $\prod_i A_i$, es decir, de
 aquellas tales que $a_i = \phi_{i,i+1}(a_{i+1})$; teniendo como morfismos $\phi_i$ las proyecciones
 canónicas


 #+begin_definition
 *Colímite*. La noción dual de límite es el *colímite*, es decir, para
 un funtor ${\cal F} : I \longrightarrow C$, su colímite es un objeto $L \in C$ con morfismos $\gamma_i : {\cal F}(I) \longrightarrow L$
 tales que

 - Conmuta el siguiente diagrama para cualquier $\alpha : I \longrightarrow J$:

 \[ \begin{tikzcd}[column sep=1.5em]
  & L  \\
 {\cal F}(I) \arrow{ur}{\gamma_I} \arrow{rr}{{\cal F}(\alpha)} && {\cal F}(J) \arrow{ul}[swap]{\gamma_J}
 \end{tikzcd} \]

 - $L$ es inicial en este diagrama.
 #+end_definition

**** 1.5. Comparando funtores
 #+begin_definition
 *Transformación natural*. Una transformación natural entre dos funtores ${\cal F} \Longrightarrow {\cal G}$ 
 consiste en morfismos $\upsilon_X : {\cal F}(X) \longrightarrow {\cal G}(X)$ tales que conmuta el diagrama:

 \[ \begin{tikzcd}
 {\cal F}(X) \arrow{r}{{\cal F}(\alpha)} \arrow{d}{\upsilon_X} & {\cal F}(Y) \arrow{d}{\upsilon_Y} \\
 {\cal G}(X) \arrow{r}{{\cal G}(\alpha)} & {\cal G}(Y)
 \end{tikzcd}
 \]

 para cualquier morfismo $\alpha$.

 Llamamos *isomorfismo natural* a una transformación natural donde cada $\upsilon$
 es un isomorfismo.
 #+end_definition

 #+begin_definition
 *Funtor adjunto*. Llamamos ${F}$ y ${G}$ adjuntos si tenemos:

 \[ Hom_C(X,GY) \cong Hom_D(FX,Y) \]

 Isomorfismos naturales.
 #+end_definition

 Lo que nos da realmente un isormorfismo natural de $Hom_C(F-,-)$ con $Hom_D(-,G-)$,
 entendidos como funtores. Llamamos aquí adjunto izquierdo a $F$ y adjunto derecho a $G$.
 Tenemos más sobre funtores adjuntos en la lista de reproducción de [[https://www.youtube.com/playlist?list=PL54B49729E5102248][The Catsters]].

 #+begin_theorem
 *Continuidad de adjuntos*. Los funtores adjuntos derechos son continuos, los adjuntos
 izquierdos son cocontinuos. Es decir, para $I : {\cal I}\longrightarrow D$, $J : {\cal J}\longrightarrow C$

 \[G(\varprojlim I) = \varprojlim (G \circ I)\]
 \[F(\varinjlim J) = \varinjlim (F \circ J)\]
 #+end_theorem

 Siempre que existan los límites. La demostración de esto se puede hacer aplicando los
 funtores en los diagramas conmutativos y usando las propiedades universales de los límites.

 #+begin_definition
 *Funtor exacto*. Un funtor exacto respeta la exactitud de las secuencias. Es decir,
 siendo la siguiente secuencia exacta:

 \[ 0 \longrightarrow A \overset{\phi}\longrightarrow B \overset{\psi}\longrightarrow C \longrightarrow 0\]

 La siguiente secuencia será exacta:

 \[ 0 \longrightarrow FA \overset{F\phi}\longrightarrow FB \overset{F\psi}\longrightarrow FC \longrightarrow 0\]
 #+end_definition

 En particular, lo llamamos /exacto a la izquierda/ si preserva la exactitud de:

 \[ 0 \longrightarrow A \overset{\phi}\longrightarrow B \overset{\psi}\longrightarrow C\]

 Y /exacto a la derecha/ si preserva la exactitud de:

 \[ A \overset{\phi}\longrightarrow B \overset{\psi}\longrightarrow C \longrightarrow 0\]

*** 2. Producto tensor y el funtor Tor
**** 2.1. Aplicaciones bilineales
 #+begin_definition
 *Aplicación bilineal*. Una aplicación $\phi:M\times N \longrightarrow P$ es bilineal si
 son lineales $\phi(\_,n)$ y $\phi(m,\_)$ para cualesquiera $m,n$.
 #+end_definition

 #+begin_definition
 *Producto tensor*. $M \otimes_R N$ es el producto tensor de $M$ y $N$ como módulos de $R$
 si cualquier aplicación bilineal factoriza de forma única a través de él:

 \[ \begin{tikzcd}
 M \times N \arrow{r}{\phi} \arrow{d}{\otimes} & P \\
 M \otimes N \arrow{ru}[swap]{\exists! \overline\phi} &
 \end{tikzcd} \]
 #+end_definition

 Usando universalidad podemos ver que $R \otimes N \cong N$ y que $M\otimes N \cong N\otimes M$. La construcción
 explícita del producto tensor se hace sobre el módulo libre sobre $M \times N$ provocando un
 cociente sobre los submódulos generados por:

 \[(m,r_1n_1+r_2n_2) - r_1(m,n_1) - r_2(m,n_2)\]
 \[(r_1m_1+r_2m_2,n) - r_1(m_1,n) - r_2(m_2,n)\]

 Lo que nos permite actuar con ellos de forma bilineal. La demostración se basa en usar
 la propiedad universal de la proyección sobre ese cociente.

**** 2.2. Adjunción con Hom
 Dado un módulo $N$ de $R$, tenemos un funtor covariante $\otimes_R N$, que será *adjunto izquierdo*
 a $Hom_{R-mod}(N,-)$. Podemos observar simplemente que una aplicación bilineal, al currificarse,
 determina una función que va de $M$ a $Hom(N,P)$, y que es lineal. Sabiendo esto, es trivial
 que:

 \[ Hom_R(M, Hom_R(N,P)) \cong Hom_R(M \otimes N, P)\]

 La naturalidad y el hecho de que es un isomorfismo se comprueban fácilmente. El hecho de
 que exista una adjunción nos dice además que $\otimes_R N$, o $N\otimes_R$ por la isomorfía anterior,
 son cocontinuos.

 #+begin_fact
 Para cualesquiera \(R\)-módulos, se tiene:

 \[(M_1 \oplus M_2) \otimes N \cong (M_1 \otimes N) \oplus (M_2 \otimes N)\]

 \[N \otimes (M_1 \oplus M_2) \cong (N \otimes M_1) \oplus (N \otimes M_2)\]

 \[(\oplus_\alpha M_\alpha) \otimes N \cong \oplus_\alpha (M_\alpha \otimes N)\]
 #+end_fact

 Por cocontinuidad.

 #+begin_fact
 Para cualesquiera dos conjuntos $A,B$, se tiene:

 \[R^{\oplus A} \otimes R^{\oplus B} \cong R^{\oplus A \times B}\]
 #+end_fact

 Teniendo \(R^{\oplus n} \otimes R^{\oplus m} \cong R^{\oplus nm}\). De hecho, la base del espacio producto
 tensor la forman los vectores puros que emparejan elementos de las 
 bases de cada uno de los espacios.

 #+begin_theorem
 *Producto tensor de cocientes*. Dado un $N$ módulo de $R$, e $I$ ideal,
 tenemos:

 \[\frac{R}{I}\otimes N \cong \frac{N}{IN}\]

 Y desde ahí, aplicando además el tercer teorema de isomorfía, tenemos:

 \[\frac{R}{I} \otimes \frac{R}{J} \cong \frac{R}{I+J}\]
 #+end_theorem

 Esto se deduce de aplicar el funtor $\_ \otimes N$ a la secuencia exacta del 
 ideal:

 \[I \longrightarrow R \longrightarrow \frac{R}{I} \longrightarrow 0\]
 
 \[I \otimes N \longrightarrow N \longrightarrow \frac{R}{I} \otimes N \longrightarrow 0\]

 Desde donde se obtiene $IN$ como inclusión de $I\otimes N$ en $N$.

**** 2.3. Exactitud y planitud
 #+begin_definition
 *Módulo plano*. El módulo $N$ es *plano* si el funtor $\_ \otimes N$ es un
 funtor exacto.
 #+end_definition

 Un *módulo libre* será siempre plano.

**** 2.4. Los funtores Tor
 #+begin_definition
 *El funtor Tor*. Lo que se aleja de la exactitud el funtor $\_ \otimes N$
 es medido por el funtor $Tor_1(\_,N)$. De hecho, si tenemos una secuencia
 exacta:

 \[0\longrightarrow A \longrightarrow B \longrightarrow C \longrightarrow 0\]

 Obtenemos aplicando el funtor $\otimes N$ esta otra secuencia:

 \[Tor_1(C,N) \longrightarrow A \otimes N \longrightarrow B \otimes N \longrightarrow C \otimes N \longrightarrow 0\]

 Y de hecho, esta secuencia podrá extenderse aún más con /funtores derivados/,
 que se definen como:

 \[Tor_i^R(M,N) = H_i(M_{\bullet} \otimes N)\]
 #+end_definition

 Aquí entendemos $M_\bullet \otimes N$ como el complejo que se obtiene tomando una resolución
 libre de $M$:

 \[\dots \longrightarrow R^{\otimes S_2} \longrightarrow R^{\otimes S_1} 
 \longrightarrow R^{\otimes S_0} \longrightarrow M \longrightarrow 0}\]

 Y retirando $M$ y tensando sobre $N$, para tener:

 \[\dots \longrightarrow N^{\otimes S_2} \longrightarrow N^{\otimes S_1} 
 \longrightarrow N^{\otimes S_0} \longrightarrow 0}\]

 Todo esto se obtendrá de manera natural aplicando el lema de la serpiente a una secuencia
 de resoluciones compatibles, algo que, si los módulos fueran PID y tuvieran una resolución
 de grado 2, sería de la forma:

 \[ \begin{tikzcd}
    & 0 \dar & 0 \dar & 0 \dar &   \\
 0 \rar & R^{\oplus a_1}\rar\dar & R^{\oplus b_1} \rar\dar & R^{\oplus c_1} \rar\dar & 0 \\
 0 \rar & R^{\oplus a_0}\rar\dar & R^{\oplus b_0} \rar\dar & R^{\oplus c_0} \rar\dar & 0 \\
 0 \rar & A\rar\dar & B \rar\dar & C \rar\dar & 0 \\
  & 0 & 0 & 0 & 
 \end{tikzcd} \]

 Tensando las dos filas superiores, que son libres, nos quedarían dos filas sobre las que aplicar
 el lema de la serpiente y obtener los funtores derivados tal y como los hemos definido.

*** 5. Funtor Hom y dualidad 
**** 5.1. Adjunciones, de nuevo
 Ya sabemos que el funtor $Hom(N,\_)$ es adjunto derecho a $\_\otimes N$, ahora
 estudiamos el funtor $Hom(\_,N)$.

 #+begin_theorem
 *Adjunción de Hom contravariante*. El funtor $Hom(\_,N)$ es adjunto derecho
 de su funtor opuesto, $Hom^{op}(\_,N)$.
 #+end_theorem

 Aplicando currificación tenemos trivialmente:

 \[Hom(L,Hom(M,N)) \cong Hom(M,Hom(L,N))\]

 Que, teniendo en cuenta que estamos usando la categoría opuesta, prueba la
 adjunción.

 #+begin_proposition
 *Exactitud de Hom*. Ambos funtores $Hom$ son adjuntos derechos y por tanto,
 exactos por la izquierda. Teniendo en cuenta que uno es contravariante, quiere
 decir que:

 \[ A \overset{}\longrightarrow B \overset{}\longrightarrow C \overset{}\longrightarrow 0\]

 Lleva a:

 \[ 0 \overset{}\longrightarrow Hom(C,N) \overset{}\longrightarrow 
 Hom(B,N) \overset{}\longrightarrow Hom(A,N)\]
 #+end_proposition

**** 5.2. Módulos duales.
 #+begin_definition
 *Módulo dual*. El dual de un R-módulo $M$ es el módulo $M^{\vee} = Hom_R(M,R)$.
 #+end_definition

 Tenemos que $Hom(M,R^n) \cong M^{\vee} \otimes R^n$.

*** 6. Módulos proyectivos e inyectivos, y el funtor Ext
**** 6.1. Proyectividad e inyectividad
 #+begin_definition
 *Módulos proyectivos e inyectivos*. Un R-módulo es /proyectivo/ si $Hom(P,\_)$
 es exacto; e /inyectivo/ si $Hom(\_,P)$ es exacto.
 #+end_definition

 Esto es equivalente a decir que cada epimorfismo $M \longrightarrow N$ lleva un
 morfismo $P \longrightarrow N$ a $P \longrightarrow M$, en el caso de /proyectividad/:

 \[ \begin{tikzcd}
  & P \dlar[swap,dashed]{\exists p'} \dar[swap]{p} \drar{0} & \\
 M \rar & N \rar & 0
 \end{tikzcd} \]

 O que cada monomorfismo $L \longrightarrow M$ lleva un morfismo $L \longrightarrow Q$ a
 un monomorfismo $M \longrightarrow Q$, en el de la /inyectividad/:

 \[ \begin{tikzcd}
  & Q & \\
 0 \urar{0} \rar & N \rar \uar[swap]{q} & M \ular[dashed,swap]{\exists q'}
 \end{tikzcd} \]

 Además, esto es equivalente a decir que un módulo $P$ es /proyectivo/ si toda secuencia

 \[ 0 \overset{}\longrightarrow L \overset{}\longrightarrow M \overset{}\longrightarrow P \overset{}\longrightarrow 0 \]

 es escindida, y $Q$ es /inyectivo/ si toda secuencia:

 \[ 0 \overset{}\longrightarrow Q \overset{}\longrightarrow M \overset{}\longrightarrow N \overset{}\longrightarrow 0 \]

 es escindida.

**** 6.2. Módulos proyectivos
 #+begin_theorem
 *Caracterización de proyectividad*. Un módulo es proyectivo ssi es el sumando
 directo de un módulo libre.
 #+end_theorem

 Así, la suma directa de dos módulos proyectivos es proyectiva; el producto tensor
 de dos módulos proyectivos es proyectivo, y todo módulo proyectivo es plano.

**** 6.3. Módulos inyectivos
 #+begin_theorem
 *Caracterización de inyectividad*. Un módulo es *inyectivo* ssi toda aplicación
 $f : I \longrightarrow Q$ extiende a una aplicación $\hat f : R \longrightarrow Q$, donde I es ideal de R.
 #+end_theorem

**** 6.4. El funtor Ext
 Existirían dos formas naturales de definir *Ext*, que coinciden no trivialmente:

 #+begin_definition
 *Funtor Ext*. Dado $M$ con una resolución proyectiva:

 \[ \dots \overset{}\longrightarrow P_1 \overset{}\longrightarrow P_0 \overset{}\longrightarrow M \overset{}\longrightarrow 0 \]

 aplicamos el funtor contravariante $Hom(\_,N)$ eliminando $M$ para obtener:

 \[ 0 \overset{}\longrightarrow Hom(P_0,N) \overset{}\longrightarrow Hom(P_1,N) \overset{}\longrightarrow Hom(P_2,N) \overset{}\longrightarrow \dots \]

 Y tomamos la cohomología de este complejo $Hom(M_\bullet,N)$, dejando como definición:

 \[Ext^i_R(M,N) = H^i(Hom(M_\bullet,N))\]
 #+end_definition

 #+begin_definition
 *Funtor Ext*. Dado $N$ con una resolución inyectiva:

 \[ 0 \overset{}\longrightarrow N \overset{}\longrightarrow Q_0 \overset{}\longrightarrow Q_1 \overset{}\longrightarrow \dots \]

 aplicamos el funtor covariante $Hom(M,\_)$ eliminando $N$ para obtener:

 \[ 0 \overset{}\longrightarrow 
 Hom(M,Q_0) \overset{}\longrightarrow 
 Hom(M,Q_1) \overset{}\longrightarrow 
 Hom(M,Q_2) \overset{}\longrightarrow \dots \]

 Y tomamos la cohomología de este complejo $Hom(M,N_\bullet)$, dejando como definición:

 \[Ext^i_R(M,N) = H^i(Hom(M,N_\bullet))\]
 #+end_definition

** IX. Álgebra homológica
*** Complejos y homología, de nuevo
**** 3.1. Recordatorio de definiciones básicas
 #+begin_definition
 *Resolución*. La /resolución/ de un objeto $A$ es un complejo
 exacto excepto en un punto, donde es isomorfa a $A$.
 #+end_definition

 Esto es equivalente a tener un complejo exacto de la forma:

 \[ \dots \overset{}\longrightarrow 
 M_2 \overset{}\longrightarrow 
 M_1 \overset{}\longrightarrow 
 M_0 \overset{}\longrightarrow 
 A \longrightarrow
 0\]

**** 3.2. La categoría de los complejos
 #+begin_definition
 *Categoría de complejos de cocadenas*. La categoría $C(A)$ tiene como objetos
 los complejos de cocadenas en una categoría $A$; y como morfismos entre dos 
 cocadenas,   $Hom(M^\bullet,N^\bullet)$, los diagramas conmutativos entre ellas. Por ejemplo:

 \[ \begin{tikzcd}
 \dots \rar & M^{i-1} \rar\dar{\alpha^{i-1}} & M^{i} \rar\dar{\alpha^{i}} &  M^{i+1} \rar\dar{\alpha^{i+1}} & \dots \\
 \dots \rar & N^{i-1} \rar & N^{i} \rar & N^{i+1} \rar & \dots
 \end{tikzcd} \]

 representa el morfismo $\alpha_\bullet$.
 #+end_definition

 Esta es una categoría abeliana. De ella definiremos además dos variantes:

 - $C^+(A)$, subcategoría plena de los complejos acotados por debajo.
 - $C^-(A)$, subcategoría plena de los complejos acotados por arriba.
* ZFC
Utilizando lógica de primer orden.

\[
\wedge, \implies, \iff, \forall, \exists
\]

Además de:

- Un conjunto infinito numerable de variables: $x_1,x_2,\dots$
- Sólo puede cuantificarse sobre variables.
- Reglas para fórmulas bien formadas.

Símbolos propios de la teoría de conjuntos:

- $=, \in$

Se usa internamente la axiomática de la lógica de primer orden.

** Axiomas de la igualdad
La igualdad es relación de equivalencia. Es

 1. Reflexiva, $\forall x: x=x$.
 2. Transitiva, $\forall x,y,z: x=y \wedge x=y \implies x=z$.
 3. Simétrica, $\forall x,y : x=y \iff y=x$.
 4. Sustitución, $\forall x,y: x=y \implies \varphi \iff \varphi'$ donde $\varphi'$ sale de sustituir $x$.

** Números como conjuntos
Algunas teorías consideran elementos que no tienen elementos dentro.
En nuestro caso usaremos conjuntos para representar todos los objetos
matemáticos.

*** Números naturales
Definimos:

 - $0 = \varnothing$
 - $S(x) = x \cup \{x\}$

*** Otra construcción posible
Definiendo:

 - $\varnothing$
 - $S(x) = \{x\}$

*** Construcción de funciones
Para definir una función, usamos su gráfico:

\[\{(a,b) \in A \times B \mid f(a) = b\}\]

** Restricciones
No podemos hablar todavía del conjunto de todos los conjuntos. Dentro
de ZFC no podemos hablar de cosas como $Obj(\mathtt{Set})$.

** Axiomas de la teoría de conjuntos
Tomamos como ciertos:

*** 0. Axioma de existencia
$\exists x : x=x$

*** 1. Axioma de extensionalidad
$\forall x,y:(\forall z: z\in x \implies z \in y) \implies x = y$

De paso definimos la inclusión:

\[
x \subseteq y := \forall z: z\in x \implies z \in y
\]

Y este axioma es equivalente a la antisimetría de la inclusión.

*** 2. Axioma de comprensión
Exigiendo que $A$ no aparezca como variable libre en $\varphi$.

\[
\forall A: \exists B: \forall z:\left( \varphi(z) \vee z \in A\right) \iff z \in B
\]

Puede usarse para demostrar que existe el conjunto vacío. O que
no existe el conjunto universal.

**** Paradoja de Russell
Supongamos el universal $U$. Podríamos definir:

\[
R = \{x \in U \mid x \notin x\}
\]

Tanto $R \in R$ como $R \notin R$. Para evitarla podríamos haber usado
estratificación.

**** El número de axiomas es numerable
Las fórmulas son sucesiones finitas de los símbolos que hemos usado
antes. Al haber una cantidad numerable de símbolos, las fórmulas son
numerables, y los axiomas que se generan en este esquema lo son.

**** NBG
En la teoría axiomática de Von-Neumann se usa un número finito de
axiomas.

**** Diferencia de conjuntos
\[A-B = \{x \in A \mid x \notin B\}\]

**** Intersección de conjuntos
Nótese que todavía no podemos definir la unión arbitraria.

\[
\bigcap {\cal F} = \{x \in A \mid \forall y \in {\cal F} x \in y\}
\]

*** 3. Axioma del par
Dados dos conjuntos, tenemos uno que los contiene a los dos:

\[
\forall a,b : \exists z:
(a\in z \vee b \in z)
\]

**** Naturales
Con este axioma podemos construir los naturales en su segunda 
construcción.

**** Hay conjuntos no vacíos
Hasta ahora, los axiomas eran consistentes con que sólo existiera
el conjunto vacío.

**** Pares ordenados
Definimos un par ordenado:

\[
(a,b) := \{a , \{a,b\}\}
\]

*** 4. Axioma de la unión
Para una colección de conjuntos, crearemos una unión:

\[
\forall {\cal F}: \exists A: \forall Y,x: (x \in Y \wedge Y \in {\cal F}) \implies x \in A
\]

*** 5. Axioma del infinito
Construye directamente los números naturales:

\[
\exists I: \varnothing \in I \wedge \forall x: x\in I \implies S(x) \in I \longrightarrow \exists \mathbb{N}
\]

Lleva a la existencia de cardinales grandes.

**** Finitud
Hasta ahora, podríamos trabajar suponiendo todos los conjuntos finitos.

*** 6. Axioma del conjunto potencia
Existencia del conjunto potencia:

\[
\forall x: \exists y: \forall z: z \subseteq x \implies z \in y
\]

**** Producto cartesiano
Podemos definir el producto cartesiano de $A,B$. Tenemos que todos los
elementos $a\in A,b \in B$ llevan a $\{a,b\} \in {\cal P}(A,B)$.

\[
A \times B = \{ x \in {\cal P}{\cal P}(A \cup B) \mid x = (a,b), a \in A, b \in B\}
\]

Nótese que así sólo hemos creado el producto cartesiano finito.

**** Funciones
Con el producto cartesiano, podemos pasar a ver las funciones como su
gráfico.
*** 7. Axioma de reemplazamiento
Con estos seis axiomas, que constituyen la teoría de Zermelo, no
podemos definir el conjunto con:

\[
\mathbb{N}, {\cal P}\mathbb{N}, {\cal P}{\cal P}\mathbb{N}, \dots
\]

Un predicado funcional es una fórmula con variables libres $\varphi(x,y)$ 
que se comporta como una función:

\[
\forall x: \exists! y: \varphi(x,y)
\]

Tenemos entonces:

\[
\forall z: \exists \omega: \forall x,y: (x \in z \wedge \varphi(x,y) \implies y \in \omega)
\]

**** Definiendo el conjunto de potencias
Usando la función $n \mapsto {\cal P}^n(\mathbb{N})$.

**** Definiendo la imagen por un funcional
Definimos $\{x \in A \mid \phi(x)\}$ partiendo en el caso de que exista y 
de que no.

**** No existe el conjunto de todos los conjuntos.
Si existiera, podríamos usar todas las topologías triviales y desde ahí
el conjunto universal.
*** 8. Axioma de elección
Para cualquier familia de conjuntos sin ninguno vacío,

\[
\forall {\cal F} : 
\left(
\forall x \in {\cal F} :\varnothing \neq x
\implies 
\exists f : {\cal F} \to \bigcup {\cal F}: f(a) \in A
\right)
\]

Siendo $f$ una función.

*** 9. Axioma de fundación
Para cualquier conjunto no vacío:

\[
\forall x: (x \neq \varnothing \implies \exists y: y \in x \wedge x \cap y = \varnothing)
\]
* Pierce - Associative Algebras
** 10. Separable Algebras
*** 10.1. Bimodules
**** Opposite algebra
If $A$ is an R-algebra, the *opposite algebra* of $A$ is $A^\ast$; where
multiplication is defined as $x \circ y = yx$.

**** Enveloping algebra
The *enveloping algebra* of an R-algebra is:

\[ A^e = A^\ast \otimes A\]

* Rotman - An introduction to homological algebra
** 1. Introduction
*** 1.1. Simplicial Homology
**** Motivation: Green's Theorem
***** Original statement
Let $C$ be a positively oriented, smooth and simple closed curve in
a plane; being $D$ the region bounded by $C$. If $L,M$ have continuous
partial derivatives in $D$, then:

\[ \oint_C (L dx + M dy) = 
\iint_D \left(
  \frac{\partial M}{\partial x} - \frac{\partial L}{\partial y}
\right) dx dy\]

***** A rewrite
If we have some "bad points" that we want to delete from $C$.
We can define multiple $\gamma_i$ around them and have our integral to be:

\[ \oint_C (L dx + M dy) +
\sum^n_{i=1} \left( \int_{\gamma_i} L dx + Q dy \right) 
= \iint_D \left(
  \frac{\partial M}{\partial x} - \frac{\partial L}{\partial y}
\right) dx dy\]

As the diagram is:

[[./images/greentheorem.png]]

In this setting, the notion of $\mathbb{Z}$ linear combinations of paths
makes sense. We can take the free abelian group $G[Y]$ with $Y$ being
the set of paths $\gamma : [0,1] \longrightarrow X$.

***** An equivalence relation
For functions satisfying $\frac{\partial Q}{\partial x} = \frac{\partial P}{\partial y}$, the double integral dissapears,
and we have:

\[ \int_{m\gamma + \sum_i m_i\gamma_i} P dx + Q dy = 0\]

Here we can define an equivalence relation between pairs of paths,
where $\beta \sim \beta'$ if:

\[ \int_\beta P dx + Q dy = \int_{\beta'} P dx + Q dy \]

The equivalence class of $\beta$ is called its *homology class*.

**** Boundaries
If we take the simplices to form abelian groups, the boundaries
are homomorphisms.

[[./images/rectangle.png]]

For instance, if we can take this rectangle and compute its boundary.
We use free abelian groups of $n\text{-simplexes}$, called $C_n(X)$.

***** Boundary of a triangle
We use the minus sign to denote the inverse path, and we have:

\[ \delta([a,b,c]) = [a,b] + [b,c] - [a,c]\]

***** Boundary of the boundary of a triangle
As the double boundary is the boundary of a sphere, it is 
automatically null:

\[
\delta(\delta([a,b,c])) = (a - b) + (b - c) - (a - c) = 0
\]

***** Boundary of the rectangle
Now, we can compute the boundary of the rectangle; assuming that
the boundary function is a homomorphism preserving the union:

\[\begin{aligned}
\delta(\square) &=  \delta[a,b,c] + \delta[a,c,d] \\ 
&= [a,b]+[b,c]-[a,c]+[a,c]+[c,d]-[a,d] \\
&= [a,b]+[b,c]+[c,d]-[a,d]
\end{aligned}\]

**** Simplicial boundary maps
Let $X$ be a finite simplicial complex. We define:

\[ \delta_n [v_0,\dots,v_n] 
= \sum^n_{i=0} (-1)^i [v_0,\dots,\hat{v_i},\dots,v_n]\]

being a map from $C_n(X)$ to $C_{n-1}(X)$. We define $\delta_0 = 0$ as a convention.

**** Boundary maps are exact
For all $n > 0$, 

\[\delta_{n-1}\delta_n = 0\]

***** Proof
We can see that, for every pair of indexes, we have the same term 
twice, depending on whether we take the two indexes ordered or using
an inverse order:

\[ 
[x_0,\dots,\hat{x_i},\dots,\hat{x_j},\dots,x_n](-1)^{i+(j-1)} +
[x_0,\dots,\hat{x_i},\dots,\hat{x_j},\dots,x_n](-1)^{j+i} = 0
\]

**** Simplicial cycles and boundaries
The elements in $Z_n(X) = \ker \delta_n \subset C_n(X)$ are called *simplicial cycles*.
The elements in $B_n(X) = \im \delta_{n+1} \subset C_n(X)$ are called *simplicial 
boundaries*.

**** Exactness for cycles and boundaries
For all $n$,

\[ B_n(X) \subseteq Z_n(X)\]

***** Proof
It is trivial knowing that boundary maps are [[*Boundary maps are exact][exact]].

**** Simplicial homology group
The nth simplicial homology group of a finite simplicial complex is:

\[ H_n(X) = Z_n(X) / B_n(X) \]

What survives in this group are the cycles that are not boundaries;
that is, the boundaries of punctured sections.

**** Two modifications
We can consider *homology* with coefficients in $G$ by tensoring the
sequence of chain groups by $G$ and taking homology groups. We can
consider the *cohomology* with coefficients in $G$ applying $Hom(-,G)$
to the chain of groups and then taking homology groups.

*** 1.2. Categories and Functors
**** 1.2.1. Russell's paradox
The Russell paradox is solved in with the Zermelo-Fraenkel axioms,
specifically, the *axiom of comprehension*. It says that any definable
subclass of a set is a set; restricting the comprehension to only
already defined sets.

**** 1.2.2. Classes and sets
A class in ZFC is called *small* if it has a cardinal number. A *set*
is only a small class. In this book, we only worry about classes and
sets that are not a member of themselves.

# A cardinal number?
# More details in Mac Lane, Categories for the working mathematician.

**** 1.2.3. Categories
A category ${\cal C}$ consists of:

 - $obj({\cal C})$, a class of objects.
 - $Hom(A,B)$, a set of morphisms for every ordered pair $(A,B)$.
 - $\circ : Hom(A,B) \times Hom(B,C) \longrightarrow Hom(A,C)$, composition of functions.

**** 1.2.4. Axioms of categories
A category has disjoint $Hom$ sets, and there must be an identity element
$1_A \in Hom(A,A)$ for every morphism, following these rules:

 - The identity is a neutral element: $f \circ 1_A = f$ and $1_B \circ f = f$.
 - Composition is associative: $f \circ (g \circ h) = (f \circ g) \circ h$

**** 1.2.5. Examples of categories
***** Sets
***** Groups
***** Partially ordered sets
***** Inclusion of open sets
***** Topological spaces
***** Abstract simplicial complexes
****** Abstract simplicial complexes
We denote =Abs= the category of abstract simplicial complexes.
An abstract simplicial complex $K$ is a set of *vertices* $Vert(K)$ and
a family of nonempty finite subsets called *simplexes* 
$\sigma \subseteq Vert(K)$ such that:

 1. $\{v\}$ is a simplex for every $v \in Vert(K)$.
 2. Every subset of a simplex is a simplex.

****** Simplicial maps
A *simplicial map* is a function $\phi : Vert(K) \longrightarrow Vert(L)$ 
such that, if $\sigma$ is a simplex in $K$, then $\phi(\sigma)$ is a simplex
in $L$.

****** Dimension
A simplex with $|\sigma| = n+1$ is called a *n-simplex*. Simplicial
maps don't have to preserve dimension.

***** Nerves
If ${\cal U} = \{U\}_{i\in I}$ is the cover of a topological space, we define an 
abstract simplicial complex ${\cal N}({\cal U})$ having vertices $Vert({\cal N}({\cal U})) = {\cal U}$
and simplexes $\{U_0,\dots,U_n\} \subseteq {\cal U}$ such that:

\[ \bigcap_{k=0}^n U_k = \varnothing\]

***** Monoids
***** Homotopy category
**** 1.2.6. Algebraic examples of categories
***** Abelian groups
***** Rings (unital)
***** Commutative rings
**** 1.2.7. Modules
A left R-module, where $R$ is a ring, is an additive abelian group $M$
with a scalar multiplication $R \times M \longrightarrow M$, such that:

 1. $r(m+m') = rm+rm'$
 2. $(r+r')m = rm + r'm$
 3. $(rr')m = r(r'm)$
 4. $1m = m$

A right module is defined anagously.

**** 1.2.8. Examples of modules
***** Vector spaces over a field
***** Abelian groups over Z
***** Every ring over itself
***** Every ring over its center

**** 1.2.9. Homomorphisms of R-modules
A function $f : M \longrightarrow N$ such that:

 1. $f(m+m') = f(m)+f(m')$
 2. $f(rm) = rf(m)$

In the case of right modules, we can define them anagously.

***** The composite and inverse of homomorphisms is an homomorphism
Trivial.

**** 1.2.10. Examples of homomorphisms
***** Linear transformations in vector spaces
***** Homomorphisms of abelian groups for Z-modules
***** Homothety
Let $M$ be an R-module, and $r \in Z(R)$; multiplication by $r$, $\mu_r$, is
an homomorphism because:

\[ \mu_r(am) = r(am) = a(rm) = a\mu_r(m)\]

**** 1.2.11. Opposite rings
If $R$ is a ring, its opposite ring $R^{op}$ is the same ring with the
opposite multiplication, defined by:

\[ \mu^o(r,t) = \mu(t,r)\]

**** 1.2.12. Categories of modules
We call $_RMod$ the category of *left* R-modules, and $Mod_R$ to the 
category of *right* R-modules.

**** 1.2.13. Subcategories
A category ${\cal S}$ is a subcategory of ${\cal C}$ when:

 1. $obj({\cal S}) \subseteq obj({\cal C})$.
 2. $Hom_S(A,B) \subseteq Hom_C(A,B)$.
 3. Identities and compositions are the same.

**** 1.2.14. Full subcategories
A full subcategory has $Hom_S(A,B) = Hom_C(A,B)$ for every $A,B \in obj({\cal S})$.

**** 1.2.15. Functors
A functor $T : {\cal C} \longrightarrow {\cal D}$ is a function such that:

 1. $T : obj({\cal C}) \longrightarrow obj({\cal D})$.
 2. $T : Hom(A,B) \longrightarrow Hom(TA,TB)$.
 3. Preserves composition: $T(f \circ g) = Tf \circ Tg$.
 4. Preserves identities: $T(1_A) = 1_{T(A)}$.

**** 1.2.16. Examples of functors
***** Subcategories as inclusion functors
***** Identity functor
***** Hom(A,-) functor
***** Chains as functors from the partially ordered integers
***** Forgetful functors

**** 1.2.27. Diagrams
A diagram is a functor whose domain is a *small category*; that
is $T : {\cal D} \longrightarrow {\cal C}$, where $obj({\cal D})$ is a set.

**** 1.2.28. Paths
A path is a functor $P : n+1 \longrightarrow {\cal C}$, where the domain is the partial 
ordering of integers $0,\dots,n+1$. A path is *simple* if the functor is
injective.

**** 1.2.29. Commutativity of diagrams
A diagram commutes if the composites of the labels on any two simple path
are equal.

**** TODO 1.2.30. Contravariant functors
**** TODO 1.2.31. Examples of contravariant functors
***** Hom(-,B) functor
***** The dual space functor
\[( )^\ast = Hom_k(-,k) : \sideset{_k}{}{Mod} \longrightarrow \sideset{_k}{}{Mod}\]
***** Order-reversing functions on partially ordered sets

***** Presheaves
If ${\cal U}$ is a topology with the inclusion, a contravariant functor 
${\cal P} : {\cal U} \longrightarrow {\cal C}$ is a presheaf.

**** 1.2.32. Faithful functors
A functor is faithful if all the functions 
$Hom(A,B) \longrightarrow Hom(TA,TB)$ are injective.
**** 1.2.33. Concrete categories
A category is concrete if there is a faithful functor ${\cal C} \longrightarrow \mathtt{Set}$.

**** 1.2.33. Opposite category
We define ${\cal C}^{op}$ to be the category with:

 - $obj({\cal C}^{op}) = obj({\cal C})$
 - $Hom_{{\cal C}^{op}}(A,B) = Hom_{\cal C}(B,A)$
 - $g \circ_{op} f = f \circ g$

**** 1.2.34. Isomorphisms
A morphism $f : A \longrightarrow B$ such that exists $g : B \longrightarrow A$ with
$f \circ g = 1$ and $g \circ f = 1$.

**** 1.2.35. Functors preserve isomorphisms
Let $T$ be a functor, if $f$ is an isomorphism, then $T(f)$ is an isomorphism.

***** Proof
If $g$ is its inverse, then:

\[ T(f)T(g) = T(fg) = 1\]
\[ T(g)T(f) = T(gf) = 1\]

If $T$ is a contravariant functor, the proof remains the same.

**** 1.2.36. Natural transformations
Let $F,G : {\cal A} \longrightarrow {\cal B}$ be covariant functors. A natural transformation
$\tau : F \Longrightarrow G$ is a family of morphisms $\tau_A : S A \longrightarrow T A$, making the following
diagram commute for every $f \in Hom(A,B)$:

\[ \begin{tikzcd}
FA \rar{\tau_A} \dar{Ff} & GA \dar{Gf} \\
FB \rar{\tau_B} & GB
\end{tikzcd} \]

We write the natural transformations as $Nat(F,G)$.

**** 1.2.37. Natural isomorphisms
A natural transformation $\tau$ for which each $\tau_A$ is an isomorphism.

**** 1.2.38. Composition of natural transformations
If $\tau : F \Longrightarrow G$ and $\sigma : G \Longrightarrow H$ are natural transformations, then the
composition is a natural transformation.

***** Proof
Composing the two commutative diagrams gives us the proof.

**** 1.2.39. Identity natural transformation
For any functor $F : {\cal A} \longrightarrow {\cal B}$, we can describe an identity natural 
transformation using the identity morphisms.

**** TODO 1.2.40. Examples of natural transformations
**** TODO 1.2.41. Natural transformations are proper classes
**** 1.2.42. Yoneda Lemma
Let $A \in obj({\cal C})$ and $G : {\cal C} \longrightarrow \mathtt{Set}$ be a covariant functor. 
There is a bijection:

\[ y : Nat(Hom_C(A,-), G) \longrightarrow G(A)\]

given by $y : \tau \longrightarrow \tau_A(1_A)$.

***** Proof
****** Every choice of p determines a natural transformation
Given $p \in GA$, we can create an unique natural transformation having
$\eta_A(1_A) = p$. A natural transformation has to obey the following 
commutative diagram:

\[\begin{tikzcd}
Hom(A,A) \rar{f \circ \_}\dar{\eta}& Hom(A,B)\dar{\eta} \\
GA \rar{Gf}& GB
\end{tikzcd}\]

Then, the image of $\eta_B(f)$ is determined.

\[\begin{tikzcd}
id \rar{f \circ \_}\dar{\eta}& f\dar{\eta} \\
p \rar{Gf}& (Gf)(p)
\end{tikzcd}\]

****** Every choice gives us a natural transformation
This gives us, in fact, a natural transformation which makes every
natural square to commute:

\[\begin{tikzcd}
Hom(A,B) \rar{g \circ \_}\dar{\eta}& Hom(A,C)\dar{\eta} \\
GB \rar{Gg}& GC
\end{tikzcd}\]

Given any element $f \in Hom(A,B)$, we can check the commutativity:

\[\begin{tikzcd}
f \rar{g \circ \_}\dar{\eta}& g \circ f\dar{\eta} \\
(Gf)(p) \rar{Gg}&  G(g \circ f)(p)
\end{tikzcd}\]

Knowing that $G(g \circ f)(p) = (Gg \circ Gf) (p)$.

**** 1.2.43. Representable functors
A covariant functor $F: {\cal C} \longrightarrow \mathtt{Set}$ is representable if $F \cong Hom(A,-)$
for some $A$.

**** 1.2.44. Yoneda Corollary
For $A,B \in obj({\cal C})$:

  1. If $\eta \in Nat(Hom(A,-),Hom(B,-))$, then $\eta = (\_ \circ \psi)$ for some unique $\psi$.
  2. If $\eta = (\_ \circ \psi)$ and $\tau = (\_\circ\phi)$, then $\tau\circ\eta = (\_ \circ \psi\circ\phi)$.
  3. $\eta = (\_\circ\psi)$ is a natural isomorphism iff $\psi$ is an isomorphism.

***** Proof
****** Corollary 1
If we apply Yoneda Lemma, every transformation is defined by
$\eta(id_A) = \psi$. The transformation has to be $(\_ \circ\psi)$ because of commutativity:

\[\begin{tikzcd}
Hom(A,A) \rar{f \circ \_}\dar{\eta}& Hom(A,C)\dar{\eta} \\
Hom(B,A) \rar{f \circ\_}& Hom(B,C)
\end{tikzcd}\]

So, given any element $f \in Hom(A,C)$, we have $\eta(f) = f \circ \psi$:

\[\begin{tikzcd}
id \rar{f \circ \_}\dar{\eta}& f\dar{\eta} \\
\psi \rar{f \circ\_}& f \circ \psi
\end{tikzcd}\]

****** Corollary 2
Trivial consequence of the first corollary.

****** Corollary 3
It is trivial given the previous corollaries and:

\[(\_\circ\psi^{-1})\circ \psi = (\_\circ id)\]

**** TODO Examples
**** TODO Yoneda Imbedding
*** 1.3. Singular Homology
**** 1.3.1. Hilbert spaces and euclidean spaces
A *Hilbert space* is the set ${\cal H}$ of all sequences $(x_i) \in \mathbb{R}$ such that
$\sum x_i^2 < \infty$. A *Euclidean space*, $\mathbb{R}^n$ is a subset of ${\cal H}$ consisting of
all sequences of the form $(x_0,x_1,\dots,x_{n-1},0,\dots)$.

**** 1.3.2. Standard n-simplex
The standard n-simplex is the set of all convex combinations:

\[\Delta^n = [e_0,e_1,\dots,e_n]\]

Where $e_i$ form an orthogonal basis.

**** 1.3.3. Singular n-simplex
Given a topological space $X$, a singular n-simplex is a continuous map
$\sigma : \Delta^n \longrightarrow X$.

**** 1.3.4. Singular n-chains
We define $S_n(X)$ as the free group with singular n-simplexes as basis.
By convention, $S_{-1}(X) = \{0\}$. The elements on this group are called
singular n-chains.

**** TODO 1.3.5. Face maps
The ith face map $\epsilon^n_i : \Delta^{n-1} \longrightarrow \Delta^n$ is defined by:

*** Exercises
**** Exercise 1.1
#+begin_statement
1. Prove, in every category ${\cal C}$, that each object $A \in {\cal C}$ has a unique identity
   morphism.
2. If $f$ is an isomorphism in a category, prove that its inverse is unique.
#+end_statement

We have $id = id \circ id' = id'$ and $\varphi^{-1} = \varphi' \circ \varphi \circ \varphi^{-1} = \varphi'$.

** 2. Hom and Tensor
*** 2.1. Modules
**** Representation of a ring
A *representation* of $R$ is an homomorphism $\varphi : R \longrightarrow End_\mathbb{Z}(M)$.

***** Equivalence of representations and modules
The product of a R-module is a representation, and every
representation gives an R-module.

****** Equivalence of types
Type of a representation:

\[R \longrightarrow End(M)\]

Type of an R-module product:

\[R \times M \longrightarrow M\]

Both types are equivalent.

**** Example: Group ring
Given $G$, a group, and $R$, a ring; we define the group ring, $RG$ to be
the set of functions $G \longrightarrow R$ of finite support, with the operations:

  - Sum of functions: $(f+g)(a) = f(a)+g(a)$
  - Convolution (product): $(f\cdot g)(a) = \sum_{uv = a} f(u)g(v)$
  - Product by a scalar on $R$: $(kf)(a) = kf(a)$

It defines a ring and an R-module.

***** Inclusion of the group
The group can be included on $RG$ with the indicator function $y \mapsto 1_{(=y)}$,
defined as:

\[
y(a) = 1_{(=y)}(a) =
\left\{\begin{array}{ll} 
1 & \mbox{if } a = y  \\
0 & \mbox{if } a \neq y
\end{array} 
\right.
\]

A function that only outputs $1$ when its input is $y$.

****** Preservation of the product

\[
1_{(=y)}\cdot 1_{(=z)} (a)
=
\sum_{u\cdot v = a} 1_{u=y}1_{v=z}
=
1_{a=yz}
\]

**** Additive functors
A functor $T : \mathtt{RMod} \longrightarrow \mathtt{Ab}$ is called *additive* if, for every pair of R-maps,
$f,g$, we have:

\[
T(f+g) = Tf + Tg
\]

***** Properties of additive functors
Let $T : \mathtt{RMod} \longrightarrow \mathtt{Ab}$ be an additive functor:

  1. $T(0) = 0$, the zero map.
  2. $T(\{0\}) = \{0\}$, the zero group.

****** Proof
******* First property
$T0 = T(0+0) = T0+T0$, and then $T0 = 0$.

******* Second property
$Hom(A,\{0\})$ only has one element.

**** Homomorphisms of r-modules are abelian groups
Given $A,B$ R-modules, $Hom_{R-mod}(A,B)$ is an abelian group with the
componentwise sum.

**** Hom as an additive functor
$Hom_{R-mod}(A,-)$ is an additive functor.

***** TODO Central case

**** TODO Hom as a contravariant functor
**** Submodules
Given $M$, an R-module, a *submodule* $N \subseteq M$ is an additive subgroup
closed under scalar multiplication.

***** Examples of submodules
****** Subgroups
A submodule of a Z-module (abelian group) is a subgroup.

**** Quotient of modules
**** Kernels, images and cokernels
**** First Isomorphism Theorem
**** Second Isomorphism Theorem
**** Third Isomorphism Theorem
**** Correspondence Theorem
**** Simple module
A proper R-module $M$ is simple if it has no proper submodules.

***** Characterization
$M$ is simple iff $M \cong R/I$, where $I$ is a maximal left ideal.

****** TODO Proof

**** Exact sequences
**** Zero-ended exact sequences
**** Short exact sequences
**** External direct sum
***** Properties of the external direct sum
**** Internal direct sum
**** Direct summands and complements
***** Retractions
**** Direct product
***** Direct sum
***** Projections
***** Injections
**** Free modules
***** Basis
***** Free abelian groups
**** Basis
***** Invariant basis number
***** Rank
**** Left exactness
*** 2.2. Tensor products
**** Bilinearity
***** Biadditivity
**** Tensor product
***** Uniqueness
***** Existence
**** Tensor functors
**** Universal property of the tensor product
**** Commutativity
**** Enveloping algebra
**** Right exactness
**** Tensor and direct sum
**** Four Lemma I
**** Four Lemma II
**** Five Lemma
**** Divisible abelian group
*** 2.2.1. Adjoint isomorphisms
**** Adjoint isomorphisms
**** Right exactness
** 3. Special Modules
*** 3.1. Projective modules
**** Exact functor
**** Lifting on free modules
**** Lifting
**** Projective modules
**** Characterization of projective modules
**** Projective modules and direct summands
**** Kaplansky theorem
**** Projective basis
**** Schnauel's Lemma
**** Ascending chaing condition
**** Noetherian rings
**** Characterization of noetherian rings
**** Hilbert basis theorem
*** 3.2. Injective modules
**** Injective module
**** Characterization of injective modules
**** Product of injective modules
**** Baer criterion
**** Divisible modules
**** Bass-Papp theorem
**** Characterization by short exact sequences
**** Essential extension
**** Characterizacion by essential extensions
**** Injective envelope
**** Eckmann-Schöpf
*** 3.3. Flat modules
**** Flat module
**** Direct sum of flat modules
**** Finitely generated submodules and flat modules
**** Torsion module
**** Torsion-free module
***** PID module
***** Flat modules
**** Character module
**** Lambek theorem
**** Villamayor theorem
**** Left coherent ring
**** Chase theorem
*** 3.3.1. Purity
**** Pure exact sequence
***** Pure submodule
**** Characterization of flatness
**** Cohn theorem
** 4. Specific Rings
*** 4.2. Von Neumann Regular Rings
**** Von Neumann Regular ring
A ring $R$ is *Von Neumann regular* if:

\[
\forall r \in R: \exists r' \in R: rr'r = r
\]

***** Boolean rings
A ring is boolean if every element is idempotent. Every boolean ring
is a commutative Von Neumann regular ring.

** 5. Setting the stage
*** 5.4. Sheaves
**** Protosheaves
 #+begin_definition
 *Local homeomorphism*. Continuous map $p : E \longrightarrow X$ such that for each $e \in E$ there is
 an open neighboorhood $S$ of $e$ such that $p|_S$ is an isomorphism.
 #+end_definition
 #+begin_definition
 *Protosheaf*. Surjective local homeomorphism.
 #+end_definition

**** Etale-sheaves
 #+begin_definition
 *Etale-sheaf of abelian groups*. A *protosheaf* such that:

 - The stalk $E_x$ is an abelian group.
 - Inversion and adition are continuous.
 #+end_definition

 #+begin_definition
 *Etale-map*. Given two etale-sheaves $E$ and $E'$, a map $\phi : E \longrightarrow E'$ such
 that $p'\phi = p$, and each $\phi|_{E_x}$ is a homomorphism.
 #+end_definition

 Here, etale-sheaves of abelian groups over a topological space X form an
 abelian category $\mathtt{Sh}_{et}(X,\mathtt{Ab})$.

*** 5.5. Abelian categories
**** Additive category
 #+begin_definition
 *Additive category*. ${\cal C}$ is additive if:

 - $Hom(A,B)$ is an *abelian group*.
 - *Distributivity* holds: $b \circ (f+g) = b\circ f + b \circ g$ and $(f+g)\circ a = f\circ a + g\circ a$.
 - Has a *zero object*.
 - Has finite *products* and *coproducts*.

 A functor $T$ between two additive categories is additive if $T(f+g) = Tf+Tg$.
 #+end_definition

 #+begin_theorem
 *Sums and products are the same*. Products and coproducts are isomorphic:

 \[A \mathbin{\Pi} B \cong A \amalg B\]

 So we call them *direct sums*, $A \oplus B$. And there are canonical morphisms:

 \[ \begin{tikzcd}
 & A \oplus B \dlar[bend right,swap]{\pi_A} \drar[bend left]{\pi_B} $ \\
 A \urar[bend right,swap]{i_A} & & B \ular[bend left]{i_B}
 \end{tikzcd} \]

 Such that: \(i_A \circ \pi_A + i_b \circ \pi_B = id\) and \(\pi_B \circ i_A = \pi_A \circ i_B = 0\).
 #+end_theorem

**** Monomorphisms and epimorphisms

#+begin_definition
*Monomorphism*. A morphism $u$ such that:
\[u \circ f = u \circ g \quad \Rightarrow \quad f = g\]
#+end_definition

#+begin_definition
*Epimorphism*. A morphism $u$ such that:
\[f \circ u = g \circ u \quad \Rightarrow \quad f = g\]
#+end_definition

We have that $u : B \longrightarrow C$ is *monomorphism* iff the induced 
$u^\ast : Hom(A,B) \longrightarrow Hom(A,C)$ is injective. And $v : B \longrightarrow C$ is *epimorphism* 
iff the induced $v^* : Hom(B,D) \longrightarrow Hom(C,D)$ is surjective.

**** Kernels and cokernels
 #+begin_definition
 *Kernel*. The kernel of $u$ is the equalizer of $u$ and $0$. In a diagram:

 \[ \begin{tikzcd}
 & C \dar[dashed] \arrow[ddr, bend left] \arrow[ddl,bend right] &\\
 & \ker(u) \dlar[swap]{i} \drar{0} & \\
 A \arrow[shift left]{rr}{u} \arrow[shift right]{rr}[swap]{0} & & B
 \end{tikzcd} \]
 #+end_definition
 #+begin_definition
 *Cokernel*. The cokernel of $u$ is the coequalizer of $u$ ans $0$. In a diagram

 \[ \begin{tikzcd}
 & C &\\
 & \ker(u) \uar[dashed]   & \\
 A \urar{0} \arrow[uur, bend left]
 \arrow[shift left]{rr}{u} \arrow[shift right]{rr}[swap]{0} & & 
 B \ular[swap]{\pi} \arrow[uul,bend right]
 \end{tikzcd} \]
 #+end_definition

 #+begin_theorem
 *Monomorphisms and kernels*.
 - If $\ker(u)$ exists, $u$ is monomorphism iff $ker(u) = 0$.
 - If $coker(v)$ exists, $v$ is epimorphism iff $coker(v) = 0$.
 #+end_theorem
**** Abelian category
 #+begin_definition
 *Abelian category*. ${\cal C}$ is abelian if

 - Every morphism has *kernel* and *cokernel*.
 - Every monomorphism is a *kernel*.
 - Every epimorphism is a *cokernel*.
 #+end_definition

 Abelian categories are /self-dual/, if ${\cal A}$ is an abelian category, then
 ${\cal A}^{op}$ is an abelian category.

 #+begin_definition
 *Image*. Given $f : A \longrightarrow B$ in an abelian category, its image is:

 \[img(f) = ker(coker(f))\]
 #+end_definition

* Carlos Ivorra - Álgebra conmutativa
** I. Funtores Derivados
*** 1.1. Haces
**** Prehaces
Un *prehaz* sobre un espacio topológico $X$ es un par $({\cal F},\rho)$, donde cada abierto $U$
tiene un grupo asociado ${\cal F}(U)$ y cada inclusión $U \subset V$ tiene asociado un homomorfismo
llamado *restricción*, $\rho_U^V : {\cal F}(V) \longrightarrow {\cal F}(U)$ cumpliendo:

  - ${\cal F}(\varnothing) = 0$
  - $\rho_U^U$ es la identidad
  - Si $U\subset V\subset W$, entonces $\rho_V^W \circ \rho_U^V = \rho_U^W$

Cuando los grupos ${\cal F}(U)$ son anillos o módulos tenemos un *prehaz de anillos* o un
*prehax de módulos*.

# Categóricamente, un funtor contravariante desde los conjuntos del espacio
# topológico con la inclusión a los grupos, o módulos, o álgebras...

**** Notación de restricción
Normalmente escribiremos $f|_{U}$ para llamar a la restricción de $f$ a $U$, esto 
es $\rho_U^V(f)$.

**** Haces
Un *haz* es un prehaz tal que si $U = \bigcup U_i$ es el recubrimiento de un abierto:

  - Si $f|_{U_i} = 0$ para todos los $i$, entonces $f = 0$.
  - Para una familia de elementos $f_i \in {\cal F}(U_i)$ cumpliendo que 
    $f_i|_{U_i \cap U_j} = f_j|_{U_i \cap U_j}$, se tiene que hay un $f \in {\cal F}(U)$ tal que $f|_{U_i} = f_i$.

**** Grupo de gérmenes o grupo local
Dado un prehaz ${\cal F}$ sobre $X$, con $P \in X$, llamamos *grupo de gérmenes* en $P$ al grupo
${\cal F}_P$, formado por las clases de equivalencia de pares $(U,f)$ con $P\in U$, $f \in {\cal F}(U)$;
respecto de la relación dada por $(U,f) \sim (V,g)$ ssi hay un abierto $W \subset U \cap V$
tal que $P \in W$ y además $f|_W = g|_W$. Teniendo como operación de grupo a:

\[ [(U,f)]+[(V,g)] = [(U\cap V, f|_{U\cap V} + g|_{U\cap V})] \]

**** Homomorfismo de prehaces
Un *homomorfismo de prehaces* $\alpha : {\cal F} \longrightarrow {\cal G}$, asigna a cada abierto $U$ un homomorfismo
de grupos $\alpha_U : {\cal F}(U) \longrightarrow {\cal G}(U)$, tal que:

\[ \begin{tikzcd}
{\cal F}(V) \rar{\alpha_V} \dar[swap]{\rho_U^V} & {\cal G}(V) \dar{\rho_U^V} \\
{\cal F}(U) \rar{\alpha_U} & {\cal G}(U)
\end{tikzcd} \]

# Categóricamente son transformaciones naturales.
* Grupos y Representaciones
** 1. Álgebras y módulos
*** 1.1. Noción de álgebra
**** 1.1. Álgebra
Un *álgebra* sobre un cuerpo $K$ es un K-espacio vectorial dotado de una
aplicación bilineal $(\cdot) : K \times K \longrightarrow K$. La bilinealidad se expresa como:

  1. $(a+b)c = ac+bc$
  2. $a(b+c) = ab+ac$
  3. $(\alpha a)b = \alpha(ab) = a(\alpha b)$

***** Álgebra asociativa
Un álgebra es *asociativa* si $(ab)c = a(bc)$.

**** 1.2. Subálgebra
Una *subálgebra* es un subespacio vectorial de un álgebra cerrado para
el producto.

**** 1.3.a. Álgebra conmutativa
Un álgebra es *conmutativa* si $ab = ba$.

**** 1.3.b. Centro de un álgebra
Se define el *centro* de un álgebra asociativa como:

\[
Z(A) = \{c \in A \mid ac = ca,\; \forall a \in A \}
\]

**** 1.4. Ideal de un álgebra
Un subespacio vectorial de álgebra, $I \subseteq A$ es *ideal* si el producto por
cualquier elemento está en el ideal $ai,ia \in I$.

**** 1.5. Cociente por un ideal
Sobre el K-espacio vectorial cociente por un ideal $A/I$, podemos definir
una K-álgebra mediante $(a+I)(b+I) = ab+I$.

***** Buena definición
Supongamos que $a+I = a'+I$ y que $b+I = b'+I$, entonces tenemos 
que:

\[
ab- a'b' = a(b-b') - (a-a')b' \in I
\]

**** 1.6. Homomorfismos de K-álgebras
Una aplicación lineal entre álgebras $f : A \longrightarrow A'$ es homomorfismo de
K-álgebras si respeta el producto:

\[
f(ab) = f(a)f(b)
\]

***** Isomorfismo de K-álgebras
Cuando un homormofismo de K-álgebras es biyectivo, se llama *isomorfismo*
y su inversa es también homomorfismo de K-álgebras.

**** 1.7. Primer teorema de isomorfía
Si $f : A \longrightarrow A'$ es homomorfismo de K-álgebras, $\mathrm{Im} f$ es subálgebra y $\ker f$
es ideal. Además, tenemos un isomorfismo de K-álgebras canónico:

\[
\widehat f : A/\ker f \longrightarrow \im f
\]

dado por $\widehat f(a+\ker f) = f(a)$.

***** Demostración
****** La imagen es subálgebra
Trivialmente, la imagen es espacio vectorial y $f(a)f(b) = f(ab)$.

****** El núcleo es un ideal
El núcleo es subespacio vectorial y además,

\[
f(ak) = f(a)f(k) = 0 = f(k)f(b) = f(kb)
\]

para cualquier $f(k) = 0$.

****** Isomorfismo de álgebras
Comprobamos que está bien definido, ya que si $a + \ker f = b + \ker f$,
se tiene que $\widehat f(a+\ker f) - \widehat f(b + \ker f) = f(a-b) = 0$.

La función es lineal y preserva el producto por la definición de
producto con la que hemos dotado al ideal. Ahora, comprobamos que
es inyectiva por tenerse:

\[
\widehat f(a+\ker f) = 
\widehat f(b+\ker f) \implies f(a-b) =
0 \implies a-b \in I
\]

Es trivialmente sobreyectiva.

**** 1.8.a. Álgebras unitales
Una K-álgebra asociativa es *unital* si existe un neutro para el
producto.

\[
1_Aa = a = a1_A; \quad 1_A \neq 0
\]

***** Homormofisos de álgebras unitales
A los homomorfismos de álgebras unitales se les pide respetar la
unidad. Para $f : A \to B$, $f(1_A) = 1_B$.

***** Asunción posterior
En el curso trabajaremos siempre con álgebras asociativas y unitales.

**** 1.9. Inclusión del cuerpo en el álgebra
Sea $A$ una K-álgebra, la inclusión $u : K \longrightarrow A$ es homomorfismo inyectivo
de K-álgebras. Como consecuencia $\im u \subseteq Z(A)$, y es una K-subálgebra.

***** Demostración
****** Es homomorfismo
La inclusión definida por $u(k) = k1_A$ es lineal por tenerse:

\[
u(\gamma\alpha+\beta) =
(\gamma\alpha+\beta)1 =
\gamma(\alpha 1) + \beta 1 =
\gamma u(\alpha) + u(\beta)
\]

Y además es multiplicativa:

\[
u(\alpha)u(\beta) = (\alpha 1)(\beta 1) = \alpha\beta 11 = u(\alpha\beta)
\]

Y trivialmente unital por $u(1) = 1$.

****** Es inyectivo
Si $u(k) = u(k')$ entonces $(k-k')1_A = 0$.

****** Es subálgebra del centro
Aplicando bilinealidad de la multiplicación:

\[u(\alpha) a = 
(\alpha 1)a = 
\alpha (1a) = 
\alpha (a1) = 
a(\alpha 1) =
au(\alpha)\]

*** 1.2. La representación regular. Unidades y divisores de cero
**** 1.11.a. Álgebra de endomorfismos
Los endomorfismos de un K-espacio vectorial forman una K-álgebra con la
composición:

\[
End_K(V) = \{ f : V \longrightarrow V \mid f \text{ es lineal}\}
\]

***** Demostración
La suma se define por $(f+g)(v) = f(v)+g(v)$, lo que da un grupo abeliano
con el neutro $0(v) = 0$; además, con $(\alpha f)(v) = \alpha f(v)$, nos da un espacio
vectorial.

Comprobamos además que la composición es bilineal:

  1. $((f+g)\circ h)(v) = f(h(v)) + g(h(v)) = (f\circ h + g\circ h)(v)$
  2. $(f\circ (g+h))(v) = f(g(v)) + f(h(v)) = (f\circ g + f\circ h)(v)$
  3. $(\alpha f \circ g)(v) = \alpha (f\circ g)(v)) = f(\alpha g(v)) = (f \circ \alpha g)(v)$

Donde en el primer y segundo punto usamos la definición de suma; y
en el tercer punto usamos la linealidad de la función para conmutar
el elemento del cuerpo y la aplicación de la función.

**** 1.11.b. Inclusión en los endomorfismos
Sea $A$ cualquier K-álgebra. La aplicación $\lambda : A \longrightarrow End_K(A)$ que asigna
a cada $a \in A$ la aplicación $\lambda_a : A \longrightarrow A$ definida por $\lambda_a(b) = ab$ para
todo $b \in A$ es un homomorfismo inyectivo de K-álgebras.

***** Caso finito
Toda K-álgebra de dimensión finita es isomorfa a una subálgebra de
matrices con coeficientes en $K$.

***** Demostración
****** Es homormorfismo
Por los axiomas de K-álgebra, $\lambda_a$ es siempre lineal. Además, la propia
$\lambda$ es lineal por tenerse:

\[
\lambda_{a+\alpha b}(c) = (a+\alpha b)c = ac + \alpha bc = 
\lambda_a(c) + \alpha\lambda_b(c) = (\lambda_a+\alpha\lambda_b)(c)
\]

Además, es multiplicativa por asociatividad:

\[
\lambda_{ab}(c) = (ab)c = a(bc) = \lambda_a \circ \lambda_b (c)
\]

****** Es inyectiva
Si $\lambda_a = 0$, se tiene $a = \lambda_a(1) = 0$.

**** Álgebra opuesta
El álgebra opuesta $A^{op}$ es la propia $A$ con el producto dado por:

\[
a \cdot b = ba
\]

**** Unidades y divisores de cero
Un $a \in A$ no nulo es *unidad* si existe $a^{-1} \in A$ tal que $aa^{-1} = 1 = a^{-1}a$.
El conjunto de las unidades, $U(A)$ forma un grupo con el producto.

***** Divisor de cero
Un $a \in A$ no nulo es *divisor de cero* si $\exists b: ab = 0$ ó $ba = 0$.

***** Clasificación en unidades y divisores de cero en dimensión finita
Sea $a \in A$ no nulo para $A$ k-álgebra de /dimensión finita/:

1. Equivalen:

   - $a \in U(A)$
   - $\exists b \in A : ab = 1$
   - $\exists c \in A : ca = 1$

2. Equivalen:

   - $a \notin U(A)$
   - $\exists b \in A: ab = 0$
   - $\exists c \in A : ca = 0$

Es decir, todo elemento no nulo es una unidad o un divisor de cero.

****** Demostración primer punto
Si $ab = 1$, $\lambda_a$ es sobreyectiva y $\lambda_b$ es inyectiva. Por ser de dimensión
finita ambas son isomorfismos. Se aplica sobre el álgebra opuesta para
llegar a la otra implicación.

****** Demostración segundo punto
Ssi $ab = 0$, $\lambda_a$ no es inyectiva, y por tanto no puede ser unidad.

***** Clasificación por el determinante
Si en un álgebra de dimensión finita tomamos la representación regular
$\lambda: A \to \mathrm{End}(A)$; podemos usar el determinante para decidir si $a \in A$ es
una unidad.

**** Álgebra de división
Un álgebra $A$ es un *álgebra de división* si $U(A) = A \setminus \{0\}$. Los cuerpos
son álgebras de división conmutativas.

*** 1.3. Representaciones y módulos
**** Representación
Una *representación* de un álgebra $A$ es un homomorfismo de k-álgebras
$\mu : A \longrightarrow End_K(V)$, donde $V$ es el k-espacio vectorial de representación.

***** Representación fiel
Se llama representación *fiel* cuando $\mu$ es inyectiva.

***** Representación regular
La inclusión en los endomorfismos $A \to \mathrm{End}(A)$ es una *representación fiel*
que llamamos representación regular.

**** Módulos de un álgebra
Dada $A$ álgebra, un A-módulo por la izquierda es un espacio vectorial $V$
con un producto bilineal $A \times V \to V$ cumpliendo $(ab)v = a(bv)$ y $1v = v$.

***** Submódulos
Llamamos *submódulo a izquierda* a un subconjunto $N$ de un módulo que 
sea subgrupo aditivo y que cumpla $an \in N$ para $n \in N$. Los submódulos
de un álgebra se llaman *ideales a izquierda*.

***** Retículo de submódulos
Llamamos ${\cal L}(M)$ a la familia de submódulos de $A$. Forman un retículo bajo
la suma y la intersección.

***** Submódulo generado
El submódulo generado por un conjunto de elementos es el menor submódulo
que los contiene.

**** Equivalencia de módulos y representaciones
Sean $A$ una k-álgebra y $V$ un k-espacio vectorial. Hay una biyección
entre el conjunto de representaciones de $A$ sobre $V$ y los A-módulos
por la izquierda sobre $V$.

***** Demostración
Si tenemos una representación $\mu\colon A \to \mathrm{End}(V)$, definimos el A-módulo
dado por $av = \mu(a)(v)$. Si tenemos una estructura de A-módulo podemos
construir la representación $\mu(a)(v) = av$.

**** Suma directa de módulos
Llamamos *suma directa* de los módulos $M_1,\dots,M_n$ al módulo sobre su
producto cartesiano con las operaciones

 * $(m_1,\dots,m_n) + (m_1',\dots,m_n') = (m_1+m_1',\dots,m_n+m_n')$
 * $a(m_1,\dots,m_n) = (am_1,\dots,am_n)$

**** Teorema de Cayley-Hamilton
Todo endomorfismo de un espacio vectorial de dimensión finita satisface
su ecuación característica.

***** Demostración
Sea $T$ un endomorfismo en un espacio $V$ con base $\{v_1,\dots,v_n\}$, definido por
la matriz siguiente

\[C =\begin{pmatrix}
a_{11} & a_{12} & \dots \\
a_{21} & a_{22} & \dots \\
\vdots & \vdots & \ddots \\
\end{pmatrix}.
\]

Si consideramos la matriz $\Delta = (TI_n - C)^t$ en $K[X]$, tenemos que

\[\Delta\begin{pmatrix}
v_1 \\ v_2 \\ \vdots \\ v_n
\end{pmatrix} = \begin{pmatrix}
Tv_1 - \sum_{j=1}^n a_{j1}v_j \\
Tv_2 - \sum_{j=1}^n a_{j2}v_j \\
\vdots \\
Tv_n - \sum_{j=1}^n a_{jn}v_j  
\end{pmatrix} = \begin{pmatrix}
0 \\ 0 \\ \vdots \\ 0
\end{pmatrix}.
\]

Multiplicando ahora por su matriz adjunta, se tiene que

\[
\widetilde \Delta\Delta\begin{pmatrix}
v_1 \\ v_2 \\ \vdots \\ v_n
\end{pmatrix} = \begin{pmatrix}
\mathrm{det}(\Delta)v_1 \\ \mathrm{det}(\Delta)v_2 \\ \vdots \\ \mathrm{det}(\Delta)v_n
\end{pmatrix} = \begin{pmatrix}
0 \\ 0 \\ \vdots \\ 0
\end{pmatrix}.
\]

Luego, por ser una base, $\mathrm{det}(\Delta)v = 0$ para cualquier $v \in V$. Tenemos
entonces que $T$ satisface la ecuación polinómica

\[ \mathrm{det}(TI_n - C) = \mathrm{det}(\Delta^t) = \mathrm{det}(\Delta) = 0.
\]

**** Submódulo finitamente generado
Un $A\text{-módulo}$ $M$ es *finitamente generado* si existe $X \subseteq M$ subconjunto
finito que lo genera, $M = RX$.

***** Submódulo cíclico
Un módulo generado por un elemento se llama *cíclico*.

**** Suma de módulos
Dados submódulos $N_1,\dots,N_m \leq M$, su suma es el menor submódulo que contiene
a todos ellos.

***** Caracterización de la suma
Sea $M$ un $A\text{-módulo}$,

 1. Dados submódulos $N_1,\dots,N_m$ de $M$, tenemos que

    \[
    N_1+\dots+N_m = \left\{ n_1+\dots+n_m \mid n_i \in N_i \right\}.
    \]

 2. Dado $X = \{m_1,\dots,m_n\} \subseteq M$, tenemos que $RX= Rm_1 + \dots + Rm_{n}$.

****** Demostración
Comprobamos que un módulo que los contenga debe contener a todos
los elementos de esa forma, además, forman un módulo, así que es
el menor.

**** Homomorfismo de módulos
Un aplicación entre $A\text{-módulos}$ $f\colon M \to N$ es *homomorfismo de módulos*
si $f(am) = af(m)$ para $a \in A, m \in M$.

**** Cociente de módulos
Sea $L < M$ un submódulo. El cociente $M/L$ tiene estructura de módulo con

\[a(m+L) = am+L
\]

y la suma inducida en el cociente.

**** Primer teorema de isomorfía para módulos
Para $f\colon M \to N$ homomorfismo de módulos, $\mathrm{ker}(f)$ e $\mathrm{im}(f)$ son submódulos
y hay un isomorfismo $\widehat f\colon M/ \mathrm{ker}(f) \to \mathrm{im}(f)$ dado por

\[
\widehat f(m+ \mathrm{ker}(f)) = f(m)
\]

***** Demostración
Aplicamos primero el primer teorema de isomorfía en grupos. Y comprobamos
que además $\widehat f$ es $A\text{-lineal}$ por ser $f$ isomorfismo de módulos.

**** Bases y módulos libres
Un conjunto de generadores de un $A\text{-módulo}$ $M$ es *base* si cada $m \in M$
se escribe únicamente como

\[
m = \sum_{i=1}^n a_im_i
\]

***** Módulo libre
Un módulo que admite una base se llama *módulo libre*. Un ejemplo de
módulo libre es $A^n$.

**** Caracterización de bases
Un subconjunto $B \subseteq M$ no vacío finito es base si, y sólo si, para 
cualquier aplicación $f\colon B \to N$ existe un único homomorfismo de
$R\text{-módulos}$ $\overline{f} \colon M \to N$ con $\overline{f}_{|B} = f$.

\[\begin{tikzcd}
B \rar[hook]\drar[dashed, swap]{\exists! \overline{f}} & M \dar{f}\\
  & N
\end{tikzcd}\]

***** TODO Demostración

**** Caracterización de finitamente generados
Para $M$ un $A\text{-módulo}$,

 1. Si $M$ admite un conjunto de generadores $\left\{ m_1,\dots,m_n \right\}$, entonces
    $M \cong A^n/L$ para cierto submódulo $L$.
 2. Si $M$ es libre con base $\left\{ m_1,\dots,m_n \right\}$, entonces $M \cong A^n$.

***** TODO Demostración

**** Segundo teorema de isomorfía para módulos
Sean $L,N \in {\cal L}(M)$ submódulos. Existe un isomorfismo

\[
\frac{L+N}{L} \cong \frac{N}{L \cap N}.
\]

***** Demostración
Aplicamos el primer teorema de isomorfía a la función 

\[
f\colon N \to \frac{L+N}{L}
\]

dada por $f(n) = n+L$. Es sobreyectiva y tiene como núcleo a $L \cap N$.

**** Tercer teorema de isomorfía para módulos
Sean $L \subseteq N \in {\cal L}(M)$. Existe un isomorfismo

\[
\frac{M/L}{N/L}\cong \frac{M}{N}
\]

Además, hay una biyección creciente entre submódulos de $M$ conteniendo
a $L$ y ${\cal L}(M/L)$.

***** Demostración
Aplicamos priemr teorema de isomorfía a la aplicación

\[
f \colon M/L \to N/L
\]

dada por $f(m+L) = m+N$.

*** 1.4. Módulos simples. Teorema de Jordan-Hölder
**** Módulo simple
Un módulo $M$ se dice simple si no tiene submódulos propios.

**** Submódulo maximal
Un submódulo propio $N < M$ es *maximal* si lo es en ${\cal L}(M)$.

***** Caracterización por simplicidad
Por tercer teorema de isomorfía, esto equivale a que $M/N$ es simple.

**** Serie de composición
Una cadena de submódulos $0 \subset M_1 \subset M_2 \subset \dots \subset M$ es una *serie de composición*
de $M$ si cada $M_{i-1}$ es maximal en $M_i$.

**** Teorema de Jordan-Hölder
Sea $M$ un $A$ módulo de /dimensión finita/ como $K$ espacio vectorial con
dos series de composición:

\[0 = M_0 \subset M_1 \subset\dots\subset M_n = M\]
\[0 = N_0 \subset N_1 \subset\dots\subset N_m = M\]

Entonces $n=m$ y existe una permutación con $M_i/M_{i-1} \cong N_{\sigma(i)}/N_{\sigma(i)-1}$.

***** Factores de composición
Los módulos $M_i/M_{i-1}$ se llaman *factores de composición* de $M$ y están
únicamente determinados salvo isomorfismo y reordenación.

***** Demostración
Usaremos inducción sobre $n$. En el caso $n=1$, $M$ es simple y no tiene
submódulos propios, luego todas sus series de composición son la misma.
En otro caso, no es simple y $n,m>1$.

****** Caso 1
Si $M_{n-1}=N_{n-1}$, aplicamos a ambos la hipótesis de inducción y
ampliamos la permutación obtenida.

****** Caso 2
Si $M_{n-1} \neq N_{n-1}$, $M_{n-1}+N_{m-1} = M$ por maximalidad, y su intersección
tiene una serie de composición

\[
0 \subset L_1 \subset \dots \subset L_{k-1} \subset N_{m-1} \cap M_{n-1}
\]

que además puede extenderse de dos formas a $M_{n-1}$ y $N_{m-1}$, sabiendo por 
segundo teorema de isomorfía que

\[
\frac{M_{n-1}}{N_{m-1}\cap M_{n-1}} \cong \frac{M}{N_{m-1}}
\quad\text{ y que }\quad
\frac{N_{n-1}}{N_{m-1}\cap M_{n-1}} \cong \frac{M}{M_{m-1}}
\]

son simples. Aplicando la hipótesis de inducción dos veces, tenemos
dos permutaciones que nos dan

\[
L_i/L_{i-1} \cong M_{\tau i}/M_{\tau i - 1}
\quad\text{ y que }\quad
L_i/L_{i-1} \cong N_{\sigma i}/M_{\sigma i - 1}.
\]

Combinándolas tenemos lo pedido.

**** Longitud de un módulo
El número de factores de composición es la *longitud* del módulo $\ell(M)$.

**** Longitud y cociente
Si $M$ es de dimensión finita y $N \in {\cal L}(M)$. Entonces $\ell(M)=\ell(N)+\ell(M/N)$.

***** Demostración
Si tenemos series de composición

\[
0 \subset N_1 \subset N_2 \subset \dots \subset N
\qquad
\frac{N}{N} \subset \frac{M_1}{N} \subset \dots \subset \frac{M}{N}
\]

podemos aplicar el tercer teorema de isomorfía para tener
$M_j/M_{j-1} \cong \frac{M_j/N}{M_{j-1}/N}$ simple, y por tanto, una serie de composición

\[
0 \subset N_1 \subset \dots \subset N \subset M_1 \subset \dots \subset M.
\]

Como consecuencia, $\ell(M)=\ell(N)+\ell(M/N)$.

**** Longitud, suma e intersección
Sea $M$ un módulo dimensión finita con $N,L \in {\cal L}(M)$. Entonces:

\[\ell(N+L) + \ell(N\cap L) = \ell(N)+\ell(L)\]

***** Demostración
Aplicamos el [[*Segundo teorema de isomorfía para módulos][segundo teorema de isomorfía]] y la [[*Longitud y cociente][longitud de un cociente]]
para tener

\[
\frac{L+N}{L} \cong \frac{N}{L \cap N},
\]

y por tanto $\ell(L+N) - \ell(L) = \ell(N) - \ell(L \cap N)$.

*** 1.5. Independencia lineal y sumas directas internas
**** Familia independiente
Una familia $\{N_i \mid i \in I\} \subset {\cal L}(M)$ es *independiente* si se verifica:

\[
N_j \cap \sum_{j\neq i} N_i = \{0\}
\]

**** Suma directa interna
Dada una familia independiente, $\sum_{i\in I} N_i \subset M$ se llama *suma directa interna*.

**** Suma directa externa e interna
Existe un único homomorfismo de módulos $\theta : \bigoplus_{i\in I} N_i \to \sum_{i\in I} N_i$, tal que
$\theta\iota_i(m) = m$ para cualquier $m \in N_i$.

***** Demostración
Extendiendo por linealidad la condición, el único homomorfismo posible es:

\[
\theta((m_i)_{i \in I}) = \sum_{i \in I} m_i
\]

**** Caracterización de familia independiente
Equivalen:

 1. La familia $\{N_i\mid i\in I\}$ es independiente.
 2. Toda subfamilia /finita/ $F \subset \{N_i\mid i\in I\}$ es independiente.
 3. La expresión de cada $m = \sum_{i\in I} m_i$ con $m_i\in N_i$ es única.
 4. Si $0 = \sum_{i\in I} m_i$, entonces $m_i = 0$.
 5. El homomorfismo canónico $\theta : \bigoplus_{i\in I} N_i \to \sum_{i\in I} N_i$ es inyectivo e isomorfismo.
 6. Para $J_1,J_2 \subset I$ con $J_1\cap J_2 = \varnothing$ se tiene $\sum_{i\in J_1} N_i \cap \sum_{i\in J_2} N_i = \{0\}$.

En este caso, notaremos la suma directa interna también por $\bigoplus_{i \in I} N_i$.

***** Demostración
****** Implicación 1 a 2
Trivial por definición de independencia.

****** Implicación 2 a 3
Esto equivale a que cada $\sum_{i \in I} m_i = 0$ lleva a $m_i = 0$. Pero si hubiera
algún $m_j$ no nulo, sería $m_j = - \sum_{i \in I, i\neq j} m_i$, contraviniendo independencia.

****** Implicación 3 a 4
Trivial por la unicidad.

****** Implicación 4 a 5
Desde lo anterior, se tiene que tiene núcleo trivial y por tanto es
inyectivo. Además, es sobreyectivo porque genera trivialmente todos los
elementos de $\sum N_i$. Es por tanto una biyección e isomorfismo.

****** Implicación 5 a 6
Si no fuera así, existirían subconjuntos $J_1,J_2$ cumpliendo:

\[
\sum_{i \in J_1} m_i = \sum_{i \in J_2} n_i
\]

Nótese que entonces la función $\theta$ daría la misma imagen para ambos
subconjuntos, contraviniendo inyectividad.

****** Implicación 6 a 1
Trivial por el caso de $J_2$ con un elemento.

**** Ampliar familia independiente
Sea $\{N_i \mid i\in I\} \subset {\cal L}(M)$ es familia independiente y tenemos:

\[
N \cap \bigoplus_{i\in I} N_i = \{0\}
\]

Entonces, $\{N_i \mid i \in I\} \cup \{N\}$ es independiente.

***** Demostración
Si $n + \sum n_i = 0$, tenemos $n \in \bigoplus N_i \cap N$ y, por tanto, $n = 0$. Por 
independencia de la familia $\sum n_i = 0$, se llega a $n_i = 0$.

**** Suma directa en suma de simples
Sea $N \subset \sum_{i\in I} M_i$ suma de submódulos simples. Existe $\{M_i \mid i \in J \subseteq I\} \cup \{N\}$ 
independiente con:

\[
N \oplus \left( 
\bigoplus_{i \in J} M_i
\right) = \sum_{i \in I} M_i
\]

***** Demostración
Tomamos el conjunto $\Gamma$ de los subconjuntos $J \subseteq I$ tales que $\{M_i \mid i \in J\} \cup \{N\}$
es independiente. Veamos que es no vacío. Si para todo $N \cap M_i \neq 0$, 
debe tenerse por simplicidad $M_i \subset N$ y por tanto $\sum M_i \subset N$. Así, debe
existir algún $M_i$ para el que $N \cap M_i = 0$.

Tomamos el maximal $J$. Para cualquier índice $i \in I -J$, se tiene entonces
por maximalidad que $M_i \cap (N + \bigoplus_{j \in J} M_j) \neq 0$, pero eso implica por simplicidad
que $M_i \subseteq N + \bigoplus_{j\in J} M_j$.

**** Existencia de base para espacio vectorial finitamente generado
Sea $_DV$ espacio vectorial izquierdo sobre el anillo de división $D$.
Para todo sistema de generadores no nulos $\{v_i\mid i\in I\}$ de $V$ existe un 
subconjunto tal que $V = \bigoplus_{j\in J} Dv_j$.

Todo espacio vectorial finitamente generado sobre $D$ tiene una base.

***** Demostración
Un anillo de división es simple. Como $Dv_j \cong D$, tenemos que es un 
espacio suma de simples, luego [[*Suma directa en suma de simples][existe un conjunto]] de independientes que
genera el espacio.

*** 1.6. Independencia en familias infinitas
**** Suma directa externa infinita
Se define la *suma directa externa* $\bigoplus_{i\in I} N_i$ como el subconjunto del producto
cartesiano formado por las tuplas con un número finito de valores no nulos.

*** 1.7. Clasificación de las álgebras de división reales de dimensión finita
**** Determinante, traza, polinomio característico y mínimo
Dada $a \in D$ en un álgebra de división sobre $k$, consideramos su *traza*,
su *determinante*, su *polinomio característico* y su *polinomio mínimo*
como los del endomorfismo lineal multiplicación, $\lambda_a \colon D \to D$.

**** Lema de clasificación de álgebras de división
Sea $D$ álgebra real de dimensión finita mayor que $1$. Entonces:

\[
V = \{a \in D : a^2 \leq 0\} = \{a\in D\mid tr(a) = 0\}
\]

Luego es un subespacio vectorial con $D = \mathbb{R} \oplus V$. Además, la dimensión real
de $D$ es par.

***** Demostración
Llamamos $n = \mathrm{dim}_{\mathbb{R}}(D)$ y dado $a \in D$ consideramos su polinomio 
característico

\[
p(X) = (X-r_1)\dots (X-r_k)q_1(X)\dots q_m(X)
\]

descompuesto en factores lineales y cuadráticos. Por Cayley-Hamilton,
tenemos que $p(a) = 0$, luego debe anularse algún polinomio,

  * si $(a-r_i) = 0$ entonces $a \in \mathbb{R}$, y si $a^2 \leq 0$, nos da $a = 0$.
  * si $a \in D \setminus \mathbb{R}$, tendremos algún $q_j(a) = 0$ como polinomio mínimo de $a$.

Por Ejercicio 18 tenemos $p = q^t$, con $2t=n$ en este caso. Por irreducibilidad
se tiene $q = (X-z)(X-\overline{z})$ para algún complejo, así que

\[\begin{aligned}
q(X) &= X^2 - 2 \mathrm{Re}(z) X + |z|^2 \\
p(X) &= X^{2t} - 2 \mathrm{Re}(z)t X^{2t-1} + \dots \\
p(X) &= X^{2t} - \mathrm{tr}(a) X^{2t-1} + \dots \\
\end{aligned}
\]

desde el desarrollo de $q$ y la definición de la traza como coeficiente del
polinomio característico.

Sustituyendo en la primera ecuación desde la última tenemos que

\[
a^2 - \frac{\mathrm{tr}(a)}{t}a + |z|^2 = 0,
\]

y que por tanto $a^2 \in \mathbb{R}^-$ si y sólo si $\mathrm{tr}(a) = 0$.

**** Teorema de Frobenius
Sea $D$ álgebra de división real de dimensión finita. Entonces $D$ es isomorfa
a $\mathbb{R}$, $\mathbb{C}$, o $\mathbb{H}$.

***** Demostración
Si $D \not\cong \mathbb{R}$, aplicamos el [[*Lema de clasificación de álgebras de división][lema de clasificación]] para tener $D$ de dimensión
par con $D = \mathbb{R}\oplus V$. Consideramos

\[
B(a,b) = \frac{ab+ba}{2}
= \frac{1}{2}\left( (a+b)^2-a^2-b^2 \right) \in \mathbb{R},
\]

una forma bilineal simétrica definida negativa. Podemos diagonalizarla
para obtener una base donde $B(e_i,e_j) = 0$ si $i\neq j$ y $B(e_i,e_i) = -1$, es decir,
por definición de $B$,

\[
e_i^2 = -1
\quad\text{ y }\quad
e_ie_j = -e_je_i.
\]

En el caso $t=1$, tenemos $\mathbb{C}$. En el caso $t>1$, tenemos además la restricción
de que si tomamos $u = e_1e_2e_j$, se cumple

\[
u^2 = -e_1e_2e_1e_je_2e_j = 1,
\]

luego $0 = (u-1)(u+1)$ en un anillo de división nos da $e_j = \pm e_1e_2$, así que
debe tenerse $t=2$, con base $\left\{ 1,e_1,e_2,e_1e_2 \right\}$. En este caso, se comprueba que
hay un isomorfismo $\mathbb{H} \cong D$.

**** Corolario de Frobenius
La única álgebra de división compleja de dimensión finita es $\mathbb{C}$.

***** Demostración
Nótese que en particular sería un álgebra de división real y no podría
ser $\mathbb{H}$ porque no tiene a los complejos como centro.

*** 1.8. Idempotentes y anillos de matrices
**** Idempotente
Un elemento de un álgebra $e \in R$ se llama *idempotente* si $e^2 = e$.
Son idempotentes triviales $0$ y $1$.

**** Conjunto completo de idempotentes ortogonales (CCIO)
Un conjunto de idempotentes no triviales $\{e_1,\dots,e_n\}$ es conjunto completo de
idempotentes ortogonales si:

\[
1 = e_1 + \dots + e_n
\]

Y además, $e_ie_j = 0$ para $i \neq j$.

**** Descomposición de un CCIO
Sea $\{e_1,\dots,e_n\}$ un CCIO para $R$. Entonces $R = Re_1 \oplus \dots \oplus Re_n$.

***** Demostración
Cualquier elemento de $R$ se expresa como:

\[
r = r(e_1+e_2+\dots+e_n)
\]

Y la suma es directa porque si se tiene $x \in Re_j \cap \left(\sum_{i\neq j} Re_i \right)$, entonces:

\[
x = xe_j = \left(\sum_{i\neq j} xe_i\right)e_j = 0
\]

**** Descomposición en un CCIO
Sea $R = I_1 \oplus \dots \oplus I_n$ descomposición por ideales a izquierda no triviales.
Entonces, si $1 = e_1 + \dots + e_n$, para $e_i\in I_i$, $\{e_1,\dots,e_n\}$ forman un CCIO 
con $I_i = Re_i$.

***** Demostración
Si $x \in I_j$, $x = x\sum e_i$ y se tiene,

\[x - xe_j = 
\sum_{i\neq j} xe_i \in I_j \cap \left(\sum_{i\neq j} I_i\right) = 
\{0\}.\]

Así, hemos demostrado que

\[
I_j = \{ x \in R \mid xe_j = x\} = Re_i
\]

y que por tanto, $e_i^2 = e_i$. Por eso se tiene $\sum_{i\neq j} e_ie_j = 0$ y por independencia
lineal, se llega a $e_ie_j = 0$.

**** Matrices de descomposición
Llamamos al conjunto de matrices siguiente,

\[
Mat(e_iRe_j) = \left\{(r_{ij}) \mid r_{ij} \in e_iRe_j\right\}
\]

que es un subespacio vectorial multiplicativamente cerrado de $M_n(R)$. La
matriz diagonal

\[\begin{pmatrix}
e_1 & 0 & \dots & 0\\
0 & e_2 & \dots & 0 \\
\vdots & & & \vdots \\
0 & 0 & \dots & e_n
\end{pmatrix}
\]

es elemento neutro multiplicativo.

***** Demostración
Se comprueba trivialmente por tenerse:

\[
(e_ire_k)(e_kr'e_j) = e_i(re_kr')e_j \in e_iRe_j
\]

Multiplicando se comprueba además que la diagonal es la unidad
multiplicativa.

**** Descomposición en matrices
La aplicación $\phi \colon R \to Mat(e_iRe_j)$ dada por $\phi(r) = (e_ire_j)_{ij}$ es un isomorfismo
de K-álgebras.

***** Demostración
****** Es homomorfismo de álgebras
Por definición es lineal. Si calculamos la componente $(i,j)$ de
$\phi(r)\phi(s)$, tenemos

\[
\sum_k e_ire_ke_kse_j =
\sum_k e_ire_kse_j =
e_ir \left(\sum_k e_k\right) se_j =
e_irse_j
\]

que es la componente $(i,j)$ de $\phi(rs)$. Además, $\phi(1)$ es claramente la unidad.

****** Es isomorfismo
Supongamos que $\phi(r)=0$, entonces se tiene

\[
r = \left(\sum_i e_i\right)r \left( \sum_{j} e_{j} \right)
= \sum_{i,j} e_{i}re_{j} = 0
\]

y la función es inyectiva. Para comprobar que es sobreyectiva, simplemente
tomamos una matriz $(r_{ij})$ de la forma, y comprobamos que por ortogonalidad
e idempotencia se tiene

\[
\phi \left( \sum_{i,j} r_{ij} \right) = (r_{ij})
\]

**** Descomposición de endomorfismos
Sea $M = M_1 \oplus M_2 \oplus \dots \oplus M_n$ un A-módulo con $M_i \cong N$. Se tiene

\[
\mathrm{End}(M) = M_n(\mathrm{End}(N)).
\]

***** TODO Demostración

**** Descomposición en ideales biláteros
Sea $R = I_1\oplus I_2\oplus \dots \oplus I_n$ descompuesto en ideales biláteros. Sea $\left\{ e_1,\dots,e_n \right\}$
su CCIO asociado. Entonces $e_i \in Z(R)$, idempotente central.

**** Descomposición en álgebras
Sea $\{e_1,\dots,e_n\}$ un CCIO centrales de $R$. Entonces $Re_i$ es un álgebra con unidad
y tenemos un isomorfismo de álgebras $R \cong Re_1\times Re_2 \times \dots \times Re_n$ definido
por $r \mapsto (re_1,\dots,re_n)$.

**** Idempotente central primitivo
Un idempotente central es *primitivo* si $Re$ no es suma directa de dos ideales
propios de $R$.

**** Descomposión en centrales primitivos
Si $R$ tiene un CCIO centrales primitivos, este conjunto es único.

***** TODO Demostración

*** 1.9. El álgebra de enfomorfismos de un módulo semisimple
**** Complemento
Para $N \subseteq M$ submódulo, un *complemento* de $N$ es un $X$ tal que

\[
M = N \oplus X.
\]

En caso de que tenga complemento lo llamamos *sumando directo*.

**** Módulos semisimples
Un módulo de dimensión finita se dice *semisimple* si todo submódulo
es un sumando directo.

**** Caracterización de semisimples
Sea $M$ módulo con dimensión finita como K-espacio vectorial. Equivalen:

  1) $M$ es semisimple.
  2) $M$ es suma directa finita de submódulos simples.
  3) $M$ es suma finita de submódulos simples.

***** Demostración
****** Primera implicación
Tomamos una familia maximal de submódulos simples linealmente
independientes. Si el complemento de su suma no fuera nulo, entonces
contendría algún submódulo simple (por finitud) que sería linealmente
independiente, contraviniendo maximalidad.

****** Segunda implicación
Trivial.

****** Tercera implicación
Trivial porque podemos tomar [[*Suma directa en suma de simples][suma directa en suma de simples]] para
encontrar el complemento.

**** Lema de Schur
Sean $M,M'$ simples con $f\colon M \to M'$ homomorfismo de módulos. Se tiene $f=0$
o $f$ isomorfismo.

***** Corolario: anillo de endomorfismos de un módulo simple
El anillo de los endomorfismos de un módulo simple es un anillo de
división.

***** Demostración
Si no es nula, el núcleo es un submódulo propio, luego debe ser inyectiva.
La imagen entonces será un submódulo propio no nulo y será sobreyectiva.

**** Submódulos y cocientes de semisimples
Si $M$ es un semisimple de dimensión finita, entonces todo submódulo de $M$
y todo cociente de $M$ es semisimple.

***** Demostración
Si existe un epimorfismo de módulos $M \to N$, se tiene $N$ semisimple.
Cualquier cociente tendrá la proyección como epimorfismo hacia él y
cualquier submódulo $N \subseteq M$ será cociente por su complemento como

\[
\frac{M}{X} =
\frac{N \oplus X}{X} \cong
\frac{N}{N \cap X} \cong N.
\]

****** El epimorfismo da la semisimplicidad
Por [[*Lema de Schur][Lema de Schur]], se tiene que la imagen de un simple será simple o
nula. Así, podemos escribir

\[
N = \sum_{i\in I} f(M_i)
\]

y tendremos que es suma de simples y por [[*Caracterización de semisimples][caracterización]], semisimple.

**** Unicidad de la descomposición en simples
Sea $M = M_1\oplus \dots \oplus M_n = N_1 \oplus \dots \oplus N_m$ semisimple descompuesto como suma
directa de simples. Entonces $n=m$ y se tiene $M_i \cong N_{\sigma i}$ para alguna 
permutación.

***** Demostración
Tenemos dos series de composición

\[\begin{aligned}
\left\{ 0 \right\} &= M_0 \subset
M_1 \subset 
M_1 \oplus M_2 \subset 
&\dots& \subset
M_1 \oplus \dots \oplus M_n &= M \\
\left\{ 0 \right\} &= N_0 \subset
N_1 \subset 
N_1 \oplus N_2 \subset 
&\dots& \subset
N_1 \oplus \dots \oplus N_n &= M \\
\end{aligned}\]

en las que los factores son simples, explícitamente por segundo
teorema de isomorfía,

\[
\frac{M_j \oplus \dots \oplus M_0}{M_{j-1}\oplus \dots\oplus M_0} \cong
\frac{M_j}{(M_{j-1} \oplus \dots \oplus M_0) \cap M_j} \cong M_j.
\]

Pero aplicando [[*Teorema de Jordan-Hölder][Jordan-Hölder]], $M_j \cong N_{\sigma j}$.

**** Componentes isotópicas de un módulo
Sea $M = M_1\oplus \dots \oplus M_n$ descomposición finita en módulos simples. Podemos
escoger módulos simples $\Sigma_1,\dots,\Sigma_t$ y una partición $\{1,\dots,n\} = \Lambda_1 \cup \dots \cup \Lambda_t$
tal que $M_i \cong \Sigma_j$ si y sólo si $i \in \Lambda_j$.

Podemos tomar $M_{\Lambda_j} = \bigoplus_{i\in \Lambda_j} M_i$ para descomponer en *componentes isotópicas*

\[
M = M_{\Lambda_1}\oplus \dots \oplus M_{\Lambda_t}
\]

y llamar a $n_j$ la *multiplicidad* $\Sigma_j$ en $M$. Las componentes con su multiplicidad
son invarriantes llamados *estructura del módulo*.

**** Estructura de los endomorfismos
Sea $M$ con estructura $(\Sigma_1,n_1),\dots,(\Sigma_t,n_t)$ entonces $\Delta_j= \mathrm{End}(\Sigma_j)$ es una
$K\text{-álgebra}$ de dimensión finita y hay un isomorfismo

\[ \mathrm{End}(M) \cong
\mathrm{M}_{n_1}(\Delta_1) \times \dots \times \mathrm{M}_{n_t}(\Delta_t)
\]

***** TODO Demostración
*** 1.10. Álgebras semisimples de dimensión finita
**** Álgebras semisimples
Un álgebra $A$ de dimensión finita es *semisimple* si todo A-módulo de
dimensión finita es semisimple.

**** Caracterización de álgebras semisimples
Un álgebra de dimensión finita es semisimple si y sólo si es semisimple
como A-módulo.

***** Demostración
Si $M$ es un módulo finito-dimensional, es el cociente de un libre $A^n$.
Como $A^n$ es semisimple por serlo $A$, su [[*Submódulos y cocientes de semisimples][cociente]] $M$ es semisimple.

**** Estructura de los módulos de un álgebra semisimple
Sea $A$ es un álgebra semisimple con estructura $(n_1,\Sigma_1),\dots,(n_t,\Sigma_t)$ como
$A\text{-módulo}$, entonces todo $A\text{-módulo}$ finito tiene estructura $(m_1,\Sigma_1),\dots,(m_t,\Sigma_t)$
para algunos $m_1,\dots,m_t$. En particular, todo $A\text{-módulo}$ simple es isomorfo a 
un $\Sigma_j$.

***** Demostración
Los módulos de dimensión finita son cocientes de $A^n$, y la estructura de
$A^n$ es simplemente $(nn_1,\Sigma_1),\dots,(nn_t,\Sigma_t)$, y sabemos que la estructura de los
submódulos y de los cocientes es la misma con coeficientes menores.

**** Álgebra de matrices sobre anillo de división es semisimple
Dada $\Delta$ álgebra de división finito-dimensional, $M_n(\Delta)$ es un álgebra 
semisimple con estructura $(n, \Sigma)$ para $\Delta \cong \mathrm{End}(\Sigma)^{op}$. Además, $M_n(\Delta)^{op} \cong M_n(\Delta^{op})$.

***** Demostración
****** El álgebra de matrices es semisimple
Tomamos $A_j$ el ideal izquierda de $M_n(\Delta)$ con base $\left\{ E_{1j},\dots,E_{nj} \right\}$.
Comprobamos que es simple, ya que cualquiera de sus elementos no
nulos genera $M_n(\Delta)E_{jj}$, por ser $\Delta$ anillo de división.

Así, vemos que $M_n(\Delta)$ es semisimple por ser

\[ M_n(\Delta) = A_1 \oplus \dots \oplus A_n. \]

****** Estructura unimodular
Veamos que existe un isomorfismo de módulos $A_1 \cong A_j$, explícitamente

\[
f(a_1E_{11}+\dots +a_nE_{n1}) = a_1 E_{1j} + \dots + a_n E_{nj}
\]

es trivialmente isomorfismo de espacios vectoriales y se comprueba que
es homomorfismo de módulos por tenerse

\[
f\left(\left( \sum_{}  \right)\right)
\]

**** Teorema de Wedderburn
Una $K\text{-álgebra}$ de dimensión finita es semisimple ssi es isomorfa a un
álgebra de la forma

\[ \mathrm{M}_{n_1}(\Delta_1) \times \dots \times \mathrm{M}_{n_t}(\Delta_t).
\]

de forma única para algunas $\Delta_1,\dots,\Delta_t$ álgebras de división de dimensión
finita. Además, esta factorización es esencialmente única.

***** TODO Demostración

**** Centro de álgebra semisimple de dimensión finita
Si $A$ es semisimple de dimensión finita, $Z(A)$ es producto finito de cuerpos
extensión finita de $k$. El número de factores es el número de $A\text{-módulos}$ simples
no isomorfos en la estructura de $A$.

***** TODO Demostración
**** Semisimplicidad del álgebra opuesta
Si $A$ es semisimple, entonces $A^{op}$ es semisimple.

***** TODO Demostración

**** Teorema de Molien
Un álgebra compleja $A$ de dimensión finita es semisimple ssi es
isomorfa a exactamente una de la forma

\[ \mathrm{M}_{n_1}(\mathbb{C}) \times \dots \mathrm{M}_{n_t}(\mathbb{C})
\]

cumpliendo $\mathrm{dim}_{\mathbb{C}}(A) = n_1^2+\dots+n_t^2$.

** 2. Representaciones de grupos finitos
*** 2.1. Representaciones lineales de grupos finitos y módulos
**** Representación
Una *representación* $k\text{-lineal}$ de $G$ es un homomorfismo de grupos

\[\rho \colon G \to \mathrm{GL}(V).\]

***** Espacio de representación
Llamamos a $V$ /espacio de representación/ y a su dimensión la
/dimensión de la representación/. Consideraremos representaciones
de dimensión finita.

**** Álgebra de grupo
Para $G$ grupo finito y $k$ cuerpo, el /álgebra de grupo/ $kG$ se define
como el $k\text{-espacio}$ vectorial libre sobre $G$ con el producto dado por la
extensión bilineal del producto sobre $G$.

**** Relación entre representación y módulo del álgebra de grupo
La aplicación que asigna cada homomorfismo de álgebras $\Pi\colon kG \to \mathrm{End}_k(V)$
su restricción $\rho \colon G \to \mathrm{GL}(V)$ es una biyección a las representaciones.

Las representaciones $k\text{-lineales}$ de $G$ son las estructuras de $kG\text{-módulo}$
sobre $V$.

***** Demostración
Sabemos que cada homomorfismo $G \to \mathrm{GL}(V)$ extiende de manera única
por ser una base de $kG$ y extiende al producto por estar definido
precisamente por extensión. Cada aplicación restringe a $GL(V)$ por
ser los elementos de $G$ invertibles en $kG$ y es homomorfismo de
grupos.

**** Subespacio invariante
Un subespacio $W \leq V$ es $\rho\text{-invariante}$ si $\rho(g)(W) \leq W$ para cualquier $g \in G$.

/Equivalentemente, es un $kG\text{-módulo}$/.

**** Representación irreducible
Una representación no nula es irreducible si no tiene espacios invariantes
propios.

/Equivalentemente, el $kG\text{-módulo}$ es simple/.

*** 2.2. Representaciones completamente reducibles. Teorema de Maschke
**** 2.8. Representación completamente reducible
Una representación se llama *completamente reducible* si es nula
o el espacio de representación es suma directa de espacios irreducibles.

/Equivalentemente, el $kG\text{-módulo}$ es semisimple/.

**** 2.9. Teorema de Maschke
Sea $G$ grupo finito y $k$ cuerpo con $\mathrm{char}(k) \nmid |G|$. Toda representación aquí es
completamente reducible.

/Equivalentemente, $kG$ es un álgebra semisimple/.

***** Demostración
Dada $\varphi \colon V \to U$ $k\text{-lineal}$, definimos

\[
\widetilde \varphi(v) = \frac{1}{|G|}\sum_{g \in G}g \varphi(g^{-1}v),
\]

usando que $\mathrm{char}(k) \nmid |G|$, y es un homomorfismo de $kG\text{-módulos}$,

\[\begin{aligned}
\widetilde\varphi(hv) = 
\frac{1}{|G|}\sum_{g \in G}hh^{-1}g\varphi(g^{-1}hv) =
h \frac{1}{|G|} \sum_{k \in G} k \varphi(k^{-1}v) = h \widetilde\varphi(v).
\end{aligned}\]

Sea ahora $V$ un $kG\text{-módulo}$ con $W \leq V$. Consideramos $\pi\colon V \to V/W$, y
usando el complemento como espacio vectorial, creamos $\varphi\colon V/W \to V$
lineal con $\pi\circ\varphi = \mathrm{id}_{V/W}$ y tomamos la $\widetilde \varphi$. Tenemos entonces

\[
\pi(\widetilde\varphi(x)) =
\pi \left( \frac{1}{|G|}\sum_{g \in G}g\varphi(g^{-1}x) \right) =
\frac{1}{|G|} g\pi(\varphi(g^{-1}x)) =
\frac{1}{|G|} \sum_{g \in G} gg^{-1}x = x,
\]

y por tanto $\pi \circ \widetilde\varphi = \mathrm{id}_{V/W}$. Si tomamos $U = \operatorname{Im} \widetilde\varphi$, vemos que $V = W \oplus U$;
luego todo submódulo es un sumando directo.

**** 2.10.a. Representaciones equivalentes
Dos representaciones $k\text{-lineales}$ de $G$ se llaman *equivalentes* si los
$kG\text{-módulos}$ son isomorfos.

**** 2.10.b. Representación regular
La representación regular $\rho_{reg}$ es la asociada al propio $kG$ como $k\text{-módulo}$.
Cuando $\mathrm{char}(k) \nmid |G|$ es, por [[*Teorema de Maschke][Teorema de Maschke]], suma de irreducibles, que
notaremos como

\[\rho \sim
\rho_1^{n_1}\oplus \dots\oplus \rho_t^{n_t}
\]

para ciertas multiplicidades $n_i$.

**** 2.10.c. Constituyentes
Usando la estructura de las álgebras semisimples, sabemos que cualquier
representación $k\text{-lineal}$ de $G$ será de la forma

\[\rho \sim
\rho_1^{m_1}\oplus \dots\oplus \rho_t^{m_t}
\]

para ciertas multiplicidades $m_i$. Llamamos a las $\rho_i$ con multiplicidad positiva
las *constituyentes* de $\rho$.

**** 2.11. Multiplicidades en la representación regular
Cuando $\mathrm{char}(k) \nmid |G|$, si las representaciones $k\text{-lineales}$ irreducibles de $G$
son $(V_1,\rho_1),\dots,(V_{t},\rho_t)$ y tenemos $n_i$ la multiplicidad de cada una de ellas
en la representación regular y $d_i = \mathrm{dim}_k(\Delta_i)$ la dimnesión asociada al
álgebra de división que da el teorema de Wedderburn; tenemos que
$\mathrm{dim}_k(V_i) = d_in_i$ y $|G| = d_1n_1^2 +\dots + d_tn_t^2$.

***** TODO Demostración

**** 2.12. Multiplicidades en al representación regular compleja
Sean $(V_1,\rho_1),\dots,(V_t,\rho_t)$ las representaciones irreducibles complejas de $G$.
Si las multiplicidades en la representación regular son $(n_1,\dots,n_t)$,
entonces $\mathrm{dim}_{\mathbb{C}} V_i = n_i$ para $i = 1,\dots,t$ y $|G| = n_1^2 + \dots + n_t^2$.

***** TODO Demostración
**** 2.13. Dimensión del centro del álgebra-grupo
Sean $C_1,\dots,C_r$ las clases de conjugación de $G$. Entonces $\mathrm{dim}_k Z(kG) = r$.

***** TODO Demostración

**** 2.14. Número de representaciones irreducibles complejas
El número de clases de conjugación de $G$ coincide con el número de
representaciones irreducibles complejas de $G$.

***** TODO Demostración
*** 2.3. Caracteres
**** 2.15. Carácter complejo
Para $(V,\rho)$ representación compleja de $G$, la aplicación $\chi_{\rho}\colon G \to \mathbb{C}$ dada
por $\chi_{\rho}(g) = \mathrm{tr}(\rho(g))$, se llama *carácter* complejo de $\rho$.

***** Carácter irreducible
El que procede de una representación irreducible.

***** Grado de un carácter
Dimensión de $V$ como espacio vectorial complejo.

**** 2.16. Carácter invariante por equivalencia
Dos representaciones complejas equivalentes proporcionan el mismo
carácter.

***** Demostración
Si $(V,\rho)$ y $(W,\pi)$ son equivalentes por $T \colon V \to W$, para $g \in G$ tenemos
que $T\rho(g) = \pi(g)T$, luego $\rho(g) = T^{-1}\pi(g)T$, y sabemos que la traza se
preserva por semejanza.

**** 2.17.a. Exponente de un grupo
El *exponente* de un grupo $G$ es el mínimo común múltiplo de los órdenes
de sus elementos.

**** 2.17.b. Diagonalización de elementos de la representación
Sea $G$ con exponente $m$ y $(V,\rho)$ representación de grado $n$. Existen raíces
$m\text{-ésimas}$ de la unidad $\omega_1,\dots,\omega_n$ en las que diagonaliza $\rho(g)$. Se tiene
entonces

\[\chi_{\rho}(g) = \omega_1+\dots + \omega_n \]

y

\[\chi_{\rho}(g^{-1}) = \overline{\chi_{\rho}(g)}.
\]

***** TODO Demostración

**** 2.18. Cota del carácter
Para $G$ con exponente $m$ y $(V,\rho)$ representación,

\[|\chi_{\rho}(g)| \leq \operatorname{deg} \chi_{\rho}.
\]

El caso de igualdad se tiene si y sólo si $\rho(g) = \omega \mathrm{id}_V$ para alguna raíz
$m\text{-ésima}$ de la unidad.

***** Caso de la identidad
En particular, $\chi_{\rho}(g) = \operatorname{deg} \chi_{\rho}$ si y sólo si $\rho(g) = \mathrm{id}_V$.

**** 2.19. Núcleo de un carácter
Dado $\chi$ carácter complejo, su *núcleo* se define como

\[\ker \chi = \left\{ g \in G \mid \chi(g) = \chi(1) \right\}.
\]

***** TODO El núcleo es un subgrupo normal

**** Extensión de representaciones y caracteres
Dada una representación $\rho \colon G \to \mathrm{Aut}(V)$, notamos por $\tilde{\rho}(g) \colon \mathbb{C}G \to \mathrm{End}_{\mathbb{C}}(V)$ la
extensión al álgebra-grupo. Dado un carácter $\chi_{\rho} \colon G \to \mathbb{C}$, notamos por 
$\widetilde{\chi_{\rho}} \colon \mathbb{C}G \to \mathbb{C}$ a la extensión al álgebra grupo.

**** Caracteres irreducibles complejos
Los *caracteres irreducibles* complejos de $G$ son los dados por sus
representaciones irreducibles.

***** Dimensión del espacio de representación
Nótese que para cualquier carácter irreducible se tiene

\[n_i = \operatorname{dim}_{\mathbb{C}} V_{i} = \chi_i(1).\]

**** Carácter de la suma directa
Si $(W,\pi)$ es una representación con $W = W_{1} \oplus \dots \oplus W_m$, se tiene que

\[\chi_{\pi} = \chi_{\pi_1} + \dots + \chi_{\pi_m}.
\]

***** TODO Demostración

**** Carácter regular
El *carácter regular* es el carácter de la representación regular.
Cumple que

 1) \[\chi_{reg}(g) = \left\{\begin{array}{ll} |G|,  & \mbox{si } g=1 \\0, & \mbox{si }  g \neq 1.
    \end{array} 
    \right.\]
 2) $\chi_{reg} = \chi_1(1)\chi_1 + \dots + \chi_t(1)\chi_t$.

***** TODO Demostración

*** 2.4. La tabla de caracteres
**** TODO Tabla de caracteres
**** TODO Teorema de Frobenius
*** 2.5. Funciones de clase. Reciprocidad
**** Producto interno
En el espacio vectorial $\mathbb{C}^G$, de dimensión $|G|$, definimos el siguiente
*producto interno*

\[(\varphi,\psi) = \frac{1}{|G|} = \sum_{g \in G}\overline{\varphi(g)}\psi(g).
\]

***** Conjunto ortonormal
Nótese que los $\left\{ \chi_1,\dots,\chi_t \right\}$ forman un /conjunto ortonormal/ de vectores
en $\mathbb{C}^G$.

***** Base ortonormal
Si $G$ es /abeliano/, tiene tantas clases de conjugación como elementos.
Tenemos $t = |G|$ y los caracteres irreducibles son una base ortonormal
de $\mathbb{C}^G$.

**** Funciones de clase
Una *función de clase* de $G$ es una aplicación $\varphi\colon G \to \mathbb{C}$ constante sobre
cada clase de conjugación de $G$. Es decir,

\[
\varphi(hgh^{-1}) = h\varphi(g) h^{-1}.
\]

Al subespacio complejo de funciones de clase lo llamamos ${\cal C}(G)$.

**** Base ortonormal de las funciones de clase
Los caracteres irreducibles $\mathrm{Irr}(G) = \left\{ \chi_1,\dots,\chi_t \right\}$ forman una base ortonormal
de ${\cal C}(G)$.

***** TODO Demostración

**** Equivalencia por caracteres
Dos representaciones complejas de $G$ son equivalentes si, y sólo si,
proporcionan el mismo carácter.

***** TODO Demostración

**** Restricción e inducción
Fijados $H \leq G$, definimos

 * la *restricción* $(-)_H\colon {\cal C}(G) \to {\cal C}(H)$ de funciones de clase.
 * la *inducción* $(-)^G\colon {\cal C}(H) \to {\cal C}(G)$ de funciones de clase.

La /inducción/ se define como

\[
\varphi^G(g) = \frac{1}{|H|}\sum_{x \in G}\varphi^{\bullet}(x^{-1}gx),
\]

donde $\varphi^{\bullet}(g) = \varphi(g)$ cuando $g \in H$ y $\varphi^{\bullet}(g) = 0$ cuando $g \notin H$.

**** Reciprocidad de Frobenius
Sea $H$ un subgrupo de $G$, $\varphi \in {\cal C}(H)$ y $\psi \in {\cal C}(G)$. Entonces

\[(\psi_H,\varphi) = (\psi,\varphi^G).
\]

***** TODO Demostración

**** La inducción de un carácter es carácter
Si $\varphi$ es carácter de $H$, entonces $\varphi^G$ es un carácter de $G$.

***** TODO Demostración

**** TODO Constituyentes

** Ejercicios de clase
*** Ejercicio 1
#+begin_statement
Comprobar que $K$ es una K-álgebra.
#+end_statement

Tenemos que $K$ es un espacio vectorial sobre sí mismo y su propio
producto es una aplicación bilineal sobre $K$, ya que cumple:

  - $(a+b)c = ac+bc$, por axiomas de anillo.
  - $a(b+c) = ab+ac$, por axiomas de anillo.
  - $a(bc) = (ab)c = b(ac)$, el producto es conmutativo y asociativo.

Además es un álgebra asociativa y unital.

*** Ejercicio 2
#+begin_statement
Calcular el centro del álgebra de matrices $M_n(K)$.
#+end_statement

Supongamos $A \in Z(M_n(K))$, si tomamos las matrices que sólo tienen una 
entrada unidad y el resto ceros $E_{ij} = (\delta_{ij})_{i,j}$. Así, tenemos:

\[
E_{ii}A = \begin{pmatrix}
0 & \dots & 0 \\
^{i)} a_{i1} & \dots & a_{in} \\
0 & \dots & 0 \\
\end{pmatrix}
\qquad
AE_{ii} = \begin{pmatrix}
0 & ^{i)}a_{1i} & 0 \\
\vdots & \vdots & \vdots \\
0 & a_{ni} & 0 \\
\end{pmatrix}
\]

Por lo tanto $a_{ij} = 0$ para $i \neq j$. Además,

\[
E_{ij}A = \begin{pmatrix}
0 & ^{j)}\dots & 0 \\
^{i)} \dots & a_{ii} & \dots \\
0 & \dots & 0 \\
\end{pmatrix}
\qquad
AE_{ij} = \begin{pmatrix}
0 & ^{j)}\dots & 0 \\
^{i)}\dots & a_{jj} & \dots \\
0 & \dots & 0 \\
\end{pmatrix}
\]

Por tanto, $A = \lambda I$. Se cumple que $(\lambda I) B = \lambda (I B) = \lambda B = \lambda (B I) = B (\lambda I)$,
y el centro es de la forma

\[
\left\{
\lambda I \mid \lambda \in K
\right\}
\]

*** Ejercicio 3
#+begin_statement
Comprobar que $Im(u) \subseteq Z(A)$, siendo $u : K \longrightarrow A$, $u(\alpha) = \alpha 1_A$.
#+end_statement

Usando la bilinealidad:

\[
u(\alpha) a =
(\alpha 1) a =
\alpha (1a) =
1 (\alpha a) =
(\alpha a) 1 =
a (\alpha 1)
\]

*** Ejercicio 4
#+begin_statement
Supongamos $A$ anillo y $K$ cuerpo. Dado un homomorfismo de anillos $u : K \longrightarrow A$,
demostrar que $A$ es una K-álgebra si defino su estructura de K-espacio 
vectorial como sigue:

\[
\forall\alpha \in K, a \in A:\quad \alpha a = u(\alpha) a
\]

Es decir, podemos definir alternativamente un álgebra sobre $K$ como un
homomorfismo de anillos $u : K \longrightarrow Z(A)$, el *homomorfismo de estructura*.
#+end_statement

Debemos comprobar que la multiplicación del anillo es bilineal sobre la
estructura de espacio vectorial:

  - $(a+b)c = ac+bc$
  - $a(b+c) = ab+ac$
  - $(\alpha a)c = (u(\alpha) a) c = a u(\alpha) c$

Por lo que forma un K-álgebra.

*** Ejercicio 5
#+begin_statement
Comprobar que $Z(\mathbb{H}) = \mathbb{R}$.
#+end_statement

Supongamos un elemento en el centro $z = a+bi+cj+dk$, debería conmutar con
$i,j$, así que:

\[
0 = zi-iz = (ai-b-ck+dj) - (ai-b+ck-dj) = 2(dj-ck)
\]
\[
0 = zj-jz = (aj+bk-c-di) - (aj-bk-c+di) = 2(bk-di)
\]

De donde tenemos $b=c=d=0$, y por tanto, el elemento debe estar en $\mathbb{R}$.

*** Ejercicio 6
#+begin_statement
Dados $q,p\in \mathbb{H}$, escritos como suma de vector y escalar, se tiene la fórmula:

\[
(a+v)(b+w) = ab + aw + bv - v\cdot w + v \wedge w
\]
#+end_statement

Los tres primeros términos se tienen porque el producto escalar coincide
con el producto de un real por un cuaternión. Los dos últimos términos se
tienen como sigue. Si tomamos $v = xi+yj+zk$, $w = oi+pj+qk$; y los
interpretamos como vectores como $v = (x\ y\ z)$, $w = (o\ p\ q)$:

\[
vw = (-xo-yp-qz) + (pxk-qxj - oyk+qyi + ozj-pzi)
\]

Y comprobamos que:

\[(x\ y\ z)(o\ p\ q) = xo+yp+zq\]

\[\begin{vmatrix}
i&j&k \\
x&y&z \\
o&p&q \\
\end{vmatrix}
=
pxk-qxj - oyk+qyi + ozj-pzi
\]

*** TODO Ejercicio 7
#+begin_statement
Demostrar que un grupo abeliano $(V,+)$ junto a una acción $A\times V \to V$ es
un módulo ssi verifica las cuatro condiciones siguientes:

  1. $(a+a')v = av + a'v$
  2. $a(v+v') = av+av'$
  3. $a(a'v) = (aa')v$
  4. $1v = v$
#+end_statement
*** Ejercicio 8
#+begin_statement
Definir un submódulo.
#+end_statement

Un submódulo debe tener estructura de módulo y una inclusión al módulo
del que es submódulo. Exigimos entonces, para que tenga estructura de módulo,
que sea cerrado respecto a la suma y al producto por elementos del álgebra.
Nótese que dentro de los elementos del álgebra están los elementos del 
cuerpo base del álgebra.

*** Ejercicio 9
#+begin_statement
Sea $N_1,\dots,N_m \in {\cal L}(M)$. Demostrar que:

\[
N_1+\dots+N_m
=
\{m_1+\dots+m_n \mid m_i \in N_i \}
\]
#+end_statement

Primero notamos que es un módulo, ya que:

 - $a(m_1+\dots+m_n) = am_1+\dots+am_n$
 - $(m_1+\dots+m_n)+(m'_1+\dots+m'_n) = (m_1+m'_1) + \dots + (m_n+m'_n)$

Después notamos que si un módulo contiene a $N_1,\dots,N_m$ debe contener
todas las sumas de sus elementos por ser cerrado para la suma. Así,
este es el mínimo módulo conteniendo a $N_i$.

*** Ejercicio 10
#+begin_statement
¿Para qué valores del ángulo el giro en el plano da sólo submódulos propios?
Es decir, ¿cuándo es $\mathbb{R}^2$ simple como $\mathbb{R}[T]$ módulo con $T$ giro?
#+end_statement

Sea $M$ un submódulo de $\mathbb{R}^2$ con $v \not\in M$. Si $T(v),v$ son linealmente 
independientes, el espacio $\langle Tv,v \rangle$ será $\mathbb{R}^2$ y no podrá existir un módulo
propio. En otro caso, $\langle v \rangle$ será un módulo propio.

Para tener $Tv,v$ independientes, es necesario tener un giro múltiplo de $\pi$.

*** TODO Ejercicio 11 (★★)
#+begin_statement
Calcular todos los $\mathbb{R}[X]\text{-módulos}$ de $\mathbb{P}_n$ para la acción de derivación.
#+end_statement

*** Ejercicio 12?
#+begin_statement
Sean $M = S_1\oplus \dots \oplus S_t$, $N = T_1\oplus \dots \oplus T_n$ con $S_i,T_i$ simples y cumpliendo
$S_i \not\cong T_j$. Probar que todo homomorfismo de módulos $f \colon M \to N$ es $0$.
#+end_statement

Similar al [[*Ejercicio 23 (★)][ejercicio 23]].

** Ejercicios de los apuntes
*** Ejercicio 1 (*)
#+begin_statement
Calcular el centro del álgebra de matrices $M_n(K)$.
#+end_statement

*** Ejercicio 2
#+begin_statement
Escribir la demostración de la Proposición 1.7.
#+end_statement

**** La imagen es subálgebra
Trivialmente, la imagen es espacio vectorial y $f(a)f(b) = f(ab)$.

**** El núcleo es un ideal
El núcleo es subespacio vectorial y además,

\[
f(ak) = f(a)f(k) = 0 = f(k)f(b) = f(kb)
\]

para cualquier $f(k) = 0$.

**** Isomorfía
Notamos primero que $\widehat f$ es el mismo que obtendríamos aplicando el
primer teorema de Isomorfía entre espacios vectoriales. Así, sabemos
que está bien definido y que es una función lineal biyectiva.

Comprobaremos simplemente que preserva el producto, probando así que
es un isomorfismo de k-álgebras; pero esto es trivial por la estructura
de álgebra con la que hemos dotado al cociente:

\[
\widehat f((a+I)(b+I)) = 
\widehat f(ab+I) = f(ab) = f(a)f(b) 
= \widehat f(a+I) \widehat f(b+I).
\]

*** Ejercicio 3
#+begin_statement
Supongamos que $K$ es un cuerpo, y $A$ es un anillo (no necesariamente
conmutativo). Sea $u : K \to A$ un homomorfismo de anillos tal que
$Im(u) \subseteq Z(A)$, donde $Z(A)$ denota el centro de $A$, definido de manera
obvia. Comprobar que si definimos la acción de $K$ sobre $A$ dada por
$\alpha a = u(\alpha) a$, para todo $\alpha \in K, a \in A$, entonces $A$ es una k-álgebra.
#+end_statement

Comprobamos primero que $A$ es un k-espacio vectorial. Con su suma es
un grupo abeliano, y por ser el producto sobre ella distributivo y
el homomorfismo de anillos unital y asociativo:

 - $u(\alpha)(a+b) = u(\alpha)a + u(\alpha)b$
 - $u(1)a = 1a = a$
 - $u(\alpha)u(\beta)(a+b) = u(\alpha\beta)(a+b)$
 - $u(\alpha+\beta)a = u(\alpha)a + u(\beta)a$

Ahora comprobaremos simplemente que el producto del anillo es una
operación bilineal en este espacio vectorial.

  - $(a+b)c = ac+bc$
  - $a(b+c) = ab+ac$
  - $(\alpha a)c = (u(\alpha) a) c = a u(\alpha) c$

Donde hemos usado distributividad del producto y que $u(\alpha) \in Z(A)$.

*** Ejercicio 4
#+begin_statement
Demostrar que, realmente, $End_K(V)$, con las operaciones recién descritas
(suma, producto escalar y composición), es una K-álgebra.
#+end_statement

La suma se define por $(f+g)(v) = f(v)+g(v)$, lo que da un grupo abeliano
con el neutro $0(v) = 0$; además, con $(\alpha f)(v) = \alpha f(v)$, nos da un espacio
vectorial.

Comprobamos además que la composición es bilineal:

  1. $((f+g)\circ h)(v) = f(h(v)) + g(h(v)) = (f\circ h + g\circ h)(v)$
  2. $(f\circ (g+h))(v) = f(g(v)) + f(h(v)) = (f\circ g + f\circ h)(v)$
  3. $(\alpha f \circ g)(v) = \alpha (f\circ g)(v)) = f(\alpha g(v)) = (f \circ \alpha g)(v)$

Donde en el primer y segundo punto usamos la definición de suma; y
en el tercer punto usamos la linealidad de la función para conmutar
el elemento del cuerpo y la aplicación de la función.

*** Ejercicio 5 (*)
#+begin_statement
Comprobar todas las afirmaciones hechas en el Ejemplo 11.
#+end_statement

**** Estructura del espacio cociente
Sabemos que cada ideal no nulo lo genera un polinomio por ser un
Dominio de Ideales Principales, que además podemos suponer mónico por ser $K$ 
un cuerpo. Como además los polinomios forman un dominio euclídeo con el
grado como función euclídea, podemos escribir cualquier polinomio $t$ como

\[
t(X) = r(X) + p(X)q(X), \text{ para } \mathrm{deg}(r) < n,
\]

y por tanto, ${\cal B} = \left\{ 1+I, x+I,\dots, x^{n-1}+I \right\}$ es un sistema generador. Sabemos
que es linealmente independiente porque si no lo fuese, tendríamos una
relación lineal que daría lugar a que un polinomio de grado menor que $n$
estuviera en el ideal. Así, ${\cal B}$ es base.

**** Matriz compañera
Podemos comprobar que la matriz compañera es la que representa a $\lambda_{x+I}$
por tenerse que $(x+I)(x^{i-1}+I) = (x^{i}+I)$ para $i < n$ y que

\[x^{n}+I = p_0-p_1x-\dots-p_{n-1}x^{n-1} + I\]

Sabemos ahora que $\lambda : A \to \mathrm{End}(A)$ es un homomorfismo inyectivo de álgebras
que lleva $\lambda_{x+I} = \tilde N(p)$ y que por ser inyectivo preserva la independencia
lineal de la base. Así, la imagen de los elementos de la base es una base
de la imagen, y tenemos que el álgebra $A$ es isomorfa a la subálgebra de
$M_n(K)$

\[
\left\{ a_0I+a_1\tilde N(p) + \dots + a_{n-1}\tilde N(p)^{n-1} \mid
a_0,a_1,\dots,a_{n-1} \in K \right\} \subseteq M_n(K).
\]

*** Ejercicio 6
#+begin_statement
Expresar el cuerpo $\mathbb{Q}(\sqrt{2})$ como una $\mathbb{Q}$ subálgebra de un álgebra de matrices
sobre $\mathbb{Q}$.
#+end_statement

Empezamos notando que

\[
\mathbb{Q}\left(\sqrt{2}\right) = \frac{\mathbb{Q}}{(X^2-2)},
\]

y que podemos por tanto aplicar el razonamiento del ejemplo 11 para saber
que si la matriz compañera del polinomio $p(x) = x^2-2$ es

\[\tilde N(p) = \begin{pmatrix}
0 & 2 \\
1 & 1
\end{pmatrix},\]

el álgebra será isomorfa a la subálgebra de $M_2(\mathbb{Q})$ dada por

\[
\left\{ aI + b\tilde N(p) \mid a,b \in \mathbb{Q} \right\}.
\]

*** Ejercicio 7
#+begin_statement
Sea

\[\mathbb{H} = \left\{ \begin{pmatrix}
\alpha & -\overline{\beta} \\
\beta & \overline{\alpha}
\end{pmatrix} \mid \alpha,\beta \in \mathbb{C} \right\}\]

  1. Demostrar que $\mathbb{H}$ es una subálgebra real de $M_2(\mathbb{C})$ y que $Z(\mathbb{H}) = \mathbb{R}$.
  2. Demostrar que todo elemento no nulo de $\mathbb{H}$ es una unidad.
  3. Demostrar que las matrices

     \[\mathbf{1} = \begin{pmatrix}1 & 0 \\0 & 1\end{pmatrix},\; 
     \mathbf{i} = \begin{pmatrix}0 & -1 \\ 1 & 0\end{pmatrix},\;
     \mathbf{j} = \begin{pmatrix}i & 0 \\ 0 & -i\end{pmatrix},\;
     \mathbf{k} = \begin{pmatrix}0 & i \\ i & 0\end{pmatrix}
     \]

     forman una base de $\mathbb{H}$ como espacio vectorial real.
  4. Comprobar las identidades

     \[
     i^2=j^2=k^2=-1,\; ij=k,\; jk=i,\; ki=j
     \]

El álgebra así construida se llama álgebra de los cuaterniones de Hamilton.
#+end_statement

**** Primer punto
Comprobamos que es cerrada bajo el producto por reales

\[\lambda\begin{pmatrix}
\alpha & -\overline{\beta} \\
\beta & \overline{\alpha}
\end{pmatrix} = \begin{pmatrix}
\lambda\alpha & -\lambda\overline{\beta} \\
\lambda\beta & \lambda\overline{\alpha}
\end{pmatrix} = \begin{pmatrix}
\lambda\alpha & -\overline{\lambda\beta} \\
\lambda\beta & \overline{\lambda\alpha}
\end{pmatrix}
\]

y que es cerrada bajo su producto

\[\begin{pmatrix}
\alpha & -\overline{\beta} \\
\beta & \overline{\alpha}
\end{pmatrix}\begin{pmatrix}
\gamma & -\overline{\delta} \\
\delta & \overline{\gamma}
\end{pmatrix} = \begin{pmatrix}
\alpha\gamma-\overline{\beta}\delta & -\overline{\delta}\alpha-\overline{\beta}\overline{\gamma} \\
\beta\gamma+\overline{\alpha}\delta & -\overline{\delta}\beta + \overline{\gamma}\overline{\alpha}
\end{pmatrix} = \begin{pmatrix}
\alpha\gamma-\overline{\beta}\delta & -\left(\overline{\beta\gamma+\overline{\alpha}\delta}\right)\\
\beta\gamma+\overline{\alpha}\delta & \overline{\alpha\gamma-\overline{\beta}\delta}
\end{pmatrix}.
\]

Además, si tomamos una matriz en el centro, debe cumplir

\[\begin{aligned}\begin{pmatrix}
a & -\overline{b} \\
b & \overline{a}
\end{pmatrix}\begin{pmatrix}
c & -\overline{d} \\
d & \overline{c}
\end{pmatrix} = \begin{pmatrix}
ac-\overline{b}d & -a\overline{d}-\overline{bc} \\
bc+\overline{a}d & \overline{ac} - b\overline{d}
\end{pmatrix} &=\\ =\begin{pmatrix}
ac-b\overline{d} & -\overline{b}c-\overline{da} \\
ad+\overline{c}b & \overline{ac}-\overline{b}d
\end{pmatrix} &= \begin{pmatrix}
c & -\overline{d} \\
d & \overline{c}
\end{pmatrix}\begin{pmatrix}
a & -\overline{b} \\
b & \overline{a}
\end{pmatrix},\end{aligned}
\]

así que $\overline{b}d = b\overline{d}$ y $\overline{a}d+bc = ad + \overline{c}d$. Tomando $c=0$ y $d=1$ llegamos a que
$a,b \in \mathbb{R}$; y tomando $d = i$, que $b=0$. Así, las únicas matrices en el centro
serán las que representan a los reales, de la forma

\[\left\{\begin{pmatrix}\lambda & 0 \\ 0 & \lambda
\end{pmatrix}\mid \lambda \in \mathbb{R}\right\}\]

**** Segundo punto
Simplemente comprobar que cada elemento tiene una inversa a derecha

\[\begin{pmatrix}
a & -\overline{b} \\ b & \overline{a}
\end{pmatrix}\begin{pmatrix}
\frac{\overline{a}}{a\overline{a}+b\overline{b}} & 
\frac{\overline{b}}{a\overline{a}+b\overline{b}} \\ 
\frac{-b}{a\overline{a}+b\overline{b}} & 
\frac{a}{a\overline{a}+b\overline{b}}
\end{pmatrix} = \begin{pmatrix}
1 & 0 \\ 0 & 1
\end{pmatrix}\]

usando que si $a\overline{a}+b\overline{b} = 0$, es porque $a=b=0$ y el elemento es nulo.

**** Tercer punto
Sabiendo que los complejos son un espacio vectorial de dimensión $2$
con base $\{1,i\}$, podemos escribir los elementos de $\mathbb{H}$ como

\[\begin{pmatrix}
a+bi & -c+di \\
c+di & a-bi
\end{pmatrix} = a\begin{pmatrix}
1 & 0 \\ 0 & 1
\end{pmatrix}+
b\begin{pmatrix}
i & 0 \\ 0 & -i
\end{pmatrix}+
c\begin{pmatrix}
0 & 1 \\ -1 & 0
\end{pmatrix}+
d\begin{pmatrix}
0 & i \\ i & 0
\end{pmatrix}\]

que trivialmente es una descomposición única por independencia lineal.

**** Cuarto punto
Podemos comprobar trivialmente los cálculos.

*** Ejercicio 8
#+begin_statement
Dado un A-módulo $V$, demostrar que $\mathrm{Ann}_A(V) = \left\{ a \in A \mid av=0\; \forall v\in V \right\}$ es un
ideal de $A$. Dotar a $V$ de estructura de $A/\mathrm{Ann}_{A}(V)\text{-módulo}$ fiel (es decir,
la representación correspondiente es fiel).
#+end_statement

Si $a \in \mathrm{Ann}_A(V)$ tenemos que para cualquier $r \in A$ y $v \in V$, $rav = r0 = 0$ y 
$(ar)v = a(rv) = 0$. Podemos dotar a $V$ de estructura de módulo en el cociente
como

\[
\left( a+ \mathrm{Ann}(V) \right)v = av.
\]

Esta representación es fiel porque si tenemos $\forall v\in V\colon av = bv$, entonces
se tiene $a-b \in \mathrm{Ann}(V)$.

*** Ejercicio 9
#+begin_statement
Dar una demostración del Lema 1.25.
#+end_statement

**** Primer punto
Es claro que el menor submódulo que contenga a $N_1 \cup \dots \cup N_m$ debe contener
en particular a todas las sumas y por tanto

\[
\left\{ n_1+\dots+n_m \mid n_i \in N_i \right\} \subseteq N_1 + \dots + N_m.
\]

Si además probamos que es un submódulo, tendremos que debe ser el menor
conteniendo a la unión. Es cerrado para la suma por tenerse

\[
(n_1+\dots+n_m)+(n'_1+\dots+n'_m) =
(n_1+n'_1)+\dots+(n_m+n_m')
\]

y cerrado para el producto por elementos del anillo por tenerse

\[
a(n_1+\dots+n_m) = an_1+\dots+an_m.
\]

**** Segundo punto
De la misma forma, es claro que el menor submódulo conteniendo a $X$ debe
contener al menor módulo conteniendo a cada uno de sus elementos, y por
tanto al menor submódulo conteniendo a todos esos submódulos. Sabemos
entonces que

\[
RX \supseteq Rm_1 + \dots + Rm_n.
\]

Pero además, una suma de módulos es un submódulo, así que este es el menor
submódulo que contiene a $X$.

*** Ejercicio 10
#+begin_statement
Dados $A\text{-módulos}$ por la izquierda $M,N$ y una aplicación $f\colon M \to N$,
demostrar que $f$ es homomorfismo de $A\text{-módulos}$ si, y sólo si,
$f(am+a'm') = af(m) + a'f(m')$ para todo $a,a'\in A;\; m,m'\in M$.
#+end_statement

**** Si es homomorfismo de módulos cumple la regla
Aplicando primero linealidad y luego dos veces la condición de homomorfismo
de módulos tenemos

\[
f(am+a'm') = f(am)+f(a'm') = af(m) + a'f(m').
\]

**** Si cumple la regla, es homomorfismo de módulos
La linealidad la comprobamos tomando $a=a'=1$, la unidad del álgebra,

\[
f(m+m') = f(1m+1m') = 1f(m) + 1f(m') = f(m) + f(m').
\]

Y la condición de homomorfismo de módulos se comprueba tomando $a' = m'=0$,

\[
f(am) = f(am+0) = af(m) + 0f(0) = af(m).
\]

*** Ejercicio 11
#+begin_statement
Demostrar que un conjunto de generadores $\{m_i \mid i \in I\}$ de un módulo $_RM$ es una
base si, y sólo si, la igualdad $\sum_{i\in I}r_im_i = 0$ para $r_i \in R$ implica $r_i = 0$ para
todo $i \in I$.
#+end_statement

**** Si es una base, se tiene la condición
Si tenemos una base $\{m_i \mid i \in I\}$, en particular el $0$ se escribe de forma 
única como $0 = \sum_{i\in I} 0m_i$. Así, cualquier otra forma de escribir $0 = \sum_{i\in I} r_i m_i$
nos da $r_i = 0$.

**** Si se tiene la condición, es una base
Si tenemos la condición y tenemos dos formas distintas de escribir un
elemento, tendríamos en particular

\[
\sum_{i\in I} r_im_i = m = \sum_{i\in I}s_im_i
\quad\text{ y }\quad
\sum_{i \in I} (r_i-s_i)m_i = 0.
\]

Lo que nos llevaría a $r_i = s_i$ para cumplir la condición.

*** Ejercicio 12
#+begin_statement
Sea $\theta \in \mathbb{R}$ y $T_\theta : \mathbb{R}^2\to\mathbb{R}^2$ el endomorfismo que gira los vectores un ángulo $\theta$
en sentido contrario de las agujas del reloj. Consideremos la correspondiente
estructura de $\mathbb{R}[X]$ módulo definida por $T_\theta$ sobre $\mathbb{R}^2$. Discutir para qué valores
de $\theta$ es este módulo simple.
#+end_statement

Supongamos un $v \in M$, subespacio vectorial. Como $Tv \in M$, tenemos dos casos,

  * si $Tv,v$ son linealmente dependientes, se tiene $Tv = \lambda v$ y por tanto debe
    tenerse $\theta = k\pi$ para algún $k \in \mathbb{Z}$. El módulo no sería simple, ya que se
    tendría $T^2v = v$.
  * si no son linealmente dependientes, se tiene un espacio de dimensión al
    menos $2$, que debe ser por tanto el total. El módulo sería simple.

Es decir, salvo en el caso $\theta = k\pi$, el módulo es simple.

*** Ejercicio 13
#+begin_statement
Sea $M$ un $A\text{-módulo}$. Demostrar que $M$ es simple si, y sólo si, $M = Am$ para
todo $0 \neq m \in M$.
#+end_statement

**** Supongamos M simple
Entonces $Am$ es un submódulo no nulo, que debe ser por tanto $M$.

**** Supongamos la caracterización
Sea un submódulo de $M$ que contiene a algún elemento no nulo $m$. Por
las propiedades de submódulo, debe contener también a todo $Am = M$.
Así, no existen submódulos propios.

*** Ejercicio 14 (*)
#+begin_statement
Consideramos $T\colon \mathbb{R}^3 \to \mathbb{R}^3$ una aplicación lineal, y la estructura de $\mathbb{R}[X]\text{-módulo}$
correspondiente sobre $\mathbb{R}^3$. Discutir los posibles valores de la longitud de
$\mathbb{R}^3$ como $\mathbb{R}[X]\text{-módulo}$. Poner un ejemplo de $T$ para el que se alcance cada longitud.
#+end_statement

La longitud debe ser como máximo $3$, su dimensión como espacio vectorial
sobre $\mathbb{R}$. Estudiaremos los casos posibles.

*Longitud 1.*
Probaremos que no puede tenerse una cadena de longitud $1$; es decir, que
$\mathbb{R}^3$ sea simple. Toda aplicación lineal $T$ nos da una ecuación polinómica

\[ | T - \lambda I | = 0
\]

de grado $3$ con coeficientes reales, que debe tener al menos una solución
en los reales. Esto nos da un vector propio y por tanto un subespacio que
queda fijo por la acción de $T$; es decir, un submódulo.

*Longitud 2.*
Tomamos $T$ la aplicación que gira un plano mientras deja fija la recta
ortogonal a él; específicamente,

\[T = \begin{pmatrix}
0 & 1 & 0 \\
-1 & 0 & 0 \\
0 & 0 & 1
\end{pmatrix}
\]

nos da el subespacio $\left\langle e_3 \right\rangle$ fijo bajo su acción. Por otro lado, el
submódulo $\left\langle e_1,e_2 \right\rangle \cong \mathbb{R}^3/ \left\langle e_3 \right\rangle$ es simple; la rotación no dejará ninguna
recta fija, no hay vectores propios. Así, tenemos una serie de
composición

\[
0 \subset \left\langle e_1,e_2 \right\rangle \subset \mathbb{R}^3.
\]

*Longitud 3.*
Simplemente tomando la identidad y retirando a cada paso una dimensión
del espacio vectorial

\[
0 \subset \left\langle e_1 \right\rangle
\subset \left\langle e_1,e_2 \right\rangle
\subset \left\langle e_1,e_2,e_3 \right\rangle.
\]

*** Ejercicio 15
#+begin_statement
Sea $\mathbb{P}_{n}$ el espacio vectorial real de las funciones polinómicas en una variable
de grado menor o igual que $n$. Sea $T\colon \mathbb{P}_n \to \mathbb{P}_n$ la aplicación lineal que asigna
a cada polinomio su derivada. Calcular una serie de composición de $\mathbb{P}_n$ visto
como $\mathbb{R}[X]\text{-módulo}$ via $T$.
#+end_statement

Tenemos una base del espacio vectorial dada por $\left\{ 1,x,\dots,x^n \right\}$, podemos generar
una serie de composición donde vemos que cada uno es un submódulo cerrado para
la derivación y que cada cociente es simple por ser de dimensión $1$ en los reales
como

\[
0 \subset 
\left\langle 1 \right\rangle \subset
\left\langle 1,x \right\rangle \subset 
\dots \subset
\left\langle 1,x,\dots,x^n \right\rangle.
\]

*** Ejercicio 16 (**)
#+begin_statement
En las condiciones del Ejercicio 15, calcular todos los $\mathbb{R}[X]\text{-submódulos}$ de $\mathbb{P}_n$.
#+end_statement

Probaremos que los únicos submódulos de $\mathbb{P}_n$ son de la forma $\left\langle 1,x,x^2,\dots,x^k \right\rangle$.
Si tomamos un polinomio en un submódulo podemos suponerlo mónico por estar
en un cuerpo; y como además es de característica $0$, sus derivadas serán cada
una de un grado menor. Así, dado $p = x^k+ \dots +a_1x + a_0 \in \mathbb{P}_n$ tendremos

\[\begin{aligned}
p =& x^k+& a_{k-1}x^{k-1} +& \dots &+& a_1x &+& a_0 \\
\partial p =&  &kx^{k-1}+& \dots &+& 2a_2x &+ &a_1 \\
\dots \\
\partial^n p =&  && && && k! \\
\end{aligned}\]

Lo que constituye una base del espacio de polinomios de dimensión $k$ 
equivalente a $\left\langle 1,x,x^2,\dots,x^k \right\rangle$ gracias a que estamos en un cuerpo. Así,
cada submódulo será el submódulo de los polinomios de grado menor o igual
a $k$ para $k$ el grado de su polinomio de mayor grado.

*** Ejercicio 17 (**)
#+begin_statement
Supongamos $T \colon V \to V$ un endomorfismo $K\text{-lineal}$, donde $V$ es un espacio vectorial
de dimensión finita que consideramos, como de costumbre, como $K[X]\text{-módulo}$.
Supongamos que el polinomio mínimo $m(X)$ de $T$ es irreducible en $K[X]$ (ver
Ejemplo 14 para el concepto de polinomio mínimo). Demostrar que existen 
$K[X]\text{-submódulos}$ simples $V_1,\dots,V_t$ de $V$ tal que $V = V_1\oplus \dots \oplus V_{t}$ como
$K[X]\text{-módulo}$.
#+end_statement

Como $m(X)$ es irreducible y estamos en un DIP el ideal que genera,
$(m(X))$, es maximal, y por tanto el cociente

\[
k \cong \frac{K[X]}{(m(X))}
\]

es un cuerpo. Y $V$ es un $k\text{-espacio vectorial}$ ya que por el primer teorema de 
isomorfía tenemos que $K[X] \to \mathrm{End}_K(V)$ descompone en una proyección y una
inyección

\[\begin{tikzcd}
K[X] \rar[two heads] & 
\displaystyle\frac{K[X]}{(m(X))} \rar[hook] &
\mathrm{End}_K(V).
\end{tikzcd}\]

Ahora, si $V$ tiene una base finita como $K\text{-espacio vectorial}$, sabiendo que $K \subseteq k$,
tenemos que $V$ tiene un sistema de generadores finito como $k\text{-espacio vectorial}$.
Por el Corolario 1.45 existe entonces un subconjunto de ese sistema de 
generadores tal que

\[
V = \bigoplus_{j \in J} kv_j = V_1 \oplus \dots \oplus V_t.
\]

Nótese que cada uno de ellos es un submódulo simple por ser isomorfos a $k$.

*** Ejercicio 18 (**)
#+begin_statement
En las condiciones del Ejercicio 17, demostrar que el polinomio característico
de $T$ es $m(X)^t$.
#+end_statement

Por Cayley-Hamilton, sabemos que $T$ cumple su ecuación característica, y por
tanto, $m(X)$ divide a su polinomio característico. 

Por otro lado, supongamos que tenemos un factor irreducible $p$ del
polinomio característico; este tendrá alguna raíz $\lambda$ en la clausura
algebraica de $K$. Es decir, tendremos un vector propio con coeficientes
en $\overline{K}$ cumpliendo $Tv = \lambda v$.

Si aplicamos el polinomio mínimo evaluado en $T$ a ese vector tendremos

\[
0 = m(T)v = m(\lambda)v,
\]

así que $\lambda$ es una raíz de $m$ en la clausura algebraica. Ahora, como el
polinomio irreducible de $\lambda$ en $K$ sigue siendo $p$, concluimos que $p \mid m$.

En general, hemos demostrado que todo factor irreducible del polinomio
característico divide al polinomio mínimo. Cuando además el polinomio
mínimo es irreducible, se tiene que el polinomio característico debe
ser de la forma $m(X)^s$.

Ahora comprobaremos que $s=t$. En efecto, tenemos que si $\mathrm{gr}(m) = n$,
entonces, por construcción, $\mathrm{dim}_Kk=n$ y por ser $V_i \cong k$, tenemos
$\mathrm{dim}_{K}(V) = tn$; que debe ser el grado del polinomio característico,
a la vez que debe ser $sn$.

*** Ejercicio 19
#+begin_statement
Demostrar que si $R$ es un dominio de integridad conmutativo, entonces $R$ no
tiene idempotentes no triviales.
#+end_statement

Si $e^2=e$, entonces $e(e-1) = 0$; lo que, en un dominio de integridad implica
que $e = 0$ ó $e-1 = 0$.

Nótese que no hemos usado la conmutatividad.

*** Ejercicio 20
#+begin_statement
Dar un CCIO para $R = M_n(k)$.
#+end_statement

Sean $E_{ii}$ las matrices nulas excepto por un $1$ en la entrada $i,i$. Se comprueba
trivialmente que $E_{ii}E_{jj} = 0$ para cualesquiera $i \neq j$, y que $E_{ii}^2 = 1$. Forman
además un conjunto completo por tenerse:

\[
I = E_{11} + E_{22} + \dots + E_{nn}
\]
*** TODO Ejercicio 21
#+begin_statement
Comprobar las afirmaciones realizadas en el Ejemplo 17.
#+end_statement
*** Ejercicio 22
#+begin_statement
Sea $\left\{ e_1,\dots,e_n \right\}$ un ccio para $R$. Demostrar que los idempotentes $e_1,\dots,e_n$ son
centrales si, y sólo si, $e_iRe_j = 0$ para todo $i \neq j$.
#+end_statement

**** Si son centrales, cumplen la condición
Si son centrales, se tiene que, para cualquier $r \in R$,

\[
e_ire_j = re_ie_j = 0
\]

por ortogonalidad.

**** Si cumplen la condición, son centrales
Sabiendo que cumplen que $e_ire_j = 0$ para cualquier $r \in R$, tenemos

\[
e_ir = e_ir\left(\sum_j e_j\right) = \sum_j e_ire_j = e_ire_i = \sum_j e_jre_i = re_i
\]

por ser completos.

*** Ejercicio 23 (*)
#+begin_statement
Sean $M$ y $N$ módulos semisimples con descomposiciones como sumas directas
de submódulos simples $M = S_1 \oplus \dots \oplus S_t$ y $N = T_1\oplus \dots \oplus T_s$. Supongamos que
$S_i$ no es isomorfo a $T_j$ para todo $i = 1,\dots,t$, $j = 1,\dots,s$. Demostrar que
todo homomorfismo de módulos de $M$ a $N$ es cero.
#+end_statement

Desde el ejemplo 17, sabemos que, en los endomorfismos de un módulo suma
directa, la composición de inclusión y proyección en las distintas componentes
nos da un ccio. Vamos a llamar $q_i \colon M \to M$ al endomorfismo que proyecta e
incluye en la componente $i\text{-ésima}$; y vamos a llamar $p_j \colon N\to N$ al que hace
lo mismo en la componente $j\text{-ésima}$ de $N$. Sabemos que

\[
q_1 + \dots + q_t = \mathrm{id}
\quad\text{ y que }\quad
p_1 + \dots + p_s = \mathrm{id}.
\]

Ahora, calculamos que

\[\begin{aligned}
f &= (q_1+\dots+q_t) \circ f \circ (p_1+\dots+p_s) \\
  &= \sum_{i=1}^t\sum_{j=1}^s q_i\circ f\circ p_j = 0,
\end{aligned}\]

ya que $q_i\circ f\circ p_j\colon S_i\to T_i$ debe ser nulo o isomorfismo por el Lema de Schur
y hemos supuesto que no es isomorfismo.

# Nótese que no es exactamente esto, sino que hay que partir q en sus
# componentes para igualar a cero.

*** TODO Ejercicio 24
#+begin_statement
Sea $M$ un módulo semisimple de dimensión finita con estructura
$\left( n_1,\Sigma_1 \right),\dots,(n_t,\Sigma_t)$. Si $N$ es un submódulo de $M$, demostrar que su estructura
es $\left( m_1,\Sigma_1 \right),\dots,(m_t,\Sigma_t)$ para ciertos $m_j \leq n_j$ (admitimos que $m_j=0$ significa
que $\Sigma_j$ no aparece en la estructura de $M$).
#+end_statement
*** TODO Ejercicio 25
#+begin_statement
Establecer un enunciado análogo al del Ejercicio 24 para cada cociente de $M$.
#+end_statement
*** TODO Ejercicio 26
#+begin_statement
Dada una $K\text{-álgebra}$ $A$, demostrar que la aplicación $\rho\colon A \to \mathrm{End}(A)^{op}$ definida
por $\rho(a)(a') = a'a$ es un isomorfismo de $K\text{-álgebras}$.
#+end_statement

*** TODO Ejercicio 27 (*)
#+begin_statement
Sea $B$ un álgebra. Demostrar que la aplicación que asigna a cada matriz
su traspuesta da un isomorfismo de álgebras $M_n(B)^{op} \cong M_n(B^{op})$.
#+end_statement

*** TODO Ejercicio 28
#+begin_statement
Sea $\varphi\colon R \to S$ un isomorfismo de $K\text{-álgebras}$, e $I,J$ ideales por la izquierda
de $R$. Demostrar que $\varphi(I),\varphi(J)$ son ideales por la izquierda de $S$ y que dado
cualquier homomorfismo de $R\text{-módulos}$ $f \colon I \to J$, la aplicación $\widehat f\colon \varphi(I) \to \varphi(J)$
definida por $\widehat f(y) = \varphi f \varphi^{-1}(y)$ para $y \in \varphi(I)$ es un homomorfismo de $S\text{-módulos}$.
#+end_statement

*** TODO Ejercicio 29
#+begin_statement
Sean $R_1,\dots,R_n$ $K\text{-álgebras}$ y $R = R_1\times \dots \times R_n$. Los ideales por la izquierda
de $R$ son de la forma $I_1\times \dots\times I_n$, con $I_i$ ideal por la izquierda de $R_i$ para
$i = 1,\dots,n$. Análoga descripción tienen los ideales biláteros de $R$.
#+end_statement

*** TODO Ejercicio 30 (*)
#+begin_statement
Sea $A$ un álgebra simple finito-dimensional. Demostrar que $R = \mathrm{M}(A)$ es un
álgebra simple de dimensión finita. Demostrar que asimismo que si $\Sigma$ es un
$A\text{-módulo}$ simple y $M$ es un $R\text{-módulo}$ simple, entonces $\mathrm{End}(\Sigma)$ y $\mathrm{End}(M)$
son álgebras isomorfas.
#+end_statement

*** TODO Ejercicio 31 (*)
#+begin_statement
Demostrar que $T_q \in SO(V)$ para todo cuaternio $q$ de norma $1$.
#+end_statement

*** TODO Ejercicio 32 (*)
#+begin_statement
Calcular explícitamente una representación real no trivial de grado $2$ del
grupo de permutaciones $S_3$.
#+end_statement
*** TODO Ejercicio 33
#+begin_statement
Comprobar que la multiplicación definida sobre $KG$ es asociativa. Su elemento
neutro es $1e$, donde $e$ es el elemento neutro de $G$.
#+end_statement
*** TODO Ejercicio 34
*** TODO Ejercicio 35
*** TODO Ejercicio 36
*** TODO Ejercicio 37
*** TODO Ejercicio 38
*** TODO Ejercicio 39
*** TODO Ejercicio 40 (*)
#+begin_statement
Calcular razonadamente la tabla de caracteres de $Q_8$.
#+end_statement

*** TODO Ejercicio 41 (*)
#+begin_statement
Calcular razonadamente la tabla de caracteres del grupo dihédrico $D_4$.
#+end_statement

*** TODO Ejercicio 42 (**)
#+begin_statement
Calcular razonadamente la tabla de caracteres del grupo dihédrico $D_n$, para
$n \geq 2$.
#+end_statement

*** TODO Ejercicio 43
#+begin_statement
Sea $G$ un grupo abeliano finito, y sea $\widehat G$ el conjunto de los caracteres 
complejos irreducibles de $G$. Demostrar que el producto inducido por el
de números complejos dota a $\widehat G$ de estructura de grupo.
#+end_statement

*** TODO Ejercicio 44 (**)
#+begin_statement
Sea $G$ un grupo abeliano finito, y $\widehat G$ el grupo definido en el Ejercicio 43.
Demostrar que existe un isomorfismo de grupos $G \cong \widehat G$.
#+end_statement

*** TODO Ejercicio 45
#+begin_statement
Sea $G$ un grupo finito y $g \in G$. Demostrar que $g$ es conjugado con $g^{-1}$ si,
y sólo si, $\chi(g) \in \mathbb{R}$ para todo carácter complejo irreducible $\chi$ de $G$.
#+end_statement
*** TODO Ejercicio 46
#+begin_statement
Demostrar que $\varphi^G \in {\cal C}(G)$ para cada $\varphi \in {\cal C}(H)$, y que $\varphi^G(1) = |G:H|\varphi(1)$.
#+end_statement
*** TODO Ejercicio 47 (*)
*** TODO Ejercicio 48 (**)
#+begin_statement
Calcular la tabla de caracteres complejos de $A_5$.
#+end_statement
* Taller de Geometría y Topología
** 1. Construcciones con regla y compás
*** 1.1. Construcciones posibles
**** 1.1.0. Construcciones elementales
Axiomáticamente consideramos realizables las siguientes construcciones
elementales:

  1. Dados dos puntos, puede construirse un *segmento* entre ellos.
  2. Todo segmento puede extenderse.
  3. Dados dos puntos, puede construirse un *círculo* con centro y radio.
  4. Dadas dos rectas secantes, puede construirse su *punto* de corte.
  5. Dados círculo y rectas, puede construirse su *punto* de corte.
  6. Dados círculos tangentes, pueden construirse *puntos* de corte.

***** Equivalencia de compases                                    :extra:
Asumimos un compás colapsable, pero podríamos usar uno no colapsable
con el mismo efecto, por la [[https://en.wikipedia.org/wiki/Compass_equivalence_theorem][equivalencia de compases]].

**** 1.1.1. Construcciones básicas
***** 1. Triángulo equilátero sobre un segmento
***** 2. Copiar un segmento
***** 3. Cortar segmento de otro dado
***** 4. Bisecar ángulo
***** 5. Mediatriz de un segmento
***** 6. Perpendicular a través de un punto en una recta
***** 7. Perpendicular a través de un punto fuera de una recta
***** 8. Triángulo con longitudes de lados dada
***** 9. Copiar un segmento a un segmento dado
***** 10. Copiar un ángulo a un rayo
***** 14. Paralela a una recta a través de un punto exterior
**** 1.1.2. Construcciones involucrando razones geométricas
***** 15. Cortar un segmento en n partes iguales
***** 16. Cortar un segmento en un racional
***** 17. Media geométrica de dos segmentos
**** 1.1.3. Construcciones involucrando áreas
***** 19. Paralelogramo con igual área que un triángulo dado
**** 1.1.4. Circunferencias destacadas
***** 24. Centro de una circunferencia
***** 25. Circunferencia inscrita a un triángulo
Usando bisectrices.
***** 26. Circunferencia circunscrita a un triángulo
*** 1.2. Construcciones imposibles
**** 1.2.1. Elementos constructibles o realizables
Un real $x$ es constructible cuando podemos construir puntos $C,D$ tales que
$\overline{CD} = x$.

***** Subcuerpo de números constructibles
Los números constructibles forman un subcuerpo de $\mathbb{R}$. Llamamos $\mathfrak{C}$ al
cuerpo de los constructibles.

****** TODO Demostración
***** Los racionales son constructibles
Todo subcuerpo de $\mathbb{R}$ debe contener a los racionales.

***** Las raíces de constructible son constructibles
Si $x \in\mathfrak{C}$, entonces $\sqrt{|x|} \in \mathfrak{C}$.

**** 1.2.1. Extensión cuadrática
Dado $\mathbb{K}$ subcuerpo de $\mathbb{R}$ llamamos a:

\[
\mathbb{K}(\sqrt{e}) = \{ a+ b\sqrt{e} \mid a,b\in\mathbb{K}\}
\]

una extensión cuadrática de $\mathbb{K}$.

**** 1.2.1. Teorema de Descartes
Un número real es constructible ssi está en alguna extensión cuadrática
iterada de $\mathbb{Q}$.

***** TODO Demostración

** Ejercicios
*** Formas del universo
**** Ejercicio 1
#+begin_statement
Como seres de dimensión 3 en un mundo de tres dimensiones es fácil
dibujar y entender posibles formas de Planilandia pero no de nuestro
propio Universo. Imaginar la forma de nuestro Universo en alguna de
las siguientes situaciones:

 * Hacemos una expedición a una galaxia remota. Al llegar a ella
   descubrimos estar de vuelta en la tierra.

 * Un astrónomo acaba de descubrir que los mismos objetos se
   encuentran en posiciones distintas del Universo.

 * Buscando ondas de radio que detecten señales extraterrestres,
   detectamos una señal que procede de una galaxia lejana.
   Investigamos y vemos que se trata de la señal de un programa de TV
   emitido hace 50 años.

A las posibles formas de nuestro Universo les llamaremos
variedades de dimensión 3 y su estudio constituye la Topología
3-dimensional.
#+end_statement

**** Ejercicio 2
#+begin_statement
1. ¿Cuáles de las siguientes superficies tienen la misma topología?
   
   [[./img/formasuniverso1.png]]

2. En Planilandia CP descubrió que dos caminos cerrados partiendo del mismo
   punto en direcciones opuestas no tienen por qué volver a cruzarse en un
   punto diferente. ¿Es esta propiedad geométrica o topológica?
3. Describir superficies con la misma topología pero diferente geometría.
#+end_statement

**** Ejercicio 3
#+begin_statement
Distingue según su topología intrínseca y extrínseca.

[[./img/formasuniverso2.png]]

 * ¿Puedes forrar un cilidro con parte de una hoja de papel sin deformarla?,
   ¿y un cono?, ¿y un trozo de esfera?
 * ¿Coḿo pueden los planilandeses que vivan en mundos como los de la figura
   conocer que sus geometrías intrínsecas son diferentes? ¿Qué pueden decir
   acerca de sus topologías extrínsecas e intrínsecas?

   [[./img/formasuniverso3.png]]

$\quad$
#+end_statement

**** Ejercicio 4
#+begin_statement
  * Justifica que el toro llano y la superficie de un donut son
    topológicamente equivalentes.

  * Consigue en la siguiente figura un de un toro llano tres =X=
    en línea.

    #+attr_latex: :width 5cm 
    [[./img/formasuniverso4.png]]

  * Cuáles de las posiciones siguientes serían equivalentes al jugar
    unas "tres en línea" sobre un toro llano.

    [[./img/formasuniverso5.png]]

  * En el siguiente tablero de ajedrez sobre un toro llano, ¿qué figuras
    están amenazadas por el caballo blanco?

    #+attr_latex: :width 5cm 
    [[./img/formasuniverso6.png]]

  * ¿Qué figuras están amenazadas por el caballo y la reina blancos?

    #+attr_latex: :width 5cm 
    [[./img/formasuniverso7.png]]

  * Las siguientes figuras muestran un toro llano de tres dimensiones.
    Explica cómo se construye e imagina qué verías al mirar en una dirección
    concreta.

    #+attr_latex: :width 5cm 
    [[./img/formasuniverso8.png]]

$\quad$
#+end_statement

**** Ejercicio 5
#+begin_statement
Jugando en la botella de Klein:

  * ¿Cuáles de las siguientes posiciones ganan en el juego del tres en
    raya dentro de una botella de Klein?

    [[./img/formasuniverso10.png]]

  * Analiza cómo hacer tres en línea en la siguiente figura.

    [[./img/formasuniverso11.png]]
#+end_statement

**** Ejercicio 6
#+begin_statement
Actividades:

 * Si un planilandés viviendo en un plano proyectivo cruza el ecuador,
   ¿vuelve como su imagen especular?
 * Una familia de planilandeses vive en un plano proyectivo. Planean
   edificar dos gasolineras separadas cuanto más mejor. ¿Dónde deberían
   construirlas?
 * CP conoce que vive en una esfera o en un plano proyectivo. ¿Cómo
   podría saber cuál de los dos es su mundo?
 * Un segundo planilandés sabe que su Universo es un plano proyectivo o
   una botella de Klein, ¿qué podría hacer para conocer de cuál de los dos
   se trata?

$\quad$
#+end_statement

**** Ejercicio 7
#+begin_statement
Haciendo sumas conexas:

 * Deducir que si a una cinta de Möbius le pagamos un disco por el borde,
   obteneos un plano proyectivo.
 * Corrobora las palabras de Klein: "La cinta de Möbius es divina, si pegas
   dos por su borde obtienes mi botella".
 * Construye usando papel la suma conexa de una cinta de Möbius a un toro
   y a una botella de Klein.
 * Muestra que la suma conexa de un toro con un plano proyectivo es 
   topológicamente equivalente a la suma conexa de una botella de Klein con
   un plano proyectivo.
 * Establece una correspondencia por equivalencia topológica entre las
   superficies de los conjuntos A y B:

   \[
   A = \{
   \mathbb{T}^2\#\mathbb{S}^2,
   \mathbb{P}^2\#\mathbb{P}^2\#\mathbb{P}^2,
   \mathbb{B}^2,
   \mathbb{S}^2\#\mathbb{S}^2\#\mathbb{S}^2,
   \mathbb{P}^2\#\mathbb{T}^2,
   \mathbb{B}^2\#\mathbb{T}^2\#\mathbb{P}^2
   \}
   \]

   \[
   B = \{
   \mathbb{P}^2\#\mathbb{P}^2,
   \mathbb{B}^2\#\mathbb{P}^2,
   \mathbb{S}^2\#\mathbb{S}^2,
   \mathbb{P}^2\#\mathbb{P}^2\#\mathbb{P}^2\#\mathbb{B}^2,
   \mathbb{T}^2,
   \mathbb{T}^2\#\mathbb{P}^2
   \}
   \]
#+end_statement

** Modelo del hiperboloide
*** Modelo
**** Forma cuadrática de Minkowski
En el espacio $n+1$ dimensional $\mathbb{R}^{n+1}$, se define la forma cuadrática de
Minkowski como:

\[
Q(x_0,x_1,\dots,x_n) = x_0^2 - x_1^2 - \dots - x_n^2
\]

Usando las identidades de polarización, podemos calcular su polarización
como:

\[
B(x,y) = x_0y_0 - x_1y_1 - \dots - x_ny_n
\]

**** Hiperboloide
Los puntos de $\mathbb{R}^{n+1}$ que cumplen $Q(x) = 1$ forman un hiperboloide de dos hojas,
o dos componentes conexas. Los puntos de nuestro modelo serán los de la
componente positiva, a la que llamaremos $S$.

**** Distancia hiperbólica
La distancia entre dos puntos $u,v \in S$ viene dada por la fórmula:

\[
d(u,v) = \mathrm{arcosh}(B(u,v))
\]

**** Geodésicas
Las geodésicas del modelo vienen dadas por intersecciones del hiperboloide
con subespacios lineales bidimensionales, que nunca serán vacíos.
* Teoría de Números y Criptografía
** Factorización
*** Métodos básicos de factorización
**** Fuerza bruta
Probando a dividir cada número hasta $\sqrt{n}$.

**** Método de Fermat
Escribimos un número como diferencia de cuadrados para factorizarlo como
$n = t^2 - s^2 = (t+s)(t-s)$.

***** Soluciones en congruencias no triviales
Si $(t,s)$ es una solución no trivial de $x^2 \equiv y^2$, entonces $gcd(n,t+s)\neq 1$
y $gcd(n,t-s) \neq 1$.

*** Método de factor base
Una *base* es un conjunto $B = \{p_0 = -1,p_1,\dots,p_h\}$ donde $p_0,p_1,\dots,p_n$
son enteros primos.

**** Conjunto de candidatos B-números
Un conjunto de candidatos B-números es $\mathbb{Z}_n$ escribiendo la
mitad de números más grandes dentro de la base, como:

\[
\mathbb{Z}_n =
\{0,1\dots,-2,-1\}
\]

Llamamos $\operatorname{abmod}$ a la clase de equivalencia del número en el conjunto 
de candidatos.

**** B-número
Un número $b$ es B-número respecto de $n$ si $\operatorname{abmod}(b^2,n)$ factoriza por los 
elementos de la base $B$.

**** Alfa-vectores
Dado $b$ un B-número, con:

\[
\operatorname{abmod}(b^2,n) = p_0^{e_0}\dots p_h^{e_h}
\]

definimos el *α-vector* como $\alpha vect(b) = (e_0,e_1,\dots,e_h)$.

**** TODO Idea del algoritmo
Sea $S_0 = \{\alpha_0,\dots,\alpha_r\}$ un α-vector del conjunto de B-números.

*** Métodos de elección de la base B y los B-números
**** Algoritmo: voy a tener suerte
Se eligen los $h \in \mathbb{N}$ primeros números primos. Escogemos dos índices
$k_{max} \leq i_{max}$ y calculamos:

  - $\lfloor \sqrt{n}\rfloor, \lfloor \sqrt{2n}\rfloor, \dots, \lfloor \sqrt{k_{max}n}\rfloor$
  - $\lfloor \sqrt{n}\rfloor+1, \lfloor \sqrt{2n}\rfloor+1, \dots, \lfloor \sqrt{k_{max}n}\rfloor+1$
  - $\dots$
  - $\lfloor \sqrt{n}\rfloor + i_{max}, \lfloor \sqrt{2n}\rfloor+i_{max}, \dots, \lfloor \sqrt{k_{max}n}\rfloor+i_{max}$

Entre estos, buscamos B-números y calculamos los α-vectores 
correspondientes.

**** Algoritmo: voy a forzar la suerte
*** Fracciones continuas
**** Fracción continua
Notamos una fracción continua como:

\[
[a_0,a_1,a_2,\dots] =
a_0 + \frac{1}{a_1+\frac{1}{a_2+\dots}}
\]

**** Propiedades de las fracciones continuas
Las fracciones continuas cumplen:

  1. Todo racional se expresa como fracción continua finita.
  2. Todo real se expresa como fracción continua.
  3. Se cumple la fórmula:

     \[\frac{a+\sqrt{d}}{b} = [a_0,[a_1,\dots,a_r]]\]

     Si notamos $[a_0,[a_1,\dots,a_r]] = [a_0,a_1,\dots,a_r,a_1,\dots,a_r,\dots]$.

**** Cálculo de la fracción continua de un real
Sea $x \in \mathbb{R}$, tomamos $a_0 = \lfloor x \rfloor$ y podemos escribir recursivamente la 
fracción continua como:

\[
x = a_0 + \frac{1}{x_1^{-1}}
\]
* Álgebra moderna
** 1. Construcción de anillos
*** 1.1. Anillos
**** Anillos
Un *anillo* es $(R,+,\times,1)$ siendo:

 1) $(R,+)$ un grupo aditivo abeliano.
 2) $(R,\times,1)$ monoide multiplicativo.
 3) $\times$ distributivo con $+$.

Llamamos $0$ al elemento neutro de la suma.

***** Anillos conmutativos
Llamamos *anillo conmutativo* a un anillo con $\times$ conmutativo.

***** Propiedades en anillos
Sea $r_1,r_2 \in R$ anillo:

 - $0r=0=r0$
 - $r_1(-r_2) = -r_1r_2 = (-r_1)r_2$
 - $r(r_1-r_2) = rr_1-rr_2$
 - $r_1+r_2=r_2+r_1$

****** Demostración
Usando distributividad se prueban trivialmente.

**** Morfismos de anillos
Un $f : R \to S$ es homomorfismo de anillos cuando:

  - $f(r_1+r_2) = f(r_1)+f(r_2)$
  - $f(r_1r_2) = f(r_1)f(r_2)$
  - $f(1) = 1$

***** Categoría de los anillos
La composición de dos morfismos de anillos es morfismo de anillos y
la identidad es morfismo de anillos. Los anillos unitales forman así
una categoría $\mathtt{Ring}$.

***** Isomorfismos de anillos
**** Subanillos
**** Retículo de subanillos
**** Ideales
**** Ideales extendidos y contraidos
**** Retículo de ideales
**** Ejemplo: Matrices infinitas
**** Ejemplo: Álgebra de Weyl
Se llama *álgebra de Weyl* al anillo de operadores en los polinomios
generado por $X$ (multiplicación por la indeterminada) y $\frac{\partial}{\partial x}$ (diferenciación);
con la composición como producto.

***** Caracterización
El álgebra de Weyl es isomorfa a:

\[
\frac{K[X,Y]}{(YX-XY-1)}ñ
\]

**** Ejemplo: Anillo de un monoide
Dado un monoide multiplicativo $M$, definimos $R[M]$ como los polinomios que
usan como exponentes los elementos de $M$. Es decir,

\[
\sum_i r_i[m_i]
\]

Y forma un álgebra definiendo:

  - Suma: $\sum_i r_i[m_i] + \sum_i r_i'[m_i] = \sum_i (r_i+r_i')[m_i]$
  - Producto: $\left(\sum_i r_i[m_i]\right)\left(\sum_i r_i'[m_i]\right) = \sum_k \left(\sum_{m_im_j=m_k} (r_ir_j')[m_k]\right)$

***** Generaliza al anillo de polinomios
Nótese que generaliza al anillo de polinomios en una variable cuando 
el monoide es $\mathbb{N}$, y que generaliza al anillo de polinomios en varias 
variables cuando el monoide es $\mathbb{N}^n$.

**** TODO Monoide libre
*** 1.2. Construcción de anillos
**** Anillo cociente
***** Proyección
**** Propiedad universal del anillo cociente
**** Primer teorema de isomorfía
**** Segundo teorema de isomorfía
**** Tercer teorema de isomorfía
**** Producto directo
**** Caracterización del producto por ortogonales centrales idempotentes
**** Anillo opuesto
**** Centro
**** Propiedad universal del anillo de un monoide
**** Anillo de polinomios
**** Propiedad universal del anillo de polinomios
*** 1.3. Módulos
**** R-módulos
***** Caracterización por anillo opuesto
**** Morfismo de R-módulos
**** Submódulos
***** Ideales como submódulos 
**** Módulo cociente
**** Propiedad universal del módulo cociente
**** Retículo de submódulos
***** Intersección de submódulos
***** Suma de submódulos
**** Submódulos maximales
*** TODO 1.4. Categorías y funtores
*** 1.5. La categoría Mod-R
**** Caracterización de monomorfismos y epimorfismos
**** Primer teorema de isomorfía
**** Segundo teorema de isomorfía
**** Tercer teorema de isomorfía
**** Producto directo
**** Suma directa
**** Límites
**** Colímites
**** Ejemplos de límite
**** Cambios de anillo
https://en.wikipedia.org/wiki/Change_of_rings
** 2. Construcción de módulos
*** 2.1. Producto tensor
**** Aplicaciones bilineales
Sean $M$ un R-módulo derecho y $N$ un R-módulo izquierdo. Un homomorfismo de
grupos es R-bilineal si:

  - $\varphi(m_1+m_2,n) = \varphi(m_1,n) + \varphi(m_2,n)$
  - $\varphi(m,n_1+n_2) = \varphi(m,n_1) + \varphi(m,n_2)$
  - $\varphi(mr,n) = \varphi(m,rn)$

**** Producto tensor
Construimos el grupo producto tensor como el grupo libre generado por
los elementos del producto cartesiano, dividido por el grupo generado 
por las relaciones de bilinealidad:

\[
M \otimes_R N = \frac{\langle
(m,n) \mid m \in M, n \in N
\rangle}{B}
\]

Donde $B$ está generado por:

  - $(m_1+m_2,n) - (m_1,n) - (m_2,n)$
  - $(m,n_1+n_2) - (m,n_1) - (m,n_2)$
  - $(mr,n)-(m,rn)$

Nótese que además tenemos la proyección $b : M \times N \to M \otimes N$.

**** Propiedad universal del producto tensor
Sean $M_R, _RN$ módulos con $f : M \times N \to X$ bilineal, existe un
único homomorfismo de grupos $\overline{f} : M \oplus_R N \to X$ tal que conmuta:

\[\begin{tikzcd}
M \times N \rar{b}\drar[swap]{f} & 
M \otimes_R N \dar[dashed]{\exists! \overline{f}} \\
& X
\end{tikzcd}\]

***** TODO Demostración

**** Neutro del producto tensor
Se cumple $M \otimes R \cong M$ y $R \otimes N \cong N$.

**** TODO Producto tensor en anillos conmutativos
**** Producto tensor de álgebras
Si $R,S$ son dos A-álgebras, su producto tensor lo es con el producto
dado por:

\[
(r_1 \otimes s_1)(r_2 \otimes s_2) = (r_1r_2)\otimes(s_1s_2)
\]

***** TODO Inclusiones en el producto tensor de álgebras

**** TODO Producto tensor de álgebras como coproducto
*** 2.2. Módulos a dos lados
**** Módulos a dos lados
Un $M$ R-módulo izquierda y S-módulo derecha se llama *(R;S)-módulo a dos lados*
si cumple:

\[
r(ms)=(rm)s
\]

**** TODO Caracterización de módulos a dos lados
**** TODO Módulos a dos lados balanceados y fieles
**** TODO Propiedad universal del producto tensor como módulo a dos lados
*** 2.3. El retículo de submódulos
**** Categoría de los conjuntos parcialmente ordenados
Tomamos la *categoría de los conjuntos parcialmente ordenados* ${\cal P}$, siendo 
sus morfismos las aplicaciones crecientes:

\[
x \leq y \implies f(x) \leq f(y)
\]

***** Submódulos como conjuntos parcialmente ordenados
Existe el funtor covariante retículo ${\cal L} : \mathtt{Mod-}R \to {\cal P}$ que lleva cada módulo 
en su retículo de submódulos y cada homomorfismo de módulos lo aplica sobre
cada submódulo del retículo:

\[
{\cal L}(f)(N) = f(N)
\]

Y existe el funtor contravariante retículo ${\cal L} : \mathtt{Mod-}R \to {\cal P}$ que lleva cada
módulo en su retículo y cada homomorfismo de módulos lo aplica de manera
inversa sobre cada submódulo del retículo:

\[
{\cal L}(f)(N) = f^{-1}(N)
\]

**** Retículos
Un *retículo* es un conjunto parcialmente ordenado donde todo par de
elementos tiene supremo e ínfimo, llamados $a \vee b$ y $a \wedge b$.

**** Propiedades del retículo
En todo retículo $({\cal L}, \leq)$ se verifican:

 1) Idempotencia, $a \vee a = a$
 2) Conmutatividad, $a \vee b = b \vee a$
 3) Asociatividad, $a \vee (b \vee c) = (a \vee b) \vee c$
 4) Absorción, $a \vee (a \wedge c) = a$

Y sus duales:

 1) Idempotencia, $a \wedge a = a$
 2) Conmutatividad, $a \wedge b = b \wedge a$
 3) Asociatividad, $a \wedge (b \wedge c) = (a \wedge b) \wedge c$
 4) Absorción, $a \wedge (a \vee c) = a$

**** Retículo abstracto
Llamamos *retículo abstracto* a un conjunto $L$ con operaciones $\vee,\wedge$ que
cumplen las propiedades de retículo.

***** Orden en un retículo abstracto
Un retículo abstracto determina una relación de orden, y además
se cumple en él:

\[
a \vee b = b \iff a \wedge b = a
\]

****** TODO Demostración
******* Relación de orden
******* Propiedad
***** Homomorfismo de retículos abstractos
Un homomorfismo de retículos abstractos es una aplicación preservando
supremos e ínfimos.

\[
f(a\wedge b) = f(a) \wedge f(b) \qquad f(a\vee b) = f(a) \vee f(b)
\]

***** Categoría de retículos abstractos
La categoría de retículos abstractos contiene a los retículos y los
homomorfismos de retículos entre ellos. Es una categoría isomorfa
a la categoría de conjuntos parcialmente ordenados.

**** Retículo de submódulos de un módulo
Los submódulos forman un retículo con:

  - $N \vee N' = N + N'$
  - $N \wedge N' = N \cap N'$

**** Retículos acotados
Un retículo con cero y uno se llama acotado, donde:

  - El elemento cero cumple: $a \wedge 0 = 0$
  - El elemento uno cumple:  $a \vee 1 = 1$

**** Retículos modulares
Llamamos retículo modular al que cumple la *ley modular*:

\[
N_1 \vee (N_2 \wedge N_3) = (N_1 \vee N_2) \wedge N_3
\]

***** El retículo de submódulos es modular
Los submódulos forman retículos modulares.

****** TODO Demostración

**** Retículos completos
Un retículo en el que existe el supremo e ínfimo de cualquier familia de
submódulos se dice *completo*.

***** El retículo de submódulos es completo
El retículo de submódulos es completo, siendo el supremo e ínfimo de
cada familia $\{ N_i \mid i \in I\}$:

  - $\bigvee N_i = \sum N_i$

  - $\bigwedge N_i = \bigcap N_i$

**** TODO Retículos superiormente continuos y compactamente generados
*** 2.5. Módulos finitamente generados
**** TODO Módulos finitamente generados
**** TODO Construcción de finitamente generados
**** TODO Submódulo maximal
**** TODO Caracterización de finitamente generados
**** TODO Homomorfismos a la suma directa
**** TODO Conmutación con sumas directas
**** TODO Compacidad
**** TODO Módulos noetherianos
**** TODO Módulos noetherianos: propiedades
*** TODO 2.6. Módulos noetherianos
** 3. Sumas directas y productos directos de módulos
*** 3.1. Biproducto de módulos
**** Biproducto de módulos
Se llama *biproducto de módulos* a la terna $(M_1\oplus M_2, \{p_1,p_2\}, \{q_1,q_2\})$,
con las proyecciones e inclusiones de producto y coproducto.

***** Propiedades del biproducto
Las composiciones de proyecciones e inyecciones cumplen:

 - $p_1q_1 = id_1$
 - $p_2q_2 = id_2$
 - $p_1q_2 = 0$
 - $p_2q_1 = 0$
 - $q_1p_1 + q_2p_2 = id$

*** TODO 3.2. Independencia y sumas directas
*** TODO 3.3. Módulos libres
*** TODO 3.4. Descomposición de anillos
** Ejercicios
*** Semana 1
#+begin_statement
Prueba que los ideales (biláteros) del anillo $M_n(R)$ son de la forma
$M_R(\mathfrak{a})$, para un ideal (bilátero) $\mathfrak{a} \subseteq R$.
#+end_statement

Llamamos $E_{ij}$ a la matriz que tiene todas sus entradas nulas excepto
la entrada $i,j$. Dada $N$, una matriz con elementos $N = (n_{ij})_{i,j}$, el
producto de matrices es:

\[
E_{ia}NE_{bj} = n_{ab}E_{ij}
\]

Es decir, si una matriz $N$ está en un ideal bilátero $J$, todas las 
matrices de la forma $n_{ab}E_{ij}$ estarán también en el ideal.

Esto nos da por un lado que los elementos que aparecen en matrices 
del ideal forman un ideal $I$, si $a,b$ están en el ideal, $(a+\alpha b)E_{ij}$ 
estará en el ideal. Y además, cualquier matriz de la forma $xE_{ij}$ para
$x \in I$ está en el ideal. Así, el ideal es de la forma:

\[
J = M_R(\mathfrak{a})
\]

*** Semana 2
#+begin_statement
Prueba que $A[|X|]$, el anillo de las series formales de potencias en una
indeterminada $X$, es isomorfo al límite inverso del sistema de anillos
dirigido inferiormente $(\{\frac{A[X]}{(X^n)}\}, \{f_{n,m}\}_{n \geq m})$, donde $f_{n,m} : \frac{A[X]}{(X^n)} \to \frac{A[X]}{(X^m)}$ es
el homomorfismo de anillos definido por $f_{n,m}(\overline{X}) = \overline{X}$, si $n \geq m$.
#+end_statement

**** Subanillo isomorfo
Empezamos definiendo un subanillo del producto de los anillos $\frac{A[X]}{(X^n)}$.
Nótese que es subanillo por ser las funciones $f_{i,j}$ morfismos de anillos:

\[
H = \left\{
(p_i)_i \in \prod_i \frac{A[X]}{(X^i)}
\;\middle|\;
f_{i,j}(m_i) = m_j
\right\}
\]

Comprobaremos que es isomorfo a $A[|X|]$; para ello definimos la función
siguiente:

\[
g(a_0+a_1X+a_2X^2+\dots) = (a_0,a_0+a_1X,a_0+a_1X+a_2X^2,\dots)
\]

Es trivialmente inyectiva porque si $p \neq q$, se diferenciarán en el primer
polinomio en el que tengan un coeficiente distinto. Es trivialmente
sobreyectiva porque si tengo un elemento de la forma $(u_0,u_1,\dots) \in H$,
se debe tener $u_n = u_{n-1} + a_n X_n$, para $u_{n-1}$ de grado $n-1$. Esto asegura
que el elemento será de la forma:

\[
(a_0,a_0+a_1X, a_0+a_1X+a_2X^2,\dots) = g(a_0+a_1X+a_2X^2+\dots)
\]

**** Límite inverso
Para probar que es límite inverso, probaremos que si existiera un $Z$ con
morfismos $\phi_n : Z \to \frac{A[X]}{(X^n)}$ cumpliendo $\phi_m = f_{n,m} \circ \phi_n$, existiría un único 
morfismo $Z \to H$ haciendo conmutar el diagrama:

\[\begin{tikzcd}
\frac{A[X]}{(X^0)} \rar &
\frac{A[X]}{(X^1)} \arrow{rr} &&
\frac{A[X]}{(X^2)} \rar &
\dots \\
&&
H \arrow{ull} \ular \urar \arrow{urr}
& & \\
& &
Z
\arrow[bend left]{uull} \arrow[bend left]{uul}
\arrow[bend right]{uurr} \arrow[bend right]{uur}
\uar[dashed]{!\exists}
&&
\end{tikzcd}\]

Ahora bien, dado $Z$ y los morfismos $\phi_n$, por propiedad universal del
producto directo, tenemos que existe un único morfismo $h: Z \to \prod_i \frac{A[X]}{(X^i)}$,
cumpliendo además que $\phi_n = \pi_n \circ h$. Aplicando $f_{n,m}$ tenemos:

\[
f_{n,m} \circ \pi_n \circ h = f_{n,m} \circ \phi_n =
\phi_m = \pi_m\circ h
\]

Lo que nos da que $im(h) \subseteq H$ y por tanto el morfismo buscado, que hereda
la unicidad.

*** Semana 3
**** Ejercicio 1.5.
#+begin_statement
Sea $R$ un anillo y $0 \neq e \in R$ un elemento idempotente; llamamos $f = 1-e$.

 1. Prueba que $eRe$ y $fRf$ son anillos.
 2. Prueba que $eRf$ es un $(eRe;fRf)$ módulo, y $fRe$ es un $(fRf,eRe)$ módulo.
 3. Prueba que existe un homomorfismo inyectivo de anillos

    $\lambda : R \longrightarrow 
    \begin{pmatrix}
    eRe & eRf \\
    fRe & fRf 
    \end{pmatrix}$, definido: $\lambda(r) = \begin{pmatrix} ere&erf\\fre&frf \end{pmatrix}$ para cada $r \in R$.

 4. Prueba que existe un isomorfismo de grupos abelianos
    $Hom_R(eR_R,fR_R) \cong fRe$, y un isomorfismo de anillos $End_R(eR_R) \cong eRe$.
 5. Prueba que:

    \[
    R \overset{\beta}\cong End_R(R_R) = 
    End_R((eR\oplus fR)_R) \cong \begin{pmatrix} eRe&eRf\\fRe&fRf \end{pmatrix}
    \]

    siendo $\beta(r)(x) = rx$. Como consecuencia $\lambda$ es un isomorfismo de anillos.

$\quad$
#+end_statement

***** Punto 1
Por propiedad distributiva, son cerrados con la misma suma que $R$. Son
trivialmente cerrados con el producto y nos falta comprobar que contiene
un elemento unidad, que es $e$ y es neutro gracias a ser idempotente:

\[
e(ere) = ere = (ere)e
\]

Nótese que $f$ es también idempotente y se repite el razonamiento.

***** Punto 2
Comprobamos que $eRf$ es cerrado para la suma, y además:

 - $(ese)(erf) = e(ser)f$
 - $(erf)(ftf) = e(rft)f$

Por lo que es un módulo a izquierda para $eRe$ y a derecha para $fRf$.

Nótese que el caso de $fRe$ es simétrico.

***** Punto 3
Nótese que $\lambda$ preserva sumas trivialmente. Debemos comprobar que respeta
la unidad y el producto. Notamos primero gracias a que $ef=0$ tenemos:

\[
\lambda(1) = \begin{pmatrix}e&0\\0&f\end{pmatrix}
\]

Que se comprueba trivialmente que es el uno de su anillo, ya que es neutro
respecto al producto:

\[\begin{pmatrix}e&0\\0&f\end{pmatrix}\begin{pmatrix}er_1e&er_2f\\fr_3e&fr_4f\end{pmatrix} =\begin{pmatrix}er_1e&er_2f\\fr_3e&fr_4f\end{pmatrix}\]

Por último comprobamos que el producto se preserva:

\[\begin{pmatrix}ere&erf\\fre&frf\end{pmatrix}\begin{pmatrix} ese & esf \\ fse & fsf \end{pmatrix}
= \begin{pmatrix}erse&ersf\\frse&frsf\end{pmatrix}\]

Donde usamos crucialmente que $erese+erfse=er(e+f)se=erse$.

***** Punto 4
****** Isomorfismo de grupos abelianos
Suponiendo que se consideran los homomorfismos como módulos a derecha
de $R$, podemos llevar cada homormofismo $\lambda$ a $\lambda(e)e$ y cada elemento $fre$
al homomorfismo $\psi(x) = (fre)x$.

Comprobamos que esto da una biyección para elemento cualquiera $fre \in fRe$
y $\lambda \in Hom(eR,fR)$ comprobando que la composición es la identidad:

\[
fre \mapsto \psi_{fre} \mapsto \psi_{fre}(e)e = freee = fre
\]
\[
\lambda(ex) \mapsto \lambda(e)e \mapsto \lambda(e)e(ex) = \lambda(ex)
\]

Donde hemos usado en el último paso que $\lambda$ es homomorfismo de R-módulos
a derecha. Que esto preserva la suma es trivial.

****** Isomorfismo de anillos
En este caso tenemos un isomorfismo de grupos abelianos dado por el
caso anterior. Además, es operación multiplicativa al tenerse:

\[
(\psi\circ\varphi)(e)e = \psi(e)\varphi(e)e
\]

Por ser homomorfismos de módulos a derecha. Y es unital por tenerse:

\[
id(e)e = e
\]

***** Punto 5
****** Primer isomorfismo
Trivialmente $\beta$ es inyectivo porque $\beta(r)$ aplica la unidad en $r$.
Que es sobreyectivo es trivial porque cada función está determinada
por dónde lleva la unidad. Por ser homomorfismo de R-módulos:

\[
\varphi(r) = \varphi(1)r
\]

****** Segundo isomorfismo
Nótese que dada una $\varphi \in End_R(eR\oplus fR)$, podemos descomponer su aplicación
a cualquier elemento como:

\[
\varphi(er+fr) = \varphi(er)+\varphi(fr) = e\varphi(er)+f\varphi(er)+
e\varphi(fr)+f\varphi(fr)
\]

Por lo que queda determinada por dos endomorfismos entre $eR$ y $fR$ y
dos homomorfismos de $eR$ a $fR$ y de $fR$ a $eR$; y se puede escribir como:

\[
\varphi(ex+fy) = \begin{pmatrix}f_1&f_2\\f_3&f_4\end{pmatrix}\begin{pmatrix}ex\\fy\end{pmatrix}
\]

Con los isomorfismos anteriores tenemos lo buscado.

****** Isomorfismo de anillos
Notamos trivialmente que el isomorfismo así determinado es $\lambda$.
Dado $r$, podemos ver que se divide como:

\[
rx = erex + erfx + frex + frfx
\]

Donde cada elemento pertenece al buscado.

**** Ejercicio 1.6.
#+begin_statement
Sea $R$ un anillo, $0\neq e \in R$ un elemento idempotente, y $f = 1 - e$. Para cada
R-módulo derecha $M$ se define $Me = \{me \mid m \in M\}$, y $Mf = \{mf \mid m \in M\}$.

 1. Prueba que $Me$ es un $eRe$ módulo derecha y $Mf$ un $fRf$ módulo derecha.
 2. Prueba que $Me \times Mf$ es un $\begin{pmatrix}eRe&eRf\\fRe&fRf\end{pmatrix}$ módulo derecha con estructura
    dada por,

    \[
    (m_1e, m_2f)
    \begin{pmatrix}em_{11}e&em_{12}f\\fm_{21}e&fm_{22}ff\end{pmatrix} =
    (m_1em_{11}e + m_2fm_{21}e, m_1em_{12}f + m_2fm_{22}f)
    \]

 3. Prueba que $h : M \longrightarrow Me \times Mf$, definido $h(m) = (me,mf)$, es un isomorfismo
    de R-módulos derecha, donde la estructura de $Me \times Mf$ está dada vía $\lambda$.
    Observa que $Me$ y $Mf$ son subgrupos de $M$, pero no necesariamente submódulos.

$\quad$
#+end_statement

***** Punto 1
Siendo $me \in Me$, tenemos que $me(ere) = (mer)e \in Me$, donde usamos que
$M$ es módulo a derecha. De la misma forma se cumple para $f$, que es
idempotente.

***** Punto 2
Simplemente tenemos que comprobar que la aplicación de multiplicar por
la matriz es lineal en $(m_1,m_2)$, y además, que los elementos vuelven
a estar en $Me \times Mf$ por escribirse como:

 - $(m_1em_{11})e + (m_2fm_{21})e$
 - $(m_1em_{12})f + (m_2fm_{22})f$

Usando de nuevo que $M$ es módulo a derecha.

***** Punto 3
Tenemos que cada elemento se escribe de forma única como $m = me+mf$.
Si tuviéramos otra suma $m = ae + bf$, se tendría $me=ae$ y $mf=bf$ al
multiplicar por cada uno de los idempotentes.

Tenemos por tanto una biyección, que además es lineal y preserva la
multiplicación por la derecha:

\[
(mre,mrf) = (me,mf)\begin{pmatrix}ere&erf\\fre&frf\end{pmatrix}
\]

Observamos que $Me$ y $Mf$ son cerrados para la suma. Pero no tienen por
qué ser cerrados como módulo. Nótese que puede darse el caso de que
$mer \notin Me$, como ocurre en las matrices, donde hay idempotentes no
centrales:

\[ e\begin{pmatrix}
a & b \\ c & d
\end{pmatrix} = \begin{pmatrix}
1 & 0 \\ 0 & 0
\end{pmatrix} \begin{pmatrix}
a & b \\ c & d
\end{pmatrix} = \begin{pmatrix}
a & b \\ 0 & 0
\end{pmatrix}\]

Que no puede pertenecer al $Me$ porque cambia al multiplicarla a la derecha
por $e$.
*** Semana 4
**** Ejercicio 1.7.
#+begin_statement
Si $K$ es un cuerpo, se considera el anillo:

\[
R = \begin{pmatrix}
K & K \\ 0 & K
\end{pmatrix}
\]

 1) Estudia los ideales derecha de $R$.
 2) Estudia los ideales izquierda de $R$.
 3) Estudia los ideales biláteros de $R$.

Ver también ejercicios anteriores.
#+end_statement

***** Ideales derecha
La multiplicación por un elemento del ideal sería:

\[\begin{pmatrix}
a & b \\ 0 & d
\end{pmatrix}\begin{pmatrix}
k_1 & k_2 \\ 0 & k_3
\end{pmatrix}  = \begin{pmatrix}
k_1a & k_2a+k_3b \\ 0 & k_3d
\end{pmatrix}\]

Estudiando cada combinación de $a,b,d$ nulos o no nulos, se obtienen
los ideales siguientes:

 - El ideal total, $\begin{pmatrix}K & K \\ 0 & K\end{pmatrix}$.

 - Suponiendo $a=0$, $\langle\begin{pmatrix}0 & k \\ 0 & 1\end{pmatrix}\rangle$.

 - Suponiendo $a=0,d=0$, $\begin{pmatrix}0 & K \\ 0 & 0\end{pmatrix}$.

 - Suponiendo $a=0,b=0$, $\begin{pmatrix}0 & 0 \\ 0 & K\end{pmatrix}$.

 - Suponiendo $d=0$, $\begin{pmatrix}K & K \\ 0 & 0\end{pmatrix}$.

 - El ideal trivial, $\begin{pmatrix}0 & 0 \\ 0 & 0\end{pmatrix}$.

***** Ideales izquierda
La multiplicación por un elemento del ideal es:

\[\begin{pmatrix}
k_1 & k_2 \\ 0 & k_3
\end{pmatrix} \begin{pmatrix}
a & b \\ 0 & d
\end{pmatrix} = \begin{pmatrix}
k_1a & k_1b+k_2d \\ 0 & k_3d
\end{pmatrix}\]

Estudiando cada combinación de $a,b,d$ nulos o no nulos, se obtienen
los ideales siguientes:

 - El ideal total, $\begin{pmatrix}K & K \\ 0 & K\end{pmatrix}$.

 - Suponiendo $d=0$, $\begin{pmatrix}K & K \\ 0 & 0\end{pmatrix}$.

 - Suponiendo $a=0$, $\begin{pmatrix}0 & K \\ 0 & K\end{pmatrix}$.

 - Suponiendo $a=0,d=0$, $\begin{pmatrix}0 & K \\ 0 & 0\end{pmatrix}$.

 - Suponiendo $a=0,b=0$ $\begin{pmatrix}K & 0 \\ 0 & 0\end{pmatrix}$.

 - El ideal trivial, $\begin{pmatrix}0 & 0 \\ 0 & 0\end{pmatrix}$.

***** Ideales biláteros
Buscamos los ideales que lo son a izquierda y derecha:

$\begin{pmatrix}K & K \\ 0 & K\end{pmatrix}$ $\begin{pmatrix}K & K \\ 0 & 0\end{pmatrix}$ $\begin{pmatrix}0 & K \\ 0 & K\end{pmatrix}$ $\begin{pmatrix}0 & K \\ 0 & 0\end{pmatrix}$ $\begin{pmatrix}0 & 0 \\ 0 & 0\end{pmatrix}$

**** Ejercicio 1.8.
#+begin_statement
Estudia los ideales derecha e izquierda del anillo:

\[
R = \begin{pmatrix}\mathbb{Q}&\mathbb{R}\\0&\mathbb{R}\end{pmatrix}
\]

 1) Prueba que $R$ es un anillo artiniano derecha y noetheriano derecha.
 2) Prueba que $R$ no es un anillo artiniano izqierda ni noetheriano izquierda.

$\quad$
#+end_statement

***** Ideales derecha
Los ideales no triviales a la derecha son los siguientes:

- $\begin{pmatrix} 0 & 0 \\ 0 & \mathbb{R} \end{pmatrix}$

- $\langle\begin{pmatrix} 0 & k \\ 0 & 1 \end{pmatrix}\rangle$

- $\begin{pmatrix} \mathbb{Q} & \mathbb{R} \\ 0 & 0 \end{pmatrix}$

- $\begin{pmatrix} \mathbb{Q} & \mathbb{R} \\ 0 & \mathbb{R} \end{pmatrix}$

Habiendo sólo una cantidad finita de ideales, el anillo será artiniano
y noetheriano.

***** Ideales izquierda
Considerando de nuevo los casos y teniendo esta vez en cuenta que el
primer coeficiente está en $\mathbb{Q}$.

- $\begin{pmatrix} \mathbb{Q} & \mathbb{K} \\ 0 & 0 \end{pmatrix}$, para cualquier $\mathbb{K}$ extensión de cuerpos $\mathbb{Q}\subset \mathbb{K}\subset\mathbb{R}$.

- $\begin{pmatrix} 0 & \mathbb{R} \\ 0 & \mathbb{R} \end{pmatrix}$

- $\begin{pmatrix} \mathbb{Q} & \mathbb{R} \\ 0 & \mathbb{R} \end{pmatrix}$

Comprobamos que no es artiniano ni noetheriano porque podemos crear
cadenas que rompen la condición de cadena ascendente y descendente.
Sabiendo que los reales tienen dimensión infinita sobre los racionales
como espacio vectorial, creamos ambas cadenas añadiendo y retirando
progresivamente vectores de la base.

*** Semana 6
#+begin_statement
Sea $M$ un grupo abeliano finitamente generado y libre de torsión.
Prueba que $M$ es un grupo libre.
#+end_statement

Si no fuera libre, cada conjunto de generadores
$\left\{ m_1,\dots,m_{n} \right\}$ debería cumplir ecuaciones de la forma

\[n_1m_1+ \dots + n_tm_t = 0,\]

y entre todos los posibles conjuntos de generadores de cardinalidad
mínima y combinaciones, podemos elegir una que minimice $|n_1|+\dots + |n_t|$.
Ahora, si hay una combinación en la que $|n_i|<|n_j|$ para dos $i\neq j$,
podemos usar que

\[
n_im_i + n_jm_j = (n_i-n_j)m_i + n_{j}(m_j-m_i)
\]

para reescribir la relación, teniendo otro sistema de generadores
equivalente $\left\langle m_1,\dots,m_i,m_j,\dots,m_{t} \right\rangle = \left\langle m_1,\dots,m_i,m_j-m_i,\dots,m_t \right\rangle$ que
tiene un $|n_1|+\dots + |n_t|$ menor. Así, en el mínimo, $|n_i| = d$ para cualquier
índice. Pero este $d$ no puede ser mayor que $1$ porque si no se tendría un
elemento de torsión

\[
d \left( \frac{n_1}{d}m_1 + \dots + \frac{n_t}{d}m_t \right) = 0.
\]

Así, hemos llegado a una relación en la que un generador puede ponerse
como suma y diferencia de los otros, 

\[
m_1 = \pm m_2 \pm m_3 \pm \dots \pm m_{t},
\]

contraviniendo la minimalidad del
sistema de generadores

*** Semana 7
#+begin_statement
Sea $R$ un anillo con un único ideal izquierda maximal $\mathfrak{a}$.

 1) Prueba que $\mathfrak{a}$ es un ideal bilátero.
 2) Prueba que $\mathfrak{a}$ es el único ideal derecha maximal.
 3) Prueba que $R/\mathfrak{a} = {\cal U}(R) = R^{\times}$, el conjunto de los elementos 
    invertibles de $R$.

Un anillo con un único ideal derecha maximal se llama *anillo local*.
#+end_statement

Nótese que por Teorema de Krull, todo ideal propio (izquierda,
derecha, bilátero) está contenido en un ideal maximal (izquierda,
derecha, bilátero). Todo elemento no unidad está contenido en un
ideal maximal (izquierda, derecha, bilátero).

**** Primer punto
Si $x \in \mathfrak{a}$, sabemos que no puede ser unidad; así, $xy$ tampoco puede serlo 
para ningún $y \in R$, y como no puede serlo, debe estar contenido en algún
ideal maximal izquierda, que debe ser $\mathfrak{a}$.

**** Segundo punto
Usando el tercer punto, cualquier elemento que estuviera en un ideal
derecha maximal que no estuviera en el único ideal bilátero que existe
debería ser una unidad.

**** Tercer punto
Si hubiera algún $x + \mathfrak{a}$ no invertible, se tendría que $\left\langle x \right\rangle$ generaría un
ideal propio que debería estar contenido en un maximal. Este maximal
debería ser $\mathfrak{a}$, y por tanto $x = 0$.

*** Semana 8
#+begin_statement
Sea $R$ un anillo y $e \in R$ un elemento idempotente

 1) para cada ideal derecha $\mathfrak{a} \subseteq R$ prueba que $\mathfrak{a} \cap Re = \mathfrak{a}e$.
 2) para cada ideal $\mathfrak{A} \subseteq R$ prueba que $\mathfrak{A} \cap Re = \mathfrak{A}e$.
 3) $eRe$ es un anillo y $\mathfrak{A} \mapsto e\mathfrak{A}e$ define una aplicación sobreyectiva que respeta
    el orden del retículo de los ideales de $R$ en el retículo de los ideales de
    $eRe$.
 4) prueba que tenemos un funtor $\text{Mod-}R \to \text{Mod-}eRe$, definido $M \mapsto Me$.
 5) si $M$ es un $R\text{-módulo}$ derecha simple, prueba que $Me = 0$ ó $Me$ es un
    $eRe\text{-módulo}$ derecha simple.
 6) ¿se conservan los $R\text{-módulos}$ derecha proyectivos?
 7) ¿se conservan los $R\text{-módulos}$ izquierda inyectivos?
#+end_statement

**** Punto 1
Sea $x \in \mathfrak{a} \cap Re$, entonces $x = xe \in \mathfrak{a}e$. Sea $ae \in \mathfrak{a}e$, es trivial que $ae \in \mathfrak{a} \cap Re$.

**** Punto 2
Un ideal es un ideal derecha.

**** Punto 3
Se comprueba que $eRe$ es anillo con unidad $e$. El producto de dos elementos
sigue siendo bilineal con $ere \cdot ese = erese$. Si $S \subseteq R$, es claro que $eSe \subseteq eRe$.
Es sobreyectiva porque si $I$ es $eRe\text{-ideal}$, podemos comprobar que $RIR$ es un
$R\text{-ideal}$ y que $eRIRe = eReIeRe = I$.

**** Punto 4
El funtor llevará $f \colon M \to N$ a $\widetilde f \colon Me \to Ne$ definida como

\[\widetilde f(me) = f(m)e.\]

Es funtor por cumplir $\widetilde g \circ \widetilde f (me) = (g \circ f(m))e$.

**** Punto 5
$Me$ sería un submódulo, así que podría ser $Me = 0$ o $Me = M$.
En el segundo caso sería un $eRe\text{-módulo}$ por ser un $R\text{-módulo}$,
y en ese caso, como $M = Me$, se tendría que si hubiera un
submódulo $A$ de $M$ como $eRe\text{-módulo}$, sería de $M$ como $R\text{-módulo}$
por tenerse $AR = ((Ae)R)e = A(eRe) = A$.

**** Punto 6
Si tenemos $P \oplus H \cong R^{(I)}$, multiplicando, $Pe \oplus He \cong (Re)^{(I)}$. Pero
sabemos que $Re \cong eRe$ como $eRe\text{-módulo}$.

**** Punto 7
Si $Q$ es un submódulo izquierda inyectivo, para cualquier $R\text{-módulo}$ $M$
con $Q \leq M$ existe un $Q \leq K$ tal que $K \oplus Q = M$, como producto directo
interno.

Sea ahora un $eRe\text{-módulo}$ $N$ tal que $Qe \leq N$. Tenemos que $Ne = N$ por
ser $e$ unidad del anillo. Como $Q$ es inyectivo, existe un $K$ tal que
$Q \cap K = \left\{ 0 \right\}$ y $Q + K = Q + N$. Si multiplicamos por $e$ tenemos

\[
Qe + Ke = Qe + N = N.
\]

De aquí se tiene que $Ke \cap N = Ke$. Entonces, $Ke \subset K \cap N$ y dado $l \in K \cap N$,
se tiene que como $l \in N$, $le=l$, luego $l \in Ke$. Así, $Ke = K \cap N$, tenemos

\[
Qe + K \cap N = N,
\]

y como $Q \cap K = \left\{ 0 \right\}$, se tiene $Qe \cap K = \left\{ 0 \right\}$ y por tanto $Qe \cap (K\cap N) = \left\{ 0 \right\}$.

** Trabajos
*** Funtores adjuntos
**** Transformaciones naturales
#+begin_definition
Dados dos funtores $S,T : A \to B$, una *transformación natural* $\tau : S \Longrightarrow T$ 
es una función asignando a cada objeto $a \in A$ un morfismo $Sa \to Ta$ y 
cumpliendo el siguiente diagrama conmutativo:

\[\begin{tikzcd}
a \dar{f} & & Sa \rar{\tau_a}\dar{Sf} & Ta \dar{Tf} \\
a' & & Sa' \rar{\tau_{a'}} & Ta'
\end{tikzcd}\]

En este caso, decimos que $\tau_a$ es /natural en/ $a$.
#+end_definition

#+begin_definition
Llamamos *isomorfismo natural* a la transformación natural en la que
cada componente $\tau_a$ tiene una inversa. Podemos definir una transformación
natural inversa $\tau^{-1}$ que tiene por componentes a cada una de las inversas.
#+end_definition

***** Composición vertical de transformaciones naturales
#+begin_definition
Dados funtores $R,S,T : {\cal A} \to {\cal B}$ y transformaciones naturales $\tau : S \Longrightarrow T$
y $\sigma : R \Longrightarrow S$, podemos componerlas componente a componente para formar
una *transformación naturalcomposición vertical* $\tau \circ \sigma$.

\[\begin{tikzcd}
Rc \rar{Rf}\dar{\sigma_c}\arrow[dd,bend right=90] &
Rc' \dar{\sigma_{c'}} \arrow[dd,bend left=90] \\
Sc \rar{Sf} \dar{\tau_c} & Sc' \dar{\tau_{c'}} \\
Tc \rar{Tf} & Tc' 
\end{tikzcd}
\]

#+end_definition

Nótese que la naturalidad se preserva, ya que si los dos cuadrados
pequeños son conmutativos, conmuta todo el diagrama.

***** Composición horizontal de transformaciones naturales
#+begin_definition
Dados funtores $S,T : {\cal A} \longrightarrow {\cal B}$ y $S',T' : {\cal B} \longrightarrow {\cal C}$ y dadas transformaciones
naturales $\tau : S \Longrightarrow T$ y $\tau' : S' \Longrightarrow T'$, podemos crear una transformación
natural entre los funtores compuestos, $\tau' \ast \tau$:

\[\begin{tikzcd}
S'Sx \arrow{rr}{(\tau' \ast \tau)_x} \dar &&
T'Tx \dar \\
S'Sy \arrow{rr}{(\tau' \ast \tau)_y} &&
T'Ty
\end{tikzcd}\]

Cada componente se crea aprovechando la siguiente igualdad:

\[
(\tau' \ast \tau) = T'\tau \circ \tau' = \tau' \circ S'\tau
\]
#+end_definition

Y puede comprobarse que constituye una transformación natural.

***** Categoría de los funtores
#+begin_definition
Dadas ${\cal A},{\cal B}$ categorías, los funtores entre ellas forman una *categoría de funtores* 
que llamaremos $Funct({\cal A},{\cal B})$ y que tiene como morfismos a las transformaciones 
naturales con la composición vertical:

\[
Nat(S,T) = \{ \tau \mid \tau : S \Longrightarrow T \}
\]
#+end_definition

Nótese que la composición es asociativa y que consta de una identidad
en la transformación natural de cada funtor consigo mismo que tiene
como componentes identidades en cada objeto.

**** Definición de funtores adjuntos por naturalidad
#+begin_definition
Una *adjunción* entre categorías ${\cal A}$ y ${\cal B}$ es un par de funtores $F:{\cal A} \to {\cal B}$ y
$G: {\cal B} \to {\cal A}$ con una familia de isomorfismos $\varphi_{a,b} : Hom(Fa,b) \cong Hom(a,Gb)$
que determinan transformaciones naturales en ambas componentes.
#+end_definition

Notamos al par de funtores adjuntos como $F \dashv G$. Llamamos a $F$ adjunto
izquierdo y a $G$ adjunto derecho.

***** Condiciones de naturalidad
Las condiciones de naturalidad de esa familia de isomorfismos equivalen
a que los siguientes diagramas conmuten:

\[\begin{tabular}{cc} \begin{tikzcd}
Hom(Fa,b) \rar{\varphi_{a,b}} \dar[swap]{f_\ast} & 
Hom(a,Gb) \dar{(Gf)_\ast} \\
Hom(Fa,b') \rar{\varphi_{a,b'}} &
Hom(a,Gb')
\end{tikzcd} &
\begin{tikzcd}
Hom(Fa,b) \rar{\varphi_{a,b}} \dar[swap]{(Fg)^\ast} & 
Hom(a,Gb) \dar{g^\ast} \\
Hom(Fa',b) \rar{\varphi_{a,b'}} &
Hom(a',Gb)
\end{tikzcd} \end{tabular}\]

Nótese que cada uno de ellos expresa la naturalidad entre los dos bifuntores
cuando se fija un argumento. Es decir, hay dos isomorfismos naturales

 1) $Hom(F-,b) \Longrightarrow Hom(-,Gb)$.
 2) $Hom(Fa,-) \Longrightarrow Hom(a,G-)$.

**** Definición por unidad y counidad
#+begin_definition 
Una *adjunción* entre categorías ${\cal A}$ y ${\cal B}$ es un par de funtores $F:{\cal A} \to {\cal B}$ y
$G: {\cal B} \to {\cal A}$ con dos transformaciones naturales:

  - La *unidad*:   $\eta : 1_{\cal A} \Longrightarrow GF$
  - La *counidad*: $\epsilon: FG \Longrightarrow 1_{\cal B}$

Cumpliendo que las composiciones siguientes dan la identidad:

 - $F \overset{F \eta} \Longrightarrow FGF \overset{\varepsilon F}\Longrightarrow F$
 - $G \overset{\eta G} \Longrightarrow GFG \overset{G \varepsilon}\Longrightarrow G$
#+end_definition

Demostraremos que esta definición es equivalente a la anterior.

***** Equivalencia de definiciones: desde familia de isomorfismos a unidades
#+begin_theorem
Dada una adjunción en términos de una familia de isomorfismos, podemos
construir una adjunción en términos de unidad y counidad.
#+end_theorem

#+begin_proof
/Paso 1: Construcción de la unidad y la counidad./

Supongamos que tenemos la familia de transformaciones naturales
$\varphi_{a,b} : Hom(Fa,b) \to Hom(a,Gb)$. Particularizaremos los cuadrados de
naturalidad en los dos casos $b = Fa$ y $a = Gb$ para crear la unidad y
la counidad.

\[\begin{tikzcd}
Hom(Fa,Fa) \arrow{d}[swap]{(Ff)^\ast} \arrow{r}{\varphi} & 
Hom(a,GFa) \arrow{d}{(f)^\ast} \\
Hom(Fa', Fa) \arrow{r}{\varphi} &
Hom(a',GFa)
\end{tikzcd}\]

Si tomamos la identidad $1_{Fa}$ y llamamos $\eta_a = \varphi(1_{Fa})$, tenemos que
$\eta \circ f = \varphi(Ff)$ por conmutatividad.

Si damos la vuelta al isomorfismo $\varphi$ para tomar $\varphi^{-1}$, llamarlo de la
misma forma y repetir el mismo proceso:

\[\begin{tikzcd}
Hom(FGb,b) \arrow{d}[swap]{(Ff)^\ast} & 
Hom(Gb,Gb) \arrow{d}{(f)^\ast} \lar[swap]{\varphi} \\
Hom(FGb', b) &
Hom(Gb',Gb) \lar{\varphi}
\end{tikzcd}\]

Nótese que aquí usamos $\varphi$ para notar un isomorfismo y su inversa;
dependerá sólo del contexto determinar cuál estamos usando.
Si tomamos la identidad $1_{Gb}$ y llamamos $\varepsilon_b = \varphi(1_{Gb})$, tenemos que
$\varepsilon \circ Ff = \varphi(f)$.

Aplicamos el mismo proceso al segundo cuadrado natural.

\[\begin{tikzcd}
Hom(Fa,Fa) \arrow{d}[swap]{g_\ast} \arrow{r}{\varphi} & 
Hom(a,GFa) \arrow{d}{(Gg)_\ast} \\
Hom(Fa, Fa') \arrow{r}{\varphi} &
Hom(a,GFa')
\end{tikzcd}\]

Y volvemos a tomar la identidad para tener $\varphi(g) = Gg \circ \eta$. Volviendo a
dar la vuelta a los isomorfismos llegamos a:

\[\begin{tikzcd}
Hom(FGb,b) \arrow{d}[swap]{(g)_\ast} & 
Hom(Gb,Gb) \arrow{d}{(Gg)_\ast} \lar[swap]{\varphi} \\
Hom(FGb,b') &
Hom(Gb,Gb') \lar{\varphi}
\end{tikzcd}\]

Que nos da, tomando la identidad, $\varphi(Gg) = g \circ \varepsilon$.

/Paso 2: Naturalidad de la unidad y la counidad./

Una vez tenemos definidas la unidad y la counidad, podemos comprobar
su naturalidad desde las ecuaciones que hemos obtenido:

\[\begin{aligned}
\eta     \circ f        &= \varphi(Ff) \\
g        \circ \epsilon &= \varphi(Gg) \\
\epsilon \circ Ff       &= \varphi(f) \\
Gg       \circ \eta     &= \varphi(g) \\
\end{aligned}\]

Y la naturalidad de $\eta$ y $\varepsilon$ se deduce desde ahí por la conmutatividad de los
siguientes diagramas, con $\eta \circ f = GFf \circ \eta$ y $g \circ\varepsilon = \varepsilon\circ FGg$:

\[\begin{tabular}{cc}\begin{tikzcd}
GFa  \arrow{r}{GFf} & 
GFb \\
a \arrow{u}[swap]{\eta_X} \arrow{r}[swap]{f} & 
b \arrow{u}{\eta_Y}
\end{tikzcd} & \begin{tikzcd}
FGX \arrow{d}[swap]{\epsilon_X} \arrow{r}{FGg} & FGY \arrow{d}{\epsilon_Y}\\
X \arrow{r}[swap]{g} & Y
\end{tikzcd}\end{tabular}\]

/Paso 3: Comprobar la condición de composición./

Por último tenemos los dos triángulos siguientes, cuya conmutatividad
equivale a la condición de que la composición debía ser la identidad.

\[\begin{tabular}{cc} \begin{tikzcd}
F \arrow{r}{F \eta_X} \arrow{dr}{id} & FGF \arrow{d}{\epsilon_{FX}} \\
 & F
\end{tikzcd} & \begin{tikzcd}
G \arrow{r}{\eta_{GX}} \arrow{dr}{id} & GFG \arrow{d}{G\epsilon_X} \\
 & G
\end{tikzcd}\end{tabular}
\]

Para ello usamos las identidades anteriores comprobando que:

\[\begin{aligned}
\epsilon \circ F\eta &= \varphi(\eta) = 1 \\
G\epsilon \circ \eta &= \varphi(\epsilon) = 1
\end{aligned}\]

$\quad$
#+end_proof

***** Equivalencia de definiciones: desde unidades a familia de isomorfismos
#+begin_theorem
Dada una adjunción en términos de unidad y counidad, podemos construir
una adjunción en términos de familia de isomorfismos.
#+end_theorem

#+begin_proof
/Paso 1: Definición de los isomorfismos./

Por las condiciones sobre la composición de unidad y counidad,
tenemos:

\[\begin{aligned}
\varepsilon \circ F\eta &= 1 \\
G\varepsilon \circ \eta &= 1
\end{aligned}\]

Y por las condiciones de naturalidad de ambas transformaciones, se
tiene:

\[\begin{aligned}
\eta \circ f &= GFf \circ \eta \\
g \circ \varepsilon &= \varepsilon \circ FGg
\end{aligned}\]

Definimos el isomorfismo y su inversa, que seguimos notando igual,
como:

\[\begin{aligned}
\varphi(f) &= \varepsilon \circ Ff \\
\varphi(g) &= Gg \circ \eta
\end{aligned}\]

Se comprueba trivialmente que es isomorfismo por las condiciones
anteriores. Tenemos así las igualdades:

\[\begin{aligned}
\eta     \circ f        &= \varphi(Ff) \\
g        \circ \epsilon &= \varphi(Gg) \\
\epsilon \circ Ff       &= \varphi(f) \\
Gg       \circ \eta     &= \varphi(g) \\
\end{aligned}\]

/Paso 2: Naturalidad de los isomorfismos./

Demostraremos que el isomorfismo es natural en cada una de sus
componentes. La naturalidad aquí se deduce de que la definición
de $\varphi$ nos da las siguientes ecuaciones para cualesquiera $f,g$:

\[\begin{aligned}
\varphi(g\circ f)   &= Gg \circ \varphi(f) \\
\varphi(Ff \circ g) &= f \circ \varphi(g)
\end{aligned}\]

Que nos dan la naturalidad de $\varphi$ en ambas componentes.
#+end_proof

**** Unicidad del adjunto
#+begin_theorem
El adjunto es esencialmente único, es decir,
si tenemos funtores $F : {\cal A} \to {\cal B}$ y $G,G' : {\cal B} \to {\cal A}$ y son ambos adjuntos por la
derecha al primero, $F \dashv G, F \dashv G'$; entonces existe un isomorfismo natural
$\tau : G \cong G'$.
#+end_theorem

#+begin_proof
/Paso 1: Definiendo el isomorfismo natural./

Por ser ambas adjunciones, tenemos un isomorfismo natural en ambas
variables $X,Y$ dado por $\varphi : Hom(X,GY) \cong Hom(X,G'Y)$, ya que
ambos eran isomorfos a $Hom(FX,Y)$.

Tomamos para cada $A$, la componente de nuestro isomorfismo natural
en $A$ como $\tau_A = \varphi_A(id_{GA})$.

/Paso 2: Probando la naturalidad./

Aplicamos dos veces la naturalidad de $\varphi$ para tener, dado un
$f : A \to B$:

\[\begin{tabular}{cc}
\begin{tikzcd}
Hom(GA,GA)\rar{\varphi} \dar[swap]{f^\ast} & Hom(GA,G'A) \dar{(Gf)^\ast} \\
Hom(GA,GB)\rar{\varphi} & Hom(GA,G'B)
\end{tikzcd} & \begin{tikzcd}
Hom(GB,GB)\rar{\varphi} \dar[swap]{(Gf)_\ast} & Hom(GB,GB') \dar{(Gf)_\ast} \\
Hom(GA,GB)\rar{\varphi} & Hom(GA,G'B)
\end{tikzcd}\end{tabular}\]

Obtenemos, tomando de la identidad en ambos diagramas, que $\tau \circ Gf = \varphi(Gf)$
y que $G'f \circ \tau = \varphi(Gf)$. Y uniendo ambas igualdades tenemos la condición de
naturalidad de la transformación $\tau$. Por ser la imagen por un isomorfismo 
natural del isomorfismo identidad, todas sus componentes son isomorfismos.
#+end_proof
**** Continuidad
#+begin_theorem
Todo funtor que es un adjunto derecho (equivalentemente, que tiene un
adjunto izquierdo) es *continuo*; es decir, preserva límites
categóricos. Por otro lado, todo functor que es un adjunto izquierdo
es *cocontinuo* y preserva colímites categóricos.
#+end_theorem

#+begin_proof
Sea $a$ el límite de un funtor en la categoría $A$ y sea $G : A \to B$ un
funtor con adjunto a la izquierda $F \dashv G$. Comprobaremos que si existiera
otro cono desde $x$, descompondría de forma única por $Ga$, haciéndolo límite.

\[\begin{tabular}{ccc}\begin{tikzcd}
a \dar[d]\dar[d,shift left=1, bend left]\dar[d,shift right=1, bend right] \\
\dots
\end{tikzcd} &
$\Longrightarrow$
&
\begin{tikzcd}
x
\arrow[in=70, out=290]{dd}
\arrow[bend left, shift left=1]{dd}
\arrow[bend right, shift right=1]{dd} \\
Ga 
\dar[d]\dar[d,shift left=1, bend left]
\dar[d,shift right=1, bend right] \\
G\dots
\end{tikzcd}\end{tabular}\]

Pero entonces, por la adjunción, por cada $x \to Gi$ tenemos un $Fx \to i$, y estas
aplicaciones generan un cono que conmuta con el diagrama por tenerse

\[\begin{tabular}{ccc}\begin{tikzcd}[column sep=0.5em]
& x \dlar[swap]{\alpha}\drar{\beta} & \\
Gi \arrow{rr}{Gf} & & Gj
\end{tikzcd} &
$\Longrightarrow$
&
\begin{tikzcd}[column sep=0.5em]
& Fx \dlar[swap]{\overline{\alpha}}\drar{\overline{\beta}} & \\
i \arrow{rr}{f} & & j
\end{tikzcd}\end{tabular}\]

y por las condiciones de naturalidad de la transformación
$Hom(F-,-) \cong Hom(-,G-)$ tenemos que

\[
\beta = Gf \circ \varphi(\alpha) = 
\varphi(f \circ \overline{\alpha}) = \varphi(\overline{\beta})
.\]

Así, como $a$ es límite, tenemos un único $Hom(Fx,a)$ que hace conmutar a los
diagramas. Como sólo existe uno, sólo existe un $Hom(x,Ga)$, lo que conlleva
que sea $Ga$ efectivamente el límite.

El caso de cocontinuidad se obtiene aplicándolo a la categoría dual.
cite:lane78categories
#+end_proof

**** Ejemplos
***** Módulos libres
Un *funtor de olvido* es aquel que proyecta estructuras en una
categoría de estructuras más generales, "olvidando" en el proceso
parte de su estructura. En nuestro caso particular de R-módulos,
tenemos el funtor de olvido que lleva cada módulo a su conjunto
subyacente y cada homomorfismo a su aplicación de conjuntos:

\[
U : R\mathtt{-Mod} \longrightarrow \mathtt{Set}
\]

Sobre cada conjunto puede generarse un R-módulo libre, y cada
aplicación de conjuntos puede extenderse directamente por linealidad
a todo el módulo libre. Esto nos da el *funtor de módulo libre*:

\[
F : \mathtt{Set} \longrightarrow R\mathtt{-mod}
\]

Definido como, 

\[F(S) = <S> \qquad F(f)\left(\sum rx\right) = \sum rf(x)\]

Hay una *adjunción* entre el funtor libre y el funtor de olvido
$F \dashv U$, ya que tenemos la correspondencia natural entre homomorfismos
dada por, para un conjunto $X$ y un R-módulo $M$:

\[
Hom(FX,M) \cong Hom(X,UM)
\]

Que hace corresponder a cada aplicación entre conjuntos su extensión
lineal, que está biunívocamente determinada.

La naturalidad se tiene por tenerse para cada $x \in X$:

\[\begin{aligned}
\varphi(g\circ f)(x) = g(f(x)) =& Ug \circ f(x) \\
\varphi(Ff \circ g)(x) = Ff(g(x)) =& f(\varphi(g)(x))
\end{aligned}\]

***** Otros funtores libres y de olvido
De la misma forma que funciona el funtor de olvido entre
módulos y conjuntos, funciona con otras estructuras algebraicas,
como por ejemplo:

 - Grupos a conjuntos.
 - Grupos abelianos a grupos.
 - K-álgebras a K-módulos.

***** Funtor diagonal
****** Categoría producto
#+begin_definition
Dada una categoría ${\cal C}$ con productos y coproductos ($\mathtt{Set}$, por ejemplo) 
definimos ${\cal C}\times{\cal C}$ como la categoría que tiene como objetos a pares de 
objetos de ${\cal C}$ y morfismos a pares de morfismos que se componen componente
a componente:

\[
(f,g)\circ(h,i) = (f\circ h, g\circ i)
\]
#+end_definition

En la categoría producto, tenemos un *funtor diagonal* $\Delta : {\cal C} \to {\cal C}\times{\cal C}$, que 
lleva cada objeto $A$ a $A\times A$ y cada morfismo $f$ a $(f,f)$.

****** Producto como adjunto derecho
Si definimos el *funtor producto*, $\times : {\cal C}\times{\cal C} \to {\cal C}$, lleva $(A,B)$ en $A\times B$
y cada par de morfismos $f : A \to C$ y $g : B \to D$, en el morfismo producto
x$f \times g : A\times B \to C \times D$, dado por el único que hace conmutar:

\[\begin{tikzcd}
& A\times B \dlar[swap]{\pi}\drar{\pi}\dar[dashed] & \\
A\dar[swap]{f} & C \times D \dlar[swap]{\pi}\drar{\pi} & B\dar{g} \\
C & & D \\
\end{tikzcd}\]

Este funtor es adjunto derecho al funtor diagonal. Nótese que se
tiene:

\[
Hom(\Delta A, (B,C)) \cong Hom(A, B \times C)
\]

Y utilizamos la propiedad universal del producto para llevar dos
morfismos $A \to B$ y $A \to C$ a un morfismo al producto $A \to B \times C$.
Y puede comprobarse la naturalidad.

****** Coproducto como adjunto izquierdo
Si definimos el *funtor coproducto* $\coprod : {\cal C}\times{\cal C} \to {\cal C}$, lleva $(A,B)$ en
$A \coprod B$ y cada par de morfismos $f : A \to C$ y $g : B \to D$, en el morfismo
coproducto, dado por el único que hace conmutar:

\[\begin{tikzcd}
A\dar{f}\drar{i} & & B\dar{g}\dlar[swap]{i} \\
C\drar{i} & A \coprod B \dar[dashed] &D\dlar[swap]{i} \\
& C \coprod D &
\end{tikzcd}\]

Y este funtor es adjunto izquierdo al funtor diagonal. Teniéndose
el isomorfismo siguiente y la naturalidad por la propiedad universal
del coproducto:

\[
Hom\left(A \coprod B, C\right) \cong Hom((A, B), \Delta C)
\]

***** Tensor-Hom
Existe una adjunción entre los funtores *tensor y Hom*. cite:kan58adjoint
Si $R,S$ son dos anillos y fijamos un (R;S)-módulo $X$, tenemos los dos funtores

\[\begin{aligned}
F : \mathtt{Mod-}R \longrightarrow \mathtt{Mod-}S
&\qquad&
F(Y) = Y \otimes_R X\\
G : \mathtt{Mod-}S \longrightarrow \mathtt{Mod-}R
&\qquad&
G(Z) = \mathrm{Hom}(X,Z)
\end{aligned}\]

y tenemos el isomorfismo natural

\[
\mathrm{Hom}_{S}(Y \otimes_{R} X, Z) \cong
\mathrm{Hom}_{R}(Y, \mathrm{Hom}_{S}(X,Z))
\]

dado por $\widehat{f}(y)(x) = f(y \otimes x)$.

bibliographystyle:unsrt
bibliography:math.bib
*** Retículos
*** Módulos libres
# Págs 167 Aluffi -> Definición de módulos libres
# Págs 349 Aluffi -> Clasificación de módulos libres sobre PIDs
# Págs 359 Aluffi -> Endomorfismos de módulos libres

**** Definición de módulo libre
#+begin_definition 
Definimos el *R-módulo libre* cite:aluffi09_rings sobre $A$ como un módulo $F^R(A)$ 
con una inclusión $j : A \to F^R(A)$ como aquel que cumple que para cualquier 
aplicación $f : A \to M$ a un R-módulo, existe un homomorfismo de R-módulos
$\varphi:F^R(A) \to M$ que hace conmutar el diagrama

\[\begin{tikzcd}
F^R(A) \rar{\varphi} & M \\
A \uar{j}\urar[swap]{f} &
\end{tikzcd}\]
#+end_definition

Sabemos por ser una propiedad universal que si existe, será único salvo
isomorfías y que $j\colon A \to F^R(A)$ será inyectivo.

***** TODO Construcción
#+begin_definition
Dado un conjunto $A$, definimos la *suma directa indexada* sobre él como
las aplicaciones de soporte finito

\[
N^{\oplus A}
=
\left\{ \alpha\colon A \to N 
\mid 
\alpha(a) \neq 0 \text{ sólo para un número finito de elementos} \right\}
\]

a las que les damos estructura de R-módulo con $(r\alpha)a = r\alpha(a)$.
#+end_definition

Además, existe una inclusión $j\colon A \to R^{\oplus A}$ definida como

\[
j(a)(x) = \left\{\begin{array}{ll} 
1 & \mbox{if } x = a  \\
0 & \mbox{if } x \neq a 
\end{array} 
\right. .
\]

#+begin_theorem
El así definido es el módulo libre sobre $A$. Es decir, $F^R(A) \cong R^{\oplus A}$.
#+end_theorem

#+begin_proof
#+end_proof

**** Independencia lineal y bases
#+begin_definition
Decimos que un conjunto indexado $i \colon I \to M$ es *linealmente independiente*
(respectivamente *sistema generador*) si el homomorfismo natural desde su
módulo libre, $\varphi\colon F^{R}(I) \to M$, haciendo conmutar

\[\begin{tikzcd}
F^{R}(I) \rar{\varphi} & M \\
I \uar{j}\urar[swap]{i} &
\end{tikzcd}\]

es inyectivo (respectivamente sobreyectivo). cite:aluffi09_linear
#+end_definition

#+begin_definition
Un conjunto indexado $I \to M$ es una base cuando es linealmente
independiente y genera $M$.
#+end_definition

#+begin_lemma
Un conjunto indexado $B \to M$ es una base si y sólo si el homomorfismo
natural desde su módulo libre es un isomorfismo $R^{\oplus B} \cong M$. Así, un
$R\text{-módulo}$ es libre si y sólo si admite una base.
#+end_lemma

#+begin_proof
Trivial si combinamos las definiciones de linealmente independiente y
sistema generador.
#+end_proof

**** TODO Caso de los espacios vectoriales
**** Clasificación de módulos libres en dominios de integridad
#+begin_theorem
Sea $M$ un $R\text{-módulo}$ libre para $R$ dominio de integridad con
$B$ un conjunto linealmente independiente maximal. Para cualquier $S$
linealmente independiente,

\[ \# S \leq \# B.
\]

En particular, cualesquiera dos conjuntos linealmente independientes
maximales tienen la misma cardinalidad.
#+end_theorem

# Completar la parte de cuerpos de fracciones.
#+begin_proof
Empezamos tomando cuerpos de fracciones y pasamos a considrear el caso
de $R$ un cuerpo y $M$ un espacio vectorial.

Comprobaremos que podemos ir reemplazando elementos de $B$ por
elementos de $S$ sucesivamente para ir creando sucesivos $B'$ y
seguir manteniendo independencia lineal y la maximalidad. Si tomamos
$B' \cup \{v\}$ para algún $v \in S$, por maximalidad tenemos una
dependencia lineal

\[
c_0v + c_1b_1 + \dots + c_tb_t = 0
\]

con $c_0 \neq 0$ para no contravenir la independencia de $B$; además, no sólo
pueden existir elementos no nulos de $S$, porque contravendría su independencia.
Debe existir un $c_1 \neq 0$ con $b_1 \in B' \setminus S$ y podemos intercambiar $b_1$ por $v$
teniendo de nuevo un conjunto linealmente independiente maximal, ya que

\[
v = -c_0^{-1}c_1b_1 - \dots - c_0^{-1}c_tb_t.
\]

Si aplicamos inducción transfinita bajo una buena ordenación de $S$, podemos
asegurar que se llega a un conjunto de cardinalidad $\#B$ que contiene a
los elementos de $S$.
#+end_proof

#+begin_corollary
Para $R$ un dominio de integridad y dos conjuntos $A,B$,

\[
F^R(A) \cong F^R(B) \iff A \cong B.
\]
#+end_corollary

#+begin_corollary
Para $R$ un dominio de integridad se satisface la propiedad IBN

\[
R^m \cong R^n \iff m = n.
\]
#+end_corollary

**** Clasificación de módulos libres en dominios de ideales principales
#+begin_lemma
Sea $R$ un dominio de ideales principales y $F$ un módulo libre finitamente
generado sobre él. Entonces existen $a\in R, x\in F, y\in M$ con $y = ax$ y
$M' \subseteq M,F' \subset F$ con $M' = F' \cap M$ submódulos cumpliendo

\[
F = \left\langle x \right\rangle \oplus F',
\qquad
M = \left\langle y \right\rangle \oplus M'.
\]
#+end_lemma

#+begin_proof
La familia de ideales $\left\{ \varphi \in \mathrm{Hom}(F,R) \mid \varphi(M) \right\}$ es no vacía. Como los PID son
noetherianos, tiene un elemento maximal $\alpha(M) = (a)$, para algún $\alpha(y) = a$.

Dado cualquier $\varphi(y)$, si tomamos el generador $(b) = (a,\varphi(y))$ tenemos que

\[
b = ra + s\varphi(y)
\]

y que si definimos $\psi = r\alpha + s\varphi$, tenemos $b = \psi(y) \in \psi(M)$, luego
$(a) \subseteq (b) \subseteq \psi(M)$, y por maximalidad, $a \mid \varphi(y)$.

Si vemos $y = \left( s_1,\dots,s_n \right)$ como elemento de $F\cong R^{\oplus n}$, tenemos $a \mid \pi_i(y) = s_i$,
así que sabemos $s_i = ar_i$, y definimos

\[
x = \left( r_1,\dots,r_n \right).
\]

Ahora tomamos $F' = \mathrm{ker}(\alpha)$ y comprobamos las sumas directas.
#+end_proof

#+begin_proposition
Sea $R$ un dominio de ideales principales y $F$ un módulo libre finitamente
generado sobre él. Todo submódulo $M \subset F$ será libre.
#+end_proposition

#+begin_proof
Aplicamos el lema anterior a los sucesivos $M^{(i)}$ que genere. Tendremos
que eventualmente $M^{(i)} = 0$, ya que los $y^{(i)}$ son independientes y $F$ es
finitamente generado.
#+end_proof

***** Resoluciones en PIDs
#+begin_proposition
Sea $R$ dominio de integridad. Será dominio de ideales principales si y sólo
si para cualquier epimorfismo a un módulo finitamente generado

\[
R^{m_0} \overset{\pi_0} \longrightarrow M \longrightarrow 0,
\]

existe un módulo libre haciendo exacta la secuencia

\[
0 \longrightarrow 
R^{m_1} \overset{\pi_1} \longrightarrow
R^{m_0} \overset{\pi_0} \longrightarrow
M \longrightarrow
0.\]
#+end_proposition

**** Anillo de endomorfismos
#+begin_proposition
Los endomorfismos de un $R\text{-módulo}$ $F$, $\mathrm{End}(F)$ forman un álgebra con la
composición.
#+end_proposition

***** Semejanza
#+begin_definition
Dos matrices $A,B \in {\cal M}_n(R)$ son *semejantes* si representan el mismo
endomorfismo $F \to F$, diferenciándose en la elección de la base.
#+end_definition

#+begin_proposition
Dos matrices $A,B$ son semejantes si y sólo si

\[
B = PAP^{-1}.
\]
#+end_proposition
# Sacar demostración de página 360.

#+begin_definition
Dos endomorfismos $\alpha,\beta \colon F \to F$ son *semejantes* si existe un
automorfismo $\pi \colon F \to F$ cumpliendo

\[
\beta = \pi \circ \alpha \circ \pi^{-1}.
\] cite:aluffi09_linear
#+end_definition

***** Semejanza y acciones de anillos de polinomios
#+begin_proposition
Una transformación lineal de $F$ es exactamente lo mismo que una estructura
como $R[X]\text{-módulo}$ compatible con la estructura de $R\text{-módulo}$.
#+end_proposition

Si tenemos una transformación lineal $\alpha$, podemos definir la acción de
un polinomio como

\[
\left( r_mt^m + \dots + r_1t + r_0 \right)(v) =
r_{m}\alpha^m(v) + \dots r_1\alpha(v) + r_0v.
\]

Y por la propiedad universal del anillo de polinomios, toda estructura
de $R[t]\text{-módulo}$ quedará determinada por el endomorfismo que asignemos a $t$.

#+begin_lemma
Dadas transformaciones lineales $\alpha,\beta$ de $F$; las estructuras como $R[t]\text{-módulo}$
son isomorfas si y sólo si $\alpha$ y $\beta$ son semejantes.
#+end_lemma
#+begin_proof
Si llamamos $F_{\alpha}$, $F_{\beta}$ a las dos estructuras como $R[t]\text{-módulo}$, tendremos que
un isomorfismo $\pi\colon F_{\alpha}\to F_{\beta}$ será lo mismo que una transformación invertible
$\pi\colon F \to F$ cumpliendo $\beta = \pi\circ\alpha\circ\pi^{-1}$.

Nótese de hecho que un isomorfismo entre módulos debe comportarse como

\[
\pi\circ\alpha (v) = \pi(tv) = t\pi(v) = \beta\circ\pi(v),
\]

por lo que $\pi\circ\alpha = \beta\circ\pi$ es la condición que lo distingue de cualquier
otra transformación lineal.
#+end_proof

#+begin_corollary
Hay una correspondencia biyectiva entre clases de semejanza de transformaciones
lineales de un $R\text{-módulo}$ libre $F$ y clases de isomorfía de estructuras de
$R[t]\text{-módulo}$ en $F$.
#+end_corollary

Nótese que esto se expande a las matrices en el caso finito-dimensional.

**** Referencias
bibliographystyle:unsrt
bibliography:math.bib
*** Categorías abelianas
**** Objeto nulo
#+begin_definition
En una categoría, un *objeto nulo* es aquel que es a la vez inicial y final.
#+end_definition

Nótese que no todas las categorías tienen por qué tener un objeto nulo.
La categoría $\mathtt{Set}$, por ejemplo, tiene objetos inicial y final no isomorfos.

#+begin_definition
En una categoría con objeto nulo llamamos *morfismo cero* entre dos
objetos, $0_{a,b}\colon a \to b$, al que resulta de componer el único morfismo $a \to 0$ con 
el único morfismo $0 \to b$.
#+end_definition

**** Núcleos y conúcleos
#+begin_definition
En una categoría con objeto nulo, el *núcleo* de un morfismo
$f \colon a \to b$ es un morfismo $k \colon \mathrm{ker}(f) \to a$ tal que $f\circ k = 0$ y que es universal 
respecto a esa propiedad; es decir, para cualquier otro $h$ cumpliendo 
que $f \circ h = 0$, se tiene el diagrama

\[\begin{tikzcd}
c \dar[dashed]{\exists! h'}\ar[bend right=90,swap]{dd}{h}\arrow[bend left=45]{ddr}{0} &   \\
\mathrm{ker}(f) \dar{k}\drar{0} &   \\
a\rar{f} & b & .\\
\end{tikzcd}\]
#+end_definition

De otra forma, podríamos definirlo como el *ecualizador* del morfismo $f$ con
el morfismo cero, es decir, como el universal respecto al diagrama

\[\begin{tikzcd} \mathrm{ker}(f) \rar{k} & 
a \rar[bend left]{f}\rar[bend right,swap]{0} & b
\end{tikzcd},\]

y por tanto, es un límite finito y es único salvo isomorfismo. 

#+begin_definition
En una categoría con objeto nulo, se define el *conúcleo*, $c \colon b \to \mathrm{coker}(f)$
de manera dual al núcleo, como universal según el siguiente diagrama 
conmutativo

\[\begin{tikzcd}
c  &   \\
\mathrm{coker}(f)  \uar[dashed]{\exists! h'} &   \\
a \ar[bend left=90]{uu}{0}\uar{0} \rar{f} & b \ular[swap]{c} \arrow[bend right=45,swap]{uul}{h} \\
\end{tikzcd}\]
#+end_definition

***** Propiedades del núcleo
#+begin_proposition
Cualquier núcleo es un monomorfismo. Dualmente, cualquier conúcleo es
un epimorfismo.
#+end_proposition
#+begin_proof
Si se tienen dos $m,n\colon d \to \mathrm{coker}(f)$, entonces sabemos que $m \circ k$ y $n \circ k$,
por propiedad universal, hacen que exista un único $h \circ k = m\circ k=n\circ k$.
Debe tenerse por tanto $h=m=n$.
#+end_proof

Nótese que el converso no tiene por qué ser cierto. En general, no todo
monomorfismo es núcleo ni todo epimorfismo es conúcleo.

***** Ejemplo: grupos
En la categoría $\mathtt{Grp}$, el objeto cero es el grupo trivial. El núcleo de
cualquier morfismo es lo que llamamos usualmente núcleo, como se puede
comprobar trivialmente. Nótese que todos los núcleos son normales en un 
grupo pero que no todas las inclusiones lo son como subgrupo normal, por 
lo que no todos los monomorfismos serán aquí núcleos.

**** Categorías preaditivas
#+begin_definition
Una *categoría preaditiva* es aquella en la que cada conjunto de morfismos
$\mathrm{hom}(a,b)$ es un grupo abeliano y la composición es bilinear respecto a la
operación de grupo.
#+end_definition

#+begin_proposition
Para un objeto en una categoría preaditiva, $z \in {\cal A}$, equivalen:

  1) $z$ es inicial.
  2) $z$ es final.
  3) $\mathrm{id}_z$ es el elemento neutro de $\mathrm{hom}(z,z)$.
  4) $\mathrm{hom}(z,z)$ es el grupo trivial.
#+end_proposition
#+begin_proof
Si $z$ es inicial o final, se tiene un único $\mathrm{id}_z = 0$, que da el grupo trivial.
Si se tiene $\mathrm{id}_z=0$, entonces para cualquier morfismo $f\colon a \to z$, se tendrá

\[
f = \mathrm{id}_z \circ f = 0\circ f = 0
\]

por la bilinealidad de la composición. Dualmente se verá que es inicial.
#+end_proof

***** Biproductos
#+begin_definition
Un *biproducto* para dos objetos en una categoría preaditiva $a,b \in A$ es un
$c$ con morfismos

\[\begin{tikzcd}
a \rar[bend right,swap]{i_{1}} &
c \rar[bend left]{p_2} \lar[bend right,swap]{p_1} &
b \lar[bend left]{i_2}
\end{tikzcd}\]

cumpliendo las identidades $p_1i_1 = \mathrm{id}_a$, $p_2i_2 = \mathrm{id}_b$, y $i_1p_1 + i_2p_2 = \mathrm{id}_{c}$.
#+end_definition

#+begin_theorem
Dos objetos en una categoría preaditiva $a,b \in A$ tienen producto (o coproducto) 
si y sólo si tienen un biproducto, que será a su vez producto y coproducto.
#+end_theorem

**** Categorías abelianas
#+begin_definition
Una *categoría abeliana* es una categoría preaditiva cumpliendo que

 1) tiene un objeto nulo.
 2) tiene biproductos finitos.
 3) todo morfismo tiene núcleo y conúcleo.
 4) todo monomorfismo es núcleo y todo epimorfismo es conúcleo.
#+end_definition

***** Factorización de un morfismo
#+begin_proposition
En una categoría abeliana, cada morfismo se factoriza como $f = m\circ e$,
donde $m = \mathrm{ker}(\mathrm{coker}(f))$ y $e = \mathrm{coker}(\mathrm{ker}(f))$. 
Además, esta factorización cumple que, dada cualquier otra factorización
de la forma $f' = m'e'$ con $m'$ monomorfismo, $e'$ epimorfismo y con morfismos
de la forma

\[\begin{tikzcd}
\cdot \rar{f}\dar[swap]{g} & \cdot \dar{h} \\
\cdot \rar[swap]{f'} & \cdot &,
\end{tikzcd}\]

existe un único $k$ cumpliendo

\[\begin{tikzcd}
\cdot \arrow[bend left]{rr}{f}\dar[swap]{g} \rar{e}& 
\cdot\rar{m}\dar{k} & \cdot \dar{h} \\
\cdot \arrow[bend right,swap]{rr}{f'} \rar{e'} & \cdot\rar{m'} & \cdot
\end{tikzcd}\]
#+end_proposition
#+begin_proof
Tomamos $m = \ker(\operatorname{coker} f)$. Como $(\operatorname{coker} f)\circ f = 0$, por propiedad universal
del núcleo sabemos que $f$ se escribe como $f = me$ para algún $e$. Como puede
demostrarse que $e$ será epimorfismo, luego $e = \operatorname{coker}(\ker f)$.

Dadas $f=me$ y $f'=m'e'$ con $g,h$ del diagrama, consideramos
$u = \ker f = \ker e$ y entonces tenemos que $0 = hfu = m'e'gu$, luego $e'gu = 0$.
Por ser $u$ núcleo, $e'g$ factoriza en $e = \operatorname{coker}(u)$ como $e'g = ke$ para algún
$k$ que además debe ser único. Así, $m'ke = hme$ y $m'k = hm$, dando la
conmutatividad del diagrama.
#+end_proof

#+begin_definition
La *imagen* y *coimagen* de un morfismo $f = me \colon a \to b$ se definen como

 * $\operatorname{im} f = m$
 * $\operatorname{coim} f = e$
#+end_definition

La proposición anterior se usa para comprobar que son únicas salvo
isomorfismo.

**** Secuencias exactas
***** Exactitud
#+begin_definition
Un par de morfismos componibles es *exacto* en el objeto que comparten
cuando $\operatorname{im} f = \operatorname{ker} g$. Equivalentemente, cuando $\operatorname{coker} f = \operatorname{coim} g$.
#+end_definition

***** Complejos de cadenas
#+begin_definition
En una categoría abeliana, un *complejo de cadenas* es una secuencia

\[\begin{tikzcd}
\dots \rar &
c_{n+1} \rar{\partial_{n+1}} &
c_n \rar{\partial_n} &
c_{n-1} \rar &
\dots
\end{tikzcd}\]

cumpliendo que $\partial_n\partial_{n+1} = 0$.
#+end_definition

***** Secuencias exactas cortas
#+begin_definition
Una *secuencia exacta corta* es un diagrama

\[
0 \longrightarrow
a \overset{f}\longrightarrow
b \overset{g}\longrightarrow
c \longrightarrow
0
\]

que es exacto en $a$,$b$ y $c$.
#+end_definition

#+begin_definition
Un *morfismo de secuencias exactas cortas* está formado por tres morfismos
$f,g,h$ que hacen conmutar el diagrama

\[\begin{tikzcd}
0 \rar& 
\cdot \rar{m}\dar{f}& 
\cdot \rar{e}\dar{g}& 
\cdot \rar\dar{h}& 
0 \\
0 \rar& 
\cdot \rar{m'}& 
\cdot \rar{e'}& 
\cdot \rar& 
0 & .\\
\end{tikzcd}\]

Las secuencias exactas cortas de una categoría abeliana $A$ con estos 
morfismos forman la categoría $\mathtt{Ses}(A)$, que se hace preaditiva sumando
las tres componentes de cada morfismo.
#+end_definition

**** Resultados en categorías abelianas
***** Manipulación elemental en categorías abelianas
#+begin_proposition
Si dados dos morfismos $f,g$ hacia $c$ calculamos su producto fibrado
(/pullback/) tendremos que $f$ epimorfismo nos da $f'$ epimorfismo en

\[\begin{tikzcd}
s\rar{f'} \dar[swap]{g'} & d \dar{g} \\
b\rar{f} & c
\end{tikzcd}\]

donde además, el núcleo de $f$ factoriza como $\mathrm{ker}(f) = g'\circ \mathrm{ker}(f')$.
#+end_proposition
#+begin_proof
El producto fibrado se construye formando la secuencia exacta

\[\begin{tikzcd}
0\rar&s\rar{m}&b\oplus d\rar{fp_1-gp_2}& c
\end{tikzcd}\]

y tomando $g' = p_1m$ y $f'=p_2m$. Probaremos que $fp_1-gp_2$ es un
epimorfismo, para lo que basta comprobar que si $h(fp_1-gp_2) = 0$
entonces

\[
0 = h(fp_1-gp_2)i_1 = hfp_1i_1 = hf,
\]

y por ser epimorfismo $f$, $h = 0$. Ahora probaremos que $f'$ es
epimorfismo; si $uf'=up_2m=0$, por exactitud, es de la forma
$up_2 = u'(fp_1-gp_2)$. Ahora tenemos

\[
0 = up_2i_1 = u'f
\]

llegándose a $u'=0$ por ser $f$ epimorfismo.
#+end_proof

#+begin_definition
Definimos un *miembro* de $a$ como un morfismo con codominio $a$. Existe
una equivalencia $x \equiv y$ entre dos miembros cuando existen epimorfismos
$u,v$ tales que $xu=yv$.
#+end_definition
#+begin_proof
Para demostrar la transitividad de esta relación de equivalencia,
debemos aplicar la proposición anterior al diagrama siguiente,

\[\begin{tikzcd}
\cdot \rar\dar & 
\cdot \rar\dar& 
\cdot \dar{x}\\
\cdot \rar\dar& 
\cdot \rar{y}\dar{y}&
a \\
\cdot \rar{z} &
a &&,\\
\end{tikzcd}\]

donde probamos que si $x \equiv y$ y $y \equiv z$, entonces $x \equiv z$.
#+end_proof

Dado un morfismo $f \colon a \to b$, cada $x \in a$ da lugar a $f \circ x \in b$; y además,
$x \equiv y$ implica $f x \equiv f y$. Gracias a esto, podemos tratar a los miembros
de un objeto en una categoría abeliana de la misma manera de la que
tratamos a los elementos de un conjunto. La aplicación de funciones
se comporta de la misma manera y preserva la relación de equivalencia
de los miembros.

#+begin_proposition
En cualquier categoría abeliana

 1) $f \colon a \to b$ es /monomorfismo/ ssi para $x \in a$, $f(x) \equiv 0 \implies x \equiv 0$.
 2) $f \colon a \to b$ es /monomorfismo/ ssi para $x,y \in a$, $f(x) \equiv f(y) \implies x\equiv y$.
 3) $g\colon b \to c$ es /epimorfismo/ ssi para $z\in c$, existe $y \in b$ con $g(y) \equiv z$.
 4) $h\colon r \to s$ es /nulo/ ssi para $x \in r$, $hx \equiv 0$.
 5) $a \overset{f}\to b\overset{g}\to c$ es /exacta/ ssi $gf = 0$ y para cada $g(y)\equiv 0$ existe un
    $x \in a$ tal que $f(x) \equiv v$.
 6) Si existen $g(x) = g(y)$, existe $g(z) = 0$; además cualquier $f(x) \equiv 0$
    implica $f(y) \equiv f(z)$ y cualquier $h(y)\equiv 0$ implica $h(x) \equiv -h(z)$.
#+end_proposition
#+begin_proof
Se tienen (1) y (2) por definición de monomorfismo. Se tiene además
(3) por construcción del producto fibrado y (4) por definición.

Si factorizamos $f = me$, por exactitud se tendrá $\operatorname{ker} g = m$. Si $g y \equiv 0$,
$y \equiv my'$, y si construimos el producto fibrado

\[\begin{tikzcd}
\cdot\dar[dashed]{y''}\rar[dashed]{e'} & \cdot\dar{y'}\drar[bend left=45]{y} \\
\cdot\rar{e} & \cdot\rar{m} & \cdot &,
\end{tikzcd}\]

como $e'$ es epimorfismo, $y \equiv fy''$.

A la inversa, si para $y \in b$ existe $k = \ker g$, entonces $k \in b$ y $gk \equiv 0$.
Existe entonces $x \in a$ con $fx \equiv k$, es decir, $ku \equiv mexv$. Esto lleva
a $\operatorname{im} f \geq \ker g$ y a $gf = 0$, la exactitud.
#+end_proof

***** Lema de los cinco
#+begin_theorem
En un diagrama conmutativo con filas exactas

\[\begin{tikzcd}
a_1 \rar{g_1} \dar{f_1} & 
a_2 \rar{g_2} \dar{f_2} &
a_3 \rar{g_3} \dar{f_3} & 
a_4 \rar{g_4} \dar{f_4} & 
a_5 \dar{f_5} \\
b_1 \rar{h_1} &
b_2 \rar{h_2} &
b_3 \rar{h_3} &
b_4 \rar{h_4} &
b_5 & ,
\end{tikzcd}\]

si $f_1,f_2,f_4,f_5$ son isomorfismos, $f_3$ es isomorfismo.
#+end_theorem
#+begin_proof
Usando la manipulación de diagramas cuyas reglas hemos escrito en
la proposición anterior, demostraremos que $f_3$ es monomorfismo.
La dualidad servirá para demostrar a su vez que es epimorfismo.
#+end_proof

***** Lema de la serpiente
#+begin_theorem
Dado un morfismo de secuencias exactas cortas $f,g,h$; existe un morfismo
$\delta \colon \operatorname{ker} h \to \operatorname{coker} f$ tal que la secuencia siguiente es exacta

\[\begin{tikzcd}
0 \rar &
\mathrm{ker}(f) \rar{m} &
\mathrm{ker}(g) \rar{e} &
\mathrm{ker}(h) \arrow[out = 0,in =180,swap]{dll}{\delta} \\&
\mathrm{coker}(f) \rar{m'} &
\mathrm{coker}(g) \rar{e'} &
\mathrm{coker}(h) \rar &
0
\end{tikzcd}\]
#+end_theorem
#+begin_proof
El diagrama extendido que tenemos es

 \[ \begin{tikzcd}
	& 0 \dar              & 0 \dar            & 0 \dar           &   \\
 0 \rar & ker(f) \rar \dar  & ker(g) \rar \dar    & ker(h) \dar \ar[out=355, in=175,looseness=1, overlay, swap]{dddll}{\delta}       &   \\
 0 \rar & a \rar{m} \dar{f}  & b \rar{e} \dar{g} & c \rar \dar{h}        & 0 \\
 0 \rar & a' \rar{m'} \dar & b' \rar{e'} \dar & c' \rar \dar        & 0 \\
	& coker(f) \rar \dar & coker(g) \rar \dar  & coker(h) \rar \dar & 0 \\
	& 0                   & 0                 & 0                &
 \end{tikzcd} \]

y desde él, manipulando de nuevo el diagrama podemos construir primero
el morfismo $\delta$ y demostrar después que efectivamente es exacto.
#+end_proof

**** Referencias
# MacLane

* Empresa y Sociedad
** Detalles de la asignatura
Profesora Matilde Ruiz, departamento de Organización de Empresas. 
(matilderuiz@ugr.es)

*Evaluación:*

- 70% Pruebas objetivas: la prueba final de junio y los exámenes parciales.
- 30% Actividades prácticas: participación, ejercicios y asistencia.

*Bibliografía:*

 - Fuentes Fuentes M. et al. /"Fundamentos de dirección y administración de empresas"/

** 1. La empresa y dirección de empresas
*** 1.0. Introducción
**** Economía
La *economía* se define como la ciencia que estudia la administración
eficiente de la escasez de recursos. También como ciencia que
estudia la elección.

Este concepto proviene de las ideas de *Malthus*. La escasez justifica
la necesidad de reparto y la pobreza.

**** Administración de empresas
La *administración de empresas* estudia la economía en el contexto de
una empresa, así como la gestión de proyectos, la planificación y el
liderazgo. Es una disciplina científica multidisciplinar y contempla
aspectos psicosociales.

*** 1.1. Concepto de empresa y de organización
**** Organización
Una *organización* es una unidad social deliberadamente destinada a un
objetivo específico. Requiere constar de una estructura interna
deliberada y fijar el objetivo común.

***** Definición de Gibson
La *organización* es una unidad coordinada /deliberada/ formada por
más de una persona que trabaja para alcanzar un /objetivo común/.

***** Definición de Etzioni
Unidades sociales deliberadamente constituidas para promover objetivos
específicos.

***** Clasificación de organizaciones
Una clasificación genérica sencilla las separa según tengan o no
*ánimo de lucro*.

****** Ejemplo: Inditex
Industria de diseño textil INDITEX S.A. es una empresa multinacional
que tiene como objetivo maximizar el beneficio. Según la empresa,
su objetivo es "/escuchar a los clientes para ofrecerles las propuestas/
/de moda que desean/".

****** Ejemplo: Amigos del museo del Prado
En sus estatutos aclara que su fin primario es cultural. Puede
obtener beneficios económicos, pero serán un fin secundario, sólo
un medio para su fin primario cultural:

"/tiene por fin particular todo lo relacionado con la promoción,/
/estímulo, apoyo y desarrollo de cuantas acciones culturales,/
/educativas y de otra índole tengan relación con el Museo/"

**** Definición de empresa
La *empresa* es una organización que /transforma/ un conjunto de recursos
físicos, monetarios y cognitivos en bienes y/o servicios, con el objetivo
principal de /obtener beneficios/.

***** Autores
Otras definiciones de empresa.

 - Unidad técnico-económica que combina elementos humanos y financieros.
 - Una organización con ánimo de lucro.
 - Unidad de decisión.
 - Sistema en el que se coordinan factores de producción.
 - Conjunto de factores de producción.

**** ¿Es el beneficio el único objetivo?
Hay posiciones distintas.

***** Friedman
Sí, hay que maximizarlo teniendo como únicas restricciones

 * las leyes,
 * las normas de la economía capitalista, y
 * evitar engaños y fraudes.

***** Freeman
No, no sólo hay que maximizar el beneficio, también hay que satisfacer
a los *stakeholders*, que son todas las personas que tienen intereses en
la compañía.

**** Stakeholder
Los *stakeholders* son todas las partes interesadas en una empresa. Pueden
ser

 * *internas*, como los empleados, gerentes y propietarios.
 * *externas*, como los proveedores, clientes y la sociedad.

Originalmente, los stakeholders se definieron como los miembros de los grupos
sin cuyo apoyo la empresa dejaría de existir.

**** La empresa social
Las *empresas sociales* nacen con el objetivo de resolver problemas
sociales. No tienen ánimo de lucro, sino que buscan un objetivo
social.

Organizaciones con ánimo de lucro y sin ánimo de lucro pueden tener un
fin fundamental con beneficio social, medioambiental o político. Pero
a las empresas sociales se les exige que sean rentables por sí mismas.

En su filosofía se incluye que no reemplaza a la empresa tradicional,
sino que que quiere coexistir con ella. Como ejemplos:

 - plataformas sociales, como /Ashoka/ y /SocialEmprende/.
 - /DBS/.

**** Tipos de responsabilidad jurídica
Existen varias formas de responsabilidad, que indican cómo responderá la
empresa ante las posibles pérdidas. La responsabilidad puede ser limitada
o ilimitada y solidaria o mancomunada.

***** Responsabilidad ilimitada
Se llama *responsabilidad ilimitada* cuando el propietario responde
con todo el patrimonio ante las posibles pérdidas de la
empresa. Existe cuando éste realiza la actividad con su propia persona
como personalidad jurídica.

***** Responsabilidad limitada
Se llama *responsabilidad limitada* a aquella que no obliga a responder
con el patrimonio a los socios ante posibles pérdidas. La responsabilidad
de cada socio está limitada por sus aportaciones.

***** Responsabilidad solidaria
La *responsabilidad solidaria* se reparte entre los socios equitativamente.

***** Responsabilidad mancomunada
La *responsabilidad mancomunada* hace que cada socio responda por su parte.

**** Clasificación de empresas según forma jurídica (individuales)
Constituidas por una persona física, que sigue usando su NIF y tributando
mediante el IRPF.

***** Empresario individual
Cuando el *empresario individual* responde por la empresa de manera
ilimitada. Se constituye como una mera persona física, que responde
con su patrimonio, utiliza su NIF como persona jurídica y paga el IRPF.

***** Emprendedor de responsabilidad limitada
El *emprendedor de responsabilidad limitada* es una forma jurídica
permitida según ciertos criterios. La única diferencia es que la
responsabilidad del empresario individual pasa a limitarse. 

Aun así, sigue siendo un empresario individual. No tiene CIF y paga el
IRPF.

**** Clasificación de empresas según forma jurídica (societarias)
En una *forma societaria*, varias personas aportan capital o trabajo
bajo un contrato de asociación que da lugar a una personalidad jurídica
nueva.

***** Sociedad colectiva
En una *sociedad colectiva* la responsabilidad es /ilimitada y
mancomunada/ entre los socios, pero sólo participan del beneficio por
la parte que han aportado de capital y trabajo.

***** Sociedad comanditaria
En una *socidedad comanditaria* existen dos tipos de socios

 - *socios colectivos*, similares a los de las sociedades colectivas,
   aportando trabajo y capital y con responsabilidad ilimitada.
 - *socios comanditarios*, sólo aportan capital y no trabajan en la
   empresa. Su responsabilidad se limita a su capital y sus beneficios
   son proporcionales a su aportación.

***** Sociedad limitada (SL)
En una *sociedad limitada* el capital se divide en *participaciones 
sociales*. Estas se diferencian de las /acciones/ en que existen obstáculos
legales a su transmisión directa; sólo pueden ser transmitidas si da el
visto bueno una /junta de socios/ o la transmisión se hace a familiares o a
otros socios.

Tiene trámites más costosos y lentos que otras formas societarias de
responsabilidad ilimitada. El capital social en ellas no puede ser inferior
a los 3000€ mínimos iniciales.

***** Sociedad de responsabilidad limitada unitaria (SLU)
Hay una *sociedad de responsabilidad limitada unitaria* cuando existe un
socio único, que debe cumplir con una declaración de unipersonalidad y que
puede tomar decisiones unilateralmente.

***** Sociedad de responsabilidad limitada nueva empresa (SLNE)
La *sociedad limitada nueva empresa* es una especialización de la
sociedad limitada que facilita su creción. Se da de alta en un
procedimiento telemático de 48 horas y se utilizan modelos genéricos
para constituirla.

***** Sociedad anónima (SA)
En una *sociedad anónima*, el capital se divide en partes iguales
(alícuotas) llamadas *acciones*. Las acciones se transmiten libremente
en el mercado financiero a terceros, suelen representar un voto y la
responsabilidad de los socios o /accionistas/ se limita a su
aportación. Es el único tipo de sociedad que puede cotizar en Bolsa.

Necesita 60000€ como capital mínimo inicial.

***** Empresas de economía social
Las *empresas de economía social* suelen constituirse para solventar
crisis de las empresas. Suelen ser democráticas.

****** Sociedades cooperativas (SC)
Las *sociedades cooperativas* no tienen ánimo de lucro. Cada socio
aporta capital y trabajo; responde sólo con el capital aportado y
tiene un voto independientemente del capital. Es /limitada/ y 
/solidaria/.

Estas uniones de trabajo asociado suelen darse cuando los trabajadores
tienen un objetivo común fuerte. Tienen regulación estatal y
autonómica y en ocasiones exenciones fiscales (las andaluzas se llaman
SCA).

El beneficio se llama /retorno/. Las reservas (la parte del beneficio
que no se distribuye entre los socios), suelen ser más grandes. Suelen
tener una reserva obligatoria para invertir en la formación de los
socios.

/Ejemplo: cooperativa Mondragón/

****** Sociedades laborales
Las *sociedades laborales* son sociedades anónimas o de responsabilidad
limitada donde los trabajadores poseen al menos el 51% del capital.

Suelen ser intentos de los trabajadores de evitar la quiebra de la
empresa.

**** Clasificación de empresas según tamaño
La clasificación según tamaño se realiza en base a varios criterios, tales
como

 * *número de trabajadores* contratados en la empresa.

 * *volumen de negocio anual*, el total de ingresos por ventas
   contabilizadas. Equivale al valor total de los bienes y servicios
   vendidos en un año.

 * *balance general anual (activo)*, bienes y derechos de la empresa, sin
   contar las obligaciones de pago, que pertenecerían al /pasivo/.

Por ellos se dividen en: grandes, medianas, pequeñas y
microempresas. El 99.9% de empresas en España son PYMEs (pequeñas y
medianas empresas).

***** Empresas autónomas o asociadas
En el caso de que la empresa tenga relación con otras, sus datos
deberán incluirse al calcular su tamaño. Una empresa se clasifica
según su relación con otras en

  * *autónoma* si es totalmente independiente y no tiene participación en
    otras empresas, ni otras empresas en ella.
  * *asociada* si hay terceros con más del 25% de la empresa o tiene
    participación de más del 25% en otra empresa.

Aun así existen empresas que se consideran autónomas a pesar de esto.
Además, dos empresas están *vinculadas* cuando una puede ejercer
influencia dominante sobre la otra, ya sea nombrando miembros del
consejo de administración, mediante cláusulas estatutarias o contratos.

*** 1.2. Enfoque sistémico de la empresa
**** Definición de sistema
Un *sistema* es un conjunto de elementos relacionados dinámicamente que
realizan una actividad para alcanzar un objetivo; operando con entradas
y proveyendo salidas.

**** Condiciones para la existencia de un sistema
Para considerar algo un sistema se le exigen

 * un *conjunto de elementos*, los factores productivos.
 * una *estructura de sistema*, jerarquía de la empresa.
 * un *plan común*, la misión de la empresa.
 * unas *funciones características*, las funciones técnicas y
   administrativas que desarrollan la actividad.
 * un *conjunto de estados*, el balance de la empresa.

La empresa transforma materias primas (proceso técnico), transforma
ahorro en capital (proceso financiero) y procesa información (proceso
mental).

**** Clasificación de sistemas
Se clasifican en

 * *abiertos* si se relacionan con el entorno.
 * *cerrados* si no interaccionan con el entorno.
 * *naturales* si no influye el ser humano en su creación.
 * *artificiales* si se crean por voluntad humana.

La empresa se considera un sistema abierto artificial.

**** Retroalimentación o feedback
La empresa se considera *autorregulada* porque cuando se desvía de los
objetivos, el proceso de *retroalimentación o feedback* permite
conocer a la empresa que se han producido estas desviaciones y
corregirlas. Puede así adaptarse al entorno.

La *homeostasis* es la capacidad de la empresa de mantener esa
estabilidad.

*** 1.3. Subsistemas funcionales de la empresa
**** Principio de jerarquía
El *principio de jerarquía* permite descomponer un sistema en
subsistemas y estudiarlos concretamente.

**** Subsistemas según criterio funcional
El *criterio funcional* de jerarquización divide a la empresa en tantos
subsistemas como actividades desarrolle. Estos son

 * *subsistema de aprovisionamiento*, que adquiere los insumos.
 * *subsistema de producción*, transforma insumos en productos.
 * *subsistema de comercialización*, decide precio, promoción y
   distribución.
 * *subsistema de recursos humanos*, selecciona y orienta
   trabajadores.
 * *subsistema financiero*, decide los fondos y aplica inversiones.
 * *subsistema de dirección*, estrategia y gestión de la empresa.

**** Sinergia
La *sinergia* es el aumento de productividad de varios sistemas cuando
interactúan entre ellos frente a cuando trabajan de manera aislada.

*** 1.4. La dirección de empresas
**** Eficiencia y eficacia
La *eficacia* mide el nivel de cumplimiento de los objetivos. La *eficiencia*
mide el uso de la cantidad adecuada de recursos para lograr sus objetivos.

Una empresa bien dirigida debe ser eficaz y eficiente.

**** Funciones de los administradores
La gestión empresarial define las siguientes *funciones del directivo*, que
son propias del subsistema de management o dirección.

 * La *planificación* define la estrategia de la empresa y los planes para
   conseguir los objetivos.
 * La *organización* diseña la estructura para realizar las tareas,
   asignando personal y decidiendo cómo se tomarán decisiones.
 * La *dirección* coordina a la organización, motivando, comunicando y
   resolviendo potenciales conflictos.
 * El *control* vigila el desempeño de la organización, lo compara con
   los objetivos y lo corrige en caso de que sea necesario.

** 2. Teorías de la empresa y del empresario
*** 2.1. Teorías de la empresa
# Nada

*** 2.2. Teorías del empresario
**** Evolución histórica del empresario
Se consideran figuras distintas según la época, en

 * *capitalismo mercantilista* (S. XVI-XVIII), existe un estado que es el
   agente económico predominante y mercaderes, que simplemente comercian.
 * *revolución industrial* (S. XVIII-XIX), se desarrolla el pensamiento
   clásico capitalista del empresario *Adam Smith* habla de la regulación
   del mercado por la mano invisible. En el siglo XIX, *Karl Marx* explica
   el beneficio como la extracción de la plusvalía de los trabajadores
   mediante la propiedad privada de los medios de producción.
 * *aportaciones posteriores*, Cantillon define en el S. XVIII el
   /entrepreneur/ y habla del talento del empresario. Say aporta la
   función directiva en el S. XIX.

**** Teoría del empresario riesgo. Knight (1921)
*Knight* desarrolla la figura del empresario como persona que asegura las
rentas de los factores productivos, adelantando el pago. El riesgo que
asume al aportar el dinero es lo que justifica el beneficio empresarial.

Los riesgos serán

  - *técnicos*, como cumplir con la producción esperada.
  - *financieros*, al aportar el capital inicial.

**** Teoría del innovador de Schumpeter (1912)
*Schumpeter* diferencia en /Teoría del desenvolvimiento económico/
entre capitalista y empresario. El empresario será el que aplica una
tecnología existente a un problema real, el capitalista pone el dinero.

Se justifica el beneficio porque se dice que esa innovación es la que
desencadena el desarrollo económico y social.  Así, el empresario que
innova es el motor del progreso económico y social.

El cambio tecnológico se desarrolla en un ciclo entre un *monopolio*
*temporal* del empresario sobre la innovación y lo pierde luego a una
*situación de equilibrio*.

# **** Autónomos
# Nos dicen que hay menos autónomos en España que en Europa por
# culpa de las cuotas de autónomo. Aquí artículos en contra:
#
# - [[http://www.ticbeat.com/empresa-b2b/desmontando-el-mito-de-la-cuota-de-autonomos-en-espana-y-europa/][Desmontando el mito de la cuota de autónomos en España]]
# - [[http://www.elderecho.com/actualidad/Espana-quinto-Europa-autonomos-ATA_0_457500143.html][España, quinto país de Europa que más autónomos crea con 46.000 nuevas altas]]
#
# Pero hay miles a favor también. Ojalá manejáramos datos.

***** Proceso de cambio tecnológico
Se definen tres fases

 - *invención*, generación de nuevas ideas, ajena a la actividad empresarial.
 - *innovación*, aplicación de la invención a un producto.
 - *imitación*, difusión de la innovación.

**** Tecnoestructura de Galbraith (1950s)
*Galbraith* supera la concepción de empresario como persona y deja que
delegue en la /tecnoestructura/, un grupo de personas, un órgano
colegiado, que dirige la empresa.

Separa propietario (capital de la empresa) y gestor (administración).

*** 2.3. Propiedad, dirección y gobierno de la empresa
**** Definición de directivo
El *directivo* supervisa la combinación de los recursos productivos. Sus
funciones son

 * fijar objetivos y toma decisiones.
 * coordinar la empresa.
 * coordinar relación de la empresa con el entorno.

Los directivos suelen ser los mismos propietarios, pero pueden ser gestores
contratados u otras personas al nombre del propietario.

**** Definición de capitalista
El *capitalista* es el propietario del capital de la empresa.

**** Empresario
El *empresario* es un directivo capitalista. 

/Ejemplos: Amancio, Florentino./

***** Emprendedor
Llamamos *emprendedor* al empresario que es a su vez el creador de la
idea del negocio o del cambio y se implica a nivel gestor y
capitalista.

***** Empresario individual propietario
Según Cuervo (1997), es el empresario clásico en el que convergen 
capitalista y directivo; sigue las nociones de [[*Teoría del empresario riesgo. Knight (1921)][empresario riesgo]] y
[[*Teoría del innovador de Schumpeter (1912)][empresario innovador]].

***** Empresario corporativo
Controla la empresa sin participar significativamente en el capital.
Es parte sólo de la tecnoestructura.

**** Estructura de la propiedad de la empresa
La *estructura de la propiedad* de una empresa es el modo en el que se
distribuye la propiedad del capital de la empresa entre sus
propietarios legales. Todo partícipe en el capital de la empresa tiene
la consideración legal de *propietario*; es decir, los propietarios
son las personas (físicas y jurídicas) que aportan el dinero y los
bienes necesarios para la actividad productiva.

Los propietarios pueden haber accedido a la titularidad

  * creándola.
  * heredándola.
  * comprándola.

***** Grupos de propiedad
Se consideran los siguientes grupos de propiedad en la empresa

 * sector público.
 * particulares y familias.
 * empresas industriales y servicios (capital empresarial).
 * entidades financieras (capital bancario).

La estructura de la propiedad refleja la importancia relativa de los
grupos. Varía según sectores y países y condiciona los objetivos que
persigue la empresa.

**** Estructura accionarial
La /estructura de la propiedad/ en sociedades anónimas se distribuye
entre los *accionistas*. Los hay de dos tipos

 * *accionistas de control*, si son activos en las decisiones de la
   empresa.
 * *accionistas pasivos*, si son simples inversores financieros.

La estructura accionarial completa se divide en

 * *Autocartera*, las acciones propias que la sociedad mantiene entre
   sus activos.
 * *Accionistas mayoritarios y de control*, que tienen control de la
   empresa.
 * *Pequeños accionistas*, capital flotante en compraventa libre en el
   mercado financiero. Son propietarios sin poder en la empresa, para
   controlarla necesitan asociarse.
 * *Inversores institucionales*, sociedades de inversión, fondos de
   pensiones o compañías de seguros que buscan la rentabilidad.

**** Gobierno corporativo
El *gobierno corporativo* es la estructura que concreta las relaciones
entre todos los /stakeholders/ para establecer los objetivos de la empresa
y los medios para controlarla.

***** Motivación
Cuando las empresas son pequeñas, suele coincidir la propiedad y la
gestión. Conforme crecen, deben dotarse de estructuras que limiten
conflictos y aseguren que los directores no toman decisiones
contrarias a los propietarios.

Se intenta paliar un problema que surge en un contexto de información
asimétrica; donde las partes interesadas pueden tener intereses
contrarios a la empresa.

***** Responsabilidad social corporativa
Los criterios de *responsabilidad social corporativa* (RSC) son códigos
de buen gobierno que buscan asegurar
 
 * la confianza y la transparencia.
 * el adecuado funcionamiento de los órganos y la separación entre ellos.
 * el control interno y la responsabilidad.

En particular, las empresas que cotizan en la comisión del mercado de
valores deben seguir un código de gobierno específico.

**** Mecanismos de control
Los *mecanismos de control* delimitan el modelo de gobierno corporativo que
sigue la empresa.

**** Mecanismos internos de control
Los *mecanismos internos* son los diseñados por la propia organización.

***** Junta general de socios accionistas
En una /sociedad anónima/, la *Junta General de Socios* es una reunión
de accionistas que toma acuerdos por mayoría. 

Sus competencias son:

 * nombrar al consejo de administración.
 * nombrar y destituir administradores.
 * disolver la sociedad.
 * elegir consejero ejecutivo.
 * adquirir de determinados bienes y tomar otras decisiones.

Es obligatoria y debe reunirse anualmente. Nótese que no puede
administrar, tomar acuerdos contrarios a los estatutos o representar a
la sociedad; sólo puede nombrar a los /administradores/.

***** Consejo de administración
En /sociedades de capital/ (limitadas, anónimas y comandatarias), el
*consejo de administración* está formado por personas elegidas por los
propietarios que administran y representan a la empresa.

Está compuesto por:

 * *Consejeros internos o ejecutivos.* Delegados de la
   empresa. /Ejemplo: Jobs, Zuckerberg./
 * *Consejeros externos dominicales.* Significativos. Representan
   empresas con capital en la sociedad.
 * *Consejeros externos independientes.* Expertos en gestión que son
   independientes. /Ejemplo: Felipe González, José María Aznar./

***** Caso de las empresas pequeñas
Normalmente coinciden. Sólo a partir de cierto tamaño tienen que
nombrar administradores.

**** Mecanismos externos de control
Los *mecanismos externos* son los que se derivan de la estructura de la
economía de mercado.

***** Oferta Pública de Adquisición de Valores (OPA)
Intenta comprar parte de una empresa para controlar sus cambios de
dirección. Puede intentarse por alterar su estructura financiera o
para construir imperios empresariales.

***** Mercados financieros
Con los fondos se determinará el valor de la empresa y la posibilidad
de ser controlada desde el exterior.

***** Mercado laboral de consejeros y directivos
La alta competencia del mercado laboral de consejeros y directivos hace
que funcionen correctamente. Se compra su reputación positiva, que deben
haber ganado en otras empresas previamente.

*** 2.4. La dirección: funciones y niveles
La *dirección* consiste en la integración de las distintas partes de la
empresa entre sí. Se divide en varios niveles de jerarquización de las 
decisiones.

**** Alta dirección
La *alta dirección* está formada por personas con responsabilidad
sobre toda la empresa que fijan los grandes objetivos.  Lo forma el
/comité ejecutivo/ de la empresa con el /director ejecutivo/ (también
consejero delegado o CEO) y las personas que considere para participar
de los análisis gestores de la empresa. 

/CEOs, Comité Ejecutivo, Presidente Ejecutivo, Consejero Delegado./

**** Dirección media
La *dirección media* la forman los directivos que actúan como enlace
jerárquico entre la alta dirección y la dirección de primera línea.
Marcan objetivos a medio y corto plazo, que deben estar alineados con
los grandes objetivos.

/Directores departamentales, director financiero, director comercial./

**** Dirección de primera línea
La *dirección de primera línea* la constituyen supervisores y directivos
que toman decisiones en problemas diarios y rutinarios para la empresa.

/Jefes de equipo, capataces, jefe de planta./

** 3. Entorno de la empresa
*** Objetivos
Conocer:

 - Análisis de entorno. PEST.
 - Comprender su utilidad en la dirección estratégica.

En conjunto forma el análisis DAFO.

**** Análisis externo: amenazas y oportunidades
**** Análisis interno: debilidades y fortalezas
*** 3.1. Definición de entorno
La empresa es un sistema abierto (se relaciona con el exterior). Según
sus decisiones cambia su relación con el entorno.

**** Definición
Conjunto de factores que, *siendo externos a la empresa*, tienen o
pueden tener incidencia en sus actuaciones y resultados.

*(!) Nada que sea parte de la empresa es entorno de la empresa.*

**** Influencia del entorno
La empresa puede influir, pero no controlar el entorno.

**** Límites del entorno
Los límites del entorno varían según la relación con el exterior.
Los proveedores pueden considerarse internos a la empresa. Son los
llamados *límites difusos*.

**** Factores estratégicos
Está formado por los factores que pueden incidir en el presente o
en el futuro en los planes o resultados de la empresa.

# Estaría muy bien un análisis formal o científico o algo de lo que
# cuentan en análisis de factores externos. Cada frase son mil
# contraejemplos.

**** Análisis del entorno
Debe sistematizarse el análisis de los factores estratégicos para 
tratar de estar preparado y anticiparse a los cambios.

***** Niveles del entorno
****** Entorno global
****** Entorno internacional
****** Entorno doméstico o nacional
****** Entorno regional
****** Entorno local
*** 3.2. Características del entorno
La teoría que caracteriza como fuente de recursos o como fuente de
incertidumbre.

**** Fuente de recursos
***** Estable-Aleatorio
Los recursos son de fácil acceso.
/Ultramarinos de un pueblo. Sin competencia. Estable./

***** Plácido-Integrado
Los recursos se concentran.

***** Inestable-Reactivo
***** Turbulento.
**** Fuente de incertidumbre
Nivel de certidumbre del entorno. Cuanto más información hay, es
más predecible o cierto.

***** Dinámico/Estable
Variaciones en la estructura del entorno.

***** Complejo/Sencillo
Grado de conocimientos necesarios para entender el entorno

***** Diverso/Integrado
Áreas diversas o reducidas, clientes diversos o reducidos.

***** Hostil/Munificiente
Mucha competición y pocos recursos.

**** Entorno estratégico: general y específico
El entorno general está integrado por un conjunto de factores que
ejercen influencia sobre todas las empresas dentro de un sistema
socioeconómico.

***** Entorno general: Análisis PESTEL
****** Partes
******* Político
Por la estabilidad, proteccionismo e intervencionismo del estado.
Nivel de corrupción de un país.

******* Económico
******** Inflación
El IPC marca los precios al consumo. Hay inflación y deflación
según suban o bajen.

******** Tasa de desempleo
******** Tipo de cambio
Frente al dólar como base.
******** Renta disponible
Renta a las familias corregida por inflación.
******** Tipos de interés
******* Social
Preferencias como valores, creencias, desigualdad, religión,
feminismo, tradición, cultura.

******* Tecnológico
Grado de infraestructuras del país. Gasto en I+D. Inversión pública
del gobierno y patentes. Leyes de proyección del conocimiento.

******* Ecológico
Política medioambiental y consumo de energía.

******* Legal
******** Legislación laboral
******** Normativa de fusiones, adquisiciones
******** Restricción a la libre competencia

****** Fases
******* Variables y factores clave
******* Oportunidades y amenazas
****** Críticas
Es muy subjetivo y cualitativo. No debe entrar en detalles y sólo
debe tratar los factores más relevantes.

No todas las variables estarán en un análisis PEST. Hay que ser
selectivos y sólo considerar los *factores estratégicos*.

****** Tabla
Todo el análisis puede representarse en una tabla.

***** Entorno general: PESTEL ampliado
En ocasiones se utiliza una versión ampliada del PESTEL.

***** Entorno general: Diamante de Porter
No lo vamos a ver en clase.

**** Entorno estratégico específico
Conjunto de empresas que se dedican a la misma actividad económica que
la empresa, forman el *sector*. Marca las reglas de competencia.

***** Modelo de las 5 fuerzas competitivas de Porter (2009)
El *grado de atractivo* de una industria viene determinado por 5
fuerzas competitivas básicas, que definen la posibilidad de obtener
rentas superiores en la industria. A más rivalidad, menos posibilidad
de obtener rentas superiores.

También se llama *modelo de rivalidad ampliada*.

****** Competidores actuales
Grado de rivalidad con los competidores del sector. Depende de

******* Número y equilibrio entre competidores.
A más competidores y más equilibrados, más competencia. Cuanto
más fragmentado está un sector más competitivo. Cuanto más concentrado
está, es más oligopólico y la competencia es menor.

Una *industria concentrada* (farmacéutica, hay pocas y tienen mucho
poder; compañías de telefonía) y una *industria fragmentada* (bares,
hay muchos y muy distintos).

# ¿Hay un índice de competencia?

******* Ritmo de crecimiento del sector.
Sectores maduros o en declive tienen menor ritmo de crecimiento.
Las ventas en este caso se reparten entre los que ya están y
la competencia es mayor.

******** Ritmo de crecimiento de la industria
Hay cuatro fases

 * Introducción
 * Crecimiento, menos competencia.
 * Madurez.
 * Declive, más competencia.

Y la posibilidad de incrementar las ventas es más difícil
después. La intensidad de la competencia es mayor conforme
avanza.

******** Ejemplos de ritmo de crecimiento
********* Introducción (Realidad virtual, coches autónomos)
********* Crecimiento (Pulseras de fitness, drones)
********* Madurez (Automóviles, libros electrónicos, electrodomésticos)
********* Declive (Ordenadores de escritorio, SMS, CD)

******* Barreras de movilidad.
Cuantas más barreras, menor la competencia. Son las barreras que
encuentran para ampliar su linea de productos a otros segmentos del
sector. Si hay muchas barreras, las empresas se quedan donde están
y la competencia del sector es menor.

******** Ejemplo: banca privada
Hay unas barreras muy grandes entre servicios usuales y los servicios
privados. Los contratos suelen estar blindados y los canales de
distribución suelen trabajar con las marcas que ya conocen.

Es muy difícil iniciarse en la banca privada.

******** Ejemplo: automoción
Sólo unas pocas fabrican coches y camiones. Es difícil saltar del
diseño de unos al diseño de otros; se necesitan tecnología, cadenas
y materiales diferentes.

******* Barreras de salida.
Cuantas más barreras de salida, mayor la competencia. Las barreras de
salida son el equivalente a la movilidad a nivel de sector. Cuanto más
difícil es salir del sector, más intentarán sobrevivir las empresas y
mayor será la competencia.

******** Ejemplo
Si hay activos especializados que no se amortizan, y que por ser tan
específicos, es muy difícil vender.

******** Costes fijos de salida
Para cerrar, hay que hacer frente a costes como los costes de
despidos.  Las empresas que no quieren pagarlos, se mantienen en el
sector.

******** Imagen de marca
En ocasiones se mantiene un sector sólo para mantener el prestigio de
la imagen de marca. El daño a la imagen es un coste de salida.

******** Empresa familiar
La barrera emocional de seguir negocio familiar tradicional constituye
una barrera de salida. Están dispuestas a continuar a pesar de las
pérdidas.

El ejemplo usual es la /almazara/.

******** Presiones externas
Fábricas que emplean a mucha gente en una región.

******* Estructura de costes de las empresas.
Cuantos menos costes fijos, menos volumen y más intensidad competitiva.
La *estructura de costes* es la proporción entre costes fijos y
costes variables

\[
CT = CF + CV
\]

Siendo
 
 * CF: Costes fijos. Hay que pagarlos siempre.
 * CV: Costes variables. Se pagan según cuánto produzcas.
 * CT: Costes totales.

El margen de beneficio es la diferencia del precio y el coste de
producción unitario $\mathrm{margen_{unitario}} = p - c_v$. El margen bruto es el
margen unitario por número de unidades

\[\mathrm{margen} = u(p - c_v).
\]

Nótese que es distinto del beneficio (!), que tiene en cuenta también
los costes fijos. El beneficio es $B = \mathrm{Ingresos} - CT$.

Así, cuando los costes fijos son muy grandes, es muy difícil entrar
en la competencia, así que la competencia será menor. El *punto muerto*
es el punto a partir del cual se van a obtener beneficios.

******* Grado de diferenciación de los productos/servicios.
La diferenciación de productos disminuye la intensidad de la
competencia. Cada uno vende cosas distintas y tiene una cartera de
clientes fieles que es difícil que cambien de proveedor.

******** Ejemplo: compañías telefónicas tienen poca diferenciación.
******** Ejemplo: las bebidas son diferentes.

******* Costes de cambio.
Los *costes de cambio* son los que debe asumir un cliente para cambiar
de proveedor. Cuantos más altos, más difícil es que cambie un cliente
y menor es la competencia. Pueden ser técnicos, de formación o
financieros.

/Ejemplo: es difícil el cambio de compañía telefónica por permanencias./

******* Capacidad productiva instalada.
Si una empresa construye una planta para producir 1000 unidades/día, 
tendrá producir a ese volumen para rentabilizarla. Cuando más capacidad
productiva instalada, hay más necesidad de vender los productos, y más
alta es la competencia.

******* Diversidad de competidores.
Si los competidores difieren en estrategias, puede aumentar la
competitividad.

******* Intereses estratégicos.
Cuando todas las empresas están interesadas en el sector, mayor será
la competencia.

****** Competidores potenciales
La amenaza de nuevos competidores depende de dos factores.

******* Barreras de entrada
Los obstáculos para entrar al sector.

******** Escalabilidad
Reducciones de costes que se tienen cuando se incrementa el volumen
de producción.

 * La escala la da el reducir costes al producir más con los mismos
   costes fijos. Puede costar menos unitariamente el producir más.
 * La deseconomía de escala la pueden dar los costes de gestión o
   de organización. Puede empezar a costar más coordinar tanto.

Cuando hay una economía de escala, los que entran nuevos tienen
una barrera para entrar a gran escala.

********* Sinergia
Utilizar el mismo recurso productivo (el trabajador, al final),
para distinto tipo de actividades. Incrementa la escalabilidad;
al tener más cosas hemos podido explotar más al trabajador (sic.).
******** Diferenciación de productos
Cuando todos tienen diferenciados sus productos, el que quiera entrar
tendrá que ofrecer algo diferente para poder competir al mismo nivel.

******** Necesidades de capital
Un sector que necesita una inversión muy grande tiene una barrera de
entrada muy grande

********* Ejemplo: farmacias, estancos
Cuesta mucho poner una nueva.
******** Costes de cambio
Si los clientes están fidelizados, el que entre nuevo en el sector
va a tener que saltar la barrera de los costes de cambio.

******** Acceso a canales de distribución
Normalmente estarán en manos de las empresas del sector.

******** Costes de desarrollo
Hay que pagar patentes o desarrollar tecnologías alternativas. Hay
que encontrar buenas localizaciones, que las tienen las empresas del
sector. La experiencia del sector la tienen las empresas.

******** Factores gubernamentales
Restricciones que limitan la entrada al sector. Normas reguladoras de
la competencia que impiden la libre competencia en el mercado.

******* Reacción esperada
Represalias de los competidores que están ya en el sector contra
los nuevos competidores. Las represalias son mayores cuanto más
recursos de defensa pueden invertir en la represalia.

******** Ejemplo: farmacéuticas, teleoperadoras
Tienen contactos (gobiernos, proveedores) para evitar que entren
otras empresas en el sector.

****** Productos sustitutivos
Cubren la misma necesidad del cliente usando otra tecnología o
materias primas alternativas.

Pueden no tener siquiera el mismo CNAE, y no los consideramos dentro
del mismo sector, pero hay competencia entre ellos.

Si hay muchos productos sustitutivos, será menos atractivo el sector.
Dependerá además de

  * el grado de sustitución.
  * los precios relativos al sustitutivo.
  * obsolescencia que causan los sustitutivos.
  * costes de cambio al sustitutivo.

******* Ejemplos
 * Azúcar/sacarina.
 * Aceite oliva/girasol.
 * SMS/Telegram.

****** Proveedores
A mayor poder de negociación, más podrán influir en el coste o los
plazos de entrega de las empresas del sector.

Cuanto más concentrados y menos sustitutos haya para los proveedores,
más poder de negociación tendrán.

******* Integración vertical
La amenaza de que el proveedor integre nuestro sector como parte de la
cadena del suyo. Que asuma el siguiente paso de la cadena de
producción como suyo propio.

Si puede integrarse, el poder de negociación del proveedor aumenta.
Cuanto más informado esté el proveedor, más fácil es que entre en el
sector por integración vertical.

******** Ejemplo: Apple
Además de producir, se encargan de vender en tiendas propias.

******** Ejemplo: Inditex
Ha ido haciendo integración hacia atrás encargándose también de
producir las telas.

******** Ejemplo: ordenadores
La empresa que sólo compra y ensambla tiene una integración vertical
menor que si produjera ella misma los componentes.

****** Clientes

***** Limitaciones y extensiones al modelo de las cinco fuerzas
Al modelo de las 5 fuerzas se le plantean las siguientes críticas

 * tiene un carácter estático, requiere de una actualización del
   análisis siempre que se pueda.
 * no tiene en cuenta industrias auxiliares y complementarias; no
   considera relaciones de colaboración.
 * no todas las fuerzas ni todos los factores tienen la misma
   influencia.
 * no todos los competidores se encuentran afectados de la misma
   manera por las fuerzas del sistema. (Se intenta salvar esto mediante
   el análisis de los sectores estratégicos, que aplica un análisis
   particular en los distintos grupos estratégicos; es distinta la
   competencia de Inditex y la de una pequeña textil) 


** 4. La dirección estratégica
** 5. La dirección financiera
* Affine group schemes seminar
** I. Álgebras de Hopf
*** 1. Definiciones
**** Álgebra de Hopf
Un *álgebra de Hopf* es una biálgebra (álgebra y coálgebra) con un 
antiautomorfismo llamado /antípoda/.

***** Explícitamente
Tenemos $(H, m, \eta, \Delta, \varepsilon, S)$ como componentes del álgebra de Hopf sobre
un cuerpo $k$, donde:

 - $H$ es el álgebra.
 - $m : H \otimes H \to H$ es el producto.
 - $\eta : k \to H$ es la unidad.
 - $\Delta : H \to H \otimes H$ es la comultiplicación.
 - $\varepsilon : H \to k$ es la counidad.
 - $S : H \to H$ la antípoda.

Bajo ciertas condiciones de compatibilidad.

**** Group-like elements
Elementos no nulos cumpliendo $\Delta(x) = x \otimes x$. Forman un grupo con la inversa
dada por la antípoda.

** II. Introduction to affine group schemes
*** 1. Definition and examples
**** Affine group scheme
An *affine group scheme* over $k$ is a representable functor $\mathtt{Alg}_k \to \mathtt{Grp}$.
More precisely, the composition of the functor with $\mathtt{Grp}\to\mathtt{Set}$ is
representable.

**** Connection with affine algebraic varieties
If $V$ is an affine algebraic variety, the we can define the corresponding
affine scheme as $Alg_k(K[V], -)$, where $K[V]$ is the coordinate algebra.

**** Algebraic affine scheme
An affine scheme is said to be *algebraic* if its representing object is
finitely generated as a k-algebra.

** III. Esquemas diagonalizables y constantes
*** 1. Introducción
**** Álgebra grupo
Dado un grupo $G$ y un cuerpo $k$, el álgebra grupo $k[G]$ está formada como el
espacio vectorial libre sobre $G$ con el producto que induce el grupo.

***** Estructura de álgebra de Hopf
Este álgebra tiene estructura de álgebra de Hopf si extendemos linealmente
las siguientes aplicaciones:

  - $\Delta(x) = x \otimes x$
  - $\varepsilon(x) = 1$
  - $S(x) = x^{-1}$
* Local variables
# Local Variables:
# eval: (text-scale-increase 1)
# End:
