#+TITLE: Grupos y representaciones
#+AUTHOR: Mario Román
#+EMAIL: mromang08@gmail.com

#+SETUPFILE: config.setup
#+LANGUAGE: es

* 1. Álgebras y módulos
** 1.1. Noción de álgebra
*** 1.1. Álgebra
Un *álgebra* sobre un cuerpo $K$ es un K-espacio vectorial dotado de una
aplicación bilineal $(\cdot) : K \times K \longrightarrow K$. La bilinealidad se expresa como:

  1. $(a+b)c = ac+bc$
  2. $a(b+c) = ab+ac$
  3. $(\alpha a)b = \alpha(ab) = a(\alpha b)$

**** Álgebra asociativa
Un álgebra es *asociativa* si $(ab)c = a(bc)$.

*** 1.2. Subálgebra
Una *subálgebra* es un subespacio vectorial de un álgebra cerrado para
el producto.

*** 1.3.a. Álgebra conmutativa
Un álgebra es *conmutativa* si $ab = ba$.

*** 1.3.b. Centro de un álgebra
Se define el *centro* de un álgebra asociativa como:

\[
Z(A) = \{c \in A \mid ac = ca,\; \forall a \in A \}
\]

*** 1.4. Ideal de un álgebra
Un subespacio vectorial de álgebra, $I \subseteq A$ es *ideal* si el producto por
cualquier elemento está en el ideal $ai,ia \in I$.

*** 1.5. Cociente por un ideal
Sobre el K-espacio vectorial cociente por un ideal $A/I$, podemos definir
una K-álgebra mediante $(a+I)(b+I) = ab+I$.

**** Buena definición
Supongamos que $a+I = a'+I$ y que $b+I = b'+I$, entonces tenemos 
que:

\[
ab- a'b' = a(b-b') - (a-a')b' \in I
\]

*** 1.6. Homomorfismos de K-álgebras
Una aplicación lineal entre álgebras $f : A \longrightarrow A'$ es homomorfismo de
K-álgebras si respeta el producto:

\[
f(ab) = f(a)f(b)
\]

**** Isomorfismo de K-álgebras
Cuando un homormofismo de K-álgebras es biyectivo, se llama *isomorfismo*
y su inversa es también homomorfismo de K-álgebras.

*** 1.7. Primer teorema de isomorfía
Si $f : A \longrightarrow A'$ es homomorfismo de K-álgebras, $\mathrm{Im} f$ es subálgebra y $\ker f$
es ideal. Además, tenemos un isomorfismo de K-álgebras canónico:

\[
\widehat f : A/\ker f \longrightarrow \im f
\]

dado por $\widehat f(a+\ker f) = f(a)$.

**** Demostración
***** La imagen es subálgebra
Trivialmente, la imagen es espacio vectorial y $f(a)f(b) = f(ab)$.

***** El núcleo es un ideal
El núcleo es subespacio vectorial y además,

\[
f(ak) = f(a)f(k) = 0 = f(k)f(b) = f(kb)
\]

para cualquier $f(k) = 0$.

***** Isomorfismo de álgebras
Comprobamos que está bien definido, ya que si $a + \ker f = b + \ker f$,
se tiene que $\widehat f(a+\ker f) - \widehat f(b + \ker f) = f(a-b) = 0$.

La función es lineal y preserva el producto por la definición de
producto con la que hemos dotado al ideal. Ahora, comprobamos que
es inyectiva por tenerse:

\[
\widehat f(a+\ker f) = 
\widehat f(b+\ker f) \implies f(a-b) =
0 \implies a-b \in I
\]

Es trivialmente sobreyectiva.

*** 1.8.a. Álgebras unitales
Una K-álgebra asociativa es *unital* si existe un neutro para el
producto.

\[
1_Aa = a = a1_A; \quad 1_A \neq 0
\]

**** Homormofisos de álgebras unitales
A los homomorfismos de álgebras unitales se les pide respetar la
unidad. Para $f : A \to B$, $f(1_A) = 1_B$.

**** Asunción posterior
En el curso trabajaremos siempre con álgebras asociativas y unitales.

*** 1.9. Inclusión del cuerpo en el álgebra
Sea $A$ una K-álgebra, la inclusión $u : K \longrightarrow A$ es homomorfismo inyectivo
de K-álgebras. Como consecuencia $\im u \subseteq Z(A)$, y es una K-subálgebra.

**** Demostración
***** Es homomorfismo
La inclusión definida por $u(k) = k1_A$ es lineal por tenerse:

\[
u(\gamma\alpha+\beta) =
(\gamma\alpha+\beta)1 =
\gamma(\alpha 1) + \beta 1 =
\gamma u(\alpha) + u(\beta)
\]

Y además es multiplicativa:

\[
u(\alpha)u(\beta) = (\alpha 1)(\beta 1) = \alpha\beta 11 = u(\alpha\beta)
\]

Y trivialmente unital por $u(1) = 1$.

***** Es inyectivo
Si $u(k) = u(k')$ entonces $(k-k')1_A = 0$.

***** Es subálgebra del centro
Aplicando bilinealidad de la multiplicación:

\[u(\alpha) a = 
(\alpha 1)a = 
\alpha (1a) = 
\alpha (a1) = 
a(\alpha 1) =
au(\alpha)\]

** 1.2. La representación regular. Unidades y divisores de cero
*** 1.11.a. Álgebra de endomorfismos
Los endomorfismos de un K-espacio vectorial forman una K-álgebra con la
composición:

\[
End_K(V) = \{ f : V \longrightarrow V \mid f \text{ es lineal}\}
\]

**** Demostración
La suma se define por $(f+g)(v) = f(v)+g(v)$, lo que da un grupo abeliano
con el neutro $0(v) = 0$; además, con $(\alpha f)(v) = \alpha f(v)$, nos da un espacio
vectorial.

Comprobamos además que la composición es bilineal:

  1. $((f+g)\circ h)(v) = f(h(v)) + g(h(v)) = (f\circ h + g\circ h)(v)$
  2. $(f\circ (g+h))(v) = f(g(v)) + f(h(v)) = (f\circ g + f\circ h)(v)$
  3. $(\alpha f \circ g)(v) = \alpha (f\circ g)(v)) = f(\alpha g(v)) = (f \circ \alpha g)(v)$

Donde en el primer y segundo punto usamos la definición de suma; y
en el tercer punto usamos la linealidad de la función para conmutar
el elemento del cuerpo y la aplicación de la función.

*** 1.11.b. Inclusión en los endomorfismos
Sea $A$ cualquier K-álgebra. La aplicación $\lambda : A \longrightarrow End_K(A)$ que asigna
a cada $a \in A$ la aplicación $\lambda_a : A \longrightarrow A$ definida por $\lambda_a(b) = ab$ para
todo $b \in A$ es un homomorfismo inyectivo de K-álgebras.

**** Caso finito
Toda K-álgebra de dimensión finita es isomorfa a una subálgebra de
matrices con coeficientes en $K$.

**** Demostración
***** Es homormorfismo
Por los axiomas de K-álgebra, $\lambda_a$ es siempre lineal. Además, la propia
$\lambda$ es lineal por tenerse:

\[
\lambda_{a+\alpha b}(c) = (a+\alpha b)c = ac + \alpha bc = 
\lambda_a(c) + \alpha\lambda_b(c) = (\lambda_a+\alpha\lambda_b)(c)
\]

Además, es multiplicativa por asociatividad:

\[
\lambda_{ab}(c) = (ab)c = a(bc) = \lambda_a \circ \lambda_b (c)
\]

***** Es inyectiva
Si $\lambda_a = 0$, se tiene $a = \lambda_a(1) = 0$.

*** Álgebra opuesta
El álgebra opuesta $A^{op}$ es la propia $A$ con el producto dado por:

\[
a \cdot b = ba
\]

*** Unidades y divisores de cero
Un $a \in A$ no nulo es *unidad* si existe $a^{-1} \in A$ tal que $aa^{-1} = 1 = a^{-1}a$.
El conjunto de las unidades, $U(A)$ forma un grupo con el producto.

**** Divisor de cero
Un $a \in A$ no nulo es *divisor de cero* si $\exists b: ab = 0$ ó $ba = 0$.

**** Clasificación en unidades y divisores de cero en dimensión finita
Sea $a \in A$ no nulo para $A$ k-álgebra de /dimensión finita/:

1. Equivalen:

   - $a \in U(A)$
   - $\exists b \in A : ab = 1$
   - $\exists c \in A : ca = 1$

2. Equivalen:

   - $a \notin U(A)$
   - $\exists b \in A: ab = 0$
   - $\exists c \in A : ca = 0$

Es decir, todo elemento no nulo es una unidad o un divisor de cero.

***** Demostración primer punto
Si $ab = 1$, $\lambda_a$ es sobreyectiva y $\lambda_b$ es inyectiva. Por ser de dimensión
finita ambas son isomorfismos. Se aplica sobre el álgebra opuesta para
llegar a la otra implicación.

***** Demostración segundo punto
Ssi $ab = 0$, $\lambda_a$ no es inyectiva, y por tanto no puede ser unidad.

**** Clasificación por el determinante
Si en un álgebra de dimensión finita tomamos la representación regular
$\lambda: A \to \mathrm{End}(A)$; podemos usar el determinante para decidir si $a \in A$ es
una unidad.

*** Álgebra de división
Un álgebra $A$ es un *álgebra de división* si $U(A) = A \setminus \{0\}$. Los cuerpos
son álgebras de división conmutativas.

** 1.3. Representaciones y módulos
*** Representación
Una *representación* de un álgebra $A$ es un homomorfismo de k-álgebras
$\mu : A \longrightarrow End_K(V)$, donde $V$ es el k-espacio vectorial de representación.

**** Representación fiel
Se llama representación *fiel* cuando $\mu$ es inyectiva.

**** Representación regular
La inclusión en los endomorfismos $A \to \mathrm{End}(A)$ es una *representación fiel*
que llamamos representación regular.

*** Módulos de un álgebra
Dada $A$ álgebra, un A-módulo por la izquierda es un espacio vectorial $V$
con un producto bilineal $A \times V \to V$ cumpliendo $(ab)v = a(bv)$ y $1v = v$.

**** Submódulos
Llamamos *submódulo a izquierda* a un subconjunto $N$ de un módulo que 
sea subgrupo aditivo y que cumpla $an \in N$ para $n \in N$. Los submódulos
de un álgebra se llaman *ideales a izquierda*.

**** Retículo de submódulos
Llamamos ${\cal L}(M)$ a la familia de submódulos de $A$. Forman un retículo bajo
la suma y la intersección.

**** Submódulo generado
El submódulo generado por un conjunto de elementos es el menor submódulo
que los contiene.

*** Equivalencia de módulos y representaciones
Sean $A$ una k-álgebra y $V$ un k-espacio vectorial. Hay una biyección
entre el conjunto de representaciones de $A$ sobre $V$ y los A-módulos
por la izquierda sobre $V$.

**** Demostración
Si tenemos una representación $\mu\colon A \to \mathrm{End}(V)$, definimos el A-módulo
dado por $av = \mu(a)(v)$. Si tenemos una estructura de A-módulo podemos
construir la representación $\mu(a)(v) = av$.

*** Suma directa de módulos
Llamamos *suma directa* de los módulos $M_1,\dots,M_n$ al módulo sobre su
producto cartesiano con las operaciones

 * $(m_1,\dots,m_n) + (m_1',\dots,m_n') = (m_1+m_1',\dots,m_n+m_n')$
 * $a(m_1,\dots,m_n) = (am_1,\dots,am_n)$

*** Teorema de Cayley-Hamilton
Todo endomorfismo de un espacio vectorial de dimensión finita satisface
su ecuación característica.

**** Demostración
Sea $T$ un endomorfismo en un espacio $V$ con base $\{v_1,\dots,v_n\}$, definido por
la matriz siguiente

\[C =\begin{pmatrix}
a_{11} & a_{12} & \dots \\
a_{21} & a_{22} & \dots \\
\vdots & \vdots & \ddots \\
\end{pmatrix}.
\]

Si consideramos la matriz $\Delta = (TI_n - C)^t$ en $K[X]$, tenemos que

\[\Delta\begin{pmatrix}
v_1 \\ v_2 \\ \vdots \\ v_n
\end{pmatrix} = \begin{pmatrix}
Tv_1 - \sum_{j=1}^n a_{j1}v_j \\
Tv_2 - \sum_{j=1}^n a_{j2}v_j \\
\vdots \\
Tv_n - \sum_{j=1}^n a_{jn}v_j  
\end{pmatrix} = \begin{pmatrix}
0 \\ 0 \\ \vdots \\ 0
\end{pmatrix}.
\]

Multiplicando ahora por su matriz adjunta, se tiene que

\[
\widetilde \Delta\Delta\begin{pmatrix}
v_1 \\ v_2 \\ \vdots \\ v_n
\end{pmatrix} = \begin{pmatrix}
\mathrm{det}(\Delta)v_1 \\ \mathrm{det}(\Delta)v_2 \\ \vdots \\ \mathrm{det}(\Delta)v_n
\end{pmatrix} = \begin{pmatrix}
0 \\ 0 \\ \vdots \\ 0
\end{pmatrix}.
\]

Luego, por ser una base, $\mathrm{det}(\Delta)v = 0$ para cualquier $v \in V$. Tenemos
entonces que $T$ satisface la ecuación polinómica

\[ \mathrm{det}(TI_n - C) = \mathrm{det}(\Delta^t) = \mathrm{det}(\Delta) = 0.
\]

*** Submódulo finitamente generado
Un $A\text{-módulo}$ $M$ es *finitamente generado* si existe $X \subseteq M$ subconjunto
finito que lo genera, $M = RX$.

**** Submódulo cíclico
Un módulo generado por un elemento se llama *cíclico*.

*** Suma de módulos
Dados submódulos $N_1,\dots,N_m \leq M$, su suma es el menor submódulo que contiene
a todos ellos.

**** Caracterización de la suma
Sea $M$ un $A\text{-módulo}$,

 1. Dados submódulos $N_1,\dots,N_m$ de $M$, tenemos que

    \[
    N_1+\dots+N_m = \left\{ n_1+\dots+n_m \mid n_i \in N_i \right\}.
    \]

 2. Dado $X = \{m_1,\dots,m_n\} \subseteq M$, tenemos que $RX= Rm_1 + \dots + Rm_{n}$.

***** Demostración
Comprobamos que un módulo que los contenga debe contener a todos
los elementos de esa forma, además, forman un módulo, así que es
el menor.

*** Homomorfismo de módulos
Un aplicación entre $A\text{-módulos}$ $f\colon M \to N$ es *homomorfismo de módulos*
si $f(am) = af(m)$ para $a \in A, m \in M$.

*** Cociente de módulos
Sea $L < M$ un submódulo. El cociente $M/L$ tiene estructura de módulo con

\[a(m+L) = am+L
\]

y la suma inducida en el cociente.

*** Primer teorema de isomorfía para módulos
Para $f\colon M \to N$ homomorfismo de módulos, $\mathrm{ker}(f)$ e $\mathrm{im}(f)$ son submódulos
y hay un isomorfismo $\widehat f\colon M/ \mathrm{ker}(f) \to \mathrm{im}(f)$ dado por

\[
\widehat f(m+ \mathrm{ker}(f)) = f(m)
\]

**** Demostración
Aplicamos primero el primer teorema de isomorfía en grupos. Y comprobamos
que además $\widehat f$ es $A\text{-lineal}$ por ser $f$ isomorfismo de módulos.

*** Bases y módulos libres
Un conjunto de generadores de un $A\text{-módulo}$ $M$ es *base* si cada $m \in M$
se escribe únicamente como

\[
m = \sum_{i=1}^n a_im_i
\]

**** Módulo libre
Un módulo que admite una base se llama *módulo libre*. Un ejemplo de
módulo libre es $A^n$.

*** Caracterización de bases
Un subconjunto $B \subseteq M$ no vacío finito es base si, y sólo si, para 
cualquier aplicación $f\colon B \to N$ existe un único homomorfismo de
$R\text{-módulos}$ $\overline{f} \colon M \to N$ con $\overline{f}_{|B} = f$.

\[\begin{tikzcd}
B \rar[hook]\drar[dashed, swap]{\exists! \overline{f}} & M \dar{f}\\
  & N
\end{tikzcd}\]

**** TODO Demostración

*** Caracterización de finitamente generados
Para $M$ un $A\text{-módulo}$,

 1. Si $M$ admite un conjunto de generadores $\left\{ m_1,\dots,m_n \right\}$, entonces
    $M \cong A^n/L$ para cierto submódulo $L$.
 2. Si $M$ es libre con base $\left\{ m_1,\dots,m_n \right\}$, entonces $M \cong A^n$.

**** TODO Demostración

*** Segundo teorema de isomorfía para módulos
Sean $L,N \in {\cal L}(M)$ submódulos. Existe un isomorfismo

\[
\frac{L+N}{L} \cong \frac{N}{L \cap N}.
\]

**** Demostración
Aplicamos el primer teorema de isomorfía a la función 

\[
f\colon N \to \frac{L+N}{L}
\]

dada por $f(n) = n+L$. Es sobreyectiva y tiene como núcleo a $L \cap N$.

*** Tercer teorema de isomorfía para módulos
Sean $L \subseteq N \in {\cal L}(M)$. Existe un isomorfismo

\[
\frac{M/L}{N/L}\cong \frac{M}{N}
\]

Además, hay una biyección creciente entre submódulos de $M$ conteniendo
a $L$ y ${\cal L}(M/L)$.

**** Demostración
Aplicamos priemr teorema de isomorfía a la aplicación

\[
f \colon M/L \to N/L
\]

dada por $f(m+L) = m+N$.

** 1.4. Módulos simples. Teorema de Jordan-Hölder
*** Módulo simple
Un módulo $M$ se dice simple si no tiene submódulos propios.

*** Submódulo maximal
Un submódulo propio $N < M$ es *maximal* si lo es en ${\cal L}(M)$.

**** Caracterización por simplicidad
Por tercer teorema de isomorfía, esto equivale a que $M/N$ es simple.

*** Serie de composición
Una cadena de submódulos $0 \subset M_1 \subset M_2 \subset \dots \subset M$ es una *serie de composición*
de $M$ si cada $M_{i-1}$ es maximal en $M_i$.

*** Teorema de Jordan-Hölder
Sea $M$ un $A$ módulo de /dimensión finita/ como $K$ espacio vectorial con
dos series de composición:

\[0 = M_0 \subset M_1 \subset\dots\subset M_n = M\]
\[0 = N_0 \subset N_1 \subset\dots\subset N_m = M\]

Entonces $n=m$ y existe una permutación con $M_i/M_{i-1} \cong N_{\sigma(i)}/N_{\sigma(i)-1}$.

**** Factores de composición
Los módulos $M_i/M_{i-1}$ se llaman *factores de composición* de $M$ y están
únicamente determinados salvo isomorfismo y reordenación.

**** Demostración
Usaremos inducción sobre $n$. En el caso $n=1$, $M$ es simple y no tiene
submódulos propios, luego todas sus series de composición son la misma.
En otro caso, no es simple y $n,m>1$.

***** Caso 1
Si $M_{n-1}=N_{n-1}$, aplicamos a ambos la hipótesis de inducción y
ampliamos la permutación obtenida.

***** Caso 2
Si $M_{n-1} \neq N_{n-1}$, $M_{n-1}+N_{m-1} = M$ por maximalidad, y su intersección
tiene una serie de composición

\[
0 \subset L_1 \subset \dots \subset L_{k-1} \subset N_{m-1} \cap M_{n-1}
\]

que además puede extenderse de dos formas a $M_{n-1}$ y $N_{m-1}$, sabiendo por 
segundo teorema de isomorfía que

\[
\frac{M_{n-1}}{N_{m-1}\cap M_{n-1}} \cong \frac{M}{N_{m-1}}
\quad\text{ y que }\quad
\frac{N_{n-1}}{N_{m-1}\cap M_{n-1}} \cong \frac{M}{M_{m-1}}
\]

son simples. Aplicando la hipótesis de inducción dos veces, tenemos
dos permutaciones que nos dan

\[
L_i/L_{i-1} \cong M_{\tau i}/M_{\tau i - 1}
\quad\text{ y que }\quad
L_i/L_{i-1} \cong N_{\sigma i}/M_{\sigma i - 1}.
\]

Combinándolas tenemos lo pedido.

*** Longitud de un módulo
El número de factores de composición es la *longitud* del módulo $\ell(M)$.

*** Longitud y cociente
Si $M$ es de dimensión finita y $N \in {\cal L}(M)$. Entonces $\ell(M)=\ell(N)+\ell(M/N)$.

**** Demostración
Si tenemos series de composición

\[
0 \subset N_1 \subset N_2 \subset \dots \subset N
\qquad
\frac{N}{N} \subset \frac{M_1}{N} \subset \dots \subset \frac{M}{N}
\]

podemos aplicar el tercer teorema de isomorfía para tener
$M_j/M_{j-1} \cong \frac{M_j/N}{M_{j-1}/N}$ simple, y por tanto, una serie de composición

\[
0 \subset N_1 \subset \dots \subset N \subset M_1 \subset \dots \subset M.
\]

Como consecuencia, $\ell(M)=\ell(N)+\ell(M/N)$.

*** Longitud, suma e intersección
Sea $M$ un módulo dimensión finita con $N,L \in {\cal L}(M)$. Entonces:

\[\ell(N+L) + \ell(N\cap L) = \ell(N)+\ell(L)\]

**** Demostración
Aplicamos el [[*Segundo teorema de isomorfía para módulos][segundo teorema de isomorfía]] y la [[*Longitud y cociente][longitud de un cociente]]
para tener

\[
\frac{L+N}{L} \cong \frac{N}{L \cap N},
\]

y por tanto $\ell(L+N) - \ell(L) = \ell(N) - \ell(L \cap N)$.

** 1.5. Independencia lineal y sumas directas internas
*** Familia independiente
Una familia $\{N_i \mid i \in I\} \subset {\cal L}(M)$ es *independiente* si se verifica:

\[
N_j \cap \sum_{j\neq i} N_i = \{0\}
\]

*** Suma directa interna
Dada una familia independiente, $\sum_{i\in I} N_i \subset M$ se llama *suma directa interna*.

*** Suma directa externa e interna
Existe un único homomorfismo de módulos $\theta : \bigoplus_{i\in I} N_i \to \sum_{i\in I} N_i$, tal que
$\theta\iota_i(m) = m$ para cualquier $m \in N_i$.

**** Demostración
Extendiendo por linealidad la condición, el único homomorfismo posible es:

\[
\theta((m_i)_{i \in I}) = \sum_{i \in I} m_i
\]

*** Caracterización de familia independiente
Equivalen:

 1. La familia $\{N_i\mid i\in I\}$ es independiente.
 2. Toda subfamilia /finita/ $F \subset \{N_i\mid i\in I\}$ es independiente.
 3. La expresión de cada $m = \sum_{i\in I} m_i$ con $m_i\in N_i$ es única.
 4. Si $0 = \sum_{i\in I} m_i$, entonces $m_i = 0$.
 5. El homomorfismo canónico $\theta : \bigoplus_{i\in I} N_i \to \sum_{i\in I} N_i$ es inyectivo e isomorfismo.
 6. Para $J_1,J_2 \subset I$ con $J_1\cap J_2 = \varnothing$ se tiene $\sum_{i\in J_1} N_i \cap \sum_{i\in J_2} N_i = \{0\}$.

En este caso, notaremos la suma directa interna también por $\bigoplus_{i \in I} N_i$.

**** Demostración
***** Implicación 1 a 2
Trivial por definición de independencia.

***** Implicación 2 a 3
Esto equivale a que cada $\sum_{i \in I} m_i = 0$ lleva a $m_i = 0$. Pero si hubiera
algún $m_j$ no nulo, sería $m_j = - \sum_{i \in I, i\neq j} m_i$, contraviniendo independencia.

***** Implicación 3 a 4
Trivial por la unicidad.

***** Implicación 4 a 5
Desde lo anterior, se tiene que tiene núcleo trivial y por tanto es
inyectivo. Además, es sobreyectivo porque genera trivialmente todos los
elementos de $\sum N_i$. Es por tanto una biyección e isomorfismo.

***** Implicación 5 a 6
Si no fuera así, existirían subconjuntos $J_1,J_2$ cumpliendo:

\[
\sum_{i \in J_1} m_i = \sum_{i \in J_2} n_i
\]

Nótese que entonces la función $\theta$ daría la misma imagen para ambos
subconjuntos, contraviniendo inyectividad.

***** Implicación 6 a 1
Trivial por el caso de $J_2$ con un elemento.

*** Ampliar familia independiente
Sea $\{N_i \mid i\in I\} \subset {\cal L}(M)$ es familia independiente y tenemos:

\[
N \cap \bigoplus_{i\in I} N_i = \{0\}
\]

Entonces, $\{N_i \mid i \in I\} \cup \{N\}$ es independiente.

**** Demostración
Si $n + \sum n_i = 0$, tenemos $n \in \bigoplus N_i \cap N$ y, por tanto, $n = 0$. Por 
independencia de la familia $\sum n_i = 0$, se llega a $n_i = 0$.

*** Suma directa en suma de simples
Sea $N \subset \sum_{i\in I} M_i$ suma de submódulos simples. Existe $\{M_i \mid i \in J \subseteq I\} \cup \{N\}$ 
independiente con:

\[
N \oplus \left( 
\bigoplus_{i \in J} M_i
\right) = \sum_{i \in I} M_i
\]

**** Demostración
Tomamos el conjunto $\Gamma$ de los subconjuntos $J \subseteq I$ tales que $\{M_i \mid i \in J\} \cup \{N\}$
es independiente. Veamos que es no vacío. Si para todo $N \cap M_i \neq 0$, 
debe tenerse por simplicidad $M_i \subset N$ y por tanto $\sum M_i \subset N$. Así, debe
existir algún $M_i$ para el que $N \cap M_i = 0$.

Tomamos el maximal $J$. Para cualquier índice $i \in I -J$, se tiene entonces
por maximalidad que $M_i \cap (N + \bigoplus_{j \in J} M_j) \neq 0$, pero eso implica por simplicidad
que $M_i \subseteq N + \bigoplus_{j\in J} M_j$.

*** Existencia de base para espacio vectorial finitamente generado
Sea $_DV$ espacio vectorial izquierdo sobre el anillo de división $D$.
Para todo sistema de generadores no nulos $\{v_i\mid i\in I\}$ de $V$ existe un 
subconjunto tal que $V = \bigoplus_{j\in J} Dv_j$.

Todo espacio vectorial finitamente generado sobre $D$ tiene una base.

**** Demostración
Un anillo de división es simple. Como $Dv_j \cong D$, tenemos que es un 
espacio suma de simples, luego [[*Suma directa en suma de simples][existe un conjunto]] de independientes que
genera el espacio.

** 1.6. Independencia en familias infinitas
*** Suma directa externa infinita
Se define la *suma directa externa* $\bigoplus_{i\in I} N_i$ como el subconjunto del producto
cartesiano formado por las tuplas con un número finito de valores no nulos.

** 1.7. Clasificación de las álgebras de división reales de dimensión finita
*** Determinante, traza, polinomio característico y mínimo
Dada $a \in D$ en un álgebra de división sobre $k$, consideramos su *traza*,
su *determinante*, su *polinomio característico* y su *polinomio mínimo*
como los del endomorfismo lineal multiplicación, $\lambda_a \colon D \to D$.

*** Lema de clasificación de álgebras de división
Sea $D$ álgebra real de dimensión finita mayor que $1$. Entonces:

\[
V = \{a \in D : a^2 \leq 0\} = \{a\in D\mid tr(a) = 0\}
\]

Luego es un subespacio vectorial con $D = \mathbb{R} \oplus V$. Además, la dimensión real
de $D$ es par.

**** Demostración
Llamamos $n = \mathrm{dim}_{\mathbb{R}}(D)$ y dado $a \in D$ consideramos su polinomio 
característico

\[
p(X) = (X-r_1)\dots (X-r_k)q_1(X)\dots q_m(X)
\]

descompuesto en factores lineales y cuadráticos. Por Cayley-Hamilton,
tenemos que $p(a) = 0$, luego debe anularse algún polinomio,

  * si $(a-r_i) = 0$ entonces $a \in \mathbb{R}$, y si $a^2 \leq 0$, nos da $a = 0$.
  * si $a \in D \setminus \mathbb{R}$, tendremos algún $q_j(a) = 0$ como polinomio mínimo de $a$.

Por Ejercicio 18 tenemos $p = q^t$, con $2t=n$ en este caso. Por irreducibilidad
se tiene $q = (X-z)(X-\overline{z})$ para algún complejo, así que

\[\begin{aligned}
q(X) &= X^2 - 2 \mathrm{Re}(z) X + |z|^2 \\
p(X) &= X^{2t} - 2 \mathrm{Re}(z)t X^{2t-1} + \dots \\
p(X) &= X^{2t} - \mathrm{tr}(a) X^{2t-1} + \dots \\
\end{aligned}
\]

desde el desarrollo de $q$ y la definición de la traza como coeficiente del
polinomio característico.

Sustituyendo en la primera ecuación desde la última tenemos que

\[
a^2 - \frac{\mathrm{tr}(a)}{t}a + |z|^2 = 0,
\]

y que por tanto $a^2 \in \mathbb{R}^-$ si y sólo si $\mathrm{tr}(a) = 0$.

*** Teorema de Frobenius
Sea $D$ álgebra de división real de dimensión finita. Entonces $D$ es isomorfa
a $\mathbb{R}$, $\mathbb{C}$, o $\mathbb{H}$.

**** Demostración
Si $D \not\cong \mathbb{R}$, aplicamos el [[*Lema de clasificación de álgebras de división][lema de clasificación]] para tener $D$ de dimensión
par con $D = \mathbb{R}\oplus V$. Consideramos

\[
B(a,b) = \frac{ab+ba}{2}
= \frac{1}{2}\left( (a+b)^2-a^2-b^2 \right) \in \mathbb{R},
\]

una forma bilineal simétrica definida negativa. Podemos diagonalizarla
para obtener una base donde $B(e_i,e_j) = 0$ si $i\neq j$ y $B(e_i,e_i) = -1$, es decir,
por definición de $B$,

\[
e_i^2 = -1
\quad\text{ y }\quad
e_ie_j = -e_je_i.
\]

En el caso $t=1$, tenemos $\mathbb{C}$. En el caso $t>1$, tenemos además la restricción
de que si tomamos $u = e_1e_2e_j$, se cumple

\[
u^2 = -e_1e_2e_1e_je_2e_j = 1,
\]

luego $0 = (u-1)(u+1)$ en un anillo de división nos da $e_j = \pm e_1e_2$, así que
debe tenerse $t=2$, con base $\left\{ 1,e_1,e_2,e_1e_2 \right\}$. En este caso, se comprueba que
hay un isomorfismo $\mathbb{H} \cong D$.

*** Corolario de Frobenius
La única álgebra de división compleja de dimensión finita es $\mathbb{C}$.

**** Demostración
Nótese que en particular sería un álgebra de división real y no podría
ser $\mathbb{H}$ porque no tiene a los complejos como centro.

** 1.8. Idempotentes y anillos de matrices
*** Idempotente
Un elemento de un álgebra $e \in R$ se llama *idempotente* si $e^2 = e$.
Son idempotentes triviales $0$ y $1$.

*** Conjunto completo de idempotentes ortogonales (CCIO)
Un conjunto de idempotentes no triviales $\{e_1,\dots,e_n\}$ es conjunto completo de
idempotentes ortogonales si:

\[
1 = e_1 + \dots + e_n
\]

Y además, $e_ie_j = 0$ para $i \neq j$.

*** Descomposición de un CCIO
Sea $\{e_1,\dots,e_n\}$ un CCIO para $R$. Entonces $R = Re_1 \oplus \dots \oplus Re_n$.

**** Demostración
Cualquier elemento de $R$ se expresa como:

\[
r = r(e_1+e_2+\dots+e_n)
\]

Y la suma es directa porque si se tiene $x \in Re_j \cap \left(\sum_{i\neq j} Re_i \right)$, entonces:

\[
x = xe_j = \left(\sum_{i\neq j} xe_i\right)e_j = 0
\]

*** Descomposición en un CCIO
Sea $R = I_1 \oplus \dots \oplus I_n$ descomposición por ideales a izquierda no triviales.
Entonces, si $1 = e_1 + \dots + e_n$, para $e_i\in I_i$, $\{e_1,\dots,e_n\}$ forman un CCIO 
con $I_i = Re_i$.

**** Demostración
Si $x \in I_j$, $x = x\sum e_i$ y se tiene,

\[x - xe_j = 
\sum_{i\neq j} xe_i \in I_j \cap \left(\sum_{i\neq j} I_i\right) = 
\{0\}.\]

Así, hemos demostrado que

\[
I_j = \{ x \in R \mid xe_j = x\} = Re_i
\]

y que por tanto, $e_i^2 = e_i$. Por eso se tiene $\sum_{i\neq j} e_ie_j = 0$ y por independencia
lineal, se llega a $e_ie_j = 0$.

*** Matrices de descomposición
Llamamos al conjunto de matrices siguiente,

\[
Mat(e_iRe_j) = \left\{(r_{ij}) \mid r_{ij} \in e_iRe_j\right\}
\]

que es un subespacio vectorial multiplicativamente cerrado de $M_n(R)$. La
matriz diagonal

\[\begin{pmatrix}
e_1 & 0 & \dots & 0\\
0 & e_2 & \dots & 0 \\
\vdots & & & \vdots \\
0 & 0 & \dots & e_n
\end{pmatrix}
\]

es elemento neutro multiplicativo.

**** Demostración
Se comprueba trivialmente por tenerse:

\[
(e_ire_k)(e_kr'e_j) = e_i(re_kr')e_j \in e_iRe_j
\]

Multiplicando se comprueba además que la diagonal es la unidad
multiplicativa.

*** Descomposición en matrices
La aplicación $\phi \colon R \to Mat(e_iRe_j)$ dada por $\phi(r) = (e_ire_j)_{ij}$ es un isomorfismo
de K-álgebras.

**** Demostración
***** Es homomorfismo de álgebras
Por definición es lineal. Si calculamos la componente $(i,j)$ de
$\phi(r)\phi(s)$, tenemos

\[
\sum_k e_ire_ke_kse_j =
\sum_k e_ire_kse_j =
e_ir \left(\sum_k e_k\right) se_j =
e_irse_j
\]

que es la componente $(i,j)$ de $\phi(rs)$. Además, $\phi(1)$ es claramente la unidad.

***** Es isomorfismo
Supongamos que $\phi(r)=0$, entonces se tiene

\[
r = \left(\sum_i e_i\right)r \left( \sum_{j} e_{j} \right)
= \sum_{i,j} e_{i}re_{j} = 0
\]

y la función es inyectiva. Para comprobar que es sobreyectiva, simplemente
tomamos una matriz $(r_{ij})$ de la forma, y comprobamos que por ortogonalidad
e idempotencia se tiene

\[
\phi \left( \sum_{i,j} r_{ij} \right) = (r_{ij})
\]

*** Descomposición de endomorfismos
Sea $M = M_1 \oplus M_2 \oplus \dots \oplus M_n$ un A-módulo con $M_i \cong N$. Se tiene

\[
\mathrm{End}(M) = M_n(\mathrm{End}(N)).
\]

**** TODO Demostración

*** Descomposición en ideales biláteros
Sea $R = I_1\oplus I_2\oplus \dots \oplus I_n$ descompuesto en ideales biláteros. Sea $\left\{ e_1,\dots,e_n \right\}$
su CCIO asociado. Entonces $e_i \in Z(R)$, idempotente central.

*** Descomposición en álgebras
Sea $\{e_1,\dots,e_n\}$ un CCIO centrales de $R$. Entonces $Re_i$ es un álgebra con unidad
y tenemos un isomorfismo de álgebras $R \cong Re_1\times Re_2 \times \dots \times Re_n$ definido
por $r \mapsto (re_1,\dots,re_n)$.

*** Idempotente central primitivo
Un idempotente central es *primitivo* si $Re$ no es suma directa de dos ideales
propios de $R$.

*** Descomposión en centrales primitivos
Si $R$ tiene un CCIO centrales primitivos, este conjunto es único.

**** TODO Demostración

** 1.9. El álgebra de enfomorfismos de un módulo semisimple
*** Complemento
Para $N \subseteq M$ submódulo, un *complemento* de $N$ es un $X$ tal que

\[
M = N \oplus X.
\]

En caso de que tenga complemento lo llamamos *sumando directo*.

*** Módulos semisimples
Un módulo de dimensión finita se dice *semisimple* si todo submódulo
es un sumando directo.

*** Caracterización de semisimples
Sea $M$ módulo con dimensión finita como K-espacio vectorial. Equivalen:

  1) $M$ es semisimple.
  2) $M$ es suma directa finita de submódulos simples.
  3) $M$ es suma finita de submódulos simples.

**** Demostración
***** Primera implicación
Tomamos una familia maximal de submódulos simples linealmente
independientes. Si el complemento de su suma no fuera nulo, entonces
contendría algún submódulo simple (por finitud) que sería linealmente
independiente, contraviniendo maximalidad.

***** Segunda implicación
Trivial.

***** Tercera implicación
Trivial porque podemos tomar [[*Suma directa en suma de simples][suma directa en suma de simples]] para
encontrar el complemento.

*** Lema de Schur
Sean $M,M'$ simples con $f\colon M \to M'$ homomorfismo de módulos. Se tiene $f=0$
o $f$ isomorfismo.

**** Corolario: anillo de endomorfismos de un módulo simple
El anillo de los endomorfismos de un módulo simple es un anillo de
división.

**** Demostración
Si no es nula, el núcleo es un submódulo propio, luego debe ser inyectiva.
La imagen entonces será un submódulo propio no nulo y será sobreyectiva.

*** Submódulos y cocientes de semisimples
Si $M$ es un semisimple de dimensión finita, entonces todo submódulo de $M$
y todo cociente de $M$ es semisimple.

**** Demostración
Si existe un epimorfismo de módulos $M \to N$, se tiene $N$ semisimple.
Cualquier cociente tendrá la proyección como epimorfismo hacia él y
cualquier submódulo $N \subseteq M$ será cociente por su complemento como

\[
\frac{M}{X} =
\frac{N \oplus X}{X} \cong
\frac{N}{N \cap X} \cong N.
\]

***** El epimorfismo da la semisimplicidad
Por [[*Lema de Schur][Lema de Schur]], se tiene que la imagen de un simple será simple o
nula. Así, podemos escribir

\[
N = \sum_{i\in I} f(M_i)
\]

y tendremos que es suma de simples y por [[*Caracterización de semisimples][caracterización]], semisimple.

*** Unicidad de la descomposición en simples
Sea $M = M_1\oplus \dots \oplus M_n = N_1 \oplus \dots \oplus N_m$ semisimple descompuesto como suma
directa de simples. Entonces $n=m$ y se tiene $M_i \cong N_{\sigma i}$ para alguna 
permutación.

**** Demostración
Tenemos dos series de composición

\[\begin{aligned}
\left\{ 0 \right\} &= M_0 \subset
M_1 \subset 
M_1 \oplus M_2 \subset 
&\dots& \subset
M_1 \oplus \dots \oplus M_n &= M \\
\left\{ 0 \right\} &= N_0 \subset
N_1 \subset 
N_1 \oplus N_2 \subset 
&\dots& \subset
N_1 \oplus \dots \oplus N_n &= M \\
\end{aligned}\]

en las que los factores son simples, explícitamente por segundo
teorema de isomorfía,

\[
\frac{M_j \oplus \dots \oplus M_0}{M_{j-1}\oplus \dots\oplus M_0} \cong
\frac{M_j}{(M_{j-1} \oplus \dots \oplus M_0) \cap M_j} \cong M_j.
\]

Pero aplicando [[*Teorema de Jordan-Hölder][Jordan-Hölder]], $M_j \cong N_{\sigma j}$.

*** Componentes isotópicas de un módulo
Sea $M = M_1\oplus \dots \oplus M_n$ descomposición finita en módulos simples. Podemos
escoger módulos simples $\Sigma_1,\dots,\Sigma_t$ y una partición $\{1,\dots,n\} = \Lambda_1 \cup \dots \cup \Lambda_t$
tal que $M_i \cong \Sigma_j$ si y sólo si $i \in \Lambda_j$.

Podemos tomar $M_{\Lambda_j} = \bigoplus_{i\in \Lambda_j} M_i$ para descomponer en *componentes isotópicas*

\[
M = M_{\Lambda_1}\oplus \dots \oplus M_{\Lambda_t}
\]

y llamar a $n_j$ la *multiplicidad* $\Sigma_j$ en $M$. Las componentes con su multiplicidad
son invarriantes llamados *estructura del módulo*.

*** Estructura de los endomorfismos
Sea $M$ con estructura $(\Sigma_1,n_1),\dots,(\Sigma_t,n_t)$ entonces $\Delta_j= \mathrm{End}(\Sigma_j)$ es una
$K\text{-álgebra}$ de dimensión finita y hay un isomorfismo

\[ \mathrm{End}(M) \cong
\mathrm{M}_{n_1}(\Delta_1) \times \dots \times \mathrm{M}_{n_t}(\Delta_t)
\]

**** TODO Demostración
** 1.10. Álgebras semisimples de dimensión finita
*** Álgebras semisimples
Un álgebra $A$ de dimensión finita es *semisimple* si todo A-módulo de
dimensión finita es semisimple.

*** Caracterización de álgebras semisimples
Un álgebra de dimensión finita es semisimple si y sólo si es semisimple
como A-módulo.

**** Demostración
Si $M$ es un módulo finito-dimensional, es el cociente de un libre $A^n$.
Como $A^n$ es semisimple por serlo $A$, su [[*Submódulos y cocientes de semisimples][cociente]] $M$ es semisimple.

*** Estructura de los módulos de un álgebra semisimple
Sea $A$ es un álgebra semisimple con estructura $(n_1,\Sigma_1),\dots,(n_t,\Sigma_t)$ como
$A\text{-módulo}$, entonces todo $A\text{-módulo}$ finito tiene estructura $(m_1,\Sigma_1),\dots,(m_t,\Sigma_t)$
para algunos $m_1,\dots,m_t$. En particular, todo $A\text{-módulo}$ simple es isomorfo a 
un $\Sigma_j$.

**** Demostración
Los módulos de dimensión finita son cocientes de $A^n$, y la estructura de
$A^n$ es simplemente $(nn_1,\Sigma_1),\dots,(nn_t,\Sigma_t)$, y sabemos que la estructura de los
submódulos y de los cocientes es la misma con coeficientes menores.

*** Álgebra de matrices sobre anillo de división es semisimple
Dada $\Delta$ álgebra de división finito-dimensional, $M_n(\Delta)$ es un álgebra 
semisimple con estructura $(n, \Sigma)$ para $\Delta \cong \mathrm{End}(\Sigma)^{op}$. Además, $M_n(\Delta)^{op} \cong M_n(\Delta^{op})$.

**** Demostración
***** El álgebra de matrices es semisimple
Tomamos $A_j$ el ideal izquierda de $M_n(\Delta)$ con base $\left\{ E_{1j},\dots,E_{nj} \right\}$.
Comprobamos que es simple, ya que cualquiera de sus elementos no
nulos genera $M_n(\Delta)E_{jj}$, por ser $\Delta$ anillo de división.

Así, vemos que $M_n(\Delta)$ es semisimple por ser

\[ M_n(\Delta) = A_1 \oplus \dots \oplus A_n. \]

***** Estructura unimodular
Veamos que existe un isomorfismo de módulos $A_1 \cong A_j$, explícitamente

\[
f(a_1E_{11}+\dots +a_nE_{n1}) = a_1 E_{1j} + \dots + a_n E_{nj}
\]

es trivialmente isomorfismo de espacios vectoriales y se comprueba que
es homomorfismo de módulos por tenerse

\[
f\left(\left( \sum_{}  \right)\right)
\]

*** Teorema de Wedderburn
Una $K\text{-álgebra}$ de dimensión finita es semisimple ssi es isomorfa a un
álgebra de la forma

\[ \mathrm{M}_{n_1}(\Delta_1) \times \dots \times \mathrm{M}_{n_t}(\Delta_t).
\]

de forma única para algunas $\Delta_1,\dots,\Delta_t$ álgebras de división de dimensión
finita. Además, esta factorización es esencialmente única.

**** TODO Demostración

*** Centro de álgebra semisimple de dimensión finita
Si $A$ es semisimple de dimensión finita, $Z(A)$ es producto finito de cuerpos
extensión finita de $k$. El número de factores es el número de $A\text{-módulos}$ simples
no isomorfos en la estructura de $A$.

**** TODO Demostración
*** Semisimplicidad del álgebra opuesta
Si $A$ es semisimple, entonces $A^{op}$ es semisimple.

**** TODO Demostración

*** Teorema de Molien
Un álgebra compleja $A$ de dimensión finita es semisimple ssi es
isomorfa a exactamente una de la forma

\[ \mathrm{M}_{n_1}(\mathbb{C}) \times \dots \mathrm{M}_{n_t}(\mathbb{C})
\]

cumpliendo $\mathrm{dim}_{\mathbb{C}}(A) = n_1^2+\dots+n_t^2$.

* 2. Representaciones de grupos finitos
** 2.1. Representaciones lineales de grupos finitos y módulos
*** 2.1. Representación
Una *representación* $k\text{-lineal}$ de $G$ es un homomorfismo de grupos

\[\rho \colon G \to \mathrm{GL}(V).\]

**** Espacio de representación
Llamamos a $V$ /espacio de representación/ y a su dimensión la
/dimensión de la representación/. 

**** Dimensión finita
Aquí consideraremos sólo representaciones de dimensión finita.

*** Álgebra de grupo
Para $G$ grupo finito y $k$ cuerpo, el /álgebra de grupo/ $kG$ se define
como el $k\text{-espacio}$ vectorial libre sobre $G$ con el producto dado por la
extensión bilineal del producto sobre $G$.

*** Relación entre representación y módulo del álgebra de grupo
La aplicación que asigna cada homomorfismo de álgebras $\Pi\colon kG \to \mathrm{End}_k(V)$
su restricción $\rho \colon G \to \mathrm{GL}(V)$ es una biyección a las representaciones.

Las representaciones $k\text{-lineales}$ de $G$ son las estructuras de $kG\text{-módulo}$
sobre $V$.

**** Demostración
Sabemos que cada homomorfismo $G \to \mathrm{GL}(V)$ extiende de manera única
por ser una base de $kG$ y extiende al producto por estar definido
precisamente por extensión. Cada aplicación restringe a $GL(V)$ por
ser los elementos de $G$ invertibles en $kG$ y es homomorfismo de
grupos.

*** Subespacio invariante
Un subespacio $W \leq V$ es $\rho\text{-invariante}$ si $\rho(g)(W) \leq W$ para cualquier $g \in G$.

/Equivalentemente, es un $kG\text{-módulo}$/.

*** Representación irreducible
Una representación no nula es irreducible si no tiene espacios invariantes
propios.

/Equivalentemente, el $kG\text{-módulo}$ es simple/.

** 2.2. Representaciones completamente reducibles. Teorema de Maschke
*** 2.8. Representación completamente reducible
Una representación se llama *completamente reducible* si es nula
o el espacio de representación es suma directa de espacios irreducibles.

/Equivalentemente, el $kG\text{-módulo}$ es semisimple/.

*** 2.9. Teorema de Maschke
Sea $G$ grupo finito y $k$ cuerpo con $\mathrm{char}(k) \nmid |G|$. Toda representación aquí es
completamente reducible.

/Equivalentemente, $kG$ es un álgebra semisimple/.

**** Demostración
Dada $\varphi \colon V \to U$ $k\text{-lineal}$, definimos

\[
\widetilde \varphi(v) = \frac{1}{|G|}\sum_{g \in G}g \varphi(g^{-1}v),
\]

usando que $\mathrm{char}(k) \nmid |G|$, y es un homomorfismo de $kG\text{-módulos}$,

\[\begin{aligned}
\widetilde\varphi(hv) = 
\frac{1}{|G|}\sum_{g \in G}hh^{-1}g\varphi(g^{-1}hv) =
h \frac{1}{|G|} \sum_{k \in G} k \varphi(k^{-1}v) = h \widetilde\varphi(v).
\end{aligned}\]

Sea ahora $V$ un $kG\text{-módulo}$ con $W \leq V$. Consideramos $\pi\colon V \to V/W$, y
usando el complemento como espacio vectorial, creamos $\varphi\colon V/W \to V$
lineal con $\pi\circ\varphi = \mathrm{id}_{V/W}$ y tomamos la $\widetilde \varphi$. Tenemos entonces

\[
\pi(\widetilde\varphi(x)) =
\pi \left( \frac{1}{|G|}\sum_{g \in G}g\varphi(g^{-1}x) \right) =
\frac{1}{|G|} g\pi(\varphi(g^{-1}x)) =
\frac{1}{|G|} \sum_{g \in G} gg^{-1}x = x,
\]

y por tanto $\pi \circ \widetilde\varphi = \mathrm{id}_{V/W}$. Si tomamos $U = \operatorname{Im} \widetilde\varphi$, vemos que $V = W \oplus U$;
luego todo submódulo es un sumando directo.

*** 2.10.a. Representaciones equivalentes
Dos representaciones $k\text{-lineales}$ de $G$ se llaman *equivalentes* si los
$kG\text{-módulos}$ son isomorfos.

*** 2.10.b. Representación regular
La representación regular $\rho_{reg}$ es la asociada al propio $kG$ como $k\text{-módulo}$.
Cuando $\mathrm{char}(k) \nmid |G|$ es, por [[*Teorema de Maschke][Teorema de Maschke]], suma de irreducibles, que
notaremos como

\[\rho \sim
\rho_1^{n_1}\oplus \dots\oplus \rho_t^{n_t}
\]

para ciertas multiplicidades $n_i$.

*** 2.10.c. Constituyentes
Usando la estructura de las álgebras semisimples, sabemos que cualquier
representación $k\text{-lineal}$ de $G$ será de la forma

\[\rho \sim
\rho_1^{m_1}\oplus \dots\oplus \rho_t^{m_t}
\]

para ciertas multiplicidades $m_i$. Llamamos a las $\rho_i$ con multiplicidad positiva
las *constituyentes* de $\rho$.

*** 2.11. Multiplicidades en la representación regular
Cuando $\mathrm{char}(k) \nmid |G|$, si las representaciones $k\text{-lineales}$ irreducibles de $G$
son $(V_1,\rho_1),\dots,(V_{t},\rho_t)$ y tenemos $n_i$ la multiplicidad de cada una de ellas
en la representación regular y $d_i = \mathrm{dim}_k(\Delta_i)$ la dimnesión asociada al
álgebra de división que da el teorema de Wedderburn; tenemos que
$\mathrm{dim}_k(V_i) = d_in_i$ y $|G| = d_1n_1^2 +\dots + d_tn_t^2$.

**** TODO Demostración

*** 2.12. Multiplicidades en al representación regular compleja
Sean $(V_1,\rho_1),\dots,(V_t,\rho_t)$ las representaciones irreducibles complejas de $G$.
Si las multiplicidades en la representación regular son $(n_1,\dots,n_t)$,
entonces $\mathrm{dim}_{\mathbb{C}} V_i = n_i$ para $i = 1,\dots,t$ y $|G| = n_1^2 + \dots + n_t^2$.

**** TODO Demostración
*** 2.13. Dimensión del centro del álgebra-grupo
Sean $C_1,\dots,C_r$ las clases de conjugación de $G$. Entonces $\mathrm{dim}_k Z(kG) = r$.

**** TODO Demostración

*** 2.14. Número de representaciones irreducibles complejas
El número de clases de conjugación de $G$ coincide con el número de
representaciones irreducibles complejas de $G$.

**** TODO Demostración
** 2.3. Caracteres
*** 2.15. Carácter complejo
Para $(V,\rho)$ representación compleja de $G$, la aplicación $\chi_{\rho}\colon G \to \mathbb{C}$ dada
por $\chi_{\rho}(g) = \mathrm{tr}(\rho(g))$, se llama *carácter* complejo de $\rho$.

**** Carácter irreducible
El que procede de una representación irreducible.

**** Grado de un carácter
Dimensión de $V$ como espacio vectorial complejo.

*** 2.16. Carácter invariante por equivalencia
Dos representaciones complejas equivalentes proporcionan el mismo
carácter.

**** Demostración
Si $(V,\rho)$ y $(W,\pi)$ son equivalentes por $T \colon V \to W$, para $g \in G$ tenemos
que $T\rho(g) = \pi(g)T$, luego $\rho(g) = T^{-1}\pi(g)T$, y sabemos que la traza se
preserva por semejanza.

*** 2.17.a. Exponente de un grupo
El *exponente* de un grupo $G$ es el mínimo común múltiplo de los órdenes
de sus elementos.

*** 2.17.b. Diagonalización de elementos de la representación
Sea $G$ con exponente $m$ y $(V,\rho)$ representación de grado $n$. Existen raíces
$m\text{-ésimas}$ de la unidad $\omega_1,\dots,\omega_n$ en las que diagonaliza $\rho(g)$. Se tiene
entonces

\[\chi_{\rho}(g) = \omega_1+\dots + \omega_n \]

y

\[\chi_{\rho}(g^{-1}) = \overline{\chi_{\rho}(g)}.
\]

**** TODO Demostración

*** 2.18. Cota del carácter
Para $G$ con exponente $m$ y $(V,\rho)$ representación,

\[|\chi_{\rho}(g)| \leq \operatorname{deg} \chi_{\rho}.
\]

El caso de igualdad se tiene si y sólo si $\rho(g) = \omega \mathrm{id}_V$ para alguna raíz
$m\text{-ésima}$ de la unidad.

**** Caso de la identidad
En particular, $\chi_{\rho}(g) = \operatorname{deg} \chi_{\rho}$ si y sólo si $\rho(g) = \mathrm{id}_V$.

*** 2.19. Núcleo de un carácter
Dado $\chi$ carácter complejo, su *núcleo* se define como

\[\ker \chi = \left\{ g \in G \mid \chi(g) = \chi(1) \right\}.
\]

**** TODO El núcleo es un subgrupo normal

*** Extensión de representaciones y caracteres
Dada una representación $\rho \colon G \to \mathrm{Aut}(V)$, notamos por $\tilde{\rho}(g) \colon \mathbb{C}G \to \mathrm{End}_{\mathbb{C}}(V)$ la
extensión al álgebra-grupo. Dado un carácter $\chi_{\rho} \colon G \to \mathbb{C}$, notamos por 
$\widetilde{\chi_{\rho}} \colon \mathbb{C}G \to \mathbb{C}$ a la extensión al álgebra grupo.

*** Caracteres irreducibles complejos
Los *caracteres irreducibles* complejos de $G$ son los dados por sus
representaciones irreducibles.

**** Dimensión del espacio de representación
Nótese que para cualquier carácter irreducible se tiene
# ¿Necesitamos que sea irreducible?

\[n_i = \operatorname{dim}_{\mathbb{C}} V_{i} = \chi_i(1).\]

*** Carácter de la suma directa
Si $(W,\pi)$ es una representación con $W = W_{1} \oplus \dots \oplus W_m$, se tiene que

\[\chi_{\pi} = \chi_{\pi_1} + \dots + \chi_{\pi_m}.
\]

**** TODO Demostración

*** Carácter regular
El *carácter regular* es el carácter de la representación regular.
Cumple que

 1) \[\chi_{reg}(g) = \left\{\begin{array}{ll} |G|,  & \mbox{si } g=1 \\0, & \mbox{si }  g \neq 1.
    \end{array} 
    \right.\]
 2) $\chi_{reg} = \chi_1(1)\chi_1 + \dots + \chi_t(1)\chi_t$.

**** TODO Demostración

** 2.4. La tabla de caracteres
*** TODO Tabla de caracteres
*** TODO Teorema de Frobenius
** 2.5. Funciones de clase. Reciprocidad
*** Producto interno
En el espacio vectorial $\mathbb{C}^G$, de dimensión $|G|$, definimos el siguiente
*producto interno*

\[(\varphi,\psi) = \frac{1}{|G|} = \sum_{g \in G}\overline{\varphi(g)}\psi(g).
\]

**** Conjunto ortonormal
Nótese que los $\left\{ \chi_1,\dots,\chi_t \right\}$ forman un /conjunto ortonormal/ de vectores
en $\mathbb{C}^G$.

**** Base ortonormal
Si $G$ es /abeliano/, tiene tantas clases de conjugación como elementos.
Tenemos $t = |G|$ y los caracteres irreducibles son una base ortonormal
de $\mathbb{C}^G$.

*** Funciones de clase
Una *función de clase* de $G$ es una aplicación $\varphi\colon G \to \mathbb{C}$ constante sobre
cada clase de conjugación de $G$. Es decir,

\[
\varphi(hgh^{-1}) = h\varphi(g) h^{-1}.
\]

Al subespacio complejo de funciones de clase lo llamamos ${\cal C}(G)$.

*** Base ortonormal de las funciones de clase
Los caracteres irreducibles $\mathrm{Irr}(G) = \left\{ \chi_1,\dots,\chi_t \right\}$ forman una base ortonormal
de ${\cal C}(G)$.

**** TODO Demostración

*** Equivalencia por caracteres
Dos representaciones complejas de $G$ son equivalentes si, y sólo si,
proporcionan el mismo carácter.

**** TODO Demostración

*** Restricción e inducción
Fijados $H \leq G$, definimos

 * la *restricción* $(-)_H\colon {\cal C}(G) \to {\cal C}(H)$ de funciones de clase.
 * la *inducción* $(-)^G\colon {\cal C}(H) \to {\cal C}(G)$ de funciones de clase.

La /inducción/ se define como

\[
\varphi^G(g) = \frac{1}{|H|}\sum_{x \in G}\varphi^{\bullet}(x^{-1}gx),
\]

donde $\varphi^{\bullet}(g) = \varphi(g)$ cuando $g \in H$ y $\varphi^{\bullet}(g) = 0$ cuando $g \notin H$.

*** Reciprocidad de Frobenius
Sea $H$ un subgrupo de $G$, $\varphi \in {\cal C}(H)$ y $\psi \in {\cal C}(G)$. Entonces

\[(\psi_H,\varphi) = (\psi,\varphi^G).
\]

**** TODO Demostración

*** La inducción de un carácter es carácter
Si $\varphi$ es carácter de $H$, entonces $\varphi^G$ es un carácter de $G$.

**** TODO Demostración

*** TODO Constituyentes

* Ejercicios de clase
** Ejercicio 1
#+begin_statement
Comprobar que $K$ es una K-álgebra.
#+end_statement

Tenemos que $K$ es un espacio vectorial sobre sí mismo y su propio
producto es una aplicación bilineal sobre $K$, ya que cumple:

  - $(a+b)c = ac+bc$, por axiomas de anillo.
  - $a(b+c) = ab+ac$, por axiomas de anillo.
  - $a(bc) = (ab)c = b(ac)$, el producto es conmutativo y asociativo.

Además es un álgebra asociativa y unital.

** Ejercicio 2
#+begin_statement
Calcular el centro del álgebra de matrices $M_n(K)$.
#+end_statement

Supongamos $A \in Z(M_n(K))$, si tomamos las matrices que sólo tienen una 
entrada unidad y el resto ceros $E_{ij} = (\delta_{ij})_{i,j}$. Así, tenemos:

\[
E_{ii}A = \begin{pmatrix}
0 & \dots & 0 \\
^{i)} a_{i1} & \dots & a_{in} \\
0 & \dots & 0 \\
\end{pmatrix}
\qquad
AE_{ii} = \begin{pmatrix}
0 & ^{i)}a_{1i} & 0 \\
\vdots & \vdots & \vdots \\
0 & a_{ni} & 0 \\
\end{pmatrix}
\]

Por lo tanto $a_{ij} = 0$ para $i \neq j$. Además,

\[
E_{ij}A = \begin{pmatrix}
0 & ^{j)}\dots & 0 \\
^{i)} \dots & a_{ii} & \dots \\
0 & \dots & 0 \\
\end{pmatrix}
\qquad
AE_{ij} = \begin{pmatrix}
0 & ^{j)}\dots & 0 \\
^{i)}\dots & a_{jj} & \dots \\
0 & \dots & 0 \\
\end{pmatrix}
\]

Por tanto, $A = \lambda I$. Se cumple que $(\lambda I) B = \lambda (I B) = \lambda B = \lambda (B I) = B (\lambda I)$,
y el centro es de la forma

\[
\left\{
\lambda I \mid \lambda \in K
\right\}
\]

** Ejercicio 3
#+begin_statement
Comprobar que $Im(u) \subseteq Z(A)$, siendo $u : K \longrightarrow A$, $u(\alpha) = \alpha 1_A$.
#+end_statement

Usando la bilinealidad:

\[
u(\alpha) a =
(\alpha 1) a =
\alpha (1a) =
1 (\alpha a) =
(\alpha a) 1 =
a (\alpha 1)
\]

** Ejercicio 4
#+begin_statement
Supongamos $A$ anillo y $K$ cuerpo. Dado un homomorfismo de anillos $u : K \longrightarrow A$,
demostrar que $A$ es una K-álgebra si defino su estructura de K-espacio 
vectorial como sigue:

\[
\forall\alpha \in K, a \in A:\quad \alpha a = u(\alpha) a
\]

Es decir, podemos definir alternativamente un álgebra sobre $K$ como un
homomorfismo de anillos $u : K \longrightarrow Z(A)$, el *homomorfismo de estructura*.
#+end_statement

Debemos comprobar que la multiplicación del anillo es bilineal sobre la
estructura de espacio vectorial:

  - $(a+b)c = ac+bc$
  - $a(b+c) = ab+ac$
  - $(\alpha a)c = (u(\alpha) a) c = a u(\alpha) c$

Por lo que forma un K-álgebra.

** Ejercicio 5
#+begin_statement
Comprobar que $Z(\mathbb{H}) = \mathbb{R}$.
#+end_statement

Supongamos un elemento en el centro $z = a+bi+cj+dk$, debería conmutar con
$i,j$, así que:

\[
0 = zi-iz = (ai-b-ck+dj) - (ai-b+ck-dj) = 2(dj-ck)
\]
\[
0 = zj-jz = (aj+bk-c-di) - (aj-bk-c+di) = 2(bk-di)
\]

De donde tenemos $b=c=d=0$, y por tanto, el elemento debe estar en $\mathbb{R}$.

** Ejercicio 6
#+begin_statement
Dados $q,p\in \mathbb{H}$, escritos como suma de vector y escalar, se tiene la fórmula:

\[
(a+v)(b+w) = ab + aw + bv - v\cdot w + v \wedge w
\]
#+end_statement

Los tres primeros términos se tienen porque el producto escalar coincide
con el producto de un real por un cuaternión. Los dos últimos términos se
tienen como sigue. Si tomamos $v = xi+yj+zk$, $w = oi+pj+qk$; y los
interpretamos como vectores como $v = (x\ y\ z)$, $w = (o\ p\ q)$:

\[
vw = (-xo-yp-qz) + (pxk-qxj - oyk+qyi + ozj-pzi)
\]

Y comprobamos que:

\[(x\ y\ z)(o\ p\ q) = xo+yp+zq\]

\[\begin{vmatrix}
i&j&k \\
x&y&z \\
o&p&q \\
\end{vmatrix}
=
pxk-qxj - oyk+qyi + ozj-pzi
\]

** TODO Ejercicio 7
#+begin_statement
Demostrar que un grupo abeliano $(V,+)$ junto a una acción $A\times V \to V$ es
un módulo ssi verifica las cuatro condiciones siguientes:

  1. $(a+a')v = av + a'v$
  2. $a(v+v') = av+av'$
  3. $a(a'v) = (aa')v$
  4. $1v = v$
#+end_statement
** Ejercicio 8
#+begin_statement
Definir un submódulo.
#+end_statement

Un submódulo debe tener estructura de módulo y una inclusión al módulo
del que es submódulo. Exigimos entonces, para que tenga estructura de módulo,
que sea cerrado respecto a la suma y al producto por elementos del álgebra.
Nótese que dentro de los elementos del álgebra están los elementos del 
cuerpo base del álgebra.

** Ejercicio 9
#+begin_statement
Sea $N_1,\dots,N_m \in {\cal L}(M)$. Demostrar que:

\[
N_1+\dots+N_m
=
\{m_1+\dots+m_n \mid m_i \in N_i \}
\]
#+end_statement

Primero notamos que es un módulo, ya que:

 - $a(m_1+\dots+m_n) = am_1+\dots+am_n$
 - $(m_1+\dots+m_n)+(m'_1+\dots+m'_n) = (m_1+m'_1) + \dots + (m_n+m'_n)$

Después notamos que si un módulo contiene a $N_1,\dots,N_m$ debe contener
todas las sumas de sus elementos por ser cerrado para la suma. Así,
este es el mínimo módulo conteniendo a $N_i$.

** Ejercicio 10
#+begin_statement
¿Para qué valores del ángulo el giro en el plano da sólo submódulos propios?
Es decir, ¿cuándo es $\mathbb{R}^2$ simple como $\mathbb{R}[T]$ módulo con $T$ giro?
#+end_statement

Sea $M$ un submódulo de $\mathbb{R}^2$ con $v \not\in M$. Si $T(v),v$ son linealmente 
independientes, el espacio $\langle Tv,v \rangle$ será $\mathbb{R}^2$ y no podrá existir un módulo
propio. En otro caso, $\langle v \rangle$ será un módulo propio.

Para tener $Tv,v$ independientes, es necesario tener un giro múltiplo de $\pi$.

** TODO Ejercicio 11 (★★)
#+begin_statement
Calcular todos los $\mathbb{R}[X]\text{-módulos}$ de $\mathbb{P}_n$ para la acción de derivación.
#+end_statement

** Ejercicio 12?
#+begin_statement
Sean $M = S_1\oplus \dots \oplus S_t$, $N = T_1\oplus \dots \oplus T_n$ con $S_i,T_i$ simples y cumpliendo
$S_i \not\cong T_j$. Probar que todo homomorfismo de módulos $f \colon M \to N$ es $0$.
#+end_statement

Similar al [[*Ejercicio 23 (★)][ejercicio 23]].

* Ejercicios de los apuntes
** Ejercicio 1 (*)
#+begin_statement
Calcular el centro del álgebra de matrices $M_n(K)$.
#+end_statement

** Ejercicio 2
#+begin_statement
Escribir la demostración de la Proposición 1.7.
#+end_statement

*** La imagen es subálgebra
Trivialmente, la imagen es espacio vectorial y $f(a)f(b) = f(ab)$.

*** El núcleo es un ideal
El núcleo es subespacio vectorial y además,

\[
f(ak) = f(a)f(k) = 0 = f(k)f(b) = f(kb)
\]

para cualquier $f(k) = 0$.

*** Isomorfía
Notamos primero que $\widehat f$ es el mismo que obtendríamos aplicando el
primer teorema de Isomorfía entre espacios vectoriales. Así, sabemos
que está bien definido y que es una función lineal biyectiva.

Comprobaremos simplemente que preserva el producto, probando así que
es un isomorfismo de k-álgebras; pero esto es trivial por la estructura
de álgebra con la que hemos dotado al cociente:

\[
\widehat f((a+I)(b+I)) = 
\widehat f(ab+I) = f(ab) = f(a)f(b) 
= \widehat f(a+I) \widehat f(b+I).
\]

** Ejercicio 3
#+begin_statement
Supongamos que $K$ es un cuerpo, y $A$ es un anillo (no necesariamente
conmutativo). Sea $u : K \to A$ un homomorfismo de anillos tal que
$Im(u) \subseteq Z(A)$, donde $Z(A)$ denota el centro de $A$, definido de manera
obvia. Comprobar que si definimos la acción de $K$ sobre $A$ dada por
$\alpha a = u(\alpha) a$, para todo $\alpha \in K, a \in A$, entonces $A$ es una k-álgebra.
#+end_statement

Comprobamos primero que $A$ es un k-espacio vectorial. Con su suma es
un grupo abeliano, y por ser el producto sobre ella distributivo y
el homomorfismo de anillos unital y asociativo:

 - $u(\alpha)(a+b) = u(\alpha)a + u(\alpha)b$
 - $u(1)a = 1a = a$
 - $u(\alpha)u(\beta)(a+b) = u(\alpha\beta)(a+b)$
 - $u(\alpha+\beta)a = u(\alpha)a + u(\beta)a$

Ahora comprobaremos simplemente que el producto del anillo es una
operación bilineal en este espacio vectorial.

  - $(a+b)c = ac+bc$
  - $a(b+c) = ab+ac$
  - $(\alpha a)c = (u(\alpha) a) c = a u(\alpha) c$

Donde hemos usado distributividad del producto y que $u(\alpha) \in Z(A)$.

** Ejercicio 4
#+begin_statement
Demostrar que, realmente, $End_K(V)$, con las operaciones recién descritas
(suma, producto escalar y composición), es una K-álgebra.
#+end_statement

La suma se define por $(f+g)(v) = f(v)+g(v)$, lo que da un grupo abeliano
con el neutro $0(v) = 0$; además, con $(\alpha f)(v) = \alpha f(v)$, nos da un espacio
vectorial.

Comprobamos además que la composición es bilineal:

  1. $((f+g)\circ h)(v) = f(h(v)) + g(h(v)) = (f\circ h + g\circ h)(v)$
  2. $(f\circ (g+h))(v) = f(g(v)) + f(h(v)) = (f\circ g + f\circ h)(v)$
  3. $(\alpha f \circ g)(v) = \alpha (f\circ g)(v)) = f(\alpha g(v)) = (f \circ \alpha g)(v)$

Donde en el primer y segundo punto usamos la definición de suma; y
en el tercer punto usamos la linealidad de la función para conmutar
el elemento del cuerpo y la aplicación de la función.

** Ejercicio 5 (*)
#+begin_statement
Comprobar todas las afirmaciones hechas en el Ejemplo 11.
#+end_statement

*** Estructura del espacio cociente
Sabemos que cada ideal no nulo lo genera un polinomio por ser un
Dominio de Ideales Principales, que además podemos suponer mónico por ser $K$ 
un cuerpo. Como además los polinomios forman un dominio euclídeo con el
grado como función euclídea, podemos escribir cualquier polinomio $t$ como

\[
t(X) = r(X) + p(X)q(X), \text{ para } \mathrm{deg}(r) < n,
\]

y por tanto, ${\cal B} = \left\{ 1+I, x+I,\dots, x^{n-1}+I \right\}$ es un sistema generador. Sabemos
que es linealmente independiente porque si no lo fuese, tendríamos una
relación lineal que daría lugar a que un polinomio de grado menor que $n$
estuviera en el ideal. Así, ${\cal B}$ es base.

*** Matriz compañera
Podemos comprobar que la matriz compañera es la que representa a $\lambda_{x+I}$
por tenerse que $(x+I)(x^{i-1}+I) = (x^{i}+I)$ para $i < n$ y que

\[x^{n}+I = p_0-p_1x-\dots-p_{n-1}x^{n-1} + I\]

Sabemos ahora que $\lambda : A \to \mathrm{End}(A)$ es un homomorfismo inyectivo de álgebras
que lleva $\lambda_{x+I} = \tilde N(p)$ y que por ser inyectivo preserva la independencia
lineal de la base. Así, la imagen de los elementos de la base es una base
de la imagen, y tenemos que el álgebra $A$ es isomorfa a la subálgebra de
$M_n(K)$

\[
\left\{ a_0I+a_1\tilde N(p) + \dots + a_{n-1}\tilde N(p)^{n-1} \mid
a_0,a_1,\dots,a_{n-1} \in K \right\} \subseteq M_n(K).
\]

** Ejercicio 6
#+begin_statement
Expresar el cuerpo $\mathbb{Q}(\sqrt{2})$ como una $\mathbb{Q}$ subálgebra de un álgebra de matrices
sobre $\mathbb{Q}$.
#+end_statement

Empezamos notando que

\[
\mathbb{Q}\left(\sqrt{2}\right) = \frac{\mathbb{Q}}{(X^2-2)},
\]

y que podemos por tanto aplicar el razonamiento del ejemplo 11 para saber
que si la matriz compañera del polinomio $p(x) = x^2-2$ es

\[\tilde N(p) = \begin{pmatrix}
0 & 2 \\
1 & 1
\end{pmatrix},\]

el álgebra será isomorfa a la subálgebra de $M_2(\mathbb{Q})$ dada por

\[
\left\{ aI + b\tilde N(p) \mid a,b \in \mathbb{Q} \right\}.
\]

** Ejercicio 7
#+begin_statement
Sea

\[\mathbb{H} = \left\{ \begin{pmatrix}
\alpha & -\overline{\beta} \\
\beta & \overline{\alpha}
\end{pmatrix} \mid \alpha,\beta \in \mathbb{C} \right\}\]

  1. Demostrar que $\mathbb{H}$ es una subálgebra real de $M_2(\mathbb{C})$ y que $Z(\mathbb{H}) = \mathbb{R}$.
  2. Demostrar que todo elemento no nulo de $\mathbb{H}$ es una unidad.
  3. Demostrar que las matrices

     \[\mathbf{1} = \begin{pmatrix}1 & 0 \\0 & 1\end{pmatrix},\; 
     \mathbf{i} = \begin{pmatrix}0 & -1 \\ 1 & 0\end{pmatrix},\;
     \mathbf{j} = \begin{pmatrix}i & 0 \\ 0 & -i\end{pmatrix},\;
     \mathbf{k} = \begin{pmatrix}0 & i \\ i & 0\end{pmatrix}
     \]

     forman una base de $\mathbb{H}$ como espacio vectorial real.
  4. Comprobar las identidades

     \[
     i^2=j^2=k^2=-1,\; ij=k,\; jk=i,\; ki=j
     \]

El álgebra así construida se llama álgebra de los cuaterniones de Hamilton.
#+end_statement

*** Primer punto
Comprobamos que es cerrada bajo el producto por reales

\[\lambda\begin{pmatrix}
\alpha & -\overline{\beta} \\
\beta & \overline{\alpha}
\end{pmatrix} = \begin{pmatrix}
\lambda\alpha & -\lambda\overline{\beta} \\
\lambda\beta & \lambda\overline{\alpha}
\end{pmatrix} = \begin{pmatrix}
\lambda\alpha & -\overline{\lambda\beta} \\
\lambda\beta & \overline{\lambda\alpha}
\end{pmatrix}
\]

y que es cerrada bajo su producto

\[\begin{pmatrix}
\alpha & -\overline{\beta} \\
\beta & \overline{\alpha}
\end{pmatrix}\begin{pmatrix}
\gamma & -\overline{\delta} \\
\delta & \overline{\gamma}
\end{pmatrix} = \begin{pmatrix}
\alpha\gamma-\overline{\beta}\delta & -\overline{\delta}\alpha-\overline{\beta}\overline{\gamma} \\
\beta\gamma+\overline{\alpha}\delta & -\overline{\delta}\beta + \overline{\gamma}\overline{\alpha}
\end{pmatrix} = \begin{pmatrix}
\alpha\gamma-\overline{\beta}\delta & -\left(\overline{\beta\gamma+\overline{\alpha}\delta}\right)\\
\beta\gamma+\overline{\alpha}\delta & \overline{\alpha\gamma-\overline{\beta}\delta}
\end{pmatrix}.
\]

Además, si tomamos una matriz en el centro, debe cumplir

\[\begin{aligned}\begin{pmatrix}
a & -\overline{b} \\
b & \overline{a}
\end{pmatrix}\begin{pmatrix}
c & -\overline{d} \\
d & \overline{c}
\end{pmatrix} = \begin{pmatrix}
ac-\overline{b}d & -a\overline{d}-\overline{bc} \\
bc+\overline{a}d & \overline{ac} - b\overline{d}
\end{pmatrix} &=\\ =\begin{pmatrix}
ac-b\overline{d} & -\overline{b}c-\overline{da} \\
ad+\overline{c}b & \overline{ac}-\overline{b}d
\end{pmatrix} &= \begin{pmatrix}
c & -\overline{d} \\
d & \overline{c}
\end{pmatrix}\begin{pmatrix}
a & -\overline{b} \\
b & \overline{a}
\end{pmatrix},\end{aligned}
\]

así que $\overline{b}d = b\overline{d}$ y $\overline{a}d+bc = ad + \overline{c}d$. Tomando $c=0$ y $d=1$ llegamos a que
$a,b \in \mathbb{R}$; y tomando $d = i$, que $b=0$. Así, las únicas matrices en el centro
serán las que representan a los reales, de la forma

\[\left\{\begin{pmatrix}\lambda & 0 \\ 0 & \lambda
\end{pmatrix}\mid \lambda \in \mathbb{R}\right\}\]

*** Segundo punto
Simplemente comprobar que cada elemento tiene una inversa a derecha

\[\begin{pmatrix}
a & -\overline{b} \\ b & \overline{a}
\end{pmatrix}\begin{pmatrix}
\frac{\overline{a}}{a\overline{a}+b\overline{b}} & 
\frac{\overline{b}}{a\overline{a}+b\overline{b}} \\ 
\frac{-b}{a\overline{a}+b\overline{b}} & 
\frac{a}{a\overline{a}+b\overline{b}}
\end{pmatrix} = \begin{pmatrix}
1 & 0 \\ 0 & 1
\end{pmatrix}\]

usando que si $a\overline{a}+b\overline{b} = 0$, es porque $a=b=0$ y el elemento es nulo.

*** Tercer punto
Sabiendo que los complejos son un espacio vectorial de dimensión $2$
con base $\{1,i\}$, podemos escribir los elementos de $\mathbb{H}$ como

\[\begin{pmatrix}
a+bi & -c+di \\
c+di & a-bi
\end{pmatrix} = a\begin{pmatrix}
1 & 0 \\ 0 & 1
\end{pmatrix}+
b\begin{pmatrix}
i & 0 \\ 0 & -i
\end{pmatrix}+
c\begin{pmatrix}
0 & 1 \\ -1 & 0
\end{pmatrix}+
d\begin{pmatrix}
0 & i \\ i & 0
\end{pmatrix}\]

que trivialmente es una descomposición única por independencia lineal.

*** Cuarto punto
Podemos comprobar trivialmente los cálculos.

** Ejercicio 8
#+begin_statement
Dado un A-módulo $V$, demostrar que $\mathrm{Ann}_A(V) = \left\{ a \in A \mid av=0\; \forall v\in V \right\}$ es un
ideal de $A$. Dotar a $V$ de estructura de $A/\mathrm{Ann}_{A}(V)\text{-módulo}$ fiel (es decir,
la representación correspondiente es fiel).
#+end_statement

Si $a \in \mathrm{Ann}_A(V)$ tenemos que para cualquier $r \in A$ y $v \in V$, $rav = r0 = 0$ y 
$(ar)v = a(rv) = 0$. Podemos dotar a $V$ de estructura de módulo en el cociente
como

\[
\left( a+ \mathrm{Ann}(V) \right)v = av.
\]

Esta representación es fiel porque si tenemos $\forall v\in V\colon av = bv$, entonces
se tiene $a-b \in \mathrm{Ann}(V)$.

** Ejercicio 9
#+begin_statement
Dar una demostración del Lema 1.25.
#+end_statement

*** Primer punto
Es claro que el menor submódulo que contenga a $N_1 \cup \dots \cup N_m$ debe contener
en particular a todas las sumas y por tanto

\[
\left\{ n_1+\dots+n_m \mid n_i \in N_i \right\} \subseteq N_1 + \dots + N_m.
\]

Si además probamos que es un submódulo, tendremos que debe ser el menor
conteniendo a la unión. Es cerrado para la suma por tenerse

\[
(n_1+\dots+n_m)+(n'_1+\dots+n'_m) =
(n_1+n'_1)+\dots+(n_m+n_m')
\]

y cerrado para el producto por elementos del anillo por tenerse

\[
a(n_1+\dots+n_m) = an_1+\dots+an_m.
\]

*** Segundo punto
De la misma forma, es claro que el menor submódulo conteniendo a $X$ debe
contener al menor módulo conteniendo a cada uno de sus elementos, y por
tanto al menor submódulo conteniendo a todos esos submódulos. Sabemos
entonces que

\[
RX \supseteq Rm_1 + \dots + Rm_n.
\]

Pero además, una suma de módulos es un submódulo, así que este es el menor
submódulo que contiene a $X$.

** Ejercicio 10
#+begin_statement
Dados $A\text{-módulos}$ por la izquierda $M,N$ y una aplicación $f\colon M \to N$,
demostrar que $f$ es homomorfismo de $A\text{-módulos}$ si, y sólo si,
$f(am+a'm') = af(m) + a'f(m')$ para todo $a,a'\in A;\; m,m'\in M$.
#+end_statement

*** Si es homomorfismo de módulos cumple la regla
Aplicando primero linealidad y luego dos veces la condición de homomorfismo
de módulos tenemos

\[
f(am+a'm') = f(am)+f(a'm') = af(m) + a'f(m').
\]

*** Si cumple la regla, es homomorfismo de módulos
La linealidad la comprobamos tomando $a=a'=1$, la unidad del álgebra,

\[
f(m+m') = f(1m+1m') = 1f(m) + 1f(m') = f(m) + f(m').
\]

Y la condición de homomorfismo de módulos se comprueba tomando $a' = m'=0$,

\[
f(am) = f(am+0) = af(m) + 0f(0) = af(m).
\]

** Ejercicio 11
#+begin_statement
Demostrar que un conjunto de generadores $\{m_i \mid i \in I\}$ de un módulo $_RM$ es una
base si, y sólo si, la igualdad $\sum_{i\in I}r_im_i = 0$ para $r_i \in R$ implica $r_i = 0$ para
todo $i \in I$.
#+end_statement

*** Si es una base, se tiene la condición
Si tenemos una base $\{m_i \mid i \in I\}$, en particular el $0$ se escribe de forma 
única como $0 = \sum_{i\in I} 0m_i$. Así, cualquier otra forma de escribir $0 = \sum_{i\in I} r_i m_i$
nos da $r_i = 0$.

*** Si se tiene la condición, es una base
Si tenemos la condición y tenemos dos formas distintas de escribir un
elemento, tendríamos en particular

\[
\sum_{i\in I} r_im_i = m = \sum_{i\in I}s_im_i
\quad\text{ y }\quad
\sum_{i \in I} (r_i-s_i)m_i = 0.
\]

Lo que nos llevaría a $r_i = s_i$ para cumplir la condición.

** Ejercicio 12
#+begin_statement
Sea $\theta \in \mathbb{R}$ y $T_\theta : \mathbb{R}^2\to\mathbb{R}^2$ el endomorfismo que gira los vectores un ángulo $\theta$
en sentido contrario de las agujas del reloj. Consideremos la correspondiente
estructura de $\mathbb{R}[X]$ módulo definida por $T_\theta$ sobre $\mathbb{R}^2$. Discutir para qué valores
de $\theta$ es este módulo simple.
#+end_statement

Supongamos un $v \in M$, subespacio vectorial. Como $Tv \in M$, tenemos dos casos,

  * si $Tv,v$ son linealmente dependientes, se tiene $Tv = \lambda v$ y por tanto debe
    tenerse $\theta = k\pi$ para algún $k \in \mathbb{Z}$. El módulo no sería simple, ya que se
    tendría $T^2v = v$.
  * si no son linealmente dependientes, se tiene un espacio de dimensión al
    menos $2$, que debe ser por tanto el total. El módulo sería simple.

Es decir, salvo en el caso $\theta = k\pi$, el módulo es simple.

** Ejercicio 13
#+begin_statement
Sea $M$ un $A\text{-módulo}$. Demostrar que $M$ es simple si, y sólo si, $M = Am$ para
todo $0 \neq m \in M$.
#+end_statement

*** Supongamos M simple
Entonces $Am$ es un submódulo no nulo, que debe ser por tanto $M$.

*** Supongamos la caracterización
Sea un submódulo de $M$ que contiene a algún elemento no nulo $m$. Por
las propiedades de submódulo, debe contener también a todo $Am = M$.
Así, no existen submódulos propios.

** Ejercicio 14 (*)
#+begin_statement
Consideramos $T\colon \mathbb{R}^3 \to \mathbb{R}^3$ una aplicación lineal, y la estructura de $\mathbb{R}[X]\text{-módulo}$
correspondiente sobre $\mathbb{R}^3$. Discutir los posibles valores de la longitud de
$\mathbb{R}^3$ como $\mathbb{R}[X]\text{-módulo}$. Poner un ejemplo de $T$ para el que se alcance cada longitud.
#+end_statement

La longitud debe ser como máximo $3$, su dimensión como espacio vectorial
sobre $\mathbb{R}$. Estudiaremos los casos posibles.

*Longitud 1.*
Probaremos que no puede tenerse una cadena de longitud $1$; es decir, que
$\mathbb{R}^3$ sea simple. Toda aplicación lineal $T$ nos da una ecuación polinómica

\[ | T - \lambda I | = 0
\]

de grado $3$ con coeficientes reales, que debe tener al menos una solución
en los reales. Esto nos da un vector propio y por tanto un subespacio que
queda fijo por la acción de $T$; es decir, un submódulo.

*Longitud 2.*
Tomamos $T$ la aplicación que gira un plano mientras deja fija la recta
ortogonal a él; específicamente,

\[T = \begin{pmatrix}
0 & 1 & 0 \\
-1 & 0 & 0 \\
0 & 0 & 1
\end{pmatrix}
\]

nos da el subespacio $\left\langle e_3 \right\rangle$ fijo bajo su acción. Por otro lado, el
submódulo $\left\langle e_1,e_2 \right\rangle \cong \mathbb{R}^3/ \left\langle e_3 \right\rangle$ es simple; la rotación no dejará ninguna
recta fija, no hay vectores propios. Así, tenemos una serie de
composición

\[
0 \subset \left\langle e_1,e_2 \right\rangle \subset \mathbb{R}^3.
\]

*Longitud 3.*
Simplemente tomando la identidad y retirando a cada paso una dimensión
del espacio vectorial

\[
0 \subset \left\langle e_1 \right\rangle
\subset \left\langle e_1,e_2 \right\rangle
\subset \left\langle e_1,e_2,e_3 \right\rangle.
\]

** Ejercicio 15
#+begin_statement
Sea $\mathbb{P}_{n}$ el espacio vectorial real de las funciones polinómicas en una variable
de grado menor o igual que $n$. Sea $T\colon \mathbb{P}_n \to \mathbb{P}_n$ la aplicación lineal que asigna
a cada polinomio su derivada. Calcular una serie de composición de $\mathbb{P}_n$ visto
como $\mathbb{R}[X]\text{-módulo}$ via $T$.
#+end_statement

Tenemos una base del espacio vectorial dada por $\left\{ 1,x,\dots,x^n \right\}$, podemos generar
una serie de composición donde vemos que cada uno es un submódulo cerrado para
la derivación y que cada cociente es simple por ser de dimensión $1$ en los reales
como

\[
0 \subset 
\left\langle 1 \right\rangle \subset
\left\langle 1,x \right\rangle \subset 
\dots \subset
\left\langle 1,x,\dots,x^n \right\rangle.
\]

** Ejercicio 16 (**)
#+begin_statement
En las condiciones del Ejercicio 15, calcular todos los $\mathbb{R}[X]\text{-submódulos}$ de $\mathbb{P}_n$.
#+end_statement

Probaremos que los únicos submódulos de $\mathbb{P}_n$ son de la forma $\left\langle 1,x,x^2,\dots,x^k \right\rangle$.
Si tomamos un polinomio en un submódulo podemos suponerlo mónico por estar
en un cuerpo; y como además es de característica $0$, sus derivadas serán cada
una de un grado menor. Así, dado $p = x^k+ \dots +a_1x + a_0 \in \mathbb{P}_n$ tendremos

\[\begin{aligned}
p =& x^k+& a_{k-1}x^{k-1} +& \dots &+& a_1x &+& a_0 \\
\partial p =&  &kx^{k-1}+& \dots &+& 2a_2x &+ &a_1 \\
\dots \\
\partial^n p =&  && && && k! \\
\end{aligned}\]

Lo que constituye una base del espacio de polinomios de dimensión $k$ 
equivalente a $\left\langle 1,x,x^2,\dots,x^k \right\rangle$ gracias a que estamos en un cuerpo. Así,
cada submódulo será el submódulo de los polinomios de grado menor o igual
a $k$ para $k$ el grado de su polinomio de mayor grado.

** Ejercicio 17 (**)
#+begin_statement
Supongamos $T \colon V \to V$ un endomorfismo $K\text{-lineal}$, donde $V$ es un espacio vectorial
de dimensión finita que consideramos, como de costumbre, como $K[X]\text{-módulo}$.
Supongamos que el polinomio mínimo $m(X)$ de $T$ es irreducible en $K[X]$ (ver
Ejemplo 14 para el concepto de polinomio mínimo). Demostrar que existen 
$K[X]\text{-submódulos}$ simples $V_1,\dots,V_t$ de $V$ tal que $V = V_1\oplus \dots \oplus V_{t}$ como
$K[X]\text{-módulo}$.
#+end_statement

Como $m(X)$ es irreducible y estamos en un DIP el ideal que genera,
$(m(X))$, es maximal, y por tanto el cociente

\[
k \cong \frac{K[X]}{(m(X))}
\]

es un cuerpo. Y $V$ es un $k\text{-espacio vectorial}$ ya que por el primer teorema de 
isomorfía tenemos que $K[X] \to \mathrm{End}_K(V)$ descompone en una proyección y una
inyección

\[\begin{tikzcd}
K[X] \rar[two heads] & 
\displaystyle\frac{K[X]}{(m(X))} \rar[hook] &
\mathrm{End}_K(V).
\end{tikzcd}\]

Ahora, si $V$ tiene una base finita como $K\text{-espacio vectorial}$, sabiendo que $K \subseteq k$,
tenemos que $V$ tiene un sistema de generadores finito como $k\text{-espacio vectorial}$.
Por el Corolario 1.45 existe entonces un subconjunto de ese sistema de 
generadores tal que

\[
V = \bigoplus_{j \in J} kv_j = V_1 \oplus \dots \oplus V_t.
\]

Nótese que cada uno de ellos es un submódulo simple por ser isomorfos a $k$.

** Ejercicio 18 (**)
#+begin_statement
En las condiciones del Ejercicio 17, demostrar que el polinomio característico
de $T$ es $m(X)^t$.
#+end_statement

Por Cayley-Hamilton, sabemos que $T$ cumple su ecuación característica, y por
tanto, $m(X)$ divide a su polinomio característico. 

Por otro lado, supongamos que tenemos un factor irreducible $p$ del
polinomio característico; este tendrá alguna raíz $\lambda$ en la clausura
algebraica de $K$. Es decir, tendremos un vector propio con coeficientes
en $\overline{K}$ cumpliendo $Tv = \lambda v$.

Si aplicamos el polinomio mínimo evaluado en $T$ a ese vector tendremos

\[
0 = m(T)v = m(\lambda)v,
\]

así que $\lambda$ es una raíz de $m$ en la clausura algebraica. Ahora, como el
polinomio irreducible de $\lambda$ en $K$ sigue siendo $p$, concluimos que $p \mid m$.

En general, hemos demostrado que todo factor irreducible del polinomio
característico divide al polinomio mínimo. Cuando además el polinomio
mínimo es irreducible, se tiene que el polinomio característico debe
ser de la forma $m(X)^s$.

Ahora comprobaremos que $s=t$. En efecto, tenemos que si $\mathrm{gr}(m) = n$,
entonces, por construcción, $\mathrm{dim}_Kk=n$ y por ser $V_i \cong k$, tenemos
$\mathrm{dim}_{K}(V) = tn$; que debe ser el grado del polinomio característico,
a la vez que debe ser $sn$.

** Ejercicio 19
#+begin_statement
Demostrar que si $R$ es un dominio de integridad conmutativo, entonces $R$ no
tiene idempotentes no triviales.
#+end_statement

Si $e^2=e$, entonces $e(e-1) = 0$; lo que, en un dominio de integridad implica
que $e = 0$ ó $e-1 = 0$.

Nótese que no hemos usado la conmutatividad.

** Ejercicio 20
#+begin_statement
Dar un CCIO para $R = M_n(k)$.
#+end_statement

Sean $E_{ii}$ las matrices nulas excepto por un $1$ en la entrada $i,i$. Se comprueba
trivialmente que $E_{ii}E_{jj} = 0$ para cualesquiera $i \neq j$, y que $E_{ii}^2 = 1$. Forman
además un conjunto completo por tenerse:

\[
I = E_{11} + E_{22} + \dots + E_{nn}
\]
** TODO Ejercicio 21
#+begin_statement
Comprobar las afirmaciones realizadas en el Ejemplo 17.
#+end_statement
** Ejercicio 22
#+begin_statement
Sea $\left\{ e_1,\dots,e_n \right\}$ un ccio para $R$. Demostrar que los idempotentes $e_1,\dots,e_n$ son
centrales si, y sólo si, $e_iRe_j = 0$ para todo $i \neq j$.
#+end_statement

*** Si son centrales, cumplen la condición
Si son centrales, se tiene que, para cualquier $r \in R$,

\[
e_ire_j = re_ie_j = 0
\]

por ortogonalidad.

*** Si cumplen la condición, son centrales
Sabiendo que cumplen que $e_ire_j = 0$ para cualquier $r \in R$, tenemos

\[
e_ir = e_ir\left(\sum_j e_j\right) = \sum_j e_ire_j = e_ire_i = \sum_j e_jre_i = re_i
\]

por ser completos.

** Ejercicio 23 (*)
#+begin_statement
Sean $M$ y $N$ módulos semisimples con descomposiciones como sumas directas
de submódulos simples $M = S_1 \oplus \dots \oplus S_t$ y $N = T_1\oplus \dots \oplus T_s$. Supongamos que
$S_i$ no es isomorfo a $T_j$ para todo $i = 1,\dots,t$, $j = 1,\dots,s$. Demostrar que
todo homomorfismo de módulos de $M$ a $N$ es cero.
#+end_statement

Desde el ejemplo 17, sabemos que, en los endomorfismos de un módulo suma
directa, la composición de inclusión y proyección en las distintas componentes
nos da un ccio. Vamos a llamar $q_i \colon M \to M$ al endomorfismo que proyecta e
incluye en la componente $i\text{-ésima}$; y vamos a llamar $p_j \colon N\to N$ al que hace
lo mismo en la componente $j\text{-ésima}$ de $N$. Sabemos que

\[
q_1 + \dots + q_t = \mathrm{id}
\quad\text{ y que }\quad
p_1 + \dots + p_s = \mathrm{id}.
\]

Ahora, calculamos que

\[\begin{aligned}
f &= (q_1+\dots+q_t) \circ f \circ (p_1+\dots+p_s) \\
  &= \sum_{i=1}^t\sum_{j=1}^s q_i\circ f\circ p_j = 0,
\end{aligned}\]

ya que $q_i\circ f\circ p_j\colon S_i\to T_i$ debe ser nulo o isomorfismo por el Lema de Schur
y hemos supuesto que no es isomorfismo.

# Nótese que no es exactamente esto, sino que hay que partir q en sus
# componentes para igualar a cero.

** TODO Ejercicio 24
#+begin_statement
Sea $M$ un módulo semisimple de dimensión finita con estructura
$\left( n_1,\Sigma_1 \right),\dots,(n_t,\Sigma_t)$. Si $N$ es un submódulo de $M$, demostrar que su estructura
es $\left( m_1,\Sigma_1 \right),\dots,(m_t,\Sigma_t)$ para ciertos $m_j \leq n_j$ (admitimos que $m_j=0$ significa
que $\Sigma_j$ no aparece en la estructura de $M$).
#+end_statement
** TODO Ejercicio 25
#+begin_statement
Establecer un enunciado análogo al del Ejercicio 24 para cada cociente de $M$.
#+end_statement
** TODO Ejercicio 26
#+begin_statement
Dada una $K\text{-álgebra}$ $A$, demostrar que la aplicación $\rho\colon A \to \mathrm{End}(A)^{op}$ definida
por $\rho(a)(a') = a'a$ es un isomorfismo de $K\text{-álgebras}$.
#+end_statement

** TODO Ejercicio 27 (*)
#+begin_statement
Sea $B$ un álgebra. Demostrar que la aplicación que asigna a cada matriz
su traspuesta da un isomorfismo de álgebras $M_n(B)^{op} \cong M_n(B^{op})$.
#+end_statement

** TODO Ejercicio 28
#+begin_statement
Sea $\varphi\colon R \to S$ un isomorfismo de $K\text{-álgebras}$, e $I,J$ ideales por la izquierda
de $R$. Demostrar que $\varphi(I),\varphi(J)$ son ideales por la izquierda de $S$ y que dado
cualquier homomorfismo de $R\text{-módulos}$ $f \colon I \to J$, la aplicación $\widehat f\colon \varphi(I) \to \varphi(J)$
definida por $\widehat f(y) = \varphi f \varphi^{-1}(y)$ para $y \in \varphi(I)$ es un homomorfismo de $S\text{-módulos}$.
#+end_statement

** TODO Ejercicio 29
#+begin_statement
Sean $R_1,\dots,R_n$ $K\text{-álgebras}$ y $R = R_1\times \dots \times R_n$. Los ideales por la izquierda
de $R$ son de la forma $I_1\times \dots\times I_n$, con $I_i$ ideal por la izquierda de $R_i$ para
$i = 1,\dots,n$. Análoga descripción tienen los ideales biláteros de $R$.
#+end_statement

** TODO Ejercicio 30 (*)
#+begin_statement
Sea $A$ un álgebra simple finito-dimensional. Demostrar que $R = \mathrm{M}(A)$ es un
álgebra simple de dimensión finita. Demostrar que asimismo que si $\Sigma$ es un
$A\text{-módulo}$ simple y $M$ es un $R\text{-módulo}$ simple, entonces $\mathrm{End}(\Sigma)$ y $\mathrm{End}(M)$
son álgebras isomorfas.
#+end_statement

** Ejercicio 31 (*)                                                 :export:
#+begin_statement
Demostrar que $T_q \in SO(V)$ para todo cuaternio $q$ de norma $1$.
#+end_statement

Sabiendo que los cuaternios se expresan como $\mathbb{H} = \mathbb{R} \oplus V$ escribimos $q = a + bu$, 
donde $u \in V$ y $\|u\| = 1$, lo que nos da $u^2 = -u(-u) = -1$. Como $q$ es de norma $1$ 
debe cumplir

\[
1 = qq^{\ast} = a^2 - ub^2 = a^2 + b^2,
\]

luego puede expresarse como $q = \cos \theta + \sin\theta u$ para algún $\theta \in \mathbb{R}$. Pero entonces
tenemos un cuaternio $w = \cos(\theta/2) + \sin(\theta/2) u$ que al elevarlo al cuadrado
nos da $q$, ya que

\[ w^2 =
\left( \cos \frac{\theta}{2} + \sin \frac{\theta}{2}u \right)^2 =
\cos^2 \frac{\theta}{2} - \sin^2 \frac{\theta}{2} + 
2 \sin \frac{\theta}{2}\cos \frac{\theta}{2}u =
\cos \theta + \sin \theta u = q.
\]

Finalmente, como $T_q = T_w \circ T_w$ siendo isometrías, tenemos que
debe cumplirse que $|T_q| = |T_w|^2 = 1$ y por tanto, $T_q \in SO(V)$.

** Ejercicio 32 (*)                                                 :export:
#+begin_statement
Calcular explícitamente una representación real no trivial de grado $2$ del
grupo de permutaciones $S_3$.
#+end_statement

Partimos de la idea de que $D_6 = S_{3}$, así que cada elemento representará
una simetría del triángulo equilátero con centro en el origen y un
vértice en $(1\ 0)$.

En $\mathbb{R}^2$, llamamos $r,s,t$ a las rectas de ángulos $0,2\pi/3,4\pi/3$. Consideraremos
las trasposiciones como simetrías respecto de estas rectas, y las permutaciones
de tres elementos serán rotaciones compuestas de dos simetrías. Explícitamente,
las trasposiciones de dos elementos son

\[
(2\ 3) \mapsto \begin{pmatrix} 1 & 0 \\ 0 & -1 \end{pmatrix},
\quad
(1\ 2) \mapsto \begin{pmatrix} -1/2 & \sqrt{3}/2 \\ \sqrt{3}/2 & 1/2 \end{pmatrix},
\quad
(1\ 3) \mapsto \begin{pmatrix} -1/2 & -\sqrt{3}/2 \\ -\sqrt{3}/2 & 1/2 \end{pmatrix},
\]

y las rotaciones son

\[
(1\ 2\ 3) \mapsto 
\begin{pmatrix} -1/2 & -\sqrt{3}/2 \\ \sqrt{3}/2 & -1/2 \end{pmatrix},
\quad
(1\ 3\ 2) \mapsto
\begin{pmatrix} -1/2 & \sqrt{3}/2 \\ -\sqrt{3}/2 & -1/2 \end{pmatrix}.
\]

Y podemos comprobar sobre ellas que cumplen la tabla de multiplicación
del grupo.

** Ejercicio 33
#+begin_statement
Comprobar que la multiplicación definida sobre $KG$ es asociativa. Su elemento
neutro es $1e$, donde $e$ es el elemento neutro de $G$.
#+end_statement

Tenemos por bilinealidad

\[
\left( \sum_{g \in G} \lambda_gg \right)
\left( \sum_{h \in G} \mu_hh \sum_{k \in G} \delta_kk \right) =
\sum_{g \in G} \lambda_gg \sum_{j,k \in G} \mu_h\delta_k hk =
\sum_{g,j,k \in G} \lambda_g\mu_h\delta_k g(hk),
\]

mientras que

\[
\left( \sum_{g \in G} \lambda_gg \sum_{h \in G} \mu_hh \right)
\left( \sum_{k \in G} \delta_kk \right) =
\sum_{g \in G} \lambda_g\mu_hgh \sum_{j,k \in G} \delta_kk =
\sum_{g,j,k \in G} \lambda_g\mu_h\delta_k (gh)k,
\]

que son iguales por asociatividad del producto de grupo. Hemos demostrado
en general que cualquier bilineal que extienda un operador binario sobre
los vectores de la base es asociativo.

** TODO [#A] Ejercicio 34
#+begin_statement
Calcular todos los subespacios invariantes para la representación de $Q_8$ 
del Ejemplo 20.
#+end_statement

** TODO [#A] Ejercicio 35
#+begin_statement
Calcular todos los subespacios invariantes para la representación de $S_3$
del Ejemplo 32.
#+end_statement

** TODO Ejercicio 36
** TODO Ejercicio 37
** TODO Ejercicio 38
** TODO Ejercicio 39
** Ejercicio 40 (*)                                                 :export:
#+begin_statement
Calcular razonadamente la tabla de caracteres de $Q_8$.
#+end_statement

Puede comprobarse multiplicando que el grupo tiene cinco clases de conjugación,
con representantes dados por $1,-1,i,j,k$, por lo que tiene cinco representaciones
irreducibles complejas. Sabemos que los cuadrados de las dimensiones de esas 
representaciones deben sumar el orden del grupo, es decir 

\[ 8 = n_1^2 + n_2^2 + n_3^2 + n_4^2 + n_5^2,\]

y como no pueden tenerse dos $n_i > 1$, la única solución posible es que tengan
dimensiones $1,1,1,1,2$, determinando el caracter de la identidad en cada una
de las representaciones.

 * El /primer carácter/ será el dado por la representación irreducible trivial
   que envía cada elemento del grupo a $1 \in \mathbb{C}$.
 * El /último carácter/, de dimensión $2$ es el dado por la representación de los
   cuaternios como matrices complejas que conocemos del Ejercicio 7. Es además
   irreducible por tenerse $(\chi_5,\chi_5) = (2^2+(-2)^2)/8 = 1$.
 * Para cualquiera de $i,j,k$, existe un subgrupo normal de $Q_8$ generado por
   el elemento con $4$ elementos, como por ejemplo $\left\{ 1,-1,i,-i \right\}$. Si llamamos a
   este grupo $A$, se tiene que $Q_8/A \cong \mathbb{Z}_2$, el único grupo de cardinalidad $2$.
   Este grupo tiene una representación irreducible en $\mathbb{C}$ como $1,-1$, y por
   el Ejercicio 38, sabemos que la composición de representación irreducible
   con una proyección a un cociente por un subgrupo normal es una 
   representación irreducible, así que lo es

   \[
   \rho_{A}\colon Q_8 \overset{\pi}\longrightarrow Q_8 / A \cong \mathbb{Z}_2 
   \longrightarrow \mathbb{C}.
   \]

   Esta representación la podemos repetir para los $A$ generados por $i,j,k$,
   dándonos las tres representaciones restantes con caracteres $\chi_2,\chi_3,\chi_4$ 
   respectivamente. Nótese que cada una de ellas
   envía al elemento $1$ a los elementos del grupo y a $-1$ a los elementos fuera
   del grupo.

Tenemos finalmente la tabla de caracteres irreducibles

\[\begin{tabular}{c|ccccc}
    & 1 &  1 & 2 & 2 & 2 \\
Q_8 & 1 & -1 & i & j & k \\
\hline
\chi_1 & 1 &  1 &  1 &  1 &  1 \\
\chi_2 & 1 &  1 & 1  & -1  & -1   \\
\chi_3 & 1 &  1  & -1   & 1   &  -1  \\
\chi_4 & 1 &  1  &  -1  & -1   & 1   \\
\chi_5 & 2 & -2 &  0 &  0 &  0 \\
\end{tabular}\]

** TODO Ejercicio 41 (*)
#+begin_statement
Calcular razonadamente la tabla de caracteres del grupo dihédrico $D_4$.
#+end_statement

Tomamos la presentación del grupo dihédrico

\[
\left\langle r,s \mid r^4=s^2=e, sr = r^{-1}s \right\rangle
\]

y comprobamos multiplicando que tiene $8$ elementos y $5$ clases de conjugación
con representantes $e,r,s,r^2,sr$, por lo que tiene cinco representaciones
irreducibles complejas. Sabemos que los cuadrados de las dimensiones de esas 
representaciones deben sumar el orden del grupo, es decir 

\[ 8 = n_1^2 + n_2^2 + n_3^2 + n_4^2 + n_5^2,\]

y como no pueden tenerse dos $n_i > 1$, la única solución posible es que tengan
dimensiones $1,1,1,1,2$, determinando el caracter de la identidad en cada una
de las representaciones.

 * El /primer carácter/ será el dado por la representación irreducible trivial
   que envía cada elemento del grupo a $1 \in \mathbb{C}$.

 * Tenemos tres subgrupos normales generados por $\left\langle e,r^2,s \right\rangle$, $\left\langle e,r^2,r \right\rangle$ y $\left\langle e,r^2,sr \right\rangle$,
   cada uno de ellos con cuatro elementos. Si llamamos a cualquiera de ellos
   $A$, tenemos la representación irreducible dada por la composición de la
   proyección al cociente con la representación irreducible de $\mathbb{Z}_2$ en los
   complejos

   \[
   \rho_{A}\colon D_4 \overset{\pi}\longrightarrow D_4 / A \cong \mathbb{Z}_2 
   \longrightarrow \mathbb{C}
   \]

   que es irreducible en virtud del Ejercicio 38. Esto nos da las
   representaciones con caracteres $\chi_2,\chi_3,\chi_4$ que envían cada elemento del
   grupo $A$ al $1$ y cada elemento fuera del grupo al $-1$.

 * El último carácter proviene de la representación matricial

   \[
   r \mapsto \begin{pmatrix}
   0 & -1 \\ 1 & 0
   \end{pmatrix} 
   \qquad
   s \mapsto \begin{pmatrix}
   1 & 0 \\ 0 & -1
   \end{pmatrix},
   \]
   
   # la irreducibilidad se debe comprobar (χ,χ)=1
   que podemos comprobar que cumple las relaciones de la presentación.
   Por el caracter que define, que no es suma de otros dos caracteres 
   irreducibles, sabemos que es forzosamente la representación irreducible
   que nos falta.

Tenemos finalmente la tabla de caracteres irreducibles como

\[\begin{tabular}{c|ccccc}
    & 1 &  1 & 2 & 2 & 2 \\
D_4 & $e$ & $r^2$ & $s$ & $r$ & $sr$ \\
\hline
\chi_1 & 1 &  1 &  1 &  1 &  1 \\
\chi_2 & 1 &  1 & 1  & -1  & -1   \\
\chi_3 & 1 &  1  & -1   & 1   &  -1  \\
\chi_4 & 1 &  1  &  -1  & -1   & 1   \\
\chi_5 & 2 & -2 &  0 &  0 &  0 \\
\end{tabular}\]

Nótese que es la misma tabla de caracteres que $Q_8$.

** Ejercicio 42 (**)                                                :export:
#+begin_statement
Calcular razonadamente la tabla de caracteres del grupo dihédrico $D_n$, 
para $n \geq 2$.
#+end_statement

Tomamos la presentación del grupo dihédrico

\[
\left\langle r,s \mid r^n=s^2=e, sr = r^{-1}s \right\rangle,
\]

y sabemos que es un grupo de $2n$ elementos. 

*** Clases de conjugación del caso impar
Cuando $n$ sea impar, sus clases de conjugación, que obtenemos
conjugando con los generadores, serán las siguientes:

 * La clase trivial $\left\{ 1 \right\}$.
 * Las clases de la forma $\left\{ r^i,r^{-i} \right\}$, donde $0 < i < n$, que se puede comprobar
   que permanecen invariantes por conjugación de los generadores. Tenemos
   $(n-1)/2$ clases de este tipo, cada una con dos elementos ya que por
   ser $n$ impar, $r^i\neq r^{-i}$.
 * La clase $\left\{ sr^i \mid 0 \leq i < n \right\}$, que se genera desde $s$ usando que $r^isr^{-i} = sr^{-2i}$ 
   y que $n$ es impar. Es una clase de $n$ elementos.

Sumando las cardinalidades de todas ellas, observamos que no hay más, ya
que

\[
2n = 1 + 2 \frac{n-1}{2} + n.
\]

Tenemos $(n+3)/2$ clases de conjugación, luego tendremos $(n+3)/2$
representaciones irreducibles complejas.

*** Representaciones en el caso impar
Podemos considerar los caracteres y representaciones siguientes:

 * el caracter trivial dado por la *representación irreducible trivial*
   que envía cada elemento del grupo a $1 \in \mathbb{C}$.

 * el grupo generado por $\left\langle r \right\rangle$ es normal y tenemos $D_n/\left\langle r \right\rangle \cong \mathbb{Z}_2$, luego una
   representación dada por la proyección y la representación irreducible
   de $\mathbb{Z}_2$ en los complejos es irreducible. La llamamos $\chi_2$.

 * si interpretamos los grupos dihédricos como grupos de simetrías de
   los polígonos, podemos escribir representaciones bidimensionales
   que toman $r$ como cualquiera de las rotaciones de ángulos $2\pi k/n$ en
   los complejos y $s$ como la simetría, es decir,

   \[
   r \mapsto \begin{pmatrix}
   e^{2\pi i k/n} & 0 \\
   0 & e^{-2\pi i k/n} \\
   \end{pmatrix}, \quad
   s \mapsto \begin{pmatrix}
   0 & 1 \\
   1 & 0 \\
   \end{pmatrix}.\]
   
   Comprobaremos que para $k>0$ todas ellas son irreducibles. Los
   espacios que deja invariantes la primera son claramente $(1\ 0)$ y
   $(0\ 1)$ con dos valores propios $e^{2\pi i k/n} \neq e^{-2\pi i k/n}$
   (aquí usamos $n$ impar), pero no son invariantes bajo simetrías,
   por lo que no existen subespacios invariantes y la representación
   es irreducible. A sus caracteres los llamamos $\chi_{k+2}$.

Dentro de las últimas, existirán algunas que serán equivalentes. Notamos
que la característica de $r$ bajo la representación dada por $k$ es $2\cos(2\pi k/n)$,
por lo que cada $k$ entre $1, \dots, (n-1)/2$ da una característica distinta y por
tanto una representación no equivalente a las demás. Con estas tenemos en
total $(n+3)/2$ representaciones irreducibles distintas, por lo que el resto
serán equivalentes.

*** Tabla de caracteres del caso impar
Tenemos finalmente la tabla de caracteres irreducibles como

\[
\small
\begin{tabular}{c|cccccc}
    & 1 &  2 & 2 & \dots & 2 & $n$ \\
D_n & $e$ & $r$ & $r^2$ & $\dots$ & $r^{(n-1)/2} & $s$ \\
\hline
\chi_1 & 1 &  1 &  1 &  \dots &  1 & 1 \\
\chi_2 & 1 &  1 & 1  &  \dots  & 1 & -1  \\
\chi_{2+1} &  2 & 2\cos(2\pi 1/n) &  2\cos(2 \pi 2/n)  & \dots   & 2\cos(2 \pi (n-1)/2n)  & 0 \\
\chi_{2+2} &  2 & 2\cos(2\pi 2/n) &  2\cos(2 \pi 4/n)  & \dots   & 2\cos(2 \pi 2(n-1)/2n)  & 0 \\
\dots & \dots & \dots & \dots  & \dots  & \dots & \dots \\
\chi_{2+(n-1)/2} &  2 & 2\cos(2\pi (n-1)/2n) &  2\cos(2 \pi 2(n-1)/2n)  & \dots   & 2\cos(2 \pi (n-1)(n-1)/4n)  & 0 \\
\end{tabular}\]

*** Clases de conjugación del caso par
Cuando $n$ es par, sus clases de conjugación, que obtendremos conjugando
con los generadores, serán las siguientes:

 * La clase trivial $\left\{ 1 \right\}$.
 * La clase que forma $\left\{ r^{n/2} \right\}$.
 * Las clases de la forma $\left\{ r^i,r^{-i} \right\}$, donde $0 < i < n$ y además exigimos que
   $i = n/2$ para evitar el caso $r^i = r^{-i}$. Tenemos $(n-2)/2$ clases de este
   tipo, cada una con $2$ elementos;
 * La clase $\left\{ sr^{2a} \mid 0 \leq a < n/2 \right\}$, que es cerrada para conjugación
   gracias a la paridad de $n$. Es una clase con $n/2$ elementos.
 * La clase $\left\{ sr^{2a+1} \mid 0 \leq a < n/2 \right\}$, de nuevo con $n/2$ elementos.
 
Sumando las cardinalidades de todas ellas, observamos que no hay más, ya
que

\[
2n = 1 + 1 + 2\frac{n-2}{2} + \frac{n}{2} + \frac{n}{2}.
\]

Tenemos por tanto $n/2 + 3$ clases de conjugación y representaciones 
irreducibles complejas distintas.

*** Representaciones en el caso par
Podemos considerar los caracteres y representaciones siguientes

 * el caracter trivial dado por la *representación irreducible trivial*
   que envía cada elemento del grupo a $1 \in \mathbb{C}$.

 * el grupo generado por $\left\langle r \right\rangle$ es normal y tenemos $D_n/\left\langle r \right\rangle \cong \mathbb{Z}_2$, luego una
   representación dada por la proyección y la representación irreducible
   de $\mathbb{Z}_2$ en los complejos es irreducible. La llamamos $\chi_2$.

 * el grupo generado por $\left\langle r^2 \right\rangle$ es normal y tenemos $D_n/\left\langle r^2 \right\rangle \cong \mathbb{Z}_2 \times \mathbb{Z}_2$, luego
   podemos buscar las representaciones irreducibles del grupo de Klein. Las
   cuatro representaciones irreducibles unidimensionales de este grupo abeliano
   podemos obtenerlas con la trivial y enviando dos de sus elementos no nulos
   al $-1$. Esto nos da los caracteres $\chi_3,\chi_4$ nuevos además de los dos anteriores.

 * si interpretamos los grupos dihédricos como grupos de simetrías de
   los polígonos, podemos escribir representaciones bidimensionales
   que toman $r$ como cualquiera de las rotaciones de ángulos $2\pi k/n$ en
   los complejos y $s$ como la simetría, es decir,

   \[
   r \mapsto \begin{pmatrix}
   e^{2\pi i k/n} & 0 \\
   0 & e^{-2\pi i k/n} \\
   \end{pmatrix}, \quad
   s \mapsto \begin{pmatrix}
   0 & 1 \\
   1 & 0 \\
   \end{pmatrix}.\]
   
   Comprobaremos que para $0<k<n/2$ todas ellas son irreducibles. Los
   espacios que deja invariantes la primera son claramente $(1\ 0)$ y
   $(0\ 1)$ con dos valores propios $e^{2\pi i k/n} \neq e^{-2\pi i k/n}$
   (aquí usamos $k < n/2$), pero no son invariantes bajo simetrías,
   por lo que no existen subespacios invariantes y la representación
   es irreducible. A sus caracteres los llamamos $\chi_{k+2}$.

Con esto tenemos los $n/2+3$ caracteres irreducibles.

*** Tabla de caracteres del caso par

\[
\small
\begin{tabular}{c|cccccccc}
    & 1  & 1 & 2 & \dots & 2 & $n/2$ & $n/2$ \\
D_n & $e$   & $r^{n/2}$ & $r$ & $\dots$ & $r^{n/2-1} & $s$ & $sr$ \\
\hline
\chi_1 & 1 &1 & 1 & \dots & 1 & 1 & 1 \\
\chi_2 & 1 &1& 1 & \dots & 1 & -1 & -1 \\
\chi_3 & 1 & (-1)^{n/2}& 1 &\dots & (-1)^{n/2-1} & 1 & -1 \\
\chi_4 & 1 & (-1)^{n/2} & 1 &\dots  & (-1)^{n/2-1} & -1 & 1 \\
\chi_{2+1} &  2 & 2\cos(2 \pi 1/2) & 2\cos(2\pi 1/n) & \dots & 2\cos(2 \pi (n/2-1)/n) & 0 & 0\\
\chi_{2+2} &  2 & 2\cos(2 \pi 2/2) & 2\cos(2\pi 2/n) & \dots  & 2\cos(2 \pi 2(n/2-1)/n) & 0 & 0 \\
\dots & \dots & \dots & \dots  & \dots  & \dots & \dots & \dots \\
\end{tabular}\]

** DONE Ejercicio 43
#+begin_statement
Sea $G$ un grupo abeliano finito, y sea $\widehat G$ el conjunto de los caracteres 
complejos irreducibles de $G$. Demostrar que el producto inducido por el
de números complejos dota a $\widehat G$ de estructura de grupo.
#+end_statement

Todas las representaciones irreducibles de un grupo abeliano son de 
dimensión $1$, luego $\chi_{\rho}(g) = \rho(g)$. La irreducibilidad se tiene por ser
todas de dimensión 1.

** TODO Ejercicio 44 (**)
#+begin_statement
Sea $G$ un grupo abeliano finito, y $\widehat G$ el grupo definido en el Ejercicio 43.
Demostrar que existe un isomorfismo de grupos $G \cong \widehat G$.
#+end_statement

** TODO Ejercicio 45
#+begin_statement
Sea $G$ un grupo finito y $g \in G$. Demostrar que $g$ es conjugado con $g^{-1}$ si,
y sólo si, $\chi(g) \in \mathbb{R}$ para todo carácter complejo irreducible $\chi$ de $G$.
#+end_statement
** TODO Ejercicio 46
#+begin_statement
Demostrar que $\varphi^G \in {\cal C}(G)$ para cada $\varphi \in {\cal C}(H)$, y que $\varphi^G(1) = |G:H|\varphi(1)$.
#+end_statement
** TODO Ejercicio 47 (*)
#+begin_statement
Sea $G$ un grupo abeliano finito, y $H$ un subgrupo de $G$. Demostrar que la
aplicación $(-)_H\colon {\cal C}(G) \to {\cal C}(H)$ es sobreyectiva. Identificar su núcleo.
#+end_statement
** Ejercicio 48 (**)                                                :export:
#+begin_statement
Calcular la tabla de caracteres complejos de $A_5$.
#+end_statement

*** Clases de conjugación
Para determinar las clases de conjugación usaremos crucialmente
que

\[
\sigma (a\ b\ \dots) \sigma^{-1} = (\sigma(a)\ \sigma(b)\ \dots).
\]

Tenemos las siguientes clases:

 * la clase trivial con el único elemento $()$.
 * la clase de ciclos de longitud $3$ con todos los elementos de la forma
   $(a\ b\ c)$, que pueden conseguirse desde cualquiera de ellos usando que
   $(a\ d\ e)(a\ b\ c)(d\ a\ e) = (d\ b\ c) = (c\ d\ b)$. Esta clase tiene cardinalidad
   $5\cdot 4\cdot 3/3 = 20$.
 * la clase de pares de trasposiciones disjuntas de la forma $(a\ b)(c\ d)$, 
   que pueden conseguirse desde cualquiera de ellos usando que
   $(e\ b\ a)(a\ b)(c\ d)(e\ a\ b) = (a\ e)(c\ d)$. Esta clase tiene cardinalidad
   $5\cdot 4\cdot 3\cdot 2/4\cdot 2 = 15$.
 * la clase de los ciclos de longitud 5 que se obtienen desde una
   permutación par desde $(1\ 2\ 3\ 4\ 5)$, que son todos aquellos que podemos
   obtener conjugando. Esta clase tiene cardinalidad $5!/5\cdot 2 = 12$.
 * la clase de los ciclos de longitud 5 que se obtienen desde una
   permutación impar desde $(2\ 1\ 3\ 4\ 5)$. Nótese que todos los ciclos de
   longitud 5 deben ser como este o como los anteriores según cómo
   sea la permutación que los lleva a $(1\ 2\ 3\ 4\ 5)$ por conjugación.
   Esta clase tiene cardinalidad $5!/5\cdot 2 = 12$.

Comprobamos que la suma de la cardinalidad de las clases de conjugación
es la cardinalidad del grupo completo,

\[
60 = 1 + 20 + 15 + 12 + 12.
\]

Y como hay $5$ clases de conjugación, existirán $5$ representaciones
irreducibles complejas, cuyas dimensiones además deberán sumar la
cardinalidad del grupo, es decir,

\[
60 = n_1^2+n_2^2+n_3^2+n_4^2+n_5^2.
\]

Sabiendo que la primera será la representación trivial, podemos
buscar exhaustivamente soluciones a $59 = n_2^2+n_3^2+n_4^2+n_5^2$ y
encontrar que la única, salvo reordenación, es $3,3,4,5$. Esas
deben ser las dimensiones de nuestras representaciones.

*** Tabla de caracteres
Calculamos la tabla de caracteres usando que:

 - tenemos claramente la representación trivial $\chi_1$.
 - desde $S_{5}$ tenemos la representación $\psi$ dada por permutar
   los vectores de una base de dimensión $5$. Si la restringimos
   tenemos $\psi_{A_5}$. Esta representación tiene un espacio
   invariante claro en $\left\langle (1,1,1,1,1) \right\rangle$ sobre el que actúa trivialmente. 
   Puede descomponerse entonces en la suma de dos representaciones,
   siendo una de ellas la trivial, y sabemos entonces que el caracter
   del otro sumando de la representación será $\psi_{A_5} - \chi_1$, por lo que
   nos queda una fila

   \[
   \small
   \begin{tabular}{c|cccccc}
   & 1    & 15             & 20          & 12                & 12                \\
   A_5        & $()$ & $(1\ 2)(3\ 4)$ & $(1\ 2\ 3)$ & $(1\ 2\ 3\ 4\ 5)$ & $(1\ 2\ 3\ 5\ 4)$ \\
   \hline
   \chi_4     & 5-1=4    & 1-1=0              & 2-1=1           & 0-1=-1                 & 0-1=-1                 \\ 
   \end{tabular}\]

   Comprobamos además que el caracter $\chi_4$ así obtenido es irreducible, 
   ya que cumple que $(\chi_4,\chi_4) = (4^2+20+12+12)/60 = 1$.

 - podemos obtener la segunda columna aplicando el teorema de ortogonalidad
   consigo misma para obtener $4 = 1^2 + x^2 + y^2 + z^2$ y con la primera
   columna para obtener $0 = 1 + 3x + 3y + 5z$. Si diagonalizamos la 
   representación de un elemento de esa clase de conjugación, como tiene
   orden $2$ la diagonal estaría formada por $\pm 1$; como además las dimensiones
   son $5,3,3$, todos impares, nunca podría ser $0$ su traza. Así, la única
   solución a la primera ecuación es $x^2 = y^2 = z^2 = 1$ y la solución a la
   segunda ecuación es $x=-1, y=-1, z=1$.

 - la última fila de la tabla de caracteres la podemos completar usando
   las relaciones de ortogonalidad. Sabemos que

   \[\begin{aligned}
   40 + 20b^2 + 12c^2 + 12d^2 &= 60 \\
   5 +15 + 20b   + 12c   + 12d   &= 0  \\
   20 + 20b   - 12c   - 12d   &= 0  \\
   \end{aligned}\]

   de donde deducimos primero que $c+d=0$, luego $b=-1$ y $c=d=0$.
   Hemos llegado a la conclusión de que

   \[\small
   \begin{tabular}{c|cccccc}
   & 1    & 15             & 20          & 12                & 12                \\
   A_5        & $()$ & $(1\ 2)(3\ 4)$ & $(1\ 2\ 3)$ & $(1\ 2\ 3\ 4\ 5)$ & $(1\ 2\ 3\ 5\ 4)$ \\
   \hline
   \chi_5     & 5    & 1              & b=-1           & c=0                 & d=0                 \\ 
   \end{tabular}\]   

 - la tercera columna de la tabla podemos obtenerla de nuevo con relaciones
   de ortogonalidad, tenemos $3 = 1 + u^2 + v^2 + 1 + 1$ y $1 -u-v-1=0$, 
   luego $u = -v$ y $u=v=0$.

 - las dos últimas entradas están sujetas a las mismas condiciones, así
   que esperamos obtenerlas como soluciones distintas del mismo sistema
   de ecuaciones de ortogonalidad. Aplicando ortogonalidad tenemos
   $3^2 + 15 + 12p^{2}+ 12q^{2} = 60$ y $3 -15+12p+12q=0$, luego $p=1-q$,
   y como $p^2+(1-p)^2 = 3$, tenemos que las dos soluciones posibles
   serán las de $p^2 - p - 1 = 0$, es decir $p=\pm(1+\sqrt{5})/2$.


Así, la tabla de caracteres acaba quedando como

\[\small
\begin{tabular}{c|cccccc}
           & 1    & 15             & 20          & 12                & 12                \\
A_5        & $()$ & $(1\ 2)(3\ 4)$ & $(1\ 2\ 3)$ & $(1\ 2\ 3\ 4\ 5)$ & $(1\ 2\ 3\ 5\ 4)$ \\
\hline
\chi_1     & 1    & 1              & 1           & 1                 & 1                 \\ 
\chi_2     & 3    & -1             & 0           & (1+\sqrt{5})/2    & (1-\sqrt{5})/2    \\ 
\chi_3     & 3    & -1             & 0           & (1-\sqrt{5})/2    & (1+\sqrt{5})/2    \\ 
\chi_4     & 4    & 0              & 1           & -1                & -1                \\ 
\chi_5     & 5    & 1              & -1          & 0                 & 0                 \\ 
\end{tabular}\]
