#+Title: Math
#+todo: TODO CHECK | DONE
#+setupfile: setup/ejerciciocomputacion.setup

** Header                                                                                                     :ignore:
#+latex_header: \usepackage{libertine}
#+latex_header: \usepackage[scale=0.85]{FiraMono}
#+latex_header: \usepackage{unicode-math}

#+latex_header: \usepackage[utf8x]{inputenc} 
#+latex_header: \setcounter{secnumdepth}{0}
#+latex_header: \setlength{\parindent}{0pt}
#+latex_header: \usepackage{physics}
#+latex_header: \usepackage{amsthm}
#+latex_header: \usepackage{amsmath}
#+latex_header: \usepackage{amssymb}
#+latex_header: \usepackage{stmaryrd}
#+latex_header: \usepackage{mathtools}
#+latex_header: \usepackage{mathabx}
#+latex_header: \usepackage{color}
#+latex_header: \usepackage{bussproofs}\EnableBpAbbreviations{}
#+latex_header: \usepackage{tikz}
#+latex_header: \usepackage{tikz-cd}
#+latex_header: \usepackage{bussproofs} \EnableBpAbbreviations{}
#+latex_header: \usepackage[makeroom]{cancel}

#+latex_header: \DeclareMathOperator{\im}{Im}
#+latex_header: \DeclareMathOperator{\coker}{Coker}
#+latex_header: \DeclareMathOperator{\spec}{Spec}
#+latex_header: \DeclarePairedDelimiter\bbk{\llbracket}{\rrbracket}
#+latex_header: \newcommand{\vertiii}[1]{{\left\vert\kern-0.25ex\left\vert\kern-0.25ex\left\vert #1 \right\vert\kern-0.25ex\right\vert\kern-0.25ex\right\vert}}
#+latex_header: \newcommand{\nnorm}[1]{{\left\vert\kern-0.25ex\left\vert\kern-0.25ex\left\vert #1 \right\vert\kern-0.25ex\right\vert\kern-0.25ex\right\vert}}

#+latex_header: \newcommand\id{\mathrm{id}}
#+latex_header: \newcommand\Id{\mathrm{Id}}
#+latex_header: \newcommand\hom{\mathrm{hom}}
#+latex_header: \newcommand\Nat{\mathrm{Nat}}
#+latex_header: \newcommand\Grp{\mathsf{Grp}}
#+latex_header: \newcommand\Set{\mathsf{Set}}
#+latex_header: \newcommand\todot{\xrightarrow{.}}
#+latex_header: \usepackage{mathtools}
#+latex_header: \DeclarePairedDelimiter\pair{\langle}{\rangle}

#+latex_header: \DeclarePairedDelimiter\abs{\lvert}{\rvert}%
#+latex_header: \DeclarePairedDelimiter\norm{\lVert}{\rVert}%
#+latex_header: \DeclarePairedDelimiter\brck{\llbracket}{\rrbracket}%

*** Macros on HoTT                                                                                           :ignore:
#+latex_header: \newcommand\ap{\mathsf{ap}}
#+latex_header: \newcommand\apd{\mathsf{apd}}
#+latex_header: \newcommand\refl{\mathsf{refl}}
#+latex_header: \newcommand\id{\mathsf{id}}
#+latex_header: \newcommand\transport{\mathsf{transport}}
#+latex_header: \newcommand\happly{\mathsf{happly}}
#+latex_header: \newcommand\funext{\mathsf{funext}}
#+latex_header: \newcommand\proj{\mathsf{pr}}
#+latex_header: \newcommand\rec{\mathsf{rec}}
#+latex_header: \newcommand\pr{\mathsf{pr}}
#+latex_header: \newcommand\idtoeqv{\mathsf{idtoeqv}}
#+latex_header: \newcommand\ua{\mathsf{ua}}
#+latex_header: \newcommand\isSet{\mathsf{isSet}}
#+latex_header: \newcommand\isProp{\mathsf{isProp}}
#+latex_header: \newcommand\Set{\mathsf{Set}}
#+latex_header: \newcommand\Prop{\mathsf{Prop}}
#+latex_header: \newcommand\fnot{\mathsf{not}}
#+latex_header: \newcommand\LEM{\mathsf{LEM}}
#+latex_header: \newcommand\trunc[1]{\left\lVert#1\right\rVert}
#+latex_header: \newcommand\isContr{\mathsf{isContr}}
#+latex_header: \newcommand\ishae{\mathsf{ishae}}
#+latex_header: \newcommand\qinv{\mathsf{qinv}}
#+latex_header: \newcommand\fib{\mathsf{fib}}
#+latex_header: \newcommand\biinv{\mathsf{biinv}}
#+latex_header: \newcommand\linv{\mathsf{linv}}
#+latex_header: \newcommand\rinv{\mathsf{rinv}}
#+latex_header: \renewcommand\succ{\mathsf{succ}}
#+latex_header: \newcommand\isequiv{\mathsf{isequiv}}
#+latex_header: \newcommand\isHinit{\mathsf{isHinit}}
#+latex_header: \newcommand\isEmbedding{\mathsf{isEmbedding}}
#+latex_header: \newcommand\isSurjective{\mathsf{isSurjective}}
#+latex_header: \newcommand\pair{\mathsf{pair}}
#+latex_header: \newcommand\inl{\mathsf{inl}}
#+latex_header: \newcommand\inr{\mathsf{inr}}
#+latex_header: \newcommand\seg{\mathsf{seg}}
#+latex_header: \newcommand\base{\mathsf{base}}
#+latex_header: \newcommand\N{\mathsf{N}}
#+latex_header: \newcommand\conn{\mathsf{conn}}
#+latex_header: \newcommand\code{\mathsf{code}}
#+latex_header: \newcommand\encode{\mathsf{encode}}
#+latex_header: \newcommand\decode{\mathsf{decode}}
#+latex_header: \renewcommand\S{\mathsf{S}}
#+latex_header: \newcommand\merid{\mathsf{merid}}
#+latex_header: \newcommand\isCut{\mathsf{isCut}}
#+latex_header: \newcommand\apart{\mathbin{\#}}
#+latex_header: \newcommand\istype[1]{\mathop{\mbox{$\mathsf{is}$-$#1$-$\mathsf{type}$}}}
*** Logic macros                                                                                             :ignore:
#+latex_header: \newcommand\land{\wedge}
#+latex_header: \newcommand\lor{\vee}
#+latex_header: \newcommand\model{\mathfrak{M}}
#+latex_header: \newcommand\entail{\models}
#+latex_header: \newcommand\seq{\Rightarrow}
*** Analysis                                                                                                 :ignore:
#+latex_header: \newcommand\oy{\overline{y}}
#+latex_header: \newcommand\tf{\tilde{f}}
#+latex_header: %\newcommand\bV{\overset{\bullet}{V}}
#+latex_header: \newcommand\bV{\dot{V}}
*** Type theory macros                                                                                       :ignore:
#+latex_header: \newcommand\ap{\mathsf{ap}}
#+latex_header: \newcommand\apd{\mathsf{apd}}
#+latex_header: \newcommand\refl{\mathsf{refl}}
#+latex_header: \newcommand\id{\mathsf{id}}
#+latex_header: \newcommand\transport{\mathsf{transport}}
#+latex_header: \newcommand\happly{\mathsf{happly}}
#+latex_header: \newcommand\funext{\mathsf{funext}}
#+latex_header: \newcommand\proj{\mathsf{pr}}
#+latex_header: \newcommand\rec{\mathsf{rec}}
#+latex_header: \newcommand\pr{\mathsf{pr}}
#+latex_header: \newcommand\idtoeqv{\mathsf{idtoeqv}}
#+latex_header: \newcommand\ua{\mathsf{ua}}
#+latex_header: \newcommand\isSet{\mathsf{isSet}}
#+latex_header: \newcommand\isProp{\mathsf{isProp}}
#+latex_header: \newcommand\Set{\mathsf{Set}}
#+latex_header: \newcommand\Prop{\mathsf{Prop}}
#+latex_header: \newcommand\fnot{\mathsf{not}}
#+latex_header: \newcommand\LEM{\mathsf{LEM}}
#+latex_header: \newcommand\trunc[1]{\left\lVert#1\right\rVert}
#+latex_header: \newcommand\isContr{\mathsf{isContr}}
#+latex_header: \newcommand\ishae{\mathsf{ishae}}
#+latex_header: \newcommand\qinv{\mathsf{qinv}}
#+latex_header: \newcommand\fib{\mathsf{fib}}
#+latex_header: \newcommand\biinv{\mathsf{biinv}}
#+latex_header: \newcommand\linv{\mathsf{linv}}
#+latex_header: \newcommand\rinv{\mathsf{rinv}}
#+latex_header: \renewcommand\succ{\mathsf{succ}}
#+latex_header: \newcommand\isequiv{\mathsf{isequiv}}
#+latex_header: \newcommand\isHinit{\mathsf{isHinit}}
#+latex_header: \newcommand\isEmbedding{\mathsf{isEmbedding}}
#+latex_header: \newcommand\isSurjective{\mathsf{isSurjective}}
#+latex_header: \newcommand\pair{\mathsf{pair}}
#+latex_header: \newcommand\inl{\mathsf{inl}}
#+latex_header: \newcommand\inr{\mathsf{inr}}
#+latex_header: \newcommand\seg{\mathsf{seg}}
#+latex_header: \newcommand\base{\mathsf{base}}
#+latex_header: \newcommand\N{\mathsf{N}}
#+latex_header: \renewcommand\S{\mathsf{S}}
#+latex_header: \newcommand\merid{\mathsf{merid}}
#+latex_header: \newcommand\istype[1]{\mathop{\mbox{$\mathsf{is}$-$#1$-$\mathsf{type}$}}}
*** Category theory macros                                                                                   :ignore:
#+latex_header: \newcommand\hom{\mathrm{hom}}
#+latex_header: \newcommand\Sets{\mathsf{Sets}}
#+latex_header: \newcommand\Set{\mathsf{Set}}
#+latex_header: \newcommand\todot{\xrightarrow{.}}
* Topics
Resources on spaced repetition

 * [[http://www.gwern.net/Spaced-repetition][Gwern - spaced repetition]]
 * [[https://www.supermemo.com/en/articles/20rules][SuperMemo - twenty rules of formulating knowledge]]

A session should be 10-15 mins long.

** Category theory                                                                                        :categories:
*** Basic category theory
**** Universality and Yoneda
***** Universal arrow                                                                                       :drill:
SCHEDULED: <2019-10-27 Sun>
:PROPERTIES:
:ID:       f5c0c0db-7fd6-486d-9eab-d0f87b6f8d54
:DRILL_LAST_INTERVAL: 487.2209
:DRILL_REPEATS_SINCE_FAIL: 6
:DRILL_TOTAL_REPEATS: 9
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 4.444
:DRILL_EASE: 3.2
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-27 Wed 13:15]
:END:
Definition of *universal arrow* from $c$ to $S$.

****** Definition
For any other $f : c \to Sd$ there exists this unique diagram

\[\begin{tikzcd}
 & Sd & d \\
c \rar[swap]{u}\urar{f} & Sr \uar[swap, dashed]{S \widetilde f}
& r \uar[dashed,swap]{\exists! \widetilde{f}}
\end{tikzcd}\]

***** Yoneda Lemma                                                                                          :drill:
SCHEDULED: <2019-01-08 Tue>
:PROPERTIES:
:ID:       dbee06db-00f9-4f92-9e8f-ab855a4a5fc6
:DRILL_LAST_INTERVAL: 199.6489
:DRILL_REPEATS_SINCE_FAIL: 6
:DRILL_TOTAL_REPEATS: 5
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.2
:DRILL_EASE: 2.52
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-22 Fri 22:15]
:END:
Statement of the first Yoneda Lemma.

****** Statement
For any covariant $K\colon D \to \mathsf{Set}$ and $r \in D$, there is a bijection

\[
y \colon \mathrm{Nat}(\mathrm{hom}_{D}(r,-), K) \cong Kr
\]

sending any natural transformation $\alpha \colon \mathrm{hom}_{D}(r,-) \xrightarrow{.} K$
to its image on the identity, $\alpha_r(\mathsf{id}_r)$.

***** Yoneda functor                                                                                        :drill:
SCHEDULED: <2018-12-31 Mon>
:PROPERTIES:
:ID:       0d249757-6f4e-4635-a141-605ae14c0aaf
:DRILL_LAST_INTERVAL: 192.1774
:DRILL_REPEATS_SINCE_FAIL: 6
:DRILL_TOTAL_REPEATS: 5
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.2
:DRILL_EASE: 2.56
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-22 Fri 22:05]
:END:
Definition of the *Yoneda functor*.

****** Definition
The *Yoneda functor*, $Y \colon D^{op} \to\Sets^{D}$, is a currying of the
hom-functor $X \mapsto \mathrm{hom}(X,-)$.

\[
\left(f \colon s \to r\right) \mapsto 
\Big(- \circ f \colon \hom_D(r,-) \to \hom_D(s,-)\Big).
\]

It can be also written as $Y' \colon D \to\Sets^{D^{op}}$.

**** Adjoints, monads and algebras
***** Unit of an adjunction                                                                                 :drill:
SCHEDULED: <2019-03-29 Fri>
:PROPERTIES:
:ID:       9048327b-599e-4d3d-8674-3384c97f18fb
:DRILL_LAST_INTERVAL: 279.9851
:DRILL_REPEATS_SINCE_FAIL: 6
:DRILL_TOTAL_REPEATS: 5
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.6
:DRILL_EASE: 2.76
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-22 Fri 22:09]
:END:
Given an adjunction $F \vdash G$, what signature does the *unit* have?

****** Answer
The unit is a natural transformation $\eta \colon \mathsf{Id} \to GF$.
***** Counit of an adjunction                                                                               :drill:
SCHEDULED: <2019-05-23 Thu>
:PROPERTIES:
:ID:       3d507be4-76aa-4852-9a79-842202789c3d
:DRILL_LAST_INTERVAL: 335.3332
:DRILL_REPEATS_SINCE_FAIL: 6
:DRILL_TOTAL_REPEATS: 5
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.6
:DRILL_EASE: 2.76
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-22 Fri 22:09]
:END:
Given an adjunction $F \vdash G$, what signature does the *counit* have?

****** Answer
The counit is $\epsilon : FG \to \mathrm{id}$.
***** Monad of an adjunction                                                                                :drill:
SCHEDULED: <2018-10-17 Wed>
:PROPERTIES:
:ID:       be30eb00-9dbd-4d91-8d58-a5e3c9cf9bff
:DRILL_LAST_INTERVAL: 157.7961
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 10
:DRILL_FAILURE_COUNT: 2
:DRILL_AVERAGE_QUALITY: 4.2
:DRILL_EASE: 3.2
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-05-12 Sat 17:47]
:END:
Given an adjunction $F \vdash G$, what monad does it give rise to?

****** Answer
The monad $T := G \circ F$.
**** Limits
***** Set is small-complete                                                                                 :drill:
SCHEDULED: <2019-03-06 Wed>
:PROPERTIES:
:ID:       b60b88db-63fd-40a4-aaa5-d591be15e290
:DRILL_LAST_INTERVAL: 251.5049
:DRILL_REPEATS_SINCE_FAIL: 6
:DRILL_TOTAL_REPEATS: 5
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.8
:DRILL_EASE: 2.9
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-27 Wed 13:09]
:END:
A category is *small-complete* when all small diagrams have limits in it.
Why is Set small-complete? How can we construct small limits in it?

****** Constructing small limits on set
Given $F \colon J \to \mathsf{Set}$, we have that the set of cones from the terminal
object $\mathrm{Cone}(\ast,F)$ is the limit.

****** As an adjunction
Crucially,

\[
\mathrm{Cone}(X,F) \cong \hom(X, \mathrm{Cone}(\ast,F)).
\]

****** TODO Isn't this simpler using the cartesian product?
***** Creation of limits                                                                                    :drill:
SCHEDULED: <2018-07-06 Fri>
:PROPERTIES:
:ID:       a2541164-f873-495c-8cdd-a7ea1f8a389d
:DRILL_LAST_INTERVAL: 9.3475
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 7
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.572
:DRILL_EASE: 2.32
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-27 Wed 13:14]
:END:
When does a functor $V \colon A \to X$ *create limits* for $F \colon J \to A$?

****** Answer
For any limiting cone $\tau\colon x \xrightarrow{.} VF$ exists $\sigma\colon a\todot F$ with $Va = x$ and $V\sigma = \tau$.
and this $\sigma$ is a limiting cone.

***** Limits from products and equalizers                                                                   :drill:
SCHEDULED: <2018-07-01 Sun>
:PROPERTIES:
:ID:       c4ec22a4-89bb-47a8-839c-25faa68f3766
:DRILL_LAST_INTERVAL: 3.6869
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 6
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.833
:DRILL_EASE: 2.56
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-27 Wed 13:08]
:END:
Conditions on products and equalizers to 

 1) have all finite limits
 2) have all small limits.

****** Answer
Having all equalizers and

 1) all finite products;
 2) all small products.

**** Monoidal and enriched categories
***** Preadditive category                                                                                  :drill:
SCHEDULED: <2018-07-02 Mon>
:PROPERTIES:
:ID:       01815e4d-7bf6-473c-a818-f5a4f3568967
:DRILL_LAST_INTERVAL: 4.5907
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 11
:DRILL_FAILURE_COUNT: 3
:DRILL_AVERAGE_QUALITY: 3.818
:DRILL_EASE: 3.0
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-27 Wed 13:07]
:END:
Definition of [[https://en.wikipedia.org/wiki/Preadditive_category][preadditive category]]

****** Definition
Every $hom(a,b)$ is an *abelian group* and composition is *bilinear*

\[
f \circ (g+h) = f \circ g+f \circ h \qquad (f+g)\circ h = f\circ h+g \circ h
\]

***** Monoidal category: isomorphisms                                                                       :drill:
SCHEDULED: <2018-09-26 Wed>
:PROPERTIES:
:ID:       b388bb90-8069-4b36-b655-acdea2c12f12
:DRILL_LAST_INTERVAL: 136.9062
:DRILL_REPEATS_SINCE_FAIL: 6
:DRILL_TOTAL_REPEATS: 5
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.8
:DRILL_EASE: 2.32
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-05-12 Sat 17:44]
:END:
Isomorphisms defining a monoidal category.

****** Answer
A *monoidal category* ${\cal B}$ is a category with a bifunctor $\otimes \colon {\cal B} \times {\cal B} \to {\cal B}$
and three natural isomorphisms

 * $\alpha \colon a \otimes (b \otimes c) \cong (a \otimes b) \otimes c$

 * $\lambda \colon e \otimes a \cong a$

 * $\rho \colon a \otimes e \cong a$

***** Monoidal category: associativity diagram                                                              :drill:
SCHEDULED: <2018-07-22 Sun>
:PROPERTIES:
:ID:       72cb82e6-5bcf-4229-ae84-54bc0cb43c26
:DRILL_LAST_INTERVAL: 70.5114
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 5
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.6
:DRILL_EASE: 2.46
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-05-12 Sat 17:40]
:END:
Diagram of a monoidal category for

 * $\alpha \colon a \otimes (b \otimes c) \cong (a \otimes b) \otimes c$

****** Diagram
\begin{tikzcd}
a \otimes (b \otimes (c \otimes d)) \dar{1 \otimes \alpha} \rar{\alpha}& 
(a \otimes b) \otimes (c \otimes d) \rar{\alpha}& 
((a \otimes b) \otimes c) \otimes d \dar{\alpha \otimes 1}\\
a \otimes ((b \otimes c) \otimes d) \ar[rr, "\alpha"] & & 
(a \otimes (b \otimes c)) \otimes d
\end{tikzcd}

***** Monoidal category: units diagram                                                                      :drill:
SCHEDULED: <2018-08-25 Sat>
:PROPERTIES:
:ID:       8c876951-43d8-4c15-b5bb-b5d659d70e1f
:DRILL_LAST_INTERVAL: 63.8954
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.25
:DRILL_EASE: 2.56
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-22 Fri 22:20]
:END:
Diagrams of a monoidal category for

 * $\lambda \colon e \otimes a \cong a$

 * $\rho \colon a \otimes e \cong a$

****** Diagram
\[\begin{tikzcd}[row sep=tiny]
& a \otimes (e \otimes c) \ar[dd, "\alpha"]\dlar[swap]{1 \otimes \lambda}\\ 
a \otimes c &\\
& (a \otimes e) \otimes c \ular{\rho \otimes 1}
\end{tikzcd}\]

**** Categorical logic
***** Cartesian closed category                                                                             :drill:
SCHEDULED: <2018-12-01 Sat>
:PROPERTIES:
:ID:       1c544faf-0c54-4fc1-b2f2-839d6fdd8354
:DRILL_LAST_INTERVAL: 203.0545
:DRILL_REPEATS_SINCE_FAIL: 6
:DRILL_TOTAL_REPEATS: 5
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.4
:DRILL_EASE: 2.7
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-05-12 Sat 17:46]
:END:
Define a *cartesian closed category* using three adjoints.

****** Definition
Any category ${\cal C}$ is cartesian closed if and only if there exist
*right adjoints* for the following functors

\begin{prooftree}
\AX$\ast\ \fCenter\to\ast$
\doubleLine
\UI$x\ \fCenter\to \top$
\AX$(x,x)\ \fCenter\to (y,z)$
\doubleLine
\UI$x\ \fCenter\to y \times z$
\AX$x \times a\ \fCenter\to y$
\doubleLine
\UI$x\ \fCenter\to y^a$
\noLine
\TIC{}
\end{prooftree}

***** Elementary topos                                                                                      :drill:
SCHEDULED: <2019-01-30 Wed>
:PROPERTIES:
:ID:       5e288a7b-486a-4d12-91b2-45834c6a0b47
:DRILL_LAST_INTERVAL: 221.7358
:DRILL_REPEATS_SINCE_FAIL: 6
:DRILL_TOTAL_REPEATS: 5
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.4
:DRILL_EASE: 2.66
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-22 Fri 22:11]
:END:
Define *elementary topos* with three properties.

****** Definition

 1. is *cartesian closed*,
 2. has all *finite limits* (pullbacks and terminal),
 3. has a *subobject classifier*.

Note that /locally cartesian closed/ is implied from these properties

***** Pullback functor in objects                                                                           :drill:
SCHEDULED: <2019-03-10 Sun>
:PROPERTIES:
:ID:       fed94983-29d8-4580-97ba-0e0d06a7da46
:DRILL_LAST_INTERVAL: 260.7727
:DRILL_REPEATS_SINCE_FAIL: 6
:DRILL_TOTAL_REPEATS: 5
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.8
:DRILL_EASE: 2.9
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-22 Fri 22:19]
:END:
Given $f : B \to A$, define the pullback functor $f^{\ast} : {\cal C}/A \to {\cal C}/B$
in objects.

****** Definition in objects
Given any $c : C \to A$, the pullback functor gives $f^{\ast}c : f^{\ast}C \to B$
with the following pullback square

\[\begin{tikzcd}
f^{\ast}C \rar{}\drar[phantom, near start, "\ulcorner"] \dar[swap]{f^{\ast}c} & C \dar{c} \\
B\rar{f} & A
\end{tikzcd}\]

***** Pullback functor in morphisms                                                                         :drill:
SCHEDULED: <2019-04-17 Wed>
:PROPERTIES:
:ID:       5bb637fe-4ec1-4cc1-9e8d-b973b81ebaff
:DRILL_LAST_INTERVAL: 299.3226
:DRILL_REPEATS_SINCE_FAIL: 6
:DRILL_TOTAL_REPEATS: 5
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.8
:DRILL_EASE: 2.9
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-22 Fri 22:17]
:END:
Given $f : B \to A$, define the pullback functor $f^{\ast} : {\cal C}/A \to {\cal C}/B$
on the morphism $h : C \to D$ defined between $c : C \to A$ and $d : D \to A$.

****** Definition in morphisms
The morphism $f^{\ast}h : f^{\ast}C \to f^{\ast}D$ is defined by the universal property
of pullbacks

\[\begin{tikzcd}
f^{\ast}C \ar{rrr}\ar[dashed]{dr}{\exists! f^{\ast}h} \ar[bend right,swap]{ddr}{f^{\ast}c} &&&
C \ar{dl}{h}\ar[bend left=60]{ddl}{c} \\
& f^{\ast}D \dar[swap]{f^{\ast}d} \rar & D \dar{d} \\
& Bñ \rar[swap]{f} & A \\
\end{tikzcd}\]
*** Categories for the working mathematician - MacLane
# Exports using config.setup, essay.setup

**** I. Categories, Functors and Natural Transformations
***** I.1. Axioms for categories
****** Metagraph
A *metagraph* consists of objects $a,b,c,\dots$ and arrows $f,g,h,\dots$, with two 
operations:

  - *domain*, $dom(f) = a$, and
  - *codomain*, $cod(f) = b$,

that we write as $f : a \to b$.

****** Metacategory
A *metacategory* is a metagraph with two additional operations:

  - *Identity*: $id_a : a \to a$
  - *Composition*: for a pair of arrows $dom(g) = cod(f)$, it defines a
    new arrow $g \circ f : dom(f) \to cod(g)$.

    \[\begin{tikzcd}
    & b \drar{g} & \\
    a \arrow{rr}{g\circ f} \urar{f} & & c
    \end{tikzcd}\]

Subject to the following axioms:

  - *Associativity*: Given objects and arrows in this configuration:
    
    $a \overset{f}\to b \overset{g}\to c \overset{k}\to d$

    We have the equality: $k \circ (g \circ f) = (k \circ g) \circ f$.

  - *Unit law*: composition with the identity arrow is neutral.

******* Metacategory of Sets
******* Metacategory of Groups
******* Arrow-only axioms
***** I.2. Categories
****** Category
An interpretation of a metacategory within set theory.

******* Diagram scheme (directed graphs)
A category is a graph with identity and composition functions.

****** Examples of categories
******* Basic examples
******** The empty category
******** 1, the category with one object and one identity
******** 2, the category a -> b with two objects
******** 3, a triangle category
******** Parallel arrows

******* Discrete categories
Where every arrow is an identity.

******* Monoids and groups
A category with one object.

******* Matrices
Objects: positive integers.
Arrows: $m\times n$ matrices.

******* Sets of sets
******* Preorder
******** Partial orders
******** Linear orders
******* Ordinal numbers
******* Simplicial category
******* Large categories
***** I.3. Functors
****** Functor
A morphism of categories. A functor $T : {\cal C} \to {\cal B}$ is given by:

  - The *object function*, $T : Obj({\cal C}) \to Obj({\cal B})$.
  - The *arrow function*, $T : (c \to c') \to (Tc \to Tc')$

With the axioms:

  - $T(1_c) = 1_{Tc}$
  - $T(f\circ g) = Tg \circ Tf$

****** Examples
******* The powerset functor
******* Homology groups
******* General linear group
******* Commutators
******* Forgetful functors
****** Composition of functors, the metacategory Cat
We can define composition of functors, and also functors as isomorphisms.

******* Isomorphisms
A functor is an isomorphism iff there is a functor $S : B \to C$ for 
which both composites are the identity $S \circ T = Id = T \circ S$.

******* Full functor
Every $g : c \to c'$ of $B$ is of the form $Tf : Tc \to Tc'$. In other words,
the arrow function (the map!) is injective.

******* Faithful functor
The equality $Tf_1 = Tf_2$ implies $f_1 = f_2$. In other words, the arrow
function is surjective.

******* Subcategories
A subcategory gives us an inclusion functor.

***** I.4. Natural transformations
****** Natural transformation
Given two functors $S,T : C \to B$, a natural transformation $\tau : S \xrightarrow{.} T$
is a function assigning every $c \in C$ an arrow $Sc \to Tc$ and yielding
a commutative diagram:

\[\begin{tikzcd}
c \dar{f} & & Sc \rar{\tau_c}\dar{Sf} & Tc \dar{Tf} \\
c' & & Sc' \rar{\tau_{c'}} & Tc'
\end{tikzcd}\]

We say that $\tau_c$ is natural in $c$.

******* Translation of pictures
A natural transformation translates a diagram from $S$ to $T$.

\[\begin{tikzcd}
a \arrow{dd}{h}\drar{f} &   & & S a \arrow{dd}{S h}\drar{S f} \arrow{rrr}{\tau a} &     & & T a \arrow{dd}{T h}\drar{T f} &     \\
  & b \dlar{g} & &     & S b \dlar{S g} \arrow{rrr}{\tau b} & &     & T b \dlar{T g} \\
c &   & & S c \arrow{rrr}{\tau c} &     & & T c &     \\
\end{tikzcd}\]

****** Natural isomorphisms
A natural transformation is a morphism of functors. We call 
*natural isomorphism* to a natural transformation where every 
component $\tau_c$ is invertible. We write it as:

$\tau : S \cong T$

The inverses form another natural transformation.

****** Examples
******* Determinant
Natural transformation between two functors
$GL, {\cal U}() : \mathtt{CRng} \longrightarrow \mathtt{Grp}$.

******* Identity and factor-commutator functor

******* Double character group
Defined as $D(G) = Hom(G, \mathbb{R}/\mathbb{Z})$, it is a contravariant functor when 
we define $(Df) t = t \circ f$. But the twice iterated functor $D^2$ is a 
covariant one.

There is a natural transformation between $Id$ and $D^2$.

\[
\tau_G(g) t = t(g)
\]

It is easy (with lambda calculus, for example) to check that this
diagram commutes.

******* Double dual of a finite vectorial space

******* Inclusion and cardinality of ordinals

***** I.5. Monics, epis and zeros
****** Isomorphism
An arrow $e : a \to b$ is an isomorphism if there is an arrow $e^{-1} : b \to a$
such that $e'e = 1$ and $ee' = 1$.

******* Isomorphic objects
Two objects are isomorphic if there is an isomorphism between them.

****** Monic and epi
An arrow is *monic* if it is left cancellable, it is *epi* if it is
right cancellable.

******* Retractions and sections
A left inverse is called a *retraction*, while a right inverse is
called a *section*.

****** Splits and idempotents
When $gh = 1$, $g$ is a split epi, $h$ is a split monic and the composite
$hg$ is an idempotent. An arrow is *idempotent* if $f^2 = f$, and it is said
to split when there exist arrows $g$ and $h$ such that $f = hg$ and $gh = 1$.

****** Terminal objects and initial objects
An object $t$ is terminal if for every $a$ there is exactly one arrow $a \to t$.
An object $s$ is initial if for every $a$ there is exactly one arrow $s \to a$.
An object $z$ is null if it is both initial and terminal.

******* Zero arrow
There is an unique arrow $a \to z \to b$ called the *zero* arrow. Any 
composite with it is itself a zero arrow.

****** Groupoids
A category where every arrow is invertible.

******* The fundamental groupoid
******* Group of homomorphisms
In a groupoid, each object determines a group, $hom(x,x)$.
If there is an arrow $f : x \to x'$, the groups $hom(x,x)$ and $hom(x',x')$
are isomorphic under conjugation $g \mapsto fgf^{-1}$.

******* Connected groupoid
A *connected groupoid* is deteremined by a group and the set of
all objects.

***** I.6. Foundations
****** Universe
An universe is a set $U$ with the closure properties:

  1. $x \in u \in U \implies x \in U$.
  2. e$u,v \in U \implies \{u,v\},(u,v),u\times v \in U$.
  3. $x \in U \implies {\cal P}x, \cup x \in U$.
  4. $\omega \in U$ where $\omega = \{0,1,2,\dots\}$.
  5. $f : a \to b$ surjective and $a \in U$, $b \subseteq U$ implies $b \in U$.

****** Small sets
Fixed an universe, we call a set $u \in U$ a *small set*. The universe is
the set of all small sets. $\mathtt{Set}$ denotes the category of small sets.

******* Small structures
A small group is a small set with a group structure. $\mathtt{Grp}$ denotes the
category of small groups.

****** Small categories
A category is small if the set of its arrows and objects are both small
sets. $\mathtt{Set}$ is not a small category.

***** I.7. Large categories
****** Abelian groups
****** Rings
****** Modules over a ring
****** Bimodules
****** Topological spaces with continuous maps
****** Topological spaces with homotopy classes
****** Pointed sets
****** Binary relations
****** Concrete categories
***** I.8. Hom-Sets
****** Hom-set
For objects $a,b \in C$, the *hom-set* is the set of all arrows between them:

\[
hom(a,b) = \{ f \mid f : a \to b \}
\]

******* Redefinition of a category
A small category is given by:

  1. Set of objects $a,b,\dots$
  2. Hom-set between two objects $hom(a,b)$
  3. Composition function $hom(b,c)\times hom(a,b) \to hom(a,c)$
  4. Identity function for every object, $id \in hom(a,a)$

The distributivity can be seen as commutativity of the following
diagram:

\[\begin{tikzcd}
hom(c,d)\times hom(b,c)\times hom(a,b) \rar\dar &
hom(b,d)\times hom(a,b) \dar \\
hom(c,d)\times hom(a,c) \rar &
hom(a,d)
\end{tikzcd}\]

****** Preadditive category
A category $A$ where each hom-set $hom(a,b)$ is an additive abelian group
for which composition is bilinear:

\[
(g+g')\circ(f+f') = g\circ f + g\circ f' + g' \circ f + g' \circ f'
\]

****** Preadditive category as an enriched category
A preadditive category is given by:

  1. Set of objects $a,b,\dots$
  2. Hom-set, an abelian group between two objects $hom(a,b)$
  3. A bilinear composition $hom(b,c) \otimes hom(a,b) \to hom(a,c)$
  4. Identity morphism for every object, $\mathbb{Z} \to hom(a,a)$

We can see the similitude with the definition of a category by hom-sets.
Categories created in this way are called *enriched categories*.

**** II. Constructions on categories
***** II.1. Duality
****** Elementary theory of an abstract category (ETAC)
A theory with statements involving:

  - Domains: $a = dom(f)$
  - Codomains: $b = codom(f)$
  - Composition: $h = g \circ f$

A *sentence* is a statement with all variables quantified, using
the logical connectives and quantifiers.

******* Dual of an statement
A dual is formed by making the following replacements:

  - $a = dom(f)$ changes to $a = codom(f)$
  - $h = g \circ f$ changes to $h = f \circ g$
  - Logic is unchanged.

******* Table of dualities
\begin{tabular}{l|r}
Statement & Dual statement \\
\hline
$f : a \to b$ & $f : b \to a$ \\
$a = \operatorname{dom} f$ & $a = \operatorname{cod} f$ \\
$h = g \circ f$ & $h = f \circ g$ \\
$f$ mono & $f$ epi
\end{tabular}

****** Duality principle
The dual of each of the axioms for a category is also an axiom. Therefore,
if $\Sigma$ is a consequence of the axioms, so is its dual statement.

****** Duality and functors
The elementary theory of one functor has the axioms of two categories
$A,B$, and the properties of a functor $T$ between them. The duality for
a statement involving several categories reverses the arrows in each
category, but does not reverse the functors.

***** II.2. Contravariance and opposites
****** Opposite category
The *opposite category*, $C^{op}$, is defined with the objects of $C$; for each 
arrow $f : a \to b$ of $C$, the corresponding $f^{op} : b \to a$ is defined with the 
composition

\[
f^{op} \circ g^{op} = (g\circ f)^{op}.
\]

******* Opposite functors
If $T : C \to B$ is a functor, we can create an opposite functor
$T^{op} : C^{op} \to B^{op}$. The assignment $C \to C^{op}$ defines a covariant functor
$\mathtt{Cat} \to \mathtt{Cat}$.

****** Contravariant functors
A functor $S : C^{op} \to B$ can be seen as a *contravariant* functor $S : C \to B$,
knowing that

\[
S(f^{op}\circ g^{op}) = (Sf^{op})(Sg^{op}) = S((g\circ f)^{op}).
\]

******* Examples: Hom-sets
For each object $a \in C$, the *contravariant hom-functor* $hom(a,-)$ and
the *covariant hom-functor* $hom(-,a)$ are defined.

******* Examples: Sheafs
Given $X$, a topological space. Its open sets define a category by 
inclusion, $\mathtt{Open}(X)$. Let ${\cal C}(U)$ denote the set of continuous functions
$h : U \to \mathbb{R}$, the assignment $h \mapsto h|_V$ is a function ${\cal C}(U)\to{\cal C}(V)$ for
each $V \subset U$; and this gives us a contravariant functor.

******* Examples: R-Modules
$\mathtt{ModR} : \mathtt{Rng} \to \mathtt{Cat}$ is a contravariant functor. If $\rho : R \longrightarrow S$ is a morphism
of rings, given $B$ an S-module, we can define $(Mod\rho) B = B\rho$ by pull-back.

***** II.3. Products of categories
****** Product of two categories
We define the *product* $B \times C$ as the category with:

  - pairs of objects $(b,c)$ as objects,
  - pairs of arrows $(f,g)$ as arrows,

with the composition given by the composites in $B$ and $C$

\[
(f',g') \circ (f,g) = (f' \circ f,g' \circ g).
\]

We can define projection functors $P : B\times C \to B$, $Q : B\times C \to C$. Given
any category $D$ and two functors $B \overset{R}\longleftarrow D \overset{T}\longrightarrow C$, there is an unique 
functor $F : D \to B\times C$ with $PF = R, QF = T$.

\[\begin{tikzcd}
& D \drar{T}\dlar[swap]{R} \dar[dashed]{\exists! F} & \\
B & B\times C \rar[swap]{Q}\lar{P} & C
\end{tikzcd}\]

****** Product of functors
Two functors $U : B \to B'$, $V : C\to C'$ have a product:

\[
U\times V : B\times C \to B'\times C'
\]

That can be described as the unique functor making the following
diagram commutative:

\[\begin{tikzcd}
B \dar{U} &
B \times C  \rar{Q}\lar[swap]{P} \dar[dashed]{U \times V}&
C \dar{V} \\
B' &
B' \times C' \rar[swap]{Q'}\lar{P'}&
C'
\end{tikzcd}\]

******* Product as a functor
The product of categories can be seen as a functor:

\[
\times : \mathtt{Cat} \times \mathtt{Cat} \to \mathtt{Cat}
\]

******* Bifunctors
Our definition of product category gives an automatic definition for
a *bifunctor*, a functor of two variables.

****** Bifunctor determined by its currifications
Let $B,C,D$ be categories. For all objects $c \in C, b \in B$, let $L_c : B \to D$
and $M_b : C \to D$ be functors such that $M_b(c) = L_c(b)$.

There exists a bifuctor $S : B\times C \to D$ such that $S(-,c) = L_c$
and $S(b,-) = M_b$ iff for every pair of arrows:

\[
M_{b'}g \circ L_c f = L_{c'}f \circ M_b g
\]

so we can define the value of $S(f,g)$ uniquely.

******* TODO Proof

****** Natural transformations between bifunctors
Given bifunctors $S,S'$, the function $\alpha$ is a natural transformation
$\alpha : S \Rightarrow S'$ iff $\alpha(b,c)$ is natural in $b$ and natural in $c$.

******* TODO Proof

***** II.4. Functor categories
****** Composition of natural transformations
Given functors $R,S,T : C \to B$ and natural transformations $\tau : S\to T$
and $\sigma : R \to S$, their compositions define composite arrows which are
the components of the composite natural transformation $\tau \cdot \sigma$.

\[\begin{tikzcd}
Rc \rar{Rf}\dar{\sigma_c}\arrow[dd,bend right=90]{(\tau \circ \sigma)_c} &
Rc' \dar{\sigma_{c'}} \arrow[dd,bend left=90]{(\tau\circ\sigma)_{c'}} \\
Sc \rar{Sf}\dar{\tau_c}  &
Sc' \dar{\tau_{c'}} \\
Tc \rar{Tf}  &  Tc' 
\end{tikzcd}\]

******* Proof
Naturality of the external square follows from the commutativity of the
two internal squares.

****** Functor category
Given categories $B,C$, let $B^C = \mathrm{Funct}(C,B)$ be the *functor category*,
with objects the functors $T\colon C \to B$ and morphisms the natural 
transformations

\[ \mathrm{Nat}(S,T) = \left\{ \tau\mid \tau\colon S \dot\to T \right\}.
\]

******* Example: Category of arrows
The category $\mathrm{Funct}(B,2)$ is called the *category of arrows* of $B$. Its
objects are arrows $f\colon a \to b$ and its morphisms are commutative squares

\[\begin{tikzcd}
a\rar{h} \dar[swap]{f} & a' \dar{f'} \\
b\rar{k} & b'
\end{tikzcd}\]

******* Example: Actions on a set
If $M$ is a monoid, $\mathrm{Funct}(M, \mathtt{Set})$ is the category with objects the actions
of $M$ on some sets and arrows the morphisms of such actions.

******* TODO Example: Group with operators
****** Example: Group representations
Given $K$ a commutative ring, the functor category $\mathrm{Funct}(G, K\mathtt{-mod})$ is the 
category of linear representations of $G$.

******* Objects
Every functor $T \colon G \to K\mathtt{-mod}$ is determined by a $K\text{-module}$ $V$ and
a morphism of groups $T\colon G \to \text{Aut}(V)$.

******* Natural transformations
A natural transformation $\sigma\colon T \to S$ is given by a single module
homomorphism $\sigma\colon V \to V'$, such that

\[\begin{tikzcd}
V\rar{\sigma} \dar[swap]{Tg} & V' \dar{T'g} \\
V\rar{\sigma} & V'
\end{tikzcd}\]

and it is called an *intertwining* operator.

***** II.5. The category of all categories
****** Identity natural transformations
The identity functor is the identity for the horizontal and vertical
compositions. We can use the symbol of the functor to denote it like
$S \colon S \dot\to S$.

****** Horizontal composition of natural transformations
Given functors $S,T \colon C \to B$ and $S',T'\colon B \to A$ and natural transformations

\[\begin{tikzcd}
C 
\rar[shift left=7pt, ""{name=UL, below}]{S} 
\rar[shift right=7pt, ""name=LL][swap]{T\vphantom{'}} &
B 
\rar[shift left=7pt, ""{name=UR, below}]{S'}
\rar[shift right=7pt, ""name=LR][swap]{T'} &
A\\
\ar[from=UL, to=LL, "\tau", shorten <= -2pt, shorten >= -2pt]
\ar[from=UR, to=LR, "\tau\smash{'}", shorten <= -2pt, shorten >= -2pt]
\end{tikzcd}\]

we can define the *horizontal composite* $\tau' \circ \tau \colon S'S \to T'T$ as the diagonal
of the commutative square

\[\begin{tikzcd}
S'Sc\rar{\tau'_{Sc}} \dar[swap]{S'\tau_c} & T'Sc \dar{T' \tau_c} \\
S'Tc\rar{\tau'_{Tc}} & T'Tc
\end{tikzcd}\]

explicitly, as $\tau' \circ \tau = T' \tau \circ \tau' = \tau' \circ S'\tau$. It is a natural transformation.

******* Alternative notation
With identity notation, we can then define the horizontal composition
as

\[
\tau'\circ \tau = 
(T' \circ \tau) \cdot (\tau'\circ S) =
(\tau' \circ T) \cdot (S'\circ \tau).
\]

******* Proof
It is natural as the following diagram is the composition of two
naturality squares

\[\begin{tikzcd}
S'Sc \rar{S'\tau} \dar{S'Sf} &
S'Tc \rar{\tau'}  \dar{S'Tf} &
T'Tc \dar{T'Tf} \\
S'Sb \rar{S'\tau} &
S'Tb \rar{\tau'} &
T'Tb
\end{tikzcd}\]

defined respectively by the naturality of $S'\tau$ and $\tau'$.

****** Interchange law
Given three categories and four transformations

\[\begin{tikzcd}
C 
\rar[shift left=15pt, ""{name=UL, below}]{} 
\rar[""name=L]
\rar[shift right=15pt, ""name=LL][swap]{} &
B 
\rar[shift left=15pt, ""{name=UR, below}]{}
\rar[""name=R]
\rar[shift right=15pt, ""name=LR][swap]{} &
A\\
\ar[from=UL, to=L, "\sigma", shorten <= -2pt, shorten >= -2pt]
\ar[from=L, to=LL, "\tau", shorten <= 2pt, shorten >= -2pt]
\ar[from=UR, to=R, "\sigma\smash{'}", shorten <= -2pt, shorten >= -2pt]
\ar[from=R, to=LR, "\tau\smash{'}", shorten <= 2pt, shorten >= -2pt]
\end{tikzcd}\]

the vertical and horizontal composites follow the interchange law

\[
(\tau'\cdot \sigma') \circ (\tau \cdot \sigma) = 
(\tau'\circ \tau) \cdot (\sigma'\circ \sigma).
\]

******* Proof
In this diagram, where every internal square is commutative by
naturality

\[\begin{tikzcd}
G_1F_1x \dar{G_1\sigma} \rar{\sigma'} \drar{\sigma'\circ\sigma} 
\ar[bend left]{rr}{\tau'\cdot\sigma'}
\ar[bend right=60,swap]{dd}{G_1(\tau \cdot \sigma)} & 
G_2F_1x \dar{G_2\sigma} \rar{\tau'} &
G_3F_1x \dar{G_3\sigma} \ar[bend left=60]{dd}{G_3(\tau \cdot \sigma)}\\
G_1F_2x \dar{G_1\tau} \rar{\sigma'} &
G_2F_2x \dar{G_2\tau} \rar{\tau'}  \drar{\tau'\circ\tau} &
G_3F_2x \dar{G_3\tau} \\
G_1F_3x \rar{\sigma'} \ar[bend right,swap]{rr}{\tau'\cdot\sigma'} &
G_2F_3x \rar{\tau'} &
G_3F_3x \\
\end{tikzcd}\]

we know, by definition, that the big diagonal must be $(\tau'\cdot \sigma') \circ (\tau\cdot\sigma)$.

****** Double category
A *double category* is a set of arrows for two different compositions
which together satisfy the [[*Interchange law][interchange law]].

****** 2-category
A *2-category* is a double category in thich every identity for the
first composition is also an identity for the second one.

******* Counterexample: commutative squares in Set
The category of commutative squares in Set is a double category but
not a 2-category.

****** Interchange law for operations
Two binary operations $\cdot,\circ$ are said to satisfy the interchange law when

\[
(a' \cdot b') \circ (a \cdot b) = (a' \circ a) \cdot (b'\circ b).
\]

******* Example: matrices
The usual product of matrices $\circ$ satisfies the interchange law with the
square-composition of matrices

\[
\tau \cdot \sigma = \begin{pmatrix}
\tau & 0\\
0 & \sigma
\end{pmatrix}.
\]

******** Proof
Trivial by definition.

****** Functor category as a functor
The functor category can be regarded as a functor

\[\mathrm{Func} \colon \mathtt{Cat}^{op}\times \mathtt{Cat} \to \mathtt{Cat}.
\]

sending an arrow, consisting of two functors $F,G$, to $F^{G}$, a functor
defined as

  * $F^GS = F \circ S \circ G$, on objects.
  * $F^{G}\tau = F \circ \tau \circ G$, on arrows.

******* Analogue with the hom-functor
Note that this is the categorical analogue of the hom-functor

\[\mathrm{Hom} \colon \mathtt{Set}^{op}\times \mathtt{Set} \to \mathtt{Set}.
\]

***** II.6. Comma categories
****** Category of objects under an object
Given $b \in C$, the category of *objects under* it, $(b \downarrow C)$, is the category
with objects all pairs $(f\colon b \to c, c)$, and arrows $h\colon (f,c) \to (f',c')$ for those
arrows such that $h\circ f = f'$.

******* Displayed notation
Objects are of the form

\[\begin{tikzcd}
b \rar{f} & c
\end{tikzcd}\]

morphisms are of the form

\[\begin{tikzcd}
& c \arrow[dd, "h"] \\[-15pt]
b \urar{f}\drar[swap]{f'}& \\[-15pt]
& c'
\end{tikzcd}\]

and the composition is the composition of two commutative triangles
in that form.

****** Category of objects over an object
The category of *objects over* $a$, $(C \downarrow a)$ can be defined similarly in
displayed notation as objects of the form

\[\begin{tikzcd}
c \rar{f} & a
\end{tikzcd}\]

and morphisms

\[\begin{tikzcd}
c \arrow[dd, "h"] \drar{f} &  \\[-15pt]
& b \\[-15pt]
c' \urar[swap]{f'} &
\end{tikzcd}\]

****** Comma category
Given categories and functors $E \overset{T}\longrightarrow C \overset{S}\longleftarrow D$, the comma category
$(T\downarrow S)$ has objects

\[\begin{tikzcd}
Te \rar{f} & Sd
\end{tikzcd}\]

and arrows commutative squares

\[\begin{tikzcd}
Te\rar{Tk} \dar[swap]{f} & Te' \dar{f'} \\
Sd\rar{Sh} & Sd'
\end{tikzcd}\]

The composite is the yuxtaposition of squares.

******* Categories of objects under/over and object
Those are particular cases when the object is seen as a functor
from the unital category $b \colon 1 \to C$.

***** II.7. Graphs and free categories
****** TODO Forgetful functor from categories to graphs
****** Free category
Let $G$ be a small graph. There is a small category $C$ called its free
category satisfying the following universal property

\[\begin{tikzcd}
G \rar{P} \drar[swap]{D} & UC\dar[dashed]{\exists! UD'} \\
& UB
\end{tikzcd}\]

which is equivalent to $P\colon G \to UC$ being initial in $(G \downarrow U)$.

***** TODO II.8. Quotient categories
**** III. Universals and Limits
***** III.1. Universal arrows
****** Universal arrow
A *universal arrow* from $c$ to $S$ is an arrow $u \colon c \to Sr$ such that
for every $c \to Sd$ exists a unique $r \to d$ making this diagram commute

\[\begin{tikzcd}
& Sd & d \\
c \rar[swap]{u}\urar{g} & Sr \uar[swap,dashed]{Sf} & r \uar[dashed]{\exists! f} &.
\end{tikzcd}\]

***** III.2. The Yoneda lemma
****** Universal arrows as natural bijections
The arrow $u \colon c \to Sr$ is universal iff $f \mapsto Sf \circ u$ is a bijection
$\mathrm{hom}(r,d) \cong \mathrm{hom}(c,Sd)$ natural in $d$. Any natural bijection of this
kind is determined by a unique universal arrow.

******* Proof
Bijection follows from the definition of [[*Universal arrow][universal arrow]], and
naturality follows from $S(gf)\circ u = Sg \circ Sf \circ u$.

Given a bijection $\varphi$, we define $u = \varphi(\mathrm{id}_r)$. By naturality we have
the bijection $\varphi(f) = Sf \circ u$, every arrow is written in this way.

****** Representation
A *representation* of $K \colon D \to \mathtt{Set}$ is a natural isomorphism

\[
\psi\colon \mathrm{hom}_{D}(r,-) \cong K.
\]

A functor is /representable/ if it has a representation. An object $r$ is
called a /representing object/. $D$ must have small hom-sets.

****** Representations from universal arrows
If $u \colon \ast \to Kr$ is a universal arrow for a functor $K\colon D \to \mathtt{Set}$, then
$f \mapsto K(f)(u\ast)$ is a representation. Every representation is obtained
in this way.

******* Proof
We know that $\mathrm{hom}(\ast, X) \xrightarrow{.} X$ is a natural isomorphism in $X$; in particular
$\mathrm{hom}(\ast, K-) \xrightarrow{.} K-$. Every representation is built then as

\[ \mathrm{hom}_{D}(r,-) \cong \mathrm{hom}(\ast,K-) \cong K, \]

for every natural isomorphism $D(r,-) \cong \mathtt{Set}(\ast,K-)$. But every natural
isomorphism of this kind is an [[*Universal arrows as natural bijections][universal arrow]].

****** Yoneda Lemma
For any $K\colon D \to \mathtt{Set}$ and $r \in D$, there is a bijection

\[
y \colon \mathrm{Nat}(\mathrm{hom}_{D}(r,-), K) \cong Kr
\]

sending the natural transformation $\alpha \colon \mathrm{hom}_{D}(r,-) \xrightarrow{.} K$ to the image of
the identity, $\alpha_r1_r$.

******* TODO Proof

****** Corollary to Yoneda Lemma
Given $r,s \in D$, any natural transformation $\mathrm{hom}(r,-) \xrightarrow{.} \mathrm{hom}(s,-)$ has
the form $h_{\ast}$ for a unique $h\colon s \to r$.

******* Proof
Using Yoneda Lemma, we know that

\[ \mathrm{Nat}(\mathrm{hom}_D(r,-), \mathrm{hom}_D(s,-)) \cong \mathrm{hom}_D(s,r),
\]

sending the natural transformation to a morphism $\alpha(id_r) = h \colon s \to r$. The
rest of the natural transformation is determined as $h_{\ast}$ by naturality.

****** Addendum to the Yoneda Lemma
The bijection on the [[*Yoneda Lemma][Yoneda Lemma]] is a natural isomorphism between
two $\mathtt{Set}^D \times D \to \mathtt{Set}$ functors.

****** Yoneda functor
In the conditions of [[*Yoneda Lemma][Yoneda Lemma]], the *Yoneda functor* is a full and
faithful functor $Y \colon D^{op} \to \mathtt{Set}^{D}$ defined with the arrow function

\[
\left(f \colon s \to r\right) \mapsto 
\Big(D(f,-) \colon D(r,-) \to D(s,-)\Big).
\]

******* TODO Proof
***** III.3. Coproducts and colimits
****** Diagonal functor
The *diagonal functor* $\Delta \colon C \to C \times C$ is defined by $\Delta(c) = (c,c)$ on objects
and by $\Delta(f) = (f,f)$ on arrows.

****** Coproduct diagram
A *coproduct diagram* of a pair $(a,b)$ is a universal arrow from $(a,b)$ to
the diagonal functor $\Delta$. The object defining this universal arrow up to
isomorphism is called the *coproduct object* and written as $a \amalg b$.

\[\begin{tikzcd}
 & (d,d) \\
(a,b) \rar[swap]{(i_a,i_b)} \urar{(f,g)} & 
(a\amalg b, a\amalg b) \uar[swap]{(f \amalg g, f \amalg g)} & .
\end{tikzcd}\]

******* Diagram rewriting
This universal property can be rewritten as

\[\begin{tikzcd}
a \rar{i}\drar[swap]{f} & a \amalg b \dar[dashed]{\exists! h} & b \lar{j}\dlar{g} \\
& d &  & .
\end{tikzcd}\]

******* Bijection rewriting
This universal arrow is a bijection $\mathrm{hom}(a,d) \times \mathrm{hom}(b,d) \cong \mathrm{hom}(a \amalg b,d)$
natural in $d$.

****** Coproduct functor
In a category $C$ where every pair has a coproduct, the coproduct bifunctor
$\amalg \colon C \times C \to C$ is defined on arrows as the unique arrow

\[\begin{tikzcd}
a \dar[swap]{f}\rar{i} & a \amalg b \dar[dashed]{\exists! f\amalg g} & b \dar{g}\lar[swap]{j} \\
a' \rar[swap]{i'} & a' \amalg b' & b \lar{j'}
\end{tikzcd}\]

making this diagram commute.

****** Infinite coproducts
A *coproduct* of objects of $C$ indexed by a discrete category $X$ is a
universal arrow to the indexed diagonal functor $\Delta \colon C \to C^{X}$. We write
the coproduct object as $\coprod_{x \in X} a_x$.

******* Bijection rewriting
This universal arrow is a bijection

\[\mathrm{hom}\left( \coprod_{x \in X}a_x, c \right)
\cong \prod_{x \in X} \mathrm{hom}(a_x,c)
\]

natural in $c$.

****** Copowers
A *copower* is a coproduct where all the factors are equal. It is written
as 

\[\coprod_{x\in X} b \cong X \cdot b.\]

****** Coequalizers
A *coequalizer* of two arrows $f,g \colon a \to b$ is $u \colon b \to e$ such that $uf = ug$; and
for every other $u'$ with the same property factorizes through it.

****** Pushout
***** III.5. Categories with finite products
****** Category with finite products
A category *has finite products* if to any finite number of objects exists
a product diagram. In particular, it has a terminal object.

****** Binary products define finite products
A category having binary products has finite products. There is then a
product bifunctor, an isomorphism

\[
\alpha \colon a \times (b \times c) \cong (a \times b) \times c
\]

natural in $a,b,c$; and isomorphisms

\[
\lambda \colon t \times a \cong a,
\qquad
\varrho\colon a \times t \cong a,
\]

both natural in $a$.

******* TODO Proof
We will prove that $a \times (b \times c)$ is a product of $a,b,c$; due to its universal
property we know it has the universal property of the product of $a,b,c$

\[\begin{tikzcd}[row sep=small]
& & b \\
a & a \times (b \times c) \rar\lar\urar\drar & b \times c \dar \uar \\
& & c
\end{tikzcd}\]

and, by the same reasoning, $(a \times b) \times c$ is also a product. They are
isomorphic due to universality.

# Why is it natural?

***** III.6. Groups in categories
****** A group has a group hom functor
In a category with finite products, $c$ is a group iff $\mathrm{hom}(c,-)$ is a group
in the functor category $\mathtt{Set}^{C^{op}}$.

******* TODO Proof

***** III.7. Colimits of representable functors
****** Representation as colimits
**** IV. Adjoints
***** IV.1. Adjunctions
****** IV.1.0. Adjunction
An *adjunction* from categories $X$ to $A$ is a pair of functors
$F\colon X \to A$, $G\colon A \to X$ with a natural bijection

\[
\varphi \colon \mathrm{hom}(Fx,a) \cong \mathrm{hom}(x,Ga),
\] 

natural in both $x\in X$ and $a \in A$. We write it as $F \dashv G$.

****** IV.1.1. Unit and counit
An adjunction determines a *unit* and a *counit*

 1) A natural transformation made with universal arrows $\eta\colon I \xrightarrow{.} GF$, where
    the right adjoint of each $f \colon Fx \to a$ is

    \[
    \varphi f = Gf \circ \eta_x \colon x \to Ga.
    \]

 2) A natural transformation made with universal arrows $\varepsilon \colon FG \xrightarrow{.} I$, where
    the left adjoint of each $g \colon x \to Ga$ is

    \[\varphi^{-1}g = \varepsilon \circ Fg \colon Fx \to a.\]

that follow the /triangle identities/ $\eta G \circ G \varepsilon = \mathrm{id}$ and $F\eta \circ \varepsilon F = \mathrm{id}$.

****** IV.1.2. Characterization of adjunctions
Each adjunction is completely determined by any of

 1) functors $F,G$ and $\eta\colon 1 \xrightarrow{.} GF$ where $\eta_x\colon x \to GFx$ is universal to $G$.
 2) functor $G$ and universals $\eta_x \colon x \to GF_0 x$, creating a functor $F$.
 3) functors $F,G$ and $\varepsilon\colon FG \xrightarrow{.} 1$ where $\varepsilon_a\colon FGa \to a$ is universal from $F$.
 4) functor $F$ and universals $\varepsilon_a\colon FG_0a \to a$, creating a functor $G$.
 5) functors $F,G$, with units and counits satisfiying the triangle
    identities $\eta G \circ G \varepsilon = \mathrm{id}$ and $F\eta \circ \varepsilon F = \mathrm{id}$.

***** IV.3. Reflective subcategories
***** IV.4. Equivalence of categories
****** Equivalence of categories
A *equivalence of categories* is a pair of functors $S,T$ which are
inverses, $S \circ T = I$. Their domain and codomain are called /equivalent/ 
/categories/.

****** Skeleton of a category
A *skeleton* is a full subcategory where every isomorphism class has
exactly one representative.

***** IV.5. Adjoints for preorders
****** Galois connections are adjoint pairs
Let $L\colon P \to Q^{op}$ and $R\colon Q^{op} \to P$ two order preserving functions. They
are adjoints iff for every two objects

\[
Lp \geq q \iff p \leq Rq.
\]

The adjunction is unique and

\[
Lp \geq LRLp \geq Lp, \qquad Rq \leq RLRq \leq Rq.
\]

***** IV.6. Cartesian closed categories
****** Cartesian closed category
A *cartesian closed category* is a category with all finite products where
the functors

\[\begin{tabular}{ccc}
$C \to 1$, & 
$C \to C \times C$, & 
$C \to C$, \\
$c \mapsto 0$, &
$c \mapsto (c,c)$, &
$c \mapsto c \times b$;
\end{aligned}\]

have specified adjoints

\[\begin{tabular}{ccc}
$0 \mapsto t$, &
$(a,b) \mapsto a \times b$, &
$c \mapsto c^b$.
\end{aligned}\]

****** TODO Evaluation map

***** IV.7. Transformations of adjoints
****** Map of adjunctions
Given two adjunctions $\varphi\colon F \dashv G$ and $\varphi'\colon F' \dashv G'$; we define a *map of adjunctions*
as two functors $K \colon A \to A'$ and $L \colon X \to X'$ such that

\[\begin{tikzcd}
A \dar{K}\rar{G} & X \dar{L} \\
A' \rar{G'} & X'
\end{tikzcd}
\quad
\begin{tikzcd}
X \dar{L}\rar{F} & A \dar{K} \\
X' \rar{F'} & A' &
\end{tikzcd}\]

commute and such that, knowing that $KF = F'L$ and $LG = G'K$,

\[\begin{tikzcd}
\mathrm{hom}(Fx,a) \rar{\varphi} \dar[swap]{K} & \mathrm{hom}(x,Ga) \dar{L} \\
\mathrm{hom}(F'Lx,Ka) \rar{\varphi'} & \mathrm{hom}(Lx,G'Ka)
\end{tikzcd}\]

commutes.

******* Equivalence for units and counits
Given the first property, the condition on hom-sets is equivalent
to $L\eta = \eta'L$ and $\varepsilon'K = K\varepsilon$.

******** TODO Proof

****** TODO Conjugate natural transformations

***** IV.9. Subsets and characteristic functions
****** Subobject classifier
A *subobject classifier* for ${\cal C}$ with a terminal object $1$ is a monomorphism
$t \colon 1 \to \Omega$ such that for every monomorphism $m$ exists a unique square

\[\begin{tikzcd}
S\rar{} \dar[swap,hook]{m} & 1 \dar[hook]{t} \\
X\rar[dashed]{\Psi_{S}} & \Omega &,
\end{tikzcd}\]

which is at the same time a pullback.

***** IV.10. Categories like sets
****** Elementary topos
An *elementary topos* is a category $E$ which

 1) has all finite limits,
 2) has a subobject classifier,
 3) is cartesian closed.

****** Presheaves
A *presheaf* is a set-valued contravariant functor on a small category.

**** V. Limits
***** V.1. Creation of limits
****** V.1.0. Small-complete category
A category is *small-complete* when all small diagrams have limits in it.

****** V.1.1. Completeness of Set
$\mathsf{Set}$ has all small limits. Given $J$ small, $F \colon J \to \mathtt{Set}$ has limit $\mathrm{Cone}(\ast,F)$,
the set of all cones $\sigma\colon \ast \to F$; with the functions $v_j\colon \sigma \mapsto \sigma_j(\ast)$.

******* Proof
As $J$ is small, $\mathrm{Cone}(\ast,F)$ is an object of $\mathsf{Set}$. We prove that it is a
cone; for any given $u \colon j \to k$ in $J$,

\[
(Fu)v_j(\sigma) = (Fu)\sigma_j = \sigma_k = v_k(\sigma).
\]

And we prove that it is universal. Given any cone $\tau \colon X \todot F$, for any
$x \in X$ we have a $\mathrm{Cone}(\ast,F)$, so there is a unique function
$h \colon X \to \mathrm{Cone}(\ast,F)$.

******* Adjunction
This can be written as the following adjunction

\[
\Nat(\Delta X,F) \cong \hom(X, \mathrm{Cone}(\ast,F)).
\]

****** TODO V.1.1. Example: p-adic numbers
****** V.1.2. Creation of limits in Grp
If a small $H \colon J \to \Grp$ can be forgot into $\Set$ with a limiting cone $v \colon L \todot UH$,
there is exactly one group structure on $L$ making each $v_i$ a homomorphism;
$L$ is a limit of $H$ with this structure.

******* Proof
We take $L = \mathrm{Cone}(\ast,UH)$ and define a group structure with $(\sigma\tau)_j = \sigma_j\tau_j$
and $(\sigma^{-1})_j = (\sigma_j)^{-1}$; making each $v$ a homomorphism. These are cones because
the functions $UHj$ are homomorphisms. Any other structure making each $v$ a
homomorphism should in particular satisfy these equations; so this structure
is unique.

Given any other group cone $\lambda \colon G \todot H$, then $U\lambda \colon UG \todot UH$ is a set cone
and there exists a unique $h \colon UG \to L$ making the diagram commute; this is
a homomorphism of groups

\[
(h(g_1g_2))_j = \lambda_j(g_1g_2) = \lambda_j(g_1)\lambda_j(g_2) = (hg_1)_j(hg_2)_j.
\]

****** V.1.2. Creation of limits
The functor $V\colon A \to X$ *creates limits* for $F\colon J \to A$ when

 1) for any con $\tau\colon x \xrightarrow{.} VF$ exists $\sigma\colon a \to F$ with $Va = x$ and $V\sigma = \tau$.
 2) this $\sigma$ is a limiting cone.

****** V.1.3. The forgetful Groups to Sets functor creates limits
The forgetful functor $U \colon \Grp\to \Set$ creates limits.

******* Proof
Rereading of the [[*V.1.2. Creation of limits in Grp][previous theorem]].

***** V.2. Limits by products and equalizers
****** V.2.1. Existence of limits from products and equalizers
If ${\cal C}$ has all equalizers and all products indexed by the sets of objects
and arrows of $J$, it has every limit $F\colon J \to {\cal C}$.

******* TODO Proof

****** TODO V.2.2. Limits from products and equalizers
****** TODO V.2.2. Finite limits from products and equalizers
If a category ${\cal C}$ has all finite products and all equalizers, it
has all finite limits.

***** TODO V.3. Limits with parameters
***** V.4. Preservation of limits
****** V.4.0. Preservation of limits
A functor $H\colon C \to D$ *preserves limits* $J \to C$ when every limiting
cone $v$ in $C$ yields a limiting cone $Hv$ in $D$.

****** V.4.0. Continuous functor
A functor is *continuous* if it preserves all small limits.

****** V.4.1. Hom-functors preserve all limits
In ${\cal C}$ with small hom-functors, each $\hom(c,-)$ preserves all limits.

******* TODO Proof

***** TODO V.5. Adjoints on limits
****** V.5.1. Right adjointa preserve all limits
If $G \colon A \to X$ has a left adjoint and the diagram $T\colon J \to A$ has a
limiting cone $\tau \colon a\todot T$, then $GT$ has the limiting cone $G\tau \colon Ga \todot GT$
in $X$.

******* Proof
As $G$ is a functor, $G\tau$ is already a cone. Given any other cone $\sigma \colon x \todot GT$,
we can take adjoints on every component and, by naturality of the adjoint,
we have a cone $\sigma_{\ast} \colon Fx \todot T$. This cone uniquely factorizes throught $\tau$ with
$h \colon Fx \to a$, naturality preserves this unique factorization in $h_{\ast} \colon x \to Ga$,

\begin{prooftree}
\AXC{\begin{tikzcd}[fragile,ampersand replacement=\&] 
x \rar{h_\ast}\& Ga \rar{G\tau} \& Gi  \end{tikzcd}}
\doubleLine
\UIC{\begin{tikzcd}[fragile,ampersand replacement=\&]
Fx \rar{h}\& a \rar{\tau} \& i \end{tikzcd}}
\end{prooftree}

so $G\tau$ is universal.

***** V.6. Freyd's adjoint functor theorem
****** V.6.1. Existence of an initial object
In ${\cal D}$ small-complete with small hom-sets, there exists an initial object
if and only if it satisfies

 - solution set condition :: there exists a small family $\left\{ k_i \right\}_{i \in I}$ such that
      for each $d \in D$ exists an arrow $k_i \to d$.

******* Proof
If it has an initial object, it trivially satisfies the condition with that
object.

We take $w = \prod k_i$ and we have at least one arrow $w \to d$ for each $d$, given
by projections. We can construct the equalizer of all $\hom(w,w)$, which is
small

\begin{tikzcd}
v \rar{e} & w \rar[bend left] \rar[bend right] & w
\end{tikzcd}

For each $d$ there exists at least one $v \to d$, if there were two $f,g \colon v \to d$,
we take the equalizer of both, $u$, and

\[\begin{tikzcd}
u \rar{e_1} & v \dlar[swap]{e}\dar{e}\rar[bend left]{f}\rar[bend right]{g} & d \\
w \uar[dashed]{s}\rar{ee_1s} & w \rar & k_i \uar
\end{tikzcd}\]

we know that a $s \colon w \to u$ must exist; as $ee_1se = e$ and $e$ is an equalizer
(and thus, a monomorphism), $e_1se =\id$. Then, $e_1$ has a right inverse and
it is also a monomorphism, so it has to be an isomorphism, $f = g$.

****** V.6.2. Lemma to Freyd I: creation of products by adjoints
Given $G \colon A \to X$ preserving all small products, the projection
$Q \colon (x \downarrow G) \to A$, $(x \to Ga) \mapsto a$ from the comma category creates
all small products.

******* Proof
Given $\left\{ f_j\colon x \to Ga_j \right\}$ an indexed family of objects in $(x \downarrow G)$ such
that $p_k \colon \prod a_j \to a_k$ exists in $A$; we know that $Gp_k \colon G\prod a_j \to Ga_j$
is a product, so there is a unique $f \colon x \to G\prod a_j$ with $(Gp_j)f=f_j$,

\[\begin{tikzcd}
\Pi a_j \dar{p_j} & & G\Pi a_j \dar{Gp_j} \\
a_j & x \rar[swap]{f_j}\urar[dashed]{f} & Ga_j \\
\end{tikzcd}\]

We can now verify that these $p_j$ create a product in the comma category.

****** TODO V.6.2. Lemma to Freyd II: creation of equalizers by adjoints
****** V.6.2. The Freyd adjoint functor theorem
A functor $G \colon A \to X$ from a locally small category has
left-adjoint iff it preserves all small limits and satisfies the

 - solution set condition :: for each object $x \in X$ there is a small set $I$
      and a family of arrows $\left\{ f_i \colon x \to Ga \right\}_{i \in I}$ such that every $h \colon x \to Ga$
      can be written as $h = Gt \circ f_i$ for some $i$ with some $t \colon a_i \to a$.

******* Proof
******** First implication
If $G$ has a left-adjoint, it preserves all limits; the unit 
$\eta \colon x \to GFx$ satisfies the solution set condition.

******** Second implication
By [[*IV.1.2. Characterization of adjunctions][characterization of adjoints]], it suffices to create a universal
arrow $x \to Ga$ for each $x$; that is, a initial object in the comma
category $(x \downarrow G)$; the solution set condition gives us the conditions
of [[*V.6.1. Existence of an initial object][existence of an initial object]]. We only need to prove that $(x \downarrow G)$
is small-complete; but $G$ preserving small products makes the projection
create all [[*V.6.2. Lemma to Freyd I: creation of products by adjoints][products]] and create all [[*V.6.2. Lemma to Freyd II: creation of equalizers by adjoints][equalizers]].

****** V.6.3. The representability theorem

***** TODO V.7. Subobjects and generators
***** TODO V.8. The special adjoint functor theorem
***** TODO V.9. Adjoints in topology
**** VI. Monads and algebras
***** VI.1. Monads in a category
****** Monad
A *monad* is a functor $T\colon X \to X$ with natural transformations

 * $\eta\colon I \xrightarrow{.} T$, called /unit/
 * $\mu \colon T^2 \xrightarrow{.} T$, called /multiplication/

such that

\[\begin{tikzcd}
T^3 \rar{T\mu}\dar{\mu T} & T^2\dar{\mu} \\
T^2 \rar{\mu} & T
\end{tikzcd}
\qquad
\begin{tikzcd}
IT \rar{\eta T}\drar[swap]{\cong} & T^2\dar{\mu} & \lar[swap]{T\eta}\dlar{\cong} TI \\
& T & &.
\end{tikzcd}\]

****** Each adjunction defines a monad
Given $F \dashv G$, $GF$ is a monad.

******* Proof
We take the unit of the adjunction as the monad unit. We define the
product as $\mu = G\varepsilon F$. Associativity follows from these diagrams

\[\begin{tikzcd}
FGFG\rar{FG\varepsilon} \dar[swap]{\varepsilon FG} & FG \dar{\varepsilon} \\
FG\rar{\varepsilon} & I
\end{tikzcd}
\qquad
\begin{tikzcd}
GFGFGF\rar{GFG\varepsilonF} \dar[swap]{G\varepsilon FGF} & GFGF \dar{G\varepsilonF} \\
GFGF\rar{G\varepsilonF} & GF &,
\end{tikzcd}\]

where the first is commutative by the [[*Interchange law][interchange law]] and the second
is obtained by applying functors $G$ and $F$. Unit laws follow from
the [[*Unit and counit][triangular identities]] after applying $F$ and $G$.

****** Comonad
A *comonad* is a functor $L\colon X \to X$ with natural transformations

 * $\varepsilon\colon L\to I$, called /counit/
 * $\delta\colon L \to L^2$, called /comultiplication/

such that

\[\begin{tikzcd}
L\rar{\delta} \dar[swap]{\delta} & L^{2} \dar{L\delta} \\
L^{2}\rar{\delta L} & L^{3}
\end{tikzcd}
\qquad
\begin{tikzcd}
& L \dar{\delta} \dlar[swap]{\cong} \drar{\cong} & \\
IL & 
L^2 \lar{\varepsilon L}\rar[swap]{L \varepsilon} & 
LI
&.
\end{tikzcd}\]

****** TODO Each adjunction defines a comonad
***** VI.2. Algebras for a monad
****** T-algebra
For a monad $T$, a $T\text{-algebra}$ is an object $x$ with an arrow $h \colon Tx \to x$ called 
/structure map/ making these diagrams commute

\[\begin{tikzcd}
T^{2}x \rar{Th}\dar[swap]{\mu} & Tx \dar{h} \\
Tx\rar{h} & x &.
\end{tikzcd}\]

****** Morphisms of T-algebras
A morphism of T-algebras is an arrow $f\colon x \to x'$ making the following square
commute

\[\begin{tikzcd}
Tx \dar[swap]{Tf}\rar{h} & Tx \dar{f} \\
Tx' \rar[swap]{h'} & Tx' &.
\end{tikzcd}\]

****** Category of T-algebras
The set of all $T\text{-algebras}$ and their morphisms form a category $X^{T}$.

******* Proof
Given $f\colon x \to x'$ and $g\colon x'\to x''$, $T\text{-algebra}$ morphisms, their composition
is also a $T\text{-algebra}$ morphism, due to the fact that this diagram

\[\begin{tikzcd}
Tx \rar{h}\dar[swap]{Tf} & 
x \dar{f}\\
Tx' \dar[swap]{Tg} \rar{h'} &
x' \dar{g}\\
Tx'' \rar{h''}&
x''
\end{tikzcd}\]

commutes.

****** Every monad is defined by its T-algebras
The monad defined by the adjunction $F^{T} \dashv G^{T}$ is $T$, where the functors
are defined as

\[F^{T}\colon \begin{tikzcd}
x \dar{f} \\
x'
\end{tikzcd} \mapsto \begin{tikzcd}
(Tx,\mu) \dar{Tf} \\
(Tx',\mu)
\end{tikzcd}
\qquad
G^{T}\colon  \begin{tikzcd}
(x,h) \dar{f} \\
(x',h')
\end{tikzcd} \mapsto
\begin{tikzcd}
x \dar{Tf} \\
x' &
\end{tikzcd}\]

knowing that $(Tx,\mu)$ is always a $T\text{-algebra}$.

******* TODO Proof

***** VI.3. The comparison with algebras
****** Comparison of adjunctions with algebras
Given $F \dashv G$ with the monad $T$, there is a unique $K\colon A \to X^T$ with
$G^TK = G$ and $KF = F^T$.

******* TODO Proof

***** TODO VI.4. Words and free semigroups
***** TODO VI.5. Free algebras for a monad
**** VII. Monoids
***** VII.1. Monoidal categories
****** VII.1.0. Strict monoidal category
A *strict monoidal category* ${\cal B}$ is a category with a bifunctor $\otimes \colon {\cal B} \times {\cal B} \to {\cal B}$
which is associative

\[
\otimes(\otimes \times 1) = \otimes (1 \times \otimes) \colon {\cal B} \times {\cal B}\times {\cal B} \to {\cal B}
\]

and with a *unit* object,

\[
\otimes(e \times \Id) = \Id_{{\cal B}} =\otimes(\Id \times e).
\]

****** VII.1.0. Monoidal category
A *monoidal category* ${\cal B}$ is a category with a bifunctor $\otimes \colon {\cal B} \times {\cal B} \to {\cal B}$
and three natural isomorphisms

 * $\alpha \colon a \otimes (b \otimes c) \cong (a \otimes b) \otimes c$

 * $\lambda \colon e \otimes a \cong a$

 * $\rho \colon a \otimes e \cong a$

such that the pentagonal diagram commutes

\begin{tikzcd}
a \otimes (b \otimes (c \otimes d)) \dar{1 \otimes \alpha} \rar{\alpha}& 
(a \otimes b) \otimes (c \otimes d) \rar{\alpha}& 
((a \otimes b) \otimes c) \otimes d \dar{\alpha \otimes 1}\\
a \otimes ((b \otimes c) \otimes d) \ar[rr, "\alpha"] & & 
(a \otimes (b \otimes c)) \otimes d
\end{tikzcd}

and the following triangular diagram commutes

\[\begin{tikzcd}[row sep=tiny]
& a \otimes (e \otimes c) \ar[dd, "\alpha"]\dlar[swap]{1 \otimes \lambda}\\ 
a \otimes c &\\
& (a \otimes e) \otimes \ular{\rho \otimes 1}
\end{tikzcd}\]

**** IX. Special limits
***** IX.1. Filtered limits
****** Directed preorder
A preorder $P$ is *directed* when any two elements have an upper bound.

****** Filtered category
A category ${\cal C}$ is *filtered* when

 1) for any $a,b \in {\cal C}$ there exists a $c$ with arrows $a \to c$, $b \to c$.
 2) for any $u,v \colon a \to b$ exists a $w\colon b \to c$ such that $wu=wv$.

In a filtered category, every finite diagram is base of at least one cone.

**** Exercises [35/52]
***** I. Categories, functors and natural transformations [19/23]
****** I.3. Functors
******* CHECK Exercise I.3.1
#+begin_statement
Show how each of the following constructions can be regarded as a functor:

 - the field of quotients of an integral domain.
 - the Lie algebra of a Lie group.
#+end_statement

******** Field of quotients
Given two integral domains and a ring homomorphism $f : R \to S$, we
define an homomorphism between its fields of quotients as:

\[
\widetilde{f}\left(\frac{a}{b}\right)
=
\frac{f(a)}{f(b)}
\]

We can prove it is well-defined using that $ab=cd$ implies
$f(a)f(b) = f(c)f(d)$, and then:

\[
\widetilde{f}\left(\frac{a}{b}\right)
=
\frac{f(a)}{f(b)}
=
\frac{f(c)}{f(d)}
=
\widetilde{f}\left(\frac{c}{d}\right)
\]

And it respects sums and products:

\[
\widetilde{f}\left(\frac{a}{b} + \frac{c}{d}\right)
=
\widetilde{f}\left(\frac{ad+cb}{bd}\right)
=
\frac{f(a)f(d)+f(c)f(d)}{f(b)f(d)}
=
\frac{f(a)}{f(b)}+\frac{f(c)}{f(d)}
\]

\[
\widetilde{f}\left(\frac{ac}{bd}\right) =
\frac{f(a)f(c)}{f(b)f(d)}
\]

So it is a field homomorphism.

******** TODO Lie algebra
Given $\phi : G \to H$, a Lie group homomorphism, we can compute its first
derivative at the identity $\phi^*$.
******* DONE Exercise I.3.2
#+begin_statement
Show that functors $1 \to C$, $2 \to C$, and $3 \to C$ correspond respectively to
objects, arrows, and composable pairs of arrows in $C$.
#+end_statement

A functor $F\colon 1 \to C$ is determined by $F1$. A functor $F\colon 2 \to C$ is determined
by $F(1\leq 2)\colon F1 \to F2$. A functor $F\colon 3 \to C$ is determined by $F(1\leq 2)$ and
$F(2\leq 3)$, which must be composable in $F2$.

******* DONE Exercise I.3.3
#+begin_statement
Interpret "functor" in the following special types of categories:

  1. A functor between two preorders is a function $T$ which is monotonic
     (i.e. $p \leq p'$ implies $Tp \leq Tp'$).
  2. A functor between two groups (one-object categories) is a morphism
     of groups.
  3. If $G$ is a group, a functor $G \to \mathtt{Set}$ is a permutation representation
     of $G$, while $G \to Matr_K$ is a matrix representation of $G$.
#+end_statement

******** First statement
A functor must be a monotonic function, as it has to send $(p\leq p')$ into
a morphism between $Tp$ and $Tp'$. This morphism exists if and only if 
$Tp \leq Tp'$.

******** Second statement
It respects the identity and the group operation, as functors respect
the identity and the composition.

******** Third statement
A functor $F\colon G \to \mathtt{Set}$ is determined by $FG$ and the assignment of every
element of $G$ to a set automorphism, that is, an element of the permutation
group of the set.

The functor $F\colon G \to \mathtt{Matr}_K$ selects a dimension $n$, and sends every element
of the group to an invertible matrix $M_{n\times n}$.

******* DONE Exercise I.3.4
#+begin_statement
Prove that there is no functor $\mathtt{Grp} \to \mathtt{Ab}$ sending each group $G$ to its
center. (Consider $S_2 \to S_3 \to S_2$, the symmetric groups).
#+end_statement

A functor must preserve identities and composition. We have the following
diagram in $\mathtt{Grp}$,

\[\begin{tikzcd}
S_2 \rar[hook]\arrow[rr,bend left, "id"] & S_3 \rar & S_2
\end{tikzcd}\]

that cannot be translated into $\mathtt{Ab}$ by this functor

\[\begin{tikzcd}
S_2 \rar & \{id\} \rar &  S_2
\end{tikzcd}\]

as we know that the identity is not the zero morphism.

******* DONE Exercise I.3.5
#+begin_statement
Find two different functors $T : \mathtt{Grp} \to \mathtt{Grp}$ with object function $T(G) = G$
the identity for every group $G$.
#+end_statement

The identity functor and a functor sending every morphism to the zero 
morphism.

****** I.4. Natural transformations
******* DONE Exercise I.4.1
#+begin_statement
Let $S$ be a fixed set, and $X^S$ the set of all functions $h : S \longrightarrow X$.
Show that $X \mapsto X^S$ is the object function of a functor $\mathtt{Set} \longrightarrow \mathtt{Set}$,
and that evaluation $e_X : X^S \times S \longrightarrow X$ defined by $e(h,s) = h(s)$, the
value of the function $h$ at $s \in S$ is a natural transformation.
#+end_statement

We define the functor $\_^S$ on arrows as follows. Given a $f : X \to Y$
and a $g : S \longrightarrow X$:

\[
f^S(g) = f \circ g
\]

And it follows the functor laws.

We can see that evaluation is a natural transformation with the
naturality square:

\[\begin{tikzcd}
X^S \times S \dar{e_X}\rar{f^S,id} & Y^S \times S \dar{e_Y}\\
X \rar{f} & Y
\end{tikzcd}\]

Which commutes on its elements:

\[\begin{tikzcd}
(f,s) \dar{e_X}\rar{g^S,id} & (g\circ f, s) \dar{e_Y}\\
f(s) \rar{f} & g(f(s))
\end{tikzcd}\]

******* DONE Exercise I.4.2
#+begin_statement
If $H$ is a fixed group, show that $G \mapsto H \times G$ defines a functor
$H \times - \colon \mathtt{Grp}\to \mathtt{Grp}$ and that each morphism $f \colon H \to K$ of groups defines
a natural transformation $H \times -\; \dot\to \; K \times -$.
#+end_statement

The functor will send a morphism $f \colon G \to G'$ to $\mathrm{id}\times f\colon H\times G \to H \times G'$.
The naturality condition is satisfied if the following diagram commutes

\[\begin{tikzcd}
H \times G \dar{\mathrm{id}\times f} \rar{g\times\mathrm{id}} & 
K \times G \dar{\mathrm{id}\times f} \\
H \times G' \rar{g\times\mathrm{id}} & 
K \times G'
\end{tikzcd}\]

but it is trivial to check commutativity.

******* DONE Exercise I.4.3
#+begin_statement
If $B$ and $C$ are groups (regarded as categories with one object each) and
$S,T \colon B \to C$ are functors (homomorphisms of groups), show that there is a
natural transformation $S \dot\to T$ if and only if $S$ and $T$ are conjugate; i.e.
if and only if there is an element $h \in C$ with $Tg = h(Sg)h^{-1}$ for all
$g \in B$.
#+end_statement

If the only object in $B$ is $b$, then $Sb = Tb = c$ must be the only object
in $c$. Naturality gives us

\[\begin{tikzcd}
c\rar{\varphi} \dar[swap]{Sf} & c \dar{Tf} \\
c\rar{\varphi} & c
\end{tikzcd}\]

so we know that $Sf \circ \varphi = \varphi \circ Tf$, and this is the conjugate condition.

******* DONE Exercise I.4.4
#+begin_statement
For functors $S,T \colon C \to P$ where $C$ is a category and $P$ a preorder, show
that there is a natural transformation $S \dot\to T$ (which is then unique) if
and only if $Sc \leq Tc$ for every object $c \in C$.
#+end_statement

To define a natural transformation, we must have a familiy of morphisms

\[
Sc \to Tc \quad\forall c \in C,
\]

but this morphism exists if and only if $Sc \leq Tc$ for every object. If the
morphisms exist, the naturality condition is trivial, as there will be
an unique morphism between two objects and all squares will commute.

******* DONE Exercise I.4.5
#+begin_statement
Show that every natural transformation $\tau\colon S \dot\to T$ defines a function
(also called $\tau$) which sends each arrow $f\colon c \to c'$ of $C$ to an arrow
$\tau f\colon Sc \to Tc'$ of $B$ in such a way that $Tg \circ \tau f = \tau(gf) = \tau g\circ Sf$ for
each composable pair $(g,f)$. Conversely, show that every such function $\tau$ 
comes from a unique natural transformation with $\tau_c = \tau(1_c)$. (This gives 
an arrows only description of a natural transformation.)
#+end_statement

Given $f\colon c \to c'$, we apply the naturality condition and take $\tau$ to be the
diagonal

\[\begin{tikzcd}
Sc \drar{\tau f} \rar{\tau} \dar[swap]{Sf} & Tc \dar{Tf} \\
Sc'\rar{\tau} & Tc'
\end{tikzcd}\]

i.e. we have defined $\tau f = Tf\circ \tau_c = \tau_{c'} \circ Sf$. The condition holds now 
trivially, as we know that

\[
Tg \circ \tau f = Tg\circ Tf\circ \tau_c = \tau(gf) = \tau_{c'}\circ Sg\circ Sf
= \tau g \circ Sf.
\]

******* TODO Exercise I.4.6
#+begin_statement
Let $F$ be a field. Show that te category of all finite-dimensional vector
spaces over $F$ (with morphisms all lineal transformations) is equivalent
to the category $\mathtt{Matr}$.
#+end_statement
****** I.5. Monics, epis and zeros
******* DONE Exercise I.5.1
#+begin_statement
Find a category with an arrow which is both epi and monic, but not 
invertible (e.g., dense subset of a topological space).
#+end_statement

In the $\mathtt{Top}$ category of topological spaces with continuous functions,
we can include a dense subset in its base space. This inclusion will
be a monomorphism (as it is injective) and an epimorphism as we know
that, if $i \colon U \subset V$ is our inclusion,

\[ f\circ i = i \circ g \implies f|_{U} = g|_{U},\]

and because it is a dense subset, by continuity, $f = g$.

But it has not to be an isomorphism. In fact, it won't be if $U$ is a
proper subset.

******* DONE Exercise I.5.2
#+begin_statement
Prove that the composite of monics is monic, and likewise for epis.
#+end_statement

If $f,g$ are monics, we can apply the definition twice to get

\[
f \circ g \circ a = f \circ g \circ b \implies
g \circ a = g\circ b \implies
a = b.
\]

The same proof can be applied in reverse.

******* DONE Exercise I.5.3
#+begin_statement
If a composite $g\circ f$ is monic, so is $f$. Is this true of $g$?
#+end_statement

No, $f$ could be a zero morphism and $g$ could still give $g\circ h = g\circ h'$ for
two $h \neq h'$.

******* DONE Exercise I.5.4
#+begin_statement
Show that the inclusion $\mathbb{Z} \to \mathbb{Q}$ is epi in the category $\mathtt{Rng}$.
#+end_statement

If $f \circ i = g \circ i$, then $f|_{\mathbb{Z}} = g|_{\mathbb{Z}$, and we can extend the morphisms uniquely
to the ring $\mathbb{Q}$, as the ring morphisms have to preserve inverses.

******* TODO Exercise I.5.5
#+begin_statement
In $\mathtt{Grp}$ prove that every epi is surjective (Hint. If $\varphi\colon G\to H$ has image
$M$ not $H$, use the factor group $H/M$ if $M$ has index 2. Otherwise, let
$\mathrm{Perm}\ H$ be the group of all permutations of the set $H$, choose three
different cosets $M,Mu$ and $Mv$ of $M$, define $\sigma \in \mathrm{Perm}\ H$ by
$\sigma(xu) = xv$, $\sigma(xv) = xu$ for $x \in M$, and $\sigma$ otherwise the identity.
Let $\psi\colon H \to \mathrm{Perm}\ H$ send each $h$ to left multiplication $\psi_h$ by $h$, while
$\psi'_h = \sigma^{-1}\psi_h\sigma$. Then $\psi\varphi = \psi'\varphi$, but $\psi \neq \psi'$).
#+end_statement

******* DONE Exercise I.5.6
#+begin_statement
In $\mathtt{Set}$, show that all idempotents split.
#+end_statement

Given $f \colon A \to A$ idempotent, we can define the set $\mathrm{img}\ f$, and two functions
$g \colon A \to \mathrm{img}\ f$, $h\colon \mathrm{img}\ f \to A$ defined naturally and satisfiying the conditions.
Notice that $g$ is an epimorphism and $h$ a monomorphism.

******* DONE Exercise I.5.7
#+begin_statement
An arrow $f \colon a \to b$ in a category $C$ is /regular/ when there exists an arrow
$g\colon b \to a$ such that $fgf = f$. Show that $f$ is regular if it has either a left or
a right inverse, and prove that every arrow in $\mathtt{Set}$ with $a \neq \varnothing$ is regular.
#+end_statement

If $f$ has either a right or a left inverse, it is trivial that it is regular.

If $a \neq \varnothing$, we can take $x_y \in \left\{ x \in a \mid f(x) = y \right\}$, a representative of the class
of elements that are mapped onto $y$, and $u \in a$ an arbitrary element, and define

\[
g(y) = \left\{\begin{array}{ll} 
x_y & \mbox{if } y \in \mathrm{img}(f)  \\
u & \mbox{otherwise }
\end{array} 
\right.
\]

and this morphism makes the $f$ regular. (Have we used the choice axiom to define
the representatives?)

******* DONE Exercise I.5.8
#+begin_statement
Consider the category with objects $\left\langle X,e,t \right\rangle$, where $X$ is a set, $e \in X$, and
$t \colon X \to X$, and with arrows $f\colon \left\langle X,e,t \right\rangle \to \left\langle X',e',t' \right\rangle$ the functions $f$ on $X$ to $X'$
with $fe=e'$ and $ft = tf'$. Prove that this category has an initial object in
which $X$ is the set of natural numbers, $e=0$, and $t$ is the successor function.
#+end_statement

We will prove that $\left\langle \mathbb{N},0,S \right\rangle$ is the initial object. For every object $\left\langle X,e,t \right\rangle$,
we only can define a function $f$, its image on zero is determined by the
first arrow condition $f(0) = e$, and its image in every other natural is
determined as

\[
f(n) = f(S \circ \overset{n}\dots \circ S(0)) = t\circ \overset{n}\dots \circ t(f(0)).
\]

******* DONE Exercise I.5.9
#+begin_statement
If the functor $T \colon C \to B$ is faithful and $Tf$ is monic, prove $f$ monic.
#+end_statement

If $f\circ g = f \circ h$, we have $Tf\circ Tg = Tf\circ Th$. $Tf$ is monic and $T$ is faithful, so
we get $g = h$.

****** I.6. Foundations
******* CHECK Exercise I.6.1
#+begin_statement
Given a universe $U$ and a function $f \colon I \to b$ with domain $I \in U$ and
with every value $f_i$ an element of $U$, for $i \in I$, prove that the usual
cartesian product $\prod_i f_i$ is an element of $U$.
#+end_statement

An element of the cartesian product will be a function $g \colon I \to \bigcup f_i$,
where $g(i) \in f_i$ for every $i \in I$. Our cartesian product is defined as

\[
\left\{ x \in {\cal P}\left( I \times \bigcup f_i \right) \;\middle|\; 
\left( \forall (i,b) \in x \colon b \in f_i \right) \wedge
\left( \forall j \in I\colon \exists! (i,b) \in x\colon j = i \right)
\right\}.
\]

Notice that the powerset and the union of elements in $U$ are elements
in $U$.

******* TODO Exercise I.6.2
#+begin_statement
(a) Given a universe $U$ and a function $f \colon I \to b$ with domain $I \in U$, show
that the usual union $\bigcup_i f_i$ is a set of $U$.

(b) Show that this one closue property of $U$ may replace condition (v) and the
condition $x \in U$ implies $\bigcup x \in U$ in the definition of a universe.
#+end_statement
***** II. Constructions on categories [6/11]
****** II.3. Products of categories
******* DONE Exercise II.3.1
#+begin_statement
Show that the product of categories includes the following known special
cases: The product of monoids (categories with one object), of groups,
of sets (discrete categories).
#+end_statement

The product of two monoids or groups has only one object, and so it is
a monoid or group. Every pair of isomorphisms has an inverse given by
the pair of inverses, and because of that, we know that the product of
two groups is in fact a group.

The product of two sets has no nontrivial morphisms and only pairs of
objects as objects.

******* DONE Exercise II.3.2
#+begin_statement
Show that the product of two preorders is a preorder.
#+end_statement

The product of two preorders gives the product preorder, where $(a,b) \leq (a',b')$
if and only if $a \leq a'$ and $b\leq b'$. That pair of morphisms is witness of the 
order.

******* DONE Exercise II.3.3
#+begin_statement
If $\left\{ C_i \mid i \in I \right\}$ is a family of categories indexed by a set $I$, describe the
product $C= \prod_iC_i$, its projections $P_i\colon C \to C_i$, and establish the universal
property of these projections.
#+end_statement

An object in this category is a function assigning $i \mapsto c_i \in C_i$. A morphism
between it and $i \mapsto d_i \in C_i$ is a function assigning $i \mapsto (f_i \colon c_i \to d_i)$ and
componentwise composition. Its projections are only the functors given by
evaluation on any element in $I$.

Given any other family of functors $D \to C_i$, we can define a functor to $C$
componentwise, being the unique functor making a product diagram commute.

******* TODO Exercise II.3.4
#+begin_statement
Describe the opposite of the category $\mathtt{Matr}_K$.
#+end_statement

******* DONE Exercise II.3.5
#+begin_statement
Show that the ring of continuous real-valued functions on a topological
space is the object function of a contravariant functor on $\mathtt{Top}$ to $\mathtt{Rng}$.
#+end_statement

We are going to define the functor $T \colon \mathtt{Top}\to \mathtt{Rng}$ taking $Tf$ to be
$(\circ f) \colon \mathrm{hom}_{\mathtt{Top}}(Y,\mathbb{R}) \to \mathrm{hom}_{\mathtt{Top}}(X,\mathbb{R})$ for any given $f \colon X \to Y$. It is 
trivially a functor, as it preserves composition.

We know that the composition of two continuous functions is
continuous, and we have to prove that $(\circ f)$ is a ring homomorphism,
but it is trivial that

\[\begin{aligned}
(g\cdot h) \circ f &= (g \circ f) \cdot (h \circ f) \\
(g + h) \circ f &= (g \circ f) + (h \circ f). \\
\end{aligned}
\]

****** II.4. Functor categories
******* TODO Exercise II.4.1
#+begin_statement
For $R$ ring, describe $R\text{-Mod}$ as a full subcategory of the functor category
$\mathtt{Ab}^R$.
#+end_statement

******* TODO Exercise II.4.2
#+begin_statement
Describe $B^X$, for $X$ a finite set (a finite discrete category).
#+end_statement

******* TODO Exercise II.4.3
#+begin_statement
Let $\mathbb{N}$ be the discrete category of natural numbers. Describe the functor
category $\mathtt{Ab}^{\mathbb{N}}$ (commonly known as the category of graded abelian groups). 
#+end_statement

****** II.5. The category of all categories
******* TODO Exercise II.5.1
#+begin_statement
For small categories $A$, $B$ and $C$ establish a bijection

\[ \mathrm{hom}(A \times B, C) \cong \mathrm{hom}(A, C^B),
\]

and show it natural in $A$, $B$ and $C$. Hence show that $-\times B \colon \mathtt{Cat}\to \mathtt{Cat}$ has
a right adjoint.
#+end_statement

****** II.6. Comma categories
******* DONE Exercise II.6.1
#+begin_statement
If $K$ is a commutative ring, show that the comma category $(K \downarrow \mathtt{CRng})$ is
the usual category of all small commutative $K\text{-algebras}$.
#+end_statement

A $K\text{-algebra}$ can be defined as an inclusion from $K$ on a ring, morphisms
of algebras must preserve this inclusion.

# A more detailed proof would be interesting.

******* DONE Exercise II.6.2
#+begin_statement
If $t$ is a terminal object in $C$, prove that $(C \downarrow t)$ is isomorphic to $C$.
#+end_statement

By definition of terminal object, there will be only an arrow 
$\ast \colon u \to t$ for any $u \in C$. Every morphism will create a commutative 
diagram because of the unicity of the morphisms.

***** III. Universals and limits [9/16]
****** III.1. Universal arrows
******* DONE Exercise III.1.1
#+begin_statement
Show how each of the following familiar constructions can be interpreted
as a universal arrow:

 * The integral group ring of a group (better, of a monoid).
 * The tensor algebra of a vector space.
 * The exterior algebra of a vector space.
#+end_statement

******** The integral group ring (monoid)
The integral group ring $\mathbb{Z}G$ is defined as the initial object of $(G \downarrow {\cal U})$,
where ${\cal U}$ is the functor that takes a ring and returns its group of units.

******** The tensor algebra of a vector space
The tensor algebra $T(V)$ is defined as the initial object of $(V \downarrow U)$,
where $U\colon \mathtt{Alg}_k \to \mathtt{Vect}_k$ is the forgetful functor.

******** The exterior algebra of a vector space
The same construction as above can be performed on the full subcategory of
external algebras.

******* DONE Exercise III.1.2
#+begin_statement
Find a universal element for the contravariant power set functor
${\cal P} \colon \mathtt{Set}^{op} \to \mathtt{Set}$.
#+end_statement

The universal arrow for $A$ will be its inclusion in ${\cal P}{\cal P}A$ as

\[
i(a) = \left\{ U \in {\cal P}A \mid a \in U \right\}.
\]

Given a morphism $f \colon A \to {\cal P}B$, we define $g \colon B \to {\cal P}A$ as

\[
g(b) = \left\{ a \in A \mid b \in f(a) \right\}.
\]

And its image when the functor is applied is

\[
{\cal P}g(\mathbb{A}) = g^{-1}(\mathbb{A})
= \left\big\{ b \in B \mid \left\{ a \mid b \in f(a) \right\} \in \mathbb{A} \right\big\}.
\]

The $g$ is unique, as it is defined by $x \in f(a) \iff a \in g(x)$.

******* DONE Exercise III.1.3
#+begin_statement
Find (from any given object) universal arrows to the following forgetful
functors: $\mathtt{Ab} \to \mathtt{Grp}$, $\mathtt{Rng}\to \mathtt{Ab}$ (forget the multiplication), $\mathtt{Top} \to \mathtt{Set}$,
$\mathtt{Set}_{\ast} \to \mathtt{Set}$.
#+end_statement

******** Abelian groups to groups
The universal arrow defines the [[https://en.wikipedia.org/wiki/Commutator_subgroup][abelianization]] of the group. A morphism
from a group to an abelian group must have the commutator subgroup in 
its kernel

\[f(aba^{-1}b^{-1}) = f(a)f(b)f(b)^{-1}f(a)^{-1} = 1.\]

Thus, every morphism can be factorized in $G/[G,G]$, giving

\[\begin{tikzcd}
g \rar[hook]{i}\drar[swap]{f} & G/[G,G]\dar[dashed]{\widetilde f} \\
  & h & .
\end{tikzcd}\]

******** TODO Rings to abelian groups
A tensor Z-algebra over the abelian group.

******** Topological spaces to sets
The inclusion on the discrete topology over the set is an universal
arrow. If we define any application $f\colon A \to O$, there is an unique 
continuous function $\widetilde f \colon (A,\tau_d) \to (O,\tau)$ defined by $\widetilde f(x) = f(x)$. It is
trivially continuous, as $\tau_d$ is the discrete topology.

******** Pointed sets to sets
Trivially, the inclusion on $(S \cup \left\{ \ast \right\}, \ast)$ defines an universal arrow.

******* TODO Exercise III.1.4
#+begin_statement
Use only universality (of projections) to prove the following isomorphisms of
group theory:

 1) For normal subgroups $M,N$ of $G$ with $M \subset N$, $(G/M)(N/M) \cong (G/M)$.
 2) For subgroups $S$ and $N$ of $G$, $N$ normal, with join $SN$, $SN/N \cong S/S\cap N$.
#+end_statement

******* TODO Exercise III.1.5
#+begin_statement
Show that the quotient $K\text{-module}$ $A/S$ ($S$ a submodule of $A$) has a description
by universality. Derive isomorphism theorems.
#+end_statement

******* TODO Exercise III.1.6
#+begin_statement
Describe quotients of a ring by a two-sided ideal by universality.
#+end_statement

******* TODO Exercise III.1.7
#+begin_statement
Show that the construction of the polynomial ring $K[x]$ in a indeterminate $x$
over a commutative ring $K$ is a universal construction.
#+end_statement

****** III.2. Yoneda Lemma
******* DONE Exercise III.2.1
#+begin_statement
Let functors $K,K' \colon D \to \mathtt{Set}$ have representations $\left\langle r,\psi \right\rangle$ and $\left\langle r',\psi' \right\rangle$, 
respectively. Prove that to each natural transformation $\tau\colon K \overset{\cdot}\to K'$,
there is a unique morphism $h \colon r' \to r$ of $D$ such that

\[
\tau\circ \psi = \psi' \circ D(h,-) \colon D(r,-) \overset{\cdot}\to K'.
\]
#+end_statement

The following natural transformation

\[\begin{tikzcd} 
\mathrm{hom}(r,-) \rar{\psi}&
K \rar{\tau}&
K' \rar{\psi'^{-1}}& 
\mathrm{hom}(r',-),
\end{tikzcd}\]

[[*Corollary to Yoneda Lemma][must]] have the form $h_{\ast}$ for a unique $h\colon r' \to r$, so $\tau \circ \psi = \psi' \circ h_{\ast}$.

******* TODO Exercise III.2.2
#+begin_statement
State the dual of the Yoneda Lemma ($D$ replaced by $D^{op}$).
#+end_statement

****** III.3. Coproducts and colimits
******* DONE Exercise III.3.1
#+begin_statement
In the category of commutative rings, show that $R \to R \otimes S \gets S$, with maps
$r \mapsto r \otimes 1$, $s \mapsto 1\otimes s$, is a coproduct diagram.
#+end_statement

Given $\alpha\colon R \to T$ and $\beta\colon S \to T$; the unique homomorphism making the diagram
commute must be defined by

\[f(r\otimes s) = f(r\otimes 1)f(1 \otimes s) = \alpha(r) \beta(s).\]
****** III.4. Products and limits
******* DONE Exercise III.4.1
#+begin_statement
In $\mathtt{Set}$, show that the pullback of $f\colon X \to Z$ and $g \colon Y \to Z$ is given
by the set of pairs $\left\{ (x,y) \mid x \in X, y \in Y, fx = gy \right\}$. Describe pullbacks
in $\mathtt{Top}$.
#+end_statement

Let $h_x,h_y$ be two functions such that $f(h_x(c)) = g(h_y(c))$. Then the only
possible $\phi \colon C \to P = \left\{ (x,y) \mid fx =gy \right\}$ is $\Phi(c) = (h_xc,h_yc) \in P$.

In $\mathtt{Top}$, the pullback is similar: it is a subspace of the product given
by $\left\{ (x,y) \mid fx = gy \right\}$.

******* DONE Exercise III.4.4
#+begin_statement
In any category, prove that $f\colon a \to b$ is epi if and only if the following
square is a pushout

\[\begin{tikzcd}
a\rar{f} \dar[swap]{f} & b \dar{1} \\
b\rar{1} & b &.
\end{tikzcd}\]
#+end_statement

The usual definition of epimorphism is equivalent to the universal
property.

******* DONE Exercise III.4.5
#+begin_statement
In a pullback square, show that $f$ monic implies $q$ monic.
#+end_statement

If $n,m \colon c \to b \times d$, with $n\pi_2 = m\pi_{2}$; as we know that $n\pi_1 f = m\pi_1 f$, we
can use monicity to get $n\pi_1 = n\pi_2$. By universal property of the pullback
square, $n = m$.

****** III.5. Categories with Finite Products
******* DONE Exercise III.5.1
#+begin_statement
Prove that the diagonal $\delta_c \colon c \to c \times c$ is natural in $c$.
#+end_statement

We use the identity $\pi_1\delta_c = 1_c = \pi_2\delta_c$ to create the four commutative
triangles that we use in this diagram. The commutativity of the diagram
follows from the universal property of the product.

\[\begin{tikzcd}
& c\dar{\delta}\dlar[swap,bend right]{id}\drar[bend left]{id} & \\
c \dar{f} & c \times c\lar[swap]{\pi}\rar{\pi} \dar{f \times f} & c \dar{f} \\
d\drar[bend right]{\delta} & d \times d \lar[swap]{\pi}\rar{\pi}\dar{id} & 
d\dlar[bend left,swap]{\delta} \\
& d\times d \\
\end{tikzcd}\]

******* TODO Exercise III.5.5
#+begin_statement
If $B$ has (finite) products show that any functor category $B^C$ also has (finite)
products (calculated "pointwise").
#+end_statement
***** IV. Adjoints [1/2]
****** IV.1. Adjunctions
******* DONE Exercise IV.1.2
#+begin_statement
Given functors $G\colon A \to X$ and $F \colon X \to A$, show that each adjunction $\left\langle F,G,\varphi \right\rangle$ can
be described as an isomorphism $\theta$ of comma categories such that the following diagram
commutes

\begin{tikzcd}[column sep=none]
\theta\colon & (F \downarrow I_{A})\dar & \cong & (I_x \downarrow G)\dar \\
& X \times A & = & X \times A & &.
\end{tikzcd}

Here the vertical maps have components the projection functors $P$ and
$Q$ of II.6(5).
#+end_statement

Given an adjunction $\varphi \colon \mathrm{hom}(Fx,y) \cong \mathrm{hom}(x,Gy)$, we can define the isomorphism
in objects as $\theta(f \colon Fx \to y) = (\varphi f \colon x \to Gy)$. And the isomorphism on morphisms
as

\begin{tabular}{ccc}
\begin{tikzcd}
Fx \dar{f}\rar{Fk} & Fx' \dar{f'} \\
y \rar{h} & y'
\end{tikzcd} 
& \Longrightarrow &
\begin{tikzcd}
x \dar{\varphi f}\rar{k} & x' \dar{\varphi f'} \\
Gy \rar{Gh} & Gy'
\end{tikzcd}
\end{tabular}

where the commutativity of the second diagram follows from the commutativity of the
first one if we apply naturality of $\varphi$. This $\theta$ is bijective and respects composition
trivially. The given diagram commutes.

# Are all isomorphisms on this form adjunctions?

******* TODO Exercise IV.1.3
#+begin_statement
For the adjunction $\left\langle \Delta,\times,\varphi \right\rangle$, show that the unit $\delta_c : c \to c \times c$ for each object
$c \in C$ is the unique arrow such that the diagram

\[\begin{tikzcd}
& C\drar{1}\dlar[swap]{1}\dar[dashed]{\delta_c} & \\
c & c \times c \rar[swap]{q}\lar{p} & c
\end{tikzcd}\]

commutes. This arrow is often called the /diagonal arrow/ of $c$. If $C = \mathtt{Set}$, show
that $\delta_cx = \left\langle x,x \right\rangle$ for $x \in c$.
#+end_statement

*** Category theory - Awodey
:PROPERTIES:
:INTERLEAVE_PDF: ~/pdf/awodey_category_theory.pdf
:END:
**** Preface
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: 4
:END:
**** 1. Categories
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: 11
:END:
***** 1.1. Introduction
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (11 . 0.29894089511445165)
:END:

1945 - Eilenberg, Mac Lane's "General theory of natural equivalences".
1940s - Algebraic topology and abstract algebra.
1950s - Grothendieck et al. in algebraic geometry.
1960s - Lawvere et al. in logic.
1970s - Computer science, linguistics, philosophy.

**** 8. Categories of diagrams
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: 169
:END:

***** 8.1. Set-valued functor categories
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (169 . 0.4065596173556542)
:END:

***** 8.2. The Yoneda embedding
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (170 . 0.4543901605739665)
:END:

****** Definition 8.1. Yoneda embedding                                                             :drill:yoneda:
SCHEDULED: <2018-07-04 Wed>
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (171 . 0.17936453706867098)
:ID:       75e75540-0bbc-4316-a943-67a3d0d514fb
:DRILL_LAST_INTERVAL: 3.9254
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-30 Sat 18:42]
:END:
Define the Yoneda embedding. What does it mean to be an embedding?

******* Definition
The Yoneda embedding is defined by

\[
yC = \hom_{\mathbb{C}}(-,C) \colon \mathbb{C}^{op} \to \mathsf{Set}
\]

and, for each $f \colon C \to D$,

\[
yf = (f \circ -) \colon \mathrm{hom}(-,C) \to \mathrm{hom}(-,D).
\]

******* Embedding
It is an /embedding/ because it is full, faithful and injective on
objects.  This is a consequence of the Yoneda Lemma.

****** Yoneda as a representation                                                                         :yoneda:
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (172 . 0.2750256235052955)
:END:

In this sense, the Yoneda embedding y represents the objects and
arrows of C as certain “structured sets” and (all of) their
"homomorphisms".

***** 8.3. The Yoneda Lemma
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (172 . 0.3467714383327639)
:END:

****** Yoneda lemma                                                                                        :drill:
SCHEDULED: <2018-07-03 Tue>
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (172 . 0.3826443457464981)
:ID:       2c7b9f5c-4064-4abe-be4f-953e7b83c626
:DRILL_LAST_INTERVAL: 3.474
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-30 Sat 18:39]
:END:

Statement of the Yoneda lemma.

******* Answer
Let $\mathbb{C}$ be locally small, there is an isomorphism

\[
\mathrm{hom}(yC,F) \cong FC
\]

natural in each object $C \in \mathbb{C}$ and any functor $F \in \mathsf{Set}^{\mathbb{C}^{op}}$.

******* Extra
Note that these are homomorphisms between functors (natural transformations).
We are not making the naturality conditions explicit.

***** 8.4. Applications of the Yoneda Lemma
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (176 . 0.3467714383327639)
:END:

****** Embedding is full and faithful                                                                      :drill:
SCHEDULED: <2018-07-04 Wed>
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (176 . 0.4902630679877007)
:ID:       8903d3bd-7725-42ab-a047-80170fc13440
:DRILL_LAST_INTERVAL: 3.8708
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-30 Sat 18:40]
:END:
Why in any small category $\mathbb{C}$ an isomorphism $yA \cong yB$ implies $A \cong B$?

******* Answer
The Yoneda embedding is full and faithful.

****** Exponential rule in cartesian closed categories                                                     :drill:
SCHEDULED: <2018-07-05 Thu>
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (176 . 0.5739665186197471)
:ID:       3581b5dc-2d1e-4830-accf-991868186c52
:DRILL_LAST_INTERVAL: 5.3678
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-30 Sat 18:41]
:END:

Prove that $(A^B)^C \cong A^{(B \times C)}$ in any cartesian category using the
Yoneda lemma.

******* Answer
It is full and faithful, so we only have to show that $y((A^B)^C) \cong y(A^{(B \times C)})$.

The following is a chain of natural isomorphisms given by adjunctions
and commutativity.

\[\begin{aligned}
\mathrm{hom}(X,(A^B)^{C})
&\cong \mathrm{hom}(X \times C,A^B) \\
&\cong \mathrm{hom}((X \times C) \times B,A) \\
&\cong \mathrm{hom}(X \times (C \times B),A) \\
&\cong \mathrm{hom}(X, A^{B \times C}) \\
\end{aligned}\]

***** 8.5 Limits in categories of diagrams
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (177 . 0.5978817902289033)
:END:

****** Presheaf categories are complete                                                           :drill:presheaf:
SCHEDULED: <2018-07-04 Wed>
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (177 . 0.7413734198838401)
:ID:       887fd9dc-cff2-473b-aef6-25ed2c15cb87
:DRILL_LAST_INTERVAL: 3.677
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-30 Sat 18:43]
:END:
Existence of limits on presheaf categories.

******* Answer
For any small $\mathbb{C}$, the category $\mathsf{Sets}^{\mathbb{C}^{op}}$ is complete; it has all small limits.
Moreover, the evaluation functor $\mathrm{ev}_C \colon \mathsf{Sets}^{\mathbb{C}^{op}} \to \mathsf{Sets}$ is preserves all limits.

***** 8.8 Topoi
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (184 . 0.29894089511445165)
:END:

****** 8.17. Categories of diagrams are topoi                                                              :drill:
SCHEDULED: <2018-07-05 Thu>
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (185 . 0.37068670994192005)
:ID:       122fd7e7-8879-47d0-98b7-e0242e3b6e45
:DRILL_LAST_INTERVAL: 5.3361
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-30 Sat 18:41]
:END:

Relation between presheaf categories and topoi.

******* Answer
For any small $\mathbb{C}$, the category $\mathsf{Sets}^{\mathbb{C}^{op}}$ is a topos.
*** Category theory foundations talk - Awodey
Following this [[https://www.youtube.com/playlist?list=PLGCr8P_YncjVjwAxrifKgcQYtbZ3zuPlb][video series]].

**** Category theory foundations 1.0
Category theory is the abstract algebra of abstract functions.

***** Functions on sets
In set theory, a function $f \colon A \to B$ is a subset of the cartesian
product $f \subset A \times B$, such that for all $a \in A$, there exists a unique
$b \in B$ such that $f(a) = b$.

Composition of functions is distributive and it has an identity.
Categories arise as an abstraction of this setting.

***** Definition of category
A category is defined by a class of objects and a class of arrows.
A distributive composition with identity. The axioms of a category
are the distributivity and the identity as a neutral element.
***** Isomorphisms
***** Examples
****** Finite categories
****** Posets
****** Monoids
****** Category of all posets
****** Relations on sets
****** Category of proofs
The objects are logic formulas and arrows are deductions on the formal
system, from the assumptions to the conclusions, that can be composed.
**** Category theory foundations 1.1
***** Constructions on categories
****** Product category
****** Arrow category
${\cal C}^{\to}$, where objects are arrows on ${\cal C}$ and arrows
are commutative squares.
****** Slice category
******* Cat, the category of categories
***** Functors
Preserve all the structure of a category.

****** Exponential functor on sets
Fix an object $A$, then $B \mapsto B^{A}$ is a functor on sets.

***** Duality
****** Contravariant functors
******* Example: Hom-Functors
***** Hom-sets
Assuming ${\cal C}$ small, $\mathrm{hom}(A,B)$ is the set of arrows from $A$ to $B$. If we fix $A$,
we get a functor $\mathrm{hom}(A,-)$; if we fix $B$, we get a contravariant functor $\mathrm{hom}(-,B)$.

**** Category theory foundations 1.2
***** Representable functors
A functor is representable if it can be written as an hom-set.

The currying of the $Hom$ functor is the Yoneda embedding. (!)

**** Category theory foundations 2.0
***** Universal mappings
****** Products (MacLane, 1949)
Products on categories, on posets...
****** Coproducts and duality
****** Exponentials
Suppose we have all products. An exponential for $A,B$ is
an object $B^{A}$ such that

\[\begin{tikzcd}
B^{A} & B^{A} \rar{e} \times A & B \\
X \uar[dashed]{\exists! f} & X \times A \uar{f \times 1} \urar[swap]{g} &
\end{tikzcd}\]

**** Category theory foundations 2.1
In groups, the homomorphisms are not an exponential. Groupoids are!
They form a cartesian closed category.

***** Cartesian closed category
A category is *cartesian closed* if it has

  * all products.
  * all exponentials.
  * the terminal object.
 
***** Adjunction Product-Exponential
Observe that the universal mapping property of the exponent
implies that every time we have a map like $X \times A \to B$,
we can define $X \to B^{A}$. It exactly says that the two functors
are adjoints.

***** Universal properties as rules of inference
Universal properties are like rules of inference

  * Product

    \begin{prooftree}
    \AxiomC{$X \to A$}
    \AxiomC{$X \to B$}
    \BinaryInfC{$X \to A \times  B$}
    \end{prooftree}

  * Coproduct

    \begin{prooftree}
    \AxiomC{$A \to X$}
    \AxiomC{$B \to X$}
    \BinaryInfC{$A + B \to X$}
    \end{prooftree}

  * Exponential

    \begin{prooftree}
    \AxiomC{$X \times A \to B$}
    \UnaryInfC{$X \to B^A$}
    \end{prooftree}

In the case where $X=1$, we get a particular case of the inference rules.

***** Exponentials in a poset
Exponentials in a poset are implications on intuitionistic
propositional calculus. Rules of logic can be written as universal
properties.

****** Proof relation
A natural deduction logic is a category where deductions are morphisms
and propositions are objects. We can prove the adjunction on the rules.

****** Category of proofs
If we take the category of proofs, we get the lambda calculus.
This is a richer structure.

This is called *category of types* or *category of proofs*.

**** Category theory foundations 2.2
***** Category of types on \lambda-calculus is CCC
To make this a CCC, we need to identify certain proofs. We have to identify
some proofs to make this a CCC

  * $\mathrm{fst}(a,b) = a$
  * $\mathrm{snd}(a,b) = b$
  * $(\lambda x.b)a = b[a/x]$

This is simplification of proofs. 

***** Theory in the \lambda-calculus
We have some basic types $A,B,\dots$, basic terms $a:X,b:Y,\dots$ and equations
between terms of the same type. That defines a theory.

You could formulate the theory of groups or any algebraic theory in
this way as a lambda theory. The theory of the reflexive domain is an
example of higher order theory that can be formulated as a lambda theory.

We can then define a model of such a theory in a CCC as an assignment of
objects to basic types and morphisms as functions.

  * $\llbracket A \rrbracket \in {\cal C}$, for any basic type
  * $\bbk{a} \colon 1 \to \bbk{X}$, for any basic term

and it can be extended to all terms as

  * $\bbk{t} \colon 1 \to A$, for any term $t \colon A$,
  * in particular, $f \colon A \to B$, $\bbk{f} \colon \bbk{A} \to \bbk{B}$.

That is, you can interpret this on any algebraic theory and a model of that
theory will arise.

***** Completeness theorem of CCC for \lambda-calculus
For any theory $\mathbb{T}$ in \lambda-calculus

  1) for any closed terms $a,b\colon X$, $\mathbb{T} \vdash a = b$ if and only if $\bbk{a} = \bbk{b}$ in
     any CCC.
  2) there exists a closed term $t : X$ if and only if in every $\mathbb{T}$ model of in 
     a CCC, $1 \to \bbk{X}$.


This says that lambda calculus is really equivalent to the notion of a CCC.
\[
\lambda^{x,\to} \simeq CCC
\]

Propositional logic itself is exactly equivalent to the notion of a CCC Poset.
If we add the disjunction, we get a Heyting algebra.

Kripke models are a specialization to some special cartesian closed categories.

**** Category theory foundations 3.0
***** Arithmetic on a Cartesian Closed Category
All the usual arithmetic can be expressed on cartesian closed categories.
***** Lambda calculus with sums on a CCC
Lambda calculus with sums can be expressed on a CCC with coproducts and
you can use it to prove equations on a CCC because of its soundness.
***** Natural transformation
Represents the concept of a morphism independent of the choice
of objects. This is the notion of parametricity or uniformity.
****** Definition of natural transformation
****** Example of naturality: sets through time
Discrete time parametrized on the natural numbers. A function
between two sets through time should be a natural transformation
between the indexed family of sets.

If we see $\omega$ as the natural preorder, the category of sets through
time is $\mathtt{Set}^{\omega}$, the category of functors from $\omega$ to $\mathtt{Set}$.

***** Definition of functor categories
****** Functor categories make Cat a CCC
****** Example: the arrow category
Can be seen as a functor category from a category with only
one morphism to the base category.
****** Example: product category
$\mathbb{C}^2 \cong \mathbb{C} \times \mathbb{C}$ where $2$ is a discrete category of two objects.
****** Example: graph category
****** Example: simplicial sets
**** Category theory foundations 3.1
***** The Yoneda embedding
Presheaves of the form $\mathtt{Sets}^{{\cal C}^{op}}$. If we assume ${\cal C}$ locally small, the functor
hom can be defined. The functor $\mathrm{Hom}$ can be curried to get a functor
$y \colon {\cal C} \to \mathtt{Sets}^{{\cal C}^{op}}$.

This functor takes a morphism to a natural transformation between two functors.
***** Yoneda Lemma
Given any $c \in {\cal C}$ and $F \colon {\cal C}^{op}\to \mathtt{Sets}$, there is an isomorphism
\[
\mathrm{Hom}(yC,F) \cong FC.
\]

****** Proof of the Yoneda Lemma

****** Corollary
The isomorphism is natural on both arguments.

****** Utility of Yoneda
The category $\mathtt{Sets}^{{\cal C}^{op}}$ is a topos, has a nice logical structure; while the
category was ${\cal C}$ any category. If the Yoneda embedding preserves the structure,
that gives us a nice structure on ${\cal C}$.

***** Examples of usage of the Yoneda Lemma
****** Product
Propositionally, the universal mapping property of the product
can be written as

\begin{prooftree}
\AxiomC{$X \to A$}
\AxiomC{$X \to B$}
\doubleLine
\BinaryInfC{$X \to A \times  B$}
\end{prooftree}

but this rule of inference goes both ways. And this is also a
bijection between the two sides;

\[
\mathrm{hom}(X,A) \times \mathrm{hom}(X,B) \cong \mathrm{hom}(X, A \times B).
\]

****** Example
Consider $\mathrm{hom}(X,-)$ and apply it to the product diagram.
We get

\[\begin{tikzcd}
& \mathrm{hom}(X,A \times B) \drar\dlar\dar[dashed]{\cong} & \\
\mathrm{hom}(X,A) & \mathrm{hom}(X,A) \times \mathrm{hom}(X,B) \lar{\pi}\rar{\pi} & \mathrm{hom}(X,B)
\end{tikzcd}\]

The universal properties can be expressed using hom-sets.

****** Claim
$yC \cong yD \implies C \cong D$

We can prove some equations using this technique.

\[
y({\cal C}^{A+B}) \cong y({\cal C}^A \times {\cal C}^B)
\]

******* Proof
$\mathrm{hom}(X\times (A+B), C) \cong \mathrm{hom}(X \times A,C) \times \mathrm{hom}(X \times B,C)$

This reduces the proof of ${\cal C}^{A+B} \cong {\cal C}^A \times {\cal C}^B$ to a much simpler algebraic
manipulation.

**** Category theory foundations 3.2
***** Laws in any CCC
Products distribute over coproducts. Exponentials make products distribute
over coproducts.

****** Proof
Using Yoneda.

****** Yoneda embedding preserves all the cartesian closed structure

**** Category theory foundations 4.0
***** Sets^C^op is a cartesian closed category
They are some kind of "variable sets"; sets that vary on a parameter
coming from the index category. These things have products and coproducts
defined pointwise. Exponentials could be also defined pointwise, but it has
a covariant and a contravariant component, so it is not useful to get a
definition of exponentials on morphisms. This does not work for exponentials.

***** Yoneda to the rescue
We are trying to define a functor $B^A(X)$. If it exists, it has to be like
\[
B^A(X) \cong \mathrm{hom}(yX,B^{A}) \cong \mathrm{hom}(yX \times A, B).
\]

If we take this as the definition, $\mathrm{hom}(y- \times A,B)$ is a contravariant
function.

****** Corollary
As a corollary, $y \colon {\cal C} \to \mathtt{Set}^{{\cal C}^{op}}$ preserves CC structure.

******* Proof
We can prove using Yoneda lemma that $y(B^A) = y(B)^{y(A)}$.

***** Completeness of \lambda-calculus
Every cartesian closed category can be embedded into a $\mathtt{Sets}^{{\cal C}^{op}}$.

#+begin_theorem
Completeness of \lambda-calculus with respect to variable sets.
Given any \lambda theory $\mathbb{T}$, and $s,t {:} X$
\[
\mathbb{T} \vdash s=t \iff \text{ for any interpretation}, \bbk{s} = \bbk{t}
\]

There is a $t \colon X$ iff in every model $\bbk{t} \colon 1 \to \bbk{X}$.
#+end_theorem

***** Awodey's Theorem
Kripke completeness.

#+begin_theorem
The same thing happens to respect to $\mathtt{Sets}^{P}$, where $P$ is a poset.
#+end_theorem

***** Adjointness
The following are examples of adjoints

  1. Products
  2. Exponentials
  3. Coproduct
  4. Induction
  5. Recursion
  6. Natural numbers
  7. Inductively defined types
  8. Logical connectives
  9. Quantifiers
  10. Sigma and Pi types

****** Product-exponential
The functors $F(X) = X \times A$ and $G(X) = Y^{A}$ are adjoints. There is a natural
isomorphism between $\mathrm{hom}(X \times A,Y) \cong \mathrm{hom}(X,Y^{A})$.

****** Product-diagonal
\[
\mathtt{hom}((X,X), (A,B)) \cong \mathtt{hom}(X,A \times B)
\]

****** Chain of adjoints

\[ + \dashv \Delta \dashv \times \dashv \mathrm{exp}
\]

**** Category theory foundations 4.1
***** Uniqueness of adjoints
Every universal property and every adjoint determine an object up
to isomorphism. Adjoints are unique up to isomorphism.

****** Proof of the uniqueness of adjoints
Using the Yoneda Lemma

***** Unit and counit of and adjunction
****** Example: product-exponent
Evaluation is the counit.
****** Example: diagonal-product
The diagonal map is the unit.
***** Example: adjoints in logic
In Propositional calculus, conjunction is an adjoint.
Entailment is reflexive and transitive, so proofs form a category.

\begin{prooftree}
\AxiomC{$\theta \vdash \varphi$}
\AxiomC{$\theta \vdash \rho$}
\doubleLine
\BinaryInfC{$\theta \vdash \varphi \times \rho$}
\end{prooftree}

\begin{prooftree}
\AxiomC{$\varphi \vdash \theta$}
\AxiomC{$\rho \vdash \theta$}
\doubleLine
\BinaryInfC{$\rho + \varphi \vdash \theta$}
\end{prooftree}

Terminal and initial objects can be written as adjoints. Implications
can be written as adjoints. This work is due to Lawvere. 

/Adjointness in Foundations/, W. Lawvere.

***** Example: quantifiers
We will write formulas with individual variables; and we build up formulas
involving some variables in the usual way. We have a deduction system with
entailment and rules of inference.

There is an operation of adding a new variable to a context. If I have,
\[
x_1,\dots,x_n \vdash \varphi(x_1,\dots,x_n),
\]

I can get
\[
x_1,\dots,x_n,y \vdash \varphi(x_1,\dots,x_n) \vdash \psi(x_1,\dots,x_n,y).
\]


This operation has adjoints. Its right adjoint is $\ast \vdash \forall$

\begin{prooftree}
\AxiomC{$^{y\text{ in context}}\varphi(x_1,\dots,x_n) \vdash \psi(x_1,\dots,x_n,y)$}
\doubleLine
\UnaryInfC{$\varphi(x_1,\dots,x_n) \vdash \forall_y \psi(x_1,\dots,x_n,y)$} 
\end{prooftree}

and its left adjoint is $\exists \vdash \ast$

\begin{prooftree}
\AxiomC{$\varphi(x_1,\dots,x_n,y) \vdash ^{y\text{ in context}}\psi(x_1,\dots,x_n)$}
\doubleLine
\UnaryInfC{$\exists_y\varphi(x_1,\dots,x_n) \vdash \psi(x_1,\dots,x_n,y)$} 
\end{prooftree}

Unit and counit look like provable formulas.

***** Proof theory of first order logic
The proof theory of propositional logic was the lambda calculus. The proof
theory of first order logic is dependent type theory (??).

****** Propositional logic

\begin{tabular}{c|c|c}
Propositional logic & Provability & Proof/type theory \\
\hline
Logical Point of view & Intuitionistic PL $\wedge,\vee$ & STLC with simple types $\times,+$ \\
CT & Poset CCC / Heyting algebra & CCC with sums \\
\hline
& Poset & Category
\end{tabular}

****** First order logic

\begin{tabular}{c|cc}
FOL & Provability & Proof/type theory \\
\hline
Logic & Intuitionistic FOL $\forall,\exists$ & Dependent Type theory $\Pi,\Sigma$ \\
CT & Heyting category & Locally cartesian closed category \\
\hline
& Poset & Category
\end{tabular}

A locally cartesian closed category is a category such that any slice is CCC.

****** Yoneda and CCC
If ${\cal C}$ is a CCC, the Yoneda embedding is also cartesian closed. It preserves the
interpretation of dependent type structure of a category.

We have the same Kripke completeness theorem for the full system of Martin-Lof
type theory.

*** The Catsters
**** Adjunctions
Serie de [[https://www.youtube.com/playlist?list=PL54B49729E5102248][vídeos]] sobre funtores adjuntos.

***** Adjuntions 1
Tenemos varias nociones de igualdad entre categorías.

#+begin_definition
*Isomorfismo de categorías*. Ocurre con dos functores:

\[ \begin{tikzcd}
{\cal C} \arrow[bend left]{r}{F} & {\cal D} \arrow[bend left]{l}{G}
\end{tikzcd}
\]

Tales que $1_C = GF$ y $FG = 1_D$.
#+end_definition

#+begin_definition
*Equivalencia de categorías*. Ocurre con dos functores:

\[ \begin{tikzcd}
{\cal C} \arrow[bend left]{r}{F} & {\cal D} \arrow[bend left]{l}{G}
\end{tikzcd}
\]

Tales que $1_C \cong GF$ y $FG \cong 1_D$. Entendiendo la isomorfía en la 
categoría de funtores, es decir, una [[https://ncatlab.org/nlab/show/natural+isomorphism][isomorfía natural]].
#+end_definition

#+begin_definition
*Adjunción*. Ocurre con dos functores:

\[ \begin{tikzcd}
{\cal C} \arrow[bend left]{r}{F} & {\cal D} \arrow[bend left]{l}{G}
\end{tikzcd}
\]

Tales que tenemos transformaciones naturales $1_C \overset{\eta}\Longrightarrow GF$ y 
$FG \overset{\epsilon}\Longrightarrow 1_D$ que cumplen las dos identidades triangulares siguientes:
 
\[ \begin{tikzcd}
F \arrow{r}{\eta} \arrow{dr}{id} & FGF \arrow{d}{\epsilon} \\
 & F
\end{tikzcd}   
\]     \[ \begin{tikzcd}
G \arrow{r}{\eta} \arrow{dr}{id} & GFG \arrow{d}{\epsilon} \\
 & G
\end{tikzcd}
\]
#+end_definition

En este caso escribimos $F \dashv G$, y $F$ es funtor adjunto de $G$.

***** Adjuntions 2
Damos una definición equivalente de funtores adjuntos.

#+begin_definition
*Adjunción*. Una adjunción es un isomorfismo natural:

\[Hom_D(FX,Y) \cong Hom_C(X,GY)\]

Natural sobre $X$ fijado cualquier $Y$ y natural sobre $Y$ fijado 
cualquier $X$. Entendiendo que usamos los funtores contravariantes $Hom(F-,Y)$,
$Hom(-,GY)$ por un lado y los funtores covariantes $Hom(FX,-)$ y $Hom(X,G-)$;
que nos dan los siguientes cuadrados de naturalidad:

\[ \begin{tikzcd}
Hom_D(FX',Y) \arrow{d}[swap]{Hom_D(Ff,Y)} \arrow{r}{\alpha_{X'}} & Hom_C(X',GY) \arrow{d}{Hom_C(f,GY)}\\
Hom_D(FX, Y) \arrow{r}{\alpha_{X}}& Hom_C(X,GY)
\end{tikzcd}
\] 

\[ \begin{tikzcd}
Hom_D(FX,Y) \arrow{d}[swap]{Hom_D(FX,g)} \arrow{r}{\beta_{Y}} & Hom_C(X,GY) \arrow{d}{Hom_C(X,Gf)}\\
Hom_D(FX,Y') \arrow{r}{\beta_{Y'}}& Hom_C(X,GY')
\end{tikzcd}
\] 
#+end_definition

Esta definición es equivalente intuitivamente a la anterior porque
podemos crear $\eta$ y $\epsilon$ desde las identidades usando las
siguientes transformaciones naturales:

\[Hom_D(FX,FX) \cong Hom_C(X,GFX)\]

\[Hom_D(FGY,Y) \cong Hom_C(GY,GY)\]

***** Adjuntions 3
Podemos presentar ejemplos de adjunciones.
Los *funtores libres y de olvido* suelen ser adjuntos. Entre $Set$ y $Monoid$ tenemos:

\[ \begin{tikzcd}
{Set} \arrow[bend left]{r}{Free} & {Monoid} \arrow[bend left]{l}{Forget}
\end{tikzcd}
\]

Con la adjunción $Free \dashv Forget$. 

#+begin_theorem
*Mónada de una adjunción*. Cada adjunción da lugar a una mónada.
#+end_theorem

Tenemos un funtor $T = GF : {\cal C}  \longrightarrow {\cal C}$. Podemos definir la unidad de
la mónada como la unidad de la adjunción $\eta : 1_C \Longrightarrow T$ y la
multiplicación podemos definirla usando $id \ast \epsilon \ast id : GFGF \Longrightarrow GF$.

Ahora debemos comprobar que cumple los axiomas de mónada. El primero
se obtiene directamente desde los triángulos de la adjunción:

\[ \begin{tikzcd}
T \arrow{r}{T\eta} \arrow{dr}{id} & T^2 \arrow{d}{\mu} \\
 & T
\end{tikzcd}   
\]   \[ \begin{tikzcd}
GF \arrow{r}{GF\eta} \arrow{dr}{id} & GFGF \arrow{d}{G \epsilon F} \\
 & GF
\end{tikzcd}   
\]

Donde el segundo es resultado de aplicar el funtor $G$ a uno de los triángulos conmutativos
de la adjunción. Comprobamos el segundo axioma:

\[ \begin{tikzcd}
T^2 \arrow{d}{\mu} & T \arrow{dl}{id} \arrow{l}[swap]{\eta T} \\
T
\end{tikzcd}   
\]   \[ \begin{tikzcd}
GFGF \arrow{d}{G \epsilon F} & GF \arrow{dl}{id} \arrow{l}[swap]{\eta GF} \\
GF
\end{tikzcd}   
\]

Donde tenemos el resultado de aplicar $F$ por la derecha al otro triángulo conmutativo.

Y finalmente el axioma de conmutatividad de la mónada se comprueba como:

\[ \begin{tikzcd}
T^3 \arrow{d}{T \mu} \arrow{r}{\mu T} & T^2 \arrow{d}{\mu} \\
T^2 \arrow{r}{\mu} & T
\end{tikzcd} \]  \[ \begin{tikzcd}
GFGFGF \arrow{d}{GFG \epsilon F} \arrow{r}{G \epsilon FGF} & GFGF \arrow{d}{G\epsilon F} \\
GFGF \arrow{r}{G \epsilon F} & GF
\end{tikzcd} \] 

Donde el segundo diagrama se obtiene desde la naturalidad de $\epsilon$ aplicando funtores.

***** Adjuntions 4
Vamos a probar la igualdad entre las dos definiciones de adjunción.
Supongamos primero que tenemos el isomorfismo natural entre los dos 
conjuntos de morfismos, es decir, tenemos:

\[ (-) : Hom_D(FX,Y) \cong Hom_C(X,GY) \]

Si tomamos ahora los dos cuadrados naturales que teníamos por este 
isomorfismo y tomamos en ellos los casos particulares $Y = FX$ primero,
y $X = GY$ después:

\[ \begin{tikzcd}
Hom_D(FX,FX) \arrow{d}[swap]{\_ \circ Ff} \arrow{r}{(-)} & Hom_C(X,GFX) \arrow{d}{\_\circ f}\\
Hom_D(FX', FX) \arrow{r}{(-)}& Hom_C(X',GFX)
\end{tikzcd}
\]

Si tomamos la identidad $1_{FX}$ y llamamos $\eta_X = \overline{1_{FX}}$, tenemos que
\(\eta \circ f = \overline{Ff}\). Ahora, si damos la vuelta al isomorfismo $(-)$ en este 
diagrama a la vez que hacemos $X = GY$:

\[ \begin{tikzcd}
Hom_D(FGY,Y) \arrow{d}[swap]{\_ \circ Ff}  & Hom_C(GY,GY) \arrow{l}[swap]{(-)} \arrow{d}{\_\circ f}\\
Hom_D(FGY',Y) & Hom_C(GY',GY) \arrow{l}[swap]{(-)}
\end{tikzcd}
\]

Volviendo a tomar la identidad $1_{GY}$ y llamando $\epsilon_Y = \overline{1_{GY}}$, tenemos
$\epsilon \circ Ff = \overline{f}$.

Ahora tomamos el segundo cuadrado natural, y repetimos el mismo
proceso.

\[ \begin{tikzcd}
Hom_D(FX,FX) \arrow{d}[swap]{g \circ \_} \arrow{r}{(-)} & Hom_C(X,GFX) \arrow{d}{Gg\circ \_}\\
Hom_D(FX,FX') \arrow{r}{(-)}& Hom_C(X,GFX')
\end{tikzcd}
\] 

Obteniendo desde la identidad en $FX$ la ecuación $\overline{g} = Gg \circ \eta$. Y volviendo
a dar la vuelta a los isomorfimos llegamos a:

\[ \begin{tikzcd}
Hom_D(FGY,Y) \arrow{d}[swap]{g \circ \_}  & Hom_C(GY,GY) \arrow{l}[swap]{(-)} \arrow{d}{Gg \circ \_}\\
Hom_D(FGY,Y') & \arrow{l}[swap]{(-)} Hom_C(GY,GY')
\end{tikzcd}
\]

Obteniendo finalmente $\overline{Gg} = g \circ \epsilon$. De este proceso hemos obtenido finalmente
las siguientes ecuaciones:

\[ \begin{aligned}
\eta \circ f &= \overline{Ff} \\
\epsilon \circ Ff &= \overline{f} \\
Gg \circ \eta &= \overline{g} \\
g \circ  \epsilon &= \overline{Gg} 
\end{aligned} \]

Con ellas podemos probar la naturalidad de $\eta$ y la naturalidad de
$\epsilon$:

\[ \begin{tikzcd}
GFX  \arrow{r}{GFf} & GFY \\
X \arrow{u}[swap]{\eta_X} \arrow{r}[swap]{f} & Y \arrow{u}{\eta_Y}
\end{tikzcd}
\]   \[ \begin{tikzcd}
FGX \arrow{d}[swap]{\epsilon_X} \arrow{r}{FGg} & FGY \arrow{d}{\epsilon_Y}\\
X \arrow{r}[swap]{g} & Y
\end{tikzcd}
\]

Ya que $\eta \circ f = \overline{Ff} = GFf \circ \eta$ y $f \circ \epsilon = \overline{Gf} = \epsilon \circ FGf$. Y además podemos probar
los dos triángulos de naturalidad.

\[ \begin{tikzcd}
F \arrow{r}{F \eta_X} \arrow{dr}{id} & FGF \arrow{d}{\epsilon_{FX}} \\
 & F
\end{tikzcd}   
\]     \[ \begin{tikzcd}
G \arrow{r}{\eta_{GX}} \arrow{dr}{id} & GFG \arrow{d}{G\epsilon_X} \\
 & G
\end{tikzcd}
\]

Teniendo finalmente que:

\[ \begin{aligned}
\epsilon \circ F\eta &= \overline{\eta} = 1 \\
G\epsilon \circ \eta &= \overline{\epsilon} = 1
\end{aligned} \]

El otro sentido de la demostración se tiene llegando primero a las
cuatro ecuaciones, y usándolas para definir el isomorfismo
$(-)$. Falta entonces demostrar su naturalidad.

*** What is an Operad? Part I - Math3ma ([[http://www.math3ma.com/mathema/2017/10/23/what-is-an-operad-part-1][link]])
An *operad* is a sequence ${\cal O}(1),{\cal O}(2),\dots$ together with compositions

\[
\circ_i \colon {\cal O}(n) \times {\cal O}(m) \to {\cal O}(m+n-1)
\]

satisfying that

 1. /composition is associative/; for each $f \in {\cal O}(n), g \in {\cal O}(m), h \in {\cal O}(p)$,

    \[
    (f \circ_j g) \circ_i h = \left\{\begin{array}{ll}
    (f \circ_i h) \circ_{j+p-1} g & \mbox{ if } 1 \leq i \leq j-1 \\
    f \circ_j (g \circ_{i-j+1} h) & \mbox{ if } j \leq i \leq n+j-1 \\
    (f \circ_{i-m+1} h) \circ_{j} g & \mbox{ if } i \geq n+j \\
    \end{array}\right.
    \]

 2. /arguments can be permuted/; for each ${\cal O}(n)$, we have an action of the
    symmetric group $S_n$ on the operations, $S_n \times {\cal O}(n) \to {\cal O}(n)$ such that
    for all $f \in {\cal O}(n)$, $g \in {\cal O}(m)$, and for all $\sigma \in S_n$, $\tau \in S_m$,

    \[
    \sigma f \circ_i \tau g = (\sigma \circ_i \tau)(f \circ_i g)
    \]

 3. /there exists a unit/; $1 \in {\cal O}(1)$ such that for every $n$ and every $f \in {\cal O}(n)$,
    we have $1 \circ_1 f = f \circ_i 1 = f$.

We are defining operads over sets, but we could define them over a
different category and ask $\circ_i$ and $S_n$ to be endomorphisms of
the category.

**** Operad axioms                                                                                           :drill:
SCHEDULED: <2018-07-04 Wed>
:PROPERTIES:
:ID:       b74b26b5-d74c-46c5-8c2e-7a08d7d1201e
:DRILL_LAST_INTERVAL: 4.1325
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-30 Sat 11:58]
:END:
Definition of operad. Axioms for defining an operad.

***** Answer
An *operad* is a sequence ${\cal O}(1),{\cal O}(2),\dots$ together with compositions

\[
\circ_i \colon {\cal O}(n) \times {\cal O}(m) \to {\cal O}(m+n-1)
\]

satisfying that

 1. composition is associative,
 2. arguments can be permuted,
 3. there exists a unit.
**** Endomorphism operad                                                                                     :drill:
SCHEDULED: <2018-07-04 Wed>
:PROPERTIES:
:ID:       f7950629-51ba-4655-a2ab-705532a9e002
:DRILL_LAST_INTERVAL: 4.6732
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 5.0
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-29 Fri 22:19]
:END:
What is an example of an operad?

***** Answer
The endomorphism operad over a vector space $V$, with ${\cal O}(n) = \mathrm{hom}(V^n,V)$.

**** Algebra over an operad                                                                                  :drill:
SCHEDULED: <2018-07-03 Tue>
:PROPERTIES:
:ID:       9d225db0-ce9b-44a2-ac3e-e16fcf194dbe
:DRILL_LAST_INTERVAL: 4.3932
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-29 Fri 22:15]
:END:
Definition of algebra over an operad.

***** Answer
Given a vector space $V$, an *O-algebra* is an assignment $\varphi_n \colon {\cal O}(n) \to \mathrm{End}_{V}(n)$
compatible with $\circ_i$ and $S_n$, compositions and permutations of arguments.

*** What is an Operad? Part II - Math3ma ([[http://www.math3ma.com/mathema/2017/10/30/what-is-an-operad-part-2][link]])
**** Associative operad                                                                                      :drill:
SCHEDULED: <2018-07-03 Tue>
:PROPERTIES:
:ID:       9f18443b-0ce6-4a15-b3af-987d37d4affd
:DRILL_LAST_INTERVAL: 4.3754
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 5.0
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-29 Fri 22:31]
:END:
Definition of the associative operad.

***** Answer
Given $V$ a vector space over a field $k$, we define $\mathsf{Assoc}(n)$ as the 1-dimensional
vector space generated by a tree with $n$ leaves. The associative operad is given
by the only possible linear composition and the obvious identity.

**** Algebra over the associative operad                                                                     :drill:
SCHEDULED: <2018-07-04 Wed>
:PROPERTIES:
:ID:       6c04a468-3844-49d1-808c-4c82cc693453
:DRILL_LAST_INTERVAL: 5.1672
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 5.0
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-29 Fri 22:25]
:END:
What name receives an algebra over the associative operad?

***** Answer
It is determined by compatibility and the image of $\varphi(\mathsf{Y})$, the image of the only
2-to-1 operation.  If we write $\varphi(\mathsf{Y})$ as multiplication, by compatibility, we have

\[
(v_1 \cdot v_2) \cdot v_3 = v_1 \cdot (v_2 \cdot v_3),
\]

an *associative algebra*.

***** Extra
If we consider the symmetric group action to be trivial, we have $v_1 \cdot v_2 = v_2 \cdot v_{1}$,
a *commutative algebra*.
**** [[https://www.youtube.com/watch?v=N7wNWQ4aTLQ&t=][Associahedra: the shapes of multiplication - Infinite Series]]
**** TODO Associahedra operad
**** TODO The little k-cubes operad
**** TODO The simplex operad

** Categorical logic                                                                                :categories:logic:
*** Sheaves in geometry and logic - MacLane, Moerdijk
:PROPERTIES:
:INTERLEAVE_PDF: ~/pdf/mac_lane_moerdijk_sheaves_in_geometry_and_logic.pdf
:END:
**** Old notes
***** IV. First properties of Elementary topoi
****** IV.1. Definition of a topos
******* Elementary topos
******** Definition
A *topos* ${\cal E}$ is a category with

  * an object $\Omega$, called the *subobject classifier*;
  * a function ${\cal P}$ on objects, called the *powerset*;
  * two natural isomorphisms $\mathrm{Sub}_{{\cal E}}A \cong \mathrm{hom}_{{\cal E}}(A,\Omega)$ and
    $\mathrm{hom}_{{\cal E}}(B \times A,\Omega) \cong \mathrm{hom}_{{\cal E}}(A,{\cal P}B)$.
******** Alternative definition
A *topos* is a category with finite limits and a function on its
objects ${\cal P}$ such that

\[
\mathrm{Sub}_{{\cal E}}(B \times A) \cong \mathrm{Hom}_{{\cal E}}(A,{\cal P}B)
\]

is an natural isomorphism in $A$.

******** Definition: Elementary form
A *topos* is a category ${\cal E}$ such that

  1) pullbacks exist for every diagram of the form

     \[\begin{tikzcd}[column sep=small, row sep=small]
     X \drar  & & Y\dlar \\
        & B &
     \end{tikzcd}\]

  2) it has a terminal object $1$;

  3) it has a *subobject classifier* $\Omega$ with a monic arrow $\mathtt{true} \colon 1 \to \Omega$ such that
     for every monomorphism $m \colon S \to B$, there is a unique arrow $\mathrm{char}\ m$, called
     the *classifying map* of $m$ such that the following diagram is a pullback

     \[\begin{tikzcd}
     S \dar[swap]{m}\rar & 1 \dar{\mathrm{true}} \\
     B \rar[swap]{\mathrm{char}\ m} & \Omega
     \end{tikzcd}\]

  4) it has a function on objects ${\cal P}$ and an morphism $\in_B\colon B \times {\cal P}B \to \Omega$ such
     that for every $f \colon B \times A \to \Omega$, an unique $g \colon A \to {\cal P}B$ making the following
     diagram commute

     \[\begin{tikzcd}[row sep=small]
     A \ar[dashed]{dd}{g} & B \times A \drar{f}\ar[dashed,swap]{dd}{1 \times g} \\
     & & \Omega \\
     {\cal P}B & B \times {\cal P}B \urar[swap]{\in_B} &
     \end{tikzcd}\]

# Membership map is dinatural in B.

******* Generalized elements
******** Generalized and global elements
An arrow $b \colon X \to B$ is a *generalized element* of $B$ defined over $X$. The generalized
elements defined over the terminal object $1$ are the *global elements* of $B$.

******** Predicate
A morphism $\theta \colon B \to \Omega$ is called a *predicate*.

******** Subobjects
A subobject of $A$ has the following three descriptions

  1) $m \colon S \to A$ monomorphism, as an equivalence class of monics;

  2) $\phi\colon A \to \Omega$, as a predicate;

  3) $s \colon 1 \to {\cal P}A$, as a global element of the powerset.

we call $S = \left\{ a \mid \phi \right\}$ the *extension* of $\phi$; $\phi = \mathrm{char}\ S$ the *characteristic function*
of $S$ and $s = \lceil\phi\rceil$ the *name* of $\phi$.

******** Kronecker delta

******** Monicity of the transpose of the Kronecker delta
For all objects $B$ in a topos, $\left\{ \cdot \right\}$ is monic.

******** Bimorphisms are isomorphisms in a topos
In a topos, every monomorphism is an equalizer and every bimorphism
is an isomorphism.

******* Exponentials
******** Every topos is cartesian closed
Every topos has exponentials.

****** IV.8. Lattice and Heyting algebra objects in a topos
******* Internal lattice
An internal lattice in a category is an object $L$ with morphisms
\[
\bigwedge \colon L \times L \to L,
\qquad
\bigvee \colon L \times L \to L
\]

and commutative diagrams expressint the identities of a lattice

  * associativity,
  * commutativity,
  * idempotent laws,
  * absorption law.

Such a lattice object has a zero and a one if there are arrows
\[
\top \colon 1 \to L,
\qquad
\bot \colon 1 \to L,
\]
with the appropiate identities.

******* Internal Heyting algebra
Exists an implication $\Rightarrow \colon L \times L \to L$ satisfiying the diagrammatic version
of the identities of the implication.

******* Partial order on an internal lattice
We can define a subobject $\leq_L$ on the category as the following equalizer
\[\begin{tikzcd}
\leq_{L}\rar & 
L \times L \rar[shift left=.75ex]{\wedge}\rar[swap,shift right=.75ex]{\pi_1} & 
L.
\end{tikzcd}\]

******** Equivalent definition of internal Heyting algebra

******* External Heyting algebra
Given $A$ in a topos ${\cal E}$, $\mathrm{Sub}\ A$ is a Heyting algebra. The structure
is natural in $A$, in the sense that the pullback along any morphism
$k\colon A \to B$ induces a map $k^{-1}$ of Heyting algebras.

******** TODO Proof
******* Internal Heyting algebra
Given $A$ in a topos ${\cal E}$, ${\cal P}A$ is an internal Heyting algebra. Th structure
is natural in $A$, in the sense that that the any morphism $k\colon A \to B$
induces a map ${\cal P}k \colon {\cal P}A \to {\cal P}B$ of Heyting algebras.

The internal structure of ${\cal P}A$ makes $\mathrm{hom}(X,{\cal P}A)$ an external Heyting
algebra with the following isomorphism of Heyting algebras
\[
\mathrm{Sub}(A \times X) \cong \mathrm{Hom}(X,{\cal P}A).
\]

******** TODO Proof
***** VI.1. The topos of sets
****** Natural numbers object
In an arbitrary topos ${\cal E}$, a *natural numbers object* is the object $\mathbb{N}$
with arrows

\[\begin{tikzcd}
1\rar{0} & \mathbb{N}\rar{s} & \mathbb{N}
\end{tikzcd}\]

which is universal in the sense that for any other object with the same
arrows, we can define a commutative diagram

e\[\begin{tikzcd}
1\rar{0}\dar{\cong} & \mathbb{N}\rar{s}\dar[dashed]{h} & \mathbb{N} \dar[dashed]{h}\\
1\rar{x} & X\rar{f} & X &.\\
\end{tikzcd}\]

******* Recursion as a universal property
Definition by recursion assumes the existence of this universal object.

****** Natural numbers by adjunction
Given ${\cal E}$ with a natural numbers object $\mathbb{N}$ and adjoints $g^{\ast} \dashv g_{\ast}$, the diagram

\[\begin{tikzcd}
1 \cong g^{\ast}(1) \rar{g^{\ast}(0)} &
g^{\ast}(\mathbb{N}) \rar{g^{\ast}(s)} &
g^{\ast}(\mathbb{N})
\end{tikzcd}\]

is a natural numbers object.

******* TODO Proof

****** Boolean topos
A topos ${\cal E}$ is *boolean* when the internal Heyting algebra $\Omega$ is an internal
boolean algebra.

**** Notes for page 33
:PROPERTIES:
:interleave_page_note: 33
:END:

***** Examples of topoi
****** Sets
Small sets with functions between them.

****** n-Sets
Given $n \in \mathbb{N}$, the $n\text{-tuples}$ of sets with $n\text{-tuples}$ of functions between them.

****** G-Sets
Representations of a fixed group $\mu\colon X\times G \to X$, with morphisms preserving
the group action $f(x\cdot g) = f(x) \cdot g$.

****** M-Sets
Representations of a fixed monoid.

****** 2-Sets
Category of functions betweeen sets $\sigma\colon X \to X'$ and commutative squares
between them.

****** N-Sets
Category of sequences $X_0 \to X_1 \to X_2 \to \dots$ of sets and commutative squares
as morphisms.

****** Preseaves
Objects are presheaves $P\colon C^{op} \to \mathtt{Sets}$, and arrows natural transformations
$\theta\colon P \to P'$.

******* Yoneda embedding
$y \colon C \to \Set^{C^{op}}$ is full and faithful.

****** Comma category
Objects are functions $h \colon X \to J$ for a fixed $J$ and arrows
commuting triangles. Each object determines a family of sets

\[
H_j = h^{-1}(j) = \left\{ x \mid x \in X, h(x) = j \right\}
\]

and each function determines a family $f_j \colon H_j \to H'_j$. If we take
$J$ as a discrete category, each object of the comma category is a
functor from it and each morphism is a natural transformation.

That is, we can see the comma category inside a presheaf category
with this assignment

\[
L\colon \Set/J \to \Set^{J}
\]

while in the other direction, each functor provides an object $\bigsqcup H_j$
in the comma category; thus providing a complete equivalence of
categories.

/The comma category is equivalent to a presheaf category./

It is *not* an isomorphism because the composition of both
constructions may not be the identity (the disjoint union is only
unique up to isomorphism).

****** Sheaves over a topological space
Category of sheaves over a topological space.

****** Continuous G-Sets
Given $G$ a topological group, the continuous representations of the group
are the objects with the continuous homomorphisms of actions.

****** Simplicial sets
A *simplicial object* is a family of objects $\left\{ S_n  \right\} \in C$ satisfiying the
simplicial identities

******* TODO Simplicial identities
****** Finite sets
Finite sets and functions between them.

****** Presheaves to finite sets

**** Notes for page 38
:PROPERTIES:
:interleave_page_note: 38
:END:

A *pullback* of $X \to B \gets Y$ is the universal object and
projections making this diagram commute

\[\begin{tikzcd}
P\rar[dashed]{f'} \dar[dashed,swap]{g'} & Y \dar{g} \\
X\rar{f} & B &.
\end{tikzcd}\]

In Sets, we have the set of pairs $\pair{x,y}$ such that $f(x)=g(y)$.

If we have that $g$ is an inclusion, $P$ is the inverse image
$f^{-1}(Y)$, included in $X$. If both $f,g$ are inclusions, we have
the intersection of two subsets.

**** Notes for page 39
:PROPERTIES:
:interleave_page_note: 39
:END:

***** Pullbacks
The pullback of any two presheaves exists on a preseaf category.

The pullback along a monic is always monic.

A category with a terminal object and all pullbacks has all finite limits.

In presheaves, all finite limits are constructed pointwise. 

**** Pullback of group actions
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (40 . 0.503994442514762)
:END:

**** Notes for page 41
:PROPERTIES:
:interleave_page_note: 41
:END:

***** Subobject classifier
A *subobject classifier* is a monic $t\colon 1 \rightarrowtail \Omega$ such that for every monic $S \rightarrowtail X$
exists a unique $\Phi \colon X \to \Omega$ creating a pullback square

\[\begin{tikzcd}
S\rar{1} \dar[swap]{i} & 1 \dar{t} \\
X\rar[dashed]{\Phi} & \Omega
\end{tikzcd}\]

where the morphism $t$ is called /true/.

***** Well-powered category
A category is *well-powered* when $\mathrm{Sub}_C(X)$ is isomorphic to a small set
for any $X$.

**** Notes for page 42
:PROPERTIES:
:interleave_page_note: 42
:END:

***** Proposition 1. Existence of a subobject classifier in well-behaved categories
A category $C$ with finite limits and small hom-sets has a subobject classifier
if and only if there is a natural isomorphism

\[
\theta \colon \mathrm{Sub}_C(-) \cong \mathrm{Hom}_C(-,\Omega),
\]

and then, $C$ is also well-powered.

****** Proof
******* Given a subobject classifier
There exists a unique characteristic function for each equivalence
class of monics; an this is a bijection (from the characteristic
function, the monic can be recovered up to isomorphism).

To show that this is natural, given any $f \colon Y \to X$, we have to
prove that

\[\begin{tikzcd}
\mathrm{Sub}(X) \rar{\theta} \dar[swap]{f^{-1}} & \mathrm{hom}(X,\Omega) \dar{\circ f} \\
\mathrm{Sub}(Y) \rar{\theta} & \mathrm{hom}(Y,\Omega)
\end{tikzcd}\]

and this can be proved by the pullback theorem, by which two pullback
squares can be joint in a outer pullback square

\[\begin{tikzcd}
S'\rar{} \dar[swap]{} & S \dar{}\rar & 1\dar{\mathrm{true}} \\
Y\rar{f} & X \rar{\phi} & \Omega
\end{tikzcd}\]

${\cal C}$ is well-powered because all hom-sets are small

******* Given a natural bijection
The identity corresponds to some subobject $t_0 \colon \Omega_0 \to \Omega$. By naturality,
$S = \mathrm{Sub}(\phi)(\Omega_0)$ and every subobject is the pullback of some $\Omega_0$.

Now, we show that $\Omega_0$ is in fact the terminal object. The following
two squares are pullbacks because $t_0$ is monic

\[\begin{tikzcd}
X \rar[bend left]{\phi'} \rar[bend right]{\phi''} \dar[swap]{\mathrm{id}} & 
\Omega_{0} \dar{t_{0}} \\
X \rar[bend left]{t_{0}\phi'} \rar[bend right]{t_{0}\phi''} & \Omega
\end{tikzcd}\]

and by unicity, we have $t_0\phi' = t_0\phi''$ and $\phi' = \phi''$.

**** Notes for page 44
:PROPERTIES:
:interleave_page_note: 44
:END:

***** Classifier for Sets and Finite sets
The classifier $1 \to 2$.

***** Classifier for n-Sets
The classifier is a n-tuple of $1 \to 2$ functions. There are $2^n$
truth values.

***** Classifier for BG-Sets
The same classifier $1 \to 2$ works, $G$ acts trivially on both sets.

***** Classifier for BM-Sets
The same classifier for groups does not work, because complements need not
to be closed under the action of a monoid.

**** Notes for page 50
:PROPERTIES:
:interleave_page_note: 50
:END:

***** Every object is a colimit of representable objects
In a functor category $\mathtt{Sets}^{C^{op}}$, every object $P$ is
the colimit of a diagram of representable objects.

**** Notes for page 55
:PROPERTIES:
:interleave_page_note: 55
:END:

For any small category ${\cal C}$, the functor category $\mathtt{Sets}^{\mathcal{C}^{op}}$ is cartesian closed.

**** Notes for page 57
:PROPERTIES:
:interleave_page_note: 57
:END:

Boolean algebras are algebraic correlates of classical propositional calculus.
Heyting algebras are algebraic correlates of intuitionistic propositional calculus.
**** Notes for page 58
:PROPERTIES:
:interleave_page_note: 58
:END:

***** Lattice
A *lattice* is a partially ordered set, which, interpreted as a category,
has all binary products and coproducts.

That is, $x \leq y$ if and only if $x \to y$.

A lattice with $0 \leq x \leq 1$ are the initial and terminal objects, and has all
finite limits and colimits.

***** Lattice                                                                            :drill:
SCHEDULED: <2018-07-04 Wed>
:PROPERTIES:
:ID:       91ba55a2-38e0-431b-bfe5-56c721bc7836
:DRILL_LAST_INTERVAL: 4.3514
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-30 Sat 18:44]
:END:
A lattice is a set with two binary operations ∨ : A × A → A, and ∧ : A × A → A,
following which rules?

****** Answer

 * associativity:    x ∧ (y ∧ z) = (x ∧ y) ∧ z
                     x ∨ (y ∨ z) = (x ∨ y) ∨ z

 * commutativity:    x ∧ y = y ∧ x
                     x ∨ y = y ∨ x

 * absorption law:   x ∧ (y ∨ x) = x = (x ∧ y) ∨ x

**** Notes for page 59
:PROPERTIES:
:interleave_page_note: 59
:END:

***** Heyting algebra                                                                    :drill:
SCHEDULED: <2018-07-04 Wed>
:PROPERTIES:
:ID:       d2716609-a6b5-47aa-860f-7e516bccab3a
:DRILL_LAST_INTERVAL: 3.6061
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-30 Sat 18:43]
:END:
Heyting algebra, definition.

****** Answer
A Heyting algebra is a bicartesian closed poset.

In other words, it has all finite limits, all finite colimits and it
is cartesian closed.

**** Notes for page 64
:PROPERTIES:
:interleave_page_note: 64
:END:
***** Proposition 4.                                                                                        :drill:
SCHEDULED: <2018-07-05 Thu>
:PROPERTIES:
:ID:       34b1e843-690f-48cf-b370-2217437aa465
:DRILL_LAST_INTERVAL: 4.9606
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-30 Sat 18:42]
:END:
When is a Heyting algebra also a Boolean algebra?

****** Answer
A Heyting algebra is a Boolean algebra

 * if and only if $\neg\neg x = x$ for all elements;
 * if and only if $x \vee \neg x = 1$ for all elements.
**** Notes for page 75
:PROPERTIES:
:interleave_page_note: 75
:END:

***** Sheaf of sets                                                                      :drill:
SCHEDULED: <2018-07-03 Tue>
:PROPERTIES:
:ID:       9f420f7c-d5e9-4eea-9c8e-8505129e5f02
:DRILL_LAST_INTERVAL: 3.8386
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-29 Fri 22:34]
:END:
*Sheaf of sets*

****** Answer
A functor $F \colon {\cal O}(X)^{op} \to \mathsf{Set}$ such that each open covering $U = \bigcup_i U_i$ yields
an equalizer diagram

\[\begin{tikzcd}
FU \rar[dashed]{e} &
\prod_i FU_i \rar[yshift=0.5ex]{p}\rar[yshift=-0.5ex,swap]{q} &
\prod_{i,j} F(U_i \cap U_j)
\end{tikzcd}\]

where for $t \in FU$, we have $e(t) = (t_{|U_i})_{i\in I}$ and for a family $t_i \in FU_i$ we
have $p(t_i)_{i \in I} = (t_{i|U_i \cap U_j})_{i,j \in I}$ and $q(t_i)_{i \in I} = (t_{j|U_i \cap U_j})_{i,j\in I}$.

**** Notes for page 76
:PROPERTIES:
:interleave_page_note: 76
:END:

***** Morphism of sheaves                                                                                   :drill:
SCHEDULED: <2018-07-04 Wed>
:PROPERTIES:
:ID:       84046292-d887-4b2e-a603-72ec55322c48
:DRILL_LAST_INTERVAL: 4.3175
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-30 Sat 11:58]
:END:
What is a morphism between sheaves $F \to G$.

****** Answer
A natural transformation between them; they are functors.

**** Notes for page 170
:PROPERTIES:
:interleave_page_note: 170
:END:

The change of base functor preserves all topos structure.

**** Notes for page 171
:PROPERTIES:
:interleave_page_note: 171
:END:

**** Notes for page 172
:PROPERTIES:
:interleave_page_note: 172
:END:

***** Elementary form                                                                                       :drill:
SCHEDULED: <2018-07-03 Tue>
:PROPERTIES:
:ID:       25e51781-23db-44db-b36c-79904e44a812
:DRILL_LAST_INTERVAL: 4.0675
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-29 Fri 22:34]
:END:
Elementary definition of a topos.

****** Answer
A category with

 * all pullbacks

 * a terminal object

 * a subobject classifier

 * a powerset for every object.

**** Notes for page 175
:PROPERTIES:
:interleave_page_note: 175
:END:

**** Notes for page 176
:PROPERTIES:
:interleave_page_note: 176
:END:

***** TODO Every topos has exponentials                                                                   :theorem:

***** Topos                                                                                                 :drill:
SCHEDULED: <2018-07-04 Wed>
:PROPERTIES:
:ID:       0af09c4d-0a39-4034-97c8-95bb2c2479cc
:DRILL_LAST_INTERVAL: 5.0251
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-29 Fri 22:23]
:END:
Definition from cartesian closed categories.

****** Answer
A topos is a cartesian closed category with equalizers and a subobject
classifier.

**** Notes for page 185
:PROPERTIES:
:interleave_page_note: 185
:END:

***** Topos, finite limits and finite colimits                                                              :drill:
SCHEDULED: <2018-07-04 Wed>
:PROPERTIES:
:ID:       31d80b9e-40a7-403a-a4cd-b4f25462a68d
:DRILL_LAST_INTERVAL: 5.2485
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 5.0
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-29 Fri 22:25]
:END:
Has a topos finite limits? why? has it finite colimits? why?

****** Answer
*A topos has all finite limits and finite colimits* 

It has finite limits by definition (cartesian closed with equalizers).
It has finite colimits; this is not trivial and must be proven using
monads.

**** Notes for page 187
:PROPERTIES:
:interleave_page_note: 187
:END:

***** Comparison functor                                                                                    :drill:
SCHEDULED: <2018-07-04 Wed>
:PROPERTIES:
:ID:       170873b3-03ec-45ed-87c1-b30c9298aa3a
:DRILL_LAST_INTERVAL: 4.9561
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-29 Fri 22:31]
:END:
Construct the comparison functor $K$ over a $G \colon A \to C$ with a
left adjoint $F \colon C \to A$.

****** Answer
We construct a monad $GF$ and the following construction where
$C^T$ is the category of T-algebras over $GF$.

\[\begin{tikzcd}
A \rar{K}\dar[bend left]{G} & C^T\dar[bend left]{F^T} \\
C \rar{1}\uar[bend left]{F} & C\uar[bend left]{G^T}
\end{tikzcd}\]

The comparison functor $K \colon A \to C^T$ is given by $(GA, G\epsilon_A \colon GFGA \to GA)$.

***** Monadic functor                                                                                       :drill:
SCHEDULED: <2018-07-03 Tue>
:PROPERTIES:
:ID:       a5ca3d08-dfeb-498a-b2a7-419f30c05272
:DRILL_LAST_INTERVAL: 4.0224
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-29 Fri 22:32]
:END:
When is $G \colon A \to C$ monadic?

****** Answer
Has a left adjoint $F \dashv G$ and the comparison functor $K \colon A \to C^T$
given by $(GA, G\epsilon_A \colon GFGA \to GA)$ is an equivalence of categories.

***** Property of monadic functors                                                                          :drill:
SCHEDULED: <2018-07-05 Thu>
:PROPERTIES:
:ID:       5ba579f3-e5c2-40a0-87a1-e833366be045
:DRILL_LAST_INTERVAL: 5.1775
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 2
:DRILL_AVERAGE_QUALITY: 2.667
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-30 Sat 11:59]
:END:
How do monadic functors and limits relate?

****** Answer
Monadic functors create all limits.

**** Notes for page 189
:PROPERTIES:
:interleave_page_note: 189
:END:

***** Left adjoint of the powerset functor                                                                  :drill:
SCHEDULED: <2018-07-05 Thu>
:PROPERTIES:
:ID:       8b55fb4c-ba74-4720-bece-fd229260205f
:DRILL_LAST_INTERVAL: 5.6307
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 5.0
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-29 Fri 22:29]
:END:
What is the left adjoint of the powerset functor $P \colon {\cal E}^{op} \to {\cal E}$?

****** Answer
$P^{op} \colon {\cal E} \to {\cal E}^{op}$, that is, the same functor
but acting on the opposite category.

**** Notes for page 190
:PROPERTIES:
:interleave_page_note: 190
:END:

***** Left adjoint of the powerset functor
Why is the left adjoint of the powerset functor itself?

****** Answer
The product is commutative, so

\[
{\cal E}(A,PB) \cong
{\cal E}(A \times B,\Omega) \cong
{\cal E}(B \times A,\Omega) \cong
{\cal E}(B,PA) =
{\cal E}^{op}(PA,B).
\]

**** Notes for page 199
:PROPERTIES:
:interleave_page_note: 199
:END:

***** The slice of a topos                                                                                  :drill:
SCHEDULED: <2018-07-04 Wed>
:PROPERTIES:
:ID:       df04a625-5b2f-4579-8b5e-6a90430849c0
:DRILL_LAST_INTERVAL: 4.5982
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 5.0
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-29 Fri 22:31]
:END:
Structure of the slice of a topos ${\cal E}/B$.

****** Answer
It is again a topos.

**** Notes for page 207
:PROPERTIES:
:interleave_page_note: 207
:END:

***** Internal lattice
An *internal lattice* in a category is an object $L$ with morphisms

\[
\wedge \colon L \times L \to L,
\qquad
\vee \colon L \times L \to L
\]

and commutative diagrams expressing the identities of a lattice

  * associativity,
  * commutativity,
  * idempotent laws,
  * absorption law.

Such a lattice object has a zero and a one if there are arrows

\[
\top \colon 1 \to L,
\qquad
\bot \colon 1 \to L,
\]

with the appropiate identities.

**** Notes for page 208
:PROPERTIES:
:interleave_page_note: 208
:END:

Heyting algebra objects from lattices. ([[id:d2716609-a6b5-47aa-860f-7e516bccab3a][Heyting algebra]])

*** Higher order categorical logic - Lambek, Scott
***** 0. Introduction to category theory
****** 0.1. Categories and functors
****** 0.2. Natural transformations
****** 0.6. Triples
****** 0.7. Examples of cartesian closed categories
***** I. Cartesian closed categories and \lambda-calculus
***** II. Type theory and toposes
***** III. Representing numerical functions in various categories
*** Introduction to categorical logic (2017) - Bauer, Awodey
**** II. Type theories
***** II.1. Algebraic theories
******* Signatures
A *signature* $\left\{ \Sigma_k \right\}$ is a family of sets of k-ary operations. Its *terms*
are constructed inductively knowing that

 * variables are terms.
 * given $\left( x_1,\dots,x_{k} \right)$ a k-uple of terms and $f \in \Sigma_k$, $f(x_1,\dots,x_{k})$ is a term.

******* Algebraic theories
An *algebraic theory* $\mathbb{A} = (\Sigma,A)$ is a signature and a set of equation
between its terms.

They are also called /equational theories/ and /Lawvere theories/.

******** Examples
********* Theory of groups
********* Theory of unital commutative rings
********* Theory of sets
********* Theory of pointed sets
********* Theory of R-modules
********* Counterexample: theory of fields
********* Theory of inductive datatypes

****** II.1.1. Many-sorted algebraic theories
******* Examples
******** Theory of left modules
******** Theory of graphs
******** Theory of symmetric graphs
******** Theory of a RAM
****** II.1.2. Models of algebraic theories
The motivation is to generalize the classical notions of algebraic
structures to morphisms and commutative diagrams.

******* Interpretation
An *interpretation* of a theory $\mathbb{A}$ on a category ${\cal C}$ with finite products
is given by an object $I\mathbb{A} \in \mathrm{obj}({\cal C})$ and a morphism for each operation of 
arity $k$,

\[
\forall f \in \Sigma_k,\qquad If : (I\mathbb{A})^k \to I\mathbb{A}.
\]

The interpretation of a term with a *context* of variables, $x_1,\dots,x_n \mid t$,
is given inductively by

 1. the interpretation of $x_i$ is the projection $\pi_i$.
 2. a term $f(t_1,\dots,t_k)$ is interpreted as the composition of the 
    interpretation of every subterm with the interpretation of $f$ as

    \[\begin{tikzcd}[column sep=huge]
    (I\mathbb{A})^n  \rar{(It_1,\dots,It_k)}  &
    (I\mathbb{A})^k  \rar{If}  &
    \mathbb{A}.
    \end{tikzcd}\]
    
Note that the interpretation of a term depends on the context.

******* Satisfacibility of equations
An equation $u=v$ of two terms in the same context is *satisfied*
by the interpretation $I$ if $Iu = Iv$ as morphisms.

******* Models of algebraic theories
A *model* is an interpretation that satisfies all the axioms of the
theory.

****** II.1.3. Algebraic theories as categories
The motivation is to have a general theory of what is a group,
independent from the choice of basic constants, operations and axioms.

******* Category of an algebraic theory
Given $\mathbb{A}$, we take as objects all the possible contexts $\left[ x_1,\dots,x_n \right]$ and
tuples $\langle t_1,\dots,t_n \rangle : [x_1,\dots,x_m] \to [x_1,\dots,x_n]$ of terms with context the
domain as morphisms.

Two morphisms are equal iff the axioms imply $t_k = t_{k}'$ on every $k$; and
the composition of morphisms $v = u \circ t$ is done by substitution

\[
v_i = u_i \left[ t_1,\dots,t_m / x_1,\dots,x_m \right].
\]

******** Closed to products
The product of $\left[ x_1,\dots,x_n \right]$ and $\left[x_1,\dots,x_m \right]$ exists as $\left[ x_1,\dots,x_{n+m} \right]$
in this category. Every object is a product of finitely many instances
of $[x_1]$.

******* Algebraic theory (alternative definition)
An *algebraic theory* is a small category with finite products whose
objects are $A^0,A^1,A^2,\dots$ such that $A^m\times A^n = A^{m+n}$.

******** Algebraic theory in the former sense
The basic operations of $\Sigma_k$ are the morphisms $A^k \to A$. An equation
$u = v$ is an axiom if the canonical interpretations of each morphism
being interpreted by itself coincide.

******* Examples
******** Algebraic theory of smooth maps
******** Algebraic theory of total recursive functions
******** Algebraic theory of an object
****** II.1.4. Models of algebraic theories as functors
******* Interpretations as functors
Given a model $M$ of $\mathbb{A}$ in ${\cal C}$, the interpretation is a functor $M : \mathbb{A} \to {\cal C}$
defined by

\[
M[x_1,\dots,x_k] = (M\mathbb{A})^k
\]

on objects and by the following rules on morphisms

 1) the morphism $\left\langle x_i \right\rangle : \left[ x_1,\dots,x_k \right] \to [x_1]$ is mapped to $\pi_i : (M\mathbb{A})^k \to M\mathbb{A}$.
 2) the morphism $\left\langle f(t_1,\dots,t_m) \right\rangle : [x_1,\dots,x_k] \to [x_{1}]$ is mapped into the
    composition

    \[\begin{tikzcd}[column sep=huge]
    (M\mathbb{A})^m \rar{(Mt_1,\dots,Mt_m)} &
    (M\mathbb{A})^k \rar{Mf} &
    \mathbb{A}
    \end{tikzcd}\]

 3) the morphism $\left\langle t_1,\dots,t_m \right\rangle : [x_1,\dots,x_k] \to [x_1,\dots,x_{m}]$ is mapped to the
    morphism $\left\langle Mt_1,\dots,Mt_m \right\rangle$, where $Mt_i$ is the value of $M\left\langle t_i \right\rangle$.

This interpretation is a in fact a functor.

******** The interpretation is a functor 
As $M$ is a model, all the equations of the theory are satisfied by
it. This preserves the identities given by composition of morphisms.

******* Model (alternative definition)
A *model* of $\mathbb{A}$ in ${\cal C}$ is a functor preserving finite products.

******* Category of models
The category $\mathtt{Mod}_{{\cal C}}(\mathbb{A})$ of models of the theory $\mathbb{A}$ in ${\cal C}$ has models
$M : \mathbb{A} \to {\cal C}$ as objects and natural transformations as morphisms.

******* Algebraic categories
An algebraic category is a category that is equivalent to a
category of models of an algebraic theory.

******** Examples
********* Category of groups
********* Category of C-rings
****** II.1.5. Completeness and universal models
******* Categorical logic
Categorical logic has two sides, the logical and the categorical.
The logic consists of

  1) A *type theory*, a calculus of types and terms. In the case
     of algebraic theories, there is only one type.
  2) A *logic*. In the case of algebraic theories, the logic only
     involves equations.
  3) A *theory* given by basic types, terms and axioms.
  4) *Interpretations and models*. The type theory and logic are
     interpreted denotationally in a category with enough structure.
     In the case of algebraic theories, those are categories with
     finite products.

There are special cases of simple logics

  * a /single-sorted logic/ if there is only one type.
  * a /type theory/ if there is only a very simple type system.
  * in /ML-type systems/, logic and types are identified.

And complementary to a logical system, we have its categorical
semantics

  1) Theories are categories. The structure of a category hides
     sintactic details and reflects types and logic.
  2) Models are functors. They go from theories to categories with
     richer structure, preserving the structure of the theory.
  3) Homomorphisms are natural transformations.
  4) Completeness and universal models. It is desirable for a
     categorical semantics to be complete or to have universal
     models.

******* Semantic completeness
The property that gives that if every model of $\mathbb{A}$ satisfies
an equation, the equation can be proved on the algebraic theory is
called *semantic completeness*.

******* Completeness for algebraic theories
Given $\mathbb{A}$ algebraic theory, exists a model $U \in \mathtt{Mod}_{{\cal A}}(\mathbb{A})$ called the
*universal model* for $\mathbb{A}$, such that,

\[
U \text{ satisfies } u = v
\iff
\mathbb{A} \text{ proves } u = v.
\]

As a corollary, categorical semantics of algebraic theories is
complete.

******** Proof
We can simply take $U = 1_{\mathbb{A}} : \mathbb{A} \to \mathbb{A}$ as a model, which clearly
identifies $1(f)=1(g)$ if and only if $f = g$.

******* Universal model on generalized sets
The Yoneda embedding $y : \mathbb{A} \to \widehat{\mathbb{A}}$ is a universal model for $\mathbb{A}$.

******** Proof
The embedding $y$ preserves limits and therefore, finite products.
It is a functor and a faithful one, which makes $\widehat{\mathbb{A}}$ an universal
model.

***** II.2. Cartesian closed categories
****** II.2.1. Exponentials
******* Exponentials
In a category with binary products ${\cal C}$, an *exponential* is an object $B^A$
with an evaluation morphism $e : B^A \times A \to B$ such that for every $f : C \times A \to B$
exists a unique $\widetilde f : C \to B^A$ for which this diagram commutes

\[\begin{tikzcd}
B^A &
B^A \times A \drar{e} &
\\
C \uar[dashed]{\widetilde f} &
C \times A \uar{{\widetilde f} \times 1_A} \rar[swap]{f} &
B
\end{tikzcd}\]

This is the universal property of exponentials.

******* Exponentiable object
An object $A \in \mathrm{obj}({\cal C})$ is exponentiable if $B^A$ exists for every $B$.

******* Characterization of exponentiable objects
An object $A$ is exponentiable iff the functor $- \times A$ has a right
adjoint $-^{A}$.

******** TODO Proofs

******* Examples
******** Propositional calculus
****** II.2.2. Cartesian closed categories
******* Cartesian category
A *cartesian category* is a category that has finite products.

******* Cartesian closed category
A *cartesian closed category* is a cartesian category with
exponentials.

******* Characterization of cartesian closed categories by adjoints
The category ${\cal C}$ is cartesian closed if the following functors
have adjoints

 * the functor $! : {\cal C} \to 1$ to the terminal category.
 * the diagonal functor $\Delta : {\cal C} \to {\cal C} \times {\cal C}$.
 * the product by every object $-\times A : {\cal C} \to {\cal C}$.

******** TODO Proof

******* Characterization of cartesian closed categories by equations
A category ${\cal C}$ is cartesian closed if and only if

  1) $1 \in {\cal C}$ and exists a morphism $! : A \to 1$ for every $A \in {\cal C}$.
  2) a product $A \times B$ with projections and the universal property
     of the product.
  3) an exponential $B^A$ with an evaluation map and the universal
     property of the exponential.

We write the projections as $\pi_0,\pi_1$; the unique function from the product
as $\left\langle f,g \right\rangle$ and $f \times g = \left\langle f \circ \pi_0, g \circ \pi_1 \right\rangle$. The types satisfy

  1) for every $f : A \to 1$, $f = !$.
  2) for all functions $\pi_0 \circ \left\langle f,g \right\rangle = f$, $\pi_1 \circ \left\langle f,g \right\rangle = g$ and $\left\langle \pi_0\circ h, \pi_1\circ h \right\rangle = h$.
  3) for all functions $e \circ (\widetilde{f} \times 1) = f$ and $(e \circ (g \times 1))^{\sim} = g$.

******* Examples of cartesian closed categories
******** Sets with hom-objects
******** Categories with functor categories
******** Presheaf category of a small category
****** II.2.3. Frames
******* Complete poset is cocomplete poset
A poset is complete iff it is cocomplete.

******** TODO Proof
******* TODO Infinite distributive law
******* Frames
A *frame* is a complete and cartesian closed poset. That is, it
is a complete poset with the distributive law

\[ x \wedge \bigvee_{i\in I} y_i = \bigvee_{i\in I} x \wedge y_i.
\]

******* Frame morphisms
A *frame morphism* is a $f : L \to M$ between frames preserving finite
infima and arbitrary suprema.

****** II.2.4. Heyting algebras
******* Lattices
A *lattice* is a poset with finite limits and colimits.

******* Lattice homomorphisms

** Type theory                                                                                                 :types:
*** Basic type theory
**** Canonicity                                                                                              :drill:
SCHEDULED: <2019-03-05 Tue>
:PROPERTIES:
:ID:       767fa380-22e3-4907-810a-a22a137c7808
:DRILL_LAST_INTERVAL: 247.7323
:DRILL_REPEATS_SINCE_FAIL: 6
:DRILL_TOTAL_REPEATS: 5
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.8
:DRILL_EASE: 2.9
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-30 Sat 11:55]
:END:
Definition of *canonicity*.

***** Definition
A type theory enjoys canonicity if every closed term can be written
in a canonical form, only using constructors of the type. In particular,
if every term of type $\mathbb{N}$ is a numeral of the form $S(S(\dots(SZ)\dots))$.

***** Canonicity and axioms
Canonicity can be lost when we add axioms. If we add LEM,
$\mathrm{case}(\mathrm{lem}(P), 0, 1)$ is a non-canonical natural.

*** Mikrokosmos - Mario Román                                                            :lambda_calculus:functional:
**** Cálculo lambda sin tipos
Una expresión lambda es

 * una variable,
 * una aplicación de dos expresiones $M\ N$,
 * una abstracción $(\lambda x.M)$, donde $M$ es un término que depende de $x$.

Una abstracción aplicada a otro término se puede reducir como

\[
(\lambda x.M)\ N \longrightarrow_{\beta} M[N/x]
\]

y las aplicaciones asocian a izquierda: $M\ N\ P$ se lee como $(M\ N)\ P$
en vez de $M\ (N\ P)$.

\[

\]

**** El intérprete
Podéis instalarlo desde github si tenéis Haskell y si no, podéis usarlo
directamente desde la página web

 * https://github.com/m42/mikrokosmos
 * https://m42.github.io/mikrokosmos/tutorial.html

En Mikrokosmos, las lambdas se escriben como una *barra invertida*, y
el programa responde con la expresión lambda y una lista de posibles
nombres que tiene esa expresión.

#+BEGIN_SRC haskell
mikro> (\x.x)
λa.a ⇒ I, ifelse, id
#+END_SRC

Para ver cómo funciona, se pueden probar algunas expresiones aritméticas
simples

#+BEGIN_SRC haskell
mult 2 3
plus 3 4
and true false
sum (take 5 naturals)
#+END_SRC

Características:
 
 * los argumentos van separados por espacios,
 * se entiende asociatividad a izquierda, y
 * se permite aplicación parcial.

Es un pequeño lenguaje de programación y está completamente basado en el 
cálculo lambda. Quiero explicaros cómo se puede obtener un lenguaje de
programación desde el cálculo lambda.

**** Primeras definiciones
Vamos a usar cálculo lambda. Las expresiones lambdas se leen
como 

#+BEGIN_SRC haskell
(\x.\y.plus x y)
plus 3 4
(\e.plus e e) 3
#+END_SRC

Diciendo: esta es una función que toma =x= e =y= y devuelve =x+y=.
Lo que vamos a aprender es cómo funcionan por dentro los números
o la función =plus=.

La función *identidad* y la función *constantemente*.

#+BEGIN_SRC haskell
id = \x.x
const = \x.\y.x

id id
id const
id 3
id 5
const 4 2
const 4 3
const 4 (id (const id id))

devuelvecuatro = const 4
devuelvecuatro 5
#+END_SRC

**** Técnica de Church
Queremos usar estructuras de datos. Tenemos primero que escribir
la estructura de datos como constructores y hacer depender de ellos
a los términos.

#+BEGIN_SRC haskell
true = \t.\f.t
false = \t.\f.f

0 = \s.\z.z
1 = \s.\z.s z

cons = \h.\t.\c.\n.c h (t c n)
nil = \c.\n.n
#+END_SRC

**** Librería
***** Básica
#+BEGIN_SRC haskell
id = \x.x
const = \x.\y.x
compose = \g.\f.\x.g (f x)
#+END_SRC

***** Booleanos
#+BEGIN_SRC haskell
true = \x.\y.x
false = \x.\y.y

not = \p.p false true

and = \p.\q.p q false
and = \p.\q.p q p

or = \p.\q.p true q
or = \p.\q.p p q
#+END_SRC

***** Aritmética básica
#+BEGIN_SRC haskell
0 = \f.\x.x
succ = \n.\f.\x.f (n f x)

plus = \m.\n.n succ m
plus = \m.\n.(\f.\x.n f (m f x))

mult = \m.\n.compose m n
mult = \m.\n.\f.\x.m (n f) x

iseven = \n.n not true
iszero = \n.n (const false) true
#+END_SRC

***** Tuplas
#+BEGIN_SRC haskell
tuple = \x.\y.\z.z x y

first = \p.p true
second = \p.p false

pred = \n.first (n (\t.tuple (first t) (succ (first t))) (tuple 0 0))
minus = \m.\n.n pred m
leq = \m.\n.iszero (minus m n)
geq = \m.\n.iszero (minus n m)
#+END_SRC

***** Listas
#+BEGIN_SRC haskell
nil = \c.\n.n
cons = \h.\l.(\c.\n.c h (l c n))

fold = \o.\n.\l.l o n

sum = fold plus 0
prod = fold mult 1
all = fold and true
any = fold or false
length = fold (\h.\t.)

map = \f.fold (\h.\t.cons (f h) t) nil
filter = \p.fold (\h.t.(p h) (cons h t) t) nil

head = fold const nil
tail = \l.first (l (\a.\t.tuple (second t) (cons a (second t))) (tuple nil nil))
take = \n.\l.first (n (\t.tuple (cons (head (second t)) (first t)) (tail (second t))) (tuple nil l))
#+END_SRC

***** Árboles
#+BEGIN_SRC haskell
nil = \d.\n.n
node = \x.\l.\r.\d.\n.(d x (l d n) (r d n))
#+END_SRC

***** Recursión
#+BEGIN_SRC haskell
omega := (\x.x x)(\x.x x)
fix := (\f.(\x.f (x x)) (\x.\f (x x)))

fact := fix (\f.\n.iszero n 1 (mult n (f (pred n))))
fib :=  fix (\f.\n.iszero n 1 (plus (f (pred n)) (f (pred (pred n)))))

infinity := fix succ
naturals := fix (compose (cons 0) (map succ))
#+END_SRC

***** Tipos
#+BEGIN_SRC haskell

#+END_SRC
*** Lecture notes on the lambda calculus - Salinger                                                 :lambda_calculus:
**** 1. Introduction
**** 2. The untyped lambda calculus
***** 2.5. Formal definitions of \beta-reduction and \beta-equivalence
****** \beta-equivalence
The \beta-equivalence $M =_{\beta} M'$ is the symmetric transitive closure
of the \beta-reduction $\rightarrow_{\beta}$.

**** 3. Programming in the untyped lambda calculus
**** 4. The Church-Rosser Theorem
***** 4.1. Extensionality, \eta-equivalence, and \eta-reduction
****** Extensionality principle
The *principle of extensionality* is defined as the following rule

\[\begin{prooftree}
\LeftLabel{($ext_{\forall}$)}
\AxiomC{$\forall A. M A = M' A$}
\UnaryInfC{$M = M'$}
\end{prooftree}\]

****** Single step \eta-reduction
****** Single step \beta-reduction

***** 4.2. Statement of the Church-Rosser Theorem
Let $\twoheadrightarrow$ be $\twoheadrightarrow_{\beta}$ or $\twoheadrightarrow_{\beta\eta}$; and lambda terms such that $M\twoheadrightarrow N$ and $M \twoheadrightarrow P$; then
there exists a term $Z$ such that $N \twoheadrightarrow Z$ and $P \twoheadrightarrow Z$.

\[\begin{tikzcd}[column sep=small]
& M \drar[two heads] \dlar[two heads] & \\
N \drar[two heads,dashed] & & P \dlar[two heads,dashed] \\
& Z & \\
\end{tikzcd}\]

***** 4.3. Preliminary remarks on the proof of the Church-Rosser theorem
****** Church-Rosser property

\[\begin{tikzcd}[column sep=small]
& M \drar[two heads] \dlar[two heads] & \\
N \drar[two heads,dashed] & & P \dlar[two heads,dashed] \\
& Z & \\
\end{tikzcd}\]

****** Semidiamond property

\[\begin{tikzcd}[column sep=small]
& M \drar[] \dlar[] & \\
N \drar[two heads,dashed] & & P \dlar[two heads,dashed] \\
& Z & \\
\end{tikzcd}\]

****** Diamond property

\[\begin{tikzcd}[column sep=small]
& M \drar[] \dlar[] & \\
N \drar[dashed] & & P \dlar[dashed] \\
& Z & \\
\end{tikzcd}\]

****** Relationship between properties
***** 4.4. Proof of the Church-Rosser Theorem (Tait & Martin-Löf)
****** Parallel one-step reduction
We define the *parallel one-step reduction* as the smallest relation
satisfying

\[\begin{prooftree}
\LeftLabel{(1)}
\AxiomC{$a$}
\UnaryInfC{$x \rhd x$}
\end{prooftree}\]

\[\begin{prooftree}
\LeftLabel{(2)}
\AxiomC{$P \rhd P'$}
\AxiomC{$N \rhd N'$}
\BinaryInfC{$PN \rhd P'N'$}
\end{prooftree}\]

\[\begin{prooftree}
\LeftLabel{(3)}
\AxiomC{$N \rhd N'$}
\UnaryInfC{$\lambda x. N \rhd \lambda x.N'$}
\end{prooftree}\]

\[\begin{prooftree}
\LeftLabel{(4)}
\AxiomC{$Q \rhd Q'$}
\AxiomC{$N \rhd N'$}
\BinaryInfC{$(\lambda x. Q) N \rhd Q'[N' / x]$}
\end{prooftree}\]

\[\begin{prooftree}
\LeftLabel{(5)}
\AxiomC{$P \rhd P'$, where $x \notin \mathrm{FV}(P)$}
\AxiomC{$N \rhd N'$}
\BinaryInfC{$(\lambda x. Q) N \rhd Q'[N' / x]$}
\end{prooftree}\]

****** TODO Lemmas on the parallel one-step reduction

****** Proof of the Church-Rosser Theorem
We know that $\rhd$ satisfies the diamond property, so its reflexive transitive
closure $\rhd^{\ast}$ also satisfies it. We use now that $\rhd^{\ast}$ is the same as $\twoheadrightarrow_{\beta\eta}$ and
that the diamond property for $\twoheadrightarrow_{\beta\eta}$ is the Church-Rosser property for $\twoheadrightarrow$.

**** 5. Combinatory algebras
***** 5.1. Applicative structures
****** Applicative structure
An *applicative structure* $(\mathbf{A},\cdot)$ is a set with a binary operation, that
can be non-associative.

****** Polynomials of applicative structures
A *polynomial* on an applicative structure $(\mathbf{A},\cdot)$ is a formal expression built
with the binary operation on variables and coefficients. It is the set of
expressions built from the grammar

\[
t,s ::= x \mid a \mid ts,
\]

where $x$ is a variable and $a \in A$.

***** 5.2. Combinatory completness
****** Combinatory completness
****** SK characterization of combinatory completness
***** 5.5. Lambda algebras

**** 6. Simply-typed lambda calculus, propositional logic, and the Curry-Howard isomorphism
***** 6.1. Simple types and simply-typed terms
****** Basic types
We assume a set of *basic types* to exist.

****** Simple types
The set of *simple types* is given by the BNF

\[
A,B ::= \iota\mid A \to B \mid A \times B \mid 1
\]

where $\iota$ is a [[*Basic types][basic type]] and $1$ is a one-element type.

****** Raw types lambda terms
The set of *typed lambda terms* is given by the BNF

\[ \mathtt{Term} ::=
\ast \mid
x \mid
\mathtt{Term}\mathtt{Term} \mid
\lambda x^{\mathtt{Type}}. \mathtt{Term} \mid
\left\langle \mathtt{Term},\mathtt{Term} \right\rangle \mid
\pi_1 \mathtt{Term} \mid
\pi_2\mathtt{Term}
\]

where $\ast$ will be the unique element of type $1$. Besides the
previously considered term application, we now introduce a typed
lambda abstraction and an explicit construction of the pair element with
its projections.

****** Typing rules for the simply-typed lambda calculus
***** 6.2. Connections to propositional logic
**** 7. Weak and strong normalization
***** 7.1. Definitions
***** 7.2. Weak and strong normalization in typed lambda calculus
**** 8. Polymorphism
System F is obtained extending the typed lambda calculus with the quantifier $\forall$.

***** 8.4. Church-Rosser property
**** 9. Type inference
A /type inference algorithm/ decides, given a term, whether it is typable or
not, and outputs a type if it is.

**** 10. Denotational semantics
Denotational semantics give an interpretation of the lambda calculus using
mathematical objects.

**** 11. The language PCF
**** 12. Complete partial orders
**** 13. Denotational semantics of PCF
*** Types and programming languages - Pierce
**** Preface
***** 1. Introduction
***** 2. Mathematical preliminaries
**** I. Untyped Systems
***** 3. Untyped arithmetic expressions
***** 4. An ML implementation of arithmetic expressions
***** 5. The untyped lambda calculus
***** 6. Nameless representation of terms
***** 7. An ML implementation of the lambda-calculus
**** II. Simple typesa
*** Dependent types at work - Ana Bove, Peter Dybjer
**** 1. What are dependent types?
**** 2. Simply Typed Functional Programming in Agda
***** 2.1. Truth Values
***** 2.2. Natural numbers
****** Notion of Inductive type
      /Recursive types/ in Haskell are *inductive types* in constructive type
      theory.
****** Notion of Canonical form
      Elements on canonical form are built up by constructors only. They do not
      contain defined functions. Martin-Löf considers /lazy canonical forms/, where
      it suffices to begin with a constructor:

      #+BEGIN_SRC haskell
      Zero * Zero        -- Not a canonical form
      Succ (Zero + Zero) -- Lazy canonical form
      Succ (Succ Zero)   -- Canonical form
      #+END_SRC
      
***** 2.3. Lambda Notation and Polymorphism
     In Agda we have no type variables, we have families of functions:

     #+BEGIN_SRC 
     id : (A : Set) -> A -> A
     id = \(A : Set) -> \(x : A) -> x
     #+END_SRC

***** 2.4. Implicit Arguments
     Implicit arguments are declared by enclosing their typings within curly 
     braces.

***** 2.5. Gödel System T
     Gödel System T is a system of primitive recursive functionals. All typable
     programs in Gödel System T terminate. We can only use β-reduction and the
     definitions of:

     #+BEGIN_SRC 
     true
     false
     zero
     succ
     if_then_else
     natrec
     #+END_SRC

     We can define all primitive recursive functions, but also others such as the
     Ackermann fuction.

***** 2.6. Parametrised Types
***** 2.7. Termination-checking
     In M-L Type Theory, all recursion is *primitive recursion*; a structural
     recursion on the well-founded data types.

     As the Agda's termination-checker has not yet been documented, if Agda will
     be used as a system for formalising mathematics rigorously, it is advisable to
     stay within a well-specified subset such as Martin-Löf type theory.

     In fact, the termination checker will not recognize calls to non-constructors
     as smaller arguments. =(m-n)= will not be recognized as smaller than =m=,
     for example.

**** 3. Dependent Types
***** 3.1. Vectors of a given length
     We have to alternatives to define vectors of a given length:
     
     - *As a Recursive Family*:
       
       #+BEGIN_SRC 
       Vec : Set -> Nat -> Set
       Vec A zero = Unit
       Vec A (succ n) = A X Vec A n
       #+END_SRC

       Functions must be written by induction on the length of the vector.

     - *As an Inductive Family*:

       #+BEGIN_SRC 
       data Vec (A : Set) : Nat -> Set where
         [] : Vec A zero
	 _::_ : {n : Nat} -> A -> Vec A n -> Vec A (succ n)
       #+END_SRC
       
     We can use type-checking to define functions that work only over non-empty
     vectors, such as =tail= or =head=.

***** 3.2. Finite Sets
     This data type is useful when we want to access the element at a certain
     position in a vector.

***** 3.3. More Inductive Families
**** TODO 4. Propositions as Types
*** The derivative of a regular type is its type of one-hole contexts - Connor McBride                  :type_algebra:
Presented by [[https://www.youtube.com/watch?v=K7tQsKxC2I8][Erik Hinton]].

**** Types and fixed points
Empty type, unit type, product and other basic types.
We use parametric types with type variables.

# We need inductive types and the W from ML-theory?
Fixed points are used to define types. Naturals are
the fixed point of $Z + S x$. We write the fixed point
of a formula $F$ over a variable $x$ as $\mu x.F$.

\[
\mathtt{Nat} = \mu x. 1 + x
\]

**** Zippers and holes
One-hole contexts with respect to some interior type. A zipper is a
one-hole context of a type and the value that was removed.

**** Derivatives
To find the type of a context of type $T$ with a hole in place of some
$x$, take the partial derivative of $T$ with respect to $x$.

Partial derivatives with respect of a type variable work directly.

Product and sum rules can be proved. Chain rule can be proved.

**** Recursive derivatives

**** Questions
Negative and fractional types. Algebraic types and the field of rationals.
Computing on the field of rationals.
*** Semantics for type theory                                                                                 :types:
# Notes on paper.

**** Formal languages and semantics
Traditional definition of formal languages. An alphabet and rules to
inductively construct words. We call $L$ the set of valid strings.

***** Example: boolean algebra
 * symbols $\Sigma = \left\{ p_1,\dots,p_n, \wedge,\neg,\implies,(,),\top,\bot,\dots \right\}$ 
   atomic propositions and logical symbols.
 * valid strings are defined inductively as
   * singletons $p_i$, $\top$ or $\bot$
   * connectors: if $a, b$ are valid, so are $a \wedge b, a \vee b, \neg a, \dots$

***** Semantics
The semantics assigns to each string a number $0$ or $1$,

\[
s \colon L \to \left\{ 0,1 \right\}
\]

and this evaluation will depend on the evaluation of atomic propositions.
If we call $\Omega = \left\{ p_1,\dots,p_n \right\}$, it depends on a valuation $v \colon \Omega \to \left\{ 0,1 \right\}$.
Connectives are interpreted naturally.

***** Observation
Sometimes $s_v(a) = s_v(b)$ regardless of $v$; in particular, $s_v(a) = 1$ regardless
of $v$ for some formulae (tautologies and absurds).

\[
s_v(A \wedge B) = s_v(B \wedge A)
\]

**** Simply typed lambda calculus
***** Definition
Taking a inductively defined set of types

 * given type $I$
 * function types $\alpha \to \beta$

The set $\Sigma$ of symbols has countably many variables of each type and the symbols of
lambda calculus $(,),\lambda, O,+,r$. We call a pair $<s,\alpha>$ a typed string; the set of
valid strings is our set of valid strings; we write $s : \alpha$ instead of $<s,\alpha> \in L$.

We have

 * $0 : I$
 * $^+ \colon I \to I$
 * $r \colon I \to (I \to I) \to I \to I$

and the usual typing rules for application and abstraction

 * if $s : \alpha, l : \alpha \to \beta$ then $sl : \beta$,
 * if $s : \beta$ and $x$ var of type $\beta$, $\lambda x.s \colon \alpha \to \beta$.

***** Semantics
We associate a set to each type, with $M(I) := \mathbb{N}$ and $M(\alpha \to \beta) := M(\beta)^{M(\alpha)}$;
and to each constant a correspondant element on the set, for example,
$M(r)$ is the unique function defined by induction.

Based on this, we construct an interpretation for each lambda term with
$M(s) \in M(\alpha)$. We give first an interpretation of variables $v = (v_{\alpha})_{\alpha \in Tp}$.
Application is interpreted as application of functions and abstraction
is interpreted as the interpretation of the body of the lambda under
a valuation that takes the bounded variable to the argument.

We can define a set of free variables of a string. Note that an
interpretation $M_{v}(x)$ with a valuation $v$ only depends on the
values of $v$ for the elements of $FV(x)$.

***** Observations
We have alpha-equivalence, beta-reduction and eta-reduction
inside the interpretation.

**** Semantics of MLTT
***** Set-theoretical semantics
It is more difficult to write a complete formalization of mltt.

We want to interpret $x_1:A_1,\dots,x_n:A_n \vdash A\ \mathrm{type}$ after interpreting

$A_1,\dots,A_n$ as sets. The interpretation will be a tuple
\[
a = \left\langle a_1,\dots,a_n \right\rangle
\]
where $a_i \in M(A_i)$, this is called the *realization of the context*.

To create an element $x_1:A_1,\dots,x_n:A_n \vdash t : A$ we should get
$M_v(t) \in M_v(A)$. We want an interpretation such that for every
definitional equality $A \equiv B$, we have the same sets $M_v(A) = M_v(B)$.

\[
M(s = t) = \left\{ \ast \right\} \mbox{ if } M(s)=M(t) \mbox{, and } \varnothing \mbox{ otherwise}
\]

But these semantics satisfy UIP.
***** Topological semantics
We interpret each type as a topological space; and each function type
as the set of continuous functions. We use simplicial sets in MLTT.

UIP does not hold under this interpretation.

*** From sets to types to categories to sets - Steve Awodey                                                   :paper:
**** 1. Sets to Types
**** 2. Types to Categories
***** Syntactic topos
**** 3. Categories to Sets
***** How to extract an elementary set theory from a topos
***** At least BIST
**** TODO 4. Composites
*** Profunctor Optics - Bartosz Milewski                                                             :optics:haskell:
#+BEGIN_SRC haskell
type Lens s t a b  = forall p. Strong p => p a b -> p s t
type Prism s t a b = forall p. Choice p => p a b -> p s t

class Profunctor p => Strong p where
  first' :: p a b -> p (a,c) (b,c)

class Profunctor p => Choice p where
  left' :: p a b -> p (Either a c) (Either b c)

class Profunctor p where
  dimap :: (a -> b) -> (c -> d) -> (p b c -> p a d)
#+END_SRC

A profunctor is a bifunctor of the form ${\cal C}^{op} \times {\cal C} \to \mathsf{Set}$.
In principle, we are not constrained to a single category,
the important notion is that the functor must be contravariant
on the first argument and covariant on the second.

#+BEGIN_SRC haskell
type f ~> g = forall x. f x -> g x
#+END_SRC

Parametricity implies naturality (?).

We have defined natural transformations as polymorphic functions.
Is this equivalent to the usual definition of natural transformation using naturality squares?

But the usual definition of natural transformations talks about naturality squares
and naturlity conditions. Are these two definitions equivalent?

Is this equivalent to the usual definition of natural transformation?
That is, does every polymorphic function satisfy the naturality condition?


**** Yoneda Lemma
#+BEGIN_SRC haskell
type Reader a x = a -> x
type Yo f a = Functor f => Reader a ~> f
-- Yo f a ~ f a
-- forall x. (a -> x) -> f x -> f a

toYo :: Functor f => f a -> Yo f a
toYo fa = \atox -> fmap atox fa

fromYo :: Functor f => Yo f a -> f a
fromYo alpha = alpha id
#+END_SRC

The Yoneda embedding

#+BEGIN_SRC haskell
forall x. (a -> x) -> (b -> x) ~ (b -> a)
#+END_SRC
*** Monad transformers - Snoyman                                                                            :haskell:
Concurrency with IO a and IO b.

*** Seemingly impossible functional programs - Escardó                                                     :topology:
#+BEGIN_SRC haskell :results output
data Bit = I | O deriving (Eq)
type Nats = Integer
type Cantor = Nats -> Bit

(#) :: Bit -> Cantor -> Cantor
x # a = \i -> if i == 0 then x else a(i-1)

forsome :: (Cantor -> Bit) -> Bit
find :: (Cantor -> Bit) -> Bit
forsome = undefined
find = undefined

main :: IO ()
main = putStrLn "hello!"
#+END_SRC

*** EUTypes Summer School
**** Introduction to type theory
***** Bibliography
HP. Barendregt. Lambda calculus: syntax and semantics.
F. Cardone, JR. Hindley. History of lambda-calculus and combinatory logic.
Statman. Lambda calculus with types.
Benjamin Pierce. Types and programming languages.
JL Krivine. Lambda calculus, types and models.

***** Introduction to type theory I
****** Introduction
******* Gentzen
Gentzen: natural deduction/sequent calculus/axiomatic system.
******* Functions
We can give multiple notions of function

 * functions as black boxes.
 * set-theoretical definition.

We can define a domain and codomain for functions. This notion leads
to the notion of the type of a function.

****** Untyped lambda calculus
******* Informal syntax
Lambda terms are divided in

 * variables, which can be bound or free. There is a countable set of
   variables.
 * application of terms, function application.
 * lambda-abstractions, function generation by binding a variable.

An example is $\lambda x. x+42$. We see the application as left-associative.

\[
M ::= x \mid MM \mid \lambda x.M
\]

******* Examples
Those are examples of lambda combinators.
 
 * $I = \lambda x.x$
 * $K = \lambda xy. x$
 * $\Delta = \lambda x . xx$
 * $Y = \lambda f.(\lambda x. f(xx))(\lambda x. f(xx))$
 * $\Omega = (\lambda x.xx)(\lambda x.xx)$.

******* Free variables and closed terms
We define the set of free variables recursively. A closed term or
*combinator* has no free variables.

******* \alpha-conversion
Renaming of bound variables. This could also be done by using *De
Bruijn* notation. We apply the Barendregt's convention of renaming
variables that would be bound after a \beta-reduction.

\[
\lambda x.M \longrightarrow_{\alpha} \lambda y.M[y/x]
\]

******* \beta-reduction
It represents function application of functions in lambda calculus.

\[
(\lambda x.M)N \longrightarrow_{\beta} M[N/x]
\]

******** Substitution as a meta notion
Substitution is an implicit meta notion that can be defined
recursively over terms

 * $x[M/x] := M$
 * $\dots$

******* \eta-conversion
It represents function extensionality

\[
\lambda x.(Mx) \longrightarrow_{\eta} M
\]

******* Normal form
A term is in *normal form* if beta-reduction cannot be applied.
For example

 * $I$ is in normal form.
 * 4$KI(KII)$ is strongly normalizing (SN) to $I$.
 * $KI\Omega$ normalizing term.
 * $Y$ is only *head-normalizable*, or solvable.

Evaluation order is important; $KI\Omega$ stops or enters an infinite loop
depending on the evaluation order; this is a normalizing but not strongly
normalizing term.

******* Confluence and the Church-Rosser theorem
If $M \to N$ and $M \to P$, then there exists $S$ such that $N \longrightarrow S$
and $P \longrightarrow S$. The proof is not trivial.

******** Corollaries
The order of applied reductions is arbitrary. The Normal form is
unique if it exists.

******* Normalisation therem
A term is in head-normal form if its head is a lambda abstraction.
A term is in normal form if there are no $\beta$ nor $\eta$ redexes.

The normalisation theorem says that the leftmost strategy results
in the normal form of $M$ if and only if it has a normal form.

******* Fixed-point theorem
There is a fixed point combinator

\[
Y \equiv \lambda f. (\lambda x.f(xx))(\lambda x.f(xx))
\]

such that $\forall F. YF \equiv F(YF)$.

******* Church encoding
Logic and arithmetic can be encoded in lambda calculus via
Church numerals.

\[
n :\equiv \lambda fx. f^n x
\]

******* Expressiveness of lambda calculus
In the 1930s

 * Kleene: it is equivalent to recursive funtions.
 * Church
 * Curry

****** Typed lambda calculus
****** Intersection types
***** Introduction to type theory II
****** Disadvantages of untyped lambda calculus

 * There exist lambda terms without normal form.
 * Meaningless expressions.

This motivates two typing paradigms

 * Implicit type assignment: lambda calculus with types.
 * Explicit type assignment: typed lambda calculus.
****** Sintatic definition of typed lambda calculus
Type assignments $M : \sigma$, declarations $x : \sigma$ and environments
$\Gamma = \left\{ x_1:\sigma_1,\dots, x_s:\sigma_s \right\}$. With rules

\begin{prooftree}
\AxiomC{}
\UnaryInfC{$\Gamma, x:\sigma \vdash x:\sigma$ }
\end{prooftree}


\begin{prooftree}
\AxiomC{$\Gamma \vdash M : \sigma \to \tau$}
\AxiomC{$\Gamma \vdash N : \sigma$}
\BinaryInfC{$\Gamma \vdash \lambda x . M : \sigma \to \tau$ } 
\end{prooftree}

\begin{prooftree}
\AxiomC{$\Gamma, x:\sigma\vdash y:\tau$}
\UnaryInfC{$\Gamma \vdash \lambda x.y : \sigma \to \tau$}
\end{prooftree}

It can be defined as a natural deduction system with introduction
and elimination rules.

****** Typing example
There are non-typable normal forms.

 * $I : \sigma \to \sigma$
 * $K : \sigma \to \tau \to \sigma$
 * $\Delta$, $Y$ or $\Omega$ can not be typed

****** Type preservation
If $M \longrightarrow P$ and $M:\sigma$, then $P:\sigma$.

****** Generation and substitution lemmas
If $\Gamma \vdash \lambda x. M: \varphi$, then $\varphi = \sigma \to \tau$ and $\Gamma, x:\sigma \vdash M : \tau$.
If $\Gamma, x:\sigma \vdash M : \tau$ and $\Gamma \vdash N:\tau$, then $\Gamma \vdash M[x/N]:\tau$.

****** Strong normalization
If $M : \sigma$, then $M$ is strongly normalizing. This was proven by
Tait in 1967.
****** Typability and inhabitation
Questions on lambda calculus

 * *Typability:* iven a term, find a type for it.
 * *Inhavitation:* given a type, construct a term of that type.
 * *Type checking:* check the type of a term.

Typability is decidable in simply typed lambda calculus. It is
decidable in second order lambda calculus with the Hindley-Milner
algoritm.

Inhabitation is equivalent to the intuitionistic logic of Gentzen's
natural deduction. The rules of typed lambda calculus are the rules
of natural deduction if we do not use the terms.

****** Curry-Howard correspondence
A formula is provable in IL iff it is inhabited in simply-typed lambda
calculus. This is also the language of Cartesian Closed Categories
(Lambek, 1970).

BHK interpretation of logical connectives is formalized by the 
Curry-Howard correspondence.

****** Consistency/Completeness/Decidability
Intuitionistic propositional logic (IL) is consistent, complete and
decidable. Due to Curry-Howard, inhabitation is decidable in STLC.
****** Lambda cube
If any $M$ is typable, $M$ is strongly normalizing.
The [[https://en.wikipedia.org/wiki/Lambda_cube][lambda cube]] represent multiple type systems.

\[\begin{tikzcd}
& & & \\
\lambda 2 & & \lambda P2 & \\
& \lambda & & \\
\lambda_{\to}& & & & \\
\end{tikzcd}\]
****** Intersection types
In our current system, $\Delta$ is not typeable. We are going to introduce
intersection types with elimination rules

\begin{prooftree}
\AxiomC{$\Gamma \vdash M : \sigma \cap \tau$}
\UnaryInfC{$\Gamma \vdash M : \sigma$}
\end{prooftree}

\begin{prooftree}
\AxiomC{$\Gamma \vdash M : \sigma \cap \tau$}
\UnaryInfC{$\Gamma \vdash M : \tau$}
\end{prooftree}

and a introduction rule

\begin{prooftree}
\AxiomC{$M:\sigma$}
\AxiomC{$M:\tau$}
\BinaryInfC{$M:\sigma\cap\tau$}
\end{prooftree}

In general, the Curry-Howard correspondance is lost here. We create
a new system $\lambda\cap$, but in this system, $\sigma \to \tau \to \sigma \cap \tau$ is provable while
it is not inhabited.

******* Now self application is typable
The self application can be of type $\lambda x.xx :((\sigma \to \tau) \cap \sigma) \to \tau$.

****** Characterization of strong normalization on intersection types
A term is typable iff it is strongly normalizing.

For example, $KI\Omega$ is not typable, even if $I$ is.

****** Typability and inhabitation are undecidable with intersection types
****** Models of lambda-calculus
We can prove completeness of type assignment. It is a theorem that

\[
\Gamma \vdash M:\sigma \iff \Gamma \models M : \sigma
\]
***** Pure type systems I
*alx@minuw.edu.pl*

****** Simple type systems
Differences between logics and type systems:

 * focus on computation instead of consistency.
 * it is meaningful to have two assumptions of the same type.
 * it is meaningful to use wh same assumption twice.

Combinatory logic, with combinators S,K, defines /minimal logic/.
With them, deduction theorem is provable. But we can add other
combinators such as B,C or W.
****** More complex type systems
We can add polymorphism with type variables. We get SystemF (aka
$\lambda 2$). We need more complex typing rules and beta reduction for types.
$\lambda P$ was proposed by deBruijn, Harper, Longo and Moggi.

****** Properties of interest of a pure type system

 1. Church-Rosser property. Values are computed deterministically.
 2. Subject reduction property. Types are invariants of the reduction.
 3. Strong normalisation property. Computation terminates.

Those properties prove consistency of the logical system.
****** Examples of PTSs
$\lambda_{\to}, \lambda 2, \lambda P, \lambda \omega, \lambda C, \lambda \ast, \lambda U$

****** Lemmas for PTSs
******* Free variables
******* Transitivity of contexts
******* Substitution
******* Weakening
******* Generation lemma
******* Condensing lemma
****** Properties of PTSs
******* Church-Rosser property
There is a PTS extended with a number of axioms which does not have
the Church-Rosser property.

******* Geuvers theorem
All functional strongly normalizing PTSs have the Church-Rosser
property.

******* Functionality
A PTS (S,A,R) is functional when A is a function from S to S and
R is a function from $S \times S$ to $S$.

******* Uniqueness of types lemma
***** Pure type systems II
****** The type inhabitation problem
**** Dependently typed programming
***** Milner's coincidence
Milner's Coincidence on Hindley-Milner's type systems

|-----------------------+--------------------------------------|
| Terms                 | Types                                |
|-----------------------+--------------------------------------|
| what we write         | we don't write these                 |
| what we read          | invisible (except errors)            |
| what gets compiled    | what gets erased                     |
| non dependent \lambda | polymorphism over types with \Lambda |
|-----------------------+--------------------------------------|

In the late 90s, this was the accepted unquestioned way of thinking
about types.
**** Homotopy type theory
The Tao of Types - Thorsten Altenkirch

 - A topological model of HoTT.

***** HoTT 1
There are multiple implementations of type theory (Coq, Agda, ...)

****** Extensionality vs intensionality
****** Set theory vs type theory
In set theory, we would write $3 \in \mathbb{N}$, and this is a proposition of the
language; we can write things like $x \in A \longrightarrow x \in B$. In type theory,
$3 : \mathbb{N}$ is instead a judgement. Statements such as $\mathbb{B}\cap \mathbb{N}$ are intensional:
they depend on the encoding.

Sometimes, we want to talk about intensional properties

****** Univalence
Two types in a one-to-one correspondence are equal.

****** Propositions as types explanation/Curry-Howard equivalence
******* Example
We will prove that $P \times Q \to R \iff P \to (Q \to R)$. We will define two
functions from and to the types

#+BEGIN_SRC haskell
f :: ((a,b) -> c) -> (a -> b -> c)
f h x y = h (x,y)

g :: (a -> b -> c) -> ((a,b) -> c)
g h (x,y) = h x y
#+END_SRC

these are curry/uncurry functions.

****** Products and sums
Products are created as

\begin{prooftree}
\AxiomC{$a:A$}
\AxiomC{$b:B$}
\BinaryInfC{$(a,b) : A \times B$}
\end{prooftree}

and sums as

\begin{prooftree}
\AxiomC{$a:A$}
\UnaryInfC{$left(a) : A +B$}
\AxiomC{$b:B$}
\UnaryInfC{$right(b):A+B$}
\noLine
\BinaryInfC{}
\end{prooftree}
 
****** Definitional equality
Equality given by the definition of the terms. These equalities are
static.

$\equiv$
****** Recursor
The recursor is a non-dependent eliminator. It gives us the ability
of doing pattern-matching on types. For example, if we want to define
a function from a pair type using the recursor for the product

\[ \mathtt{rec}^{\times} :
(A \to B \to C) \to (A \times B) \to C
\]

or a recursor for the sum type

\[ \mathtt{rec}^+ :
(A \to C) \to (B \to C) \to (A + B \to C)
\]

the recursor for the empty type

\[ \mathrm{rec}^\bot : \bot \to C
\]

is implemented without using anything because of the nature of the
empty type.
***** HoTT 2
****** What is a type?
We allow the following judgements,

 * $a:A$, type declarations.
 * $a \equiv_{A} b$, definitional equality.

and we define a universe of types ${\cal U}$, a type whose elements are types.

******* Is type a type?
If we set $Type : Type$, we can encode a version of Russell's paradox
using trees of types. Being of a type is a judgement, so we can not
encode the traditional Russell paradox.

******* Type universes
We are going to use type universes $Type_0: Type_1: Type_2 : \dots$,
constructing a *predicative* hierarchy. It is a cumulative hierarchy,
where we can lift a type $A : Type_{i}$ to $\lceil A\rceil : Type_{i+1}$ and any function
$A \to B$ to $\lceil A\rceil \to \lceil B\rceil$. 

****** Dependent types
A *dependent type* depends on a term. An example is $Fin : \mathbb{N} \to Type$.
Another example is $Vec : Type \to \mathbb{N} \to Type$ or $Prime : \mathbb{N} \to Type$.
****** Pi-types
Pi types are a generalization of function types allowing the codomain
to depend on the domain.

******* Example: zeroes

\[
zeroes : \prod_{n:\mathbb{N}} Vec\ \mathbb{N}\ n
\]

where

\[
zeroes\ n = (0,0,\dots,0)
\]

******* Example: theorems on naturals

\[
pluszero : \prod_{n : \mathbb{N}} n+0 =_{\mathbb{N}} n
\]

****** Sigma-types
Sigma tupes generalize product types to the case where the type of
second depends on the first. They work as dependent pairs.

******* Example: lists

\[
\sum_{n:\mathbb{N}} Vec\ A\ n
\]

****** Particular cases
The function type is a particular case of a pi-type, while the 
product type is a particular case of a sigma-type.

 * $\prod_{a:A} B \text{ is } A \to B$
 * $\sum_{a:A} B \text{ is } A \times B$

****** Example of predicate logic
We have the following logic equivalence in predicate logic

\[
\left(\sum_{x:A}  P\ x\right)\to Q \iff \prod_{x:A} P\ x \to Q
\]

and the proof is similar to that of $((P,Q) \to R) \to (P \to Q \to R)$.
Yesterday we talked only about propositional logic.
****** Numerical interpretation
If $f : n \to \mathbb{N}$, and we take $\overline{n}$ to be a type with $n$ elements

\[
\sum_{i:\overline{n}} \overline{f(i)}
=
\overline{\sum_{i=0}^{n-1} f(i)
\]

and the same is true for pi-types, they are related to a product.
****** Sum as a sigma type
We can define $A + B$ using $\sum_{x:2}\text{if x then } A \text{ else } B$; and the same trick
can be used for products, taking $A \times B$ to be $\prod_{x:2}\text{if x then } A \text{ else } B$.

\[\begin{tikzcd}
    & $\sum$ &          & $\prod$ &       \\
$+$  &        & $\times$ &         & $\to$
\end{tikzcd}\]

****** Eliminators of dependent types
The eliminator of the sum type is

\[
R^+ : (A \to B) \to (A \to C) \to A + B \to C
\]

and we can define a dependent version of the eliminator

\[
R^+ : \left( \prod_{x:A} C(inl(x)) \right) \to 
\left(\prod_{y:B} C(inr(y))\right) \to
\prod_{z: A+B} C(z)
\]

of which the first is a particular case.
***** HoTT 3
****** Intensional equality
****** Uniqueness of equality proofs

\[
uep : \prod_{x,y:A}\prod_{p,q: x=y} p=q
\]

******* Proof and the need for K
It has been proved that this does not depend on J using
countermodels. We need to add another eliminator called K.
If we have

\[
C : \prod_{x:A} x =x \to Type
\]

then

\[
K_C : \prod_{x:A} C\ x\ (refl\ x) \to \prod_{x:A}\prod_{p:x=x} C\ x\ p
\]

******* What can we proof without K?
The groupoid structure of paths can be proven wihtout K.

\[
\prod_{x,y:A}\prod_{p : x=y}
trans\ p\ refl = p
\]

****** Extensionality
We need extensionality to prove

\[
\lambda x. x+0 = \lambda x.0+x
\]

using that $f x = g x$ for all $x$ implies $f = g$.

******* Product
The equality of a product is the product of two equalities;
the equality of a coproduct is a coproduct, and so on.

******* Equality of types
Equivalence or isomorphism of types can be defined with two
mutually inverse functions between them. They give us a one-to-one
correspondence between types. This is written as $A \simeq B$.

We would need

\[
\eta : \prod_{x:A} g(f(x)) = x
\]

and

\[
\varepsilon : \prod_{y:B} f(g(y)) = y
\]

We could use J to prove

\[
\prod_{A,B: {\cal U}} A=B \to A \simeq B
\]

but this is not provable.

******* Automorphisms of Bool
There are two proofs of equality of Bool to Bool.

There are two ways of proving $f(g(f(x))) = f(x)$ with the previous
definition.

We fix that with

\[
\tau : \prod_{x:A} f(\eta (x)) = \varepsilon f(x)
\]

******* Definition of equivalence
This definition of isomorphism 

\[
isequiv(f) = \prod_{b:B} iscontractible \left( \sum_{a:A} f(a) = b \right)
\]

is equivalent to our previous definition of equivalence.
******* Isomorphisms and equivalence
There are more isomorphisms than equivalences, but for every
isomorphism, we can build an equivalence

\[
A \simeq B \iff A\cong B
\]

The previous definition of univalence was unsound because it
made isomorphisms and equivalences equal.
***** HoTT 4
****** What is a proposition?
****** Axiom of choice
Diaconescu; from the set-theoretical axiom of choice, we get that,
for all propositions the LEM holds, $\prod_{P:Prop} P \vee \neg P$.
****** Sets and propositions

\[ \mathtt{isSet}\ A \equiv
\prod_{x,y:A} \mathtt{isProp}(x =_{A} y)
\]

$Type_0$ is an example of something that is not a set. There are two
different proofs of the equality $Bool = Bool$.

****** n-Types

\[
isntype(A) \equiv
\prod_{x,y:A} is(n-1)type(x = y)
\]

An n-type is also an (n+1)-type.

|  -2 | Contractible type |
|  -1 | Proposition       |
|   0 | Set               |
|   1 | Groupoid          |
|   2 | 2-Groupoid        |
| ... | ...               |

The sphere $\mathbb{S}^2$ is not an n-type for any n.

****** Hedberg's theorem
Given $A:Type$ with decidable equality

\[
d : \forall x,y : A.\quad x=y \vee x \neq y
\]

it is a set, $\mathtt{isSet}(A)$.
***** HoTT 5
****** Negative translation of classical logic

 * $A \vee B \mapsto \neg (\neg P \wedge \neg Q)$
 * $\exists_{x:A}B(x) \mapsto \neg \prod_{x:A} \neg B(x)$

*** Oregon Programming Languages Summer School 2017
**** Programming Languages Background 1
A programming language is defined by

 * *statics*, how it is written;
 * *dynamics*, how it is executed;

and they should be coherent in some way.

***** Statics
 1. Concrete syntax. Linear representations, usually. Psycology of
    programming languages determines how they are written.
 2. Abstract syntax.
 3. Context-sensitive conditions and well-formation.

The practical foundation are ABT (abstract binding trees); the syntax
is generated by operators with arguments.

[7:27]
*** School on Univalent Mathematics - Birmingham
**** Spartan type theory - Andrej Bauer
**** Univalent foundations - Martin Escardo
**** Semantics for type theory - Helfer
# Notes on paper.

***** Formal languages and semantics
Traditional definition of formal languages. An alphabet and rules to
inductively construct words. We call $L$ the set of valid strings.

****** Example: boolean algebra
 * symbols $\Sigma = \left\{ p_1,\dots,p_n, \wedge,\neg,\implies,(,),\top,\bot,\dots \right\}$ 
   atomic propositions and logical symbols.
 * valid strings are defined inductively as
   * singletons $p_i$, $\top$ or $\bot$
   * connectors: if $a, b$ are valid, so are $a \wedge b, a \vee b, \neg a, \dots$

****** Semantics
The semantics assigns to each string a number $0$ or $1$,

\[
s \colon L \to \left\{ 0,1 \right\}
\]

and this evaluation will depend on the evaluation of atomic propositions.
If we call $\Omega = \left\{ p_1,\dots,p_n \right\}$, it depends on a valuation $v \colon \Omega \to \left\{ 0,1 \right\}$.
Connectives are interpreted naturally.

****** Observation
Sometimes $s_v(a) = s_v(b)$ regardless of $v$; in particular, $s_v(a) = 1$ regardless
of $v$ for some formulae (tautologies and absurds).

\[
s_v(A \wedge B) = s_v(B \wedge A)
\]

***** Simply typed lambda calculus
****** Definition
Taking a inductively defined set of types

 * given type $I$
 * function types $\alpha \to \beta$

The set $\Sigma$ of symbols has countably many variables of each type and the symbols of
lambda calculus $(,),\lambda, O,+,r$. We call a pair $<s,\alpha>$ a typed string; the set of
valid strings is our set of valid strings; we write $s : \alpha$ instead of $<s,\alpha> \in L$.

We have

 * $0 : I$
 * $^+ \colon I \to I$
 * $r \colon I \to (I \to I) \to I \to I$

and the usual typing rules for application and abstraction

 * if $s : \alpha, l : \alpha \to \beta$ then $sl : \beta$,
 * if $s : \beta$ and $x$ var of type $\beta$, $\lambda x.s \colon \alpha \to \beta$.

****** Semantics
We associate a set to each type, with $M(I) := \mathbb{N}$ and $M(\alpha \to \beta) := M(\beta)^{M(\alpha)}$;
and to each constant a correspondant element on the set, for example,
$M(r)$ is the unique function defined by induction.

Based on this, we construct an interpretation for each lambda term with
$M(s) \in M(\alpha)$. We give first an interpretation of variables $v = (v_{\alpha})_{\alpha \in Tp}$.
Application is interpreted as application of functions and abstraction
is interpreted as the interpretation of the body of the lambda under
a valuation that takes the bounded variable to the argument.

We can define a set of free variables of a string. Note that an
interpretation $M_{v}(x)$ with a valuation $v$ only depends on the
values of $v$ for the elements of $FV(x)$.

****** Observations
We have alpha-equivalence, beta-reduction and eta-reduction
inside the interpretation.

***** Semantics of MLTT
****** Set-theoretical semantics
It is more difficult to write a complete formalization of mltt.

We want to interpret $x_1:A_1,\dots,x_n:A_n \vdash A\ \mathrm{type}$ after interpreting

$A_1,\dots,A_n$ as sets. The interpretation will be a tuple
\[
a = \left\langle a_1,\dots,a_n \right\rangle
\]
where $a_i \in M(A_i)$, this is called the *realization of the context*.

To create an element $x_1:A_1,\dots,x_n:A_n \vdash t : A$ we should get
$M_v(t) \in M_v(A)$. We want an interpretation such that for every
definitional equality $A \equiv B$, we have the same sets $M_v(A) = M_v(B)$.

\[
M(s = t) = \left\{ \ast \right\} \mbox{ if } M(s)=M(t) \mbox{, and } \varnothing \mbox{ otherwise}
\]

But these semantics satisfy UIP.
****** Topological semantics
We interpret each type as a topological space; and each function type
as the set of continuous functions. We use simplicial sets in MLTT.

UIP does not hold under this interpretation.
**** Set-level mathematics - Helfer
***** Motivation
Given $X$ topological space, we say it is n-truncated if

\[
\pi_m(X) = 0 \text{ for all } m > n.
\]

 1) We know from homotopy theory that if $X$ is n-truncated, the
    space of paths between any two points is (n-1)-truncated.

 2) If $X$ is 0-truncated, it is homotopy equivalent to a discrete
    space; that is, a set.

A similar phenomenon occurs in category theory; a category has
objects, morphisms between them, morphisms between morphisms and so
on. The connection between categories and homotopical spaces is known
as the *[[https://ncatlab.org/nlab/show/homotopy+hypothesis][homotopy hypothesis]]*.

There are some definitions of ∞-groupoids for which the homotopy
hypothesis is a proven theorem.

***** H-levels
\[
\mathsf{isofhlevel} : \mathbb{N} \to {\cal U} \to {\cal U}
\]

defined as

 * $\mathsf{isoflevel}(0,X) :\equiv \mathsf{iscontr}(X)$
 * $\mathsf{isoflevel}(S(n),X) :\equiv \prod_{x,x' : X} \mathsf{isofhlevel}(n,x=x')$

****** Sets
A set is a type of h-level 2.

 * Dependent pair of sets is a set.
 * Binary product of sets is a set.
 * Dependent function from a set to a family of sets is a set.
 * Function space to a set is a set.

***** How to show that something is not a set
****** Decidable types
A type $A$ is *decidable* if $A + \neg A$.

A type $A$ has *decidable path-equality* if all path types are
decidable

\[
\prod_{x,x' : A} (x = x') + \neg (x = x')
\]

****** Hedberg's theorem
Any type with decidable equality is a set.

****** Are all types sets?
 * In spartan type theory, there are types that cannot be shown to be
   sets. It is consistent with spartan type theory to assume that all
   types are sets.
 * In univalent type theory, some types are not sets.

****** Another set

\[
\mathsf{hProp} :\equiv \sum_{X:U} \mathsf{isaprop}(X)
\]

is a set. This can be generalized: the type of types of n-level is
of (n+1)-level.

****** The universe is not a set
The booleans have a non-trivial automorphism.

****** Sets and propositions

\[
\mathsf{isInjective}(f) :\equiv \prod_{x,x' : X}f(x) = f(x') \to x = x'
\]

is a proposition when $X,Y$ as sets.

***** Set-level quotient
****** Quotient
A map compatible with a relation is a map from the quotient;
the equivalence is given by precomposition with the projection.

\[
\sum_{f \colon X \to Y} \mathsf{isCompatible}(f) \simeq X/R \to Y
\]

****** Subtype
A subtype of a type is a map from the subtype to hProp.
# Note that this definition is similar to that of the dependent sum.

******* The type of binary relations is a set

****** Defining quotients
Equivalence classes

\[
\mathsf{iseqclass}(A) = \| \mathsf{carrier}(A) \| \times 
\left( \prod_{x,y:A} Rxy \to Ax \to Ay \right)
\times 
\left( \prod_{x,y:A} Ax \to Ay \to Rxy \right)
\]

Quotients

\[
X/R :\equiv \sum_{A : X \to \mathsf{hProp}} \mathsf{iseqclass}(A)
\]

***** Set-level mathematics
****** Groups in type theory
We want the proofs of the axioms of a group to be elements of a
proposition; having this, any two groups with the same data are
equivalent.

A group isomorphism is a bijective function compatible with the
group structure; we can show that the type of equality between
of groups is the type of isomorphisms.

# Identity is isomorphism for groups!  Transport along the path given
# by univalence for a equivalence is conjugation by that equivalence.
**** Category theory - Lumsdaine
Definition of a category in the univalent setting is different than
that from a classical setting. What works the same in this
formulation and what works differently?

***** Difference
****** Definition
A *category* consists of 

 * a type of objects $\mathrm{ob}({\cal C})$;
 * for each pair of objects, a set of morphisms $\mathrm{hom}(a,b)$;

and the axioms, with are all about morphisms and they behave well with
objects not being a set.

******* Terminology
This is terminology in UniMath, in the HoTT book this is called
*precategory*. A precategory here would be just types
$\mathsf{hom}(x,y)$ but this is not discussed in the HoTT book.

******* Set-category
A set category is a category where $\mathrm{ob}({\cal C})$ is a set.

******* Carrier set
It is useful to take the carrier to be a set; in other case, we
would get a more general algebraic structure where equalities do
not work as well as in the particular case.

****** Examples
******* Sets
Sets is a category in the way we expect; but it is *not* a set
category; the set of h-sets is not an h-set. This is why we don't
want to take set-categories as our definition.

******* Simplicial set
$\Delta$ can be constructed with objects $\mathbb{N}$ and maps $m \to n$ 
as order-preserving maps $f \colon [m] \to [n]$. It is a set
category.

Small cats, combinatorially constructed ones, are set-cats in
practice.

****** Univalent categories and Rezk completion
A category is *univalent* if the canonical map (defined with identity)
$x = y \to \mathrm{Iso}(x,y)$ is an equivalence for each pair $x,y$. This is like
an internal version of univalence.

This is called /saturated category/ in the HoTT book.

******* Example: sets
Sets is univalent. Most categories in practice are univalent.
Tops, Grps, and algebraic constructions in general. Products of
univalent categories and algebras for a monad in a univalent
category are univalent.

/Heuristic:/ if the category is "the category of its objects" it will
be univalent.

******* Counterexample
The homotopy category of topological spaces where

 * objects are topological spaces,
 * and maps are continuous maps up to homotopy.

There are non-equal objects here that are homotopically-equal. It is not
the category of topological spaces but a category of homotopy types, and
we are using topological spaces only as representatives.

******* Counterexample
A preorder (category where each hom-set is a prop) is univalent iff
$\mathrm{ob}({\cal C})$ is a set and $x \leq y, y \leq x$ implies $x = y$.

******* Fact: categories have an univalent completion operation
The *Rezk completion* (Ahrens, Kapulkin, Shulman) is a sort of
univalent completion.

\[\begin{tikzcd}
& RC({\cal C}) \drar[dashed] & \\
{\cal C} \ar{rr} \urar & & {\cal E}
\end{tikzcd}\]

Given any univalent ${\cal E}$, any map factors through the completion.
The functor ${\cal C} \to RC({\cal C})$ is fully faithfull and essentially surjective.

***** What works the same?
Most things that don't mention equality of objects; modulo being
careful about existence vs chosen structure and not having the
axiom of choice.

****** Example: having products
If they exist, they are unique up to isomorphism.

****** In univalent categories
In an univalent category, they are actually unique! existence
of products is equivalent to chosen products and this is a
proposition.

****** Unimath

- Functors, natural transformations.
- Monads.
- Functor categories.
- Colimits, limits.

***** What works a little differently?
****** Displayed categories
Examples of equality on objects

 * *fibrations of categories*; for example, if ${\cal C}$ has pullbacks, the
   arrow category ${\cal C}^{\to}$ with the projection to the second object is a
   fibration.

   Typically, fibers are

   \[
   \mathrm{ob}({\cal E}) :\equiv \sum_{x : {\cal E}} \text{objects of ${\cal E}$ over ${\cal C}$}
   \]

****** Definition of displayed category
A displayed category over ${\cal C}$ has

 - for $c : \mathrm{ob}({\cal C})$, a type $\mathrm{ob}_c({\cal D})$;
 - for 

   \[\begin{tikzcd}
   d' & d \\
   c'\rar{f} & c
   \end{tikzcd}\]
 
   a set $\mathrm{hom}(d',d)$.

They 

****** Utility of displayed categories
Useful for building up categories of multi-component structures and
reasoning about them one cat at a time.

****** Example: groups
Groups are a displayed category over sets. The objects are group
structures over set; and the $\mathrm{hom}(g,g')$ is a function
between the sets together with the assumption that it preserves the
structure.
****** !
***** What works very differently?
Unexplored territory

****** 2-categories, higher categories
In univalent categories, we don't have enough strict 2-categories; in
particular, the category Cat is not a strict 2-category in the univalent
setting.
**** How to implement type theory in an hour - Andrej Bauer

 * Unicode input
 * Pretty printing
 * Loading filesv
 
***** Type checking
Bidirectional type checking.

***** Equality of types
Not every theory has an algorithm checking equality of types.

 -> We use an algorithm due to Bob Harper.
    It uses the extensionality rules to check for equality of terms.

     * Every two elements of the unit are equal.
     * We can apply a judgmental eta rule with a fresh variable.

    We have *extensional rules* for free.

It does not work with primitive symbols. Then we switch to normalization
phase and structurally compare the two weak normal form of the types.
**** Future of unimath - Ahrens
**** Presentations
***** Nominal sets
****** First definition
Given a set with decidable equality (eg. naturals), $X$ is
a nominal set...

\[
\forall x \in X, \exists A \subset \mathbb{N}, \forall u \in \mathrm{Perm}(\mathbb{N}), u|_{A} = \mathrm{id}: u(x) = x
\]
****** Presheaf definition
Ĺet $N$ be the subcategory of finite subsets of $\mathbb{N}$,
morphisms injections. A nominal set is a functor $\mathbb{N} \to \mathrm{Set}$.

** Constructivism                                                                               :constructivism:logic:
*** Intuitionistic mathematics and realizability in the physical world - Andrej Bauer                         :drill:
:PROPERTIES:
:INTERLEAVE_PDF: ~/pdf/bauer_intuitionistic_mathematics_and_realizability_in_the_physical_world.pdf
:ID:       6c678fe5-6875-41a1-a9f9-0e5343c31d35
:END:
**** Notes for page 4
:PROPERTIES:
:interleave_page_note: 4
:END:

***** Principle of micro-affinity                                                                           :drill:
SCHEDULED: <2018-07-03 Tue>
:PROPERTIES:
:ID:       4b085376-84d9-4589-aab5-31196a37346f
:DRILL_LAST_INTERVAL: 3.7488
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 5.0
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-29 Fri 22:13]
:END:
Principle of micro-affinity in synthetic differential geometry.

****** Answer
An infinitesimal change in the independent variable causes an affine
(linear) change in the dependent variable.

For any $f \colon \mathbb{R} \to \mathbb{R}$, there exists a unique $f'(x)$ such that

\[
f(x + dx) = f(x) + f'(x)dx
\]

for all nilpotent *infinitesimals* ($dx$ such that $dx^2 = 0$).

***** Non-standard analysis                                                                                 :drill:
SCHEDULED: <2018-07-03 Tue>
:PROPERTIES:
:ID:       88710dd8-2f57-4ec3-b686-fa5e9dbf4ffd
:DRILL_LAST_INTERVAL: 4.2705
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 5.0
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-29 Fri 22:21]
:END:
In which fundamental sense are Non-Standard Analysis and Synthetic
Differential Geometry different?

****** Answer

- Non-Standard Analysis is classical.
- Synthetic Differential Geometry has nilpotents.
**** Notes for page 5
:PROPERTIES:
:interleave_page_note: 5
:END:
***** Law of cancellation                                                                                   :drill:
SCHEDULED: <2018-07-06 Fri>
:PROPERTIES:
:ID:       c90276ae-709a-4ace-a332-fd03ba1ddbaa
:DRILL_LAST_INTERVAL: 5.5088
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 5.0
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-30 Sat 11:53]
:END:
Law of cancellation in synthetic differential geometry.

****** Answer
If $a\,dx = b\, dx$ for all infinitesimals $dx$, then $a = b$.

**** Notes for page 11
:PROPERTIES:
:interleave_page_note: 11
:END:

***** Unbounded Turing computable binary trees                                                              :drill:
SCHEDULED: <2018-07-03 Tue>
:PROPERTIES:
:ID:       b1e4c220-e3a8-426d-a2a7-44794ab561ea
:DRILL_LAST_INTERVAL: 3.9343
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-29 Fri 22:19]
:END:
Can an unbounded computable binary tree have no computable infinite
paths?

****** Answer
Yes, Kleene constructed one. See [[id:7e1cbeaa-95c1-44f2-a514-83b0a33d695f][König's lemma and Kleene Tree by Andrej Bauer]].

*** TODO König's lemma and Kleene Tree - Andrej Bauer
:PROPERTIES:
:INTERLEAVE_PDF: ~/pdf/bauer_könig's_lemma_and_kleene_tree.pdf
:ID:       7e1cbeaa-95c1-44f2-a514-83b0a33d695f
:END:

*** TODO Realizability as the connection between computable and constructive mathematics - Andrej Bauer
*** TODO The realizability approach to computable analysis and topology - Andrej Bauer
*** TODO First steps in synthetic computability theory - Andrej Bauer
**** 2.1. Type I computability
In Type I computability, computations are performed by partial
recursive functions on natural numbers.

**** 2.2. Type II computability
In Type II computability, computations are performed by computable
partial functions on the Baire space $\mathbb{B} = \mathbb{N}^{\mathbb{N}}$.

***** Card                                                                                                  :drill:
SCHEDULED: <2018-07-05 Thu>
:PROPERTIES:
:ID:       2bf3de9d-49f5-4393-bf32-24c4fabba4e0
:DRILL_LAST_INTERVAL: 8.1517
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.5
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-27 Wed 13:10]
:END:
Difference beeween Type I computability and Type II computability.

****** Description

 - *Type I*
   Computations are performed by partial recursive functions on natural
   numbers.

 - *Type II*
   Computations are performed by Turing machines writing infinite outputs
   on a write-only tape.  The usual domain is the Baire space $\mathbb{B}= \mathbb{N}^{\mathbb{N}}$.

**** 5. Examples from computable mathematics
Computable mathematics is the realizability interpretation of
constructive mathematics.

** Homotopy type theory                                                                                         :hott:
*** Basic homotopy type theory
**** 3. Sets and logic
***** Sets                                                                                                  :drill:
SCHEDULED: <2019-03-28 Thu>
:PROPERTIES:
:ID:       642db2e3-5cf0-4bfc-8d34-0bd7a3723374
:DRILL_LAST_INTERVAL: 317.2681
:DRILL_REPEATS_SINCE_FAIL: 6
:DRILL_TOTAL_REPEATS: 5
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.8
:DRILL_EASE: 2.9
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-05-15 Tue 23:14]
:END:
Definition of *sets* in type theory.

****** Definition
\[
\textsf{isSet}(A) \equiv \prod_{(x,y : A)} \prod_{(p,q : x = y)} p = q.
\]

***** Subtypes                                                                                              :drill:
SCHEDULED: <2019-06-13 Thu>
:PROPERTIES:
:ID:       64ba6bc2-b0cc-4863-809e-baf0200c59d3
:DRILL_LAST_INTERVAL: 350.165
:DRILL_REPEATS_SINCE_FAIL: 6
:DRILL_TOTAL_REPEATS: 8
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 4.125
:DRILL_EASE: 2.96
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-28 Thu 22:09]
:END:
Definition of *subtype* in HoTT.

****** Definition
For a family of *mere propositions* $P : A \to {\cal U}$, we write

\[
\left\{ x : A\mid P(x) \right\} 
 \equiv
\sum_{x:A} P(x)
\]

and call this a subtype of $A$.

***** Axiom of choice                                                                                       :drill:
SCHEDULED: <2019-01-27 Sun>
:PROPERTIES:
:ID:       f8e99cbf-4821-4cb3-b622-dfd84d4d4215
:DRILL_LAST_INTERVAL: 219.3012
:DRILL_REPEATS_SINCE_FAIL: 6
:DRILL_TOTAL_REPEATS: 8
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.875
:DRILL_EASE: 2.76
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-22 Fri 22:07]
:END:
*Axiom of choice* in type theory.

****** Statement

\[
\left( \prod_{x:X} \trunc{\sum_{a:A(x)} R(x,a)} \right)
\to
\trunc{\sum_{(g: \prod_{x:X}A(x))} \prod_{(x:X)} R(x,g(x))}.
\]

for a given  $R : \prod_{x:X} (A(x) \to {\cal U})$.

***** Decidable type                                                                                        :drill:
SCHEDULED: <2019-03-17 Sun>
:PROPERTIES:
:ID:       b7080b88-8de1-4c7d-b804-73dc6ff6d702
:DRILL_LAST_INTERVAL: 268.2915
:DRILL_REPEATS_SINCE_FAIL: 6
:DRILL_TOTAL_REPEATS: 5
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 5.0
:DRILL_EASE: 3.0
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-22 Fri 22:05]
:END:
Definition of *decidable type*.

****** Definition

$A + \neg A$

***** Decidable equality                                                                                    :drill:
SCHEDULED: <2019-03-10 Sun>
:PROPERTIES:
:ID:       0784e9e9-14c0-42c7-ae4a-25aa5e192c4b
:DRILL_LAST_INTERVAL: 261.2567
:DRILL_REPEATS_SINCE_FAIL: 6
:DRILL_TOTAL_REPEATS: 5
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 5.0
:DRILL_EASE: 3.0
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-22 Fri 22:05]
:END:
Definition of *decidable equality*.

****** Definition

\[
\prod_{a,b : A} (a = b) + \neg (a = b)
\]

***** Decidable type family                                                                                 :drill:
SCHEDULED: <2019-05-02 Thu>
:PROPERTIES:
:ID:       dc617b60-30a0-40c0-b631-b6277f138150
:DRILL_LAST_INTERVAL: 313.7072
:DRILL_REPEATS_SINCE_FAIL: 6
:DRILL_TOTAL_REPEATS: 5
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 5.0
:DRILL_EASE: 3.0
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-22 Fri 22:05]
:END:
Definition of *decidable type family*.

****** Definition

\[
\prod_{a : A} B(a) + \neg B(a)
\]

***** Contractible type                                                                                     :drill:
SCHEDULED: <2018-07-01 Sun>
:PROPERTIES:
:ID:       24050684-5b1f-48bc-859b-5169e66d0198
:DRILL_LAST_INTERVAL: 4.0884
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 6
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 4.333
:DRILL_EASE: 2.9
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-27 Wed 13:08]
:END:
Definition of *contractible type*.

****** Definition
\[
\isContr(A) :\equiv \sum_{a:A}\prod_{x:A}(a = x)
\]

$A$ is contractible if there exists a center of contraction $a$.

***** Mere propositions and contractibility                                                                 :drill:
SCHEDULED: <2019-04-30 Tue>
:PROPERTIES:
:ID:       8be8a4a1-667a-4a64-b96a-f07d9d46ca61
:DRILL_LAST_INTERVAL: 312.4413
:DRILL_REPEATS_SINCE_FAIL: 6
:DRILL_TOTAL_REPEATS: 7
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 4.429
:DRILL_EASE: 3.0
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-22 Fri 22:21]
:END:
Define *mere proposition* in terms of contractibility.

****** Definition
$A$ is a mere proposition iff for all $x,y : A$, the type $x = y$ is
contractible.

***** Hedberg's theorem                                                                                     :drill:
SCHEDULED: <2019-03-02 Sat>
:PROPERTIES:
:ID:       2bde59f5-b573-44cc-9aa0-319cafd7916c
:DRILL_LAST_INTERVAL: 253.0514
:DRILL_REPEATS_SINCE_FAIL: 6
:DRILL_TOTAL_REPEATS: 5
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.8
:DRILL_EASE: 2.9
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-22 Fri 22:08]
:END:
Statement of *Hedberg's theorem*.

****** Statement
If a type has decidable equality, it is a set.

**** 4. Equivalences
***** Type-theoretical fiber                                                                                :drill:
SCHEDULED: <2019-04-02 Tue>
:PROPERTIES:
:ID:       f92e8b0d-a516-41ab-af1c-47a714f0b557
:DRILL_LAST_INTERVAL: 284.1624
:DRILL_REPEATS_SINCE_FAIL: 6
:DRILL_TOTAL_REPEATS: 5
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.8
:DRILL_EASE: 2.9
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-22 Fri 22:09]
:END:
Definition of *fiber* of $f : A \to B$ over $b : B$ in HoTT.

****** Definition

\[
\fib_f(b) :\equiv \sum_{a:A}(f(a) = b).
\]

**** 11. Reals
***** Notions of constructive compactness                                                                   :drill:
SCHEDULED: <2018-07-09 Mon>
:PROPERTIES:
:ID:       4245c70a-41e5-4c32-8c1b-0fecf44d5f7d
:DRILL_LAST_INTERVAL: 11.8024
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 7
:DRILL_FAILURE_COUNT: 2
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.42
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-27 Wed 13:13]
:END:
Give the three constructive notions of compactness inside the
reals in Homotopy Type theory.

****** Three notions

 * *Metrically compact:* Cauchy complete and totally bounded.
 * *Bolzano-Weierstrass:* every sequence has a convergent subsequence.
 * *Heine-Borel:* every open cover has a finite subcover.

These are equivalent in classical mathematics.

**** Other
***** UIP is not derivable                                                                                  :drill:
SCHEDULED: <2019-03-03 Sun>
:PROPERTIES:
:ID:       59132f0b-aa24-454c-9397-622348e5b16d
:DRILL_LAST_INTERVAL: 253.5467
:DRILL_REPEATS_SINCE_FAIL: 6
:DRILL_TOTAL_REPEATS: 5
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.8
:DRILL_EASE: 2.9
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-22 Fri 22:18]
:END:
Uniqueness of Identity Proofs is not derivable in MTLL. Why?

****** Reference
In the groupoid model by Hoffmann, elements of the identity type
different from reflexivity can be built.

*** Homotopy type theory book - Univalent Foundations
:PROPERTIES:
:INTERLEAVE_PDF: ~/pdf/the_univalent_foundations_program_homotopy_type_theory.pdf
:END:

**** Preface
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (5 . 0.083235)
:END:

**** Table of Contents
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (9 . 0.083235)
:END:

**** Introduction
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (15 . 0.318161)
:END:

**** I Foundations
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (34 . 0.083235)
:END:

***** 1 Type theory
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (37 . 0.083235)
:END:

****** 1.1 Type theory versus set theory
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (37 . 0.379617)
:END:
******* Judgements and rules
Set theory is not only about seta but also about the interplay between /sets/
and /propositions/ of first-order logic, the system where sets are formulated.
In contrast, type theory does not need to be formulated inside any 
superstructure such as first-order logic. It is its own deductive system.

First-order logic is based on only one kind of judgment: whether any
given proposition as a proof; but in type theory, the basic judgment
is $a : A$, where $a$ is an element of the type $A$. Although it could
be seen as an analogous to $a \in A$ in set theory, the difference
resides in that $a \colon A$ is not a proposition but a judgment of
the theory. In particular, we cannot disprove those judgements and we
cannot talk about an element $a$ without specifying its type.

******* Propositional equality
Equality here is not a proposition but a type. Given $a,b : A$, we can define
the type $a =_A b$; we say that $a$ and $b$ are *propositionally equal* when this
type is unhabited.

******* Judgmental equality
*Judgmental equality* or *definitional equality* is an equality judgment
given by definitions: it can be decided expanding out the definitions. 
We write it as $a \equiv b$ and we introduce definitions as $a :\equiv b$.

******* Judgments of type theory
Type theory will be a system based on two forms of judgement

 * $a : A$, meaning $a$ has type $A$.
 * $a \equiv b : A$, meaning that $a$ and $b$ are definitionally equal.

******* Contexts
A *context* is a collection of assumptions in which a judgment may depend on.

# It can be thougt as a parameter space (?)
# https://en.wikipedia.org/wiki/Parameter_space

******* Rules and axioms of type theory
Rules of type theory can be grouped into type formers, procedural ways
to construct types. Usually, no axioms are necessary in type theory.

****** 1.2 Function types
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (42 . 0.984877)
:END:
******* Functions
Given types $A,B$, $A \to B$ is the type of *maps* or *functions* between them.
Functions are a primitive concept of type theory; given $f : A \to B$, it can
be applied to $a \colon A$ to obtain $f a : B$.

******** Constructing functions
Given $\Phi$, an expression of type $B$ assuming $x : A$; we can define a function
as

\[
f(x) :\equiv \Phi,
\]

and also as a \lambda-expression, written as

\[
(\lambda (x:A) . \Phi) : A \to B,
\quad
\text{ or even }
\quad
(x \mapsto \Phi) : A \to B.
\]

******* \beta-reduction
*\beta-reduction* is a computation rule defined by

\[
(\lambda x. \Phi) (a) \equiv \Phi',
\]

where every ocurrence of $x$ in $\Phi$ has been replaced by $a$ in $\Phi'$, in a way that
the binding structure is preserved; maybe renaming variables.

******* \eta-reduction
*\eta-reduction*, often called /uniqueness principle for function types/
is the computation rule defined by

\[
f \equiv (\lambda x. f(x)).
\]

******* Currying
*Currying* is a way to define multiple-input functions as functions returning
partially aplied functions. For example, $f : A \to (B \to C)$ can be applied
to two arguments as $(f\ a)\ b : C$.

****** 1.3 Universes and families
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (46 . 0.516406)
:END:
******* Universes
A *universe* is a type whose elements are types.

******** Russell's paradox
As in set theory, a universe of all types including itself, ${\cal U}_{\infty} : {\cal U}_{\infty}$, is
unsound.

******** Hierarchy of universes
A cumulative hierarchy of universes is defined, where every universe
is an elemtn of the next universe, ${\cal U}_i : {\cal U}_{i+1}$; and all the elements of
a universe are elements of all the higher universes.

\[
{\cal U}_0 : {\cal U}_1 : {\cal U}_2 : \dots
\]

*Typical ambiguity* is the writing style where we omit the level unless
it is necessary.

******* Families of types
A *family of types*, is a collection of types varying over a type
variable $A$. They are functions whose codomain is a universe, $f : A \to {\cal U}$.

****** 1.4 Dependent function types (Π-types)
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (47 . 0.768555)
:END:
******* Dependent function types
Given $A : {\cal U}$ and $B : A \to {\cal U}$, we construct the type of *dependent functions*
as $\prod_{(x:A)}B(x) : {\cal U}$.

******** Constructing dependent functions
Given $\Phi : B(x)$, a expression assuming $x : A$, we can use \lambda-abstraction
to write

\[
\lambda x . \Phi(x) : \prod_{(x:A)} B(x).
\]

******** Reductions
\beta and \eta-reductions still hold on dependent functions.

******* Polymorphic functions
A *polymorphic function* takes a type as one of its arguments, and acts on
elements of that type.

******** The identity function
The polymorphic identity function $\mathrm{id} : \prod_{(A:{\cal U})} A \to A}$ is defined as
$\mathrm{id} =& \lambda (A:{\cal U}) . \lambda (x:A) . x$.

****** 1.5 Product types
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (49 . 0.861916)
:END:
******* Cartesian product
Given $A,B : {\cal U}$, the *cartesian product type* $A \times B : {\cal U}$ contains pairs
$(a,b) : A \times B$, where $a:A$ and $b:B$. A function on a product type is
defined by

\[
f((a,b)) :\equiv g(a)(b),
\]

where $g : A \to B \to C$.

******* Unit type
The *unit type* $1$ has a unique element $\star : 1$.

******* TODO Introducing new types
******* Product type recursor
The *recursor* for product types symbolizes the fact that we can define a 
function on a product type only by giving its value on pairs,

\[ \mathtt{rec}_{A \times B}(C,g,(a,b)) = g(a)(b),
\]

where it has type

\[ \mathtt{rec}_{A \times B} : \prod_{C : {\cal U}} (A \to B \to C) \to A \times B \to C.
\]

******* TODO Unit type recursor

******* TODO Product type dependent recursor
******* TODO Propositional uniqueness principle
******* Induction principle on product types
The induction principle on product types has type

\[ \mathtt{ind}_{A \times B} :
\prod_{C : A \times B \to {\cal U}}
\left( \prod_{(x:A)} \prod_{(y:B)} C((x,y)) \right) \to
\prod_{(x:A \times B)} C(x)
\]

and defining equation $\mathtt{ind}_{A \times B} (C,g,(a,b)) :\equiv g(a)(b)$.

******* TODO Induction principle on unit types

****** 1.6 Dependent pair types (Σ-types)
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (54 . 0.861155)
:END:
******* TODO Type-theoretic axiom of choice
******* Example: Magmas
We can define a *magma* as

\[ \mathtt{magma} :\equiv
\sum_{A : {\cal U}} A \to A \to A.
\]

****** 1.7 Coproduct types
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (59 . 0.149731)
:END:
******* TODO Coproduct type
******* TODO Empty type

****** 1.8 The type of booleans
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (60 . 0.67055)
:END:
******* TODO if-then-else
******* TODO Coproducts as dependent types
****** 1.9 The natural numbers
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (62 . 0.984877)
:END:
******* TODO Natural numbers
******* Addition
We define $\mathsf{add} : \mathbb{N} \to \mathbb{N} \to \mathbb{N}$ as

 * $\mathsf{add}(0,n) \equiv n$,
 * $\mathsf{add}(\succ(m),n) \equiv \succ(\mathsf{add}(m,n))$.

******* TODO Associativity
****** 1.10 Pattern matching and recursion
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (66 . 0.793771)
:END:
We would like to define a function only writing its /defining equations/.
An example of this is this =double= function

\[\begin{aligned} 
\mathtt{double}(0) &:\equiv 0 \\ 
\mathtt{double}( \mathtt{succ}(n) ) &:\equiv \mathtt{succ} (\mathtt{succ} (\mathtt{double} (n))).
\end{aligned}\]

This style is called *pattern matching*; it is similar to recursion but
it is limited in the recursive calls it can use. Explicitly, it can be used
only as a shorthand for writing a definition using the recursor. Given

\[\begin{aligned} 
f(0) &:\equiv \Phi_0 \\ 
f( \mathtt{succ}(n) ) &:\equiv \Phi_{s},
\end{aligned}\]

we need $\Phi_s$ to depend on $f$ only via $f(n)$ in order to be well-defined as

\[
f :\equiv \mathtt{rec}_{\mathbb{N}} (C,\Phi_0,\lambda n. \lambda r. \Phi'_{s}).
\]

****** 1.11 Propositions as types
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (68 . 0.66391)
:END:
An element of the type corresponding to a proposition is a *witness* or 
a *proof* of the truth of that proposition. From this perspective, proofs
are mathematical objects per se.

******* Constructive logic
The natural interpretation of propositions-as-types is /constructive/,
meaning that certain tautologies on classical logic, such as the 
*law of excluded middle* (LEM) do not hold.

The logic is still compatible with the presence of the LEM as an axiom.

****** 1.12 Identity types
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (76 . 0.503446)
:END:

\[ \mathsf{refl} : \prod_{a:A} (a =_A a) \]

******* 1.12.1 Path induction
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (78 . 0.567577)
:END:

******* 1.12.2 Equivalence of path induction and based path induction
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (82 . 0.695977)
:END:

******* 1.12.3 Disequality
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (85 . 0.354787)
:END:

****** Notes
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (85 . 0.684066)
:END:

****** Exercises
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (88 . 0.572359)
:END:
******* DONE Exercise 1.1
#+begin_statement
Given functions $f : A \to B$ and $g : B \to C$, define their composite
$g \circ f : A \to C$. Show that we have $h \circ (g \circ f) \equiv (h \circ g) \circ f$.
#+end_statement

We define

\[
g \circ f :\equiv \lambda x.g(f(x))
\]

and thus

\[\begin{aligned}
h \circ (g \circ f) &:\equiv \lambda x. h((g \circ f)(x)) \\ 
&\equiv \lambda x. h((\lambda y.g(f(y)))(x)) \\
&\equiv \lambda x. h(g(f(x))) \\
&\equiv \lambda x. (\lambda y. h(g(y)))(f(x)) \\
&\equiv (h \circ g) \circ f.
\end{aligned}\]

******* TODO Exercise 1.2
******* TODO Exercise 1.3
******* TODO Exercise 1.4
#+begin_statement
Assuming as given only the iterator for natural numbers

\[
\mathsf{iter} : \prod_{C:{\cal U}} C \to (C \to C) \to \mathbb{N} \to C.
\]

with the defining equations

 * $\mathsf{iter}(C,c_0,c_s,0) :\equiv c_{0}$,
 * $\mathsf{iter}(C,c_0,c_s,\succ(n)) :\equiv c_s(\mathsf{iter}(C,c_0,c_s,n))$,

....
#+end_statement

******* TODO Exercise 1.5
******* DONE Exercise 1.10
#+begin_statement
Show that the Ackermann function $\mathsf{ack} : \mathbb{N} \to \mathbb{N} \to \mathbb{N}$ is definable using
only $\mathsf{rec}_{\mathbb{N}}$ satisfying the following equations

 * $\mathsf{ack}(0,n) \equiv \mathsf{succ}(n)$,

 * $\mathsf{ack}( \mathsf{succ}(m),0) \equiv \mathsf{ack}(m,1)$,

 * $\mathsf{ack}(\mathsf{succ}(m), \mathsf{succ}(n)) \equiv \mathsf{ack}(m, \mathsf{ack}(\succ(m),n)$.
#+end_statement

We can define

\[
\rec_{\mathbb{N}}\ \succ\ 
(\lambda m. \lambda a_m. 
\rec_{\mathbb{N}}\ (a_m\ 1)\ (\lambda n. \lambda a_{mn}. a_m\ a_{mn})
)
\]

where we can take $a_{m}$ to mean the $\mathsf{ack}$ function partially applied to $m$,
whereas we can take $a_{mn}$ to mean $\mathsf{ack}(m,n)$. With these definitions, we
have the base and successor equalities judgmentally.

******* DONE Exercise 1.11
#+begin_statement
Show that for any type $A$ we have $\neg\neg\neg A \to \neg A$.
#+end_statement

We write the function 

\[
\lambda f. \lambda a. f (\lambda h. h(a)) : \neg\neg\neg A \to \neg A
\]

where $f : \neg\neg\neg A$, $h : \neg A$ and $(\lambda h. h(a)) : \neg\neg A$.

******* DONE Exercise 1.12
#+begin_statement
Using the propositions as types interpretation, derive the
following tautologies

 1) if A, then (if B then A);
 2) if A, then not (not A);
 3) if (not A or not B), then not (A and B).
#+end_statement

We define the following terms

 * $\lambda a.\lambda b.a : A \to (B \to A)$;
 * $\lambda a.\lambda f.f(a) : A \to \neg\neg A$;
 * $\lambda u. \rec(u, \lambda f.\lambda (a,b).f(a), \lambda g.\lambda (a,b). g(b))$;

with the desired types.

******* DONE Exercise 1.13
#+begin_statement
Using propositions-as-types, derive the double negation of the principle
of excluded middle, i.e., prove /not (not (P or not P))/.
#+end_statement

We can define a function

\[
(\lambda f. f (\inr (\lambda p. f (\inl (p))))) 
\]

whose type is $\neg (\neg (P \vee \neg P))$ for any given $P$.

******* TODO Exercise 1.15
******* TODO Exercise 1.16
#+begin_statement
Show that addition of natural numbers is commutative,

\[
\prod_{i,j : \mathbb{N}} i + j = j + i.
\]
#+end_statement

We proceed by induction on $i$. In the first case, we have to
prove $\prod_{j : \mathbb{N}} 0 + j = j + 0$; and this can be done by induction
on $j$. In fact,

 * $\mathsf{commzero}(0) = \refl_0$,
 * $\mathsf{commzero}(S(n)) = \ap_{\succ}(\mathsf{commzero}(n))$.

***** 2 Homotopy type theory
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (91 . 0.083235)
:END:

In homotopy type theory, each type has the structure of an
$\infty\text{-groupoid}$, arising from the induction principle for
identity types.

Homotopy type theory provides a /synthetic/ description of the spaces,
in contrast with the usual analytic approach of topology.

****** 2.1 Types are higher groupoids
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (95 . 0.682291)
:END:

******* 2.1.1. Path inverse
Given $x,y : A$, there is a function called *inverse*

\[
(-)^{-1} : (x = y) \to (y = x)
\]

such that $\refl^{-1} = \refl$.

******** Proof
Given $p : x = y$, we apply path induction and then provide $\refl : x = x$.

******* 2.1.2. Path composition
Given $x,y,z : A$, there is a function called *concatenation*

\[
\cdot : (x = y) \to (y = z) \to (x = z)
\]

such that $\refl \cdot \refl = \refl$.

******** First proof
Given $p \cdot q$, we apply path induction on $p$ and $q$. Definitionally,
we can provide an element of $x = x$,

\[
\refl \cdot \refl = \refl
\]

******** Second proof
We apply path induction over $p$, and provide $q$ as an element
of $x = z$. We have $\refl \cdot q \equiv q$.

******** Third proof
We apply path induction over $q$, and provide $p$ as an element
of $x = y$. We have $p \cdot \refl \equiv p$.

******** Proof-relevance and definitional equalities
These three proofs are not definitionally equal, and they provide
different functions with sightly different definitions. In particular,
we get three different definitional equalities

 1) $\refl \cdot \refl \equiv \refl$,

 2) $p \cdot \refl \equiv p$,

 3) $\refl \cdot q \equiv q$;

and, while doing informal mathematics, we will prefer the symmetry of
the first one.

******* TODO 2.1.4. Path operation properties

******* TODO 2.1.6. Eckmann-Hilton
******* 2.1.7. Pointed type
A *pointed type* is a type with a basepoint of that type. That is,
${\cal U}_{\bullet} :\equiv \sum_{A:{\cal U}} A$ is the type of pointed types.

******* 2.1.8. Loop spaces
Given a pointed type $(A,a)$, we define the *loop space* as

\[
\Omega(A,a) :\equiv ((a=a),\refl_a)
\]

and the *n-fold iterated loop space* recursively as

 * $\Omega^0(A,a) :\equiv (A,a)$,

 * $\Omega^{n+1}(A,a) :\equiv \Omega^n(\Omega(A,a))$.

****** 2.2 Functions are functors
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (106 . 0.600341)
:END:

******* 2.2.1. Definition of ap
Given $f: A \to B$, there is an operation

\[
\ap_f : x=y \to f(x) = f(y)
\]

such that $\ap_f(\refl) \equiv \refl_{f(x)}$.

******** Notation
We write $\ap_f(p)$ as $f(p)$.

******** Proof
Trivially defined by path induction.

******* 2.2.2. Functoriality of ap
Given $f : A \to B$ and $g : B \to C$ and paths $p : x = y$ and
$q : y = z$, we have

 1) $\ap_f(p \cdot q) = \ap_f(p) \cdot \ap_f(q)$
 2) $\ap_f(p^{-1}) = ap_f(p)^{-1}$
 3) $\ap_g(\ap_f(p)) = \ap_{g \circ f}(p)$
 4) $\ap_{id_A}(p) = p$

******** Proof
Trivial by path induction on $p$.

****** 2.3 Type families are fibrations
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (107 . 0.773135)
:END:
******* 2.3.1. Transport
Given $P : A \to {\cal U}$ and $p : x = y$, there exists a function

\[
p_{\ast} : P(x) \to P(y),
\]

such that $\refl_{\ast}$ is the identity.

******** Notation
Sometimes we notate transport as

\[
p_{\ast} \equiv \transport^P(p,-) : P(x) \to P(y).
\]

******** Proof
Applying path induction over $p$, $x \equiv y$ and $\id : P(x) \to P(x)$
is an inhabitant of the type.

******* 2.3.2. Path lifting property
Given $P : A \to {\cal U}$ and $u : P(x)$, for any $p : x = y$,

\[
\mathsf{lift}(u,p) : (x,u) = (y, p_{\ast}(u));
\]

in $\sum_{x:A}P(x)$ such that $\mathsf{pr}_1(\mathsf{lift}(u,p)) = p$.

******** Proof
The first component is given by $p$, the second one can be defined
applying path induction over $p$ and, knowing that $x \equiv y$ and thus,
$u \equiv p_{\ast}(u)$.

******* 2.3.4. Dependent map
Given $f : \prod_{x:A} P(x)$ there exists a map

\[
\apd_f : \prod_{p : x=y} p_{\ast}(f(x)) =_{P(y)} f(y)
\]

******** Proof
Path induction.

******* TODO 2.3.5. Constant transport
******* TODO 2.3.8. Constant plus dependent transport
******* 2.3.9. Transport composition lemma
Given $P : A \to {\cal U}$, $p : x = y$ and $q : y = z$, for $u : P(x)$ we have

\[
q_{\ast}(p_{\ast}(u)) = (p \cdot q)_{\ast} (u).
\]

******** Proof
Double path induction.

******* TODO 2.3.10. Transport precomposition lemma
******* TODO 2.3.11. Naturality of transport
****** 2.4 Homotopies and equivalences
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (113 . 0.304028)
:END:
******* 2.4.1. Homotopy
A *homotopy* between $f, g : \prod_{x:A} P(x)$ is a dependent function
of type

\[
(f \sim g) :\equiv \prod_{x:A} f(x) = g(x).
\]

******* 2.4.2. Homotopy is an equivalence relation
Homotopy is an equivalence relation on each dependent function
type $\prod_{x:A} P(x)$. We have elements of

 1) reflexivity

    \[
    \prod_{f:\prod_{x:A} P(x)} (f \sim f)
    \]

 2) symmetry

    \[
    \prod_{f,g : \prod_{x:A}P(x)} (f \sim g) \to (g \sim f)
    \]

 3) transitivity

    \[
    \prod_{f,g,h : \prod_{x:A} P(x)} (f \sim g) \to (g \sim h) \to (f \sim h)
    \]

******** Proof
Given any $f$ and $x$, $\refl$ is of type $f(x) = f(x)$.

Given any $f,g$ such that $f \sim g$, for every $x$, we have an inhabitant of
$f \sim g$. By path induction, it must be $\refl$, so $\refl : g(x) = f(x)$.
 
Given any $f,g,h$ such that $f \sim g$ and $g \sim h$, for every $x$, we
have $f(x) = g(x) = h(x)$, and, in particular $f(x) = h(x)$.

******* 2.4.3. Naturality of homotopies
Given $H : f \sim g$ and $p : x = y$, 

\[
H(x) \cdot g(p) = f(p) \cdot H(y).
\]

As a commutative diagram,

\[\begin{tikzcd}
f(x)\rar[equal]{f(p)} \dar[swap,equal]{H(x)} & 
f(y)\dar[equal]{H(y)} \\
g(x)\rar[equal]{g(p)} &
g(y)
\end{tikzcd}\]


******** Proof
By path induction, $p = \refl$, and $\ap$ computes on reflexivity.

******* 2.4.4. Endonaturality of homotopies
Given $H : f \sim \id_{A}$, for any $x : A$,

\[
H(f(x)) = f(H(x))
\]

******** Proof
By naturality, and knowing that $H(x) : f(x) = x$, 

\[\begin{tikzcd}
f(x)\rar[equal]{f(H(x))} \dar[swap,equal]{H(x)} & 
f(f(x))\dar[equal]{H(f(x))} \\
x\rar[equal]{H(x)} &
f(x)
\end{tikzcd}\]

thus,

\[
f(H(x)) \cdot H(x) = H(f(x)) \cdot H(x),
\]

and then $f(H(x)) = H(f(x))$.

******* 2.4.6. Quasi-inverse
A *quasi-inverse* of $f : A \to B$ is a triple $(g,\alpha,\beta)$ with homotopies
$\alpha : f \circ g \sim \id_B$ and $\beta : g \circ f \sim \id_A$.

\[
\mathsf{qinv}(f) = \sum_{g:B \to A} (f \circ g \sim \id) \times (g \circ f \sim \id).
\]

******* 2.4.9. Transport has a quasi-inverse
The transport $p : x = y$ for $P \colon A \to {\cal U}$,

\[
\mathsf{transport}^P(p,-) : P(x) \to P(y)
\]

has a quasiinverse $\transport^P(p^{-1},-)$.

****** 2.5 The higher groupoid structure of type formers
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (117 . 0.979938)
:END:

****** 2.6 Cartesian product types
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (119 . 0.680777)
:END:
******* 2.6.2. Cartesian product equalities
For any $x,y$, the function

\[
x = y \to (\proj_1(x) = \proj_1(y)) \times (\proj_2(x) = \proj_2(y))
\]

given by applying projections to the equality, is an equivalence.
We denote the quasiinverse as

\[
\mathsf{pair}^{=} :
(\proj_1(x) = \proj_1(y)) \times (\proj_2(x) = \proj_2(y))
\to
x = y.
\]

******** Proof
We will define a function in the other direction. By induction,
we assume $x \equiv (a,b)$ and $y \equiv (a',b')$; thus we have $a = a'$
and $b = b'$. We apply path induction to both paths and we
get that $(a,b) \equiv (a',b')$.

Now we have to prove that it is a quasiinverse. In one direction,
if we have $r : x = y$, we apply path induction and we get the
pair $(\refl_{\proj_1(x)}, \refl_{\proj_2(x)})$. If we apply induction to $x$, we
get $(\refl_a,\refl_{b})$; our inverse takes this to $\refl_{(a,b)}$.

In the other direction, if we have $p : a = a'$ and $q : b = b'$,
we apply induction to get $\refl_{(a,b)}$; applying a function to
reflexivity gives again $(\refl_a, \refl_b)$.

******* 2.6.4. Cartesian product transport
Given two type families $A,B : Z \to {\cal U}$ and a path $p : z = w$,
for every $x : A(z) \times B(z)$,

\[
p_{\ast}(x) = (\transport^A(p,\proj_1(x)), \transport^B(p,\proj_2(x)))
\]

******** Proof
By path induction, it remains to prove

\[
x = (\proj_1(x), \proj_2(x)),
\]

which is definitionally equal.

******* 2.6.5. Functoriality under cartesian products
Given $x,y : A \times B$, $p,q$ path between components. For every function
defined as $f(x) :\equiv (g(\proj_1(x)), h(\proj_2(x)))$, it holds that

\[
f(\mathsf{pair}^{=}(p,q)) = \mathsf{pair}^{ =}(g(p),h(q)).
\]

******** Proof
We first apply induction over $x$, and then path induction over
$p,q$. We get reflexivity in both sides.

****** 2.7 Σ-types
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (123 . 0.273722)
:END:
******* 2.7.2. Sigma type equalities
Given a type family $P : A \to {\cal U}$, there is an equivalence

\[
(w = w') \simeq \sum_{p : \proj_1(w) = \proj_1(w')} 
p_{\ast}(\proj_2(w)) = \proj_2(w'). 
\]

This can be seen as an introduction $\pair^{=}$ and elimination rules
for equalities between dependent pairs.

******** Proof
********* First component of the equivalence
We define the first part of the equivalence depending on
$w,w' : \sum_{x:A}P(x)$, of type

\[
f : \prod_{w,w' : \sum_{x:A}P(x)} 
\left(
(w=w') \to
\sum_{p:\proj_1(w) = \proj_1(w')} p_{\ast}(\proj_2(w)) = \proj_2(w')
\right)
\]

by induction on the path $w = w'$ as

\[
f(w,w,\refl) = (\refl_{\pr_1(w)}, \refl_{\pr_2(w)}).
\]

********* Second component of the equivalence
And we define the second part of the equivalence depending
again on both $w,w'$, of type

\[
g : \prod_{w,w' : \sum_{x:A}P(x)}
\left( \left(
\sum_{p:\pr_1(w) = \pr_1(w')}  
p_{\ast}(\pr_2(w)) = \pr_2(w')
\right)
\to (w = w')
\right)
\]

defined by induction on $w = (x,y)$ and $w' = (x',y')$ first and then on
$p : x = x'$ and $p_{\ast}(y) = y'$, to get

\[
g((x,y),(x,y),\refl,\refl) = \refl_{(x,y)}.
\]

********* First homotopy
Finally, we have to show that they form an equivalence. Given any $w,w'$ and

\[
r : \sum_{p:\pr_1(w) = \pr_1(w')} p_{\ast}(\pr_2(w)) = \pr_2(w'),
\]

we can apply induction over both $w = (x,y)$ and $w' = (x',y')$, and then over
$r$ to get paths $p : x = y$ and $p_{\ast}(y) = y'$. By path induction and the definition
of $f$ and $g$, we get the desired result, $f(g(r)) = r$.

********* Second homotopy
On the other hand, if we have $p : w = w'$, we can directly apply path induction
and use the definitions to get $g(f(p)) = p$.

******* 2.7.3. Sigma equality to its parts
For any $z : \sum_{x:A}P(x)$, we have $z = (\pr_1(z),\pr_2(z))$.

******** Proof
By induction on $z = (x,y)$, we trivially arrive at an
identity path.

# HoTT MAILING LIST !

******** Proof in HoTT book
Applying the [[*2.7.2. Sigma type equalities][previous lemma]], we only have to provide evidence
for the equality of both projections. We trivially have

\[
\pr_1(z) = \pr_1(\pr_1(z),\pr_2(z))
\]

and by judgmental equality, it is trivial that

\[
(\refl_{\pr_1(z)})_{\ast}(\pr_2(z)) = \pr_2(z) = \pr_2(\pr_1(z),\pr_2(z)).
\]

******* 2.7.4. Transport over sigma equalities
Given $P : A \to {\cal U}$ and

\[
Q : \left( \sum_{x:A} P(x) \right) \to {\cal U},
\]

for any path $p : x = y$, and $(u,z) : \sum_{u:P(x)} Q(x,u)$ we have

\[
p_{\ast}(u,z) = 
(p_{\ast}(u), \pair^{=}(p,\refl_{p_{\ast}(u)})_{\ast} (z)).
\]

****** 2.8 The unit type
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (125 . 0.984877)
:END:
******* Unit type equality
Given $x,y:1$, we have $(x = y) \simeq 1$.

******** Proof
A function $(x = y) \to 1$ is defined trivially; and given any $x, y : 1$
we now by induction that $x \equiv y$ and we can write a constant function
to $\refl_{\star}$.

Given an element $u : 1$, it is trivial that the composite is an element
of $1$, and therefore both are equal to $\star$. Given an element $p : x = y$,
we can apply path induction to get $p = \refl_{x}$ and induction over $x$ to
get $\refl_{\star}$. As a consequence, $p$ goes to $\refl_{\star}$.

****** 2.9 Π-types and the function extensionality axiom
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (126 . 0.733191)
:END:
******* 2.9.2. happly
There exists a function

\[
\happly : (f = g) \to \prod_{x:A} f(x) = g(x)
\]

defined by path induction.

******* 2.9.3. Function extensionality axiom
The function $\happly$ is an equivalence. It has a quasi-inverse given
by

\[
\funext : \left(\prod_{x:A} f(x) = g(x)\right) \to (f = g).
\]

such that, for any $h : \prod_{x:A} f(x) = g(x)$,

\[
\happly(\funext(h), x) = h(x).
\]

******* TODO 2.9.4. Dependent identity, inverses and composition

******* 2.9.4. Rules for dependent transport
Given $f : A(x) \to B(x)$ and $p : x = y$,

\[
p_{\ast}(f) = p_{\ast}\circ f \circ p^{-1}_{\ast}.
\]

******** Proof
Path induction.

******* 2.9.6. Equivalence for the dependent function equality
Given $A,B : X \to {\cal U}$, $p : x = y$ and two functions $f : A(x) \to B(x)$
and $g : A(y) \to B(y)$, we have an equivalence

\[
(p_{\ast}(f) = g) \simeq \prod_{a:A(x)} p_{\ast}(f(a)) = g(p_{\ast}(a)).
\]

Moreover, given $q : p_{\ast}(f) = g$, we have

\[
\happly(q,p_{\ast}(a)) : (p_{\ast}(f))(p_{\ast}(a)) = g(p_{\ast}(a))
\]

equal to the composite

\[
p_{\ast}(f)(p_{\ast}(a)) = p_{\ast}(f(p^{-1}_{\ast}(p_{\ast}(a))))
= p_{\ast}(f(a)) = g(p_{\ast}(a)).
\]

******** Proof
By path induction on $p$, we arrive to function extensionality.
Computation rule for function extensionality gives us the value
of $\happly$.

******* TODO 2.9.7. Transport equivalence between families

****** 2.10 Universes and the univalence axiom
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (129 . 0.774211)
:END:
******* 2.10.1. idtoeqv
Given any types $A,B : {\cal U}$, there is a function

\[
\idtoeqv : (A = B) \to (A \simeq B).
\]

******** TODO Proof

******* 2.10.3. Voevodsky's Univalence Axiom
A universe is univalent if for any $A,B : {\cal U}$, $\idtoeqv$ is an equivalence.
All universes are univalent. There exists

\[\ua : (A \simeq B) \to (A = B),
\]

such that 

\[
\transport(\ua(f), x) = f(x).
\]

******* TODO 2.10.5. Transport and idtoeqv
****** 2.11 Identity type
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (131 . 0.796127)
:END:
******* 2.11.1. Aplication of equivalences is an equivalence
If $f : A \to B$ is an equivalence, so is

\[
\mathsf{ap}_f : (a = a') \to (f(a) = f(a')).
\]

******** Proof
Let $f^{-1}$ be a quasiinverse with homotopies

\[
\alpha : \prod_{b:B} f(f^{-1}(b)) = b
\quad\mbox{ and }\quad
\beta : \prod_{a:A}f^{-1}(f(a)) = a.
\]

the quasiinverse of $\ap_f$ will be $\ap_{f^{-1}}$ concatenated with $\beta^{-1}$ and $\beta$.
We will show that this is a quasiinverse. On one direction,

\[
\beta_a^{-1} \cdot \ap_{f^{-1}}(\ap_f(p)) \cdot \beta_{a'} = p
\]

is true by [[*2.4.4. Endonaturality of homotopies][endonaturality of the homotopy]] $\beta$ and functoriality
of the application $\ap_{f^{-1}} \circ \ap_f = \ap_{f^{-1} \circ f}$.

******* 2.11.2. Path transport
Given any $a : A$ with $p : x_1 = x_2$,

 1) for $q : a = x_1$, we have $\transport^{x \mapsto a=x}(p,q) = p_{\ast}(q) = q \cdot p$;
 2) for $q : x_1 = a$, we have $\transport^{x\mapsto x=a}(p,q) = p^{-1} \cdot q$;
 3) for $q : x_1 = x_1$, we have $\transport^{x\mapsto (x=x)}(p,q) = p^{-1} \cdot q \cdot p$.

******** Proof
By path induction on $p$, we get the composition rules for
reflexivity.

****** 2.12 Coproducts
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (134 . 0.228504)
:END:
******* 2.12.1. Characterization of equalities for coproducts
Given a coproduct type $A + B$, 

 * $(\inl(a_1) = \inl(a_2)) \simeq (a_1 = a_{2})$,
 * $(\inr(b_1) = \inr(b_2)) \simeq (b_1 = b_2)$,
 * $(\inl(a) = \inr(b)) \simeq 0$.

******** Proof
Given $a_0 : A$ we will characterize the family

\[
(x \mapsto (\inl(a_0) = x)) : A + B \to {\cal U},
\]

using the following type family

 * $\code(\inl(a)) :\equiv (a_0 = a)$,
 * $\code(\inr(a)) :\equiv 0$.

and proving that $(\inl(a_0) = x) \simeq \code(x)$ in the following
[[*2.12.5. Code for coproducts][lemma]]. An analogous family $(x \mapsto (\inr(b_0) = x))$ can be also
characterized.

******* 2.12.5. Code for coproducts
Given $a_0 : A$, for all $x:A+B$, we have $(\inl(a_0) = x) \simeq \code(x)$;
with the definition presented in the previous [[*2.12.1. Characterization of equalities for coproducts][proof]].

******** Proof
We first define a function

\[
\encode : \prod_{(x:A+B)} \prod_{(p : \inl(a_0) = x)} \code(x)
\]

using transport, as $\encode(\inl(a), p) = p_{\ast}(\refl_{a_0})$. Next, we define
a function

\[
\decode : \prod_{(x : A+B)}\prod_{(c : \code(x))} (\inl(a_0) = x)
\]

by induction on $x$ as

 * $\decode(\inl(a), c) :\equiv \ap_{\inl}(c)$,
 * $\decode(\inr(b),c) :\equiv \mathsf{abort}(c)$.

Now, we must prove that they form an equivalence. On the one hand, given
$x : A +B$ and $p : \inl(a_0) = x$, we must show that

\[
\decode(x,\encode(x,p)) = p;
\]

and this can be done by path induction on $p$. On the other hand, given
any $c : \code(x)$, we want to prove that

\[
\encode(x,\decode(x,c)) = c;
\]

and we can proceed by induction on $x$; if $x \equiv \inr(b)$, then we arrive at
a contradiction in $c$; in other case, $x \equiv \inl(a)$ so we can apply path
induction on $c$.

****** 2.13 Natural numbers
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (137 . 0.857941)
:END:
******* 2.13.0. Codes for identities on natural numbers
We define $\mathsf{code} \colon \mathbb{N} \to \mathbb{N} \to {\cal U}$ by double recursion as

 * $\code(0,0) :\equiv 1$,
 * $\code(\succ(m),0) :\equiv 0$,
 * $\code(0,\succ(n)) :\equiv 0$,
 * $\code(\succ(m),\succ(n)) :\equiv \code(m,n)$,

and trivially, a diagonal function $r : \prod_{n:\mathbb{N}} \code(n,n)$ by induction.

******* 2.13.1. Equivalence code-identity
We have $(n = m) \simeq \code(m,n)$.

******** Proof
********* Encode function
We define a function $\prod_{m,n \colon \mathbb{N}} (n = m) \to \code(m,n)$ by transport
and using the diagonal $r : \prod_{n:\mathbb{N}} \code(n,n)$.

********* Decode function
We define a function $\prod_{m,n\colon \mathbb{N}} \code(m,n) \to (n = m)$ by double induction
on $n$ and $m$.

 * On the case $n=m=0$, we define a function to $\refl_0$.
 * On the cases where only one of them is zero, we arrive a contradiction.
 * On the case were both are successors, we have an element $\code(m,n)$, so
   we can recursively apply the decode function to it to get $m = n$. Now
   it suffices to use $\ap_{\succ}$.

********* Quasiinverses I
We will show first that given any $p : m = n$,

\[
\decode(n,n,\encode(n,n,\refl)) = \refl,
\]

which is to show $\decode(n,n,r(n)) = \refl$. This can be done by induction
on $n$, where in the case $0$, we get reflexivity and in the successor case,
we use that $\ap(\refl) = \refl$.

********* Quasiinverses II
Given any $c : \code(m,n)$, we can apply double induction.

 * In the zero case, we have a unit type that remains the same after
   encoding.
 * In the only one successor case, we arrive a contradiction.
 * In the both successor cases, 
   \[\begin{aligned}
   \encode&(\succ(m),\succ(n),\decode(\succ(m),\succ(n),c)) \\
     &= \encode(\succ(m),\succ(n),\ap_{\succ}(\decode(m,n,c))) \\
     &= (\ap_{\succ}(\decode(m,n,c)))_{\ast} (r(\succ(m))) \\
     &= (\decode(m,n,c))_{\ast} (r(m)) \\
     &= \encode(m,n,\decode(m,n,c)) \\
     &= c
   \end{aligned}\]
   by induction.

In other words, we can prove that each code is a diagonal and then
apply induction over $\decode(m,n,c)$.

******* 2.13.2. Zero is not a successor
We have that zero is not the successor of any natural number,
in particular

\[
\encode(\succ(m),0) : (\succ(m) = 0) \to 0.
\]

******** Proof
Applying [[*2.13.1. Equivalence code-identity][decode-encode]] directly.

******* 2.13.3. Successor is injective
The sucessor function is injective, in particular

\[
(\succ(m) = \succ(n)) \to (m = n).
\]

******** Proof
We can apply $\encode$ to the equality and get a new code
to which apply $\decode$. Note that

$\encode(\succ(m),\succ(n)) : \code(m,n)$

is well-typed.

****** 2.14 Example: equality of structures
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (139 . 0.984877)
:END:

******* 2.14.1 Lifting equivalences
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (140 . 0.879418)
:END:
******** 2.14.1. Semigroup structures
The type of *semigroup structures* on $A$ is defined as

\[
\mathsf{SemigroupStr}(A) :\equiv \sum_{(m : A \to A \to A)} \prod_{(x,y,z : A)} m(x,m(y,z)) = m(m(x,y),z)
\]

and a *semigroup* is defined in general as

\[
\mathsf{Semigroup} :\equiv \sum_{A : {\cal U}} \mathsf{SemigroupStr}(A).
\]

******** 2.14.1. Induced structures
Given an equivalence $e : A \simeq B$, we can transport semigroup
structures

\[
(\ua(e))_{\ast} : \mathsf{SemigroupStr}(A) \to \mathsf{SemigroupStr}(B).
\]

Given $(m,a) : \mathsf{SemigroupStr}(A)$, we want to compute

\[
\ua(e)_{\ast} (m,a) : \mathsf{SemigroupStr}(B)
\]

and transporting over a [[*2.7.4. Transport over sigma equalities][coproduct]] is the same as transporting over its
components. We will get some $(m',a')$ where

 * $m'(b_1,b_2) :\equiv (\ua(e)_{\ast}(m))(b_1,b_2)$;

 * $a' :\equiv (\pair^{=}(\ua(e), \refl))_{\ast}\ a$.

By function extensionality, we only have to check the behaviour of
$m'$ given a pair of arguments. We have,
# UA is quasi-inverse to transport^(X \to X)

\[\begin{aligned}
m'(b_1,b_2) &=
\ua(e)_{\ast} (m (\ua(e)_{\ast}^{-1} b_1, \ua(e)_{\ast}^{-1} b_2)) \\
&= e(m(e^{-1}b_1,e^{-1}b_2))
\end{aligned}\]

It can be proved that the transported $a'$ works by algebraic
manipulation using this fact.

******* 2.14.2 Equality of semigroups
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (142 . 0.612707)
:END:

****** 2.15 Universal properties
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (143 . 0.779086)
:END:
******* 2.15.2. Universal property of the product
There is an equivalence

\[
(X \to A \times B) \simeq (X \to A) \times (X \to B);
\]

given by $f \mapsto (\pr_1 \circ f, \pr_2 \circ f)$.

******** TODO Proof

******* 2.15.5. Dependent universal property of the product
There is an equivalence

\[
\left( \prod_{x:X} A(x) \times B(x) \right) \simeq
\left( \prod_{x:X} A(x) \right) \times 
\left( \prod_{x:X} B(x) \right)
\]

given by $f \mapsto (\pr_1 \circ f, \pr_2 \circ f)$.

******** TODO Proof

******* 2.15.7. Theorem of choice
There is an equivalence

\[
\left( \prod_{x:X}\sum_{(a : A(x))} P(x,a) \right) \simeq
\left( \sum_{g : \prod_{x:X}A(x)} \prod_{x:X} P(x,g(x)) \right)
\]

trivially determined.

******** TODO Proof

******* 2.15.11. Pullbacks
Given $f : A \to C$ and $g : B \to C$, we define the *pullback* as

\[
A \times_C B :\equiv \sum_{(a:A)}\sum_{(b:B)}(f(a) = g(b)).
\]

****** Notes
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (146 . 0.729471)
:END:

****** Exercises
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (149 . 0.525005)
:END:
******* TODO Exercise 2.1
#+begin_statement
Show that the three obvious proofs of Lemma 2.1.2 are pairwise equal.
#+end_statement

******* TODO Exercise 2.2
******* TODO Exercise 2.3
******* TODO Exercise 2.4
******* TODO Exercise 2.5
******* TODO Exercise 2.6
******* TODO Exercise 2.7
******* TODO Exercise 2.8
******* TODO Exercise 2.9
******* DONE Exercise 2.10
#+begin_statement
Prove that \Sigma-types are associative, in that for any $A : {\cal U}$ and
families $B : A \to {\cal U}$ and $C : \left(\sum_{x:A} B(x)\right) \to {\cal U}$, we have

\[
\left( \sum_{x:A}\sum_{y:B(x)} C(x,y) \right)
\simeq
\left( \sum_{p : \sum_{x:A}B(x)} C(p) \right)
\]
#+end_statement

We first define a function

\[
f : \left( \sum_{x:A}\sum_{y:B(x)} C(x,y) \right)
\to
\left( \sum_{p : \sum_{x:A}B(x)} C(p) \right)
\]

by induction on the argument, as

\[
f (x,y,c) :\equiv ((x,y),c).
\]

Now we have to prove that this is an equivalence with two homotopies,
with an inverse defined by induction

\[
g((x,y),c) :\equiv (x,y,c).
\]

In fact, given any $(x,y,c)$, or any $((x,y),c)$ it is trivial to check
that there exist two homotopies. Note how we use induction to get the
constructors of the pair.
******* TODO Exercise 2.11
#+begin_statement
A homotopy commutative square

\[\begin{tikzcd}
P\rar{h} \dar[swap]{k} & A \dar{f} \\
B\rar{g} & C
\end{tikzcd}\]

consists of functions $f,g,h$ and $k$ as shown, together with a path $f \circ h = g \circ k$.
Note that this is exactly an element of the pullback $(P \to A) \times_{(P \to C)} (P \to B)$
as defined in (2.15.11). A commutative square is called a (homotopy)
*pullback square* if for any $X$, the induced map

\[
(X \to P) \to (X \to A) \times_{(X \to C)} (X \to B)
\]

is an equivalence. Prove that the pullback $P :\equiv A \times_C B$ defined in (2.15.11)
is the corner of a pullback square.
#+end_statement

******* TODO Exercise 2.12
******* DONE Exercise 2.13
#+begin_statement
Show that $(2 \simeq 2) \simeq 2$.
#+end_statement

We have $(2 \simeq 2)$ with two possible elements determined by the function
given by $2 \to 2$. If we take $\id : 2 \to 2$, that is a trivial equivalence,
and if we take $\neg : 2 \to 2$ we have a different equivalence. 

Now, given any function $f : 2 \to 2$, we can apply induction to both
$f(1)$ and $f(0)$ and then, by function extensionality, assert that it
has to be a constant function or some of the previous equivalences.
We only have two possible equivalences then.

We declare a function taking $\id$ to $\mathsf{true}$ and $\neg$ to $\mathsf{false}$, the inverse
is trivially defined.

******* DONE Exercise 2.14
#+begin_statement
Suppose we add to type theory the equality reflection rule which says
that if there is an element $p : x = y$, then in fact $x \equiv y$. Prove that
for any $p : x = x$ we have $p \equiv \refl$.
#+end_statement

Given any $p : x = y$, we have $x \equiv y$, and we can prove the (well-typed!)
equality $p = \refl$ by path induction. Note that we have used the equality
reflection rule to prove that 

\[
\prod_{x,y : A}\prod_{p : x=y} p = \refl_x
\]

is actually well-typed.

******* TODO Exercise 2.15
******* TODO Exercise 2.16
#+begin_statement
Suppose that rather than function extensionality (Axiom 2.9.3),
we suppose only the existence of an element

\[
\mathsf{funext} : \prod_{A:{\cal U}} \prod_{B:A \to {\cal U}} \prod_{f,g : \prod_{x:A}B(x)} (f \sim g) \to (f = g).
\]
#+end_statement

******* TODO Exercise 2.18
#+begin_statement
State and prove a version of Lemma 2.4.3 for dependent functions.
#+end_statement

***** 3 Sets and logic
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (153 . 0.083235)
:END:

****** 3.1 Sets and n-types
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (153 . 0.661767)
:END:
******* 3.1.1. Sets
A type $A$ is a *set* if every two equalities $p,q : x =_A y$ are equal.

\[
\textsf{isSet}(A) \equiv \prod_{(x,y : A)} \prod_{(p,q : x = y)} p = q.
\]

******* 3.1.6. Dependent product of sets is a set
Given $A$ a set and $B : A \to {\cal U}$ such that each $B(x)$ is a set, $\prod_{x:A} B(x)$ 
is a set.

******** Proof
Suppose $f, g : \prod_{x:A} B(x)$ and $p, q : f = g$. Applying function
extensionality,

 * $p = \mathsf{funext}(\lambda x. \mathsf{happly}(p,x))$,
 * $q = \mathsf{funext}(\lambda x. \mathsf{happly}(q,x))$.

Since $B(x)$ is a set, 

 * $\mathsf{happly}(p,x) : f(x) = g(x)$
 * $\mathsf{happly}(q,x) : f(x) = g(x)$

must be equal. Thus, by function extensionality $(\lambda x. \mathsf{happly}(p,x)) = (\lambda x. \mathsf{happly}(q,x))$,
and applying $\mathsf{funext}$, $p = q$.

******* 3.1.7. 1-types
A type $A$ is a *1-type* if for all $x,y:A$ and $p,q : x = y$ and $r,s : p = q$,
we have $r = s$.

******* 3.1.8. Every set is a 1-type
Every set is a *1-type*.

******** Proof
If we have $x,y : A$, $p,q : x = y$ and $f : \isSet(A)$, then we
can define $g = f(x,y,p)$ by partial application, and

\[
g : \prod_{q : x = y}(p = q);
\]

we can now, given $r : q = q'$, use dependent application to get

\[
\apd_g(r) : r_{\ast}(g(q)) = g(q').
\]

By path transport, that means that $g(q) \cdot r = g(q')$. In particular,
given any two $r,s : p = q$;

\[
g(p) \cdot r = g(q) = g(p) \cdot s
\]

and $r = s$ by cancellation.

******* 3.1.9. Not all types are sets
The universe ${\cal U}$ is not a set.

******** TODO Proof
We take $2$ to be the type of the booleans. There exists a
function $\mathrm{not}\colon 2 \to 2$ which is an equivalence; by univalence,
there exists $\ua(\mathrm{not}) \colon 2 = 2$ which is not $\refl$. If it were
$\refl$, then, by univalence, $0_2 = 1_2$.

****** 3.2 Propositions as types?
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (156 . 0.601855)
:END:

******* 3.2.2. Negation of double negation
It is not true that $\neg(\neg A) \to A$ for each $A : {\cal U}$.

******** Proof
Given $f \colon \prod_{A:{\cal U}} \neg(\neg A) \to A$, we will arrive to a contradiction.

Let $p \colon 2 = 2$ be the non-trivial path of the booleans. We know
that $f(2) : \neg\neg 2 \to 2$ and

\[
\apd_f(p) : p_{\ast}(f(2)) = f(2),
\]

applying [[*2.9.4. Rules for dependent transport][rules for dependent transport]], we have

\[
p_{\ast}(f(2))(u) = (p_{\ast} \circ f(2) \circ p_{\ast}^{-1})(u).
\]

Every two $u,v : \neg\neg 2$ are equal by function extensionality; thus

\[
p^{-1}_{\ast}(u) = u
\]

and so

\[
p_{\ast}(f(2)(u)) = p_{\ast}(f(2))(u) = f(2)(u).
\]

We have now that $\fnot(f(2)(u)) = f(2)(u)$, and, at the same time,
it is obvious that $\prod_{x:2} \neg (\fnot(x) = x)$.

******* 3.2.7. Negation of LEM
It is not true that $A + (\neg A)$ for each $A \colon {\cal U}$.

******** Proof
An element of type $\prod_{A:{\cal U}} \neg\neg A \to A$ can be constructed from
an element of type $\prod_{A:{\cal U}} A + (\neg A)$.

****** 3.3 Mere propositions
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (158 . 0.984877)
:END:

******* 3.3.1. Mere proposition
A type $P$ is a *mere proposition* when

\[
\isProp(P) : 
\prod_{x,y : P} x = y
\]

is inhabited.

******* 3.3.2. Truth is the only true mere proposition
If $P$ is a mere proposition and $x_0 : P$, then $P \simeq 1$.

******** Proof
A trivial equivalence can be constructed.

******* 3.3.3. Equivalence of connected mere propositions
If $P$ and $Q$ are mere propositions, $P \to Q$ and $Q \to P$
imply $P \simeq Q$.

******** Proof
If $f : P \to Q$ and $g : Q \to P$, then $f(g(x)) = x$ and
$g(f(x)) = x$ because both are mere propositions.

******* 3.3.4. Mere propositions are sets
Every mere proposition is a set.

******** Proof
Given $f : \isProp(A)$, we fix $x : A$ and define $g(y) :\equiv f(x,y)$
of type $\prod_{y : A} x = y$. Given two $y,z : A$ with $p : y = z$, we
have

\[
\apd_g(p) : p_{\ast}(g(y)) = g(z)
\]

hence $g(y) \cdot p = g(z)$, or $p = g(y)^{-1} \cdot g(z)$; thus given $p,q : x = y$
we have $p = g(x)^{-1} \cdot g(y) = q$.

******* 3.3.5. isProp and isSet are mere propositions
Given any type $A$, the types $\isSet(A)$ and $\isProp(A)$ are mere
propositions.

******** Proof
If we have $f,g : \isProp(A)$, we know that $f(x,y) = g(x,y)$ because
$A$ is a mere proposition. By function extensionality, $f = g$.

If we have $f,g : \isSet(A)$ we know that $f(x,y,p,q) = g(x,y,p,q)$
because $x = y$ is a mere proposition from the fact that $A$ is a set.
By function extensionality, $f = g$.

****** 3.4 Classical vs. intuitionistic logic
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (161 . 0.251814)
:END:

******* 3.4.1. Law of excluded middle
We define the *law of excluded middle* as

\[
\LEM :\equiv \prod_{A : {\cal U}} \Big( \isProp(A) \to (A + \neg A) \Big)
\]

whereas the usual general law of excluded middle is renamed as

\[
\LEM_{\infty} :\equiv \prod_{A : {\cal U}} (A + \neg A).
\]

The law of excluded middle can be assumed as an axiom.

******* 3.4.3. Decidable types
1. A type is *decidable* if $A + \neg A$.

2. A type family is *decidable* if

   \[
   \prod_{a : A} B(a) + \neg B(a)
   \]

3. A type has *decidable equality* if
   
   \[
   \prod_{a,b : A} (a = b) + \neg (a = b)
   \]

The Law of excluded middle says that all mere propositions are
decidable.

****** 3.5 Subsets and propositional resizing
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (163 . 0.371394)
:END:
******* 3.5.1. Uniqueness of dependent sum of mere propositions
Given $P \colon A \to {\cal U}$ such that $P(a)$ is always a mere proposition;
if $u,v \colon \sum_{x:A}P(x)$ are such that $\proj_1(u) = \proj_1(v)$, then
$u = v$.

******** Proof
Given $p : \proj_1(u) = \proj_1(v)$, we only have to show that

\[
p_{\ast}(\proj_2(u)) = \proj_2(v)
\]

and this is true because both are members of $P(\proj_1(v))$, a
mere proposition.

******* 3.5.1. Subtypes
If $P$ is a family of mere propositions, we write

\[
\sum_{x:A} P(x) \equiv \left\{ x : A\mid P(x) \right\}
\]

and call this a *subtype*. We can define membership and subsets
analogously.

******** Subuniverses of sets and mere propositions
We define

 * $\Set_{{\cal U}} :\equiv \left\{ A : {\cal U} \mid \isSet(A) \right\}$,
 * $\Prop_{{\cal U}} :\equiv \left\{ A : {\cal U} \mid \isProp(A) \right\}$.

There are natural maps $\Set_{{\cal U}_i} \to \Set_{{\cal U}_{i+1}}$.

******* 3.5.2. Propositional resizing
*Propositional resizing* is the fact that the natural map
$\Prop_{{\cal U}_i} \to \Prop_{{\cal U}_{i+1}}$ is an equivalence.

Propositional resizing can be taken as an axiom.

******** Omega-indexation of propositions
From propositional resizing follows the existence of $\Omega$, a
type that indexes mere propositions. If propositional resizing
is true, $\Omega :\equiv \Prop_{{\cal U}_0}$.

******** Powersets
If propositional resizing is true, we can define

\[
{\cal P}(A) :\equiv (A \to \Omega),
\]

which is independent of the universe.
****** 3.6 The logic of mere propositions
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (165 . 0.61291)
:END:
******* TODO 3.6.1. Product of mere propositions is a mere proposition
******* TODO 3.6.2. Dependent functions to mere propositions are mere propositions
******* TODO 3.6.2. Sums of mere propositions are not mere propositions

****** 3.7 Propositional truncation
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (166 . 0.643534)
:END:

******* 3.7.0. Propositional truncation type
For any $A$ there is a *truncation type* $\trunc{A}$, with constructors

 * $|a| : \trunc{A}$ for any $a : A$;
 * $x=y$ for any $x,y : \trunc{A}$;

ensuring that it is a mere proposition.

******** Recursion principle
If $B$ is a mere proposition and $f : A \to B$, then there exists
$g : \trunc{A} \to B$ such that $g(|a|) \equiv f(a)$ for all $a:A$.

******* 3.7.1. Traditional logical notation
We define

 * $\top :\equiv 1$,

 * $\bot :\equiv 0$,

 * $P \land Q :\equiv P \times Q$,

 * $P \lor Q :\equiv \trunc{P + Q}$,

 * $P \Rightarrow Q :\equiv P \to Q$,

 * $P \Leftrightarrow Q :\equiv P = Q$,

 * $\neg P :\equiv P \to 0$,

 * $\forall (x:A). P(x) :\equiv \prod_{x:A} P(x)$,

 * $\exists (x:A).P(x) :\equiv \trunc{\sum_{x:A} P(x)}$.

******* 3.7.2. Traditional set notation
We define

 * $\left\{ x:A\mid P(x) \right\} \cap \left\{ x:A \mid Q(x) \right\} :\equiv \left\{ x:A \mid P(x) \wedge Q(x) \right\}$,
 * $\left\{ x:A \mid P(x) \right\} \cup \left\{ x:A \mid Q(x) \right\} :\equiv \left\{ x:A\mid P(x) \lor Q(x) \right\}$,
 * $A \setminus \left\{ x:A\mid P(x) \right\} :\equiv \left\{ x:A \mid \neg P(x) \right\}$.

Note how the latter are not complements in the absence of LEM.

****** 3.8 The axiom of choice
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (168 . 0.729181)
:END:
******* 3.8.1. The axiom of choice
Given a $X$ and type families $A : X \to {\cal U}$, $P : \prod_{x:X} (A(x) \to {\cal U})$
such that $X$ and $A(x)$ are always sets and $P(x,a)$ is always a
mere proposition; the *axiom of choice* asserts

\[
\left( \prod_{x:X} \trunc{\sum_{a:A(x)} P(x,a)} \right)
\to
\trunc{\sum_{(g: \prod_{x:X}A(x))} \prod_{(x:X)} P(x,g(x))}.
\]

In logical notation, this means,

\[
\bigg( \forall (x:X). \exists (a:A(x)). P(x,a) \bigg)
\Rightarrow
\left( \exists \bigg(g: \prod_{x:X}A(x)\bigg). \forall (x:X). P(x,g(x)) \right)
\]

******* 3.8.2. Simpler axiom of choice
The axiom of choice is equivalent to 

\[
\left( \prod_{x:X} \trunc{Y(x)} \right) \to
\trunc{ \prod_{x:X} Y(x) }
\]

for any $X$ and $Y(x)$ always sets.

******** TODO Proof

******* TODO 3.8.5. Counterexample to the simpler version

****** 3.9 The principle of unique choice
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (171 . 0.234132)
:END:
******* 3.9.1. Equivalence of mere propositions and truncations
If $P$ is a mere proposition, $P \simeq \trunc{P}$.

******** Proof
We apply the universal property to $\id$ to get $\trunc{P} \to P$;
and we have a $P \to \trunc{P}$ by definition. This [[*3.3.3. Equivalence of connected mere propositions][proves]] an
equivalence of mere propositions.

******* 3.9.2. The principle of unique choice
Given $P \colon A \to {\cal U}$ such that

 * $P(x)$ is always a mere proposition;
 * $\trunc{P(x)}$ is always true.

Then $\prod_{x:A}P(x)$.

******** TODO Proof

****** 3.10 When are propositions truncated?
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (172 . 0.437266)
:END:

****** 3.11 Contractibility
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (175 . 0.459436)
:END:
******* 3.11.1. Contractible type
A type $A$ is *contractible*, or *singleton* if there is a center of
contraction $a : A$ such that $a = x$ for all $x : A$.

\[
\isContr(A) :\equiv \sum_{a:A}\prod_{x:A}(a = x)
\]

******* 3.11.3. Characterization of contractibility
Given $A$, the following are equivalent

 1. $A$ is contractible,
 2. $A$ is a mere proposition, and there is a point $a:A$,
 3. $A$ is equivalent to $1$.

******** Proof
If $A$ is contractible, it has a point $a : A$ and every two other
points are equal to it.

If $A$ is an inhabited mere proposition, it is equivalent to $1$.

And $1$ is contractible.

******* TODO 3.11.4. Contr is a mere proposition
******* TODO 3.11.5. Contractibility of Contr
******* TODO 3.11.6. Dependent product of contractible types
******* TODO 3.11.7. Retracts and contractibility
******* TODO 3.11.8.
******* TODO 3.11.9.
******* 3.11.10. Mere propositions and contractibility
$A$ is a mere proposition iff for all $x,y : A$, the type $x = y$ is
contractible.

******** TODO Proof
If $A$ is a mere proposition, then $x = y$ must be true; it must be
also a set, so $x=y$ must be contractible.

If $x=y$ is contractible, it is inhabited, so $A$ is a mere
proposition.

****** Notes
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (178 . 0.596795)
:END:

****** Exercises
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (179 . 0.721841)
:END:
******* DONE Exercise 3.1
#+begin_statement
Prove that if $A \simeq B$ and $A$ is a set, then so is $B$.
#+end_statement

The equivalence gives us a pair of functions $f : A \to B$ and $g : B \to A$
with homotopies $\eta : g \circ f \sim \id$ and $\epsilon : f \circ g \sim \id$. By naturality of
$\eta$ we have, for any two paths $p,q : x =_B y$, that

\[\begin{tikzcd}
fg(x)\rar[equal]{fg(p)} \dar[swap,equal]{\eta_x} & 
fg(y)\dar[equal]{\eta_y} \\
x \rar[equal]{p} &
y
\end{tikzcd}\]

and

\[\begin{tikzcd}
fg(x)\rar[equal]{fg(q)} \dar[swap,equal]{\eta_x} & 
fg(y)\dar[equal]{\eta_y} \\
x \rar[equal]{q} &
y
\end{tikzcd}\]

but $g(p) = g(q)$ because $A$ is a set, so $fg(p) = fg(q)$ and therefore, $p=q$.

******* DONE Exercise 3.2
#+begin_statement
Prove that if $A$ and $B$ are sets, then so is $A + B$.
#+end_statement

Note that $A + B = \prod_{x:2} C(x)$ for some family $C$, and we know that the
[[*3.1.6. Dependent product of sets is a set][dependent product of sets is a set]].

******* TODO Exercise 3.3
******* TODO Exercise 3.4
#+begin_statement
Show that $A$ is a mere proposition if and only if $A \to A$ is
contractible.
#+end_statement

******* TODO Exercise 3.5
#+begin_statement
Show that $\isProp(A) \simeq (A \to \isContr(A))$.
#+end_statement

******* TODO Exercise 3.6
#+begin_statement
Show that if $A$ is a mere proposition, then so is $A + (\neg A)$. Thus,
there is no need to insert a propositional truncation in 3.4.1.
#+end_statement

******* TODO Exercise 3.9
#+begin_statement
Show that if $\LEM$ holds, then the type $\Prop :\equiv \sum_{A:{\cal U}} \isProp(A)$
is equivalent to $2$.
#+end_statement

******* TODO Exercise 3.21
#+begin_statement
Prove that $\isProp(P) \simeq (P \simeq \trunc{P})$.
#+end_statement

***** 4 Equivalences
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (183 . 0.083235)
:END:

****** 4.1 Quasi-inverses
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (184 . 0.216036)
:END:

******* 4.1.1. Characterization of the quasi-inverse type
If given $f : A \to B$, $\qinv{}(f)$ is inhabited,

\[
\qinv(f) \simeq \prod_{x:A}(x=x)
\]

******** TODO Proof
As $f$ is an equivalence, we apply univalence to get $p : A = B$.
Applying path induction, $p = \refl$ and $f = \id$. Then,

\[
\qinv(\id) \equiv \sum_{g : A \to A} (g \sim \id) \times (\id \sim g)
\]

which is equivalent by function extensionality to

\[
\sum_{g : A \to A} (g = \id) \times (g = \id)
\]

******* 4.1.2. Existence of center
Given $a : A$ and $q : a = a$ such that

 1. $a = a$ is a set,
 2. $\trunc{a = x}$ for all $x : A$,
 3. $p \cdot q = q \cdot p$ for all $p : a = a$,

there exists $f : \prod_{x:A}(x = x)$ such that $f(a) = q$.

******** TODO Proof
******* 4.1.3. qinv is not always a mere proposition
There exists a function such that $\qinv(f)$ is not a mere
proposition.

******** TODO Proof

****** 4.2 Half adjoint equivalences
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (186 . 0.984877)
:END:

******* 4.2.1. Half adjoint equivalence
A function $f : A \to B$ is a *half adjoint equivalence* if

\[
\ishae(f) :\equiv
\sum_{(g : B \to A)}
\sum_{(\eta : g \circ f \sim \id_{A})}
\sum_{(\epsilon : f \circ g \sim \id_{B})}
\prod_{(x:A)}
f(\eta(x)) = \epsilon(f(x))
\]

that is, there exist two homotopies and a coherence condition
between them.

******* 4.2.2. Logical equivalence of half adjoint equivalences
Given $f : A \to B$ and $g : B \to A$ with homotopies $\eta : g \circ f \sim \id$ and
$\epsilon : f \circ g \sim \id$, the following two types are logically equivalent

 * $\prod_{x:A}f(\eta(x)) = \epsilon(f(x))$,

 * $\prod_{x:A} g(\epsilon(x)) = \eta(g(x))$.

******** Proof
We will prove the second homotopy from $\tau : \prod_{x:A}f(\eta(x)) = \epsilon(f(x))$;
simmetry gives us the other direction.

By [[*2.4.4. Endonaturality of homotopies][endonaturality of homotopies]] in $\epsilon$ we have

\[\begin{tikzcd}
fgfg(x) \rar[equal]{fg \epsilon(x)} \dar[swap,equal]{\epsilon fg(x)} & 
fg(x) \dar[equal]{\epsilon(x)} \\
fg(x) \rar[equal]{\epsilon(x)} &
x
\end{tikzcd}\]

and applying $g$ to the complete diagram renders

\[\begin{tikzcd}
gfgfg(x) \rar[equal]{gfg\epsilon(x)} \dar[swap,equal]{g\epsilon fg(x)} & 
gfg(x) \dar[equal]{g\epsilon(x)} \\
gfg(x) \rar[equal]{g\epsilon(x)} &
gx
\end{tikzcd}\]

applying now the homotopy $\tau(g(x))$, we get $g \epsilon fg(x) = gf \eta g(x)$;
and again by [[*2.4.4. Endonaturality of homotopies][naturality]], we have $gf \eta g(x) = \eta gfg(x)$, and the
diagram is

\[\begin{tikzcd}
gfgfg(x) \rar[equal]{g fg\epsilon(x)} 
\dar[swap,equal]{\eta gfg(x)} & 
gfg(x) \dar[equal]{g\epsilon(x)} \\
gfg(x) \rar[equal]{g\epsilon(x)} &
gx
\end{tikzcd}\]

Meanwhile, by naturality of $\eta$ between $gfgfg$ and $gfg$, we have that

\[\begin{tikzcd}
gfgfg(x) \rar[equal]{g fg\epsilon(x)} 
\dar[swap,equal]{\eta gfg(x)} & 
gfg(x) \dar[equal]{\eta g(x)} \\
gfg(x) \rar[equal]{g\epsilon(x)} &
gx
\end{tikzcd}\]

and joining both diagrams we get $\eta g(x) = g \epsilon(x)$.

******* 4.2.3. qinv implies ishae
It is obvious that $\ishae$ implies $\qinv$.
For any $f : A \to B$ we have $\qinv(f) \to \ishae(f)$.

******** Proof
Given a quasiinverse $(f,g,\eta,\epsilon)$, we will define a new tuple
$(f,g,\eta,\epsilon',\tau')$; taking $\epsilon'$ to be

\[
\epsilon'(b) :\equiv \epsilon fg(b)^{-1} \cdot f\eta g(b) \cdot \epsilon(b)
\]

so we need to find an homotopy

\[
\tau(a) : f\eta(a) = \epsilon fgf(a)^{-1} \cdot f \eta gf(a) \cdot \epsilon f(a)
\]

but we know by [[*2.4.4. Endonaturality of homotopies][endonaturality]] that $\eta gf(a) = gf \eta(a)$ and by
homotopy that

\[
f \eta gf(a) \cdot \epsilon f(a) = fgf\eta(a) \cdot \epsilon f(a) = \epsilon fgf(a) \cdot f\eta(a).
\]

******* 4.2.4. Fiber of a map
The *fiber* of $f : A \to B$ over a point is

\[
\fib_f(y) :\equiv \sum_{x:A}(f(x) = y).
\]

******* 4.2.5. Equality of fibers
Given $f : A \to B$ and $(x,p), (x',p') : \fib_f(y)$,

\[
((x,p) = (x',p'))
\simeq
\left( \sum_{\gamma : x = x'} f(\gamma) \cdot p' = p \right)
\]

******** TODO Proof
# Path lemmas

******* 4.2.6. Fibers of half-adjoint equivalences are contractible
If $\ishae(f)$ for $f : A \to B$, then $\fib_f(y)$ is contractible for any $y : B$.

******** TODO Proof

******* 4.2.7. Left and right inverses
Given $f : A \to B$ we define

 * its *left inverses*, $\linv(f) :\equiv \sum_{g : B \to A} (g \circ f \sim \id)$,

 * its *right inverses*, $\rinv(f) :\equiv \sum_{g \colon B \to A}(f \circ g \sim \id)$.

****** 4.3 Bi-invertible maps
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (192 . 0.224058)
:END:
******* 4.3.1. Bi-invertible
A function $f : A \to B$ is *bi-invertible* if it
[[*4.2.7. Left and right inverses][has left and right inverses]]

\[
\biinv(f) :\equiv \linv(f) \times \rinv(f).
\]

******* 4.3.2. biinv is a mere proposition
The type $\biinv(f)$ is a mere proposition for any $f : A \to B$.

******** TODO Proof

******* 4.3.3. Equivalence biinv and ishae
Given $f : A \to B$, we have $\qinv(f) \simeq \ishae(f)$.

******** TODO Proof

****** 4.4 Contractible fibers
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (192 . 0.979938)
:END:
******* 4.4.1. Contractible maps
A function $f : A \to B$ is *contractible* if $\fib_f(y)$ is contractible
for every $y : B$; that is, we define

\[
\isContr(f) :\equiv \prod_{y:B} \isContr(\fib_f(y)).
\]

******* 4.4.3. isContr implies ishae
For any $f : A \to B$, we have $\isContr(f) \to \ishae(f)$.

******** TODO Proof

******* 4.4.4. isContr is a mere proposition
For any $f$, the type $\isContr(f)$ is a mere proposition.

******** TODO Proof
******* 4.4.5. isContr is equivalent to ishae
For any $f : A \to B$, we have $\isContr(f) \simeq \ishae(f)$.

******** TODO Proof
****** 4.5 On the definition of equivalences
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (194 . 0.590656)
:END:

We have proved equivalent

\[
\isContr(f) \simeq \ishae(f) \simeq \biinv(f)
\]

so we choose $\isequiv{}(f) :\equiv \ishae(f)$.

****** 4.6 Surjections and embeddings
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (195 . 0.172333)
:END:

******* 4.6.0. Isomorphisms
When two sets are equivalent, we say that they is an *isomorphism*
or a *bijection*.

******* 4.6.1. Surjections and embeddings
A function $f : A \to B$ is

 * *surjective* if $\trunc{\fib_f(b)}$ for every $b : B$;
 * *embedding* if $\ap_f : (x=y) \to (f(x) = f(y))$ is an equivalence.

******** Split surjection
We say that a function $f : A \to B$ is a *split surjection* if

\[
\prod_{b:B}\sum_{a:A} f(a) = b.
\]

Note that it is a stronger assertion than being surjective, that
only asks for an inhabitant without constructive evidence.

******** Axiom of choice and split surjections
The [[*3.8.1. The axiom of choice][axiom of choice]] says exactly that every surjection between sets is
split.

******* 4.6.2. Characterization of embeddings
A function $f : A \to B$ between sets is an embedding if and only if

\[
\prod_{x,y:A} f(x) = f(y) \to x = y.
\]

And we say that it is an *injection*.

******** Proof
We apply that $f(x) = f(y)$ and $x = y$ are mere propositions to get
an equivalence from the logical implications.

******* 4.6.3. Equivalence is surjection and embedding
Any function $f : A \to B$ is an equivalence if and only if it is both
surjective and an embedding.

******** TODO Proof

******* 4.6.4. Equivalence is equivalent to surjection and embedding
For any $f : A \to B$,

\[
\isequiv(f) \simeq \isEmbedding(f) \times \isSurjective(f).
\]

****** 4.7 Closure properties of equivalences
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (196 . 0.792414)
:END:

******* 4.7.1. The 2-out-of-3 property
If any two $f,g,g\circ f$ are equivalences, so is the third.

******** Proof
Given $g \circ f$ and $g$ equivalences, we show that $(g \circ f)^{-1} \circ g$ is a
quasi-inverse to $f$ because

 * on the one hand,

   \[
   ((g \circ f)^{-1} \circ g) \circ f \sim \id_{A}
   \]

 * on the other hand,

   \[\begin{aligned}
   f \circ (g \circ f)^{-1} \circ g &\sim
   g^{-1} \circ g \circ f \circ (g \circ f)^{-1} \circ g \\
   &\sim g^{-1} \circ g \\
   &\sim \id.
   \end{aligned}\]

In a similar way, we can prove the other two pair of equivalences.

******* 4.7.2. Retracts
A function $g : A \to B$ is a *retract* of $f : X \to Y$ in

\[\begin{tikzcd}
A \rar{s}\dar{g} & X \rar{r}\dar{f} & A\dar{g} \\
B \rar{s'}& Y \rar{r'}& B
\end{tikzcd}\]

if

 * $R : s \circ r \sim \id$,
 * $R' : s' \circ r' \sim \id$,
 * $L : f \circ s \sim s' \circ g$,
 * $K : g \circ r \sim r' \circ f$.
 * a path $H(a)$ witnessing commutativity of

   \[\begin{tikzcd}
   grs(a) \dar[equal,swap]{g(Ra)}\rar[equal]{Ks(a)} & r'fs(a) \dar[equal]{r'(La)} \\
   g(a)  \rar[equal]{R'(ga)^{-1}} & r's'g(a) \\
   \end{tikzcd}\]

******* TODO 4.7.3. Retract of equivalence is equivalence
******* TODO 4.7.5. 

****** 4.8 The object classifier
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (199 . 0.979938)
:END:
******* TODO 4.8.1. Fiber of a type family
******* TODO 4.8.2. 
******* 4.8.3. Object classifier
Given any type $B$ there is an equivalence

\[
\chi :
\left( \sum_{A:{\cal U}}(A \to B) \right) \simeq (B \to {\cal U}).
\]

******** TODO Proof
We can define 

 * $\chi((A,f),b) :\equiv \fib_f(b)$

 * $\psi(P) :\equiv \left( \left(\sum_{b:B} P(b) \right), \pr_1 \right)$

and now verify that this constitutes an equivalence.

****** 4.9 Univalence implies function extensionality
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (202 . 0.553567)
:END:
We do not assume function extensionality on this section.

******* 4.9.1. Weak function extensionality principle
The *weak function extensionality principle* asserts that,
for any family $P : A \to {\cal U}$,

\[
\left( \prod_{x:A} \isContr(P(x)) \right)
\to
\isContr \left( \prod_{x:A}P(x) \right).
\]

******* 4.9.2. Equivalence on slice objects
If ${\cal U}$ is univalent, $A,B,X : {\cal U}$ and $e : A \simeq B$, there is 
an equivalence

\[
(X \to A) \simeq (X \to B).
\]

******** TODO Proof

******* TODO 4.9.3. 
******* TODO 4.9.5. Weak function extensionality implies function extensionality
The weak function extensionality principle implies the axiom
of [[*2.9.3. Function extensionality axiom][function extensionality]].

******** Proof

****** Notes
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (205 . 0.335925)
:END:

****** Exercises
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (205 . 0.984877)
:END:

***** 5 Induction
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (209 . 0.083235)
:END:

****** 5.1 Introduction to inductive types
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (209 . 0.463989)
:END:
******* 5.1.1. Uniqueness of functions over the natural numbers
Given $f,g : \prod_{n:\mathbb{N}} E(x)$ with

\[
e_z : E(0)
\quad\text{ and }\quad 
e_s : \prod_{n:\mathbb{N}}E(n) \to E(\succ(n)) 
\]

such that $f(0) = e_z = g(0)$ and

 * $\prod_{n:\mathbb{N}} f(\succ(n)) = e_s(n,f(n))$,
 * $\prod_{n:\mathbb{N}} g(\succ(n)) = e_s(n,g(n))$;

then $f$ and $g$ are equal.

******** Proof
We apply induction on $n$ over the type family $f(n) = g(n)$.
In the base case, $f(0) = g(0)$; and in the successor case,
knowing that $f(n) = g(n)$,

\[
f(\succ(n)) = e_s(n,f(n)) = e_s(n,g(n)) = g(\succ(n)).
\]

******* TODO 5.2. Uniqueness of inductive types
****** 5.2 Uniqueness of inductive types
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (212 . 0.840835)
:END:

****** 5.3 W-types
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (216 . 0.171897)
:END:

****** 5.4 Inductive types are initial algebras
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (219 . 0.996777)
:END:
******* 5.4.1. N-algebra
A $\mathbb{N}\text{-algebra}$ is a type with two elements

\[
\mathbb{N}\text{alg} :\equiv \sum_{C:{\cal U}} C \times (C \to C).
\]

******* 5.4.2. N-homomorphism
A $\mathbb{N}\text{-homomorphism}$ between algebras is a function preserving
the zero and successor elements up to path equality

\[
\mathbb{N}\text{Hom}((C,c_0,c_s), (D,d_0,d_s)) :\equiv
\sum_{h \colon C \to D} (h(c_0) = d_0) \times \left( \prod_{c:C} h(c_s(c)) = d_s(h(c)) \right).
\]

******* 5.4.3. Homotopy initial N-algebra
An algebra is homotopy initial if the type of homomorphisms to any
other algebras is contractible; that is

\[
\isHinit_{\mathbb{N}}(I) :\equiv \prod_{C : \mathbb{N}\text{Alg}} \isContr(\mathbb{N}\text{Hom}(I,C)).
\]

******* TODO 5.4.4. Uniqueness of homotopy initial N-algebras

******* TODO 5.4.5. The naturals are an homotopy initial N-algebra
******* TODO 5.4.6. W-algebras
****** 5.5 Homotopy-inductive types
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (223 . 0.673142)
:END:

****** 5.6 The general syntax of inductive definitions
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (228 . 0.348776)
:END:

****** 5.7 Generalizations of inductive types
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (233 . 0.839872)
:END:

****** 5.8 Identity types and identity systems
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (237 . 0.233446)
:END:

****** Notes
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (242 . 0.701526)
:END:

****** Exercises
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (243 . 0.480867)
:END:

***** 6 Higher inductive types
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (247 . 0.083235)
:END:

****** 6.1 Introduction
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (247 . 0.377078)
:END:

****** 6.2 Induction principles and dependent paths
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (249 . 0.979938)
:END:

******* 6.2.1. Propositional equality by definition
In the case of higher inductive types, we give equalities by
definition that use non-fundamental parts of the type theory,
and so they are propositional instead of judgmental.

We write them as $f(\mathsf{loop}) := \ell$ to indicate this fact.

******* 6.2.2. Notation for dependent paths
We write dependent paths as

\[
(u =^P_p v) :\equiv \transport^P(p,u) = v.
\]

******* 6.2.5. Non-dependent computation rule of the circle
Given $a : A$ with $p : a = a$, there is a function $f : \mathbb{S}^1 \to A$ such
that

 * $f(\base) :\equiv a$,
 * $\ap_f(\mathsf{loop}) :\equiv p$.

******** TODO Proof

****** 6.3 The interval
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (255 . 0.575336)
:END:
******* 6.3.0. The interval
We denote $I$ to the type generated by

 * $0_I : I$, a start point,
 * $1_I : I$, an end point,
 * $\seg : 0_I = 1_I$, a segment between points.

******** TODO Induction principle of the interval
******** TODO Recursion principle of the interval
******* 6.3.1. The interval is contractible
The type $I$ is contractible.

******** Proof
We define a function of type $\prod_{i:I}(i = 1)$, by induction over the
interval

 * $f(0) :\equiv \seg$,
 * $f(1) :\equiv \refl_1$,

and $\apd_f(\seg) : \seg_{\ast}(\seg) = \refl$ can be defined knowing
that this type is equivalent to $\seg^{-1} \cdot \seg = \refl$, and
that path inverse is an inhabitant.

******* TODO 6.3.2. Extensionality from the interval type

****** 6.4 Circles and spheres
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (257 . 0.229024)
:END:

****** 6.5 Suspensions
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (259 . 0.984877)
:END:
******* 6.5.0. Suspension of a type
The *suspension* of a type $A$ is a type $\Sigma A$ defined by the
generators

 * north, $\N : \Sigma A$;

 * south, $S : \Sigma A$;

 * and meridians, $\merid : A \to (\N = \S)$.

******** TODO Induction principle

******* 6.5.1. Circle as suspension
The circle can be seen as the suspension of the booleans,

\[
\Sigma 2 \simeq \mathbb{S}^{1}.
\]

******** TODO Proof

****** 6.6 Cell complexes
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (263 . 0.984877)
:END:

****** 6.7 Hubs and spokes
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (265 . 0.648892)
:END:

****** 6.8 Pushouts
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (267 . 0.457813)
:END:

****** 6.9 Truncations
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (271 . 0.620396)
:END:

****** 6.10 Quotients
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (275 . 0.1231)
:END:

****** 6.11 Algebra
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (280 . 0.984877)
:END:

****** 6.12 The flattening lemma
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (287 . 0.415721)
:END:

****** 6.13 The general syntax of higher inductive definitions
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (293 . 0.998326)
:END:

****** Notes
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (296 . 0.348989)
:END:

****** Exercises
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (297 . 0.789835)
:END:

***** 7 Homotopy n-types
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (299 . 0.083235)
:END:

****** 7.1 Definition of n-types
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (299 . 0.984877)
:END:
******* 7.1.1. is-n-type
We define $\istype{n} : {\cal U} \to {\cal U}$ as

\[
\istype{n}(X) :\equiv
\left\{\begin{array}{ll}
\isContr(X) & \mbox{if } n = -2, \\
\prod_{x,y:X} \istype{n'}(x = y) & \mbox{if } n = n' + 1.
\end{array}\right.
\]

******* TODO 7.1.4. Retraction of an n-type
******* TODO 7.1.5. Equivalence preserves n-types
****** 7.2 Uniqueness of identity proofs and Hedberg's theorem
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (304 . 0.230568)
:END:
******* TODO 7.2.0. Uniqueness of identity proofs (UIP)

******* 7.2.1. Axiom K
A type $A$ is a set if and only if it satisfies *Axiom K*, for
all $x:X$ and $p : x = x$, we have $p = \refl$.

******** TODO Proof

******* 7.2.2. Mere identity relations in sets
Given $R$ a reflexive mere relation on $X$ implying identity, $X$
is a set and $R(x,y) \simeq (x = y)$ for all $x,y :X$.

******** Proof
Given $\rho : \prod_{x:X}R(x,x)$ and $f : \prod_{x,y}R(x,y) \to (x = y)$, we have
that if $X$ is a set, $x = y$ is a mere proposition logically equivalent
to $R(x,y)$. On the other hand, if $x = y$ is equivalent to $R(x,y)$ and
it is a mere proposition, $X$ is a set.

We can give two proofs, either proving that $X$ is a set or that $R(x,y)$
is equivalent to $x = y$.

********* X is a set
Given $x:X$ and $p : x = x$, we consider

\[
\apd_{f(x)}(p) : p_{\ast}(f(x,x)) = f(x,x)
\]

which, by [[*2.9.6. Equivalence for the dependent function equality][path equalities for dependent functions]] gives us a path

\[
p_{\ast}(f(x,x,r)) = f(x,x,p_{\ast}(r)).
\]

Knowing that $R(x,x)$ is a mere proposition, $p_{\ast}(r) = r$; and transport
in the identity type is equal to concatenation, so

\[
f(x,x,r) \cdot p = f(x,x,r)
\]

and $p = \refl$, satisfying axiom K.

********* TODO R is equivalent to equality

******* 7.2.3. A type with double negation cancellation equality is a set
If $X$ has the property $\neg\neg (x=y) \to (x=y)$, it is a set.

******** Proof
We have $\neg\neg(x=y)$ as a reflexive mere relation implying identity,
so we can apply the previous [[*7.2.2. Mere identity relations in sets][lemma]].

******* 7.2.5. Hedberg's theorem
If a type has [[*3.4.3. Decidable types][decidable]] equality, it is a set.

******** TODO Proof.

******* TODO 7.2.6. Natural numbers form a set
The type of natural numbers has decidable equality, and hence is a set.

******** TODO Proof
Given $x,y : \mathbb{N}$, we proceed by induction in both arguments. In the first
case, $\refl_0$ proves the equality; in the case of a successor and a zero,
we can apply 

****** 7.3 Truncations
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (308 . 0.475366)
:END:

****** 7.4 Colimits of n-types
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (315 . 0.536449)
:END:

****** 7.5 Connectedness
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (320 . 0.65016)
:END:
******* 7.5.1. n-connected function
A function $f : A \to B$ is *n-connected* if $\trunc{\fib_f(b)}_n$ is
contractible for all $b : B$.

\[
\conn_n(f) :\equiv \prod_{b:B} \isContr(\trunc{\fib_f(b)}_n)
\]

A type $A$ is *n-connected* if the function $A \to 1$ is.

******* TODO 7.5.2. Surjectivity is (-1)-connectedness
A function is (-1)-connected iff it is [[*4.6.1. Surjections and embeddings][surjective]].
****** 7.6 Orthogonal factorization
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (326 . 0.984877)
:END:

****** 7.7 Modalities
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (332 . 0.979938)
:END:

****** Notes
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (338 . 0.477456)
:END:

****** Exercises
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (339 . 0.682024)
:END:

**** II Mathematics
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (345 . 0.083235)
:END:

***** 8 Homotopy theory
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (347 . 0.083235)
:END:

We define the *homotopy groups* of a pointed type $(A,a)$ as

\[
\pi_n(A,a) :\equiv \trunc{\Omega^n(A,a)}_{0}.
\]

****** 8.1 π₁(S¹)
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (352 . 0.436728)
:END:

******* 8.1.1 Getting started
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (352 . 0.671895)
:END:
We define $\mathsf{code} : \mathbb{S}^1 \to {\cal U}$ by recursion as

 * $\mathsf{code}(\mathsf{base}) :\equiv \mathbb{Z}$,
 * $\mathsf{code}(\mathsf{loop}) :\equiv \ua(\succ)$.

******* 8.1.2 The classical proof
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (353 . 0.646195)
:END:
We have that

 * $\transport^{\mathsf{code}}(\mathsf{loop},x) = x + 1$,
 * $\transport^{\mathsf{code}}(\mathsf{loop},x) = x -1$.

******* 8.1.3 The universal cover in type theory
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (354 . 0.480867)
:END:

******* 8.1.4 The encode-decode proof
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (356 . 0.704682)
:END:

******* 8.1.5 The homotopy-theoretic proof
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (359 . 0.827644)
:END:
We define the function $\mathsf{encode} : \prod_{x:\mathbb{S}^1}(\base = x) \to \mathsf{code}(x)$ by

\[
\mathsf{encode}\ p :\equiv \transport^{\mathsf{code}}(p,0).
\]

******* 8.1.6 The universal cover as an identity system
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (361 . 0.409399)
:END:
We can define a function $\mathsf{decode} : \prod_{x:\mathbb{S}^1} \mathsf{code}(x) \to (\base = x)$.

******** TODO Definition
******* 8.1.7 Encode-decode of a path
For all $x : \mathbb{S}^1$ and $p : \base = x$,

\[
\mathsf{decode}(\mathsf{encode}(p)) = p.
\]

******** TODO Proof
****** 8.2 Connectedness of suspensions
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (363 . 0.380733)
:END:

****** 8.3 π_(k≤n) of an n-connected space and π_(k<n)(Sⁿ)
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (365 . 0.2169)
:END:

****** 8.4 Fiber sequences and the long exact sequence
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (365 . 0.842291)
:END:

****** 8.5 The Hopf fibration
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (371 . 0.459893)
:END:

******* 8.5.1 Fibrations over pushouts
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (372 . 0.66545)
:END:

******* 8.5.2 The Hopf construction
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (374 . 0.446319)
:END:

******* 8.5.3 The Hopf fibration
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (375 . 0.996941)
:END:

****** 8.6 The Freudenthal suspension theorem
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (378 . 0.839517)
:END:

****** 8.7 The van Kampen theorem
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (386 . 0.69401)
:END:

******* 8.7.1 Naive van Kampen
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (387 . 0.556292)
:END:

******* 8.7.2 The van Kampen theorem with a set of basepoints
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (393 . 0.233446)
:END:

****** 8.8 Whitehead's theorem and Whitehead's principle
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (397 . 0.828618)
:END:

****** 8.9 A general statement of the encode-decode method
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (402 . 0.451157)
:END:

****** 8.10 Additional Results
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (404 . 0.424413)
:END:

****** Notes
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (405 . 0.501647)
:END:

****** Exercises
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (407 . 0.37052)
:END:

***** 9 Category theory
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (409 . 0.083235)
:END:

****** 9.1 Categories and precategories
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (410 . 0.745723)
:END:

****** 9.2 Functors and transformations
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (415 . 0.260174)
:END:

****** 9.3 Adjunctions
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (419 . 0.682161)
:END:

****** 9.4 Equivalences
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (420 . 0.744738)
:END:

****** 9.5 The Yoneda lemma
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (427 . 0.984877)
:END:

****** 9.6 Strict categories
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (431 . 0.979938)
:END:

****** 9.7 †-categories
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (432 . 0.979938)
:END:

****** 9.8 The structure identity principle
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (434 . 0.399634)
:END:

****** 9.9 The Rezk completion
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (437 . 0.98337)
:END:

****** Notes
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (447 . 0.083235)
:END:

****** Exercises
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (448 . 0.634425)
:END:

***** 10 Set theory
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (451 . 0.083235)
:END:

****** 10.1 The category of sets
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (452 . 0.193966)
:END:

******* 10.1.1 Limits and colimits
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (452 . 0.367507)
:END:

******* 10.1.2 Images
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (452 . 0.779886)
:END:

******* 10.1.3 Quotients
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (457 . 0.21413)
:END:

******* 10.1.4 Set is a ΠW-pretopos
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (459 . 0.980218)
:END:

******* 10.1.5 The axiom of choice implies excluded middle
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (461 . 0.295056)
:END:

****** 10.2 Cardinal numbers
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (463 . 0.255527)
:END:

****** 10.3 Ordinal numbers
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (466 . 0.992398)
:END:

****** 10.4 Classical well-orderings
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (474 . 1.009469)
:END:

****** 10.5 The cumulative hierarchy
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (478 . 0.680281)
:END:

****** Notes
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (485 . 0.979938)
:END:

****** Exercises
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (486 . 0.727911)
:END:

***** 11 Real numbers
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (491 . 0.083235)
:END:

****** 11.1 The field of rational numbers
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (492 . 0.622338)
:END:

****** 11.2 Dedekind reals
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (493 . 0.485995)
:END:

******* 11.2.1 The algebraic structure of Dedekind reals
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (495 . 0.639703)
:END:
******** Dedekind cuts
A *Dedekind cut* is a pair $(L,U)$ of mere predicates such that
it is

 1) /inhabited:/ $\exists (q : \mathbb{Q}). L(q)$ and $\exists (r : \mathbb{Q}) . U(r)$;

 2) /rounded:/ for all $q,r \in \mathbb{Q}$,

    * $L(q) \iff \exists (r : \mathbb{Q}). (q < r) \wedge L(r)$

    * $U(r) \iff \exists(q:\mathbb{Q}).(q < r) \wedge U(q)$

 3) /disjoint:/ $\neg (Lq \wedge Uq)$ for all $q:\mathbb{Q}$,

 4) /located:/ $(q < r) \implies Lq \vee Ur$ for all $q,r : \mathbb{Q}$.

We define $\isCut(L,U)$ as the mere proposition of the conjunction
of these conditions. The set of *Dedekind reals* is defined as

\[
\mathbb{R}_d :\equiv
\left\{ (L,U) : (\mathbb{Q} \to \Omega) \times (\mathbb{Q} \to \Omega)
\mid \isCut(L,U) \right\}. 
\]

******** Rational embedding
To each rational $q$, we associate $L_q(r) :\equiv (r < q)$ and
$U_q(r) :\equiv (q < r)$.

******** Algebraic structure
We define addition as

\[
L_{x+y}(r) :\equiv \exists (t,s :\mathbb{Q}),\quad L_x(t) \land L_y(s) \land (t + s = q)
\]

and multiplication

\[\begin{aligned}
L_{x\cdot y}(q) :\equiv \exists (a,b,c,d : \mathbb{Q}), &\quad
L_x(a) \land U_x(b) \land L_y(c) \land U_y(d) \land \\ 
& (q < \min(ac,ad,bc,bd))
\end{aligned}\]

This has structure of commutative ring.

******** TODO Order
******** Weak linearity
Linearity, $(x < y) \lor (y \leq x)$, is valid only if we assume LEM. We
have *weak linearity* $(x < y) \to (x < z) \lor (z < y)$.
******** Apartness
\[
(x \apart y) :\equiv (x < y) \lor (y < x)
\]

we have $(x \apart y) \to \neg (x = y)$, but the converse is not true.

********* TODO Apartness is cotransitive
******** Invertibility
A real is invertible if and only if it is apart from 0.

******** Archimedean principle for Rd
If $x,y : \mathbb{R}$ such that $x < y$, then there merely exists $q : \mathbb{Q}$
such that $x < q < y$.


******* 11.2.2 Dedekind reals are Cauchy complete
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (498 . 1.003216)
:END:
******** Cauchy sequence
A sequence $x : \mathbb{N} \to \mathbb{Q}$ is *Cauchy* if

\[
\prod_{(\epsilon : \mathbb{Q}_+)} \sum_{(n:\mathbb{N})}
\prod_{(m,k \geq n)} |x_m-x_k| < \epsilon
\]

note how we can get a modulus of convergence out of this explicit
existential by Theorem of Choice.

******** Cauchy approximation
A *Cauchy approximation* is a map $x \colon \mathbb{Q}_+ \to \mathbb{R}_d$ such that

\[
\forall (\delta,\epsilon : \mathbb{Q}_+), |x_{\delta} - x_{\epsilon}|
< \delta + \epsilon,
\]

and its *limit* is $l : \mathbb{R}_d$ such that

\[
\forall (\epsilon, \theta : \mathbb{Q}_+), |x_{\epsilon}- l| < \epsilon + \theta
\]

******** Completeness for Cauchy approximations
Every Cauchy approximation has a limit.

********* TODO Proof

******** TODO Completeness for Cauchy sequences

******* 11.2.3 Dedekind reals are Dedekind complete
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (500 . 0.669742)
:END:

****** 11.3 Cauchy reals
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (502 . 0.252284)
:END:

******* 11.3.1 Construction of Cauchy reals
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (503 . 0.586389)
:END:

******* 11.3.2 Induction and recursion on Cauchy reals
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (505 . 0.984877)
:END:

******* 11.3.3 The algebraic structure of Cauchy reals
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (520 . 0.657569)
:END:

******* 11.3.4 Cauchy reals are Cauchy complete
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (526 . 0.164536)
:END:

****** 11.4 Comparison of Cauchy and Dedekind reals
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (526 . 0.979938)
:END:

****** 11.5 Compactness of the interval
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (528 . 0.490225)
:END:
******* Notions of compactness

 * *Metrically compact:* Cauchy complete and totally bounded.
 * *Bolzano-Weierstrass:* every sequence has a convergent subsequence.
 * *Heine-Borel:* every open cover has a finite subcover.

These are equivalent in classical mathematics.
******* 11.5.1. Metric space
******* 11.5.2. Cauchy approximation
******* 11.5.2. Complete metric space
******* 11.5.3. e-nets
******* 11.5.3. Totally bounded space
******* 11.5.5. Uniform continuity
******* 11.5.6. Metrical compactness of the interval
****** 11.6 The surreal numbers
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (537 . 0.300144)
:END:

****** Notes
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (551 . 0.979938)
:END:

****** Exercises
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (553 . 0.282243)
:END:

**** Appendix
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (557 . 0.083235)
:END:

***** A Formal type theory
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (559 . 0.083235)
:END:

****** A.1 The first presentation
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (561 . 0.980218)
:END:

******* A.1.1 Type universes
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (563 . 0.450923)
:END:

******* A.1.2 Dependent function types (Π-types)
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (563 . 0.964715)
:END:

******* A.1.3 Dependent pair types (Σ-types)
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (564 . 0.529346)
:END:

******* A.1.4 Coproduct types
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (565 . 0.24388)
:END:

******* A.1.5 The finite types
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (565 . 0.540825)
:END:

******* A.1.6 Natural numbers
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (565 . 0.783442)
:END:

******* A.1.7 W-types
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (566 . 0.293082)
:END:

******* A.1.8 Identity types
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (566 . 0.685745)
:END:

****** A.2 The second presentation
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (566 . 0.987412)
:END:

******* A.2.1 Contexts
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (567 . 0.777581)
:END:

******* A.2.2 Structural rules
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (568 . 0.425459)
:END:

******* A.2.3 Type universes
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (569 . 0.650701)
:END:

******* A.2.4 Dependent function types (Π-types)
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (569 . 0.984877)
:END:

******* A.2.5 Dependent pair types (Σ-types)
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (571 . 0.260262)
:END:

******* A.2.6 Coproduct types
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (572 . 0.171897)
:END:

******* A.2.7 The empty type 0
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (572 . 0.859729)
:END:

******* A.2.8 The unit type 1
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (573 . 0.127758)
:END:

******* A.2.9 The natural number type
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (573 . 0.543736)
:END:

******* A.2.10 Identity types
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (574 . 0.25004)
:END:

******* A.2.11 Definitions
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (574 . 0.737321)
:END:

****** A.3 Homotopy type theory
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (575 . 0.461918)
:END:

******* A.3.1 Function extensionality and univalence
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (575 . 0.653945)
:END:

******* A.3.2 The circle
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (576 . 0.266769)
:END:

****** A.4 Basic metatheory
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (576 . 0.983344)
:END:

****** Notes
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (579 . 0.277915)
:END:

**** Bibliography
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (581 . 0.083235)
:END:

**** Index of symbols
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (593 . 0.083235)
:END:

**** Index
:PROPERTIES:
:INTERLEAVE_PAGE_NOTE: (601 . 0.305241)
:END:

*** [[https://abooij.github.io/wiwikwlhott/][What I wish I knew when learning HoTT]] - Auke Booij
*** HoTT-EST seminars
**** Carlo Angiuli - Computational semantics of cartesian cubical type theory
Link to the video: [[https://zoom.us/recording/play/XP5xo5yzDYuJ-tFYIvNTIEVG5jPVFl0_Rz5PsUZZPrjyZa83b_CIHnuLhdfKwkjP][video]]

Canonicity only holds for closed terms. 

Computational semantics are given by a model in which closed terms are
programs.

***** Operational semantics
Syntax of untyped preterms (modulo alpha-equivalence). Raw syntax of
the theory.

Each closed term reduces to a value. The meanings of non values are
determined by the values to which they reduce.

The meanings of open terms are determined by thei rbehavior as maps
from closed to closed terms.

*** Course on HoTT - Robert Harper
**** Lecture 1: Intuitionistic Type Theory
***** Intuitionistic Type Theory (TT),
The *Intuitionistic Type Theory* is based on the work of Per
Martin-Löf on the 1970s.  It is an analysis and expansion of Brouwer's
intuitionism.

***** Intensional Type Theory (ITT)
The *Intensional Type Theory* will be our base theory. Other forms of
type theory are extensions of this one.

***** Extensional Type Theory (ETT)
The *Extensional Type Theory* has the core of ITT plus the principles
of equality reflection (ER) and uniqueness of the identity proofs
(UIP).

This is the intuitionistic theory of sets in which NuPRL is based.
It is a form of constructive set theory, developed by Bishop; where
types are treated as sets.

***** Homotopy Type Theory (HoTT)
The *Homotopy Type Theory* is an elaboration of ITT with higher
inductive types (HIT) and the univalence axiom (UA).

It is an intuitionistic theory of weak $\infty\text{-groupoids}$. Here types
are spaces in an abstract sense.
***** Brower's program
The *Brower's program* is a philosophy of mathematics based on the
following ideas
 
 1. mathematics is a human social activity. The focus is on the /language/
    as a tool for communication of mathematical concepts.

 2. the fundamental human capability is the understanding an execution
    of /algorithms/ for performing /constructions/. Proofs are forms
    of construction.

In this setting, the only way to describe infinite things is by
communicate them with an algorithm. 

****** Proof relevance
From the second point, arises the principle of *proof relevance*.
Proofs are mathematical objects that we can see an manipulate. In
other foundations of mathematics, only a limiting enumerable set of
formal proofs can be viewed as proofs.

****** Proof relevance in HoTT
In HoTT, our proofs will be paths in a space. This conception
will provide a synthetic way of working with homotopy which is a
cleaner, shorter and mechanizable way writting proofs.

****** Synthetic perspective in mechanized reasoning
Synthetic geometry is what Euclides did; analytic geometry is what
Descartes did. The traditional formulation of Homotopy Theory, using
euclidean spaces and topology, is an analytic one. Synthetic
formulations of Homotopy Theory are based on Quillen model categories or
HoTT.

This distinction of synthetic and analytical is due to Lawvere.

/Twelf vs Coq is another example/
***** Type Theory
Type theory is an analysis and codification of Brower's intuitionism
drawning on Gentzen's proof theory. Types classify the admisible
constructions. A type is defined by

 * *introduction rules*, showing how to make a construction.
 * *elimination rules*, showing how to use a construction.

linked by the *inversion principle*, or principle of conservation of
proofs; stating that the introduction is inverse to the elimination.
This inversion principle is the basis for the computational content
of our language.

***** Axiomatic freedom of constructive mathematics
In the Hilbert/Brouwer debate, Hilbert believed that Brouwer was negating
everything that has been done so far; but, as fewer assumptions lead to
stronger results, the exclusion of certain principles leads only to axiomatic
freedom.

For example, the law of excluded middle is not negated on constructive
mathematics, they are simply independent of it; but it can still be
taken as an hypothesis on certain subfields.

We can now include certain assumptions locally, and so, the
constructivity is not a limitation.
***** Computational aspect
Type theory acts as an unified theory of computation. Programming
languages and computation are particular manifestations of this
unified theory.

***** Computational trinitarianism

\[\begin{tikzcd}[row sep=huge, col sep=tiny]
& \begin{matrix}\text{Type}\\ \text{Theory}\end{matrix} \drar[to-to]\dlar[to-to] & \\
\text{Logic}\arrow[rr,to-to] & & \begin{matrix}\text{Category}\\ \text{Theory}\end{matrix}
\end{tikzcd}\]

There is a complete correspondence between the three theories.
***** Intuitionistic logic
*Intuitionistic logic* is based on the principles of intuitionism.
It has the following judgements

 1. $A$ is a proposition.
 2. $A$ is a true proposition, it has a proof.

We do not expect that a proposition is either provable or refutable.
We assume also /open-endedness/, we cannot write all the proofs in a
systematic way.

***** Negative fragment of intuitionistic propositional logic
We will write a grammar of proofs.

 * The trivially true proposition, this is the *truth-formation*
   rule

   \begin{prooftree}
   \RightLabel{(T-form)}
   \AxiomC{}
   \UnaryInfC{T prop}
   \end{prooftree}

   this trivially true proposition is true

   \begin{prooftree}
   \RightLabel{(T-intro)}
   \AxiomC{}
   \UnaryInfC{T true}
   \end{prooftree}

   but there is no truth elimination rule, as we are not using any
   information when we write this proposition.

 * Conjunction formation

   \begin{prooftree}
   \RightLabel{($\wedge$-form)}
   \AxiomC{A prop}
   \AxiomC{B prop}
   \BinaryInfC{A $\wedge$ B prop}
   \end{prooftree}

   conjunction introduction

   \begin{prooftree}
   \RightLabel{($\wedge$-intro)}
   \AxiomC{A true}
   \AxiomC{B true}
   \BinaryInfC{A $\wedge$ B true}
   \end{prooftree}
   
   we will use two elimination rules to extract the two pieces 
   of information that went into that fact.

   \begin{prooftree}
   \RightLabel{($\wedge$-elim$_1$)}
   \AxiomC{A $\wedge$ B true}
   \UnaryInfC{A true}
   \RightLabel{($\wedge$-elim$_2$)}
   \AxiomC{A $\wedge$ B true}
   \UnaryInfC{B true}
   \noLine
   \BinaryInfC{}
   \end{prooftree}

 * Implication formation

   \begin{prooftree}
   \RightLabel{($\supset$-form)}
   \AxiomC{A prop}
   \AxiomC{B prop}
   \BinaryInfC{A $\supset$ B prop}
   \end{prooftree}

   and implication introduction, which uses only entailment

   \begin{prooftree}
   \RightLabel{($\supset$-intro)}
   \AxiomC{A true $\vdash$ B true}
   \UnaryInfC{A $\supset$ B true}
   \end{prooftree}

   in the Hilbert formulations of logic, we supress the difference
   between entailment and implication. The logical entailment is prior
   to the implication, it is a map of proofs; while the implication only
   captures that into the logic. The elimination rule is the modus ponens

   \begin{prooftree}
   \RightLabel{($\supset$-elim)}
   \AxiomC{A $\supset$ B true}
   \AxiomC{A true}
   \BinaryInfC{B true}
   \end{prooftree}

**** Lecture 2: Intuitionistic Propositional Logic
***** Negative fragment of intuitionistic propositional logic
We have talked about

 * the Gentzen principle of conservation of evidence.
 * the truth value.
 * the conjunction.
 * the implication.

Why are these "correct" rules? We are keeping a correspondence between
introduction and elimination rules; that is the beauty of the Gentzen
system and what gives rise to the computational interpretation.

These are not arbitrary rules, there is a coherence that is being kept.
***** Structural properties of entailment
The concept of *logical entailment* is a compound judgement. It express
the idea of a conclusion derived from a set of assumptions

\[\underbrace{
A_1 \text{ true},
A_2 \text{ true},
\dots,
A_n \text{ true}}_{\Gamma}
\vdash
A
\]

Logical entailment is a mapping between propositions.
The properties of logical entailment (aka hypothetical judgement) are
the following properties
 
 1. Reflexivity (R), $A \text{ true} \vdash A \text{ true}$.
 2. Transitivity (T),
    
    \begin{prooftree}
    \RightLabel{(T)}
    \AxiomC{$\Gamma_1 \vdash A$ true}
    \AxiomC{$\Gamma_2,A$ true $\vdash B$ true}
    \BinaryInfC{$\Gamma_1,\Gamma_{2} \vdash B$ true}
    \end{prooftree}

    in presence of the weakening, contraction, and exchange properties,
    this can be rewritten using only a $\Gamma$.

 3. Weakening (W),
    
    \begin{prooftree}
    \RightLabel{(W)}
    \AxiomC{$\Gamma$ $\vdash A$ true}
    \UnaryInfC{$\Gamma,B$ true $\vdash A$ true}
    \end{prooftree}

    where the two first properties are fundamental, and this third is
    not as fundamental. You can consider deniying this principle, and
    you will arrive at the notion of /relevant entitlement/, where every
    assumption has to be used in the entitlement.

 4. Contraction (C), 
    
    \begin{prooftree}
    \RightLabel{(C)}
    \AxiomC{$\Gamma,A$ true,$A$ true $\vdash B$ true}
    \UnaryInfC{$\Gamma, A$ true $\vdash B$ true}
    \end{prooftree}

    in certain logics, we may will want to keep an accounting of
    how many times have we used a lemma; we will have to deny this
    property.

 5. Exchange (E), the order of the assumptions does not matter

    \begin{prooftree}
    \RightLabel{(C)}
    \AxiomC{$\Gamma \vdash A$ true}
    \UnaryInfC{$\pi(\Gamma) \vdash A$ true}
    \end{prooftree}

    where $\pi$ is any permutation.

When any of these properties fail, we talk of substructural entailment.

***** Local form
We are writing the rules in local form. They can be used in the same
way on the presence of assumptions. A $\Gamma$ could be added to all
the rules to obtain the global form. It is implied in our rules.

There are certain scenarios in which we will want $\Gamma$ to be explicitely
empty.

***** Order-theoretic formulation
Let us define $A \leq B$, an order on propositions, meaning that
$A \text{ true} \vdash B \text{ true}$.

****** Preorder
This is a preorder,

  * it is reflexive,

    \begin{prooftree}
    \RightLabel{($\leq$-refl)}
    \AxiomC{}
    \UnaryInfC{$A \leq A$}
    \end{prooftree}


  * it is transitive,

    \begin{prooftree}
    \RightLabel{($\leq$-trans)}
    \AxiomC{$A \leq B$}
    \AxiomC{$B \leq C$}
    \BinaryInfC{$A \leq C$}
    \end{prooftree}

  * we have a greatest, final element

    \begin{prooftree}
    \RightLabel{($\leq_\top$)}
    \AxiomC{}
    \UnaryInfC{$A \leq \top$}
    \end{prooftree}
   
  * we have meets given by conjunction. That is, there is a lower
    bound

    \begin{prooftree}
    \RightLabel{($\leq,\wedge_1$)}
    \AxiomC{}
    \UnaryInfC{$A \wedge B \leq A$}
    \RightLabel{($\leq,\wedge_2$)}
    \AxiomC{}
    \UnaryInfC{$A \wedge B \leq B$}
    \noLine
    \BinaryInfC{}
    \end{prooftree}

    which is also universal

    \begin{prooftree}
    \RightLabel{($\leq,\wedge$-bound)}
    \AxiomC{$C \leq A$}
    \AxiomC{$C \leq B$}
    \BinaryInfC{$C \leq A \wedge B$}
    \end{prooftree}

Those follow from the properties of entailment. We can draw those
properties with Hasse diagrams, where we can see a similarity with
a product diagram on category theory

\[\begin{tikzcd}[column sep=tiny]
& C \dar[dashed] \ar[ddr,bend left]\ar[ddl, bend right] & \\
& A \wedge B \drar\dlar & \\
A & & B &.
\end{tikzcd}\]

****** Antisymmetry and equivalence
We have now a lower semilattice. Sometimes, lower semilattices are
defined to be partial orders, where we have antisymmetry

    \begin{prooftree}
    \RightLabel{}
    \AxiomC{$A \leq B$}
    \AxiomC{$B \leq A$}
    \BinaryInfC{$A = B$}
    \end{prooftree}

but we are going to work without antisymmetry. We haven't talked yet
about equality, but we are going to introduce the univalent principle.
We could define $A \simeq B$ when $A \leq B$ and $B \leq A$, they are not equal,
but equivalent. We could also work with equivalence classes $[A]_{\simeq}$ here.
Univalence will imply the equality of equivalent propositions.

***** Positive fragment of IPL
Now we write the grammar of the positive fragment

 * The false proposition, this is the *false-formation* rule

   \begin{prooftree}
   \RightLabel{($\bot$-form)}
   \AxiomC{}
   \UnaryInfC{$\bot$ prop}
   \end{prooftree}

   there is no introduction rule, only an elimination rule

   \begin{prooftree}
   \RightLabel{($\bot$-elim)}
   \AxiomC{$\bot$ true}
   \UnaryInfC{A true}
   \end{prooftree}

   since there is no introduction rule and this never happens,
   this preserves the coherence principle.

 * Disjunction formation

   \begin{prooftree}
   \RightLabel{($\vee$-form)}
   \AxiomC{A prop}
   \AxiomC{B prop}
   \BinaryInfC{A $\vee$ B prop}
   \end{prooftree}

   disjunction introduction

   \begin{prooftree}
   \RightLabel{($\vee$-intro$_{1}$)}
   \AxiomC{A true}
   \UnaryInfC{A $\vee$ B true}
   \RightLabel{($\vee$-intro$_{2}$)}
   \AxiomC{B true}
   \UnaryInfC{A $\vee$ B true}
   \noLine
   \BinaryInfC{}
   \end{prooftree}
   
   we will use an elimination rule to extract the piece of
   of information that went into that fact as in

   \begin{prooftree}
   \RightLabel{($\vee$-elim)}
   \AxiomC{A $\vee$ B true}
   \AxiomC{A true $\vdash$ C true}
   \AxiomC{B true $\vdash$ C true}
   \TrinaryInfC{C true}
   \end{prooftree}

***** Order-theoretical properties
We have now a least or initial element,
 
    \begin{prooftree}
    \RightLabel{($\leq$-$\bot$)}
    \AxiomC{}
    \UnaryInfC{$\bot \leq A$}
    \end{prooftree}

and joins or upper bounds

    \begin{prooftree}
    \RightLabel{($\leq,\vee_1$)}
    \AxiomC{}
    \UnaryInfC{$A \leq A \vee B$}
    \RightLabel{($\leq,\vee_2$)}
    \AxiomC{}
    \UnaryInfC{$A \leq A \vee B$}
    \noLine
    \BinaryInfC{}
    \end{prooftree}

where the bound is the least upper bound

    \begin{prooftree}
    \RightLabel{($\leq,\vee$-bound)}
    \AxiomC{$A \leq C$}
    \AxiomC{$B \leq C$}
    \BinaryInfC{$A \vee B \leq C$}
    \end{prooftree}

Note that those bounds are unique up to equivalence, as they follow
also a categorical universal diagram, in this case, the coproduct
diagram

\[\begin{tikzcd}[column sep=tiny]
A \drar\ar[ddr, bend right] & & B \dlar\ar[ddl, bend left] \\
& A \vee B \dar[dashed] & \\
& C  & &.
\end{tikzcd}\]

This is a lattice, that has all finite meets and joins.

***** Order-theoretic formulation of the implication
We have an exponential $B^A$ whenever $A \supset B$, this is defined
as the property

\begin{prooftree}
\AxiomC{}
\UnaryInfC{$A\wedge (A \supset B) \leq B$}
\end{prooftree}

and the exponential is the universal element with this property

\begin{prooftree}
\AxiomC{$A \wedge C \leq B$}
\UnaryInfC{$C \leq A \supset B$}
\end{prooftree}

***** Heyting algebra
A *Heyting algebra* is a lattice with exponentials.

****** Yoneda Lemma
The Yoneda Lemma on lattices says that

$a \leq b \iff \left(\forall x: x \leq a \implies x \leq b\right)$.

It is trivial by transitivity and identity. This is
an instance of a more general fact.
***** Negation
We define $\neg A := A \supset \bot$. It is the largest proposition inconsistent
with $A$, the largest proposition such that $A \wedge \neg A \leq \bot$.

***** Complement
We define $\overline{A}$ as the universal element with the property that $\top \leq A \vee \overline{A}$
and $\overline{A} \wedge A \leq \bot$.

We have a complement distributive algebra (a boolean algebra!) and such thing
has exponentials.

\begin{prooftree}
\AxiomC{$\top \leq A \vee C$}
\UnaryInfC{$\overline{A} \leq C$}
\end{prooftree}

***** Boolean algebra
A *boolean algebra* is a complemented distributive lattice. Therefore, it has
exponentials, defined as $B^A := \overline{A} \vee B$.

***** Completeness theorem
If $A \leq B$ in every Heyting algebra, it must be deducible that $A \vdash B$.
If something is valid in all models, in all Heyting algebras, it must be
provable.

This logic is complete for Heyting algebras, but it is not going to be
complete for boolean algebras. $A \vee \neg A$ is not going to be provable in
our logic.

****** Proof
If something is provable in every Heyting algebra, you can construct the
propositional *Lindenbaum algebra*; and this is used to show completenaess.
If $A \leq B$ holds in every Heyting algebra, then $A \text{ true} \vdash B \text{ true}$. We
need to interpret the propositions as elements on a Heyting algebra.

****** Converse
If something is provable, it holds in every Heyting algebra. 

***** Issue: negation and complement
In a boolean algebra, $A \vee \neg A \simeq \top$.

**** Lecture 3: Propositions as Types
***** Last week
Last week we saw IPL from a provability perspective. $A$ is true if it
has a proof, and $A$ is false if it has a refutation. We got the
structure of Heyting algebra (a lattice (partial order with all finite
meets and joins) and exponentials). Every Heyting algebra is
distributive. We defined the negation.

****** Soundness incompleteness result
$\Gamma \vdash A$ true iff $\Gamma^{\ast} \leq A^{\ast}$ in every Heyting algebra.

****** Boolean and Heyting algebras
Not every boolean algebra is a Heyting algebra, but every Heyting
algebra is a boolean algebra.

****** DeMorgan Duality
$\overline{A \wedge B} = \overline{A} \vee \overline{B}$ and $\overline{A \vee B} = \overline{A} \wedge \overline{B}$.

***** Claim
In IPL, not all instances of LEM are provable. We cannot prove
in general that $A \vee \neg A \text{ true}$.

****** Idea
The disjunction property says that if $A \vee B \text{ true}$, then $A$ true
or $B$ true. This would imply that LEM gives us a proof or a
refutation of every element.

***** There exists a Heyting algebra which is not a boolean algebra
We need only a countermodel, a Heyting algebra where $\top \leq A \vee \neg A$
does not hold. It will show that this is not provable in general
in IPL.

***** Decidable proposition
A proposition is *decidable* iff $A \vee \neg A \text{ true}$. There are decidable
propositions even if LEM does not hold.

****** Example
Two decidable propositions are $\bot$ and $\top$.

Equality on natural numbers will be decidable, but equality on reals
will not.
***** Stable proposition
A proposition is *stable* iff $(\neg \neg A) \supset A \text{ true}$.

***** Negation of the negation of LEM
We can prove $\neg \neg (A \vee \neg A)$. This proves that not every proposition
is stable as a corollary.

****** Proof
We will assume $\neg (A \vee \neg A)$ and arrive at a contradiction. If we
assume $A$, we have $A \vee \neg A$, and then a contradiction, so it must
be the case that $\neg A$. We know now that $A \vee \neg A$, arriving at a
contradiction.

***** Prove the disjunction property for IPL
We interpret the rules of IPL as an inductive definition of
the entailment relation.

We have finitary derivation trees of every $\Gamma \vdash A$.

****** Disjunction property: formal statement
If $\varnothing \vdash A \vee B \text{ true}$, then $\varnothing \vdash A \text{ true}$ or $\varnothing \vdash B \text{ true}$.

******* Counterexample if the context were not empty
If we take $A \vee B$ as an assumption, this would trivially
not hold.
****** Disjunction property: draft of a proof
We will use an induction on derivations. We examine all possible
derivations $\varnothing \vdash A \vee B \text{ true}$ and show that there are derivations of
$A$ or $B$ also.

The last step of a derivation of $A \vee B$ should be an introduction
$\vee-I_{1}$ or $\vee-I_2$; so there should be a derivation of $A$ or $B$ in
the previous step. The assumption rule is also not applicable.
Conjunction introduction is not applicable, and the same hold for
true introduction and implication introduction. Elimination rules
are our real problem here. For example, implication elimination should
be proved.

To prove this for the implication elimination rule, we suppose that
we have the derivations for $\vdash C$ and $C \vdash (A \vee B)$, and then we could
inline the first derivation using transitivity of entailment to get
a derivation of $\vdash A \vee B$. Note that this is not a complete proof! the
derivation of $C \supset (A \vee B)$ could have be done by other elimination
rules and we should prove that for them too.
***** Structural properties are admissible
*Weakening is admissible*, if $\Gamma \vdash_{IPL} B\text{ true}$, then $\Gamma,A \text{ true} \vdash_{IPL} B \text{ true}$.
If you give a derivation of the first, you can get a derivation of the
second one.

****** Why is weakening admissible
Because the rules are polymorphic! They do not depend of Gamma. We
could inductively weaken every step $\Gamma \mapsto \Gamma,A\text{ true}$, and then, reapplying
the rules, would give us the same conclusion.

****** Similarly
You could do exchange or contraction. But reflexivity is a primitive rule!
Transitivity for $\text{IPL}^{-}$ is homework.
****** We have now defined a good logic
It is not simply a bunch of rules, they follow a criteria. The
structural properties should hold. There are substructural logics,
but those are not our topic of interest.
***** Gentzen's insight
Our previous idea to prove the disjunction property uses crucially an
inversion principle between implication introduction and implication
elimination.

*ELIM is post-inverse to INTRO.*

We are saying something like the following for introductions, eliminations
and derivations.

 * $(\wedge E_1 \circ \wedge I)({\cal D}_1,{\cal D}_2) = {\cal D}_1$

This gives rise to a dynamics of proof! We do not only look at provability,
we look at the proofs per se.

***** II. Proof relevant logic
We will write a grammar of proofs. $M : A$ means that $M$ is a proof
of $A$. In correspondence with the assumptions, there is the concept
of variables

\[ x_1:A_1, \dots , x_n:A_n \vdash M : A.\]

Transitivity now reads as a substitution rule

\begin{prooftree}
\AxiomC{$\Gamma, x : A\vdash M : B$}
\AxiomC{$\Gamma \vdash N : A$}
\BinaryInfC{$[N/x]M : B$}
\end{prooftree}

and reflexivity is only a use of a variable

\begin{prooftree}
\AxiomC{}
\UnaryInfC{$\Gamma, x:A \vdash x : A$}
\end{prooftree}

We will write this derivations as mappings on a bicartesian closed category

\[M : A_1 \times \dots \times A_n \to A.
\]

Proof-relevant logic will give rise to Type Theory and Category Theory.
**** Lecture 4: Proof Reduction and Equivalence
We first saw logic from the point of view of provability. We are going
to look at the idea of logic with proofs. From the first, we got Heyting
Algebras; from the second, we are going to get bicartesian closed categories.

We going to define equivalence of proofs $M \equiv N : A$.

***** Proof terms
We will need a grammar of proofs to construct proof terms.
The structural properties are now properties for this grammar.

 * Reflexivity is now the introduction of a variable.
 * Transitivity is now the substitution of a variable.
 * Weakening is now the ability to discard variables.
 * Contraction is now a replication of variables.
 * Exchange is a permutation of variables.

***** Logic
Now the negative fragment of our logic can be written as

\begin{prooftree}
\RightLabel{$(\top_{I})$}
\AxiomC{}
\UnaryInfC{$\Gamma \vdash \left\langle  \right\rangle : \top$}
\end{prooftree}

\begin{prooftree}
\RightLabel{$(\wedge-I)$}
\AxiomC{$\Gamma \vdash M : A$}
\AxiomC{$\Gamma \vdash N : B$}
\BinaryInfC{$\Gamma \vdash \left\langle M,N \right\rangle : A \wedge B$}
\end{prooftree}

\begin{prooftree}
\RightLabel{$(\wedge_{E1})$}
\AxiomC{$\Gamma \vdash M : A \wedge B$}
\UnaryInfC{$\Gamma \vdash \text{fst}(M) : A$}
\RightLabel{$(\wedge_{E2})$}
\AxiomC{$\Gamma \vdash M : A \wedge B$}
\UnaryInfC{$\Gamma \vdash \text{snd}(M) : B$}
\noLine
\BinaryInfC{}
\end{prooftree}


\begin{prooftree}
\RightLabel{$(\supset_{I})$}
\AxiomC{$\Gamma, x:A \vdash M:B$}
\UnaryInfC{$\Gamma \vdash \lambda x . M : A \supset B$}
\end{prooftree}

\begin{prooftree}
\RightLabel{$(\supset_{E})$}
\AxiomC{$\Gamma \vdash M . A \supset B$}
\AxiomC{$\Gamma \vdash N : A$}
\BinaryInfC{$\Gamma \vdash M(N) : B$}
\end{prooftree}

***** Gentzen's Inversion principle
***** Definitional equality
In first order logic, no one draws a distinction between propositional
equality and definitional equality.

*Definitional equality* is the least congruence closed under the following
rules
 
 * it is a equivalence relation.
 * it is compatible with the rules.

\begin{prooftree}
\AxiomC{$\Gamma \vdash M \equiv M' : A \wedge B$}
\UnaryInfC{$\Gamma \vdash \text{fst}(M) \equiv \text{fst}(M') : A$}
\end{prooftree}

Now the inversion principle can be written on proof terms.
Simplifications such as $\text{fst}\left\langle M,N \right\rangle \equiv M$ are now useful if we
interpret this as a running program with proof dynamics.

Those are called Beta rules.
The inversion principle on conjunction is now

\begin{prooftree}
\RightLabel{$(\beta\wedge_1)$}
\AxiomC{$\Gamma \vdash M : A$}
\AxiomC{$\Gamma \vdash N : B$}
\BinaryInfC{$\Gamma \vdash \text{fst}\left\langle M,N \right\rangle \equiv M : A$}
\RightLabel{$(\beta\wedge_2)$}
\AxiomC{$\Gamma \vdash M : A$}
\AxiomC{$\Gamma \vdash N : B$}
\BinaryInfC{$\Gamma \vdash \text{snd}\left\langle M,N \right\rangle \equiv N : B$}
\noLine
\BinaryInfC{}
\end{prooftree}

The inversion principle on implication is inlining

\begin{prooftree}
\RightLabel{$(\beta\supset_1)$}
\AxiomC{$\Gamma,x:A \vdash M : B$}
\AxiomC{$\Gamma \vdash N : A$}
\BinaryInfC{$\Gamma \vdash (\lambda x. M)(N) \equiv [N/x]M : B$}
\end{prooftree}

Now we can compute by calculation with closed terms written
as $M \equiv N$.

***** Gentzen's Unicity Principles
Those are $\eta$ rules.

\begin{prooftree}
\RightLabel{$(\eta\top)$}
\AxiomC{$\Gamma \vdash M : \top$}
\UnaryInfC{$\Gamma \vdash M \equiv \left\langle  \right\rangle : \top$}
\end{prooftree}

\begin{prooftree}
\RightLabel{$(\eta\wedge)$}
\AxiomC{$\Gamma\vdash M: A \wedge B$}
\UnaryInfC{$M \equiv \left\langle \text{fst}(M),\text{snd}(M) \right\rangle$}
\end{prooftree}

\begin{prooftree}
\RightLabel{$(\wedge\supset)$}
\AxiomC{$\Gamma\vdash M:A \supset B$}
\UnaryInfC{$\Gamma\vdash M \equiv \lambda x. Mx : A \supset B$}
\end{prooftree}

***** Propositions as types
The inversion and unicity principles will make a very strong
correspondence on categories.

\begin{tabular}{c|c|c|c}
Latticces & Propositions & Types & Categories \\
\hline
greatest & $\top$ & $1$ & final object \\
meets & $A \wedge B$ & $A \times B$ & finite products \\
exponential & $A \supset B$ & $A \to B$ & exponential \\
minimum & $\bot$ & $0$ & initial object \\
joins & $A \vee B$ & $A+B$ & coproducts
\end{tabular}

***** Category
A *category* is a generalized preoder with evidence.
The difference between preorder and partial order is
related to univalence

\begin{prooftree}
\AxiomC{$A \leq B$}
\AxiomC{$B \leq A$}
\BinaryInfC{$A \equiv B$}
\end{prooftree}

where this is an instance of univalence. 

In a category we have the structure of a preorder

 1) Reflexivity, $\mathrm{id} : A \to A$.
 2) Transitivity; if $f: A \to B$ and $g : B \to C$ then
    $g \circ f : A \to C$.

Those have to satisfy some coherence conditions, which are 
the following unit laws

 * $\mathrm{id_B}\circ f = f = f \circ \mathrm{id_A}$
 * $f \circ (g \circ h) = (f\circ g)\circ h$

The equality here is interesting. We could think of this structure
representing two paths and an homotopy between two paths on a 2-cell;
some kind of transformation. We are going to talk of a deformation
given by an associator

\[
\alpha : f \circ (g \circ h) \to (f \circ g) \circ h.
\]

And those notions of evidence (which act as natural transformations) need
also a notion of equivalence and a higher dimensional map between them. But 
this process could be repeated to infinity!

We are going to express the relation of types and terms in categorical terms.

***** Terminal object
Definition of final object

\begin{prooftree}
\AxiomC{$$}
\UnaryInfC{$\left\langle\right\rangle : A \to 1$}
\AxiomC{$M : A \to 1$}
\RightLabel{$(\eta{\top})$}
\UnaryInfC{$M = \left\langle  \right\rangle : 1$}
\noLine
\BinaryInfC{}
\end{prooftree}

this was, in our old notation, $A \vdash \left\langle  \right\rangle : 1 = \top$.

***** Product objects
There are maps

 1) $\mathrm{fst} : A \times B \to A$
 2) $\mathrm{snd} : A \times B \to A$

satisfying

\[\begin{tikzcd}[column sep=tiny]
& D \ar[bend left]{ddr}{M}\ar[swap,bend right]{ddl}{N}\dar[dashed]{\exists!} & \\
& A \times B \drar[swap]{\mathrm{fst}} \dlar{\mathrm{snd}} & \\
A && B
\end{tikzcd}\]

Pairing is the function taking two functions and returning
the function to the product

\begin{prooftree}
\AxiomC{$M : D \to A$}
\AxiomC{$N : D \to B$}
\BinaryInfC{$\left\langle M,N \right\rangle : D \to A \times B$}
\end{prooftree}

algebraically,

 * $\mathrm{fst}\circ \left\langle M,N \right\rangle = M : D \to A$
 * $\mathrm{snd}\circ \left\langle M,N \right\rangle = N : D \to B$

and there is a uniqueness condition; given

\begin{prooftree}
\RightLabel{$(\eta \times)$}
\AxiomC{$P : D \to A \times B$}
\AxiomC{$\mathrm{fst} \circ P = M$}
\AxiomC{$\mathrm{snd} \circ P = N$}
\TrinaryInfC{$P = \left\langle M,N \right\rangle : D \to A \times B$}
\end{prooftree}

the uniqueness can be seen as the existence of homotopy between
any two functions making the product diagram commute.

In particular, $\left\langle  \mathrm{fst}\circ P, \mathrm{snd} \circ P  \right\rangle = P$. Or we can say that $\left\langle \mathrm{fst}, \mathrm{snd} \right\rangle = \mathrm{id}$
or $\left\langle M,N \right\rangle \circ P = \left\langle M\circ P,N \circ P \right\rangle$.

Lawvere and Lambek first saw those connections on the 70s.

***** Exponentials
The exponential $B^A$, gives the application map with the universal
diagram

\[\begin{tikzcd}
C \dar[dashed,swap]{\exists! \lambda(h)} & 
C \times A \ar{dr}{h}\dar[dashed,swap]{\lambda(h) \times id_A} & \\
B^{A} & B^{A} \times A \rar[swap]{app} & B \\
\end{tikzcd}\]

If we write that on syntax, that is equal to

 * $app(\lambda(h) \times \mathrm{id}) = ap \circ \left\langle \lambda(h) \circ \mathrm{fst}, \mathrm{snd} \right\rangle = h$.
 * if there is any $g$ such that $ap \circ (g \times \mathrm{id}) = h$, then $g = \lambda(h)$.

We get the $\eta\text{-rule}$ of

\[
g = \lambda(\mathrm{ap} \circ (g \times \mathrm{id}))
  = \lambda(\mathrm{ap} \circ \left\langle g \circ \mathrm{fst}, \mathrm{snd} \right\rangle).
\]

The essence of all this is

\begin{prooftree}
\AxiomC{$\Gamma, x:A \vdash h : B$}
\UnaryInfC{$\Gamma \vdash \lambda x. h: B^A$}
\end{prooftree}

***** DeBruijn indices
If we write contexts as $A_{n-1}\times \dots \times A_{1}$, and we refer to the
variables using $\mathrm{snd}(\mathrm{fst}(\mathrm{fst}\dots))$.

**** Lecture 5: Universal properties
In the previous weeks we talked about

 * logic via provability and truth.
 * the entailment relation.
 * an order theoretic interpretation.
 * a logic for proofs with proof terms.
 * a notion of equality for proofs.

***** Gentzen's inversion principle
Represented on the $\beta$ principles, rules such as

 * $\mathtt{fst} \left\langle M,N \right\rangle \equiv M$
 * $\mathtt{snd} \left\langle M,N \right\rangle \equiv N$
 * $(\lambda x. M)(N) \equiv [N/x]M$
 * $\mathtt{case}(\mathtt{inl}(M), x.P, y.Q) \equiv [M/x]P$
 * $\mathtt{case}(\mathtt{inr}(M), x.P, y.Q) \equiv [M/y]Q$

they act as rules for proof simplification and can be interpreted as
a dynamics for proofs. Proofs are programs.

***** Gentzen's unicity principles
Represented on $\eta$ principles.

\begin{prooftree}
\AxiomC{$\Gamma \vdash M : \top$}
\UnaryInfC{$\Gamma \vdash M \equiv \langle\rangle : \top$}
\end{prooftree}

\begin{prooftree}
\AxiomC{$\Gamma \vdash M : A \wedge B$}
\UnaryInfC{$\Gamma \vdash M \equiv \left\langle \mathtt{fst}(M),\mathtt{snd}(M) \right\rangle : A \wedge B$}
\end{prooftree}

there is another way of saying this

\begin{prooftree}
\AxiomC{$\Gamma \vdash M : A \wedge B$}
\AxiomC{$\Gamma \vdash \mathtt{fst}(M) \equiv P : A$}
\AxiomC{$\Gamma \vdash \mathtt{snd}(M) \equiv Q : B$}
\TrinaryInfC{$\Gamma \vdash M \equiv \left\langle P,Q \right\rangle : A \wedge B$}
\end{prooftree}

\begin{prooftree}
\AxiomC{$\Gamma \vdash M : A \supset B$}
\UnaryInfC{$\Gamma \vdash M \equiv \lambda x. M(x) : A \supset B$}
\end{prooftree}

***** Categorical interpretation
A derivation

\[
x_1:A_1,\dots,x_n:A_n \vdash M : A
\]

is interpreted as a morphism

\[
M : A_1 \times \dots \times A_n \to A\]
\[M \equiv N : A_1 \times \dots \times A_n \to A
\]

The product diagram relates

 * the existence with the introduction.
 * the uniqueness with the $\eta$ rules.
 * the commutativity with the $\beta$ rules.

***** Unicity principle for the disjunction [40:00]
It is more difficult to see how the disjunction property should be
written. An inspiration is the notion of Shannon expansion: the type
of booleans can be written as $\top \vee \top$; then $\mathtt{case}$ acts as a binary decision 
diagram. The Shannon expansion is a substitution using booleans where
 
 * $\mathtt{inl} \left\langle  \right\rangle \equiv true$
 * $\mathtt{inl} \left\langle  \right\rangle \equiv false$

then

\[
[M/x]P \equiv \text{ if } M \text{ then } [true/x]P \text{ else } [false/x]P.
\]

and, in particular,

\[
P \equiv \text{ if } x \text{ then } [true/x]P \text{ else } [false/x]P.
\]

The eta rule for disjunction is then

\begin{prooftree}
\AxiomC{$\Gamma \vdash M : A \vee B$}
\AxiomC{$\Gamma, z:A \vee B \vdash P : C$}
\BinaryInfC{$\Gamma \vdash [M/z]P \equiv \mathrm{case}(M; x : [\mathtt{inl}(x)/z]P; y : [\mathtt{inr}(y)/z]P) : C$}
\end{prooftree}

like a generalized Shannon expansion. As an special case, we
get that $M \equiv \mathtt{case}(M, x . \mathtt{inl}(x), y . \mathtt{inr}(y))$.

***** Remark
We could have defined the relationship on variables $x \equiv \left\langle \mathtt{fst}(x), \mathtt{snd}(x) \right\rangle$, but
to derive the general rule from there, we would have needed another property
to get a correct substitution rule.

***** Coproduct
We write the coproduct as $A + B$, and its diagram as

\[\begin{tikzcd}[column sep=tiny]
& C  & \\
& A+B  \uar[dashed]{\exists! \left\{ P,Q \right\}}  & \\
A\ar[bend left]{uur}{P}       \urar[swap]{\mathtt{inl}} &&
B\ar[swap,bend right]{uul}{Q} \ular{\mathtt{inr}}
\end{tikzcd}\]

where

\[
\left\{ P,Q \right\} \equiv \mathtt{case} ( - , x.P, y.Q) 
\]

And the unicity simply says that

\begin{prooftree}
\AxiomC{$\Gamma, x:A \vdash [ \mathtt{inl}(x)/z ]M \equiv P : C$}
\AxiomC{$\Gamma, y:B \vdash [ \mathtt{inr}(y)/z ]M \equiv Q : C$}
\BinaryInfC{$\Gamma, z : A+B \vdash M \equiv \mathtt{case}(z,x:P,y:Q) : C$}
\end{prooftree}

This is an induction principle. We can caracterize the behaviour of $M$ simply
by giving its behaviour on the $\mathtt{inl}$ and the $\mathtt{inr}$.
***** Beta/eta rules
The beta rules are analytic judgements. Self-evident.
The eta rules are synthetic judgements. They require proof.

The beta rules correspond to definitional equality and the 
eta rules correspond to propositional equality; it will be
expressed typically by a type. The definitional equality, on
the other hand, is simply a judgement and it is also called
a judgmental equality.
**** Lecture 6: Dependency, families of types
So far, we have seen a propositions/types correspondence.
We will add a type of natural numbers, and look for its correspondence
in intuitionistic logic.

***** Gödel's T
We will call Gödel's T to the system we have developed so far plus
a natural numbers type. This is not exactly Gödel's T in the literature,
where it is defined only with function types.

\begin{prooftree}
\RightLabel{(Nat$_{I-0}$)}
\AxiomC{}
\UnaryInfC{$\Gamma \vdash 0 : Nat$}
\RightLabel{(Nat$_{I-S}$)}
\AxiomC{$\Gamma \vdash M : Nat$}
\UnaryInfC{$\Gamma \vdash s(M) : Nat$}
\noLine
\BinaryInfC{}
\end{prooftree}

The elimination form is just definition by recursion

\begin{prooftree}
\RightLabel{(Nat$_{E}$)}
\AxiomC{$\Gamma \vdash M : Nat$}
\AxiomC{$\Gamma \vdash P : A$}
\AxiomC{$\Gamma, x:A \vdash Q:A$}
\TrinaryInfC{$\Gamma \vdash \mathtt{rec}(P,x.Q)(M) : A$}
\end{prooftree}

We need now two beta rules to comply with the inversion principle.

 * $\mathtt{rec}(P,Q)(0) \equiv P$
 * $\mathtt{rec}(P,Q)(s(M)) \equiv [ \mathrm{rec}(P,Q)(M)/x ]Q$

so, if $\overline{n} = s(\dots s(0)\dots)$, $\mathtt{rec}(P,Q)(\overline{n}) \equiv Q(Q(\dots (Q(P))\dots)$.

There is also a eta rule, that was not considered by Gödel at the moment.
Suppose an $M$ acting the same way on the $0$ and the $s$, then it is the
recursor.

\begin{prooftree}
\AxiomC{$\Gamma,z : Nat \vdash M : A$}
\AxiomC{$\Gamma \vdash [0/z] M \equiv P:A$}
\AxiomC{$\Gamma, z:Nat \vdash [ S(z)/z ]M \equiv [M/x]Q$}
\TrinaryInfC{$\Gamma,z:Nat \vdash M \equiv \mathtt{rec}(P,Q)(z)$}
\end{prooftree}

****** Special case on the recursor
Plugging naturals on the recursor

$z : Nat \vdash \mathtt{rec}(0,y.s(y))(z) \equiv z : Nat$

****** Commuting conversion

$\Gamma, z:Nat \vdash [ \mathtt{rec}(0,y.s(y))(z)/z  ]M \equiv \mathtt{rec}([0/z]M, y.[s(y)/z]M)(z)$

***** Natural numbers object in a category
The natural numbers object is the universal object in the following
diagram

\[\begin{tikzcd}[column sep=huge]
1 \rar{0}\drar[swap]{P} &
\mathbb{N} \dar[dashed]{\exists! \mathtt{rec}(P,Q)} &
\mathbb{N} \rar{s}\dar[dashed]{\exists! \mathtt{rec}(P,Q)} &
\mathbb{N} \dar[dashed]{\exists! \mathtt{rec}(P,Q)} \\
&
A &
A \rar[swap]{Q}&
A
\end{tikzcd}\]

***** Reorging the NNO into an initial algebra
This is equivalent to this universality property

\[\begin{tikzcd}[column sep=60pt]
1+\mathbb{N} \dar[swap]{\left\{ 0,s \right\}} \rar[dashed]{ id + \mathtt{rec}(P,Q) } & 
1+A \dar{\left\{ P,Q \right\}} \\
\mathbb{N} \rar[dashed]{\mathtt{rec}(P,Q)}  & 
A
\end{tikzcd}\]

where $f+g : A+B \to A'+B'$ is defined componentwise on the coproduct.

***** Initial algebras
This is an instance of a more general phenomenon, where a functor $F$ satisfies
the diagram with the initial object $I$.

\[\begin{tikzcd}
F(I)\rar{F(!)} \dar[swap]{i} & F(A) \dar{f} \\
I\rar{(!)} & A
\end{tikzcd}\]

This is called an *initial algebra*.

***** Defining addition
We can define addition on the second argument

$\mathtt{plus} := \lambda x. \lambda y. \mathtt{rec}(x;z.s(z))(y)$

and we can check that $\mathtt{plus}\ \overline{m}\ \overline{n} \equiv \overline{m+n}$. But we also can
define addition on the first $\mathtt{q}:= \lambda x.\lambda y. \mathtt{p}\ y\ x$, and this also
implements addition: $\mathtt{q}\ \overline{m}\ \overline{n} \equiv \overline{m+n}$.

Be we cannot prove

\[
x:Nat, y:Nat \vdash \mathtt{p}\ x\ y \equiv \mathtt{q}\ x\ y  \equiv \mathtt{p}\ y\ x
\]

as these are NOT definitionally equal! It can be proved that it is
not provable using only beta rules. This would require a proof by
induction: to show something for all the numerals is the same thing
as to show it for any numeral variables.

***** Extensional and intensional equality
Those are *extensionally* equal, but they are not intensionally equal
(definitional equality). They represent a different algorithm. In the
*sense of Frege*, they have the same reference, but not the same sense.
They have the same IO but different algorithms.

 * Extensional equality is analytic, it does not require proof.
 * Intensional equality is synthetic, does requires proof.

Extensional equality on $(\mathbb{N}\to \mathbb{N})\to(\mathbb{N}\to \mathbb{N})$ has a high quantifier
complexity. A bunch of nested forall and exist.

***** Extensional equality
Intensional equality is an inductive defined judgment, whereas
Extensional equality is a proposition such as

\[ \mathtt{p}\ x\ y =_{Nat} \mathtt{q}\ x\ y
\]

that is an atomic proposition. By the propositions as types
principle, extensional equality is a family of types.

\[
x: Nat, y:Nat \vdash x = y \text{ type}
\]

sometimes $x=y$ is written as $Id_{Nat}(x,y)$. It is a propositional
function or a binary relation.

This family can be instantiated by substitution

\[
Id_{Nat}(M,N) \text{ type}
\]

whenever $M,N:Nat$.

***** Example of extensional equality
We can define the finite sequence of naturals of length $x:Nat$

\[
x : Nat \vdash Seq(x) \text{ type.}
\]

In this case, $Seq(p\ \overline{m}\ \overline{n}) \equiv Seq(q\ \overline{m}\ \overline{n})$ because of the fact that
$p\ \overline{m}\ \overline{n} \equiv q\ \overline{m}\ \overline{n}$. But

\[
x:Nat, y:Nat \vdash Seq(p\ x\ y) \not\equiv Seq(q\ x\ y)
\]

will not be definitionally equal. But they are isomorphic! In some
sense, they should be equivalent. $A \simeq B$ should mean that for some
$f,g$, we should get

\[\begin{aligned}
\alpha :&\quad g \circ f = \mathrm{id} \\
\beta :&\quad f \circ g = \mathrm{id}
\end{aligned}\]

but again, we are we meaning here by equality? In this case we are
talking about propositional equality. There should be transformations
$\alpha,\beta$ between the compositions and the identities.

***** Univalence axiom
In some sense, we expect them to be equal. Univalence says that $A=B \iff A \simeq B$.
There will be an equivalence between those two types.
***** Setup for dependent types
Context/closed types. We have judgements
 
 * $\Gamma \text{ ctx}$
 * $\Gamma \equiv \Gamma'$

Open types/families

 * $\Gamma \vdash A \text{ type}$
 * $\Gamma : A \equiv A'$

Elements of types

 * $\Gamma \vdash M : A$
 * $\Gamma \vdash M \equiv M' : A$

We will have a notion of empty context and the notion of adding anything
to a context

\begin{prooftree}
\AxiomC{}
\UnaryInfC{$\cdot \text{ ctx}$}
\AxiomC{$\Gamma \text{ ctx}$}
\AxiomC{$\Gamma \vdash A \text{ type}$}
\BinaryInfC{$\Gamma, x:A \text{ ctx}$}
\noLine
\BinaryInfC{}
\end{prooftree}

and the equality

\begin{prooftree}
\AxiomC{}
\UnaryInfC{$\cdot \equiv \cdot$}
\AxiomC{$\Gamma \equiv \Gamma'$}
\AxiomC{$\Gamma \vdash A \equiv A'$}
\BinaryInfC{$\Gamma, x:A \equiv \Gamma, x:A'$}
\noLine
\BinaryInfC{}
\end{prooftree}

we can take variables

\begin{prooftree}
\AxiomC{}
\UnaryInfC{$\Gamma,x:A,\Delta \vdash x :A $}
\end{prooftree}

here it is necessary a weakening rule

\begin{prooftree}
\AxiomC{$\Gamma,\Delta \vdash J$}
\AxiomC{$\Gamma \vdash A \text{ type}$}
\BinaryInfC{$\Gamma, x:A, \Delta \vdash J$}
\end{prooftree}

and a substitution

\begin{prooftree}
\RightLabel{(substitution/transitivity)}
\AxiomC{$\Gamma, x:A, \Delta \vdash J$}
\AxiomC{$\Gamma \vdash M:A$}
\BinaryInfC{$\Gamma [M/x]\Delta \vdash [M/x]J$}
\end{prooftree}

and the principle of functionality

\begin{prooftree}
\AxiomC{$\Gamma, x:A, \Delta \vdash N:B$}
\AxiomC{$\Gamma\vdash M\equiv M' :A$}
\BinaryInfC{$\Gamma [M/x] \Delta \vdash [M/x]N \equiv [M'/x]N : [M/x]B$}
\end{prooftree}

another simpler rule is

\begin{prooftree}
\AxiomC{$\Gamma \vdash M:A$}
\AxiomC{$\Gamma \vdash A \equiv A'$}
\BinaryInfC{$\Gamma \vdash M:A'$}
\end{prooftree}

and similarly

\begin{prooftree}
\AxiomC{$\Gamma \vdash M \equiv M':A$}
\AxiomC{$\Gamma \vdash A \equiv A'$}
\BinaryInfC{$\Gamma \vdash M\equiv M':A'$}
\end{prooftree}

All this is written on the section 2 of the appendix of HoTT.

****** Exercise
Consider exchange and contraction
***** Formation rules
The identity type is constructed as

\begin{prooftree}
\RightLabel{(Id-F)}
\AxiomC{$\Gamma \vdash A \text{ type}$}
\AxiomC{$\Gamma \vdash M:A$}
\AxiomC{$\Gamma \vdash N:A$}
\TrinaryInfC{$\Gamma \vdash Id_A(M,N) \text{ type}$}
\end{prooftree}

iterated identity types can be defined $Id_{Id_A(M,N)}$ to any dimension.
The introduction rule should be

\begin{prooftree}
\RightLabel{(Id-I)}
\AxiomC{$\Gamma \vdash M:A$}
\UnaryInfC{$\Gamma \vdash \mathrm{refl}(M) : Id_A(M,M)$}
\end{prooftree}

being a witness of the fact that $M$ is equal to itself.
**** Lecture 7: Dependent Types
***** Last week
The basic judgements are

 1) $\Gamma \text{ ctx}$
 2) $\Gamma \equiv \Gamma'$
 3) $\Gamma \vdash A \text{ type}$
 4) $\Gamma \vdash A \equiv A'$
 5) $\Gamma \vdash M:A$
 6) $\Gamma \vdash M \equiv M' :A$

and they follow structural properties. For example, typing respect definitional
equivalence

\begin{prooftree}
\AxiomC{$\Gamma \vdash M:A$}
\AxiomC{$\Gamma \vdash A \equiv A'$}
\BinaryInfC{$\Gamma \vdash M : A'$}
\end{prooftree}

We left open the exact formulation.

****** Example
An example of dependent type is $x : Nat \vdash Seq(x) \text{ text}$.

\begin{prooftree}
\AxiomC{$M \equiv M' : Nat$}
\UnaryInfC{$Seq(M) \equiv Seq(M')$}
\end{prooftree}

But we do not get $x,y : Nat \not\vdash Seq(x+y) \equiv Seq(y+x)$. The
reason is that $x + y \not\equiv y + x$, they are only intensionally equivalent.
To apply $\eta$ you need to establish an invariant about a candidate $M$,
and the $\eta$ rule would not be enough to write a proof of induction of
that fact. We do not want an induction eta-rule.

***** Proof-relevance
An element $P : Id_A(M,N)$ can be seen as

 1) a proof that $M$ is $N$.
 2) an identification of $M$ with $N$.
 3) a path from $M$ to $N$.

This $x =_A y$ is called propositional equality.

***** Generalization to dependent types
We will review the initial structure of types to generalize the
propositional negative connectives to their dependent forms.
For example, $A \times B$ will generalize to a sigma type $\sum_{x:A}B_x$;
and $A \supset B$ generalizes to $\prod_{x:A}B_{x}$.

\[
\prod_{x:Nat} \sum_{y:Nat} Id_{Nat}(y, \mathtt{succ}(x))
\]

They will represent logical conectives as

\[
\forall x:Nat. \exists y:Nat.\quad y = \mathtt{succ}(x).
\]

***** Pi Types
Formation rules

\begin{prooftree}
\RightLabel{($\pi$-F)}
\AxiomC{$\Gamma \vdash A \text{ type}$}
\AxiomC{$\Gamma, x : A \vdash B_x \text{ type}$}
\BinaryInfC{$\Gamma \vdash \prod_{x:A}B_{x} \text{ type}$}
\end{prooftree}

introductory rules

\begin{prooftree}
\RightLabel{($\pi$-I)}
\AxiomC{$\Gamma, x:A \vdash M_{x} : B_{x}$}
\UnaryInfC{$\Gamma \vdash \lambda x. M_x : \prod_{x:A}B_{x}$}
\end{prooftree}

elimination rules

\begin{prooftree}
\RightLabel{($\pi$-E)}
\AxiomC{$\Gamma \vdash M : \prod_{x:A}B_x$}
\AxiomC{$\Gamma \vdash N:A$}
\BinaryInfC{$\Gamma \vdash MN : [N/x]B$}
\end{prooftree}

There is a beta-rule

\[
(\lambda x.M)N \equiv [N/x]M
\]

and an eta-rule

\[
(\lambda x.M x)\equiv M.
\]
***** Particular case
$A \supset B$ is a particular case of a pi-type where $B$ does
not depends on $A$.

***** Sigma type
****** Formation

\begin{prooftree}
\AxiomC{$\Gamma \vdash A \text{ type}$}
\AxiomC{$\Gamma, x:A \vdash B_{x} \text{ type}$}
\BinaryInfC{$\Gamma \vdash \sum_{x:A}B_x \text{ type}$}
\end{prooftree}

****** Introduction
This is constructive existence, you are required to show evidence
of a particular case where it does hold

\begin{prooftree}
\AxiomC{$\Gamma \vdash M :A $}
\AxiomC{$\Gamma \vdash N : [M/x]B$}
\BinaryInfC{$\Gamma \vdash \left\langle M,N \right\rangle : \sum_{x:A} B_x$}
\end{prooftree}

****** Particular case
The product of types is a particular case where $B_x$ is
independent from $x:A$.

****** Elimination
Will not be the same as in the HoTT book.

\begin{prooftree}
\RightLabel{($\Sigma_{E_1}$)}
\AxiomC{$\Gamma \vdash M : \sum_{x:A} B_x$}
\UnaryInfC{$\Gamma \vdash \mathtt{fst}(M) : A$}
\RightLabel{($\Sigma_{E_2}$)}
\AxiomC{$\Gamma \vdash M : \sum_{x:A} B_x$}
\UnaryInfC{$\Gamma \vdash \mathtt{snd}(M) : [ \mathtt{fst}(M)/x]B_x$}
\noLine
\BinaryInfC{}
\end{prooftree}

****** Beta/eta rules
Beta rules

 * $\mathtt{fst}\left\langle M,N \right\rangle \equiv N$,
 * $\mathtt{snd}\left\langle M,N \right\rangle \equiv N$

and an eta-rule

 * $\left\langle \mathtt{fst}(M), \mathtt{snd}(M) \right\rangle \equiv M$.
 
***** Constructive logic
Can be seen as a refinment of classical logic, not as anything opposite
to it.
***** Positive fragment
In the positive fragment, we have $(0,A+B,Nat,\dots)$. But are not
going to change the types. Issue: the positive elims reach into
arbitrary types.

For example, the elim of $+$ was

\begin{prooftree}
\AxiomC{$\Gamma \vdash M : A + B$}
\AxiomC{$\Gamma,x:A \vdash N:C$}
\AxiomC{$\Gamma, y:B \vdash P:C$}
\TrinaryInfC{$\Gamma \vdash \mathtt{case}(M,x.N,y.P) : C$}
\end{prooftree}

but here there is no dependency. $C$ captures the join point of two
branches; or proof by cases.

****** Example: induction
Let $2 := 1 + 1$, $tt := \mathtt{inl}\langle\rangle$ and $ff := \mathtt{inr}\langle\rangle$. We define

\[ \mathtt{if}(M,N,P) := \mathtt{case}(M,-.N,-.P)
\]

and we want to prove that every element of $2$ is one of those

\[
\prod_{x:2} \left( Id_2(x, \mathtt{tt}) + Id_2(x, \mathtt{ff}) \right).
\]

We have to prove both

 * $Id_2(\mathtt{tt}, \mathtt{tt}) + Id_2(\mathtt{tt}, \mathtt{ff})$
 * $Id_2(\mathtt{ff}, \mathtt{tt}) + Id_2(\mathtt{ff}, \mathtt{ff})$

So we use

\begin{prooftree}
\AxiomC{$\Gamma \vdash M : A + B$}
\AxiomC{$\Gamma, z:A+B \vdash C_{z}$ type}
\AxiomC{$\Gamma, x:A \vdash N: [\mathtt{inl}(x)/z] C$}
\noLine
\UnaryInfC{$\Gamma, y:B \vdash P: [\mathtt{inr}(y)/z] C$}
\TrinaryInfC{$\Gamma \vdash \mathtt{case} [z.C] (M;x.N;y.P) : [M/z]C$}
\end{prooftree}

where $[z.C]$ is called the *motive* (term by Connor McBride). In this
particular case

\begin{prooftree}
\AxiomC{$\Gamma \vdash M : 2$}
\AxiomC{$\Gamma, z:2 \vdash C_{z}$ type}
\AxiomC{$\Gamma\vdash N: [\mathtt{tt}/z] C$}
\noLine
\UnaryInfC{$\Gamma\vdash P: [\mathtt{ff}/z] C$}
\TrinaryInfC{$\Gamma \vdash \mathtt{if}(M;N;P) : [M/z]C$}
\end{prooftree}

This is a rule of induction.

****** Example
We have the expression

$\mathtt{if}(M,17, \mathtt{tt}) : \mathtt{if} (M,Nat,2)$

but, it is a well-typed expression? not yet. We cannot type
those as types.

***** Induction on naturals
\begin{prooftree}
\AxiomC{$\Gamma \vdash M : Nat$}
\AxiomC{$\Gamma, z:Nat \vdash C \text{ type}$} 
\AxiomC{$\Gamma \vdash N : [0/z]C$}
\noLine
\UnaryInfC{$\Gamma,x:Nat, y:[x/z]C \vdash P:[s(x)/z]C$}
\TrinaryInfC{$\Gamma \vdash \mathtt{rec}[z.C](M,N;x,y.P) : [M/z]C$}
\end{prooftree}

with the two beta rules

 * $\mathtt{rec}[z.C](0,N; x,y.P) \equiv N$
 * $\mathtt{rec}[z.C](s(M), N; x,y.P) \equiv [M, \mathtt{rec}[z.C](M,N;x,y.P)/x,y]P$

It has an eta rule which is not useful.

****** Exercise

$\prod_{x:Nat} \left(Id(s(x),0) \to \bot\right)$

we will use

\[
\lambda x. \mathtt{rec}[-](x; -,-)
\]

****** Hard exercise
We cannot solve this yet

$\prod_{x,y : Nat} (Id_{Nat}(sx,sy) \to Id_{Nat}(x,y))$
***** The other form of product types, sigma variant
Idea: elimination as pattern-matching.

\begin{prooftree}
\AxiomC{$\Gamma \vdash M : \Sigma_{x:A}B_x$}
\AxiomC{$\Gamma, z : \Sigma_{x:A}B_x \vdash C \text{ type}$}
\AxiomC{$\Gamma, x:A, y:B \vdash P : [\langle x,y \rangle/z]C$}
\TrinaryInfC{$\Gamma \vdash \mathtt{split}[z.C](M;x,y.P) : [M/z]C$}
\end{prooftree}

the beta rule is

 * $\mathtt{split}[z.C](\left\langle M_1,M_2 \right\rangle; x,y.P) \equiv [M_1,M_2/x,y]P$

and the eta rule is similar to previous $\eta$ rules. Anything like split is split.

****** Exercise
Define =split= from fst,snd.
Define =fst=, =snd= from split. (Not yet)
**** Lecture 8: Identity types
***** Polarity
Negative and positive fragments. The difference here is
if the type is based on the elimination or the introduction
rule; the other part of the rule is determined by this first
rule. In category theory, it corresponds to the universal
property mapping /in/ or /out/ the definition of the type.

\begin{tabular}{c|cc}
            & negative    & positive     \\
\hline
type theory & elimination & introduction \\
category theory & UP mapping in & UP mapping out
\end{tabular}

For example, $A\times B$ is /negative/. We write the elimination rule:
given a product, we have =fst= and =snd=. The introduction rule is
a pair, needing an $A$ and a $B$.
***** Last week
Dependent formulations of 

 1) negatives $\Pi,\Sigma$.
 2) positives, the type does not change, but the elimination forms do;
    they become induction principles

Elim for the booleans is an example of branching. Today

 * identity types
 * universes
 * ITT. Limitations and peculiarities

***** Identity types
They have this rule of formation

\begin{prooftree}
\RightLabel{(Id-F)}
\AxiomC{$\Gamma \vdash A \text{ type}$}
\AxiomC{$\Gamma \vdash M : A$}
\AxiomC{$\Gamma \vdash N : A$}
\TrinaryInfC{$\Gamma \vdash Id_A(M,N) \text{ type}$}
\end{prooftree}

if we read this type propositionally, this is the type of proofs of
equality between $M$ and $N$. As a notation we use $M =_A N$.

\begin{prooftree}
\RightLabel{(Id-T)}
\AxiomC{$\Gamma \vdash M : A$}
\UnaryInfC{$\Gamma \vdash \mathtt{refl}_A(M) : Id_A(M,M)$}
\end{prooftree}

In ITT, this would be the only intro rule. We can think of $Id$ as an
inductively generated family of types. 

***** Elimination rule for identity types
The elimination rule would then work as

\begin{prooftree}
\RightLabel{(Id-E)}
\AxiomC{$\Gamma \vdash P: Id_{A}(M,N)$}
\AxiomC{$\Gamma, x:A, y:A, z:Id_A(x,y) \vdash C \text{ type}$}
\AxiomC{$\Gamma, x:A \vdash Q: [x,x,\mathtt{refl}(x)/x,y,z]C$}
\TrinaryInfC{$\Gamma \vdash J[x,y,z.C](P;x.Q) : [M,N,P/x,y,z]C$}
\end{prooftree}

This principle is called *path induction*, where a path is an element
of the identity type. The beta rule is then

 * $J[x,y,z.C]( \mathtt{refl}(M), x.Q) \equiv [M/x]Q : [M,M, \mathtt{refl}(M)/x,y,z]C$

This $J$ is the computational content of the proofs by path induction.
***** Equivalence relation of identity
The identity type should be an equivalence relation

 1) it is reflexive by definition, $Id_A(M,M) \text{ true}$.
 2) it is symmetric showing that there is a function

    \[ \mathtt{sym}_A : \prod_{x,y:A}Id_A(x,y) \to Id_A(y,x)
    \]

 3) it is transitive with

    \[ \mathtt{trans}_A:
    \prod_{x,y,z:A} Id_A(x,y) \to Id_A(y,z) \to Id_A(x,z)
    \]

To define symmetry, we will take

\[ \mathtt{sym}_A :=
\lambda x,y:A.\quad \lambda z:Id_A(x,y).\quad
J[x,y, - : Id_A(y,x)}](z;x. \mathtt{refl}_A(x))
\]

Note that $\mathtt{sym}(M)(M)(\mathtt{refl}(M)) \equiv \mathtt{refl}(M)$ due to the beta rule for $J$.

To define transitivity 

\[ \mathtt{trans}_A :=
\lambda m,n,p. \ \lambda u{:}Id_A(m,n).\ \lambda v{:} Id_A(n,p).\  
(J[x,y, -:Id_A(y,p) \to Id(x,p) ](u; x.\lambda w.w))(v)
\]

# It would be better to stop using lambdas for the parameters and
# write the arguments as arguments.

Note that, in particular, $\mathtt{trans}(M)(M)(P)(\mathtt{refl_A(M)})(Q) \equiv Q$.

****** Exercise
Find two other proofs, not definitionally equivalent, of transitivity.
Hint: double induction.
***** Simple functionality
Suposse $x:A\vdash F:B$ where $A,B$ are types. We have $F\colon A \to B$.
We would like to have a way to prove that maps preserve equality

\[
x,y{:}A, u{:}Id_A(x,y) \vdash Id_B(Fx,Fy)
\]

We will define $\mathtt{ap}\ F\ u$, also called $F(|u|)$; the functorial action

\[ \mathtt{ap}\ F\ u = 
J[x,y, -:Id_B(Fx,Fy)](u, x. \mathtt{refl}_B(F\ x))
\]

***** Transportation property
Suposse $x:A \vdash B \text{ type}$, two pictures are useful

 1) Assigning $a{:}A \mapsto B[a]$ should be functorial.
 2) $\int_{A} B$ should have a display map with fibers sending elements
    on $B[a]$ to $a$.

In some sense, $a = a'$ must imply $B[a] \simeq B[a']$. Transportation could
be thought as functionality for families.

We would want to have 

\[
m,m':A, u:Id_A(m,m'), v : [m/x]B \vdash \mathtt{tr}[x.B](u)(v) : [m'/x]B
\]

the notation for $\mathtt{tr}[x.B](u)(v)$ is $u_{\ast}(v)$.

# Diagram of the lifting property [1:19:50]

This should be defined using path induction

\[ \mathtt{tr}[x.B](u)(v) :=
J\Big[x,y, -:[x/z]B \to [y/z]B\Big](u; z. \lambda w.w)(v)
\]

***** Exercise
Find a map 

\[
x,y{:}Nat \vdash  -{:} Seq(x+y) \to Seq(y+x)
\]

To do this we need

 1) to find a path $x,y{:} Nat \vdash -{:}x+y =_{Nat} y+x$.
 2) transport along that path.
**** Lecture 9: Universes
***** Last week
Maps preserve proofs of identity (functionality)

 * if $F \colon A \to B$ and $p : Id_A(a,a')$, then $\mathtt{ap}\ f\ p : Id_B(f(a),f(a'))$.
   If $a = a'$ is true, $f(a) = f(a')$ is true.

The transportation creates isomorphisms between families of types.

 * If $x:A\vdash B$ is a type and $p : Id_A(a,a')$, then
   $\mathtt{tr}[x.B](p) : B[a] \to B[a']$. This is family functionality.
   If $a=a'$, then $B[a] \iff B[a']$.
***** Universes and large elims
Last notion on ITT.

****** Example
We defined $\mathtt{if}(M,N;P) : B[M]$, and we would want to write things like
$\mathtt{if}(M;17;\mathtt{tt}) : \mathtt{if}(M; Nat,Bool)$; a type depending on a boolean. But we cannot
write it because those are types instead of terms.

****** Large eliminations (ad hoc)
We simply introduce a new type

\begin{prooftree}
\AxiomC{$M:Bool$}
\AxiomC{$A$ type}
\AxiomC{$B$ type}
\TrinaryInfC{$IF(M,A,B)$ type}
\end{prooftree}

where

 * $IF(\mathtt{tt},A,B) \equiv A$
 * $IF(\mathtt{ff},A,B) \equiv B$

Those are called *large eliminations*.

****** Universes of types
A *universe* is a type of types.

\begin{prooftree}
\AxiomC{}
\UnaryInfC{${\cal U}$ type}
\end{prooftree}

\begin{prooftree}
\AxiomC{}
\UnaryInfC{${\cal U} \equiv {\cal U}$}
\end{prooftree}

where the introduction rules are the previous formation rules.
For example,

\begin{prooftree}
\RightLabel{(UI-Id)}
\AxiomC{$A: {\cal U}$}
\AxiomC{$M,N:A$}
\BinaryInfC{$Id_A(M,N) : {\cal U}$}
\end{prooftree}

The universe should be closed to type formation, for example, closed
to pi-types, sigma-types, 0, 1, sum of two types...

\begin{prooftree}
\AxiomC{$A : {\cal U}$}
\AxiomC{$x:A \vdash B:{\cal U}$}
\BinaryInfC{$\prod_{x:A} B:{\cal U}$}
\end{prooftree}

But we do NOT postulate that ${\cal U} : {\cal U}$. Its formation rule is the unique
formation rule that is not translated. In other way, the Burali-Forte
Paradox could be reproduced.

****** Solving the problem with universes
Now, we could form $\mathtt{if}(M,Nat,Bool) : {\cal U}$; except we should define some
elimination rules.

Universes allow us to prove

 * injectivity of succ.
 * define =fst=, =snd= from =split=.

If we were to have large elims, we could write things like $\mathtt{If}(M,U,U\to U)$; but
not with the universal type, where is not true that $U : U$.

***** Hierarchy of universes
To solve previous problems, we could write a cumulative hierarchy of
universes. We have a family of rules

\begin{prooftree}
\RightLabel{(U-I)}
\AxiomC{$$}
\UnaryInfC{${\cal U}_i : {\cal U}_{i+1}$}
\RightLabel{(U-$\equiv$)}
\AxiomC{$$}
\UnaryInfC{${\cal U}_i \equiv {\cal U}_{i}$}
\noLine\BinaryInfC{}
\end{prooftree}

defining ${\cal U}_1,{\cal U}_2,\dots$ with a trivial definitional equality and closure
properties for every universe, for example

\begin{prooftree}
\AxiomC{$A : {\cal U}_i$}
\AxiomC{$x:A \vdash B:{\cal U}_i$}
\BinaryInfC{$\prod_{x:A} B:{\cal U}_i$}
\end{prooftree}

and the *principle of cumulativity*

\begin{prooftree}
\RightLabel{(cumulativity)}
\AxiomC{$A:{\cal U}_i$}
\UnaryInfC{$A : {\cal U}_{i+1}$}
\RightLabel{(cumulativity-$\equiv$)}
\AxiomC{$A \equiv B : {\cal U}_{i}$}
\UnaryInfC{$A \equiv B : {\cal U}_{i+1}$}
\noLine\BinaryInfC{}
\end{prooftree}

This architecture is forced on us by the Burali-Forte paradox. This
corresponds to the idea of inaccesible cardinals; to a size hierarchy.
***** Dimension
There will be another different notion (on a different axis) than
size (universes). Dimensions are new in HoTT.

***** Formation rules in HoTT
In the HoTT book, formation rules are written as introductions to
the universal type

\begin{prooftree}
\AxiomC{$A : {\cal U}$}
\AxiomC{$x:A \vdash B:{\cal U}$}
\BinaryInfC{$\prod_{x:A} B : {\cal U}$}
\end{prooftree}

This uses *typical ambiguity*, ${\cal U}$ can be ${\cal U}_i$. The type inference algorithms
of proof assistants solve these constraints, specifying the level in which
we are working. Is a kind of Universe Polymorphism: it let you pretend
${\cal U} : {\cal U}$.

It is very difficult to write something where it is not possible to get an
error at the time of inferring universes. The Burali-Forte paradox cannot be
written in this setting.

***** ITT
At this point, we have introduced ITT with Nats, Sigma, Pi, Identity and
Universes. [Martin-Löf 73]

****** Theorem of Choice in ITT
When $C$ is a total relation, we can pick up a canonical representative of
the elements to which $x$ is related to.

\[
\left(\prod_{x:A} \sum_{y:B} C(x,y)\right) \to \sum_{f:A\to B}\prod_{x:A} C(x,f(x))
\]

where $f$ is called the choice function.

In set theory, this is indepent of the axioms of sets; but in type
theory, it is a theorem because of proof-relevance.

\[
\lambda F.\ 
\left\langle \lambda x. \mathtt{fst}(F(x)) , \lambda x. \mathtt{snd}(F(x)) \right\rangle
\]

where $\mathtt{snd}(F(x)) = C(x, \mathtt{fst}(F(x)))$. 

****** Axiom of choice on sets
How about translating this proof to set theory? We would need for the proof
to be a parametrized object! Proof relevance is key to prove the theorem of
choice. If we cannot look inside the first proof, we could not prove the
theorem.

***** Martin-Lof theorem
If $p:Id_A(M,N)$ for any closed $M,N,A$; without hypothesis (a theorem),
then $M \equiv N : A$.

****** Example
If we have that 

$A = Nat \to Nat \to Nat$
$M = \lambda x. \lambda y.\ x+y$
$N = \lambda x. \lambda y.\ y+x$
$M \not\equiv N$

There is no proof $p : Id(M,N)$, no term of that type. Yet, given $x,y,z: Nat$,
there exists a proof of $p : Id(x+y,y+x)$. The axiom of extensionality fails
here. It is NOT true that

\begin{prooftree}
\AxiomC{$x : A \vdash p:Id_{B}(fx,gx)$}
\UnaryInfC{\vdash -:Id$_{A\to B}(f,g)$}
\end{prooftree}

So the ordinary notion of function is not true here anymore. We cannot
even prove that $\lambda x.fx = \lambda x.gx$. This is a weakness of ITT.

****** Function extensionality as an axiom
If we introduce extensionality as an axiom, we would have introduced another
intro for identity types, and $J$ should have to be redefined.

In HoTT, we can construct this from the axioms, and this makes very difficult
the task of giving it a meaningful computational interpretation.

***** Extensional theory of types (ETT)
In ETT (Extensional here has another meaning), the only identifications are
=refl=. We have the principle of *identity reflection*

\begin{prooftree}
\AxiomC{$p : Id_{A}(M,N)$}
\UnaryInfC{$M \equiv N : A$}
\end{prooftree}

and the only possible proof of identity is =refl=

\begin{prooftree}
\AxiomC{$p : Id_{A}(M,N)$}
\UnaryInfC{$p \equiv \mathtt{refl}(M): Id_A(M,N)$}
\end{prooftree}

In this case, the problem is solved. $Id_B(fx,gx)$ gives us $fx \equiv gx$,
so $\lambda x. fx \equiv \lambda x. gx$, and by eta-reduction, $f \equiv g$. This implies function
extensionality and obviates the need for a rule of transport, we can in fact
show that $B[a] \equiv B[a']$. NuPRL was based on ETT, Coq is based on ITT.

***** The disadvantage of ETT
$M:A$ is decidable (not feasible) in ITT, while $M : A$ is undecidable in ETT.
We need arbitrary theorem proving to decide the equality on ETT. It is instead
decidable if a derivation is a valid one.

**** Lecture 10: Groupoid structure of types
***** Last week
We considered ITT vs ETT. ETT has advantages

 * in ETT, there is no necessity for transport.
 * ETT is similar to standard mathematics, in that there is "just
   equality".
 * function extensionality is implied from the rules.

And disadvantages

 * type checking is no longer decidable; judgmental equality
   is not decidible and it involves proof search and arbitrary theorem
   proving.

A *setoid* in ITT is a set with a given equivalence relation chosen to
have properties like function extensionality. So, the alternative to ETT
is to work with setoids on ITT.

Types are (limited to) sets (aka hsets). The reason why ETT looks like standard
mathematics is because we are working with Sets, where the only paths/identifications
are reflexivities. A sufficient condition for being discrete is decibility of equality.

***** Groupoids
Types in ITT, in contrast, are more general. They are $\infty\text{-groupoids}$, 
and they have richer path structure. Paths can be composed

 * $p : Id_A(a,b)$
 * $q : Id_A(b,c)$

When ITT was introduced, it had power to use gropoids. At the very
beginning, no one realized this feature. ETT works for set-level 
mathematics and it is easier.

****** Strict/weak refl
In ETT we can have two views of refl. NuPRL uses strict sets.

****** HoTT
ITT + axioms introducing new paths. Examples of new types are the
interval.

\[\begin{tikzcd}
I : & \underset{0}\cdot \rar[no head] & \underset{1}\cdot 
\end{tikzcd}\]

which is different from boolean types in that it has a nontrivial path

\[\begin{tikzcd}
Bool : & \underset{0}\cdot & \underset{1}\cdot 
\end{tikzcd}\]

There elements $0,1 : I$ and $seg : \mathrm{Id}_I(0,1)$. The booleans have a mapping
out property where a function $f : Bool \to A$ is defined by

 * $f(0) : A$
 * $f(1) :A$

on intervals, to create a function $f : I \to A$, you must also specify what the
function does on the segment

 * $f(\mathtt{seg}) : f(0) = f(1)$

just intuitively, we want some free structure on the data defining the type,
so that if we want to map out a type, we are required to define how to get
from a type to another on all constructors. $f : I \to A$, for example, picks
a path in $A$.
***** How does J deal with new paths?
Where do you get off adding axioms to type theory? In type theory, 
we have introductions, eliminations, and the Gentzen's inversion/unicity
principle gives us computation by beta rules. Everything has a beta-normal
form.

But when we add axioms, we get into trouble. What should we do on these cases

 * $J[\ ](\mathtt{seg}, x.Q) \equiv ?$
 * $J[\ ](\lambda x.p, y.Q) \equiv ?$

the principal problem with HoTT is how to recover constructivity/computation on
HoTT. We can here express non set-level math. If every equalities are decidable,
we have to be working with sets.

***** I. types are infinite-groupoids
Types are $\infty\text{-groupoids}$. 

Recall that $id_A(M) := \mathtt{refl}_A(M) : Id_A(M,M)$ and that
$p: Id_A(M,N) \vdash p^{-1} : Id_A(N,M)$ was defined by $J$. We also
had composition of paths (transitivity). =trans(p,q)= is defined
by $J$; so we have an equivalence relation.

We have to write code to prove that this is, in fact, an equivalence
relation. Those paths follow the groupoid laws.

****** Groupoid laws
In a groupoid, these laws has to be satisfied

  * $p \cdot p^{-1} \equiv \mathrm{id}$, could be an option, but we usually will accept
    equality on a weaker sense $p \cdot p^{-1} =_{\mathrm{Id}_A(M,N)} \mathrm{id}$.

So we would have elements giving us

  * $\mathtt{unitr} : Id_{Id_A(M,N)}(pp^{-1}, \mathrm{id}(M))$
  * $\mathtt{unitl} : p^{-1}p = \mathrm{id}(N)$
  * $\mathrm{idr} : p \cdot \mathrm{id}(N) = p$
  * $\mathrm{idl} : \mathrm{id}(M) \cdot p = p$

And associativity

  * $\mathtt{assoc} : (p \cdot q) \cdot r = p \cdot ( q \cdot r)$

All of those paths are definible from $J$, they are implicit on the
structure of types and they are called higher-coherences. If we consider only
paths from $M$ to $M$, we would get a higher-group.

****** Defining groupoid laws from J
The groupoid laws can be proven from J.

***** II. Maps are functors
If $f : A \to B$ and $p: M = M'$, we get $\mathrm{ap}_f(p) : fM = fM'$. 
That is the principle of equality functionality. This is written using
$J$ again. We know that $\mathrm{ap}(\mathtt{refl}(M)) \equiv \mathtt{refl}(f(M))$. $\mathtt{ap}$ preserves
identities in this sense. Does it preserve all the groupoid structure?

We can prove that $\mathtt{ap}$ preserves all the structure, it gives us a principle
of *equality functoriality*; it is functorial.

**** Lecture 11: Functoriality
***** Last week
It is a generalization of the structure given by the equivalence
relation on paths. Path satisfy the groupoid laws with the
concatenation of paths. The data associated to every path can be
thought as a higher dimensional path.

For $f : A \to B$, we have

\[ \mathtt{ap}_f : Id(M,N) \to Id(fM, fN)
\]

and it is a functorial application, respecting the groupoid structure
due to the eta-rules for $J$ as

 * $ap(id) = id$
 * $ap(p^{-1}) = ap(p)^{-1}$
 * $ap(p\cdot q) = ap(p) \cdot ap(q)$

and having also that $ap_{id} = id$ and $ap_{f \circ g} = ap_g \circ ap_f$. Suppose $f : \prod_{x{:}A}B_x$,
we would like to have the path

\[ Id_A(M,N) \to Id_B(fM,fN)
\]

but $fM : [M/x]B$ and $fN:[N/x]B$ are not of the same type! But we could use
the transport property to get $p_{\ast} : [M/x]B \to [N/x]B$. If we apply the transport
property to the inversed path, we get the inverted path $B[N] \to B[M]$. We would
get different proofs of the lemma if we use $p_{\ast}$ or $p_{\ast}^{-1}$.

***** Path-over-path
The lemma we want to do is

\[
M =_A N \longrightarrow f(M) =_p^{x:B_{x}} f(N)
\]

this is a notation that says that $f(M)$ and $f(N)$ are correlated by
$p$ on the fiber $x:B_x$. We will be able to send $p$ to a
path-over-path $q : f(M) =_p^{x:B_x} f(N)$.

#+begin_definition
Given $x : A \vdash B : {\cal U}_x$ and $p : M =_A N$,

\[
\Big(Q =_p^{x:B} R \Big)
:=
\Big(p_{\ast} Q =_{[N/x]B} R\Big)
\]
#+end_definition

It is possible to prove a lot of lemmas about this type. We can
state reflexivity, symmetry properties and so on.
***** Equivalence of types: motivation
Equivalence vs definitional and propositional equality of types as
elements of the universe.

 * In an informal treatment of classical logic, we mix $\iff$ and $=$.
   Nothing can distinghish between them. In classical logic there are
   only two propositions, so it is difficult to distingish.
 * Equality should be the relationship respected by everything inside
   the language.
 * But when we are working on a proof relevance setting, there could
   be many different proofs of two propositions, and two implications
   do not have to be inverses!
 * Isomorphisms of sets work on a similar way. It is not important to
   distinghish between two isomorphic sets given any isomorphism $f,f^{-1}$.

We could write bijections like $\omega = \omega^2$, but there are
contexts where we want to make a difference between the two. Set theory
allows us to ask nonsensical things like $0 \in 1$.

The condition of bijection on types can be translated as a function
$f : A \to B$ with a $g : B \to A$ such that

In ITT, let's suppose a set of functions $N \to N$ and a non-trivial 
bijection to itself.

 * $F(f) = f'$ and $G(f') = f$
 * $F(g) = g'$ and $G(g') = g$

but what do those equalities mean? 

 * $F(f)(x) = f'(x)$ and $G(f)(y) = f(y)$ would be an interpretation.
   Those would be extensionally equal, but different functions.

The notion of bijection is not very useful when working on higher-order
types.
***** Equivalence on types involving a universe
The elements of ${\cal U}$ have structure, each one of them is a groupoid.
The idea of bijection $FG(A) = A$ is not workable; we are interested
in nontrivial isomorphisms, in an equivalence rather than equality
$FG(A) \simeq A$.

This is similar to isomorphisms and equivalence of categories. We want
$FG(A) \cong A$, we do not need $FG(A) = A$. Equivalence is isomorphism up
to isomorphism.

And when we have a universe of universes, the same question repeats
itself. We need another level of comparison now. We would get the
higher-group structure of a type.

Isomorphism here is not a proposition but a structure.
***** Equivalence
Given $f : A \to B$, a quasiinverse of $f$ is given by
$(g,\alpha,\beta)$ such that

 * $g : B \to A$
 * $\alpha : \prod_{a:A} g(f(a)) =_A a$
 * $\beta : \prod_{b:B} f(g(b)) =_B b$

The type of *quasiinverses* is

\[
QI(f)_{A\to B} := \sum_{g : B \to A} 
\left(
\left(\prod_{a:A} g(f(a)) = a\right)
\times
\left(\prod_{b:B} f(g(b)) = b\right)
\right)
\]

****** Another version
In ITT, this is different from

 * $\alpha' : g \circ f = id_A$
 * $\beta' : f \circ g = id_B$

this uses two paths instead of two homotopies.
Function extensionality is now

\[
(f =_{A \to B} g) \simeq
\left( \prod_{a:A}f(a)=_B g(a) \right)
\]

saying that every homotopy defines an equation. Those
two types of proofs are equivalent.

***** Univalence axiom
There is an equivalence between equivalence and equality.

\[
(A \simeq B) \simeq (A = B)
\]

Equivalences are given by

\[
\sum_{f : A \to B} \sum_{g : B \to A} 
\left( f \circ g = id_B \times g \circ f = id_A \right)  \times \text{ some coherence condition }
\]

to avoid the function extensionality issue, we can write
homotopies instead

\[
\sum_{f : A \to B} \sum_{g : B \to A} 
\left( f \circ g \sim id_B \times g \circ f \sim id_A \right) \times \text{ some coherence condition }
\]

but we are going to have function extensionality.
**** Lecture 12: Equivalence of Types
***** Equivalence of types
We write the equivalence of $A \simeq B$. We say that $f : A \to B$ 
is an *equivalence* if there exists

\[
\left( \sum_{g:B\to A} f \circ g \sim id_B \right) \times
\left( \sum_{h:B\to A} h \circ f \sim id_A \right)
\]

the type of equivalences is

\[
A \simeq B := \sum_{f:A\to B} \mathrm{isequiv}(f)
\]

***** Elements of the equivalence
An equivalence is defined whenever those functions
exist

 1. $f : A \to B$
 2. $g:B\to A$
 3. $\alpha: \prod_{y:B} f(g(y)) =_B y$
 4. $h : B\to A$
 5. $\beta : \prod_{x:A} h(f(x)) =_A x$

***** Quasiinverse
Quasiinverses are defined as

\[ \mathrm{quasiinverse}(f) :=
\sum_{g:B\to A} f\circ g \sim id_B \times g \circ f \sim id_{A}
\]

There are three important properties

 1. $qinv(f) \to isequiv(f)$
 2. $isequiv(f) \to qinv(f)$
 3. $isequiv(f)$ expresses an HPROP, it has at most one proof up
    to higher homotopy.

we can transform the data from a quasiinverse to a equivalence.
from  $H : f \sim_{A \to B} g$ we get $\prod_{x:A} Id_B(f x, gx)$. $H$ is functorial in
$x:A$; in the sense that this diagram commutes for any $p : a = a'$

\[\begin{tikzcd}
f(a)\rar[no head]{H(a)} \dar[swap,no head]{ap_f(p)} & g(a) \dar[no head]{ap_g(p)} \\
f(a')\rar[no head]{H(a')} & g(a')
\end{tikzcd}\]

Homotopy is natural (or /polymorphic/) in $x$.

***** Funtion extensionality

 1) definable if $\mathtt{happly}: f =_{A \to B} g \to f \sim g$.
 2) the axiom of funtion extensionality says that the
    above map is an equivalence.

In the presence of function extensionality, we could write $\alpha$
and $\beta$ as $f \circ g \sim id$ and $h \circ f \sim id$. Once you
have function extensionality, you can write the homotopy as
an equality

 * $\prod_{y:B} f(g(y)) = y$
 * by definition of homotopy, $f\circ g \sim id$
 * by function extensionality, $f \circ g = id_{B}$

***** Exercises

 1) $id : A \to A$ is an equivalence, give the four parts of the
    equivalence.
 2) if $f$ is an equivalence, $f^{-1}$, given by the quasiinverse, is
    an equivalence.
 3) if $f$ and $g$ are equivalences, then so is $g \circ f: A \to C$.

***** Structure of paths in types
For example, if we take $Id_{A \times B}(-,-)$, the identity type seems invariant
to the way the type has been constructed; but a structure can be deduced
from the types.

There is a function $f$ with the type $Id_{A \times B}(x,y) \to Id_A(\pi_1x, \pi_2y) \times Id_B( \pi_2x, \pi_2y)$
that we can define as

\[
f := \lambda p. \left\langle \mathrm{ap}_{\pi_1}(p), \mathrm{ap}_{\pi_2}(p) \right\rangle
\]

And we can prove that $f$ is an equivalence

\[
Id_A(x,y) \simeq Id_A(\pi_1x,\pi_1y) \times Id_B(\pi_2x, \pi_2y)
\]

because it suffices to exhibit a quasiinverse for $f$.

 * $g : Id_A(\pi_1x,\pi_1y) \times Id_B(\pi_2x,\pi_2y) \to Id_{A \times B}(x,y)$
 * $\alpha : g(f(p)) =_{Id_{A\times B}(x,y)} p$
 * $\beta : f(g(q)) =_{Id_A(-,-) \times Id_B(-,-)} q$

we use pattern matching

\[
g := \lambda (p,q). ap^2_{pair}\ p\ q
\]

where $pair = \lambda x,y. (x,y)$, and $ap^2_f\ p\ q : Id(f x y, f x' y')$ where
$p: Id(x,x')$ and $q : Id(y,y')$.
***** Products
We need to show the following for the quasi-inverse

 * $\eta :\prod_p (ap^2_{pair} \left(ap_{\pi_1}(p), ap_{\pi_2}(p)) = p\right)$
 * $\beta_1 : \prod_p\prod_q ap_{\pi_1}(ap^2_{pair}\ p\ q) = p$
 * $\beta_2 : \prod_p\prod_q ap_{\pi_2}(ap^2_{pair}\ p\ q) = p$

We need by path induction $x : A \times B \vdash - : ap^2_{pair}\ (ap_{\pi_1}(refl(x))\ ap_{\pi_2}(refl(x)) = refl(x)$

 * $ap_{\pi_1}(refl(x)) \equiv refl(\pi_1(x))$
 * $ap_{\pi_2}(refl(x)) \equiv refl(\pi_2(x))$

Note that the type checking will depend on the computation rules, and
this is antimodular. If you change anything on the code, everything that
relies on it could break.

 * $ap^2_{pair}\ (refl(\pi_1 x))\ (refl(\pi_2 x)) \equiv refl(\pi_1(x),\pi_2(x)) \equiv refl(x)$
***** Nullary case

\[
Id_{1}(x,y) \simeq 1
\]

***** Coproducts
In coproducts, we would like to prove that

 * $Id_{A+B}(inl(a),inl(a')) \simeq Id_A(a,a')$
 * $Id_{A+B}(inr(b),inr(b')) \simeq Id_B(b,b')$
 * $Id_{A+B}(inl(a),inr(b)) \simeq 0$
 * $Id_{A+B}(inr(b),inl(a)) \simeq 0$

If we were to find a map from

 * $x : Id_{A+B}(inl(a),inl(a')) \vdash -:Id_A(a,a')$

using path induction on $p$, we would have to find a motive $C = ?$
and the conclusion should be $C(inl(a),inl(a'), p)$, where $J[C](p,\dots)$
would be the induction on paths. But how do we get rid of the $inl$?
We should define a motive as

\[
D(u,v) = Id_{A}(outl(u), outl(u))
\]

but there are not $outl$ functions! We want the motive to be

\[
F : (A+B) \times (A+B) \to {\cal U}
\]

such that
 
 * $F(inl(a),inl(a')) \equiv Id_A(a,a')$
 * $F(inr(b),inl(b')) \equiv Id_A(b,b')$
 * $F(inl(-),inr(-)) \equiv 0$
 * $F(inr(-),inr(-)) \equiv 0$

Exercise: define such an $F$ by double induction.

The critical lemma is $x : A+B \vdash -:F(x,x)$, which we need to
use path induction.

\[ \mathtt{case}[z.F(z,z)](x; m:A. refl(m) ; n:B. refl(n) ) : F(x,x)
\]

where $[inl(m)/z]F(z,z) \equiv F(inl(n),inl(n))$.
**** Lecture 13: Path structure of Types
***** Last week
We characterized paths in coproducts.

****** Lemma
$x : A +B \vdash -:F(x,x)$

we use induction on $x$

 * $a:A \vdash refl(a) : F(inl(a),inl(a))$
 * $b:B \vdash refl(b) : F(inr(b),inr(b))$

what we want to define a quasiinverse 

\[
f : \prod_{x,x' : A+B} Id_A(x,x') \to F(x,x')
\]

\begin{aligned}
f := \lambda x. \lambda x'. \mathtt{case}(x;\ a:A.\ \mathtt{case}( & \\
& x'; a':A. \lambda p:Id_A(inl(a),inl(a')) . J[F](p; z.F(z,z), \\
& \dots )
\end{aligned}

****** Quasiinverse
Now we have to define

\[
g : \prod_{x,x':A+B} F(x,x') \to Id_{A+B}(x,x')
\]

as

\[
g := \lambda x,x',z:F(x,x')\ \text{cases on }\ x\ x'
\]

and now we want to show

 * $z:F(x,x') \vdash \alpha(z) : f(g(z)) = z$
 * $z:Id_{A+B}(x,x') \vdash \beta(z) : g(f(z)) = z$

***** Positive types
We work with coproducts as examples of positive types. We will
characterize $Id_0(-,-)$ and the path structure of $\mathbb{S}^1$.

\[
Id_{s'}(b,b) = \Omega_b(S') \simeq \mathbb{Z}
\]

We are doing synthetic homotopy theory.

***** Characterizing paths on identity types
Given a type $A$, we consider $Id_{Id_{\dots_A}}(-,-)$. We cannot say much, because
it includes as special cases the spheres $\Omega(S^n)$.

If $f : A \to B$ is an equivalence, then so is $ap_f : a =_A a' \to f(a) = f(a')$.
What we have is $f : A \to B$, so $\alpha : \prod_{a:A}f^{-1}(f(a)) =_A a$ and $\beta : \prod_{b:B}f^{-1}(f(b)) =_B b$.
because it has quasiinverses. To prove this, we define

\[ ap^{-1}_f := \alpha(a)^{-1} \cdot ap_{f^{-1}} \cdot \alpha(a')
\]

now we need

 * $\alpha' : \prod_{p:a =_A a'} ap^{-1}_f(ap_f(p)) =_{a = a'} p$
 * $\beta' : \prod_{q:f(a) =_B f(a')} ap_f(ap_{f}^{-1}(q)) =_{f(a) = f(a')} q$

and both can be proved by path induction.
***** Identity types are homs in an (infinite,1)-category
The type $Id_A(x,y)$ is similar to $Hom_A(x,y)$. $Id_A(-,-)$ is a family
of types, and hence a fibration.

We look at the transport/fibration properties taking
the notation $E(x,y) := Id(x,y)$

  1) fix $x_{0}:A$, consider $\lambda y:A.E(x_0,y)$,

     \[
     tr[y.E(x_0,y)](q) : E(x_0,y) \to E[x_0,y']
     \]

     it maps $p:E(x_0,y) \mapsto p \cdot q$

  2) fix $y_0 : A$, consider $x . E(x,y_0)$,

     \[
     tr[x.E(x,y_0)](p) : E(x,y_0) \to E(x',y_0)
     \]

     mapping $q \mapsto p^{-1}\cdot q$.

  3) for $p : x = x'$, $q : E(x,x)$; $tr[x.E(x,x)](p) : q \mapsto p^{-1} \cdot q \cdot p$.

It can be checked by path induction. This show that they behave like
Hom's and that they exhibit the infinity-groupoid structure.
***** Recall: identity elimination rule
The idea is that, in ITT, this can be thought of as an induction
principle arising from taking the Id to be the least reflexive
relation, because the only introduction rule says so; and the 
elimination works as that.

\begin{prooftree}
\AxiomC{$\Gamma \vdash p:Id_A(M,N)$}
\noLine
\UnaryInfC{$\Gamma,x:A,y:A,z:Id(x,y) \vdash F : {\cal U}$}
\AxiomC{$\Gamma, x:A \vdash q : F(x,x,refl) $}
\BinaryInfC{$\Gamma \vdash J[F](p,x.q) : F(M,N,p)$}
\end{prooftree}

For doing set-level mathematics, this works. In HoTT, we interpret the
identities as paths in $A$, not as inductive types. We conclude things
about non-trivial paths only reasoning about reflexivity!
**** Lecture 14: Identity elimination
***** Last week exercise
If $ - : qinv(f)$, then $-: ap_f$.

 1) $ap_f^{-1} = ap_{f^{-1}}$
 2) $\alpha : \prod_{p : a=_A a'} \dots$
 3) $\beta : \prod_{q : f(a) = (a')} ap_f(\alpha(a)^{-1} \cdot ap_{f^{-1}}(Q) \cdot \alpha(a')) = q$

the (2) is proved by path induction, but (3) is not so easy. If we use
path induction there, we will get $F[f(a),f(a'),q]$ as motive, which should
be then $ap_f(\alpha(a)^{-1} \cdot ap_{f^{-1}}(Q) \cdot \alpha(a')) = q$. Recall that, for coproducts,

 * $F[inl(a),inl(a')] \equiv (a = a')$

but here, we cannot do that, we would need to define it such that
$F[f(a),f(a'),q] =_{{\cal U}} \left(ap_f(\alpha(a)^{-1} \cdot ap_{f^{-1}}(Q) \cdot \alpha(a')) = q\right)$. If $M:A$ and
$p : A =_{{\cal U}} A'$, then $p_{\ast}(M) : A'$. So you use the fact that

 * $f^{-1}(f(a)) =_A a$, and
 * $(f^{-1},\alpha,\beta) : qinv(f)$.
***** Justifying the J operator
The J operator has different meanings in ITT and HoTT

 1. In ITT, J expresses an induction principle on proofs of identity,
    of which there is exactly one.

 2. In HoTT (or ITT + FUNEXT), the situation is less clear,

    \[J[\ ](refl(M), x.Q) \equiv [M/x]Q\]
    
    but then, we have the problem

    \[J[\ ](funext(H); x.Q) \equiv ?
    \]

    where the Gentzen's principle does not hold. How should apply
    $J$ with the Univalence Axiom or to other defined equalities?

    * $J[\ ](UA(E), x.id) \equiv ?$
    * $J[\ ](seg, x.id) \equiv ?$
    * $J[\ ](loop, x.id) \equiv ?$

 3. In ETT, it does not work like this. Equality reflection allows us
    to replace to equalities; we do not need J at all. We get FUNEXT
    without special arrangement. It has a computational interpretation.
    You end using a theory of realizability.

 4. In OTT, we can have FUNEXT without special arrangement. It has a
    computational interpretation.

In HoTT, we give up on computation; but maybe we can recover one. We
justify the theory by interpretation into the classical ZF using
simplicial sets.
***** Solving (partially) the problem
Idea: have $x:A \vdash Q : C[x,x,refl(x)]$ where the motif
$x:A,y:A,z: x=y \vdash C : {\cal U}$. We want to get $- : C[M,N,P]$ 
where $M,M':A,P: M=M'$. This is what the J-rule is saying. 

We know that $[M/x]Q : C[M,M,refl(M)$, and $Q$ depends functorially
on $x$. The logic in HoTT is integrated with the whole structure of
maps. There is a continuous dependency from $Q$ to $A$. So we also
know that $[P/x]Q : [M/x]Q =_p^{C(-,-,refl(-))} [N/x]Q$ (in an abuse of language)
and $ - : p_\ast [M/x]Q =_{C(M',M',refl(M'))} [M'/x]Q$.

Since $refl(M) : M = M and $p : M = M'$, now it suffices to find
$\alpha : refl(M) =^{Id(-,-)}_{(refl(M),p)} p$, wich is to say that

\[
\alpha : \left\langle refl(M),p \right\rangle(refl(M)) = p
\]

the triple $(refl,p,\alpha)$ would take $C(M,M,refl(M))$ into $C(M,M',p)$.

\[ tr[x.Id(x,x)](p)(q) = p^{-1}\cdot q \cdot p\]

it works choosing $refl_{Id_{A}(M,M')}(p)$. $C$ does the work! A priori, $C$ respects
whatever it is that $Id$ internalizes!

***** The identity type
The equality is respected by all the theory, that is why the identity
type has those special properties. In HoTT, $Id$ internalizes homotopy
equivalence, and, by univalence, everything respects homotopy
equivalence. In contrast, in ITT, $Id$ internalizes definitional
equality.

The identity type does not define homotopy equivalence, it only 
internalizes the notion.
***** Homotopy types
The slogan is that Homotopy (Type Theory) is (Homotopy Type) Theory.
# Así que debe traducirse por teoría de tipos homotópicos o
# por teoría de tipos homotópica.

#+begin_definition
A type $A$ is a *set*, aka 0-type, iff for all $p,q : x =_{A} y$, we have
that $p=q$.
#+end_definition

\[ \mathrm{isSet}(A) :=
\prod_{x,y:A}\prod_{p,q: x=y} p = q
\]

it is a discrete groupoid up to higher homotopy. The only paths are
the reflexivities, but up to higher-homotopy! There can be other loops,
but they are homotopic to the reflexivity.

You can form a type theory there every type is a set.
**** Lecture 15: Sets and propositions
***** Last week
We saw a justification for the J-rule and the interaction with
the functioriality of $C$ and the inductive analysis of J.

***** The Interval Type
Formation rule

\begin{prooftree}
\RightLabel{$(I-F)$}
\AxiomC{}
\UnaryInfC{$\Gamma \vdash I : {\cal U}$}
\end{prooftree}

Introduction rules

\begin{prooftree}
\RightLabel{(iI0)}
\AxiomC{}
\UnaryInfC{$\Gamma \vdash  0 : I$}
\RightLabel{(iI1)}
\AxiomC{}
\UnaryInfC{$\Gamma \vdash  1 : I$}
\noLine
\BinaryInfC{}
\end{prooftree}

And another introduction rule

\begin{prooftree}
\RightLabel{(iIseg)}
\AxiomC{}
\UnaryInfC{$\Gamma \vdash seg : Id_I(0,1)$}
\end{prooftree}

This is an inductive definition of the type. The type should be
freely generated by these constructors.

\begin{prooftree}
\AxiomC{$\Gamma, x:I \vdash C[x] : {\cal U}$}
\AxiomC{$\Gamma \vdash M_0 : C[0]$}
\noLine
\UnaryInfC{$\Gamma \vdash M_1 : C[1]$}
\AxiomC{$\Gamma \vdash p : M_0 =_{seg}^{x:C} M_1$}
\TrinaryInfC{$\Gamma, x:I \vdash \mathrm{rec}_I[x.C](x;M_0,M_1 )  : C[x]$}
\end{prooftree}

where it is defined as

 * $rec[x.C](0;M_0,M_1, -) \equiv M_0 : C[0]$
 * $rec[x.C](1;M_0,M_1, -) \equiv M_1 : C[1]$
 * $dap(\lambda x . rec[x.C](0;M_0,M_1,p)) \equiv p : M_0 =^{x:C}_{seg} M_1$

the $dap$ map should be functorial

\[ dap : \prod_f \prod_{x:A}B \longrightarrow \prod_{p:Id(x,y)} Id(fx,fy)
\]

***** The total path space of a type
The total path space are the morphisms from the interval

\[
\sum_{x:A}\sum_{y:A} Id(x,y) \simeq (I \to A)
\]

****** Proof
The rec function goes from left to right

$\lambda x,y,p. \lambda t. rec[-:A](t;x,y,p)$

And the description of the path goes the other way

\[ \lambda h. (h(0),h(1), ap(seg)).
\]

***** Conclusion on the total path space
A path between functions is an homotopy, a path between
every pair of points

\begin{align*}
\int Id_{A \to B} &
\simeq I \to (A \to B) \\&
\simeq (I \times A) \to B \\&
\simeq (A \times I) \to B \\&
\simeq A \to (I \to B) \\&
\simeq A \to \int Id_{B}
\end{align*}

Function extensionality says that

\[
Id(f,g) \simeq \prod_{x:A}Id_{A \to B}(fx,gx)
\]

which can be proved by definition and taking the right-to-left
direction as an axiom.
***** Sets
A type is a set if it is homotopically discrete.

\[
\mathrm{isSet}(A) \equiv \prod_{x,y:A}\prod_{p,q : x=y} p=q
\]

up to higher homotopy, the only equality is reflexivity.
Pure ITT is a theory of sets. All of the constructs of ITT
preserve the property of being a set

 1) $1$ is a set.
 2) if $A,B$ are sets, $A \times B$ is a set.
 3) if $A,B[x:A]$ are sets, $\sum_{x:A} B$ is a set.
 4) if $A,B$ are sets, $A+B$ is a set.
 5) $Nat$ is a set.
 6) if $A,B$ are sets, $A \to B$ is a set.
 7) if $A,B[x:A]$ are sets, $\prod_{x:A} B$ is a set.

In the NPS book, they use the terminology =Sets=.
***** Problems interpreting ITT as a theory of sets
Why are the identities sets? Why is the universe a set?

ETT is also a set theory, and it is easier to work with it. In
ITT, we have to pay the price of higher dimensionality without
using it.

***** Is universe a set?
Are the elements of ${\cal U}$ codes (names of types) or types? We can
introduce the elements of ${\cal U}$ inductively. The codes will form a
set.

NuPRL and HoTT take the elements to be types; but NPS take the
elements to be codes and to form a set, using ITT as a set theory.
**** Lecture 16: ITT
All of the basic constructs of ITT preserve the relation of being a Set.
Up to higher homotopy, there is at most one proof of equality of any two
elements.

${\cal U}$ is rigged to be a set and it is a set of codes; an inductively defined
set.

***** The identity type is a set
$Id_A(x,y)$ is a set if $A$ is a set

****** Proof
Assume that $A$ is a set

\[
H : \prod_{x,y:A}\prod_{p,q:Id_A(x,y)}Id_{Id_A(x,y)}(p,q)
\]

and we want to show that $Id(x,y)$ is a set. Assume $u,v : A$,
$r,s:Id(u,v)$ and $\alpha,\beta : Id(r,s)$. We have to show that

\[
Id_{Id_{Id_A(u,v)}(r,s)}(\alpha,\beta)
\]

We specialize $H' := H(u)(v)(r) : \prod_{q:Id_A(u,v)} Id(r,q)$; and we are going
to exploit the functoriality of $H'$. So

\[ apd_{H'} : \prod_{q,q': Id_A(u,v)} \prod_{\gamma : Id(q,q')} Id(\gamma_{\ast}(H'(q)),H'(q')
\]

being a path-over scenario. Here,

\[
apd_{H'}(r,s,\alpha) : Id(\alpha_{\ast}(H'(r)), H'(s))
\]

and, similarly

\[
apd_{H'}(r,s,\beta) : Id(\beta_{\ast}(H'(r)), H'(s)).
\]

So, we can conclude that I can get an element of the identity
$Id(\alpha_{\ast}(H'(r)), \beta_{\ast}(H'(r)))$. What this is telling us is that, by
post-composition given by transport in the identity, $Id(H'(r)\alpha, H'(r)\beta)$.

We have that $H'(r)\cdot \alpha = H'(r)\cdot \beta$, so I can multiply by the inverses
to get

\[
H'(r)^{-1}H'(r)\alpha = H'(r)^{-1}H'(r)\beta
\]

and then $\alpha = \beta$. We have used here the groupoid structure.
***** ETT
ETT is also a set theory because ITT is a set theory. ETT is easier to
use when working with sets than ITT. HoTT adds the univalence axiom
and Higher Inductive Types. Here, homotopy can be thought as a branch
of logic. 

***** ITT+UA
But ITT+UA is *not* a set theory; not all types are sets! In particular,
${\cal U}$ is a proper groupoid; there are non-trivial paths between elements.

For example, we will show two non-related paths between $1+1=2$ and
$2 = 1+1$. We know that

\[ UA: (A = B) \simeq (A \simeq B)
\]

and we are going to use it to create two different paths.

 * $ud(id)$
 * $ud(not)$

and $id \neq not : 2 \to 2$ by function extensionality; they are two different
equivalences. We also have $refl(tt) : tt =_2 tt$; and by transport if the
two paths were the same up to higher homotopy, $tr('') : ff = tt$, which is 
falsable.

***** H-props
Start with $n \geq -2$. 

#+begin_definition
A type $A$ is an *h-prop* or prop iff

\[ \mathrm{IsProp(A)} :\equiv
\prod_{x,y:A} Id(x,y)
\]
#+end_definition

It is a subsingleton and it has at most one element up to higher
homotopy. The problem with this naming is that this collides with
the idea that propositions are types! It is better to call them
*h-props* instead of *props*.

The truth of these propositions is proof-irrelevant for types that
are called h-props.

****** Example: NuPRL and Markov's principle
In NuPRL, the types were specifications, and proofs where programs.
If we want to look for a zero on a sequence

\[s : \left( \sum_{t:Nat\to Nat}\sum_{i:Nat} t(i) = 0 \right)
\to 
\left(\sum_{i : [0..|s|-1]} s(i) = 0\right)
\]

but here there is a solution in constant time! The $i$ is part of the
specification, we provided too much information on the input. The
problem here is proof-relevance. How could we suppress this information
in a type?

The first idea is an observation by *Brower*: we can change the specification
to use double negation

\[s : \left(\neg\neg \sum_{t:Nat\to Nat}\sum_{i:Nat} t(i) = 0 \right)
\to 
\left(\sum_{i : [0..|s|-1]} s(i) = 0\right)
\]

but now, should a while terminate? *Markov's principle* says that, if you
can prove that a machine can't fail to halt, then it must halt. This is a
very contentfull statement in a constructivist setting. This is a very
strong axiom, the characteristic of the Russian school of constructivism.
(Markov, Kolmogorov).

****** Double negation and computational content
In NuPRL, we do not have Markov's principle. We would change $Nat \to Nat$ to
$FinSeq(k)$ in order to have a bound. Double negation kill computational,
proof relevant content.

#+begin_proposition
For any $A$, $\mathrm{IsProp}(\neg \neg A)$.
#+end_proposition

It has a simple proof.

****** Gödel's double negation translation
The idea of Gödel was to embed classical into constructive logic.
Here, classical logic is just a particular case of constructive
logic. This is called /squashing/

 * $\|1\| = 1$
 * $\|A \wedge B\| = \|A\| \wedge \|B\|$
 * $\|0\| = 0$
 * $\|A \vee B\| = \neg\neg(\|A\| \vee \|B\|)$

For implication, we have to choices

 * if we only want to just squash, $\|A \supset B\| = \|A\|\supset \|B\|$, suffices.
 * but if we want to recover classical logic, $\|A\| \supset (\neg\neg \|B\|)$.

Classical logic is constructive + double negation elimination; the
notion of $\neg\neg A \supset A$.

 * with the first option, $\|\neg\neg A \supset A\| = \neg\neg A \supset A$.
 * with the second one, $\|\neg\neg A \supset A\| = \neg\neg A \supset \neg\neg A$, which is true!

This is called the CTS transform for compilers. Where $\neg A$ is interpreted
as a countinuation for compilers. This is the type of a continuation

\[
(\|A\| \times (\|B\| \to 0)) \to 0
\]

With this technique, classical logic can be recovered from the constructivistic
logic.

***** Propositional truncation
We will abstract the idea of squasing into truncation; the idea is
to quotient by the full relation. You take a type and a relation where
you quotient by all the relationships. The notion of subsingleton is
also useful to do proof-irrelevance.

The idea of a subquotient does not work well with set theories. In
HoTT we will use the idea of a quotient.

***** Hedberg's theorem
A type with decidable equality is a set.

If $\prod_{x,y:A} Id(x,y) \vee \neg Id(x,y)$, then $isSet(A)$.

****** Corollary
Classical logic destroy the higher-homotopy structure! If you
postulate excluded-middle, everything is now gone.

****** Proof
 1) Decidable equality implies stable equality.

    \[
   \neg \neg Id(x,y) \to Id(x,y)
   \]

 2) Stability implies sethood.
**** Lecture 17: Hedbergs theorem, truncation
***** Last week
A type is a set if any two proofs of equality are equal. In other
words, if the equality is a proposition. A proposition is a type such
that any two elements of it are equal.

***** The negations are propositions
The negation of any type is a proposition.

****** Proof
If $x,y : A \to \bot$, then $x = y$, as we have function extensionality;
and given any $a : A$, we could use ex falso quodlibet, $\mathtt{abort}(xa) : xa = ya$.
# Check this line on agda with hott

***** Hedberg's theorem
A type with decidable equality is a set. Decidable equality
can be written as

\[
\prod_{x,y : A} Id(x,y) \vee \neg Id(x,y)
\]

and a type is a set if

\[
\prod_{x,y: A} \prod_{p,q : x=y} p = q.
\]

****** Proof 1: Decidable equality implies Stable equality
Stable equality, by definition, is

\[
\prod_{x,y : A} \neg \neg Id(x,y) \to Id(x,y).
\]

In general, what we know is that if $A \vee \neg A$, then $\neg\neg A \to A$. This
is only an instance of that.

****** Proof 2: Stable equality implies Sethood
Suppose that the equality on $A$ is stable, $h :\prod_{x,y: A} \neg \neg (x = y) \to (x = y)$.
It suffices to show that every $p : x = x$ is $p = \mathtt{refl}$. We can apply the
path to get, by transport

\[
p_{\ast}(h(x)(x)) =_{\neg\neg x = x \to x = x} h(x)(x)
\]

so we know that, for any $r: \neg\neg (x = x)$, we know that

\[
p_{\ast}(h(x)(x)) (r) =_{x = x} h(x)(x)(r).
\]

And Lemma 2.9.6 from HoTT book is a technical result, saying that

\[
h(x)(x)(r)(p) = h(x)(x)(p_\ast r)= p_{\ast}(h(x)(x)) (r) =_{x = x} h(x)(x)(r) = h(x)(x)(r),
\]

where we use that negated types are propositions.

****** Example: N is a set
By double induction, we can show the decidability of equality on this
type.
***** Every proposition is a set
In general, we will get that any n-type is a n+1-type. If
$\prod_{x,y : A} x = y$, then $\prod_{x,y:A}\prod_{p,q:x=y} p = q$. Suppose a function given
with $f : \prod_{x,y:A} x = y$; then we can fix $x_0:A$ and let $g(y) \equiv f(x_0)(y)$.

By functioriality, if we have $p : y = y'$, then $apd(p) : p_{\ast}(g(y)) = g(y')$.
And if $q : y = y'$ and $q = g(y^{-1})g(y')$, so $p = q$.

***** The statement of anything being a proposition or a set is a proposition

 * $isProp(isProp(A))$
 * $isProp(isSet(A))$

In the book, there is a chapter on when is a proposition an equivalence of
two types. $isProp(isEquiv(A)(B))$? In the case of the definition by quasiinverses,
it is not a proposition. A function can has many quasiinverses.

****** First proof
Given $f,g : isProp(A)$, we will show that they are equal. It suffices to show that
$x,y:A \vdash - : f(x)(y) =_{x=y} g(x)(y)$. Since $isProp(A)$ implies $isSet(A)$, the desired
equation holds.

****** Second proof
We can use a similar argument.
***** Propositional truncation, aka "squashing"
When we worked in the Godel double negation translation,

\[
\|A \to B\| = \|A\| \to \neg\neg \|B\|
\]

A more abstract notion of truncation is do the squashing and not to
worry about recovering classical logic. What you do is to introduce
the type $\|A\|_{-1}$ of a truncation of $A$. It has the introduction form

\begin{prooftree}
\RightLabel{($\|\cdot\|$-I)}
\AxiomC{$M:A$}
\UnaryInfC{$|M| : \|A\|$}
\end{prooftree}

and the rule that any two elements are going to be the same up to higher
homotopies

\begin{prooftree}
\AxiomC{$M:A$}
\AxiomC{$N:A$}
\BinaryInfC{$- : Id_{\|A\|}(|M|,|N|)$}
\end{prooftree}

This is the quotient of $A$ by the full relation. The elimination form has
to be, then

\begin{prooftree}
\RightLabel{$\|\cdot\|$ - E}
\AxiomC{$M : \|A\|$}
\AxiomC{$x : A \vdash N : B$}
\AxiomC{$p : isProp(B)$}
\TrinaryInfC{$\mathtt{trunc}(M, x.N, p):B$}
\end{prooftree}

the requirement of $B$ to be a proposition, ensures that N's behaviour is
independent of the choice of representative of the suplied equivalence
class. We could relax the condition to a weaker one requiring only this.
***** Contractibility
A type is contractible if it has an element and every other element is
equal to it

\[
isContr(A) = \sum_{x:A}\prod_{y:A} x=y
\]

****** Lemma

\[
isProp(A) \iff
\prod_{x,y:A} isContr(x=y)
\]

***** n-types
Something is a -2type iff it is contractible. And something is an
n+1-type iff for all $x,y$, $x=y$ is a n-type.

 * A proposition is a -1 type
 * A set is a 0 type
 * A groupoid is a type
 * A 2-groupoid is a 2-type
 * and so on

Any n-type is also an n+1-type. It is a *cumulative hierarchy*.

***** Not any type is an n-type
Not any type is an n-type for some n! There are types with a higher structure
up to infinity.

**** Lecture 18: Homotopy n-types, contractability
***** Last week
We defined contractability using centers of contraction.
It expresses the idea of unique existence $\exists!$. It is sometimes
written as $\Sigma!$.

Something is contractible if it is a proposition and it has
one element.

***** Fact of contractability
If you fix any point $a : A$; you can consider the neighborhood of $A$
and we can consider the star of $A$ and that is contractible.
We can prove that

\[
isContr\left(\sum_{x:A} a = x\right)
\]

given $a : A$.
***** The special case of the propositional truncation
We are going to call propositional truncation as -1-truncation.
We can write it as $\|A\|_{-1}$. It will be useful to define other
truncations. The idea is to have

\[
isProp(\|A\|)
\]

for any $A : {\cal U}$. That is to say that the equality type of this type
is contractible as

\[
\prod_{x,y:\|A\|} isContr(x = y).
\]

The intuition is that

\begin{prooftree}
\AxiomC{$\Gamma \vdash M : A$}
\UnaryInfC{$\Gamma \vdash |M| : \|A\| $}
\end{prooftree}

and in the elimination rule, we should prevent proofs for depending on
the witness of the inhabitation.

\begin{prooftree}
\AxiomC{}
\UnaryInfC{$\Gamma, x : \|A\|, y: \|A\| \vdash \mathtt{squash}(x,y) : x = y$}
\end{prooftree}

The eliminator was defined as

\begin{prooftree}
\AxiomC{$\Gamma \vdash M : \|A\|$}
\AxiomC{$\Gamma, x : A\vdash N : B$}
\AxiomC{$\Gamma \vdash p : isProp(B)$}
\TrinaryInfC{$\Gamma \vdash elim[B](M,x.N,p) : B$}
\end{prooftree}

by using that $B$ was a proposition, we were sure that the result did not
depend on the representative of $A$.

***** Gentzen and squash
Squash is another case of a new primitive equality. By Gentzen's principle,
we would need a beta and an eta rule

 * $elim[B](|M|; x.N, p) \equiv [M/x]N : B$

we would like to have a rule such as

 * $ap(\lambda z. elim[B](z;x.N,p))(squash(|M|,|N|)) \equiv (|M| =|N|)$

this is problematic. (?) If you are using a $J$ and the argument is a
squash, what should that be definitionally equal to?
***** Revisit the axiom of choice
The Axiom of Choice $AC_{\infty}$ has a formulation as

\[
\prod_{A : {\cal U}}
\prod_{B : A \to {\cal U}}
\prod_{C : \prod_{x:A} B \to {\cal U}}
\left(
\prod_{x:A}\sum_{y:B_x} C(x,y)
\overset{\simeq}\longrightarrow
\sum_{f : \prod_{x:A} B} \prod_{x:A} C(x,f(x))
\right)
\]

and we can check in fact that this is a definable *equivalence*. It is
not an axiom! it is a theorem. The theorem of choice. We use crucially
the proof relevance to prove it.

****** Proof
From left to right

\[
\lambda F. \left(
 \lambda x. \mathtt{fst}(F x),
 \lambda x. \mathtt{snd}(F x)
\right)
\]

and from right to left

\[
\lambda \left\langle f,g\right\rangle . \lambda x .(f x, gx)
\]

and those are mutually inverses. We will need eta rules for products and
eta rules for sums.
****** It is a theorem
It is not saying exactly what the axixom of choice says usually.
***** Versions of the axiom of choice
If we use propositional truncations we get the actual axiom of choice,
that we will call $AC_{-1}$.

\begin{aligned}
AC_{-1} : 
  \prod_{A :{\cal U}} isSet(A) \to 
  \prod_{B : A \to {\cal U}} \prod_{x : A} isSet(B(x)) \to
  \prod_{C : \prod_{x:A} B \to {\cal U}} \prod_{x:A} \prod_{y:B} isProp(C(x,y)) \to \\
  \left(
    \left( \prod_{x:A} \| \sum_{y:B} C(x,y) \| \right) \to
    \left\| \sum_{f : \prod_{x:A} B} \prod_{x:A} C(x,f(x)) \right\|
  \right)
\end{aligned}

And this is *not* a theorem. We are using truncation and this is expressing the idea
that there is no functional dependency but we can, nevertheless, build a function.

****** NuPRL
Using squashing, we can express this also on the NuPRL system.
****** Expressivity
The constructive setting is more expressive than the classical one. We can choose,
by introducing identifications, to work on the classical setting.
****** Restatement
If we use the equivalence from before, we can write that

\[
\left\| \sum_{f : \prod_{x:A} B} \prod_{x:A} C(x,f(x)) \right\| \simeq
\left\| \prod_{x:A}\sum_{y:B} C(x,y)  \right\|
\]

and that means that we can restate the axiom of choice using

\[
    \left( \prod_{x:A} \left\| \sum_{y:B} C(x,y) \right\| \right) \to
    \left\| \prod_{x : A} \sum_{y:B} C(x,y) \right\|
\]

instead. And we can reduce this to a simpler form as

\[
\prod_{x:X}\|Y(x)\| \to
\left\| \prod_{x:A} Y(x)  \right\|
\]

which can be read as "the product of a family of inhabited sets
is an inhabited set". This is also an equivalence.

This version of the axiom of choice is false if $X$ is not constrained
to be a set.
***** Quasiinverses
Recall that a quasiinverse was

\[ \mathtt{qinv}( f : A \to B) :\equiv
  \sum_{g : B\to A} f \circ g \sim id \times g \circ f \sim id
\]

in the presence of function extensionality, we can replace $\sim$ with
$=$. We will show that $qinv$ is not necessarily a -1-type (a proposition).

****** Characterization of quasiinverses
If $f : A \to B$ and $e : qinv(f)$ then 

\[
qinv(f) \simeq \prod_{x:A} x = x
\]

sometimes we write $x =_{A} x \equiv \Omega(A,x)$. This uses univalence.

****** Existence of a not-proposition
There is a type $X$ such that

\[
\prod_{x : X} x=_Xx
\]

is not a proposition. An example of this is $X = \pi(\mathbb{S}) \simeq \mathbb{Z}$, which
will be a set. Another one is $X = K(G,1)$, a space with its fundamental
group being $G$.

As a corollary, $qinv(f)$ need not be a proposition.

***** A good definition of equivalence
The criterion is that it should be a proposition, so the quasiinverses
definition does not qualify. We create new definitions

 * $isContr(f)$
 * $isBiequiv(f)$, we have a left inverse and a right inverse.
 * $isHalfAdjoint(f)$, defined by quasiinverses plus a coherence condition.

all these definitions are equivalent. And these are all propositions.

***** Contractability definition of equivalence
For $f : A \to B$,

\[
isContr(f) :\equiv
\prod_{y:B} isContr(fibers_f(y))
\]

where

\[
fibers_f(y) \equiv \sum_{x:A} f(x) = y
\]

the things that are sent by $f$ to $y$. The total "sum of fibers" is
the total $A$.

****** Voevodsky's definition of equivalence
The definition can be stated as that exists a unique

\[
\prod_{y:B}\sum_{z: fib_f(y)} \prod_{z' : fib_f(y)} z = z'
\]

so the function is a bijection up to homotopy.
**** Lecture 19: Inductive types I
***** Last week
We suppose that we had a quasiinverse for $f$ given by an inverse,
and two proofs of the inverse, $\left\langle g_0,\alpha_0,\beta_0 \right\rangle$. The claim was that

\[
qinv(f) \simeq \prod_{x:A} x = x
\]

in the presence of FUNEXT, this is equivalent to the fact that
$id = id$. The type of quasiinverses is

\[
\sum_{g : B \to A}\sum_{\alpha : g \circ f = id} \sum_{\beta : f \circ g = id} 1
\]

and a similar type is contractible

\[
\sum_{g : B \to A} \sum_{\beta : f \circ g = id} 1
\]

with center $(g_0,\beta_0)$. This says that $f$ has exactly one right inverse.
If we consider $(g_1,b_1) : \sum_{g : B \to A}\sum_{\beta : f \circ g = id} 1$, we have to show that
$p : g_1 = g_0$ and then, by transport $- : \beta_0 = \beta_1$.
***** Biinverse
If we use the definition of biinverses

\[
binv(f) :\equiv
\left(\sum_{r : B \to A} f \circ r = id\right) \times
\left( \sum_{l:B \to A} l \circ f = id \right)
\]

as both factors are contractible, the type is contractible. This
definition is related to the half-adjoint definition. $f$ is
bijective up to homotopy if this holds.

It is reasonable to speak of $biinv(f)$ true as it were a proposition.
***** Inductive types (the nat case)
Reconsider Nat in simple types. We had introductory rules

\begin{prooftree}
\AxiomC{}
\UnaryInfC{$\Gamma \vdash 0 : Nat$}
\AxiomC{$\Gamma \vdash M : Nat$}
\UnaryInfC{$\Gamma \vdash succ(M) : Nat$}
\noLine
\BinaryInfC{}
\end{prooftree}

elimination rules

\begin{prooftree}
\AxiomC{$\Gamma \vdash M : Nat$}
\AxiomC{$\Gamma \vdash M_{0} : A$}
\AxiomC{$\Gamma, x:A \vdash M_1 : A$}
\TrinaryInfC{$\Gamma \vdash rec[A](M,M_0,x.M_1) : A$}
\end{prooftree}

with beta-like rules (inversion principle), which can be
expressed as a commutative diagram

 * $rec[A](0,M_0; x.M_1) \equiv M_0$
 * $rec[A](succ(M);M_0,x.M_1) \equiv [rec[A](M,M_0,x.M_1)/x]M_0 : A$
 
and an eta-like rule (unicity principle), which is the
unicity of the diagram

\begin{prooftree}
\AxiomC{$[0/x]N \equiv M_{0}$}
\AxiomC{$z : Nat \vdash [succ(z)/x]N \equiv [[z/x]N/x]M_{1}:A$}
\BinaryInfC{$\Gamma, x:Nat \vdash N \equiv rec[A](x,M_0,x.M_1)$}
\end{prooftree}
***** Local definition
We could write the introductions as

 * $\vdash 0 : Nat$
 * $x : Nat \vdash succ(x) : Nat$

and the global version works on a suitable theory. We could write
them even as

 * $0 : 1 \to Nat$
 * $succ : Nat \to Nat$

and in a suitable theory, we can derive the rules from the constants.
Note that those two notations are NOT the same thing!

We could write also the induction as an element of a function type

\begin{prooftree}
\AxiomC{$\Gamma \vdash M_{0} : A$}
\AxiomC{$\Gamma, x:A \vdash M_1 : A$}
\BinaryInfC{$\Gamma, z:Nat \vdash rec[A](M_0, x.M_1)(z) : A$}
\end{prooftree}
***** Nat-algebras
We can write this as a single function

\[
z : 1 + Nat \vdash case\{-.0 ; x.succ(x)\}(z) : Nat
\]

we can write this as

\[
z : 1 + Nat \vdash \{0,succ\}(z) : Nat
\]

This notation uses eta/beta properties of coproducts and
products to get its etea/beta properties. Any mapping
$\alpha : 1 + Nat \to Nat$ is called a *Nat-algebra*. More generally,
a Nat-algebra is $\alpha : 1 + A \to A$. 

A *Nat-algebra category* is defined by the idea that if we have
two Nat-algebras, we can define a mapping between them as

\[\begin{tikzcd}
1+A\dar{\alpha}\rar{1+h} & 1+B\dar{\beta} \\
A\rar{h} & B
\end{tikzcd}\]

and we call this a Nat-homomorphism. The previous definition of the
naturals is in fact the initial object in the category on
nat-homomorphisms. This is an initial algebra, there is a unique
morphism from this algebra to all the others; and this morphism is
precisely the recursor. Any other morphism is unique up to higher
homotopy to the other morphism (eta-rule).

There are implicit uses of the Yoneda Lemma here.
***** F-algebra
Given a functor $F$ on some category, we are going to define a
F-algebra. The particular case of Nat is $F(X) = 1 + X$.

\[\begin{tikzcd}
F(A)\dar{\alpha}\rar{F(h)} & F(B)\dar{\beta} \\
A\rar{h} & B
\end{tikzcd}\]

***** F-coalgebra
We can define coalgebras and study the final objects on coalgebra
categories. The unique function to a final coalgebra is a corecursor.

****** Exercise
What is the final coalgebra for Nat? $F(X) = 1+X$.

***** Lambek's lemma
If $i : F(I) \to I$ is an initial F-algebra, then $i$ is an
isomorphism; and then, $F(I) \cong I$.

This is called a *fixed point*.

****** Proof
If we have an algebra, we also have $FI$ as an algebra

\[\begin{tikzcd}
FI  \rar[dashed]{F!}\dar{i} & FFI \dar{Fi} \\
I  \rar[dashed]{!} & FI
\end{tikzcd}\]

we use that the first one is initial. And we also have

\[\begin{tikzcd}
FI \rar{i}\dar[dashed]{F!}\ar[dd,bend right,swap,"Id"] & 
I \dar[dashed]{!}\ar[dd,bend left,"Id"] \\
FFI  \rar{Fi}\dar{Fi} & FI \dar{i} \\
FI  \rar{i} & FI
\end{tikzcd}\]

so we know that $i \circ ! = id$ and $!\circ i = F(i \circ !) = id$.
****** CoLambek
If we have a final coalgebra it is also an isomorphism.
**** Lecture 20: Inductive types II
***** Last week
We reexamined Nat as an inductive type. We claim that $1+Nat \to Nat$
is initial in the category of Nat-algebras. Any other Nat-algebra can
be written as $\alpha = \left\langle \alpha_0,\alpha_{1} \right\rangle$; and the function from the initial algebra
is simply the recursor $rec[A](\alpha_0,x.\alpha_1)$.

***** Nats Inside type theory
A Nat-algebra would be

\[
NatAlg :\equiv
  \sum_{A : {\cal U}} 1+A \to A \simeq
  \sum_{A : {\cal U}} A \times (A \to A)
\]

and a Nat-homomorphism is

\[
NatHom(\alpha,\beta) :\equiv
  \sum_{h : A \to B} \beta \circ (1+h) = h \circ \alpha
\]

then $\nu :\equiv \left\langle Nat, \{0,succ\} \right\rangle$ is a Nat-algebra an we can prove that this is
in fact initial, which is to say that

\[
NatHom(\nu,\alpha) \text{ is contractible}
\]

Two terminologically different traditions collide here, so we are using
them both.
***** Derivation of mathematical induction
The recursor for the naturals is

\begin{prooftree}
\AxiomC{$M_{0}:A$}
\AxiomC{$x.A \vdash M_1:A$}
\BinaryInfC{$x:Nat \vdash rec[A](M_0;x.M_1) : A$}
\end{prooftree}

with its beta and eta rules. In HoTT, we take the eta rules
to be not definitional equalities $\equiv$ but propositional equalities $=$.

***** The principle of induction
The induction principle says that, given,

 * $x : Nat \vdash P(x) : {\cal U}$
 * $M_0 : P(0)$
 * $x:Nat, y:P(x) \vdash M_1 : P(succ(x))$

we have

 * $z:Nat \vdash ind[x.P](M_0,x.y.M_1)(z) : P(z)$

and the beta and eta rules are similar to those of the recursor.
But, with respect to what equality?
***** Idea
Consider $\int P :\equiv \sum_{x:Nat} P(x)$, we define an auxiliary function

 * $i :\equiv \lambda z:Nat.\  rec[\int P](\left\langle 0,M_0 \right\rangle; \left\langle x,y \right\rangle.\left\langle succ(x), M_1 \right\rangle)(z)$
 * $i0 \equiv \left\langle 0,M_0 \right\rangle$
 * $i(succ(M)) \equiv \left\langle succ(fst(M)), [snd(iM)/y]M_1 \right\rangle$

****** Kleene discovered how to define the predecessor

***** Lambek inside type theory
We can define functors up to higher homotopy. When we apply Lambek, we
get a fixed point $FI \cong I$ up to isomorphism.

****** Not functors
There are cases where, if we define things like $F X =X \to X$, we get a 
*non-algebraic* datatype. There is a way of solving this equations using
fixpoint induction.

****** Nat+
We could define a final coalgebra as

\[
Nat^+ \to 1 + Nat^{+}
\]

and we could think of this loosely as $Nat \cup \{\infty\}$.
 
***** Positive and negative types
Positive types correspond to inductive types and negative types
correspond to coinductive types. Negative types are limits, and
positive types are colimits.
***** Brower ordinals (aka W types)
Well-founded trees or preorders. The ordinals codify what transfinite
induction is.

****** Brower ordinals
Nodes labeled as

 - $0$                   z

 - $1 = sup(0)$          s -> z

 - $2 = sup(1)$          s -> s -> z

 - ...

 - $\omega = sup(0,1\dots)$     w -> z
                         \-> s -> z
                          \-> s -> s -> z
                           \-> ...

****** Well-founded
There is no infinite descendent branches, there may be as many width
branches as we want.

The right definition is that "The principle of transfinite induction is
valid". Is something holds for all predecessors.

***** Formation rule for W-types
Given a type of node sorts, $A$, 

\begin{prooftree}
\AxiomC{$A:{\cal U}$}
\AxiomC{$x:A \vdash B:{\cal U}$}
\BinaryInfC{$W_{x:A}B : {\cal U}$}
\end{prooftree}

given $x:A \vdash B(x)$ is the branching factor; the index type for
the predecessors. 

****** Example
As an example, $A :\equiv 1+1 = [Z,S]$ is an enumeration type, and
you define $B$ by case analysis.

 * $B(Z) :\equiv \bot : {\cal U}$
 * $B(S) :\equiv 1 : {\cal U}$

and $Nat$ will be $W_{x:A}B$.

***** Introduction rule for W-types

\begin{prooftree}
\AxiomC{$a:A$}
\AxiomC{$x:B(a) \vdash w(x) : W_{x:A}$}
\BinaryInfC{$sup[a](x.w) : W_{x:A}B$}
\end{prooftree}

****** Example

 * $0 :\equiv sup[z](x.abort(x))$
 * $1 :\equiv sup[s](-.0)$

***** Elimination rule, non-dependent form

\begin{prooftree}
\AxiomC{$\Gamma,\ a:A,\ p:B(a) \to W_{x:A}B,\ r:B(a) \to C \vdash M:C$}
\UnaryInfC{$z: W_{x:A}B \vdash  wrec[c](  a,p,r.M     )(z)      :C$}
\end{prooftree}

and we are going to have a beta rule

 * $wrec[c]( a,p,r.M )(sup[a](w)) \equiv [a,w,\lambda z. wrec[c](a,p,r.M) /a,p,r] M$

and the eta rule says that it is the only such thing.

****** Polynomial functors
The W types determine polynomial functors over certain classes.

\[
F(x) :\equiv \sum_{a:A}B(a) \to X
\]

in the case of naturals, it is $(1\to X)\times (X\to X)$.

***** Transfinite induction - dependent elimination rule

\begin{prooftree}
\AxiomC{$\Gamma,z: W_{x:A} B \vdash P:{\cal U}$}
\noLine\UnaryInfC{$\Gamma,a:A, p:B(a) \to W_{x:A}B, h:\prod_{b:B(a)}P(p(b)) \vdash M : P(sup[a](p))$}
\UnaryInfC{$\Gamma,z:W_{x:A}B \vdash wind[x.P](  ): P(z)$}
\end{prooftree}

***** Exercise: Invent the M type, dual to the W type
**** Lecture 21: Higher inductive types I
***** Last week: lower inductive types
Well-founded trees $W_{x:A} B$ with an elimination rule based on
transfinite induction. It can be characterized as the homotopy
initial algebras for polynomial functors.

The universal property is here propositional.

***** Higher inductive types
The idea is to take some type of free structure using inductive
definitions with equational laws. It is a similar idea to the
presentation of algebraic structures using generatos and relations.
This will be a 0-type concept; but higher inductive types must be
more general than that.

They are relevant because of

 1. full higher-dimensional structure or path structure.
 2. proof-relevance means generators and relations are the same thing.

Informally, we are building the free infinity groupoid on the structure
we are building.

***** Current status of HoTT
HoTT is ITT + UA + HIT. The Univalence Axiom is a matter of mathematical
efficiency; and the HIT is a matter of expressiveness on higher types.

HITs are not yet fully worked out.
***** Example: interval
We can write the interval using inductive definitions

 * $0 : I$, a 0-cell.
 * $1 : I$, a 0 cell.
 * $seg : Id_I(0,1)$, a 1-cell.

This definition implies the existence of other paths. For example,
$seg^{-1} : Id(1,0)$ or $refl(0) : Id(0,0)$. Moreover, they are significant
and they induce even higher paths.

It is an open problem what is implied for a given inductive
definition.

***** Recursor
An inductive definition induces a recursor; a function from an
initial object on a given category.

In the example, given any "interval algebra", we have a function
from the interval to it

\begin{prooftree}
\AxiomC{$a:A$}
\AxiomC{$b:B$}
\AxiomC{$\beta : a=_Ab$}
\TrinaryInfC{$z:I \vdash rec[A](a,b,\beta)(z):A$}
\end{prooftree}

the Gentzen's inversion principle holds as

 * $rec[A](a,b,\beta)(0) \equiv a : A$
 * $rec[A](a,b,\beta)(1) \equiv b : A$
 * $ap_{rec[A](a,b,\beta)}(seg) = \beta : a =_{A} b$

we could think of the first two cases as an $ap$ on 0-types. Note that
the third case uses a propositional equality; $ap$ is a defined
function! we cannot define what its behaviour should be.
***** Induction
The induction can be written as

\begin{prooftree}
\AxiomC{$z: I \vdash A(z) : {\cal U}$}
\AxiomC{$a_0 : A(0)$}
\noLine\UnaryInfC{$a_1 : A(1)$}
\noLine\UnaryInfC{$p : a_0 =_{seg}^{z.A} a_1$}
\BinaryInfC{$z:I \vdash ind[z.A](a_0,a_1,p) : A(z)$}
\end{prooftree}

where we are using a transportation to have that

\[
trans[z.A](seg)(a_0) =_{A(1)} a_1
\]

And now we expect the following equations to hold

 * $ind[z.A](a_0,a_1,p)(0) \equiv a_0 : A(0)$
 * $ind[z.A](a_0,a_1,p)(1) \equiv a_1 : A(1)$
 * $ap_{ind[z.A](a_0,a_1,p)}(seg) = p$ true.

and there is also a unicity condition
***** Example: circle
The circle $\mathbb{S}^1$ is a type given by the higher inductive definition

 * $base : \mathbb{S}^{1}$, a 0-cell
 * $loop : Id(base,base)$, a 1-cell

This definition induces loops such as $loop \cdot loop : Id(base,base)$ or
$loop^{-1} : Id(base,base)$. Those will form the integers; a set-level
group.

****** Recursor
It is defined as

\begin{prooftree}
\AxiomC{$a_0 : A$}
\AxiomC{$l : a_0 =_A a_0$}
\BinaryInfC{$z : \mathbb{S}^1 \vdash rec[A](a_0,l)(z) : A$}
\end{prooftree}

where

 * $rec[A](a_0,l)(base) \equiv a_0 : A$
 * $ap_{rec[A](a_0,l)}(loop) = l$ true

and we can have the unicity

 * $z : \mathbb{S}^1\vdash P : {\cal U}$
 * $b : P(base)$
 * $l : b =^{z.P}_{loop} b$, so this is preserved going around the loop
***** Recall: the interval
The interval characterizes the total path space of $A$

\[
I \to A \simeq
\int Id_A :\equiv \sum_{x,y:A} Id(x,y)
\]

the identifications are paths. The usual way to do this in Topology is
similar. Here,

\[ \mathbb{S}^{1} \to A \simeq
\int \Omega_A := \sum_{x:A}Id(x,x)
\]

is the loop space.

 1) define $f : (\mathbb{S}^1 \to A) \to \int \Omega_A$ by $\lambda g. \left\langle g(base), ap_g(loop) \right\rangle$.
 2) we show that $\prod_{l : \int \Omega_A} fib(l)$ is contractible

***** Suspension: circle
Another picture of $\mathbb{S}^1$ could use two poles and two
meridians. This is called $Susp(2)$.

 * $N : \mathbb{S}^1$
 * $S :\ \mathbb{S}^1$
 * $mer : 2 \to (N = S)$

and we can check that this is equivalent to the previous
definition.

***** Suspensions
We define $Susp(A)$ as two zero cells

 * $N : Susp(A)$
 * $S : Susp(A)$

and the meridians

 * $mer : A \to (N = S)$

****** Example: susp^2 is the sphere
$Susp^2(2)$ has two meridians associated with N and S and also two
higher-order paths W E associated with the two meridians on
$Susp(2)$.

We will prove that this is the sphere.

***** Suspensions in type theory
We can define the introduction

\begin{prooftree}
\AxiomC{$x:A\vdash m(x) : n =_{B} s$}
\AxiomC{$n:B$}
\noLine\UnaryInfC{$s:B$}
\BinaryInfC{$z:Susp(A) \vdash rec[B](n,s,x.m):B$}
\end{prooftree}

with the beta and eta usual rules.
**** Lecture 22: Higher inductive types II
***** Last week
We defined suspensions

 * $N : Susp(A)$
 * $S : Susp(A)$
 * $merid : \prod_{x:A} N =_{Susp(A)} S$

We defined functorial mappings from the suspension of a type
to another type.

***** Iterated suspension
It can be showed that

$\mathbb{S}^1 \simeq Susp(2)$

by defining an invertible function between them.

***** Pointed types
A point is preserved up to homotopy by mappings

\[
X \multimap Y := \sum_{f:X\to Y} f(x_0) = y_0
\]

***** Characterization of suspensions
Suspensions follow a kind of adjunction with the loop space

\[
(Susp(A) \multimap B) \simeq (A \to \Omega(B))
\]

***** Pushouts
Generally used for amalgamation properties and quotients. In classical
set theory. They are the dual of pullbacks, the constrained subset of
a product.

We glue two sets in a way that a deisgnated subset of the two sets is
regarded as the same; as $A \sqcup^{C} B$, where $C$ is the diagram for the 
considered subset. The coproduct is the special case where $C = \varnothing$.

****** Denotational semantics
In denotational semantics, we want to form the disjoint union of two
types with common elements.

****** In sets
In sets, pushouts do always exist.

***** Pushouts as HIT
We define the inclusions

 * $inl : A \to A \sqcup^C B$
 * $inr : B \to A \sqcup^C B$

and a glue term

 * $glue : \prod_{c:C} inl(f(c)) = inr(g(c))$

****** Universal constructions

\begin{prooftree}
\AxiomC{$x:A \vdash l:D$}
\noLine\UnaryInfC{$y:B \vdash r:D$}
\AxiomC{$u:C \vdash q: [f(u)/x]l = [g(u)/x]r$}
\BinaryInfC{$z: A \sqcup^C B \vdash rec[D](x.l,y.r;u.q) : D$}
\end{prooftree}

with the usual beta/eta rules.

****** Suspension
In particular,

$Susp(A) := 1 \sqcup^{A} 1$
**** Lecture 23: Pushouts
***** Last week
Pushouts as HITs.

***** Quotients as HITs
We can define the expected quotients

 * $a:A \vdash q(a) : A/R$
 * $a,b:A, r:R(a,b) \vdash wd(a,b,r) : q(a) = q(b)$

and a truncation rule

 * $x,y:A/R, p,q:x=y \vdash tr(x,y,p,q):p=q$

so that $A/R$ is a set.

****** Example: Integers as formal differences of naturals

***** Truncations as HITs
The propositional truncation $\|A\|_{-1}$ can be defined as a type
with an induction principle.

****** Induction on integers

***** Fundamental group of S1

\[
\pi_1(\mathbb{S}^1) \simeq \mathbb{Z}
\]

we can show that $\Omega(\mathbb{S}^1,base) \simeq \mathbb{Z}$.

****** Proof
In the proof, we define the winding function from the loop
space to the integers. We then use induction on $\mathbb{Z}$.
**** Exercises
***** Homework 1: Heyting algebra and IPL [5/6]
****** DONE Task 1
#+begin_statement
Show that $A \wedge (B \vee C) \leq (A \wedge B) \vee (A \wedge C)$ in any Heyting algebra.
Hint: use the Yoneda Lemma.
#+end_statement

The Yoneda Lemma in this setting says that the statement is equivalent
to say that, for all $D$, if $(A \wedge B) \vee (A \wedge C) \leq D$, then $A \wedge (B \vee C) \leq D$.
In this case we have

 * $A \wedge B \leq D$
 * $A \wedge C \leq D$

and crucially using the definition of exponential

 * $B \wedge C \leq B,C \leq A \supset D$.

****** DONE Task 2
#+begin_statement
Show that in any Heyting algebra, $A \supset \bot$ is one of the largest elements
inconsistent with $A$, and is equivalent to any largest inconsistent one.
#+end_statement

By definition, $A \wedge (A \supset \bot) \leq \bot$, and for any other element $C$ such that
$A \wedge C \leq \bot$, $C \leq (A \supset \bot)$. Any other largest inconsistent element should
satisfy $(A \supset \bot) \leq C$.

****** DONE Task 3
#+begin_statement
Show that, in any Boolean algebra (complemented distributive lattice),
$\overline{A} \vee B$ is a valid implementation of $A \supset B$. That is, it satisfies all
properties of $A \supset B$.
#+end_statement

We know that

\[
A \wedge (\overline{A}\vee B) \leq 
(A \wedge \overline{A}) \vee (A \wedge B) \leq
(A \wedge B) \leq B
\]

and if $A \wedge C \leq B$, then

\[
C \leq
C \wedge (A \vee \overline{A}) \leq
B \vee (C \wedge \overline{A}) \leq \overline{A} \vee B.
\]
****** TODO Task 4
#+begin_statement
Show that IPL is transitive, which is to say ...
#+end_statement

****** DONE Task 5
#+begin_statement
Show that for any Heyting algebra and any evaluation function on
atoms, if $\Gamma \vdash P$ true then $\Gamma^+\leq P^{\ast}$. You only have to consider the
cases in which the last rule applied is $(\supset I)$ or $(\supset E)$.
#+end_statement

  * In the first case, $(\supset I)$, we know that $\Gamma, A \vdash B$. By induction,
    we know that $\Gamma^{+} \wedge A^{\ast} \leq B^{\ast}$, and then $\Gamma^{ +} \leq (A^{\ast} \supset B^{\ast})$.
  * In the second case, we know by induction that $\Gamma^{ +} \leq A^{\ast} \supset B^{\ast}$ and
    $\Gamma^{+} \leq A^{\ast}$, so $\Gamma^{ +} \leq A^{\ast} \wedge (A^{\ast} \supset B^{\ast}) \leq B^{\ast}$.

****** DONE Task 6
#+begin_statement
Consider the Lindembaum algebra of IPL where the elements are all
propositions in IPL (with the translation $(-)^{\ast}$ being the identity function) 
and the relationship $\leq$ is defined by provability in IPL. That is, $A\leq B$ 
iff $A \text{ true} \vdash B\text{ true}$. Show that this is a Heyting algebra. You only have to
prove the transitivity. You may assume weakening and exchange of IPL,
or cite previous tasks as lemmas.
#+end_statement

If $A \leq B$ and $B \leq C$, we know that, by weakening, $A \text{ true},B \text{ true} \vdash C \text{ true}$.
We now can apply transitivity to $A \text{ true} \vdash B \text{ true}$ and the previous formula
to obtain $A \text{ true} \vdash C \text{ true}$.
***** Homework 2: Kindom of Kittens [0/7]
****** TODO Task 1
#+begin_statement
Weite down a suitable morphism in terms of the primitive constructs and
the morphisms immediately available in each subtask. The primitive
constructs include $\mathrm{id}$, $f \circ g$, $\left\langle f,g \right\rangle$, $\mathtt{fst}$, $\mathtt{snd}$, $\mathtt{inl}$, $\mathtt{inr}$, $\left\{ f,g \right\}$, $\lambda(f)$ and $\mathtt{map}$.

 * *Reflexivity*, write down a morphism from $\Gamma^+ \times P^{\ast}$ to $P^{\ast}$.
 * *Contraction*, write down a morphism from $\Gamma^{ +} \times P^{\ast}$ to $Q^{\ast}$ in terms of
   a morphism $f \colon (\Gamma^{ +}\times P^{\ast})\times P^{\ast} \to Q^{\ast}$.
 * *Weakening*, write down a morphism from $\Gamma^{ +} \times P^{\ast}$ to $Q^{\ast}$ in terms of a
   morphism $f \colon \Gamma^{ +} \to Q^{\ast}$.
 * *Exchange*, write down a morphism from $(\Gamma^{ +}\times Q^{\ast}) \times P^{\ast}$ to $R^{\ast}$ in terms
   of a morphism $f \colon (\Gamma^{ +}\times P^{\ast}) \times Q^{\ast} \to R^{\ast}$.
 * *Substitution*, write down a morphism from $\Gamma^{ +}$ to $Q^{\ast}$ in terms of two 
   morphisms $f \colon \Gamma^{ +}\to P^{\ast}$ and $g\colon \Gamma^{ +}\times P^{\ast} \to Q^{\ast}$.
#+end_statement

****** TODO Task 2
****** TODO Task 3
****** TODO Bonus Task 1
****** TODO Task 4
****** TODO Task 5
****** TODO Task 
**** Bibliography
 * Awodey, Category theory.
 * Programming in Martin-Löf Type theory.
 * Homotopy Type Theory book.
*** Working group on Univalent Foundations - Michael Shulman

Categories can have an internal language or internal logic.

| Type theory    | Categories                                                            |
|----------------+-----------------------------------------------------------------------|
| Extensional TT | 1-categories (toposes, pretoposes, sheaves, realizability, gluing...) |
| Homotopy TT    | (∞,1)-categories, model categories, ∞-toposes                         |

The first example is the simplicial model of type theory.

**** Type-theoretic fibration category
Two classes of examples

 1. Simplicial sets
 2. Sintactic category of a type theory

It should have

 * a terminal object,
 * fibrations (Kan fibrations, display maps) closed under composition and pullback.

Given a fibration $g \colon A \twoheadrightarrow B$, the pullback functor ${\cal C}/B \to {\cal C}/A$ has a right adjoint
taking fibrations to fibrations. (Pullback preserves acyclic cofibrations)

***** Weak factorization system
Two classes of maps $({\cal L}, {\cal R})$ and every morphism factors
as something in ${\cal L}$ and something in ${\cal R}$. Every square

\[\begin{tikzcd}
\cdot \rar{} \dar[swap]{{\cal L}} & \cdot \dar{{\cal R}} \\
\cdot\rar{} \urar[dashed] & \cdot 
\end{tikzcd}\]

factors as shown.
*** Fields lectures
http://www.fields.utoronto.ca/video-archive//event/2012/2016

**** [May 16] Michael Shulman: synthetic homotopy theory
It shows a proof of the equality between integers and the foundamental
group of the circle.

***** Introduction: type theory
Homotopy type theory is a variation on ML-TT with Higher inductive
types and univalence. In type theory we have

 - types,
 - terms,
 - type constructors, like Pi or Sigma,
 - several universes

From the homotopic point of view, we think of types as spaces or
groupoids. A type family is a homotopy-theoretic fibration: if
we have $B : A \to {\cal U}$, $B(x)$ is the fiber over $x : A$.

***** Identity types
Identity types provide the groupoid structure to a type. Equalities
are paths between two points of a type.

 - Leibniz/Lawvere/Martin-Lof notion. The family of equality types for
   any given type is freely generated by the reflexivity path.

****** Why does this work? How can exist non-trivial paths?
The space of paths with a fixed endpoint is contractible. There are no
paths but reflexivity. Every path can be retracted back to
reflexivity.  You can use the Yoneda lemma here; the hom functor is
determined by the identity map.

****** Homotopy structure
Any type has an internal homotopy structure

***** Observational/definitional/cubicaal approach
The meaning of the identity type is defined recursively on the
structure of the type A. For example, if we have a product type,
two pairs are equal if their components are equal.

We have operations of transport defined in terms of the structure of
the type.

***** n-types & propositions
We regard types as representing propositions, things that we can prove;
and elements of a type are their proofs.

 - A type is a proposition if every two elements of that type are
   propositionally equal.

Note that propositional equalities have nothing to do with these mere
propositions.

****** Propositional truncation
A type such that every map from a type factors uniquely throught its
propositional truncation.
***** Synthetic homotopy theory
Synthetic homotopy theory is the study in HoTT of properties of types
that traditionally belong to homotopy spaces. We view types as spaces
and we try to apply ideas from homotopy theory.

For example, we classically define the homotopy group of a space as a
map from the sphere to a space.

We can define the loop space of a type. If we iterate over this, we get
higher homotopy groups. The zero truncation of these types gives us the
homotopy paths.

****** Traditional vs synthetic
Traditional

 - spaces are sets of points,

Synthetic

 - spaces are fundamental notions,
 - paths are fundamental notions.

Synthetic homotopy theory models other homotopy theories, things like
higher toposes are expected to be models of this theory.

***** Our tools: HITs and univalence
HITs give us a way to construct spaces in type theory.

In classical homotopy theory we have cell-complexes and we use them to
build complicated spaces. A higher inductive is a cell-complex what an
inductive type is a 0-dimensional cell-complex.

The circle can be constructed directly as a HIT.

We can prove that
\[
\Omega(\mathbb{S}^1, \mathrm{base}) = \mathbb{Z},
\]
by defining a map from the integers to the paths, $n \mapsto \mathrm{loop}^n$.

We need the UA in order to create the converse function.
**** [May 19] Thorsten Altenkirch: why does homotopy type theory matter?

 * *Realist* foundation of mathematics. Mathematical objects are real
   things instead of constructed notions. We use sets.

 * *Constructivist* foundation of mathematics. We are not basing this
   in real objects, we are only communicating ideas. Type theory can be
   thought of as an implementation of constructivism.

   * We can reason about propositions.
   * We use types instead of sets.

We can translate propositions as types, and this is not a sintactic
trick but a new way of understanding a proposition. If we use types
instead of sets, we have to introduce types and terms from that type
at the same time. There is no way to reference untyped objects.

\[
\mathtt{Bool} \cong \mathtt{Prop},
\]

if and only if the LEM holds.

***** What has homotopy theory ever done for us?
In Martin-Löf first version, membership was impredicative. Then he
introduced extensional type theory; and then later he introduced
intensional type theory.

 - Programming in Martin-Lof's type theory, Nordström.

In intensional type theory, two objects are equal only if they are
defined the same way; that is a problem. These two functions

 - $\lambda x.x + 0$,
 - $\lambda x.0+x$, 

for example, are not equal.

***** Setoids
Setoids are a way to solve the problem with intensional type theory.
A setoid is a type with some equivalence relation. From any two
setoids $A,B$, we can define a new setoid $A \to B$ whose functions
must preserve the equivalence relation. That is, we can translate the
usual type constructors into setoid constructors.

***** TODO Setoid interpretation
** Topology                                                                                                 :topology:
*** Basic topology
**** Covering space                                                                                          :drill:
SCHEDULED: <2018-07-01 Sun>
:PROPERTIES:
:ID:       915fad6c-c2b3-479f-b16d-b24f97abbd13
:DRILL_LAST_INTERVAL: 4.4901
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 6
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 4.333
:DRILL_EASE: 2.9
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-27 Wed 13:08]
:END:
Definition of *covering space*.

***** Definition
A *continuous surjective* $p : E \to B$ such that every $b \in B$ has a
neighborhood $V$ such that $p^{-1}(V)$ is an open partition $\{V_n\}$ of
*slices*, every one of them isomorphic to $V_b$.

**** Topological retraction                                                                                  :drill:
SCHEDULED: <2019-03-17 Sun>
:PROPERTIES:
:ID:       36cc4b72-f8d6-45ab-8377-7aa2dfb4420b
:DRILL_LAST_INTERVAL: 267.9428
:DRILL_REPEATS_SINCE_FAIL: 6
:DRILL_TOTAL_REPEATS: 5
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.8
:DRILL_EASE: 2.9
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-22 Fri 22:00]
:END:
Definition of topological *retraction*.

***** Definition
An inclusion $i : A \subseteq X$ with a continuous map $r : X \to A$ 
such that $r \circ i = \mathsf{id}$.

**** Compact space (by open covers)                                                                          :drill:
SCHEDULED: <2018-07-13 Fri>
:PROPERTIES:
:ID:       9944a022-526f-42bc-92b9-16b8b5519958
:DRILL_LAST_INTERVAL: 65.0035
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.25
:DRILL_EASE: 2.56
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-05-09 Wed 15:15]
:END:
Give the classical definition of compact space by open covers.

***** Definition
$X$ is compact if any open cover ${\cal O}$,

\[
\bigcup_{O \in {\cal O}} O = X
\]

has a finite subcover ${\cal O}' \subset {\cal O}$.

**** Are the open and closed intervals homeomorphic?                                                         :drill:
SCHEDULED: <2019-01-19 Sat>
:PROPERTIES:
:ID:       72ebf2a8-8fe0-4179-a952-5ccddf9b7315
:DRILL_LAST_INTERVAL: 251.9582
:DRILL_REPEATS_SINCE_FAIL: 6
:DRILL_TOTAL_REPEATS: 5
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.8
:DRILL_EASE: 2.9
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-05-12 Sat 17:47]
:END:
Prove or disprove: are the open and closed intervals homeomorphic?

***** Answer
No, [0,1] is compact and (0,1) is not. Compactness is preserved
by homeomorphisms.

***** Answer 2
We can take a point on both intervals and see that only one of them
has to be connected.

**** The fundamental group of a topological group
Why do we know that the fundamental group of a topological group is abelian?

***** Answer
By a Eckmann-Hilton argument.

In categorical terms, we can use that the foundamental group functor from
path-connected topological groups to groups, $\pi_1 \colon \mathsf{pcTop} \to \mathsf{Grp}$, respects
products. A group object in $\mathsf{pcTop}$ is sent to a group object in $\mathsf{Grp}$, that
is, an abelian group. ([[https://math.stackexchange.com/a/686923/85067][Math.SE]])

*** Classification of Surfaces - Chen Hui George Tao
**** 1. Introducción
Vamos a demostrar que todas las superficies compactas son homeomorfas
a la esfera, la suma conexa de toros o la suma conexa de planos proyectivos.

**** 2. Superficies
***** Superficies
Una *superficie* es una 2-variedad. Un espacio Hausdorff contable
localmente homeomorfo a $\mathbb{R}^2$.

***** Idea del artículo
Dado un polígono, si identificamos las aristas en pares, tendremos una
superficie. Veremos que toda superficie se construye a partir de un
polígono con las aristas identificadas.

**** 3.1. Triangulaciones. Complejos simpliciales
***** Simplex
Dados $v_0,\dots,v_k$ en posición general, el *simplex* que generan es el
conjunto de combinaciones convexas bajo la topología inducida.

***** Complejo simplicial euclídeo
Un *complejo simplicial* es una colección $K$ de símplices cumpliendo:

  1. Si $\sigma \in K$, cada cara suya está en $K$.
  2. Si $\sigma,\tau \in K$, $\sigma \cap \tau$ es vacía o una cara de ambas.
  3. Cada punto tiene un entorno que interseca a sólo finitos símplices.

***** Poliedro
La unión de todos los símplices de $K$ es un espacio simplicial llamado
su *poliedro*, $|K|$.

***** Homomorfismo simplicial
Función continua entre dos poliedros cuya restricción a cada simplex
es afín. Es *isomorfismo simplicial* cuando es homeomorfismo.

**** 3.2. Triangulaciones
***** Triangulación
Una triangulación es un homeomorfismo entre un espacio topológico
y un espacio simplicial euclídeo.

***** Teorema de Radó
Toda superficie es un poliedro de un complejo simplicial 2-dimensional.
Donde además, cada 1-símplex es cara de dos 2-símplex.

****** Demostración
La demostración es larga. La idea es recubrir toda la superficie con
discos regulares y usar el Teorema de Schonflies.

**** 4.1. Presentación poligonal. Polígonos
***** Región poligonal
Compacto $P$ del plano cuya frontera es un 1-símplex cumpliendo:

  1. Cada $q$ que no es vértice tiene un entorno $U$ tal que $P \cap U$ es
     intersección de $U$ con un plano.
  2. Cada $q$ que es vértice tiene un entorno $U$ tal que $P \cap U$ es
     intersección de $U$ con dos planos con fronteras intersecando en $q$.

***** Una región poligonal relacionada a pares es una superficie compacta
Sea $P$ región poligonal. Dada una relación que identifique cada 
arista con exactamente otra por isomorfismo simplicial, el
espacio cociente resultante es una superficie compacta.

****** Demostración
Sea $M = P/\sim$, con proyección $\pi:P \longrightarrow M$. Por compacidad, $\pi(P) = M$
es compacto. Podemos dividir los puntos de $M$ en:

******* Puntos en una cara
Como la proyección es homeomorfismo local en el interior del polígono,
tenemos que son localmente euclídeos.

******* Puntos en una arista
Claramente, existe un entorno sin vértices. Por definición de la
relación, el punto está identificado con exactamente otro y podemos
usar los entornos $V_1,V_2$ que son discos de intersecciones con planos.

Ahora creamos aplicaciones afines $\alpha_1,\alpha_2$ que peguen las dos partes del 
disco en $\mathbb{R}^2$ y las usamos para construir una proyección de $V_1\cup V_2$ a
$\mathbb{R}^2$. Por tener la misma relación de equivalencia que $\pi$, los espacios
cocientes son homeomorfos, y podemos ver que el punto tiene un
entorno euclídeo en este espacio.

******* Vértices
Repetimos exactamente lo mismo que hemos hecho con la arista pero
sabiendo que cada identificación del vértice nos da un ángulo que
debemos pegar después en $\mathbb{R}^2$.

**** 4.2. Presentación poligonal. Suma conexa de superficies
***** Suma conexa
Dadas superficies $M_1,M_2$, bolas regulares $B_1,B_2$, y un homeomorfismo
$f : dM_2' \longrightarrow dM_1'$. El espacio que identifica cada punto con su imagen
es la *suma conexa*.

***** Suma conexa de superficies conexas
La suma conexa de superficies conexas es una superficie conexa.

****** Demostración
Debemos ver que es localmente euclídea y Hausdorff. Tomamos como
proyección:

\[
\pi : M_1' \sqcup M_2' \longrightarrow M_1\# M_2
\]

Y tenemos dos tipos de puntos.

******* Puntos en el interior
Los puntos que no tocan al disco de unión tienen a la proyección
localmente homeomorfa en ellos y por eso son localmente euclídeos.

******* Puntos en el borde
Tomamos un entorno de ambos puntos tal que contengan los mismos
puntos identificados del borde. Los proyectamos a $\mathbb{R}^2$ pegando
ambos bordes y nos damos cuenta de que es la misma relación de
equivalencia que daría $\pi$, luego son espacios homeomorfos y el
punto en ellos, llevado al $0$, es localmente euclídeo.

**** 4.3. Presentación poligonal
***** Presentación poligonal
Una *presentación poligonal* es un conjunto finito con finitas palabras
$W_1,\dots,W_k$, cada una de longitud 3 o mayor.

***** Realización geométrica de una presentación poligonal
La *realización geométrica* de una presentación poligonal se construye:

  1. Cada palabra $W_i$ da $P_i$, región poligonal de $k$ lados construída del
     polígono regular modelo.
  2. Damos una biyección de cada símbolo con los lados de $P_i$ en orden.
  3. Unimos disjuntamente los $P_i$ e identificamos aristas con el mismo
     nombre y homeomorfismos afines.

***** Presentación de superficie
Presentación poligonal donde cada símbolo ocurre exactamente dos veces.

****** La realización de una presentación de superficie es superficie compacta
Hemos probado antes que en este caso, obteníamos una [[*Una región poligonal relacionada a pares es una superficie compacta][superficie compacta]]
en la realización.

***** Presentaciones topológicamente equivalentes
Dos presentaciones son equivalentes si tienen la misma realización 
geométrica.

***** Toda superficie compacta tiene una presentación de superficie
Toda superficie compacta tiene una presentación de superficie.

****** Demostración
Dada una superficie $M$, por triangulación es homeomorfa a un complejo
simplicial donde cada arista es cara de dos símplices. Dado un complejo
simplicial podemos construir una presentación donde:

  - Cada 2-símplex es una palabra de longitud 3.
  - Dos aristas se llaman igual si vienen del mismo símplex.

La presentación entonces nos da dos proyecciones desde los polígonos
hasta la realización de la presentación y al símplex.

  - $\pi_K : P_1\sqcup\dots\sqcup P_n \longrightarrow |K|$
  - $\pi_{\cal P} : P_1\sqcup\dots\sqcup P_n \longrightarrow |{\cal P}|$

******* Ambas proyecciones identifican los mismos puntos
Es claro que identifican las mismas aristas por construcción.
Debemos comprobar que identifican los mismos vértices. Sea $v$
un vértice, que debe estar en una arista que debe estar en dos 
2-símplex $\sigma,\sigma'$. Definimos una relación entre 2-símplices si
comparten una arista. Para comprobar que los vértices se mantienen
por una proyección entre aristas, comprobaremos que hay una sola
clase de equivalencia.

Si hubiera dos clases de equivalencia $\{\sigma_i\},\{\tau_i\}$, podemos tomar una
bola suficientemente pequeña (por la condición de finitud de los
complejos simpliciales) para que interseque sólo a símplices 
conteniendo a $v$. Esto nos da una bola homeomorfa a $\mathbb{R}^2$, luego
$U \setminus \{v\}$ es conexo. Podríamos quitar el $v$ en los complejos simpliciales
de ambas clases de equivalencia y serían disconexas.

***** Extensión de isomorfismo de bordes
Sean $P_1,P_2$ polígonos convexos con $f : bP_1 \longrightarrow bP_2$ isomorfismo simplicial,
entonces se extiende a un homeomorfismo $F : P_1 \longrightarrow P_2$.

****** Demostración
Cualquier punto en el interior forma uniéndose con los vértices un
complejo simplicial. Los poliedros de ambos son homeomorfos porque
los complejos simpliciales lo son.

***** Las transformaciones elementales dan realizaciones equivalentes
Las transformaciones elementales de las presentaciones dan lugar a
superficies topológicamente equivalentes

****** Reflexión
Claramente una aplicación afín de reflexión nos da lo buscado.

****** Rotación
La rotación es una aplicación afín que nos da lo buscado.

****** Cortar
Tomamos las dos proyecciones de presentación antes y después de
cortar y comprobamos que identifican los mismos puntos.

****** Doblar
Tomamos las dos proyecciones y añadimos las aristas que faltan para
comprobar que identifican los mismos puntos.

***** Presentación de la suma conexa
La presentación de la suma conexa es la unión de las palabras.

****** Demostración
Dadas $W_1,W_2$, cortamos un disco como $W_1c^{-1}b^{-1}a^{-1}$ y $abcW_2$ e 
identificamos las aristas dadas.

**** 5. Teorema de clasificación
***** Lema: Botella de Klein
***** Lema: Suma de toro y plano proyectivo
***** Teorema de clasificación
Toda superficie compacta conexa es homeomorfa a una de las siguientes:

  - $\mathbb{S}^2$
  - $\mathbb{T}^{\#n}$
  - $\mathbb{RP}^{2\#n}$

****** Demostración
Tomamos transformación desde la presentación hasta llegar a la
presentación de un modelo.

******* Paso 1: Una sola cara
******* Paso 2: Sin pares complementarios adyacentes
******* Paso 3: Todos los pares retorcidos adyacentes
******* Paso 4: Identificamos todos los vértices en un punto
******* Paso 5: Comprobamos que los complementarios están entrelazados
******* Paso 6: Llevamos los complementarios juntos
******* Paso 7: Comprobamos que es una presentación modelo
** Locales                                                                                          :topology:locales:
Some [[https://math.stackexchange.com/a/2825138/85067][reference texts on locales]] from SO, quick reviews:

 * Picado, Pultr, Tozzi: Locales
 * Johnstone: The point of pointless topology

and standard textbooks:

 * Johnstone: Stone spaces (1986) -- for a duality-theory oriented introduction to frames/locales.
 * Vickers: Topology via logic (1996) -- for the relations with computer science and logic.
 * Pultr, Picado: Frames and Locales - topology without points (2011) -- for the more classical, topology oriented approach.

*** The point of pointless topology - Johnstone                                                       :paper:locales:
:PROPERTIES:
:INTERLEAVE_PDF: ~/pdf/johnstone_the_point_of_pointless_topology.pdf
:END:

**** Frames and locales
:PROPERTIES:
:interleave_page_note: 3
:END:

Frames and locales.

***** Frame                                                                                         :drill:locales:
SCHEDULED: <2018-07-03 Tue>
:PROPERTIES:
:ID:       869b43f9-6d28-4f26-b139-0eb67e9649f8
:DRILL_LAST_INTERVAL: 3.6719
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-29 Fri 22:20]
:END:
*Frame*

****** Answer
A poset with 

 * arbitrary joins (small coproducts) $\bigvee$,

 * finite meets (finite products) $\wedge$,

 * satisfying the /infinite distributive law/

   \[
   x \wedge \left( \bigvee_i y_i \right)  = \bigvee_i \left( x \wedge y_i \right)
   \]

***** Locales                                                                                       :drill:locales:
SCHEDULED: <2018-07-04 Wed>
:PROPERTIES:
:ID:       563403ea-8ed2-439b-907f-04f9679da424
:DRILL_LAST_INTERVAL: 3.9336
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-30 Sat 11:56]
:END:
How the category of locales is constructed.

****** Answer
The category of locales is the opposite category to the category of frames.

\[
\mathsf{Locale} = \mathsf{Frame}^{op}.
\]

** Statistics                                                                                             :statistics:
*** Normal distribution                                                                                       :drill:
SCHEDULED: <2018-07-02 Mon>
:PROPERTIES:
:ID:       9d9e5534-15b0-4c90-a482-97100e0507bb
:DRILL_LAST_INTERVAL: 5.2815
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 7
:DRILL_FAILURE_COUNT: 2
:DRILL_AVERAGE_QUALITY: 3.572
:DRILL_EASE: 2.52
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-27 Wed 13:07]
:END:
Probability density function of the normal distribution.

**** Function

\[
f(x \mid \mu,\sigma^2) = \frac{1}{\sqrt{2\sigma^2\pi}}e^{-\frac{(x-\mu)^2}{2\sigma^2}}
\]

*** Bayes' theorem                                                                                            :drill:
SCHEDULED: <2018-07-10 Tue>
:PROPERTIES:
:ID:       b716bff8-b809-4e11-94e3-1ddd6ad697e4
:DRILL_LAST_INTERVAL: 12.6717
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 6
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 4.333
:DRILL_EASE: 2.9
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-27 Wed 13:14]
:END:
Probability of $P(A \mid B)$.

**** Statement

\[
P(A\mid B) = \frac{P(B \mid A)P(A)}{P(B)}
\]

** Algebra                                                                                                   :algebra:
*** Basic algebra
**** Cayley-Hamilton theorem
The characteristic polynomial of an $n \times n$ matrix

\[p(\lambda) = \mathrm{det}(\lambda I_n - A),\]

is zero when evaluated (interpreted as a n-th order polynomial)
in the matrix, $p(A) = 0$.

***** Card                                                                                                  :drill:
SCHEDULED: <2018-07-04 Wed>
:PROPERTIES:
:ID:       69035ffd-8039-4e89-ac2d-f0ae7712d8a1
:DRILL_LAST_INTERVAL: 4.0564
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-30 Sat 11:52]
:END:
Given a characteristic polynomial, $p(\lambda) = \mathrm{det}(\lambda I_n - A)$,
evaluate $p(A)$ symbolically.

****** Answer
$p(A) = 0$ is the Cayley-Hamilton theorem.

**** Rank-nullity theorem                                                                                    :drill:
SCHEDULED: <2018-07-03 Tue>
:PROPERTIES:
:ID:       b4ed18f9-2f91-4028-8379-6d79acbe6cc3
:DRILL_LAST_INTERVAL: 4.0
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-29 Fri 22:09]
:END:
Given $V$ finite dimensional and $T \colon V\to W$ linear, state the
rank-nullity theorem.

***** Statement

\[
\mathrm{dim}(\mathrm{im}(T))+ \mathrm{dim}(\mathrm{ker}(T)) = \mathrm{dim}(V)
\]

**** Exponentiation of versors                                                                               :drill:
SCHEDULED: <2019-02-11 Mon>
:PROPERTIES:
:ID:       8404f823-c268-4627-8229-8432570411eb
:DRILL_LAST_INTERVAL: 272.3165
:DRILL_REPEATS_SINCE_FAIL: 6
:DRILL_TOTAL_REPEATS: 6
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.8
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-05-15 Tue 23:14]
:END:
Given a quaternion $q$, how we define and compute $\mathrm{exp}(q)$?

***** Definition
We define the exponentiation using Taylor Series

\[\exp(q) =  1 + q + \frac{q^2}{2!} + \frac{q^3}{3!} + \dots + \frac{q^n}{n!} + \cdots\ .\]

***** Computation
If we write any quaternion as a versor, $q = \cos\theta + v\sin\theta$, we can
use that $v$ is unitary, $v^2 = -1$, to compute the Euler's formula for
quaternions

\[q = \exp(\theta v) = \cos \theta + v \sin \theta,\]

and then

\[q^t = \exp(t \theta v) = \cos (t \theta) + v \sin (t \theta).\]
**** Snake lemma                                                                                             :drill:
SCHEDULED: <2018-07-09 Mon>
:PROPERTIES:
:ID:       159f12f8-6ca4-4723-8eb7-378a418d38b7
:DRILL_LAST_INTERVAL: 11.9157
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 7
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 4.285
:DRILL_EASE: 2.9
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-27 Wed 13:14]
:END:
Given a morphism of short exact sequences as 

\[\begin{tikzcd}
& A \rar{f}\dar{a} & B \rar{g}\dar{b} & C \rar\dar{c} & 0  \\
0 \rar & A' \rar{f'} & B' \rar{g'} & C' \\
\end{tikzcd}\]

what does the snake lemma provide?

***** Answer
There exists a morphism $\delta \colon \operatorname{ker} c \to \operatorname{coker} a$ such that the 
following sequence is exact

\[\begin{tikzcd}
0 \rar &
\mathrm{ker}(a) \rar{f} &
\mathrm{ker}(b) \rar{g} &
\mathrm{ker}(c) \arrow[out = 0,in =180,swap]{dll}{\delta} \\&
\mathrm{coker}(a) \rar{f'} &
\mathrm{coker}(b) \rar{g'} &
\mathrm{coker}(c) \rar &
0
\end{tikzcd}\]

Diagramatically,

\[ \begin{tikzcd}
& 0 \dar              & 0 \dar            & 0 \dar           &   \\
0 \rar & ker(a) \rar \dar  & ker(b) \rar \dar    & ker(c) \dar \ar[out=355, in=175,looseness=1, overlay, swap]{dddll}{\delta}       &   \\
& A \rar{f} \dar{a}  & B \rar{g} \dar{b} & C \rar \dar{c}        & 0 \\
0 \rar & A' \rar{f'} \dar & B' \rar{g'} \dar & C' \dar        &  \\
& coker(a) \rar \dar & coker(b) \rar \dar  & coker(c) \rar \dar & 0 \\
& 0                   & 0                 & 0                &
\end{tikzcd} \]

**** TODO Difference between direct sum and direct product in abelian groups                                 :drill:
:PROPERTIES:
:ID:       b3903d4f-4550-414a-8b1f-9a6fdc37048c
:END:
**** Norm inequality                                                                                         :drill:
SCHEDULED: <2018-07-04 Wed>
:PROPERTIES:
:ID:       5a7545ad-d087-43f1-affa-07101400c452
:DRILL_LAST_INTERVAL: 4.1209
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-30 Sat 11:59]
:END:
Prove that, for any $N$ norm in a vector space.

\[
\abs{N(x)-N(y)} \leq N(x-y)
\]

***** Answer
Norm is [[https://en.wikipedia.org/wiki/Norm_(mathematics)][subadditive]] (triangle inequality). It is trivial from the properties.

*** Algebra: chapter 0 - Aluffi
**** III. Anillos y módulos
***** 7. Complejos y homología
****** 7.1. Complejos y secuencias exactas.
 #+begin_definition
 *Complejo*. Un complejo es una serie de morfismos $d_i$ entre R-Módulos:

 \[\dots \longrightarrow M_{i+1} \longrightarrow M_i \longrightarrow M_{i-1} \longrightarrow \dots\]

 tales que $d_i \circ d_{i+1} = 0$.
 #+end_definition

 Además lo llamamos *exacto* cuando $im (d_{i+1}) = ker (d_i)$.

 #+begin_proposition
 *Exactitud de monomorfismos y epimorfismos*. Dos complejos de la forma:

 \[ \dots \longrightarrow 0 \longrightarrow L \overset{\alpha}\longrightarrow M \longrightarrow \dots \]
 \[ \dots \longrightarrow M \overset{\beta} \longrightarrow N \longrightarrow 0 \longrightarrow \dots \]

 Son exactos en $L$ y $N$ ssi $\alpha$ y $\beta$ son monomorfismo y epimorfismo, 
 respectivamente.
 #+end_proposition

 #+begin_definition
 *Secuencia exacta corta*. Una secuencia exacta corta es un complejo de la forma:

 \[ 0 \longrightarrow L \overset{\alpha}\longrightarrow M \overset{\beta}\longrightarrow N \longrightarrow 0 \]
 #+end_definition

 El primer teorema de isomorfía nos dice que $N \cong \frac{M}{ker(\beta)} = \frac{M}{im(\alpha)}$ lo que nos 
 lleva a identificar   $N \cong \frac{M}{L}$. De hecho, cada monomorfismo da lugar a una 
 secuencia exacta corta:

 \[ 0 \longrightarrow \ker(\phi) \longrightarrow M \longrightarrow im(\phi) \longrightarrow 0 \]

****** 7.2. Secuencias exactas escindidas
 #+begin_definition
 *Secuencia escindida*. Una secuencia exacta corta:

 \[ 0 \longrightarrow M_1 \longrightarrow N \longrightarrow M_2 \longrightarrow 0 \]

 es escindida si es isomorfa a una secuencia de la forma siguiente:

 \[ \begin{tikzcd}
 0   \arrow{r}{} & 
 M_1 \arrow{d}{\sim}\arrow{r}{} & 
 N   \arrow{d}{\sim}\arrow{r}{} & 
 M_2 \arrow{d}{\sim}\arrow{r}{} & 
 0 \\
 0   \arrow{r}{} & 
 M_1 \arrow{r}{} & 
 M_1 \oplus M_2   \arrow{r}{} & 
 M_2 \arrow{r}{} & 
 0
 \end{tikzcd} \]

 Es decir, hay un isomorfismo entre secuencias.
 #+end_definition

 #+begin_theorem
 *Relación entre secuencias escindidas e inversas*. Sea $\phi$ un homomorfismo;
 entonces tiene inversa izquierda ssi la secuencia siguiente escinde:

 \[ 0 \longrightarrow M \overset{\phi}\longrightarrow N \longrightarrow coker(\phi) \longrightarrow 0 \]

 Y tiene inversa derecha si la secuencia siguiente escinde:

 \[ 0 \longrightarrow ker(\phi) \longrightarrow M \overset{\phi}\longrightarrow N \longrightarrow 0 \]
 #+end_theorem

****** 7.3. Homología, y el lema de la serpiente
 #+begin_definition
 *Homología*. La i-ésima homología de un complejo,

 \[ \dots \longrightarrow M_{i+1} \overset{d_{i+1}}\longrightarrow M_i \overset{d_i}\longrightarrow M_{i-1} \longrightarrow \dots \]

 es el R-módulo:

 \[H_i(M) = \frac{ker(d_i)}{im(d_{i+1})}\]
 #+end_definition

 La homología mide lo que se aleja de ser exacto en un punto determinado, y
 es $0$ cuando el complejo es exacto. Puede verse como una generalización de
 kernel y cokernel; que los realiza en este caso extremo:

 \[ 0 \longrightarrow M_1 \overset{\phi}\longrightarrow M_0 \longrightarrow 0 \]

 En el que $H_1(M) \cong ker(\phi)$ y $H_0(M) \cong coker(\phi)$.

 #+begin_theorem
 *Lema de la serpiente*. Teniendo dos secuencias exactas en el diagrama 
 conmutativo siguiente:

 \[ \begin{tikzcd}
 0 \rar & L_1 \rar{\alpha_1}\arrow{d}{\lambda} & M_1 \rar{\beta_1}\arrow{d}{\mu} & N_1 \rar\arrow{d}{\eta} & 0 \\
 0 \rar & L_0 \rar{\alpha_0}                   & M_0 \rar{\beta_0}               & N_0 \rar                & 0
 \end{tikzcd} \]

 Existe una secuencia exacta de la forma:

 \[ 0 \overset{}\longrightarrow 
 ker(\lambda) \overset{}\longrightarrow 
 ker(\mu) \overset{}\longrightarrow 
 ker(\eta) \overset{\delta}\longrightarrow 
 coker(\lambda) \overset{}\longrightarrow 
 coker(\mu) \overset{}\longrightarrow 
 coker(\eta) \overset{}\longrightarrow 
 0\]
 #+end_theorem

 El diagrama desde el que se deduce todo esto, con columnas exactas, es
 el siguiente:

 \[ \begin{tikzcd}
	& 0 \dar              & 0 \dar            & 0 \dar           &   \\
 0 \rar & ker(\lambda) \rar \dar  & ker(\mu) \rar \dar    & ker(\eta) \dar \ar[out=355, in=175,looseness=1, overlay, swap]{dddll}{\delta}       &   \\
 0 \rar & L_1 \rar{\alpha_1} \dar{\lambda}  & M_1 \rar{\beta_1} \dar{\mu} & N_1 \rar \dar{\eta}        & 0 \\
 0 \rar & L_0 \rar{\alpha_0} \dar & M_0 \rar{\beta_0} \dar & N_0 \rar \dar        & 0 \\
	& coker(\lambda) \rar \dar & coker(\mu) \rar \dar  & coker(\eta) \rar \dar & 0 \\
	& 0                   & 0                 & 0                &
 \end{tikzcd} \]

**** IV. Álgebra lineal
***** 4. Presentaciones y resoluciones
****** 4.1. Torsión
 #+begin_definition
 *Torsión*. Un elemento $m \in M$ módulo de $R$ es de *torsión* si $\{m\}$ es linealmente
 dependiente. Es decir,

   \[ \exists r \in R,\ r \neq 0\ :\ rm = 0 \]

 El conjunto de elementos de torsión se llama $Tor(M)$. Un módulo es *libre de torsión*
 si $Tor(M) = 0$ y *de torsión* si $Tor(M)=M$.
 #+end_definition

 Un anillo conmutativo es libre de torsión sobre sí mismo si y sólo si es dominio de
 integridad. Cuando esto ocurre, $Tor(M)$ es siempre submódulo de $M$. Submódulos o
 sumas de módulos libres de tensión serán libres de torsión, y por todo esto, los módulos
 libres sobre dominios de integridad serán libres de torsión.

 #+begin_definition
 *Cíclico*. Un módulo es *cíclico* cuando es generado por un elemento. Es decir,
 cuando $M \cong R/I$ para algún ideal.
 #+end_definition

 Cuando en un dominio de integridad todos sus
 módulos cíclicos son libres de torsión, es un cuerpo. Otra forma de pensar sobre un módulo
 cíclico es como aquel que admite un epimorfismo:

 \[ R \longrightarrow M \longrightarrow 0 \]

****** 4.2. Módulos finitamente presentados y resoluciones libres
 #+begin_definition
 *Anulador.* El anulador de un módulo $M$ es:

 \[Ann_R(M) = \{ r \in R\ |\ \forall m \in M, rm = 0 \}\]
 #+end_definition

 Es un ideal de $R$. Cuando $M$ es finitamente generado y $R$ es dominio de integridad,
 $M$ es de torsión si y sólo si $Ann(M) \neq 0$.

 #+begin_definition
 *Módulos finitamente generados y presentados*. Sabemos que todos los módulos admiten un
 epimorfismo de la forma:

 \[ R^{\oplus A} \longrightarrow M \longrightarrow 0\]

 Cuando lo admiten con $A$ finito, se tiene $M$ *finitamente generado*. Un módulo se dice
 *finitamente presentado* si hay una secuencia exacta de la forma:

 \[R^n \overset{\phi}\longrightarrow R^m \longrightarrow M \longrightarrow 0\]

 .
 #+end_definition

 Si $R$ es Noetheriano, todo módulo finitamente generado es finitamente presentado.

 #+begin_definition
 *Resolución*. Una resolución de $M$ mediante módulos libres finitamente generados es
 un complejo exacto:

 \[ \dots \rightarrow R^{m_3} \rightarrow R^{m_2} \rightarrow R^{m_1} \rightarrow R^{m_0} \rightarrow M \rightarrow 0 \]
 #+end_definition

 Aquí podemos entender que $R^{m_0}$ contiene los generadores, $R^{m_1}$ las relaciones
 entre los generadores, $R^{m_2}$ las relaciones entre relaciones, y así sucesivamente.

 Un dominio de integridad es *cuerpo si y sólo si todos sus módulos son finitamente generados*,
 esto es equivalente a tener:

 \[ 0 \longrightarrow R^m \longrightarrow M \longrightarrow 0 \]

 para cualquier módulo.

 Un dominio de integridad es *PID si todas las resoluciones como finitamente generado 
 extienden a finitamente presentado*, de la forma:

 \[0 \longrightarrow R^{m_1} \longrightarrow R^{m_0} \overset{\pi}\longrightarrow M \longrightarrow 0\]

 esto equivale a pedir que $\ker(\pi)$ sea libre.

****** 4.3. Leyendo una presentación
 Hemos visto que podemos estudiar un módulo finitamente presentado por un
 morfismo $\phi: R^n \longrightarrow R^m$, donde $M = coker(\phi)$. Esto quiere decir que 
 podemos asignarle una matriz explícita.

 #+begin_theorem
 *Producto de módulos en matrices*. Sean $M,N$ módulos con matrices $A,B$.
 Tenemos $M \oplus N$ con matriz:

 \[\left(\begin{array}{c|c}
 A & 0 \\ \hline 0 & B 
 \end{array}\right)\]
 #+end_theorem

 Además nótese que las *matrices equivalentes* representan el mismo 
 homeomorfismo, y por tanto el mismo módulo.

 #+begin_theorem
 *Transformaciones de matrices de módulos*. Una matriz representa el mismo módulo
 tras las transformaciones de:
  - Permutar filas o columnas
  - Añadir filas o columnas linealmente dependientes
  - Multiplicar filas o columnas por una unidad
  - Quitar una fila y columna en la que sólo queda una unidad
 #+end_theorem

 Las primeras son consecuencia de la equivalencia. La última puede colocarse como
 una parte de identidad en una matriz de la forma:

 \[A = \left(\begin{array}{c|c}
 u & 0 \\ \hline 0 & A' 
 \end{array}\right)\]

 Que no afecta al cokernel.

**** VII. Cuerpos
***** 1. Extensiones de cuerpos I
****** 1.1. Definiciones básicas
******* Categoría de los cuerpos
Los cuerpos forman la *categoría $\mathtt{Fld}$* con los homomorfismos de 
anillos entre ellos. Todo homomorfismo de anillos entre cuerpos
es inyectivo y todo morfismo en esta categoría es monomorfismo.

Así, todo morfismo entre cuerpos en $Hom(k,K)$ es una extensión $K/k$.

******* Característica de un cuerpo
      La *característica* de $K$ es el generador de $ker(i)$ para 
      $i : \mathbb{Z} \longrightarrow K$. Las extensiones preservan la 
      característica, así que podemos particionar la categoría en categorías 
      $\mathtt{Fld}_p$.

******* Cuerpos primos
      El inicial de $\mathtt{Fld}_0$ es $\mathbb{Q}$, y el de $\mathtt{Fld}_p$ es $\mathbb{F}_p = \mathbb{Z}/p\mathbb{Z}$. Todos los
      cuerpos son extensiones de uno de estos llamados *cuerpos primos*.

******* Grado de una extensión
El *grado*, $[F : K]$, de una extensión es su dimensión como espacio
vectorial sobre la base. Es *finita* o *infinita* si lo es su grado.

****** 1.2. Extensiones simples
******* Extensión simple
Una extensión es *simple* si es de la forma $K(\alpha)$ donde 
$K(\alpha)$ es la intersección de todos los subcuerpos de algún
$F$ conteniendo al cuerpo $K$ y el elemento $\alpha$.

******* Polinomio irreducible mínimo
Dada una extensión simple $K(\alpha)$, consideramos la evaluación
$\epsilon : K[X] \longrightarrow K(\alpha)$ por casos:

 - Es *inyectiva* ssi es una *extensión infinita*. En este
   caso $K(\alpha) \cong K(X)$ es el cuerpo de funciones racionales.
 - No es *inyectiva*. Existe un único polinomio mónico
   irreducible $p$ que genera el núcleo,

   \[ K(\alpha) \cong \frac{K[t]}{(p(t))}\]

   Se le llama *polinomio mínimo*.

******* TODO Extensión de isomorfismos a extensiones simples
Proposition 1.5
******* Automorfismos de una extensión
El *grupo de automorfismos* de una extensión $Aut_K(F)$, es el
grupo de los automorfismos de cuerpos que dejan fijo $K$.
******* Automorfismos y raíces
Sea $K(\alpha)$ con $p$ polinomio mínimo. Entonces $p$ tiene $|Aut_K(K(\alpha))|$ raíces
distintas en $K(\alpha)$. En particular,

\[ |Aut_K(K(\alpha))| \leq [K(\alpha):K] \]

y el caso de igualdad se tiene con $p$ factorizando en factores 
lineales sobre $F$.
****** 1.3. Extensiones finitas y algebraicas
******* Elementos algebraicos y trascendentes
Sea $F/K$ una extensión con $\alpha \in F$, entonces $\alpha$ es *algebraico*
cuando $K(\alpha)/K$ es finita, y *trascendente* si no. Una extensión
es *algebraica* si todos sus elementos lo son.

***** 6. Un poco de teoría de Galois
****** 6.1. Correspondencia de Galois y extensiones de Galois
******* Cuerpo fijo
Sea $F/k$ extensión y $G \subseteq Aut_k(F)$. Llamamos *cuerpo fijo* de $G$ a:

\[ F^G = \{ \alpha\in F \mid \forall g \in G, g\alpha=\alpha\}\]

******* Correspondencia de Galois
Hay correspondencia entre los cuerpos intermedios de la extensión
y los subgrupos del grupo de automorfismos.

Dado $E$ cuerpo intermedio, lo enviamos a $Aut_E(F)$. Dado $G$ lo enviamos
a $F^G$.

******* Inclusión y correspondencia
Para cualesquiera subgrupo $G$ y cuerpo intermedio $E$:

 - $E \subseteq F^{Aut_E(F)}$
 - $G \subseteq Aut_{F^G}(F)$

Si llamamos $E_1E_2$ al menor subcuerpo de $F$ conteniendo $E_1,E_2$ y llamamos
$<G_1,G_2>$ al menor subgrupo de los automorfismos conteniendo $G_1,G_2$:

 - $Aut_{E_1E_2}(F) = Aut_{E_1}(F) \cap Aut_{E_2}(F)$
 - $F^{<G_1,G_2>} = F^{G_1} \cap F^{G_2}$

******* Extensiones de Galois
Sea $F/k$ extensión, equivalen:

 - $F$ es cuerpo de descomposición de algún $f \in k[t]$.
 - $F/k$ es normal y separable.
 - $|Aut_k(F)| = [F : k]$.
 - La correspondencia de Galois es biyección.
 - $F/k$ separable y, si $E/F$ es algebraica con $\sigma \in Aut_k(E)$, $\sigma(F)=F$.

Llamamos a esto una *extensión de Galois*.
**** VIII. Vuelta al álgebra lineal
***** 1. Preliminares
****** 1.1. Funtores
 #+begin_definition
 *Funtor*. Un funtor covariante:

 \[{\cal F} : C \longrightarrow D\]

 Asigna a cada $A \in C$ un ${\cal F}(A) \in D$ y mapea los morfismos entre cada par de objetos:

 \[Hom_C(A,B) \rightarrow Hom_D({\cal F}(A),{\cal F}(B))\]

 Respetando la identidad y la composición de morfismos. 

 Un *funtor contravariante* es un funtor desde la categoría opuesta:

 \[{\cal F} : C^{op} \longrightarrow D\]
 #+end_definition

 Los funtores preservan los diagramas conmutativos. Llamamos *prehaz* a un funtor
 contravariante $C \longrightarrow \mathtt{Set}$.

 #+begin_definition
 *Funtor aditivo*. Llamamos a un funtor 
 ${\cal F}: R-\mathtt{Mod} \longrightarrow S-\mathtt{Mod}$ *aditivo* cuando
 la función $Hom_{R}(A,B) \rightarrow Hom_{S}({\cal F}(A),{\cal F}(B))$ es homomorfismo de grupos.
 #+end_definition

****** 1.3. Equivalencia de categorías
 #+begin_definition
 *Funtores plenamente fieles*. Dada la función inducida:
 \[Hom_C(A,B) \rightarrow Hom_D({\cal F}(A),{\cal F}(B))\]
 Un funtor es *fiel* si es inyectiva, *pleno* si es sobreyectiva y *plenamente fiel*
 si es biyectiva.
 #+end_definition

 #+begin_definition
 *Equivalencia de categorías*. Un funtor es una equivalencia de categorías si 
 es plenamente fiel y esencialmente sobreyectivo, es decir, para cada $Y \in D$,
 existe un $X \in C$ tal que $F(X) \cong Y$.
 #+end_definition

****** 1.4. Límites y colímites

 #+begin_definition
 *Límite*. Para un funtor ${\cal F}: {\cal I} \longrightarrow C$, su límite es
 un objeto $L \in C$ con morfismos $\lambda_I: L \longrightarrow {\cal F}(I)$ tales que

 - Conmuta el siguiente diagrama para cualquier $\alpha : I \longrightarrow J$:

 \[ \begin{tikzcd}[column sep=1.5em]
  & L \arrow{dr}{\lambda_J} \arrow{dl}[swap]{\lambda_I} \\
 {\cal F}(I) \arrow{rr}{{\cal F}(\alpha)} && {\cal F}(J)
 \end{tikzcd} \]

 - $L$ es final en este diagrama.
 #+end_definition

 Será esencialmente único y puede notarse por $\varprojlim {\cal F}$.

 #+begin_theorem
 *Límites sobre cadenas en R-Mod*. En R-Mod siempre existe un límite llamado \(\varprojlim {\cal A}_i\) sobre una
 cadena de la forma:

 \[ \begin{tikzcd}
 & & A 
 \arrow{lld}[swap]{\phi_5}
 \arrow{ld}{\phi_4}
 \arrow{d}{\phi_3}
 \arrow{rd}[swap]{\phi_2}
 \arrow{rrd}{\phi_1} 
 & & \\
 \dots \arrow{r}[swap]{\phi_{45}}  &
 A_4 \arrow{r}[swap]{\phi_{34}} &
 A_3 \arrow{r}[swap]{\phi_{23}} &
 A_2 \arrow{r}[swap]{\phi_{12}} &
 A_1
 \end{tikzcd} \]
 #+end_theorem

 Este límite es el submódulo de las /secuencias coherentes/ en $\prod_i A_i$, es decir, de
 aquellas tales que $a_i = \phi_{i,i+1}(a_{i+1})$; teniendo como morfismos $\phi_i$ las proyecciones
 canónicas


 #+begin_definition
 *Colímite*. La noción dual de límite es el *colímite*, es decir, para
 un funtor ${\cal F} : I \longrightarrow C$, su colímite es un objeto $L \in C$ con morfismos $\gamma_i : {\cal F}(I) \longrightarrow L$
 tales que

 - Conmuta el siguiente diagrama para cualquier $\alpha : I \longrightarrow J$:

 \[ \begin{tikzcd}[column sep=1.5em]
  & L  \\
 {\cal F}(I) \arrow{ur}{\gamma_I} \arrow{rr}{{\cal F}(\alpha)} && {\cal F}(J) \arrow{ul}[swap]{\gamma_J}
 \end{tikzcd} \]

 - $L$ es inicial en este diagrama.
 #+end_definition

****** 1.5. Comparando funtores
 #+begin_definition
 *Transformación natural*. Una transformación natural entre dos funtores ${\cal F} \Longrightarrow {\cal G}$ 
 consiste en morfismos $\upsilon_X : {\cal F}(X) \longrightarrow {\cal G}(X)$ tales que conmuta el diagrama:

 \[ \begin{tikzcd}
 {\cal F}(X) \arrow{r}{{\cal F}(\alpha)} \arrow{d}{\upsilon_X} & {\cal F}(Y) \arrow{d}{\upsilon_Y} \\
 {\cal G}(X) \arrow{r}{{\cal G}(\alpha)} & {\cal G}(Y)
 \end{tikzcd}
 \]

 para cualquier morfismo $\alpha$.

 Llamamos *isomorfismo natural* a una transformación natural donde cada $\upsilon$
 es un isomorfismo.
 #+end_definition

 #+begin_definition
 *Funtor adjunto*. Llamamos ${F}$ y ${G}$ adjuntos si tenemos:

 \[ Hom_C(X,GY) \cong Hom_D(FX,Y) \]

 Isomorfismos naturales.
 #+end_definition

 Lo que nos da realmente un isormorfismo natural de $Hom_C(F-,-)$ con $Hom_D(-,G-)$,
 entendidos como funtores. Llamamos aquí adjunto izquierdo a $F$ y adjunto derecho a $G$.
 Tenemos más sobre funtores adjuntos en la lista de reproducción de [[https://www.youtube.com/playlist?list=PL54B49729E5102248][The Catsters]].

 #+begin_theorem
 *Continuidad de adjuntos*. Los funtores adjuntos derechos son continuos, los adjuntos
 izquierdos son cocontinuos. Es decir, para $I : {\cal I}\longrightarrow D$, $J : {\cal J}\longrightarrow C$

 \[G(\varprojlim I) = \varprojlim (G \circ I)\]
 \[F(\varinjlim J) = \varinjlim (F \circ J)\]
 #+end_theorem

 Siempre que existan los límites. La demostración de esto se puede hacer aplicando los
 funtores en los diagramas conmutativos y usando las propiedades universales de los límites.

 #+begin_definition
 *Funtor exacto*. Un funtor exacto respeta la exactitud de las secuencias. Es decir,
 siendo la siguiente secuencia exacta:

 \[ 0 \longrightarrow A \overset{\phi}\longrightarrow B \overset{\psi}\longrightarrow C \longrightarrow 0\]

 La siguiente secuencia será exacta:

 \[ 0 \longrightarrow FA \overset{F\phi}\longrightarrow FB \overset{F\psi}\longrightarrow FC \longrightarrow 0\]
 #+end_definition

 En particular, lo llamamos /exacto a la izquierda/ si preserva la exactitud de:

 \[ 0 \longrightarrow A \overset{\phi}\longrightarrow B \overset{\psi}\longrightarrow C\]

 Y /exacto a la derecha/ si preserva la exactitud de:

 \[ A \overset{\phi}\longrightarrow B \overset{\psi}\longrightarrow C \longrightarrow 0\]

***** 2. Producto tensor y el funtor Tor
****** 2.1. Aplicaciones bilineales
 #+begin_definition
 *Aplicación bilineal*. Una aplicación $\phi:M\times N \longrightarrow P$ es bilineal si
 son lineales $\phi(\_,n)$ y $\phi(m,\_)$ para cualesquiera $m,n$.
 #+end_definition

 #+begin_definition
 *Producto tensor*. $M \otimes_R N$ es el producto tensor de $M$ y $N$ como módulos de $R$
 si cualquier aplicación bilineal factoriza de forma única a través de él:

 \[ \begin{tikzcd}
 M \times N \arrow{r}{\phi} \arrow{d}{\otimes} & P \\
 M \otimes N \arrow{ru}[swap]{\exists! \overline\phi} &
 \end{tikzcd} \]
 #+end_definition

 Usando universalidad podemos ver que $R \otimes N \cong N$ y que $M\otimes N \cong N\otimes M$. La construcción
 explícita del producto tensor se hace sobre el módulo libre sobre $M \times N$ provocando un
 cociente sobre los submódulos generados por:

 \[(m,r_1n_1+r_2n_2) - r_1(m,n_1) - r_2(m,n_2)\]
 \[(r_1m_1+r_2m_2,n) - r_1(m_1,n) - r_2(m_2,n)\]

 Lo que nos permite actuar con ellos de forma bilineal. La demostración se basa en usar
 la propiedad universal de la proyección sobre ese cociente.

****** 2.2. Adjunción con Hom
 Dado un módulo $N$ de $R$, tenemos un funtor covariante $\otimes_R N$, que será *adjunto izquierdo*
 a $Hom_{R-mod}(N,-)$. Podemos observar simplemente que una aplicación bilineal, al currificarse,
 determina una función que va de $M$ a $Hom(N,P)$, y que es lineal. Sabiendo esto, es trivial
 que:

 \[ Hom_R(M, Hom_R(N,P)) \cong Hom_R(M \otimes N, P)\]

 La naturalidad y el hecho de que es un isomorfismo se comprueban fácilmente. El hecho de
 que exista una adjunción nos dice además que $\otimes_R N$, o $N\otimes_R$ por la isomorfía anterior,
 son cocontinuos.

 #+begin_fact
 Para cualesquiera \(R\)-módulos, se tiene:

 \[(M_1 \oplus M_2) \otimes N \cong (M_1 \otimes N) \oplus (M_2 \otimes N)\]

 \[N \otimes (M_1 \oplus M_2) \cong (N \otimes M_1) \oplus (N \otimes M_2)\]

 \[(\oplus_\alpha M_\alpha) \otimes N \cong \oplus_\alpha (M_\alpha \otimes N)\]
 #+end_fact

 Por cocontinuidad.

 #+begin_fact
 Para cualesquiera dos conjuntos $A,B$, se tiene:

 \[R^{\oplus A} \otimes R^{\oplus B} \cong R^{\oplus A \times B}\]
 #+end_fact

 Teniendo \(R^{\oplus n} \otimes R^{\oplus m} \cong R^{\oplus nm}\). De hecho, la base del espacio producto
 tensor la forman los vectores puros que emparejan elementos de las 
 bases de cada uno de los espacios.

 #+begin_theorem
 *Producto tensor de cocientes*. Dado un $N$ módulo de $R$, e $I$ ideal,
 tenemos:

 \[\frac{R}{I}\otimes N \cong \frac{N}{IN}\]

 Y desde ahí, aplicando además el tercer teorema de isomorfía, tenemos:

 \[\frac{R}{I} \otimes \frac{R}{J} \cong \frac{R}{I+J}\]
 #+end_theorem

 Esto se deduce de aplicar el funtor $\_ \otimes N$ a la secuencia exacta del 
 ideal:

 \[I \longrightarrow R \longrightarrow \frac{R}{I} \longrightarrow 0\]
 
 \[I \otimes N \longrightarrow N \longrightarrow \frac{R}{I} \otimes N \longrightarrow 0\]

 Desde donde se obtiene $IN$ como inclusión de $I\otimes N$ en $N$.

****** 2.3. Exactitud y planitud
 #+begin_definition
 *Módulo plano*. El módulo $N$ es *plano* si el funtor $\_ \otimes N$ es un
 funtor exacto.
 #+end_definition

 Un *módulo libre* será siempre plano.

****** 2.4. Los funtores Tor
 #+begin_definition
 *El funtor Tor*. Lo que se aleja de la exactitud el funtor $\_ \otimes N$
 es medido por el funtor $Tor_1(\_,N)$. De hecho, si tenemos una secuencia
 exacta:

 \[0\longrightarrow A \longrightarrow B \longrightarrow C \longrightarrow 0\]

 Obtenemos aplicando el funtor $\otimes N$ esta otra secuencia:

 \[Tor_1(C,N) \longrightarrow A \otimes N \longrightarrow B \otimes N \longrightarrow C \otimes N \longrightarrow 0\]

 Y de hecho, esta secuencia podrá extenderse aún más con /funtores derivados/,
 que se definen como:

 \[Tor_i^R(M,N) = H_i(M_{\bullet} \otimes N)\]
 #+end_definition

 Aquí entendemos $M_\bullet \otimes N$ como el complejo que se obtiene tomando una resolución
 libre de $M$:

 \[\dots \longrightarrow R^{\otimes S_2} \longrightarrow R^{\otimes S_1} 
 \longrightarrow R^{\otimes S_0} \longrightarrow M \longrightarrow 0}\]

 Y retirando $M$ y tensando sobre $N$, para tener:

 \[\dots \longrightarrow N^{\otimes S_2} \longrightarrow N^{\otimes S_1} 
 \longrightarrow N^{\otimes S_0} \longrightarrow 0}\]

 Todo esto se obtendrá de manera natural aplicando el lema de la serpiente a una secuencia
 de resoluciones compatibles, algo que, si los módulos fueran PID y tuvieran una resolución
 de grado 2, sería de la forma:

 \[ \begin{tikzcd}
    & 0 \dar & 0 \dar & 0 \dar &   \\
 0 \rar & R^{\oplus a_1}\rar\dar & R^{\oplus b_1} \rar\dar & R^{\oplus c_1} \rar\dar & 0 \\
 0 \rar & R^{\oplus a_0}\rar\dar & R^{\oplus b_0} \rar\dar & R^{\oplus c_0} \rar\dar & 0 \\
 0 \rar & A\rar\dar & B \rar\dar & C \rar\dar & 0 \\
  & 0 & 0 & 0 & 
 \end{tikzcd} \]

 Tensando las dos filas superiores, que son libres, nos quedarían dos filas sobre las que aplicar
 el lema de la serpiente y obtener los funtores derivados tal y como los hemos definido.

***** 5. Funtor Hom y dualidad 
****** 5.1. Adjunciones, de nuevo
 Ya sabemos que el funtor $Hom(N,\_)$ es adjunto derecho a $\_\otimes N$, ahora
 estudiamos el funtor $Hom(\_,N)$.

 #+begin_theorem
 *Adjunción de Hom contravariante*. El funtor $Hom(\_,N)$ es adjunto derecho
 de su funtor opuesto, $Hom^{op}(\_,N)$.
 #+end_theorem

 Aplicando currificación tenemos trivialmente:

 \[Hom(L,Hom(M,N)) \cong Hom(M,Hom(L,N))\]

 Que, teniendo en cuenta que estamos usando la categoría opuesta, prueba la
 adjunción.

 #+begin_proposition
 *Exactitud de Hom*. Ambos funtores $Hom$ son adjuntos derechos y por tanto,
 exactos por la izquierda. Teniendo en cuenta que uno es contravariante, quiere
 decir que:

 \[ A \overset{}\longrightarrow B \overset{}\longrightarrow C \overset{}\longrightarrow 0\]

 Lleva a:

 \[ 0 \overset{}\longrightarrow Hom(C,N) \overset{}\longrightarrow 
 Hom(B,N) \overset{}\longrightarrow Hom(A,N)\]
 #+end_proposition

****** 5.2. Módulos duales.
 #+begin_definition
 *Módulo dual*. El dual de un R-módulo $M$ es el módulo $M^{\vee} = Hom_R(M,R)$.
 #+end_definition

 Tenemos que $Hom(M,R^n) \cong M^{\vee} \otimes R^n$.

***** 6. Módulos proyectivos e inyectivos, y el funtor Ext
****** 6.1. Proyectividad e inyectividad
 #+begin_definition
 *Módulos proyectivos e inyectivos*. Un R-módulo es /proyectivo/ si $Hom(P,\_)$
 es exacto; e /inyectivo/ si $Hom(\_,P)$ es exacto.
 #+end_definition

 Esto es equivalente a decir que cada epimorfismo $M \longrightarrow N$ lleva un
 morfismo $P \longrightarrow N$ a $P \longrightarrow M$, en el caso de /proyectividad/:

 \[ \begin{tikzcd}
  & P \dlar[swap,dashed]{\exists p'} \dar[swap]{p} \drar{0} & \\
 M \rar & N \rar & 0
 \end{tikzcd} \]

 O que cada monomorfismo $L \longrightarrow M$ lleva un morfismo $L \longrightarrow Q$ a
 un monomorfismo $M \longrightarrow Q$, en el de la /inyectividad/:

 \[ \begin{tikzcd}
  & Q & \\
 0 \urar{0} \rar & N \rar \uar[swap]{q} & M \ular[dashed,swap]{\exists q'}
 \end{tikzcd} \]

 Además, esto es equivalente a decir que un módulo $P$ es /proyectivo/ si toda secuencia

 \[ 0 \overset{}\longrightarrow L \overset{}\longrightarrow M \overset{}\longrightarrow P \overset{}\longrightarrow 0 \]

 es escindida, y $Q$ es /inyectivo/ si toda secuencia:

 \[ 0 \overset{}\longrightarrow Q \overset{}\longrightarrow M \overset{}\longrightarrow N \overset{}\longrightarrow 0 \]

 es escindida.

****** 6.2. Módulos proyectivos
 #+begin_theorem
 *Caracterización de proyectividad*. Un módulo es proyectivo ssi es el sumando
 directo de un módulo libre.
 #+end_theorem

 Así, la suma directa de dos módulos proyectivos es proyectiva; el producto tensor
 de dos módulos proyectivos es proyectivo, y todo módulo proyectivo es plano.

****** 6.3. Módulos inyectivos
 #+begin_theorem
 *Caracterización de inyectividad*. Un módulo es *inyectivo* ssi toda aplicación
 $f : I \longrightarrow Q$ extiende a una aplicación $\hat f : R \longrightarrow Q$, donde I es ideal de R.
 #+end_theorem

****** 6.4. El funtor Ext
 Existirían dos formas naturales de definir *Ext*, que coinciden no trivialmente:

 #+begin_definition
 *Funtor Ext*. Dado $M$ con una resolución proyectiva:

 \[ \dots \overset{}\longrightarrow P_1 \overset{}\longrightarrow P_0 \overset{}\longrightarrow M \overset{}\longrightarrow 0 \]

 aplicamos el funtor contravariante $Hom(\_,N)$ eliminando $M$ para obtener:

 \[ 0 \overset{}\longrightarrow Hom(P_0,N) \overset{}\longrightarrow Hom(P_1,N) \overset{}\longrightarrow Hom(P_2,N) \overset{}\longrightarrow \dots \]

 Y tomamos la cohomología de este complejo $Hom(M_\bullet,N)$, dejando como definición:

 \[Ext^i_R(M,N) = H^i(Hom(M_\bullet,N))\]
 #+end_definition

 #+begin_definition
 *Funtor Ext*. Dado $N$ con una resolución inyectiva:

 \[ 0 \overset{}\longrightarrow N \overset{}\longrightarrow Q_0 \overset{}\longrightarrow Q_1 \overset{}\longrightarrow \dots \]

 aplicamos el funtor covariante $Hom(M,\_)$ eliminando $N$ para obtener:

 \[ 0 \overset{}\longrightarrow 
 Hom(M,Q_0) \overset{}\longrightarrow 
 Hom(M,Q_1) \overset{}\longrightarrow 
 Hom(M,Q_2) \overset{}\longrightarrow \dots \]

 Y tomamos la cohomología de este complejo $Hom(M,N_\bullet)$, dejando como definición:

 \[Ext^i_R(M,N) = H^i(Hom(M,N_\bullet))\]
 #+end_definition

**** IX. Álgebra homológica
**** Complejos y homología, de nuevo
***** 3.1. Recordatorio de definiciones básicas
 #+begin_definition
 *Resolución*. La /resolución/ de un objeto $A$ es un complejo
 exacto excepto en un punto, donde es isomorfa a $A$.
 #+end_definition

 Esto es equivalente a tener un complejo exacto de la forma:

 \[ \dots \overset{}\longrightarrow 
 M_2 \overset{}\longrightarrow 
 M_1 \overset{}\longrightarrow 
 M_0 \overset{}\longrightarrow 
 A \longrightarrow
 0\]

***** 3.2. La categoría de los complejos
 #+begin_definition
 *Categoría de complejos de cocadenas*. La categoría $C(A)$ tiene como objetos
 los complejos de cocadenas en una categoría $A$; y como morfismos entre dos 
 cocadenas,   $Hom(M^\bullet,N^\bullet)$, los diagramas conmutativos entre ellas. Por ejemplo:

 \[ \begin{tikzcd}
 \dots \rar & M^{i-1} \rar\dar{\alpha^{i-1}} & M^{i} \rar\dar{\alpha^{i}} &  M^{i+1} \rar\dar{\alpha^{i+1}} & \dots \\
 \dots \rar & N^{i-1} \rar & N^{i} \rar & N^{i+1} \rar & \dots
 \end{tikzcd} \]

 representa el morfismo $\alpha_\bullet$.
 #+end_definition

 Esta es una categoría abeliana. De ella definiremos además dos variantes:

 - $C^+(A)$, subcategoría plena de los complejos acotados por debajo.
 - $C^-(A)$, subcategoría plena de los complejos acotados por arriba.
**** Exercises [20/62]
***** I. Preliminaries: Set theory and categories [1/1]
****** I.5. Universal properties
******* DONE Exercise I.5.12
#+begin_statement
Define notions of /fibered products/ and /coproducts/, as terminal objects of
the categories $C_{\alpha,\beta}$ and $C^{\alpha,\beta}$ considered in Example 3.10, by stating carefully
the corresponding universal properties.

As it happens, $\mathtt{Set}$ has both fibered products and coproducts. Define these
objects 'concretely', in terms of naive set theory.
#+end_statement

******** Fibered products
Given $\alpha\colon A \to C$ and $\beta \colon B \to C$, we take the objects of the category
to be commutative diagrams

\[\begin{tikzcd}[row sep=tiny]
 & A \drar{\alpha} & \\
Z\drar{g}\urar{f} && C\\
& B \urar{\beta} & &.
\end{tikzcd}\]

And morphisms to be of the form

\[\begin{tikzcd}[row sep=tiny]
& & A \drar{\alpha} & \\
Z' \rar{h}\ar[bend right]{drr}{g'} \ar[bend left]{urr}{f'} &
Z\drar{g}\urar{f} && C\\
& & B \urar{\beta} & &.
\end{tikzcd}\]

With the trivial identity $\mathrm{id}_Z \colon (Z,f,g) \to (Z,f,g)$. The terminal object
should be the one such that every other object's morphisms descompose
through it.

\[\begin{tikzcd}[row sep=tiny]
& & A \drar{\alpha} & \\
Z' \rar[dashed]{\exists! h}\ar[bend right]{drr}{g'} \ar[bend left]{urr}{f'} &
F\drar{\pi_{\beta}}\urar{\pi_{\alpha}} && C\\
& & B \urar{\beta} & &.
\end{tikzcd}\]

******** Fibered coproducts
The same idea can be applied to the dual construction

\[\begin{tikzcd}[row sep=tiny]
& & A \dlar{\iota_A}\ar[bend right]{lld}{f'} & \\
Z &
F \lar[dashed]{\exists! h} && 
C \ular{f}\dlar{g}\\
& & B \ular{\iota_B}\ar[bend left]{llu}{g'} & &.
\end{tikzcd}\]

******** In the category of sets
In $\mathtt{Set}$, the fibered product will be

\[
\left\{ (a,b) \in A \times B \mid \alpha(a) = \beta(b) \right\},
\]

as we can show using the product universal property. The fibered coproduct
is the coproduct divided by the equivalence relation generated by the
pairs $a \sim b$ such that $\exists c\colon a = f(c), b = g(c)$.

***** II. Groups, first encounter [16/28]
****** II.1. Definition of group
******* DONE Exercise II.1.1
#+begin_statement
Write a careful proof that every group is the group of isomorphisms of a
grupoid. In particular, every group is the group of automorphisms of some
object in some category.
#+end_statement

Given a group $(G,\bullet)$, we can define an object $G$ with morphisms the elements
of the group. Composition will be the binary operation of the group, and we
can check, using the group properties, that category axioms hold

 1. *Identity*, there is an identity element on $G$ which acts as the identity
    morphism: $e \circ a = a = a \circ e$.
 2. *Associativity* holds directly: $a \circ (b\circ c) = (a \circ b)\circ c$.

This only object defines a category which is also a grupoid, as every arrow
has an *inverse* by the last property of groups: every element of the group has
an inverse.

******* DONE Exercise II.1.2
#+begin_statement
Consider the 'sets of numbers' listed in 1.1, and decide which are made into 
groups by conventional operations such as $+$ and $\cdot$. Even if the answer is negative,
see if variations on the definition of these sets lead to groups.
#+end_statement

******** The empty set
It is not a group, as it has no identity.

******** Naturals
They form no group with addition, as not every element has an inverse.

******** Integers
They are a commutative group with the addition.

******** Rational numbers
They are a group with addition, and also a group with multiplication if we
consider $0$ out of the group.

******** Real numbers
They follow the same logic as the rationals.

******** Complex numbers
Same logic as the rationals.
******* TODO Exercise II.1.3
******* TODO Exercise II.1.4
******* TODO Exercise II.1.5
******* TODO Exercise II.1.6
******* TODO Exercise II.1.7
******* TODO Exercise II.1.8
******* TODO Exercise II.1.9
******* TODO Exercise II.1.10
******* TODO Exercise II.1.11
******* TODO Exercise II.1.12
******* DONE Exercise II.1.13
#+begin_statement
Give an example showing that $|gh|$ is not necessarily equal to $\mathrm{lcm}(|g|,|h|)$, even
if $g$ and $h$ commute.
#+end_statement

In $(\mathbb{Z}/\mathbb{Z}_4,+)$, we have $\mathrm{lcm}(|1|,|1|) = |1| = 4$, but $|1+1| = 2$.

******* DONE Exercise II.1.14
#+begin_statement
As a counterpoint to [[*Exercise II.1.13][Exercise 13]], prove that if $g$ and $h$ commute, 
and $\mathrm{gcd}(|g|,|h|) = 1$, then $|gh| = |g||h|$.
#+end_statement

We know that $|gh| = N \mid |g||h|$. If we divide to obtain $g^{N} = (h^{-1})^{N}$, we have

 * $1 = \left( g^{-1} \right)^{N|g|} = h^{N|g|}$
 * $1 = \left( h^{-1} \right)^{N|h|} = g^{N|h|}$

and then, $|h| \mid N|g|$ and they are coprimes, so $|h| \mid N$. Likewise, $|g| \mid N$.
Finally, $|gh| = \mathrm{lcm}(|h|,|g|) \mid N$.

******* DONE Exercise II.1.15
#+begin_statement
Let $G$ a commutative group, and let $g \in G$ be an element of maximal /finite/
order: that is, such that if $h \in G$ has finite order then $|h| \leq |g|$. Prove that
in fact if $h$ has finite order in $G$ then $|h|$ divides $|g|$.
#+end_statement

If $|h|$ does not divide $|g|$, then there is a prime $p$ such that

 * $|h| = p^{a+b}m$
 * $|g| = p^bn$, with $\mathrm{gcd}(n,p) = 1$.

then we know that $|h^m| = p^{a+b}$ and $|g^{p^b}| = n$. Using [[*Exercise II.1.14][exercise 14]] (we are in a
commutative group), we know that $|g^{p^b}h^m| = p^{a+b}n$, contradicting maximality.

****** II.2. Examples of groups
******* DONE Exercise II.2.2
#+begin_statement
Prove that if $d \leq n$, then $S_n$ contains elements of order $d$.
#+end_statement

The element $(1\;2\;\dots\;d)$ has order $d$.

******* TODO Exercise II.2.5
****** II.3. The category Grp
******* DONE Exercise II.3.1
#+begin_statement
Let $\varphi\colon G \to H$ be a morphism in a category $C$ with products. Explain why there
is a unique morphism

\[(\varphi\times\varphi)\colon G\times G \to H \times H.\]
#+end_statement

The real morphism is $(\varphi\circ \pi_1 \times \varphi \circ \pi_2)$, using the projections from $C$ as presented
in the following diagram

\[\begin{tikzcd}[column sep=small,row sep=tiny]
& G \times G\drar\dlar\ar[dashed]{dd}{\varphi\times\varphi} & \\
G\ar{dd} & & G\ar{dd} \\
& H \times H\drar\dlar & \\
H & & H \\
\end{tikzcd}\]

******* DONE Exercise II.3.8
#+begin_statement
Define a group $G$ with two generators $x,y$, subject (only) to the relations
$x^2=e$, $y^3=e$. Prove that $G$ is a coproduct of $C_2$ and $C_3$ in $\mathtt{Grp}$.
#+end_statement

Given any two morphisms $f\colon C_2 \to H$ and $g \colon C_3 \to H$, we define $h(x) = f(1)$ 
and $h(y) = g(1)$ as it should be to make the diagram commutative. There is
only a possible way to extend this morphism to $h \colon G \to H$.

****** II.4. Group homomorphisms
******* DONE Exercise II.4.3
#+begin_statement
Prove that a group of order $n$ is isomorphic to $\mathbb{Z}/n\mathbb{Z}$ if and only if it
contains an element of order $n$.
#+end_statement

If it contains $a$ of order $n$, then $e,a,a^2,\dots,a^{n-1}$ are $n$ different elements.
As the group is of order $n$, they constitute the whole group.

******* DONE Exercise II.4.8
#+begin_statement
Let $G$ be a group, and $g \in G$. Prove that the function $\gamma_g \colon G \to G$ defined
by $\gamma_g(a) = gag^{-1}$ is an automorphism of $G$. Prove that the function $G \to \mathrm{Aut}(G)$
defined by $g \mapsto \gamma_g$ is a homomorphism. Prove that this homomorphism is trivial
if and only if $G$ is abelian.
#+end_statement

The function $\gamma_g$ is trivially a homomorphism, and it has the inverse $\gamma_{g^{-1}}$.
We can check that $g\mapsto \gamma_g$ is a homomorphism, as

\[
\gamma_h\gamma_g(a) = hga(hg)^{-1} = \gamma_{hg}(a).
\]

If the homomorphism is trivial, $a = gag^{-1}$ for any $a,g \in G$; this is 
equivalent to abelianity.

******* DONE Exercise II.4.11
#+begin_statement
In due time, we will prove the easy fact that if $p$ is a prime integer then
the equation $x^d=1$ can have at most $d$ solutions in $\mathbb{Z}/p\mathbb{Z}$. Assume this fact,
and prove that the multiplicative group $G = (\mathbb{Z}/p\mathbb{Z})^{\ast}$ is cyclic.
#+end_statement

If the group is not cyclic there is no element of order $p-1$. So the element
of maximal order has order $d < p-1$, and every other element has a [[*Exercise II.1.15][divisor
of this order]] as its order. Then the equation $x^d = 1$ has more than $p-1$ roots,
contradicting the assumption.

******* TODO Exercise II.4.16
#+begin_statement
Prove /Wilson's theorem/: a positive integer $p$ is prime if and only if

\[(p-1)! \equiv -1  \mod p.
\]
#+end_statement

We are multiplying all elements of $(\mathbb{Z}/p\mathbb{Z})^{\ast} \cong (\mathbb{Z}/(p-1)\mathbb{Z})$

****** II.5. Free groups
******* DONE Exercise II.5.3
#+begin_statement
Use the universal property of free groups to prove that the map $j \colon A \to F(A)$ is
injective, for all sets $A$.
#+end_statement

If it were not injective, with $j(a) = j(b)$, every $f \colon A \to G$ should follow 
$f(a)=f(b)$, but given any two $a,b$ we can define $f \colon A \to \mathbb{Z}\times\mathbb{Z}$ by sending
$f(a) = (1,0)$, $f(b) = (0,1)$, and every other element to $0$.

******* DONE Exercise II.5.6
#+begin_statement
Prove that the group $F(\left\{ x,y \right\})$ is a coproduct $\mathbb{Z}\ast\mathbb{Z}$ of $\mathbb{Z}$ by itself in the
category $\mathtt{Grp}$.
#+end_statement

Given $d \colon \left\{ a,b \right\} \to G$, we use the coproduct inclusions on $\mathtt{Set}$ to define 
individual arrows

\[\begin{tikzcd}[column sep=tiny]
& G & \\
& \left\{ a,b \right\}\uar{d} & \\
\left\{ a \right\} \arrow[bend left]{uur} \urar{i} & & 
\left\{ b \right\} \arrow[bend right]{uul} \ular[swap]{i}
\end{tikzcd}\]

and then simply use the universal property of the free modules of one
element as follows

\[\begin{tikzcd}[column sep=small]
& G & \\
& \mathbb{Z}\ast\mathbb{Z} \uar[dashed] & \\
\mathbb{Z}\ar{ur}\ar[dashed,bend left]{uur} & & 
\mathbb{Z}\ar{ul}\ar[dashed,bend right]{uul} \\
& \left\{ a,b \right\} \ar[dashed]{uu} &\\
\left\{ a \right\}\urar \arrow[bend left=90]{uuuur}  \ar{uu} &&
\left\{ b \right\}\ular \arrow[bend right=90]{uuuul} \ar{uu}
\end{tikzcd}\]

******* DONE Exercise II.5.7
#+begin_statement
Extend the result of [[*Exercise II.5.6][Exercise 5.6]] to free groups $F(\left\{ x_1,\dots,x_n \right\})$ and to free
/abelian/ groups $F^{ab}(\left\{ x_1,\dots,x_n \right\})$.
#+end_statement

The same argument can be repeated $n$ times to obtain $\mathbb{Z}\ast \overset{n}\dots \ast\mathbb{Z}$ as free group.
As $\mathbb{Z}\oplus\mathbb{Z}$ is the abelian coproduct, $\mathbb{Z}\oplus\dots\oplus\mathbb{Z}$ is the free group.

****** II.6. Subgroups
******* DONE Exercise II.6.1
#+begin_statement
The group of invertible $n \times n$ matrices with entries in $\mathbb{R}$ is denoted $GL_n(\mathbb{R})$.
Similarly, $GL_n(\mathbb{C})$ denotes the group of $n \times n$ invertible matrices with complex
entries. Consider the following sets of matrices:

 * $SL_n(\mathbb{R}) = \left\{ M \in GL_n(\mathbb{R}) \mid \mathrm{det}(M)=1 \right\}$;
 * $SL_n(\mathbb{C}) = \left\{ M \in GL_n(\mathbb{C}) \mid \mathrm{det}(M)=1 \right\}$;
 * $O_n(\mathbb{R}) = \left\{ M \in GL_n(\mathbb{R}) \mid MM^t = M^tM = I_n \right\}$;
 * $SO_n(\mathbb{R}) = \left\{ M \in O_n(\mathbb{R}) \mid \mathrm{det}(M)=1 \right\}$;
 * $U(n) = \left\{ M \in GL_n(\mathbb{C}) \mid MM^{\dag} = M^{\dag}M = I_n \right\}$;
 * $SU(n) = \left\{ M \in U_n(\mathbb{C}) \mid \mathrm{det}(M) = 1 \right\}$;

Here $I_n$ stands for the $n \times n$ identity matrix, $M^t$ is the /transpose/ of $M$,
$M^{\dag}$ is the /conjugate transpose/ of $M$, and $\mathrm{det}(M)$ denotes the /determinant/
of $M$. Find all possible inclusions among these sets, and prove that in every
case the smaller set is a subgroup of the larger one.
#+end_statement

We are dealing with three different properties:

  1. The matrix has entries in $\mathbb{C}$.
  2. The matrix has its conjugate transpose as its inverse, $MM^{\dag}=I_n$.
  3. The matrix has determinant $1$, $\mathrm{det}(M) = 1$.

None of them implies the others. The three properties give rise to this 
three-dimensional cube

\[\begin{tikzcd}[column sep=tiny, every arrow/.append style={dash}]
&& GL(\mathbb{C}) & \\
& U(n) \urar & SL_n(\mathbb{C})\uar & GL(\mathbb{R})\ar{ul} \\
& SU(n) \uar\ar{ur} & O_n(\mathbb{R}) \ular\urar & SL_n(\mathbb{R}) \ular\uar\\
&& SO_n(\mathbb{R})\uar \urar\ular & & .
\end{tikzcd}\]

******* DONE Exercise II.6.3
#+begin_statement
Prove that every matrix in $SU(2)$ may be written in the form

\[\begin{pmatrix}
a+bi & c+di \\
-c+di & a-bi
\end{pmatrix}\]

where $a,b,c,d \in \mathbb{R}$ and $a^2+b^2+c^2+d^2 = 1$. (Thus, $SU(2)$ may be
realized as a three-dimensional sphere embedded in $\mathbb{R}^4$; in particular,
it is /simply connected/.)
#+end_statement

If we take $\alpha,\beta,\gamma,\delta \in \mathbb{C}$, and create a special unitary matrix, we have 
the relationships

 * $|\alpha|+|\beta| = 1$
 * $\alpha\delta-\beta\gamma = 1$
 * $\alpha\overline{\gamma} + \beta\overline{\delta} = 0$

that are solved by $\alpha = \overline{\delta}$ and $\beta = -\overline{\gamma}$, while the first one gives us the
sphere condition.

***** III. Rings and modules [3/15]
****** III.1. Definition of a ring
******* DONE Exercise III.1.1
#+begin_statement
Prove that if $0=1$ in a ring $R$, then $R$ is a zero-ring.
#+end_statement

By definition,

\[
r = 1r = 0r = 0r+0r = 0.
\]

****** III.5. Modules over a ring
******* DONE Exercise III.5.4
#+begin_statement
Let $R$ be a ring. A nonzero $R\text{-module}$ is /simple/ (or /irreducible/) if its
only submodules are $\left\{ 0 \right\}$ and $M$. Let $M,N$ be simple modules, and let
$\varphi \colon M \to N$ be a homomorphism of $R\text{-modules}$. Prove that either $\varphi = 0$, or
$\varphi$ is an isomorphism. (This rather innocent statement is known as *Schur's 
Lemma*.)
#+end_statement

The kernel and image of $\varphi$ will be submodules, they only can be the total
submodule or the zero submodule, as $M,N$ are simple modules. There are two 
cases

  - If $\operatorname{ker}\phi = \{0\}$, it is a monomorphism. Its image must be different
    from $0$, thus it must be $N$.

  - If $\operatorname{ker} \phi = M$, we have $\phi = 0$.

****** III.6. Products and coproducts in R-Mod
******* CHECK Exercise III.6.16
#+begin_statement
Let $R$ be a ring. A (left-)$R\text{-module}$ $M$ is /cyclic/ if $M = \left\langle m \right\rangle$ for
some $m \in M$. Prove that simple modules (cf. Exercise 5.4) are cyclic.
Prove that an $R\text{-module}$ $M$ is cyclic if and only if $M \cong R/I$ for some
(left-)ideal $I$. Prove that every quotient of a cyclic module is cyclic.
#+end_statement

******** Un módulo simple es cíclico
Tomemos un elemento suyo cualquiera y
creamos $<m>$. Ocurre que debe ser un submódulo y por ser simple, todo
el módulo.

******** Un cociente por ideal es cíclico.
 Sea $M = R/I$, un módulo sobre $R$ podemos generarlo simplemente 
 por $<1>$, luego es cíclico.
 Sea $M=<m>$ un módulo cíclico. Podemos tomar un isomorfismo que lleve
 $r \mapsto rm$ y definir $I = \{r\;|\;rm=0\}$. Por 1er Teorema de isomorfía:

 \[M \cong R/ker(\phi) \cong R/I\]

******** Todo cociente de cíclico es cíclico.
Usando el tercer teorema de isomorfía:

\[\frac{\frac{R}{I}}{J} \cong \frac{\frac{R}{I}}{\frac{I+J}{I}} \cong \frac{R}{I+J}\] (?)

****** III.7. Complexes and homology
******* TODO Exercise III.7.1. Exactitud entre ceros.

 \[ \dots \overset{}\longrightarrow 0 \overset{}\longrightarrow M \overset{}\longrightarrow 0 \overset{}\longrightarrow \dots \]

 Tenemos que el núcleo de la segunda debe ser igual a la imagen de la primera y
 por tanto, cero. Eso sólo es posible si $M=0$.

******* TODO Exercise III.7.2. Exactitud entre isomorfías
     \[ \dots \overset{}\longrightarrow 0 \overset{}\longrightarrow M \overset{}\longrightarrow M' \overset{}\longrightarrow 0 \longrightarrow \dots\]
 Tenemos por el primer 0 la función inyectiva y por el segundo la función 
 sobreyectiva. Debe ser por tanto isomorfismo.

******* TODO Exercise III.7.3. Kernel y cokernel en secuencia exacta
     \[ \dots \overset{}\longrightarrow 0 \overset{}\longrightarrow L \overset{}\longrightarrow M 
     \overset{\phi}\longrightarrow M' \longrightarrow N \longrightarrow 0 \longrightarrow \dots \]
 Por el primer 0 tengo una inyección $i$ de $L$ en $M$, que lo identifica con
 $im(i) = ker(\phi)$. Del segundo 0 tengo que la imagen de la proyección $\pi$ de
 $M'$ en $N$ es todo $N$. Entonces, por teorema de isomorfía y por exactitud:

 \[N = im(\pi) \cong \frac{M'}{ker(\pi)} = \frac{M'}{im(\phi)} = coker(\phi)\]

******* TODO Exercise III.7.4. Hotel de Hilbert
 Dada una secuencia de enteros, podemos moverla un paso a la derecha:

 \[(a_1,a_2,a_3,\dots) \longrightarrow (0,a_1,a_2,\dots)\] 

 Para tener el morfismo $\alpha$ que nos da la secuencia exacta:

 \[ 0 \overset{}\longrightarrow \mathbb{Z}^{\oplus \mathbb{N}} \overset{\alpha}\longrightarrow \mathbb{Z}^{\oplus \mathbb{N}} \overset{\pi_1}\longrightarrow \mathbb{Z} \overset{}\longrightarrow 0 \]

 Dada una secuencia de enteros, podemos moverla a los sitios pares y hacer
 proyección de los impares luego:

 \[(a_1,a_2,a_3,\dots) \longrightarrow (0,a_1,0,a_2,0,a_3,\dots)\]

 Para tener los morfismos $\beta$ y $\pi$ que nos dan la secuencia exacta:

 \[ 0 \overset{}\longrightarrow \mathbb{Z}^{\oplus \mathbb{N}} \overset{\beta}\longrightarrow \mathbb{Z}^{\oplus \mathbb{N}} \overset{\pi}\longrightarrow \mathbb{Z}^{\oplus \mathbb{N}} \overset{}\longrightarrow 0 \] 

******* TODO Exercise III.7.5. Exactitud entre noetherianos
 Tenemos la secuencia exacta:

 \[ \dots \overset{}\longrightarrow L \overset{\alpha}\longrightarrow M \overset{\beta}\longrightarrow N \overset{}\longrightarrow \dots \]

 Y supongamos $L,N$ noetherianos. Sea entonces una sucesión de ideales \(\{M_i\}\),
 tenemos que las sucesiones de ideales \(\{\alpha^{-1}(M_i)\}\) y \(\{\beta(M_i)\}\) se estabilizarán
 a partir de un cierto $j$. Tomando un $i > j$ tendremos que $M_i = M_{i+1}$ y por tanto,
 se estabilizará la secuencia inicial.

 Supongamos que existiera $x \in M_{i+1}$ pero $x \notin M_i$. Dividimos en dos casos:

 *Caso 1*. $x \in im(\alpha)$, tendríamos que existiría algún elemento 
 $a \in \alpha^{-1}(x) \subset \alpha^{-1}(M_{i+1}) = \alpha^{-1}(M_{i})$, pero por definición entonces $x = \alpha(a) \in M_i$.

 *Caso 2*. $x \notin im(\alpha)$, tendríamos $\beta(x) \in \beta(M_{i+1})$. Existe un $y \in M_i$ tal que 
 $\beta(y) = \beta(x)$, es decir, $x-y \in ker(\beta)$. Pero entonces $x-y \in im(\alpha)$ y por tanto,
 $x-y \in M_i$, llevando a $x\in M_i$.

******* TODO Exercise III.7.6. Epimorfismo escindido
 Sea una sucesión:

 \[ 0 \overset{}\longrightarrow ker(\phi) \overset{}\longrightarrow M \overset{\phi}\longrightarrow N \overset{}\longrightarrow 0 \]

 Supongamos que *escinde*, entonces $\phi$ es la proyección hacia $N$ y tiene
 como inversa derecha a la inclusión.

 Supongamos que *tiene inversa* derecha $\psi$, entonces buscamos un isomorfismo
 entre $M \cong ker(\phi) \oplus N$, que tenemos con estos dos morfismos:

 \[(k,n) \mapsto \psi n + k\]
 \[m \mapsto (m-\psi \phi m, \phi m)\]

******* TODO Exercise III.7.10. Lema corto de los cinco 
 Si en el lema de la serpiente son $\lambda$ y $\nu$ isomorfismos, tenemos la sucesión:

 \[0 \longrightarrow 0 \longrightarrow ker(\mu) \longrightarrow 0 \overset{\delta}\longrightarrow
   0 \longrightarrow coker(\mu) \longrightarrow 0 \longrightarrow 0\]

 Por tanto, el kernel y cokernel de $\mu$ son nulos y es isomorfismo.

******* TODO Exercise III.7.11. Todo morfismo de escisión es isomorfismo
 Directamente aplicando el ejercicio anterior, tenemos que $N \cong M_1 \oplus M_2$.

******* TODO Exercise III.7.12. Lema de los cuatro (1)
 Lo probamos por caza del diagrama. Primero tomamos un elemento en el núcleo
 de C y aplicamos:

 - Inyectividad de $\delta$. 
 - Exactitud de $BCD$.
 - Exactitud de $ABC$.
 - Sobreyectividad de $\alpha$.
 - Exactitud de $ABC$.

 Teniendo que el elemento es nulo.

******* TODO Exercise III.7.13. Lema de los cuatro (2)
 Volvemos a cazar diagramas. Tomamos un $c'$ en $coker(\gamma)$ y hacemos:

 - Exactitud de CDE.
 - Inyectividad en E.
 - Sobreyectividad de D.
 - Exactitud de CDE.

 Y así llegamos a un $z \in C$ que tiene como imagen un $z' \in C'$. Tomamos $c'-z'$,
 que tiene imagen nula en $D$ y aplicamos:

 - Exactitud de BCD.
 - Sobreyectividad en $B$.

 Y obtenemos un $x \in C$ que tiene como imagen a $c'-z'$. Finalmente: $\gamma(x+z) = c'$.

******* TODO Exercise III.7.14. Lema de los cinco
 Trivial uniendo ambos lemas de los cuatro.

***** VI. Linear Algebra [0/13]
****** VI.1. Free modules revisited
******* TODO Exercise VI.1.1. R y C son isomorfos como espacios vectoriales de Q
Sabemos que $C \cong R \oplus R$. Dada una base $B$ de $\mathbb{R}$, podemos ver que será
infinita y por axioma de elección isomorfa a $B+B$, que será a su
vez una base de $\mathbb{R}^2$. Luego $\mathbb{R} \cong \mathbb{R} \oplus \mathbb{R}$.

******* TODO Exercise VI.1.4. Álgebras de Lie
 Demostramos que $[u,v] = -[v,u]$. Ya que tenemos:

 $$[u,v] + [v,u] = [u,v] + [u,u] + [v,v] + [v,u] = [u+v,v] + [u+v,u] = [u+v,u+v] = 0$$

 Para todas las K-álgebras, tomar $[v,w] = vw-wv$ nos da un álgebra de Lie.
 Podemos verlo porque cumple las tres primeras propiedades que se le piden a un
 álgebra de Lie y además:

 \begin{align*}
 [[u,v],w] + [[v,w],u] + [[w,u],v] & = \\
 (uvw-vuw-wuv+wvu) &+\\
 (vwu-wvu-uvw+uwv) &+\\
 (wuv-uwv-vwu+vuw) &=\\
 0
 \end{align*}

******* TODO Exercise VI.1.5. Sistemas generadores e independientes en dominios de integridad
 Un sistema independiente puede no crecer a base y un sistema generador
 puede no reducirse a base en un dominio de integridad. Como ejemplos
 tenemos $\mathbb{Z}$ con: {2} como sistema independiente y $\{2,3\}$ como sistema generador.
 Ninguno puede crear base porque las únicas bases posibles serían $\{1\}$ y $\{-1\}$.

******* TODO Exercise VI.1.13. Un grupo abeliano con endomorfismos de característica 0.
 Si tiene endomorfismos que forman un cuerpo de característica 0, podemos
 identificar $\mathbb{Z}$ con los endomorfismos por propiedad universal y
 luego podemos extenderlo por contener $Q$ las inversas. De otro modo, 
 $Q$ es inicial en la categoría de cuerpos de característica 0, así, hay
 forma de identificarlo con endomorfismos del cuerpo.

 Así, nuestro grupo $A$ es espacio vectorial sobre $Q$. Y es de dimensión 1,
 porque si tuviera dimensión mayor y una base de más de un elemento, colapsar
 dos elementos de la base en uno sería un endomorfismo sin inversa.

******* TODO Exercise VI.1.14. La potencia de un isomorfismo estabiliza kernel e imagen.
 Tenemos que $ker(\phi^n) \subset ker(\phi^{n+1})$ y que dos subespacios contenidos de la misma
 dimensión deben ser iguales. Por tanto, la dimensión debe crecer o estabilizarse
 a cada paso. Si la dimensión es finita debe estabilizarse en algún punto.

 Por otro lado, tenemos que las imágenes deben estabilizarse en dimensión
 para tener $ker(\phi^n) \oplus im(\phi^{n+1}) = V$. Y entonces, para que el kernel no crezca,
 ninguno de los vectores que forman la base de $im(\phi^n)$ pueden tener como
 imagen algo que esté en $ker(\phi)$, así que vuelven a tener como imagen algo en
 $im(\phi^{n+1})$, que debe estar contenido en $im(\phi^n)$ y ser de la misma
 dimensión.

****** VI.2. Homomorphisms of free modules I
******* TODO Exercise VI.2.1. Grupo isomorfo a la suma
 Tenemos que:

 \[
 \left( \begin{matrix} 1 & 0 \\ r & 1 \end{matrix} \right)
 \left( \begin{matrix} 1 & 0 \\ p & 1 \end{matrix} \right) =
 \left( \begin{matrix} 1 & 0 \\ r+p & 1 \end{matrix} \right)
 \]

 Luego la proyección del tercer elemento es un isomorfismo
 de grupos.

******* TODO Exercise VI.2.6. Row echelon form
 Cuando trabajamos en un cuerpo podemos pasar a /row echelon form/ usando
 los siguientes pasos:

  - Pasamos el primer elemento no nulo a la fila más alta.
  - Lo hacemos uno con su inversa y reducimos toda la columna restante.
  - Hacemos lo mismo con la submatriz a la derecha y debajo de ese 1.

 Esto debe dejarnos sólo ceros debajo y encima de los 1 pivotes.

****** VI.4. Presentations and resolutions
******* TODO Exercise VI.4.1. Tor(M) es submódulo de M cuando R es dominio de integridad.
 Tenemos $Tor(M) = \{ m | \exists r \in R : r \neq 0, rm = 0\}$, y siendo dos elementos $m,n$ en $Tor(M)$, 
 que cumplen que $rm = 0$ y $qn = 0$, podemos
 ver que su suma será cerrada y que el producto por $r\in R$ será cerrado cuando
 $R$ es conmutativo:

  - $rq(m+n) = rqm+qrn = 0+0 = 0$
  - $r(pm) = p(rm) = 0$

 Usando aquí que es dominio de integridad y por tanto $rq \neq 0$.

******* TODO Exercise VI.4.2. Hom(M,N) es libre de torsión cuando lo es N.
 Supongamos que no lo fuera, existiría un $f \in Hom_R(M,N)$ tal que 
 $rf = 0$ para algún $r$ no divisor de $0$. Pero entonces, esto haría
 que en el anillo $N$ existiese $rf(m) = 0$ para cualquier $m$, y por 
 ser libre de torsión, se tendría $f(m) = 0$ para todo $m$.
 Luego $f=0$.

 En particular $Hom_R(M,R)$ es libre de torsión.

******* TODO Exercise VI.4.4. Propiedades del anulador
 Suponiendo $p,q \in Ann(R)$, tenemos que para todo $m \in M$ se tendrá
 $pm=0$ y $qm=0$. Por lo tanto $(p+q)m=0$ y $rpm = 0$, haciéndolo ideal.

******** M de torsión si y sólo si el anulador es no nulo.
 Si $Ann(M) \neq 0$, existe un elemento de $R$ que anula todo $M$, como
 además $R$ es dominio de integridad, este elemento no será divisor de 0, y $M$
 será torsión. Si $M$ es torsión y finitamente generado, tendrá un elemento
 $r_i$ que anulará cada uno de sus generadores $m_i$. Siendo $R$ conmutativo,
 el elemento producto estará en el anulador

                      \[
 \prod_{i} r_i
 \] 

 Nótese que si quitamos la condición de que $M$ sea finitamente generado, existen
 módulos como \(\mathbb{Z}_2 \oplus \mathbb{Z}_4 \oplus \mathbb{Z}_8 \dots\) que son torsión porque todo elemento se anula pero
 tienen anulador vacío porque no existen elementos que anulen todo el módulo.

******* TODO Exercise VI.4.13. Complejo de Koszul

******** Es un complejo.
 Comprobamos que es un complejo viendo que las siguientes composiciones son $0$:

  - \(d_1 \circ d_2 (t) = bta - atb = 0\)
  - \(\pi \circ d_1 (r,s) = (ra+sb)\ mod(a,b)) = 0 \)

******** Es un complejo exacto cuando la secuencia es regular.
 Y comprobamos que es exacto en el caso en el que la secuencia es regular viendo
 que:

 - \(ker(d_2) = 0\), ya que $a$ no es divisor de cero.
 - \(ker(d_1) = <(b,-a)>\). Tenemos que $b$ no es divisor de cero módulo $a$, así, para que
   sea linealmente dependiente con $a$ necesitamos algo que sea cero módulo $a$. Este
   caso requiere $s$ múltiplo de $a$. Esto requiere estar dentro del ideal generado por
   $(b,-a)$.
 - Que la imagen de $d_1$ es el núcleo de $\pi$ y que la proyección es sobreyectiva
   es trivial.

******* TODO Exercise VI.4.14. Complejo de Koszul en el caso de 3 elementos
******** Es un complejo
 Volvemos a comprobar que las composiciones son nulas. Tenemos de hecho que:

 \[d_2 \circ d_1 = d_3 \circ d_2 = 0\]

 Y que la proyección coincide con el generado por $d_1$.

******** Es un complejo exacto cuando la secuencia es regular
 Otra vez, como $c$ no es divisor de cero módulo $(a,b)$, tenemos que el kernel
 de $d_3$ es nulo. De la misma forma, se tiene que el $ker(d_2)=im(d_3)$, aplicando
 en cada caso el no ser divisor de cero. Vuelve a tenerse una ecuación similar
 que demuestra $ker(d_1) = im(d_2)$. El caso de la proyección es trivial.
******* TODO Exercise VI.4.15. Resolución de Z sobre Z[x,y]
 Podemos encontrar una resolución como:

 \[0 \longrightarrow 
 \mathbb{Z}[x,y] \overset{\phi} \longrightarrow 
 \mathbb{Z}[x,y]^2 \overset{\delta} \longrightarrow 
 \mathbb{Z}[x,y] \overset{\pi} \longrightarrow 
 \mathbb{Z} \longrightarrow 0 \]

 Donde $\pi$ es un morfismo que cancela $x,y$. $\delta$ es un morfismo que lleva
 cada una de las copias del $1$ a $x$ e $y$. Finalmente, $\phi$ es monomorfismo
 que lleva $1$ a $(y,-x)$ que es generador de $ker(\delta)$.

***** VIII. Linear algebra, reprise [0/5]
****** VIII.1. Preliminaries, reprise
******* TODO Exercise VIII.1.2. Funtor plenamente fiel respeta isomorfías 
 Sea ${\cal F}(A) \cong {\cal F}(B)$, gracias a dos morfismos inversos $\alpha,\beta$. Como
 el funtor es pleno, existen dos morfismos preimagen de ambos
 llamados $\alpha',\beta'$ y tenemos que:

 \[{\cal F}(\alpha' \circ \beta') = \alpha \circ \beta = 1\]

 Por ser fiel, debemos tener $\alpha' \circ \beta' = 1$.
******* TODO Exercise VIII.1.3. Acción de grupo como funtor
 Sea $G$ un grupo. Su acción sobre un objeto $C$ será un morfismo que
 envíe cada elemento del grupo a un isomorfismo de $C$. Es decir, un
 homomorfismo de grupos:

 \[(G,\ast) \longrightarrow (Aut(C),\circ)\]

 Pero como podemos ver $G$ como un objeto tal que cada uno de sus elementos
 sea un isomorfismo, tenemos claramente un isomorfismo:

 \[(Aut(G),\circ) \cong (G,\ast) \longrightarrow (Aut(C),\circ)\]

 Y podemos definir el funtor que lleva $G$ a $C$ y que lleva cada endomorfismo
 de $G$ a uno de $C$.

******* TODO Exercise VIII.1.17. Compleción de un álgebra
 Tenemos que los $R/I^n$ son módulos en R-Mod, por tanto, la cadena siguiente
 tendrá límite. Donde los morfismos serán las inclusiones naturales:

 \[\dots \longrightarrow R/I^3 \longrightarrow R/I^2 \longrightarrow R/I \]

 Ese límite lo llamamos $R_I$, y es el submódulo de secuencias coherentes de $\prod_i R/I^i$.
 Es decir, un elemento suyo es una secuencia tal que cada elemento es la proyección
 del siguiente. Este submódulo es conmutativo porque lo es el producto de todos los módulos.

 Podemos incluir $R$ en $R_I$ llevando el $1$ a $(1,1,1,\dots)$. Y esto conmutará con las
 proyecciones naturales que nos daba la propiedad universal.
 Para que $x$ se anule al incluirlo en $R_I$ desde $R$, necesitamos que todas las proyecciones
 de su imagen sean $0$, así que necesitamos que pertenezca a $I_n$ para cada $n$.

******* TODO Exercise VIII.1.19. Enteros p-ádicos
 Llamamos enteros p-ádicos al límite $\mathbb{Z}_p = \varprojlim \mathbb{Z}/p^i\mathbb{Z}$, y números p-ádicos a su cuerpo de fracciones
 $\mathbb{Q}_p$. Por definición, un entero p-ádico es una secuencia de enteros $\{a_i\}$ tales que:

 \[ a_s \equiv a_r  \mod (p^s)\]

 Para cualesquiera $s \leq r$. De otra forma, cada entero tiene una expansión única:

 \[ A = b_0 + b_1 p + b_2 p^2 + b_3 p^3 + \dots\]

 Donde $b_i < p$. Esto es así porque dada una secuencia $(a_i)$, tenemos la igualdad:

 \[b_0 = a_0\]
 \[b_i p^i + a_{i+1} = a_i\]

 Y se puede construir una desde la otra usando que $a_i - a_{i+1} \equiv_{p^i} 0$. 

 A partir de aquí podemos hacer aritmética como usualmente desde estos desarrollos de los
 números p-ádicos.
****** VIII.2. Tensor products, and the Tor functors
******* TODO Exercise VIII.2.14. Tor en 0 es el producto tensor
 La definición inicial de Tor es como:

 \[Tor^R_i(M,N) = H_i(M_\bullet \otimes N)\]

 Y como tenemos que el complejo $M_\bullet \otimes N$ es el siguiente,
 siendo $S_0$ una base de $M$, y $S_1$ base de las relaciones de $M$:

 \[ \dots \overset{}\longrightarrow N^{\oplus S_2} 
 \overset{\phi_2}\longrightarrow N^{\oplus S_1} 
 \overset{\phi_1}\longrightarrow N^{\oplus S_0} 
 \overset{}\longrightarrow 0 \]

 Que ha salido de tensar el siguiente complejo exacto:

 \[ \dots \overset{}\longrightarrow R^{\oplus S_1} \overset{\psi_2}\longrightarrow R^{\oplus S_0} \overset{\psi_1}\longrightarrow M \overset{}\longrightarrow 0 \]

 Tenemos que:

 \[H_i(M_\bullet \otimes N) \cong \frac{N^{\otimes S_0}}{im(\phi_1)} \cong 
 \frac{R^{\otimes S_0}}{im(\psi_2)} \otimes N \cong M \otimes N \]

 Donde usamos la exactitud de la segunda secuencia con el primer teorema de isomorfía
 y el hecho de que el functor $\otimes N$ respeta los colímites y por tanto el cociente, que puede
 verse como coecualizador.
*** An introduction to homological algebra - Rotman
**** 1. Introduction
***** 1.1. Simplicial Homology
****** Motivation: Green's Theorem
******* Original statement
Let $C$ be a positively oriented, smooth and simple closed curve in
a plane; being $D$ the region bounded by $C$. If $L,M$ have continuous
partial derivatives in $D$, then:

\[ \oint_C (L dx + M dy) = 
\iint_D \left(
  \frac{\partial M}{\partial x} - \frac{\partial L}{\partial y}
\right) dx dy\]

******* A rewrite
If we have some "bad points" that we want to delete from $C$.
We can define multiple $\gamma_i$ around them and have our integral to be:

\[ \oint_C (L dx + M dy) +
\sum^n_{i=1} \left( \int_{\gamma_i} L dx + Q dy \right) 
= \iint_D \left(
  \frac{\partial M}{\partial x} - \frac{\partial L}{\partial y}
\right) dx dy\]

As the diagram is:

[[./images/greentheorem.png]]

In this setting, the notion of $\mathbb{Z}$ linear combinations of paths
makes sense. We can take the free abelian group $G[Y]$ with $Y$ being
the set of paths $\gamma : [0,1] \longrightarrow X$.

******* An equivalence relation
For functions satisfying $\frac{\partial Q}{\partial x} = \frac{\partial P}{\partial y}$, the double integral dissapears,
and we have:

\[ \int_{m\gamma + \sum_i m_i\gamma_i} P dx + Q dy = 0\]

Here we can define an equivalence relation between pairs of paths,
where $\beta \sim \beta'$ if:

\[ \int_\beta P dx + Q dy = \int_{\beta'} P dx + Q dy \]

The equivalence class of $\beta$ is called its *homology class*.

****** Boundaries
If we take the simplices to form abelian groups, the boundaries
are homomorphisms.

[[./images/rectangle.png]]

For instance, if we can take this rectangle and compute its boundary.
We use free abelian groups of $n\text{-simplexes}$, called $C_n(X)$.

******* Boundary of a triangle
We use the minus sign to denote the inverse path, and we have:

\[ \delta([a,b,c]) = [a,b] + [b,c] - [a,c]\]

******* Boundary of the boundary of a triangle
As the double boundary is the boundary of a sphere, it is 
automatically null:

\[
\delta(\delta([a,b,c])) = (a - b) + (b - c) - (a - c) = 0
\]

******* Boundary of the rectangle
Now, we can compute the boundary of the rectangle; assuming that
the boundary function is a homomorphism preserving the union:

\[\begin{aligned}
\delta(\square) &=  \delta[a,b,c] + \delta[a,c,d] \\ 
&= [a,b]+[b,c]-[a,c]+[a,c]+[c,d]-[a,d] \\
&= [a,b]+[b,c]+[c,d]-[a,d]
\end{aligned}\]

****** Simplicial boundary maps
Let $X$ be a finite simplicial complex. We define:

\[ \delta_n [v_0,\dots,v_n] 
= \sum^n_{i=0} (-1)^i [v_0,\dots,\hat{v_i},\dots,v_n]\]

being a map from $C_n(X)$ to $C_{n-1}(X)$. We define $\delta_0 = 0$ as a convention.

****** Boundary maps are exact
For all $n > 0$, 

\[\delta_{n-1}\delta_n = 0\]

******* Proof
We can see that, for every pair of indexes, we have the same term 
twice, depending on whether we take the two indexes ordered or using
an inverse order:

\[ 
[x_0,\dots,\hat{x_i},\dots,\hat{x_j},\dots,x_n](-1)^{i+(j-1)} +
[x_0,\dots,\hat{x_i},\dots,\hat{x_j},\dots,x_n](-1)^{j+i} = 0
\]

****** Simplicial cycles and boundaries
The elements in $Z_n(X) = \ker \delta_n \subset C_n(X)$ are called *simplicial cycles*.
The elements in $B_n(X) = \im \delta_{n+1} \subset C_n(X)$ are called *simplicial 
boundaries*.

****** Exactness for cycles and boundaries
For all $n$,

\[ B_n(X) \subseteq Z_n(X)\]

******* Proof
It is trivial knowing that boundary maps are [[*Boundary maps are exact][exact]].

****** Simplicial homology group
The nth simplicial homology group of a finite simplicial complex is:

\[ H_n(X) = Z_n(X) / B_n(X) \]

What survives in this group are the cycles that are not boundaries;
that is, the boundaries of punctured sections.

****** Two modifications
We can consider *homology* with coefficients in $G$ by tensoring the
sequence of chain groups by $G$ and taking homology groups. We can
consider the *cohomology* with coefficients in $G$ applying $Hom(-,G)$
to the chain of groups and then taking homology groups.

***** 1.2. Categories and Functors
****** 1.2.1. Russell's paradox
The Russell paradox is solved in with the Zermelo-Fraenkel axioms,
specifically, the *axiom of comprehension*. It says that any definable
subclass of a set is a set; restricting the comprehension to only
already defined sets.

****** 1.2.2. Classes and sets
A class in ZFC is called *small* if it has a cardinal number. A *set*
is only a small class. In this book, we only worry about classes and
sets that are not a member of themselves.

# A cardinal number?
# More details in Mac Lane, Categories for the working mathematician.

****** 1.2.3. Categories
A category ${\cal C}$ consists of:

 - $obj({\cal C})$, a class of objects.
 - $Hom(A,B)$, a set of morphisms for every ordered pair $(A,B)$.
 - $\circ : Hom(A,B) \times Hom(B,C) \longrightarrow Hom(A,C)$, composition of functions.

****** 1.2.4. Axioms of categories
A category has disjoint $Hom$ sets, and there must be an identity element
$1_A \in Hom(A,A)$ for every morphism, following these rules:

 - The identity is a neutral element: $f \circ 1_A = f$ and $1_B \circ f = f$.
 - Composition is associative: $f \circ (g \circ h) = (f \circ g) \circ h$

****** 1.2.5. Examples of categories
******* Sets
******* Groups
******* Partially ordered sets
******* Inclusion of open sets
******* Topological spaces
******* Abstract simplicial complexes
******** Abstract simplicial complexes
We denote =Abs= the category of abstract simplicial complexes.
An abstract simplicial complex $K$ is a set of *vertices* $Vert(K)$ and
a family of nonempty finite subsets called *simplexes* 
$\sigma \subseteq Vert(K)$ such that:

 1. $\{v\}$ is a simplex for every $v \in Vert(K)$.
 2. Every subset of a simplex is a simplex.

******** Simplicial maps
A *simplicial map* is a function $\phi : Vert(K) \longrightarrow Vert(L)$ 
such that, if $\sigma$ is a simplex in $K$, then $\phi(\sigma)$ is a simplex
in $L$.

******** Dimension
A simplex with $|\sigma| = n+1$ is called a *n-simplex*. Simplicial
maps don't have to preserve dimension.

******* Nerves
If ${\cal U} = \{U\}_{i\in I}$ is the cover of a topological space, we define an 
abstract simplicial complex ${\cal N}({\cal U})$ having vertices $Vert({\cal N}({\cal U})) = {\cal U}$
and simplexes $\{U_0,\dots,U_n\} \subseteq {\cal U}$ such that:

\[ \bigcap_{k=0}^n U_k = \varnothing\]

******* Monoids
******* Homotopy category
****** 1.2.6. Algebraic examples of categories
******* Abelian groups
******* Rings (unital)
******* Commutative rings
****** 1.2.7. Modules
A left R-module, where $R$ is a ring, is an additive abelian group $M$
with a scalar multiplication $R \times M \longrightarrow M$, such that:

 1. $r(m+m') = rm+rm'$
 2. $(r+r')m = rm + r'm$
 3. $(rr')m = r(r'm)$
 4. $1m = m$

A right module is defined anagously.

****** 1.2.8. Examples of modules
******* Vector spaces over a field
******* Abelian groups over Z
******* Every ring over itself
******* Every ring over its center

****** 1.2.9. Homomorphisms of R-modules
A function $f : M \longrightarrow N$ such that:

 1. $f(m+m') = f(m)+f(m')$
 2. $f(rm) = rf(m)$

In the case of right modules, we can define them anagously.

******* The composite and inverse of homomorphisms is an homomorphism
Trivial.

****** 1.2.10. Examples of homomorphisms
******* Linear transformations in vector spaces
******* Homomorphisms of abelian groups for Z-modules
******* Homothety
Let $M$ be an R-module, and $r \in Z(R)$; multiplication by $r$, $\mu_r$, is
an homomorphism because:

\[ \mu_r(am) = r(am) = a(rm) = a\mu_r(m)\]

****** 1.2.11. Opposite rings
If $R$ is a ring, its opposite ring $R^{op}$ is the same ring with the
opposite multiplication, defined by:

\[ \mu^o(r,t) = \mu(t,r)\]

****** 1.2.12. Categories of modules
We call $_RMod$ the category of *left* R-modules, and $Mod_R$ to the 
category of *right* R-modules.

****** 1.2.13. Subcategories
A category ${\cal S}$ is a subcategory of ${\cal C}$ when:

 1. $obj({\cal S}) \subseteq obj({\cal C})$.
 2. $Hom_S(A,B) \subseteq Hom_C(A,B)$.
 3. Identities and compositions are the same.

****** 1.2.14. Full subcategories
A full subcategory has $Hom_S(A,B) = Hom_C(A,B)$ for every $A,B \in obj({\cal S})$.

****** 1.2.15. Functors
A functor $T : {\cal C} \longrightarrow {\cal D}$ is a function such that:

 1. $T : obj({\cal C}) \longrightarrow obj({\cal D})$.
 2. $T : Hom(A,B) \longrightarrow Hom(TA,TB)$.
 3. Preserves composition: $T(f \circ g) = Tf \circ Tg$.
 4. Preserves identities: $T(1_A) = 1_{T(A)}$.

****** 1.2.16. Examples of functors
******* Subcategories as inclusion functors
******* Identity functor
******* Hom(A,-) functor
******* Chains as functors from the partially ordered integers
******* Forgetful functors

****** 1.2.27. Diagrams
A diagram is a functor whose domain is a *small category*; that
is $T : {\cal D} \longrightarrow {\cal C}$, where $obj({\cal D})$ is a set.

****** 1.2.28. Paths
A path is a functor $P : n+1 \longrightarrow {\cal C}$, where the domain is the partial 
ordering of integers $0,\dots,n+1$. A path is *simple* if the functor is
injective.

****** 1.2.29. Commutativity of diagrams
A diagram commutes if the composites of the labels on any two simple path
are equal.

****** TODO 1.2.30. Contravariant functors
****** TODO 1.2.31. Examples of contravariant functors
******* Hom(-,B) functor
******* The dual space functor
\[( )^\ast = Hom_k(-,k) : \sideset{_k}{}{Mod} \longrightarrow \sideset{_k}{}{Mod}\]
******* Order-reversing functions on partially ordered sets

******* Presheaves
If ${\cal U}$ is a topology with the inclusion, a contravariant functor 
${\cal P} : {\cal U} \longrightarrow {\cal C}$ is a presheaf.

****** 1.2.32. Faithful functors
A functor is faithful if all the functions 
$Hom(A,B) \longrightarrow Hom(TA,TB)$ are injective.
****** 1.2.33. Concrete categories
A category is concrete if there is a faithful functor ${\cal C} \longrightarrow \mathtt{Set}$.

****** 1.2.33. Opposite category
We define ${\cal C}^{op}$ to be the category with:

 - $obj({\cal C}^{op}) = obj({\cal C})$
 - $Hom_{{\cal C}^{op}}(A,B) = Hom_{\cal C}(B,A)$
 - $g \circ_{op} f = f \circ g$

****** 1.2.34. Isomorphisms
A morphism $f : A \longrightarrow B$ such that exists $g : B \longrightarrow A$ with
$f \circ g = 1$ and $g \circ f = 1$.

****** 1.2.35. Functors preserve isomorphisms
Let $T$ be a functor, if $f$ is an isomorphism, then $T(f)$ is an isomorphism.

******* Proof
If $g$ is its inverse, then:

\[ T(f)T(g) = T(fg) = 1\]
\[ T(g)T(f) = T(gf) = 1\]

If $T$ is a contravariant functor, the proof remains the same.

****** 1.2.36. Natural transformations
Let $F,G : {\cal A} \longrightarrow {\cal B}$ be covariant functors. A natural transformation
$\tau : F \Longrightarrow G$ is a family of morphisms $\tau_A : S A \longrightarrow T A$, making the following
diagram commute for every $f \in Hom(A,B)$:

\[ \begin{tikzcd}
FA \rar{\tau_A} \dar{Ff} & GA \dar{Gf} \\
FB \rar{\tau_B} & GB
\end{tikzcd} \]

We write the natural transformations as $Nat(F,G)$.

****** 1.2.37. Natural isomorphisms
A natural transformation $\tau$ for which each $\tau_A$ is an isomorphism.

****** 1.2.38. Composition of natural transformations
If $\tau : F \Longrightarrow G$ and $\sigma : G \Longrightarrow H$ are natural transformations, then the
composition is a natural transformation.

******* Proof
Composing the two commutative diagrams gives us the proof.

****** 1.2.39. Identity natural transformation
For any functor $F : {\cal A} \longrightarrow {\cal B}$, we can describe an identity natural 
transformation using the identity morphisms.

****** TODO 1.2.40. Examples of natural transformations
****** TODO 1.2.41. Natural transformations are proper classes
****** 1.2.42. Yoneda Lemma
Let $A \in obj({\cal C})$ and $G : {\cal C} \longrightarrow \mathtt{Set}$ be a covariant functor. 
There is a bijection:

\[ y : Nat(Hom_C(A,-), G) \longrightarrow G(A)\]

given by $y : \tau \longrightarrow \tau_A(1_A)$.

******* Proof
******** Every choice of p determines a natural transformation
Given $p \in GA$, we can create an unique natural transformation having
$\eta_A(1_A) = p$. A natural transformation has to obey the following 
commutative diagram:

\[\begin{tikzcd}
Hom(A,A) \rar{f \circ \_}\dar{\eta}& Hom(A,B)\dar{\eta} \\
GA \rar{Gf}& GB
\end{tikzcd}\]

Then, the image of $\eta_B(f)$ is determined.

\[\begin{tikzcd}
id \rar{f \circ \_}\dar{\eta}& f\dar{\eta} \\
p \rar{Gf}& (Gf)(p)
\end{tikzcd}\]

******** Every choice gives us a natural transformation
This gives us, in fact, a natural transformation which makes every
natural square to commute:

\[\begin{tikzcd}
Hom(A,B) \rar{g \circ \_}\dar{\eta}& Hom(A,C)\dar{\eta} \\
GB \rar{Gg}& GC
\end{tikzcd}\]

Given any element $f \in Hom(A,B)$, we can check the commutativity:

\[\begin{tikzcd}
f \rar{g \circ \_}\dar{\eta}& g \circ f\dar{\eta} \\
(Gf)(p) \rar{Gg}&  G(g \circ f)(p)
\end{tikzcd}\]

Knowing that $G(g \circ f)(p) = (Gg \circ Gf) (p)$.

****** 1.2.43. Representable functors
A covariant functor $F: {\cal C} \longrightarrow \mathtt{Set}$ is representable if $F \cong Hom(A,-)$
for some $A$.

****** 1.2.44. Yoneda Corollary
For $A,B \in obj({\cal C})$:

  1. If $\eta \in Nat(Hom(A,-),Hom(B,-))$, then $\eta = (\_ \circ \psi)$ for some unique $\psi$.
  2. If $\eta = (\_ \circ \psi)$ and $\tau = (\_\circ\phi)$, then $\tau\circ\eta = (\_ \circ \psi\circ\phi)$.
  3. $\eta = (\_\circ\psi)$ is a natural isomorphism iff $\psi$ is an isomorphism.

******* Proof
******** Corollary 1
If we apply Yoneda Lemma, every transformation is defined by
$\eta(id_A) = \psi$. The transformation has to be $(\_ \circ\psi)$ because of commutativity:

\[\begin{tikzcd}
Hom(A,A) \rar{f \circ \_}\dar{\eta}& Hom(A,C)\dar{\eta} \\
Hom(B,A) \rar{f \circ\_}& Hom(B,C)
\end{tikzcd}\]

So, given any element $f \in Hom(A,C)$, we have $\eta(f) = f \circ \psi$:

\[\begin{tikzcd}
id \rar{f \circ \_}\dar{\eta}& f\dar{\eta} \\
\psi \rar{f \circ\_}& f \circ \psi
\end{tikzcd}\]

******** Corollary 2
Trivial consequence of the first corollary.

******** Corollary 3
It is trivial given the previous corollaries and:

\[(\_\circ\psi^{-1})\circ \psi = (\_\circ id)\]

****** TODO Examples
****** TODO Yoneda Imbedding
***** 1.3. Singular Homology
****** 1.3.1. Hilbert spaces and euclidean spaces
A *Hilbert space* is the set ${\cal H}$ of all sequences $(x_i) \in \mathbb{R}$ such that
$\sum x_i^2 < \infty$. A *Euclidean space*, $\mathbb{R}^n$ is a subset of ${\cal H}$ consisting of
all sequences of the form $(x_0,x_1,\dots,x_{n-1},0,\dots)$.

****** 1.3.2. Standard n-simplex
The standard n-simplex is the set of all convex combinations:

\[\Delta^n = [e_0,e_1,\dots,e_n]\]

Where $e_i$ form an orthogonal basis.

****** 1.3.3. Singular n-simplex
Given a topological space $X$, a singular n-simplex is a continuous map
$\sigma : \Delta^n \longrightarrow X$.

****** 1.3.4. Singular n-chains
We define $S_n(X)$ as the free group with singular n-simplexes as basis.
By convention, $S_{-1}(X) = \{0\}$. The elements on this group are called
singular n-chains.

****** TODO 1.3.5. Face maps
The ith face map $\epsilon^n_i : \Delta^{n-1} \longrightarrow \Delta^n$ is defined by:

***** Exercises
****** Exercise 1.1
#+begin_statement
1. Prove, in every category ${\cal C}$, that each object $A \in {\cal C}$ has a unique identity
   morphism.
2. If $f$ is an isomorphism in a category, prove that its inverse is unique.
#+end_statement

We have $id = id \circ id' = id'$ and $\varphi^{-1} = \varphi' \circ \varphi \circ \varphi^{-1} = \varphi'$.

**** 2. Hom and Tensor
***** 2.1. Modules
****** Representation of a ring
A *representation* of $R$ is an homomorphism $\varphi : R \longrightarrow End_\mathbb{Z}(M)$.

******* Equivalence of representations and modules
The product of a R-module is a representation, and every
representation gives an R-module.

******** Equivalence of types
Type of a representation:

\[R \longrightarrow End(M)\]

Type of an R-module product:

\[R \times M \longrightarrow M\]

Both types are equivalent.

****** Example: Group ring
Given $G$, a group, and $R$, a ring; we define the group ring, $RG$ to be
the set of functions $G \longrightarrow R$ of finite support, with the operations:

  - Sum of functions: $(f+g)(a) = f(a)+g(a)$
  - Convolution (product): $(f\cdot g)(a) = \sum_{uv = a} f(u)g(v)$
  - Product by a scalar on $R$: $(kf)(a) = kf(a)$

It defines a ring and an R-module.

******* Inclusion of the group
The group can be included on $RG$ with the indicator function $y \mapsto 1_{(=y)}$,
defined as:

\[
y(a) = 1_{(=y)}(a) =
\left\{\begin{array}{ll} 
1 & \mbox{if } a = y  \\
0 & \mbox{if } a \neq y
\end{array} 
\right.
\]

A function that only outputs $1$ when its input is $y$.

******** Preservation of the product

\[
1_{(=y)}\cdot 1_{(=z)} (a)
=
\sum_{u\cdot v = a} 1_{u=y}1_{v=z}
=
1_{a=yz}
\]

****** Additive functors
A functor $T : \mathtt{RMod} \longrightarrow \mathtt{Ab}$ is called *additive* if, for every pair of R-maps,
$f,g$, we have:

\[
T(f+g) = Tf + Tg
\]

******* Properties of additive functors
Let $T : \mathtt{RMod} \longrightarrow \mathtt{Ab}$ be an additive functor:

  1. $T(0) = 0$, the zero map.
  2. $T(\{0\}) = \{0\}$, the zero group.

******** Proof
********* First property
$T0 = T(0+0) = T0+T0$, and then $T0 = 0$.

********* Second property
$Hom(A,\{0\})$ only has one element.

****** Homomorphisms of r-modules are abelian groups
Given $A,B$ R-modules, $Hom_{R-mod}(A,B)$ is an abelian group with the
componentwise sum.

****** Hom as an additive functor
$Hom_{R-mod}(A,-)$ is an additive functor.

******* TODO Central case

****** TODO Hom as a contravariant functor
****** Submodules
Given $M$, an R-module, a *submodule* $N \subseteq M$ is an additive subgroup
closed under scalar multiplication.

******* Examples of submodules
******** Subgroups
A submodule of a Z-module (abelian group) is a subgroup.

****** Quotient of modules
****** Kernels, images and cokernels
****** First Isomorphism Theorem
****** Second Isomorphism Theorem
****** Third Isomorphism Theorem
****** Correspondence Theorem
****** Simple module
A proper R-module $M$ is simple if it has no proper submodules.

******* Characterization
$M$ is simple iff $M \cong R/I$, where $I$ is a maximal left ideal.

******** TODO Proof

****** Exact sequences
****** Zero-ended exact sequences
****** Short exact sequences
****** External direct sum
******* Properties of the external direct sum
****** Internal direct sum
****** Direct summands and complements
******* Retractions
****** Direct product
******* Direct sum
******* Projections
******* Injections
****** Free modules
******* Basis
******* Free abelian groups
****** Basis
******* Invariant basis number
******* Rank
****** Left exactness
***** 2.2. Tensor products
****** Bilinearity
******* Biadditivity
****** Tensor product
******* Uniqueness
******* Existence
****** Tensor functors
****** Universal property of the tensor product
****** Commutativity
****** Enveloping algebra
****** Right exactness
****** Tensor and direct sum
****** Four Lemma I
****** Four Lemma II
****** Five Lemma
****** Divisible abelian group
***** 2.2.1. Adjoint isomorphisms
****** Adjoint isomorphisms
****** Right exactness
**** 3. Special Modules
***** 3.1. Projective modules
****** Exact functor
****** Lifting on free modules
****** Lifting
****** Projective modules
****** Characterization of projective modules
****** Projective modules and direct summands
****** Kaplansky theorem
****** Projective basis
****** Schnauel's Lemma
****** Ascending chaing condition
****** Noetherian rings
****** Characterization of noetherian rings
****** Hilbert basis theorem
***** 3.2. Injective modules
****** Injective module
****** Characterization of injective modules
****** Product of injective modules
****** Baer criterion
****** Divisible modules
****** Bass-Papp theorem
****** Characterization by short exact sequences
****** Essential extension
****** Characterizacion by essential extensions
****** Injective envelope
****** Eckmann-Schöpf
***** 3.3. Flat modules
****** Flat module
****** Direct sum of flat modules
****** Finitely generated submodules and flat modules
****** Torsion module
****** Torsion-free module
******* PID module
******* Flat modules
****** Character module
****** Lambek theorem
****** Villamayor theorem
****** Left coherent ring
****** Chase theorem
***** 3.3.1. Purity
****** Pure exact sequence
******* Pure submodule
****** Characterization of flatness
****** Cohn theorem
**** 4. Specific Rings
***** 4.2. Von Neumann Regular Rings
****** Von Neumann Regular ring
A ring $R$ is *Von Neumann regular* if:

\[
\forall r \in R: \exists r' \in R: rr'r = r
\]

******* Boolean rings
A ring is boolean if every element is idempotent. Every boolean ring
is a commutative Von Neumann regular ring.

**** 5. Setting the stage
***** 5.4. Sheaves
****** Protosheaves
 #+begin_definition
 *Local homeomorphism*. Continuous map $p : E \longrightarrow X$ such that for each $e \in E$ there is
 an open neighboorhood $S$ of $e$ such that $p|_S$ is an isomorphism.
 #+end_definition
 #+begin_definition
 *Protosheaf*. Surjective local homeomorphism.
 #+end_definition

****** Etale-sheaves
 #+begin_definition
 *Etale-sheaf of abelian groups*. A *protosheaf* such that:

 - The stalk $E_x$ is an abelian group.
 - Inversion and adition are continuous.
 #+end_definition

 #+begin_definition
 *Etale-map*. Given two etale-sheaves $E$ and $E'$, a map $\phi : E \longrightarrow E'$ such
 that $p'\phi = p$, and each $\phi|_{E_x}$ is a homomorphism.
 #+end_definition

 Here, etale-sheaves of abelian groups over a topological space X form an
 abelian category $\mathtt{Sh}_{et}(X,\mathtt{Ab})$.

***** 5.5. Abelian categories
****** Additive category
 #+begin_definition
 *Additive category*. ${\cal C}$ is additive if:

 - $Hom(A,B)$ is an *abelian group*.
 - *Distributivity* holds: $b \circ (f+g) = b\circ f + b \circ g$ and $(f+g)\circ a = f\circ a + g\circ a$.
 - Has a *zero object*.
 - Has finite *products* and *coproducts*.

 A functor $T$ between two additive categories is additive if $T(f+g) = Tf+Tg$.
 #+end_definition

 #+begin_theorem
 *Sums and products are the same*. Products and coproducts are isomorphic:

 \[A \mathbin{\Pi} B \cong A \amalg B\]

 So we call them *direct sums*, $A \oplus B$. And there are canonical morphisms:

 \[ \begin{tikzcd}
 & A \oplus B \dlar[bend right,swap]{\pi_A} \drar[bend left]{\pi_B} $ \\
 A \urar[bend right,swap]{i_A} & & B \ular[bend left]{i_B}
 \end{tikzcd} \]

 Such that: \(i_A \circ \pi_A + i_b \circ \pi_B = id\) and \(\pi_B \circ i_A = \pi_A \circ i_B = 0\).
 #+end_theorem

****** Monomorphisms and epimorphisms

#+begin_definition
*Monomorphism*. A morphism $u$ such that:
\[u \circ f = u \circ g \quad \Rightarrow \quad f = g\]
#+end_definition

#+begin_definition
*Epimorphism*. A morphism $u$ such that:
\[f \circ u = g \circ u \quad \Rightarrow \quad f = g\]
#+end_definition

We have that $u : B \longrightarrow C$ is *monomorphism* iff the induced 
$u^\ast : Hom(A,B) \longrightarrow Hom(A,C)$ is injective. And $v : B \longrightarrow C$ is *epimorphism* 
iff the induced $v^* : Hom(B,D) \longrightarrow Hom(C,D)$ is surjective.

****** Kernels and cokernels
 #+begin_definition
 *Kernel*. The kernel of $u$ is the equalizer of $u$ and $0$. In a diagram:

 \[ \begin{tikzcd}
 & C \dar[dashed] \arrow[ddr, bend left] \arrow[ddl,bend right] &\\
 & \ker(u) \dlar[swap]{i} \drar{0} & \\
 A \arrow[shift left]{rr}{u} \arrow[shift right]{rr}[swap]{0} & & B
 \end{tikzcd} \]
 #+end_definition
 #+begin_definition
 *Cokernel*. The cokernel of $u$ is the coequalizer of $u$ ans $0$. In a diagram

 \[ \begin{tikzcd}
 & C &\\
 & \ker(u) \uar[dashed]   & \\
 A \urar{0} \arrow[uur, bend left]
 \arrow[shift left]{rr}{u} \arrow[shift right]{rr}[swap]{0} & & 
 B \ular[swap]{\pi} \arrow[uul,bend right]
 \end{tikzcd} \]
 #+end_definition

 #+begin_theorem
 *Monomorphisms and kernels*.
 - If $\ker(u)$ exists, $u$ is monomorphism iff $ker(u) = 0$.
 - If $coker(v)$ exists, $v$ is epimorphism iff $coker(v) = 0$.
 #+end_theorem
****** Abelian category
 #+begin_definition
 *Abelian category*. ${\cal C}$ is abelian if

 - Every morphism has *kernel* and *cokernel*.
 - Every monomorphism is a *kernel*.
 - Every epimorphism is a *cokernel*.
 #+end_definition

 Abelian categories are /self-dual/, if ${\cal A}$ is an abelian category, then
 ${\cal A}^{op}$ is an abelian category.

 #+begin_definition
 *Image*. Given $f : A \longrightarrow B$ in an abelian category, its image is:

 \[img(f) = ker(coker(f))\]
 #+end_definition
*** Koszul Pairs and applications - Pascual Jara, Dragoş Ştefan                                      :algebra:koszul:
**** Introduction
***** Koszul ring
*Koszul ring*. A graded ring $A$ is *Koszul* if $A^0$ is a semisimple ring 
and it has a resolution $P_\ast$ by projective graded left A-modules such 
that each $P_n$ is generated by homogeneous elements of degree $n$.

***** Graded ring
*Graded ring*. A ring that is a direct sum of abelian groups:

\[ A = \bigoplus_{n \in \mathbb{N}} A_n\]

such that $A_iA_j \subset A_{i+j}$.

****** Homogeneous Elements
A *homogeneous element* is an element of any factor $A_i$ of the 
decomposition.

*Example:* A polynomial ring $A = \mathbb{K}[x_1,x_2, \dots]$ is graded with $A_i$ 
being the abelian group of polynomials with only monomials of 
degree $i$.
# QUESTION: Do they admit a different gradation?
# We can take $A_i$ to be the group of polynomials of degree 
# *equal or less* than i!

***** Semisimple group
*Semisimple group*. A group is semisimple if it has no non-trivial 
normal abelian subgroups.

Different uses of this term can be found [[http://planetmath.org/semisimplegroup][here]].
# QUESTION: Which are we interested in?

***** Semisimple module
*Semisimple module*. It is a direct sum of simple modules, that is, 
they have no non-zero proper submodules.

***** Semisimple algebra
An associative finite dimensional algebra $A$ is *semisimple* if
$A$ is a direct product of simple algebras or equivalently, if $A$ has
trivial Jacobson radical.

**** 1. Almost-koszul pairs
***** 1.1. R-rings
****** R-Ring
*R-ring*. Associative and unital algebra. It is an associative and 
unital ring $A$ together with a morphism $u : R \longrightarrow A$.

****** Graded and connected R-rings
*Graded and connected R-rings*. A R-ring is graded if it is equipped 
with a decomposition:

\[A = \bigoplus_{n \in \mathbb{N}} A^n \]

such that multiplicaton $m^{p,q}$ maps $A^p \otimes A^q$ into $A^{p+q}$. It is *connected* 
when $A_0 = R$. It is *strongly graded* when $m^{1,p}$ is surjective. We 
call $\pi^n_A$ to the projection of $A$ onto $A^n$.

***** 1.2. R-corings
****** Definition of coalgebra
A [[https://en.wikipedia.org/wiki/Coalgebra#Formal_definition][coalgebra]] over a field $K$ is a *vector space* $V$ together with linear
maps $\Delta : V \longrightarrow V \otimes V$ and $\varepsilon : V \longrightarrow K$ such that:

 1. $(id \otimes \Delta) \circ \Delta = (\Delta \otimes id) \circ \Delta$
 2. $(id \otimes \varepsilon) \circ \Delta = id 
    = (\varepsilon \otimes id) \circ \Delta$

Sometimes, the coalgebras use [[https://en.wikipedia.org/wiki/Coalgebra#Sweedler_notation][Sweedler notation]].

****** Examples of coalgebras
******* The divided power coalgebra
Consider $K[X]$, the polynomial ring, where we define by linearity:

\[\Delta(X^n) = \sum^n_{k=0} {n \choose k} X^k \otimes X^{n-k}\]

\[\epsilon(X^n) = \twopartdef{1}{n=0}{0}{n>0}\]

When the structures of algebra and coalgebra are compatible, they
are called [[https://en.wikipedia.org/wiki/Bialgebra][bialgebras]].

****** R-coring
*R-coring*. Coassociative and counital coalgebra. It is an R-bimodule 
with a /comultiplication/ $\Delta : C \longrightarrow C \otimes C$ and 
a /counit/ $\epsilon : C \longrightarrow R$.

****** Graded corings
*Graded corings*. Decomposition $C = \bigoplus_{n \in \mathbb{N}} C_n$, 
such that:

\[\Delta(C_n) \subset \bigoplus_{p=0}^n C_p \otimes C_{n-p}\]

***** 1.3. Almost-Koszul pair
*Almost-Koszul pair*. Connected R-ring and R-coring $(A,C)$ with an 
isomorphism $\theta_{C,A} : C_1 \longrightarrow A^1$, that satisfies the relation:

\[ m^{1,1} \circ (\theta_{C,A} \otimes \theta_{C,A}) \circ \Delta_{1,1}
= 0\]

Or, using Sweedler notation, for any $c \in C_2$:

\[ \sum \theta_{C,A}(c_{(1,1)}) \theta_{C,A}(c_{(2,1)}) = 0\]

***** 1.4. Opposite Koszul pair
If $(A,C)$ is a Koszul pair, then $(A^{op},C^{op})$ are Koszul pairs with
respect to:

\[\theta_{C^{op},A^{op}} = \theta_{C,A}\]

***** 1.5. The normalized bar resolution of R
For every strongly graded R-ring A, there is a graded coring C such that
$(A,C)$ is an almost-Koszul pair.

****** The normalized right bar resolution
The exact sequence $\beta_\ast^r(A)$:

\[ 0 \longleftarrow 
R \overset{\delta_0}\longleftarrow 
A \overset{\delta_1}\longleftarrow
\overline{A} \otimes A \overset{\delta_2}\longleftarrow
\overline{A} \otimes \overline{A} \otimes A \overset{\delta_3}\longleftarrow
\overline{A} \otimes \overline{A} \otimes \overline{A} \otimes A \longleftarrow
\dots
\]

is called the *normalized right bar resolution*. Where
the $\delta$ are defined as:

 - $\delta_0 = \pi^0_A$
 - \[ \delta_n(a_1 \otimes \dots \otimes a_n \otimes a_{n+1}) 
      = \sum_{i=1}^n (-1)^i  a_1 \otimes \dots \otimes a_ia_{i+1} \otimes \dots \otimes a_{n+1}\]

****** TODO Normalized bar complex

**** 2. Koszul Pairs

**** 3. Hochschild (co)homology of Koszul rings
***** 3.1. The cyclic tensor product
****** Enveloping algebra of R
The tensor product algebra $R^e = R \otimes_\mathbb{K} R^{op}$ is called the 
*enveloping algebra* of $R$.

**** 4. Almost-Koszul pairs associated to twisted tensor products

**** 5. The Hochschlid cohomology of a twisted tensor product

*** Affine group schemes seminar
**** I. Álgebras de Hopf
***** 1. Definiciones
****** Álgebra de Hopf
Un *álgebra de Hopf* es una biálgebra (álgebra y coálgebra) con un 
antiautomorfismo llamado /antípoda/.

******* Explícitamente
Tenemos $(H, m, \eta, \Delta, \varepsilon, S)$ como componentes del álgebra de Hopf sobre
un cuerpo $k$, donde:

 - $H$ es el álgebra.
 - $m : H \otimes H \to H$ es el producto.
 - $\eta : k \to H$ es la unidad.
 - $\Delta : H \to H \otimes H$ es la comultiplicación.
 - $\varepsilon : H \to k$ es la counidad.
 - $S : H \to H$ la antípoda.

Bajo ciertas condiciones de compatibilidad.

****** Group-like elements
Elementos no nulos cumpliendo $\Delta(x) = x \otimes x$. Forman un grupo con la inversa
dada por la antípoda.

**** II. Introduction to affine group schemes
***** 1. Definition and examples
****** Affine group scheme
An *affine group scheme* over $k$ is a representable functor $\mathtt{Alg}_k \to \mathtt{Grp}$.
More precisely, the composition of the functor with $\mathtt{Grp}\to\mathtt{Set}$ is
representable.

****** Connection with affine algebraic varieties
If $V$ is an affine algebraic variety, the we can define the corresponding
affine scheme as $Alg_k(K[V], -)$, where $K[V]$ is the coordinate algebra.

****** Algebraic affine scheme
An affine scheme is said to be *algebraic* if its representing object is
finitely generated as a k-algebra.

**** III. Esquemas diagonalizables y constantes
***** 1. Introducción
****** Álgebra grupo
Dado un grupo $G$ y un cuerpo $k$, el álgebra grupo $k[G]$ está formada como el
espacio vectorial libre sobre $G$ con el producto que induce el grupo.

******* Estructura de álgebra de Hopf
Este álgebra tiene estructura de álgebra de Hopf si extendemos linealmente
las siguientes aplicaciones:

  - $\Delta(x) = x \otimes x$
  - $\varepsilon(x) = 1$
  - $S(x) = x^{-1}$
*** Harpreet Bedi's channel
**** Sheaves and coho
***** Preseaves and sheaves
****** Preseaf definition
#+begin_definition
*Preseaf*. A preseaf ${\cal F}$ of abelian groups on a topological space $X$ consists of:

- For each open set $U$, an abelian group ${\cal F}(U)$, whose elements are called 
  *sections*.
- For each inclusion $V \subseteq U$, a *restriction map*, homomorphism of the form:
  
 
\[p_{U,V} : {\cal F}(U) \longrightarrow {\cal F}(V)\]

such that $p_{U,W} = p_{V,W} \circ p_{U,V}$.
#+end_definition

We can write the restriction of an element $u \in U$ to a set $V \subseteq U$ as
$u|_V = p_{U,V}(u)$.

****** Sheaf definition
 #+begin_definition
 *Gluability axiom*. Given $U = \bigcup U_i$ with sections $s_i \in {\cal F}(U_i)$, if we have:

 \[ s_\alpha|_{U_\alpha \cap U_\beta} = s_\beta|_{U_\alpha \cap U_\beta} \]

 then there exists $s \in {\cal F}(U)$ such that $s|_U_\alpha = s_\alpha$.
 #+end_definition
 #+begin_definition
 *Uniqueness axiom*. Given $U = \bigcup U_i$ with sections $s,t \in {\cal F}(U)$ such that:

 \[\forall U_\alpha:\ s|_U_\alpha = t|_U_\alpha\]

 then $s=t$.
 #+end_definition
 #+begin_definition
 *Sheaves*. A presheaf satisfiying gluability and uniqueness.
 #+end_definition
**** Homological Algebra
***** 2. Chain Complex and Homology
***** 4. Homology Theorem
****** Setting
Given a SES of chain complexes $0 \longrightarrow {\cal A}
\longrightarrow{\cal B}
\longrightarrow{\cal C}
\longrightarrow 0$, we have a long exact
sequence like:

\[ \begin{tikzcd}
 & \dots\rar & H_{n+1}({\cal C}) \arrow[out=355,in=175,swap]{dll}{\delta_{n+1}} \\
H_{n}({\cal A})\rar & H_{n}({\cal B}) \rar & H_{n}({\cal C}) \arrow[out=355,in=175,swap]{dll}{\delta_n}\\
H_{n-1}({\cal A})\rar & \dots & 
\end{tikzcd} \]

****** Naturality
When we have two SES of chain complexes:

\[ \begin{tikzcd}
0 \rar & {\cal A}\rar\dar & {\cal B}\rar\dar & {\cal C}\rar\dar & 0 \\
0 \rar & {\cal A}'\rar & {\cal B}'\rar & {\cal C}'\rar & 0 \\
\end{tikzcd} \]

where it hols for every $n$ that:

\[ \begin{tikzcd}
H_n({\cal C}) \rar\dar & H_{n-1}({\cal A})\dar \\
H_n({\cal C}') \rar & H_{n-1}({\cal A}')
\end{tikzcd} \]

***** 8. Proj, inj and flat modules
****** Definitions
An R-module $D$ is:

 1. *Projective* if $Hom(D, -)$ is exact.
 2. *Injective* if $Hom(-,D)$ is exact.
 3. *Flat* if $D \otimes -$ is exact.

****** Considerations
We know that $Hom(D,-)$ and $Hom(-,D)$ are left-exact and that
$D\otimes -$ is right-exact; so for them to be exact, we only need:

 - A module $D$ is *projective* when $B \longrightarrow C$ surjective induces
   $Hom(D,B) \longrightarrow Hom(D,C)$ surjective.

   \[ \begin{tikzcd}
               & B \dar[two heads] \\
   D \rar\urar[dashed]{\exists} & C
   \end{tikzcd} \]

 - A module $D$ is *injective* when $A \longrightarrow B$ surjective induces
   $Hom(B,D) \longrightarrow Hom(A,D)$ surjective.

   \[ \begin{tikzcd}
     & A \dar[two heads]\dlar \\
   D & B \lar[dashed]{\exists}
   \end{tikzcd} \]

 - A module $D$ is *flat* when $A \longrightarrow B$ injective induces 
   $D\otimes A \longrightarrow D \otimes B$ injective.

***** 9. Resolutions: projective, injective and flat
****** Definitions
******* Resolutions
Resolutions are *exact sequences*.

******* Projective resolution
A resolution, with $d_i$ maps:

\[\dots\longrightarrow P_2\longrightarrow P_1\longrightarrow P_0
\longrightarrow M \longrightarrow 0\]

where $P_i$ is projective.

******* Injective resolution
A resolution:

\[0 \longrightarrow M \longrightarrow E_0\longrightarrow E_1
\longrightarrow E_2 \longrightarrow \dots\]

where $E_i$ is injective.

******* Flat resolution
A resolution:

\[\dots\longrightarrow F_2\longrightarrow F_1\longrightarrow F_0
\longrightarrow M \longrightarrow 0\]

where $F_i$ is flat.

****** How to form a resolution
It is important to notice that, given a module $M$, we can always find
a surjection from a proyective module (if we have /enough
projectives/). So we can construct a projective resolution as follows:

\[ \begin{tikzcd}[column sep=tiny]
&\ker f_2 \drar&&&&\ker \pi\drar &&& \\
\dots&&P_2 \drar[two heads]{f_2}&&P_1 \urar[two heads]{f_1} && P_0 \ar[two heads,rr]{\pi} && M \rar & 0\\
&&&\ker f_1 \urar&&&&
\end{tikzcd} \]

We can also reverse the arrows to obtain an injective resolution.

***** TODO 10. Homotopic projective resolutions
****** Extending a morphism
Given two projective resolutions of two $R$ modules, $A$ and $A'$, and a morphism
between them, $f$. We can extend it to $f_n \in Hom(P_n,P_n')$.

\[ \begin{tikzcd}
\dots\rar & P_{n+1}\rar & P_n\rar& \dots
 \rar & P_1\rar{d_1} & P_0\rar{d_0}& A \dar{f} \rar& 0 \\
\dots\rar & P_{n+1}'\rar & P_n'\rar&\dots
 \rar & P_1'\rar{d_1¡} & P_0'\rar{d_0'}& A' \rar& 0 \\
\end{tikzcd} \]

******* Extending the morphism, base case
We use that $P_0$ is projective to construct:

\[ \begin{tikzcd}
     & P_0 \arrow[ddl,"f_0",dashed,swap] \dar\\
     & A \dar{f} \\
P_0' \rar[two heads] & A'
\end{tikzcd} \]

******* Extending the morphism, inductive case
We are going to show that $f_n(\im d_{n+1}) \subset \im d_{n+1}' = \ker d_n'$. That is, 
$d_n' \circ f_n \circ d_{n+1} = 0$. And that follows from diagram chasing. We use
again the projectivity of $P_{n+1}$.

\[ \begin{tikzcd}
     & P_{n_+1} \arrow[ddl,"f_{n+1}",dashed,swap] \dar\\
     & \im d_{n+1} \dar{f_n} \\
P_{n+1}' \rar[two heads] & \im d_{n+1}'
\end{tikzcd} \]

****** TODO Homotopic resolutions
***** 11. Derived functors Ext and Tor
****** Right derived functors
Let $F$ be additive, covariant and left-exact. Let 
$0 \longrightarrow M \longrightarrow E^\bullet$ be an injective resolution with $M$ deleted; then $F(E^\bullet)$ 
is a complex, and we define:

\[R^i F(M) = H^i(F(E^\bullet)) = 
\frac{\ker \{F(E_i) \longrightarrow F(E_{i+1})\}}
{\im\{ F(E_{i-1}) \longrightarrow F(E_i)\}}\]

That is, if we take the injective resolution:

\[ 0 \longrightarrow M \longrightarrow E_0 \longrightarrow E_1 
\longrightarrow \dots\]

Delete $M$ and apply $F$ to get a (non neccesarily exact) complex where 
we can compute the homology:

\[ 0 \longrightarrow F(E_0) \longrightarrow F(E_1)
\longrightarrow F(E_2) \longrightarrow \dots\]

****** Left derived functors
Let $F$ be additive, contravariant and left-exact. Let 
$P^\bullet \longrightarrow M \longrightarrow 0$ be a projective resolution with $M$ deleted; 
then $F(P^\bullet)$ is a complex, and we define:

\[R^i F(M) = H^i(F(P^\bullet)) = 
\frac{\ker \{F(P_i) \longrightarrow F(P_{i+1})\}}
{\im\{ F(P_{i-1}) \longrightarrow F(P_i)\}}\]

That is, if we take the injective resolution:

\[\dots \longrightarrow P_2\longrightarrow P_1\longrightarrow P_0
\longrightarrow M \longrightarrow 0\]

Delete $M$ and apply $F$ to get a (non neccesarily exact) complex 
where we can compute the homology:

\[ 0 \longrightarrow F(P_0) \longrightarrow F(P_1)
\longrightarrow F(P_2) \longrightarrow \dots\]

***** 12. Computations of some standard Ext and Tor examples
***** 13. Long Exact Sequence for Tor
**** Algebraic Geometry
***** 1. Intro to Algebraic Geometry

** Analysis                                                                                                 :analysis:
*** Basic
**** Integrals
***** Variable change                                                                                       :drill:
SCHEDULED: <2018-07-05 Thu>
:PROPERTIES:
:ID:       d952ab85-d01d-42b8-8d72-735e6d8b9147
:DRILL_LAST_INTERVAL: 4.5028
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 5.0
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-30 Sat 11:53]
:END:
Given $\varphi$ differentiable and $f$ integrable, state the
integration by substitution rule.

****** Definition

\[
\int_a^b f(\varphi(t))\varphi'(t) \; dt = \int_{\varphi(a)}^{\varphi(b)} f(x)\; dx
\]

**** Definitions
***** Lipschitz continuous                                                                                  :drill:
SCHEDULED: <2018-09-11 Tue>
:PROPERTIES:
:ID:       921ecf4c-ac54-4c0f-a35e-6644cbe4cb02
:DRILL_LAST_INTERVAL: 75.9758
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.5
:DRILL_EASE: 2.7
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-27 Wed 13:16]
:END:
A function $f$ between metric spaces is Lipschitz continuous when...

****** Definition
\[
d(f(x),f(y)) \leq k\, d(x,y)
\]

***** Locally Lipschitz continuous                                                                          :drill:
SCHEDULED: <2018-09-10 Mon>
:PROPERTIES:
:ID:       4e9b39cc-4e82-442d-883d-97f8105ae90b
:DRILL_LAST_INTERVAL: 79.6653
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.75
:DRILL_EASE: 2.8
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-22 Fri 22:19]
:END:
A function $f \colon D \to \mathbb{R}^k$ is locally Lipschitz continuous when...

****** Definition
for each $x \in D$ there exists a open $x \in U \subset D$ such that

\[
\|f(x)-f(y)\| \leq k\|x-y\|
\]

***** Hyperbolic sine                                                                                       :drill:
SCHEDULED: <2018-07-04 Wed>
:PROPERTIES:
:ID:       ad50cfd5-ba16-4bb6-beb4-88764926513f
:DRILL_LAST_INTERVAL: 5.4797
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 5.0
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-29 Fri 22:23]
:END:
Definition of hyperbolic sine

****** Definition
\[
\sinh(x) = \frac{e^x-e^{-x}}{2}
\]
***** Hyperbolic cosine                                                                                     :drill:
SCHEDULED: <2018-07-03 Tue>
:PROPERTIES:
:ID:       8abc2ece-687c-434c-a63d-52e8ada791bd
:DRILL_LAST_INTERVAL: 3.9682
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 5.0
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-29 Fri 22:31]
:END:
Definition of hyperbolic cosine

****** Definition
\[
\cosh(x) = \frac{e^x+e^{-x}}{2}
\]

**** Measure theory
***** Measurable space                                                                                      :drill:
SCHEDULED: <2018-07-01 Sun>
:PROPERTIES:
:ID:       87ac46cb-8da5-4d58-ab9c-75c766932e94
:DRILL_LAST_INTERVAL: 4.3657
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 7
:DRILL_FAILURE_COUNT: 2
:DRILL_AVERAGE_QUALITY: 3.428
:DRILL_EASE: 2.46
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-27 Wed 13:24]
:END:
Definition of *measurable space*.

****** Definition
A measurable space $(\Omega,\Sigma)$ is given by a set $\Omega$ and a /σ-algebra/
on the set, that is, a set of subsets with

 * the empty set,
 * all complements,
 * all countable unions,
 * all countable intersections.

***** Measure                                                                                               :drill:
SCHEDULED: <2018-07-07 Sat>
:PROPERTIES:
:ID:       385a9a40-8890-4928-b5c5-2c938dec604e
:DRILL_LAST_INTERVAL: 9.9448
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 8
:DRILL_FAILURE_COUNT: 2
:DRILL_AVERAGE_QUALITY: 3.625
:DRILL_EASE: 2.66
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-27 Wed 13:10]
:END:
Definition of *measure* $\mu$.

****** Definition
A *measure* over a σ-algebra $\Sigma$ is a function $\mu \colon \Sigma \to [0,+\infty]$,

 * null, $\mu(\varnothing) = 0$,
 * σ-additive $\mu\left( \bigcup^{\infty}_{k=1} E_k \right) = \sum_{k=1}^{\infty}\mu(E_k)$, if we have $E_i \cap E_j = \varnothing$.

***** Fatou's lemma                                                                                         :drill:
SCHEDULED: <2018-09-04 Tue>
:PROPERTIES:
:ID:       6af0cfe7-d340-4be8-b036-c14f636fd988
:DRILL_LAST_INTERVAL: 74.1784
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 7
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.285
:DRILL_EASE: 2.32
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-22 Fri 22:16]
:END:
Given a measure space $\Sigma$ and functions $f_n \colon X \to [0,+\infty]$; that are
$\Sigma,{\cal B}_{\mathbb{R}}\text{-measurable}$, what does the Fatou's lemma states?

****** Statement
Taking $f(x) = \liminf_{n\to \infty} f_n(x)$; we have that $f$ is $\Sigma,{\cal B}_{\mathbb{R}}\text{-measurable}$ and

\[
\int_X \liminf_{n \to \infty }f_n\ d\mu \leq \liminf_{n\to\infty} \int_X f_n\ d\mu.
\]

**** Differential equations

*** The formation of swarms as a consesus problem - Ulrich Krause
Estructuras complejas globales emergiendo de interacciones locales.
We will use topology instead of differential equations.

**** Model
Ensemble of birds in $\mathbb{R}^{d}$. Others $d$ different than 3 are allowed.
Position $x_i$ and velocity $v_i$ of each bird. The align by averaging.

\[
v_i = \sum_{j \in N} a_{ij}(t) v_i(t)
\]

The coefficients $a_{ij}$ model intensity of interactions; they depend
on the time. The set of seen birds is

S\[
S(i,t) = \left\{ j \in N \mid a_{ij}(t) > 0 \right\}
\]

***** Swarm formation
A swarm can be formed if

\[
\lim_t v_{i}(t) = v
\]

**** Swarm formation - theorem 1
***** Two assumptions
 * Structure not too loose.
 * Interaction does not decay too fast.
**** Swarm formation 2
Interaction only at certain points of time.

***** Core of a stochastic matrix
If $A$ has positive diagonal, $\mathrm{cor}(A) \neq \varnothing \iff A^k$ is scrambling;
we call these matrices *coherent*.

New conditions

 * structure of matrix not too loose;
 * intensity of interaction decays not too fast;
 * intensity of interaction decays slowly.

That can be interpreted as

 * every bird sees itself,
 * there is a sight chain to a leader.

**** Flight formations
***** V-formation and echelon
A leader is the only one in the core
***** Other possible cores: sterling clouds
Loops in the sight chain; connected loops.

****** Systematic account of flight formations?
Graphs changing in time.

****** Computer simulations?

**** Sight cones / cones of vision
Given by direction of flight. Non-convex cones would be also an
option.

***** Farkas lemma
***** Helly's theorem
**** Models of intensity of interaction
Cucker-Smale model of bird flocking.
** Logic                                                                                                       :logic:
*** Basic logic
**** Definition of validity                                                                                  :drill:
SCHEDULED: <2018-11-28 Wed>
:PROPERTIES:
:ID:       edf5dad9-0999-4098-861e-61a16ee7fd2e
:DRILL_LAST_INTERVAL: 199.9033
:DRILL_REPEATS_SINCE_FAIL: 6
:DRILL_TOTAL_REPEATS: 5
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.2
:DRILL_EASE: 2.52
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-05-12 Sat 17:48]
:END:
When is a sentence $\varphi$ *valid*?

***** Answer
$\varphi$ is *valid*, written $\models \varphi$ iff $\model \models \varphi$ for every structure $\model$.
Every structure satisfies the sentence.

**** Definition of soundness                                                                                 :drill:
SCHEDULED: <2019-03-22 Fri>
:PROPERTIES:
:ID:       56f2cb1c-ccdb-4416-b52d-be6fae51723f
:DRILL_LAST_INTERVAL: 272.6464
:DRILL_REPEATS_SINCE_FAIL: 6
:DRILL_TOTAL_REPEATS: 5
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.8
:DRILL_EASE: 2.9
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-22 Fri 22:08]
:END:
When is a proof system *sound*?

***** Answer
When $\Gamma \vdash \Phi$ implies $\Gamma \models \Phi$.

/You cannot prove anything that is wrong./

Where
 
 * $\Gamma \vdash \Phi$ is logical entailment with the inference rules of the system;
 * $\Gamma \models \Phi$, is implication in the desired semantics; every structure satisfies it.

**** Definition of completeness                                                                              :drill:
SCHEDULED: <2019-03-12 Tue>
:PROPERTIES:
:ID:       a9041c29-30d2-406e-a1d8-335b58aa4b5a
:DRILL_LAST_INTERVAL: 263.0187
:DRILL_REPEATS_SINCE_FAIL: 6
:DRILL_TOTAL_REPEATS: 5
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.8
:DRILL_EASE: 2.9
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-22 Fri 22:09]
:END:
When is a proof system *complete*?

***** Answer
When $\Gamma \models \Phi$ implies $\Gamma \vdash \Phi$.

/You can prove everything that is true./

Where
 
 * $\Gamma \vdash \Phi$ is logical entailment with the inference rules of the system;
 * $\Gamma \models \Phi$, is implication in the desired semantics; every structure satisfies it.

*** Intermediate logic - Open Logic, Zach
**** II. First-order logic
***** 5. Syntax and Semantics
****** 5.1. Introduction
 - Syntax :: how well-formed terms and formulas can be defined.
 - Semantics :: how meaning can be given to expressions.

****** 5.2. First-order languages
Any first-order language ${\cal L}$ is determined by logical, non-logical
symbols and some punctuation marks.

******* Logical symbols
 1. Logical connectives: $\neg,\land,\lor,\forall,\exists$,
 2. Propositional constant for falsity: $\bot$,
 3. Binary identity predicate: $=$,
 4. Numerable set of variables: e$v_0,v_1,\dots$

We assume $\top$ and $\leftrightarrow$ as defined as abbreviatures. We could use 
"truth functionally complete" subsets of boolean operators such
as $\{\neg,\lor\}$.

******* Non-logical symbols
 1. A numerable set of n-ary predicates for each $n>0$, as $\{A_0^n,A_1^n,\dots\}$,
 2. A numerable set of constants $c_0,\dots$,
 3. A numerable set of n-ary functions, as $\{f_0^n,f_1^n,\dots\}$.

******* Examples
 - Arithmetic with $S,O,<,+,\times$.
 - Set theory with $\in$.
 - Orders with $\leq$.

****** 5.3. Terms and formulas
******* Terms
The set of *terms* of a language ${\cal L}$ is defined inductively

 1. variables are terms,
 2. constants are terms,
 3. given an n-ary function and $n$ terms, $f(t_1,\dots,t_n)$
    is a term.

Constants are regarded as 0-ary functions.

******* Formulas
The set of *formulas* of a language ${\cal L}$ is defined inductively

 1. $\bot$ is a formula;
 2. given any n-ary predicate and $n$ terms, $R(t_1,\dots,t_n)$ is
    a formula;
 3. given any two terms, $t_1 = t_{2}$ is a formula;
 4. $\neg \varphi$;
 5. $\varphi \lor \psi$;
 6. $\varphi \land \psi$;
 7. $\varphi \to \psi$;
 8. $\forall x. \varphi$;
 9. $\exists x.\varphi$.

******* Syntatic identity
Two strings of symbols are syntatically identical, $\varphi \equiv \psi$, if
they contain the same symbols in the same place.

****** 5.4. Unique readability
Every formula has a unique reading. The correct definitions, using
parentheses constraint the set of possible formulas.  The number of
left and right parentheses in a formula are equal, by induction.

******* Proper prefixes
A string $\varphi$ is a *proper prefix* of $\psi$ if it can be obtained by 
appending symbols to $\varphi$.

#+ATTR_LATEX: :options []
#+BEGIN_lemma
Every proper prefix of a formula is not a formula.
#+END_lemma
#+BEGIN_proof
Using the fact that there is an equal number of left and right
parentheses in every formula.
#+END_proof

******* Unique readability
Every atomic formula satisfies one and only one of the following
conditions

 1. $\varphi \equiv \bot$
 2. $\varphi \equiv R(t_1,\dots,t_n)$
 3. $\varphi \equiv t_1 = t_2$

And every formula is of the form

 1. atomic
 2. $\neg \psi$
 3. $\varphi \lor \psi$
 4. $\varphi \land \psi$
 5. $\psi \to \varphi$
 6. $\forall x.\psi$
 7. $\exists x.\psi$

The proof crucially uses the fact that no formula is a proper prefix
of any other formula.

****** 5.5. Main operator of a formula
The outermost operator of a formula exists if the formula is not
atomic. It is always unique, as we have proved earlier.

****** 5.6. Subformulas
******* Immediate subformulas
*Immediate subformulas* are defined inductively as

 1. no subformulas for atomic formulas;
 2. $\varphi$ and $\psi$ are immediate subformulas of $\varphi \ast \psi$;
 3. $\psi$ is an immediate subformula of $\forall x.\psi$;
 4. $\psi$ is an immediate subformula of $\exists x.\psi$.

******* Proper subformulas
The *proper subformulas* of a formula are its immediate subformulas and
their proper subformulas.

We also consider the formula to be a non-proper subformula of itself.

****** 5.7. Free variables and sentences
A variable appears *free* when it is not bounded by a quantifier. The
precise definition can be trivially written by induction. Every
bounded variable has a *scope*, a subformula over which the quantifier
acts.

******* Sentences
A formula is a *sentence* if it contains no free ocurrences of variables.

****** 5.8. Substitution
*Substitution* of a variable by a term, $s[t/x]$, can be recursively
defined as

 * $c[t/x]$ is $c$, provided $c$ is a constant;
 * $y[t/x]$ is $y$, provided $y$ is a variable;
 * $x[t/x]$ is $t$;
 * $f(t_1,\dots,t_n)[t/x]$ is $f(t_1[t/x],\dots,t_n[t/x])$.

Substitution can be extended trivially to formulas; but we have to
check that every term appears free for the variable in order to avoid
undesired bounds for a variable.

****** 5.9. Structures for first-order languages
*Structures* are the basis for /semantic notions/. A structure $\model$ for
a language ${\cal L}$ consists of

 1. a *domain*, a non empty set $|\model|$;
 2. an interpretation for each *constant*, $c^{\model} \in |\model|$;
 3. an interpretation for each *predicate*, $R^{\model} \subseteq |\model|^n$;
 4. an interpretation for each *function*, $f^{\model} \colon |\model|^n\to |\model|$.

Non emptiness ensures that the existential generalization is sound.

******* Examples
 - Standard model of arithmetic.
 - Structure of hereditarily finite sets.

****** 5.10. Covered structures for first-order languages
******* Values
The value of a term is defined recursively as

 * $\mathrm{Val}^{\model}(c) = c^{\model}$;
 * $\mathrm{Val}^{\model}(f(t_1,\dots,t_n)) = f^{\model}(\mathrm{Val}^{\model}(t_1),\dots \mathrm{Val}^{\model}(t_n))$.

******* Covered structures
A structure is covered if every element is the value of some
closed term.

****** 5.11. Satisfaction of a formula in a structure
******* Satisfaction
A formula is *satisfied* in a structure if the interpretation makes
the formula true.

******* Variable assignment
A problem with quantifiers arise when we try to interpret free variables.
We need to define *variable assignments*, functions $s : \mathrm{Var} \to |\model|$.

The value of a variable $x$ under an assignment $s$ is given by $s(x)$.

******* x-Variant
Any variable assignment $s'$ which differs from $s$ at most in one variable $x$ is
called an *x-variant*, and written as $s \sim_x s'$.

******* Satisfaction
*Satisfaction* of a formula $\varphi$ in a structure $\model$ relative to a variable
assignment $s$; written as $\model,s \models \varphi$ is defined recursively as

 1. $\model,s \not\models \bot$;
 2. $\model, s \models R(t_1,\dots,t_n)$ iff $\langle \mathrm{Val}^{\model}_s(t_1),\dots,\mathrm{Val}^{\model}_s(t_n) \rangle \in R^{\model}$;
 3. $\model,s \models t_1 = t_2$ iff $\mathrm{Val}^{\model}_s(t_1) = \mathrm{Val}^{\model}_s(t_2)$;
 4. $\model,s \models \neg\varphi$ iff $\model,s \not\models \varphi$;
 5. $\model,s \models \varphi \land \psi$ iff $\model,s \models \varphi$ and $\model,s \models \psi$;
 6. $\model,s \models \varphi \lor \psi$ iff $\model,s \models \varphi$ or $\model,s \models \psi$;
 7. $\model,s \models \varphi \to \psi$ iff  $\model,s \not\models \varphi$ or $\model,s \models \psi$;
 8. $\model,s \models \forall x. \varphi$ iff $\model,s' \models \varphi$ for every x-variant $s'$;
 9. $\model,s \models \exists x. \varphi$ iff $\model,s' \models \varphi$ for some x-variant $s'$;

Variable assignments are crucial here because we have to define a
formula for every $a \in |\model|$, but $a$ is not a formula.

****** 5.12. Variable assignments
Two assignments assigning the same value to the same free variables
produce the same values and entail the same formulas. In particular,
in the case of *sentences* without free variables, the truth value
is independent of the variable assignment.

******* Independence of variables in values
#+BEGIN_proposition
If $t$ has variables among $x_1,\dots,x_n$ and $s_1(x_i) = s_2(x_i)$; then
$\mathrm{Val}^{\model}_{s_1}(t) = \mathrm{Val}^{\model}_{s_2}(t)$.
#+END_proposition

Trivially by induction.

******* Independence of variables in formulas
#+BEGIN_proposition
If $\varphi$ has variables among $x_1,\dots,x_n$ and $s_1(x_i) = s_2(x_i)$; then
$\model,s_1 \models \varphi$ iff $\model,s_2 \models \varphi$.
#+END_proposition

Again by induction.

******* Satisfaction in a structure
A structure $\model$ *satisfies* $\varphi$, and it is written as $\model \models \varphi$, if
$\model, s \models \varphi$ for all variable assignments $s$.

****** 5.13. Extensionality
Where two structures agree on all elements, they entail the same truth
values. If $\model_1$ and $\model_2$ agree on constants, relations and functions;
$\model_1,s \models \varphi$ iff $\model_2,s \models \varphi$.

In particular, this happens for any sentence.

******* Dependence on subterms for values
Given a structure $\model$ and $s$ with $s \sim_x s'$ given by $s'(x) = \mathrm{Val}^{\model}_s(t')$.
Then $\mathrm{Val}^{\model}_s(t[t'/x]) = \mathrm{Val}^{\model}_{s'}(t)$.

******** Proof by induction
******* Dependence on subterms for formulas
Given a structure $\model$ and $s$ with $s \sim_x s'$ given by $s'(x) = \mathrm{Val}^{\model}_s(t)$.
Then $\model,s \models \varphi[t/x]$ iff $\model,s' \models \varphi$.

****** 5.14. Semantics notions
Semantic properties.

******* Validity
$\varphi$ is *valid*, written $\models \varphi$ iff $\model \models \varphi$ for every structure $\model$.

******* Entailment
A set of sentences $\Gamma$ *entails* $\varphi$, written $\Gamma \models \varphi$ iff $\model \models \varphi$ for
every structure such that $\model \models \Gamma$.

******* Satisfiability
A set of sentences $\Gamma$ is *satisfiable* if $\model \models \Gamma$ for some structure
$\model$.

******* Validity and entailment
A sentence $\varphi$ is valid iff $\Gamma \models \varphi$ for any set of sentences $\Gamma$.

******* Satisfiability and entailment
$\Gamma \models \varphi$ iff $\Gamma \cup \{\neg \varphi\}$ is unsatisfiable.

******* Strengthening
If $\Gamma \subseteq \Gamma'$ and $\Gamma \models \varphi$, then $\Gamma' \models \varphi$.

******* Semantic deduction theorem
$\Gamma \cup \{\varphi\} \models \psi$ iff $\Gamma \models \varphi \to \psi$.

******* Quantifiers and entailment
 1. $\varphi(t) \entail\exists x.\varphi(x)$,
 2. $\forall x. \varphi(x) \entail \varphi(t)$.
***** 6. Theories and their models
****** 6.1. Introduction
******* Closure
A set of sentences $\Gamma$ is *closed* if it is equal to its closure,
$\{ \varphi : \Gamma \models \varphi\}$. $\Gamma$ is *axiomatized* by $\Delta$ if it is its closure.

****** 6.2. Expressing properties of structures
******* Model
The structure $\model$ is a *model* of $\Gamma$ if $\model \models \varphi$ for all $\varphi \in \Gamma$.

****** 6.3. Examples of first-order theories
******* Strict linear orders
******* Theory of groups
******* Peano arithmetic with induction schemas
******* Pure sets with naive comprehension schemes
****** 6.4. Expressing relations in a structure
A formula $\varphi(v_1,\dots,v_n)$ expresses the relation $R \subseteq |\model|^n$ if
\[
Ra_1\dots a_n
\quad\mbox{ iff }\quad
\model,s \models \varphi(v_1,\dots,v_n)
\]
for any variable assignment such that $s(v_i) = a_i$.

****** 6.5. The theory of sets
ZFC is the most widely studied axiomatic system for set theory.
Inclusion can be defined by defining membership, and sets have
to be implicitely defined.

For example, the empty set $\varnothing$ is defined with
\[
\exists x. (\neg \exists y. y \in x) \land (\forall z. x \subseteq z)
\]
and operations on set could be defined in the same way.

The comprehension principle is inconsistent (Russell's paradox),
therefore, ZFC only allows the separation principle,
\[
\forall z. \exists y. \forall x. (x \in y \leftrightarrow (x \in z \land \varphi(x))).
\]

****** 6.6. Expressing the size of structures
There are sentences which are true in a structure iff the domain
has a specific size. The property of being non-enumerable or being
finite cannot be expressed even with an infinite set of sentences
(Löwenheim-Skolem theorems).

**** III. Proofs and completeness
***** 7. The Sequent Calculus
****** 7.1. Rules and derivations
******* 7.1. Sequent
A *sequent* is an expression $\Gamma \seq \Delta$ between sequences of
sentences. Semantically, it means that, if $\Gamma = \left\langle \varphi_1,\dots,\varphi_n \right\rangle$
and $\Delta = \left\langle \psi_1,\dots,\psi_m \right\rangle$,

\[
(\varphi_1 \land \dots \land \varphi_n) \to
(\psi_1 \lor \dots \lor \psi_m).
\]

******* 7.2. Initial sequent
An *initial sequent* is of the form

 1. $\varphi \seq \varphi$
 2. $\bot \seq$

where $\varphi$ is a sentence.

****** 7.2. Propositional rules
******* Rules for negation
Formation (L)

\[\begin{prooftree}
\AX$\Gamma \fCenter\seq \Delta,\varphi$
\UI$\neg \varphi, \Gamma \fCenter\seq \Delta$
\end{prooftree}\]

Formation (R)

\begin{prooftree}
\AX$\varphi, \Gamma \fCenter\seq \Delta$
\UI$\Gamma \fCenter\seq \Delta,\neg \varphi$
\end{prooftree}

******* Rules for conjunction
Formation (L)

\begin{prooftree}
\AX$\varphi, \Gamma \fCenter\seq \Delta$
\UI$\varphi \land \psi, \Gamma \fCenter\seq \Delta$
\end{prooftree}

Formation (R)

\begin{prooftree}
\AXC{$\Gamma \seq \Delta,\varphi$}
\AXC{$\Gamma \seq \Delta,\psi$}
\BIC{$\Gamma \seq \Delta,\varphi \land \psi$}
\end{prooftree}

******* Rules for disjunction
Formation (L)

\begin{prooftree}
\AXC{$\varphi, \Gamma \seq \Delta$}
\AXC{$\psi, \Gamma \seq \Delta$}
\BIC{$\varphi \lor \psi, \Gamma \seq \Delta$}
\end{prooftree}

Formation (R)

\begin{prooftree}
\AX$\Gamma \fCenter\seq \Delta,\varphi$
\UI$\Gamma \fCenter\seq \Delta,\varphi \lor \psi$
\end{prooftree}

******* Rules for implication
Formation (L)

\begin{prooftree}
\AXC{$\Gamma \seq \Delta,\varphi$}
\AXC{$\psi, \Pi \seq \Lambda$}
\BIC{$\varphi \to \psi, \Gamma, \Pi \seq \Delta,\Lambda$}
\end{prooftree}

Formation (R)

\begin{prooftree}
\AX$\varphi, \Gamma \fCenter\seq \Delta, \psi$
\UI$\Gamma \fCenter\seq \Delta, \varphi \to \psi$
\end{prooftree}

****** 7.3. Quantifier rules
******* Rules for universal quantifiers
Formation (L), where $t$ is a closed term

\begin{prooftree}
\AX$\varphi(t), \Gamma \fCenter\seq \Delta$
\UI$\forall x.\varphi(x), \Gamma \fCenter\seq \Delta$
\end{prooftree}

Formation (R), where $a$ is an *eigenvalue*; a constant which must not
occur anywhere in the lower sequent

\begin{prooftree}
\AX$\Gamma \fCenter\seq \Delta, \varphi(a)$
\UI$\Gamma \fCenter\seq \Delta, \forall x.\varphi(x)$
\end{prooftree}

******* Rules for existential quantifiers
Formation (L), where $a$ is an *eigenvalue*

\begin{prooftree}
\AX$\varphi(a), \Gamma \fCenter\seq \Delta$
\UI$\exists x.\varphi(x), \Gamma \fCenter\seq \Delta$
\end{prooftree}

Formation (R), where $t$ is a closed term

\begin{prooftree}
\AX$\Gamma \fCenter\seq \Delta, \varphi(t)$
\UI$\Gamma \fCenter\seq \Delta, \exists x.\varphi(x)$
\end{prooftree}

****** 7.4. Structural rules
******* Weakening
Left weakening

\begin{prooftree}
\AX$\Gamma \fCenter\seq \Delta$
\UI$\varphi, \Gamma \fCenter\seq \Delta$
\end{prooftree}

Right weakening

\begin{prooftree}
\AX$\Gamma \fCenter\seq \Delta$
\UI$\Gamma \fCenter\seq \Delta, \varphi$
\end{prooftree}

******* Contraction
Left contraction

\begin{prooftree}
\AX$\varphi, \varphi, \Gamma \fCenter\seq \Delta$
\UI$\varphi, \Gamma \fCenter\seq \Delta$
\end{prooftree}

Right contraction

\begin{prooftree}
\AX$\Gamma \fCenter\seq \Delta, \varphi, \varphi$
\UI$\Gamma \fCenter\seq \Delta, \varphi$
\end{prooftree}

******* Exchange
Left exchange

\begin{prooftree}
\AX$\Gamma, \varphi, \psi, \Pi \fCenter\seq \Delta$
\UI$\Gamma, \psi, \varphi, \Pi \fCenter\seq \Delta$
\end{prooftree}

Right exchange

\begin{prooftree}
\AX$\Gamma \fCenter\seq \Delta, \varphi, \psi, \Lambda$
\UI$\Gamma \fCenter\seq \Delta, \psi, \varphi, \Lambda$
\end{prooftree}

******* Cut
Cut is not necessary, but makes it easier to reuse derivations

\begin{prooftree}
\AXC{$\Gamma \seq \Delta,\varphi$}
\AXC{$\varphi, \Pi \seq \Lambda$}
\BIC{$\Gamma,\Pi \seq \Delta, \Lambda$}
\end{prooftree}

It follows from the implication rule.

****** 7.5. Derivations
******* LK-derivation
An *LK-derivation* of a sequent is a tree of sequents starting from
initial sequents and applying inference rules.

****** 7.6. Examples of derivations
****** 7.7. Derivations with quantifiers
****** 7.8. Proof-theoretic notions
******* Theorems
A *theorem* is a sentence $\varphi$ such that there is a derivation of $\seq \varphi$.
We write $\vdash \varphi$ if it is a theorem and $\not\vdash \varphi$ if it is not.

******* Derivability
A sentence $\varphi$ is *derivable* from $\Gamma$ if there is a finite subset $\Gamma' \subseteq \Gamma$
such that the system derives $\Gamma \seq \varphi$. We write $\Gamma \vdash \varphi$ if $\varphi$ is derivable,
we write $\Gamma \not\vdash \varphi$ if it is not.

******* Consistency
A set of sentences $\Gamma$ is *inconsistent* if a finite subset $\Gamma' \subseteq \Gamma$ derives
$\Gamma' \seq$ . If a system is not inconsistent, it is *consistent*.

******* Reflexivity
If $\varphi \in \Gamma$, then $\Gamma \vdash \varphi$.

******** Proof
$\varphi \seq \varphi$ is an initial sequent.

******* Monotony
If $\Gamma \subseteq \Delta$ and $\Gamma \vdash \varphi$, then $\Delta \vdash \varphi$.

******** Proof
Given $\Gamma' \subseteq \Gamma \subseteq \Delta$, we know that $\Gamma' \subseteq \Delta$.

******* Transitivity
If $\Gamma \vdash \varphi$ for every $\varphi \in \Delta$ and $\Delta \vdash \psi$, then $\Gamma \vdash \varphi$.

******** Proof
If $\Delta \vdash \psi$, then there exists a finite $\Delta_0 \seq \psi$. We proceed by
induction on the size of $\Delta_0$,

 * if $\Delta_0$ is empty, $\seq \psi$ and, in particular $\Gamma \vdash \psi$;
 * if $\varphi \in \Delta_0$, we define $\Delta_1 = \Delta_0 \setminus \{\varphi\}$; and we know that $\varphi, \Delta_1 \seq \psi$,
   so $\Delta_1 \seq \varphi \to \psi$. By induction hypothesis, there exist $\Gamma_0 \seq \varphi \to \psi$
   and $\Gamma_1 \seq \varphi$; thus $\varphi \to \psi, \Gamma_1 \seq \psi$ and, by cut elimination rule,
   $\Gamma_0, \Gamma_1 \seq \psi$.

******* Principle of explosion
$\Gamma$ is inconsistent iff $\Gamma \vdash \varphi$ for every $\varphi$.

******** Proof
If $\Gamma \seq \bot$, by cut elimination, $\Gamma \seq$ . If $\Gamma \seq$ , then by
weakening, $\Gamma \seq \varphi$.

******* Compactness
 1. If $\Gamma \vdash \varphi$, there exists a subset $\Gamma_0 \subseteq \Gamma$ such that $\Gamma_0 \vdash \varphi$.
 2. If every subset of $\Gamma$ is consistent, $\Gamma$ is consistent.

******** Proof
By definition of derivability.

****** 7.9. Derivability and consistency
******* Transitivity of inconsistency
If $\Gamma \vdash \varphi$ and $\Gamma \cup \{\varphi\}$ is inconsistent, $\Gamma$ is inconsistent.

******** Proof
We have $\Gamma_0,\Gamma_1 \subseteq \Gamma$ such that $\Gamma_0 \seq \varphi$ and $\varphi, \Gamma_1 \seq$ ; thus,
by cut elimination, $\Gamma_0, \Gamma_1 \seq$.

****** 7.10. Derivability and the propositional connectives
******* Conjunction
We know that

 * $\varphi \land \psi \vdash \varphi$
 * 4$\varphi \land \psi \vdash \psi$
 * $\varphi, \psi \vdash \varphi \land \psi$

******** Proof
Applying the propositional rules for conjunction, we know that
$\varphi \land \psi \seq \varphi$ and $\varphi \land \psi \seq \psi$; while applying the right hand
side rule, $\varphi, \psi \seq \varphi \land \psi$.

******* TODO Disjunction

****** 7.11. Derivability and the quantifiers
******* Derivability of the universal quantifier
If $\Gamma \vdash \varphi(c)$ and $c$ does not appear in $\Gamma$; $\Gamma \vdash \forall x.\varphi(x)$.

******** Proof
Trivial by definition of derivability.

******* Initial derivations for quantifiers
 1. $\varphi(t) \vdash \exists x.\varphi(x)$
 2. $\forall x.\varphi(x) \vdash \varphi(t)$

******** Proof
Both are derivable from the quantifier rules.

****** 7.12. Soundness
******* Satisfaction of a sequent
A structure $\model$ *satisfies* a sequent $\Gamma \seq \Delta$ if and only if $\model \not\models \varphi$ for
some $\varphi \in \Gamma$ or $\model \models \varphi$ for some $\varphi \in \Delta$.

******* Valid sequents
A sequent is *valid* if every structure $\model$ satisfies it.

******* Soundness
If LK derives $\Theta \seq \Xi$, then it is a valid sequent.

******** Proof
By structural induction on the derivation. If it has no inferences,
it has to be an initial sequent, and $\varphi \seq \varphi$ and $\bot \seq$  are valid
sequents. In other case, we apply structural induction to get

 1. left and right weakening, trivially;
 2. left and right negation, trivially;
 3. left conjunction, trivially;
 4. right disjunction, trivially;
 5. right implication, trivially;
 6. universal quantifiers, trivially using previous lemmas;

with one premise, and

 1. cut elimination,
 2. right conjunction,
 3. left disjunction,

with two premises. All are valid by the definition of [[*Satisfaction of a sequent][satisfaction]] and
the notion of [[*Satisfaction][satisfaction]] of a formula in a structure.

***** 8. The Completeness Theorem
****** 8.3. Complete consistent sets of sequences
******* Complete set
A set $\Gamma$ is *complete* iff for any sentence either $\varphi \in \Gamma$
or $\neg \varphi \in \Gamma$.

******** Membership
In particular, $\varphi \not\in \Gamma$ implies $\neg\varphi\in\Gamma$.

******* Complete consistent sets
If $\Gamma$ is complete and consistent,

 1. if $\Gamma \vdash \varphi$, then $\varphi \in \Gamma$;
 2. $\varphi \land \psi \in \Gamma$ iff $\varphi \in \Gamma$ and $\psi \in \Gamma$;
 3. $\varphi \lor \psi \in \Gamma$ iff $\varphi \in \Gamma$ or $\psi \in \Gamma$;
 4. $\varphi \to \psi \in \Gamma$ iff $\varphi \not\in \Gamma$ or $\psi \in \Gamma$.

****** 8.4. Henkin expansion
Henkin expansion adds infinitely many constant symbols to allow
existential quantifiers to be satisfied by one of these symbols.

******* Extension of consistency
If $\Gamma$ is consistent in ${\cal L}$ and we obtain a new language by adding
a numerable set of constants, ${\cal L}'$, then $\Gamma$ is consistent in ${\cal L}'$.

******** Proof
Trivial by definition of [[*Consistency][consistency]].

******* Saturated set
A set $\Gamma$ is *saturated* iff for each formula $\varphi(x) \in \mathrm{Frm}({\cal L})$ where
$x$ is a free variable, there is a constant symbol $c \in {\cal L}$ such that
$\exists x.\varphi(x) \to \varphi(c) \in \Gamma$.

******* Theta sentences
Given a language ${\cal L}'$ and an enumeration $\varphi_i(x_i)$ of formulas of ${\cal L}'$ in
which a variable $x_i$ occurs free.

Let $c_0$ be the first fresh constant symbol not in $\varphi_0(x_0)$, and $c_n$
the first fresh constant symbol not in $\theta_0,\dots,\theta_{n-1}, \varphi_n(x_n)$.

We define $\theta_n$ as $\exists x_n. \varphi_n(x_n) \to \varphi(c_n)$.

******* Extension of saturation
If $\Gamma$ is consistent, it can be extended to a saturated consistent set
$\Gamma'$.

******** Proof
Given ${\cal L}$, we get ${\cal L}'$, and then let using [[*Theta sentences][theta sentences]],

 * $\Gamma_0 = \Gamma$,
 * $\Gamma_{n+1} = \Gamma_n \cup \{\theta_n\}$,

then $\Gamma' = \bigcup \Gamma_n$ is saturated. If it were [[*Consistency][inconsistent]], empty could be
derived from a finite set of sentences, so some $\Gamma_n$ would be inconsistent.
We will show that each $\Gamma_n$ is consistent. If we had

 * $\Gamma_n \vdash \neg\{\theta_n\}$,

where $\theta_n$ is $\exists x_n.\varphi_n(x_n)$ then we would have

 * $\Gamma_n \vdash \exists x_n. \varphi_n(x_n)$,
 * $\Gamma_n \vdash \neg \varphi_n(c_n)$;

but as $c_n$ does not appear in $\Gamma_n$, $\Gamma_n \vdash \forall x.\neg \varphi_n(x)$ and then

\[
\forall x.\neg \varphi_n(x) \vdash \neg \exists x_{n}.\varphi_n(x)
\]

thus making $\Gamma_{n}$ inconsistent.

******* Complete, consistent and saturated sets
If $\Gamma$ is complete, consistent and saturated

 1. $\exists x.\varphi(x) \in \Gamma$ iff there exists $\varphi(t) \in \Gamma$, for some $t$;
 2. $\forall x.\varphi(x) \in \Gamma$ iff $\varphi(t) \in \Gamma$ for all closed $t$.

******** Proof
 1. By saturation we have $\exists x.\varphi(x) \to \varphi(c)$ for
    some $c$; then by completion, $\varphi(c) \in \Gamma$ or $\neg\varphi(c) \in \Gamma$;
    but only the first case allows consistency to be true.

    In the other direction, if $\varphi(t) \in \Gamma$, then by completion
    and consistency, $\exists x.\varphi(x) \in \Gamma$.

 2. If $\forall x.\varphi(x) \in \Gamma$, then for every $t$, by completion, we have $\varphi(t) \in \Gamma$
    or $\neg \varphi(t) \in \Gamma$; if we had $\neg\varphi(t)$, it would be inconsistent.

    In the other direction, by completion, if we had $\neg\forall x.\varphi(x) \in \Gamma$
    then we deduce $\exists x. \neg \varphi(x) \in \Gamma$, and by saturation and completion,
    again, $\neg \varphi(c) \in \Gamma$.

****** 8.5. Lindenbaum's lemma
******* Lindenbaum's lemma
Every consistent set $\Gamma'$ in a language ${\cal L}'$ can be extended to a complete
and consistent set $\Gamma^{\ast}$.

******** Proof
We take $\Gamma_0 = \Gamma'$ and we enumerate all formulas $\{\varphi_i\}$. At each step we
add $\Gamma_{n+1} = \Gamma_n \cup \{\varphi_{n}\}$ if it is consistent or $\Gamma_{n+1} = \Gamma_n \cup \{\neg\varphi_{n}\}$ 
otherwise. Let $\Gamma^{\ast} = \bigcup \Gamma_n$.

If both $\Gamma_n\cup \{\varphi_n\}$ and $\Gamma_n\cup \{\neg\varphi_n\}$ were inconsistent, $\Gamma_n$ would be
inconsistent. Thus, every subset of $\Gamma^{\ast}$ is consistent and it has to be
consistent.

****** 8.6. Construction of a model
******* Term model
Given $\Gamma^{\ast}$ complete, consistent and saturate; the *term model* $\model(\Gamma^{\ast})$ is
defined with

 1. domain $|\model(\Gamma^{\ast})|$ given by the set of closed terms;
 2. the interpretation of every constant as itself, $c^{\model(\Gamma^{\ast})} = c$;
 3. the function symbol is assigned to a function which returns the
    closed term of that function, $f^{\model(\Gamma^{\ast})}(t_1,\dots,t_n) = f(t_1,\dots,t_n)$;
 4. and if $R$ is an n-place symbol,
    \[
    \left\langle t_1,\dots,t_n \right\rangle \in R^{\model(\Gamma^{\ast})}
    \text{ iff }
    R(t_1,\dots,t_n) \in \Gamma^{\ast}.
    \]

******* TODO Term model and quantifiers
# Our model is covered

******* Truth lemma
If $\varphi$ does not contain $=$, then $\model(\Gamma^{\ast})\models \varphi$ iff $\varphi \in \Gamma^{\ast}$.

First-order logic for sets $\Gamma$ that do not contain $=$ is complete.

******** TODO Proof

****** 8.7. Identity
******* Factoring identity
Given $\Gamma^{\ast}$ a consistent and complete set in ${\cal L}$, the *relation* $\approx$ is
defined as $t \approx t'$ iff $t=t' \in \Gamma^{\ast}$.

******* TODO Properties of the new identity relation

******* Equivalence classes
Given $\Gamma^{\ast}$ a consistent and complete set in ${\cal L}$, then $t$ is a term and
$\approx$ as in the previous definition,

\[
[t]_{\approx} = \left\{ t' : t' \in \mathrm{Trm}({\cal L}), t \approx t' \right\};
\]

and $\mathrm{Trm}({\cal L})/_{\approx} = \left\{ [t]_{\approx} : t \in \mathrm{Trm}({\cal L}) \right\}$.

******* Representative term structure
****** 8.8. Completeness theorem
******* Gödel's Completeness theorem
Let $\Gamma$ be a set of sentences; if it is consistent, it is satisfiable.

******** Proof
There is a saturated $\Gamma' \supseteq \Gamma$, and there is a $\Gamma^{\ast} \supseteq \Gamma'$ consistent and
complete; while it is also saturated. If $\Gamma$ contains $=$, then we compute
the quotient to have $\model/_{\approx}\models \varphi$ iff $\varphi \in \Gamma^{\ast}$.

******* Completeness theorem, second version
For all $\Gamma$ and $\varphi$, if $\Gamma\models\varphi$, then $\Gamma \vdash \varphi$.

******** Proof
If $\Gamma \models \varphi$, then $\Gamma \cup \{\neg\varphi\}$ is unsatisfiable; by completeness theorem,
it has to be inconsistent, so $\Gamma \vdash \varphi$.

****** TODO 8.9. Compactness theorem
****** TODO 8.10. A direct proof of the compactness theorem
****** TODO 8.11. The Löwenheim-Skolem theorem
****** TODO 8.12. Overspill
*** ZFC - Pablo Baeyens
# Estos apuntes han sido tomados durante el seminario de Pablo
# Baeyens para LibreIM sobre ZFC. El artículo que acompaña a
# este seminario puede leerse en
#
#  http://tux.ugr.es/libreim/blog/2017/03/25/zfc/
#
# Estos apuntes están licenciados bajo CC-BY-SA.
Utilizando lógica de primer orden.

\[
\wedge, \implies, \iff, \forall, \exists
\]

Además de:

- Un conjunto infinito numerable de variables: $x_1,x_2,\dots$
- Sólo puede cuantificarse sobre variables.
- Reglas para fórmulas bien formadas.

Símbolos propios de la teoría de conjuntos:

- $=, \in$

Se usa internamente la axiomática de la lógica de primer orden.

**** Axiomas de la igualdad
La igualdad es relación de equivalencia. Es

 1. Reflexiva, $\forall x: x=x$.
 2. Transitiva, $\forall x,y,z: x=y \wedge x=y \implies x=z$.
 3. Simétrica, $\forall x,y : x=y \iff y=x$.
 4. Sustitución, $\forall x,y: x=y \implies \varphi \iff \varphi'$ donde $\varphi'$ sale de sustituir $x$.

**** Números como conjuntos
Algunas teorías consideran elementos que no tienen elementos dentro.
En nuestro caso usaremos conjuntos para representar todos los objetos
matemáticos.

***** Números naturales
Definimos:

 - $0 = \varnothing$
 - $S(x) = x \cup \{x\}$

***** Otra construcción posible
Definiendo:

 - $\varnothing$
 - $S(x) = \{x\}$

***** Construcción de funciones
Para definir una función, usamos su gráfico:

\[\{(a,b) \in A \times B \mid f(a) = b\}\]

**** Restricciones
No podemos hablar todavía del conjunto de todos los conjuntos. Dentro
de ZFC no podemos hablar de cosas como $Obj(\mathtt{Set})$.

**** Axiomas de la teoría de conjuntos
Tomamos como ciertos:

***** 0. Axioma de existencia
$\exists x : x=x$

***** 1. Axioma de extensionalidad
$\forall x,y:(\forall z: z\in x \implies z \in y) \implies x = y$

De paso definimos la inclusión:

\[
x \subseteq y := \forall z: z\in x \implies z \in y
\]

Y este axioma es equivalente a la antisimetría de la inclusión.

***** 2. Axioma de comprensión
Exigiendo que $A$ no aparezca como variable libre en $\varphi$.

\[
\forall A: \exists B: \forall z:\left( \varphi(z) \vee z \in A\right) \iff z \in B
\]

Puede usarse para demostrar que existe el conjunto vacío. O que
no existe el conjunto universal.

****** Paradoja de Russell
Supongamos el universal $U$. Podríamos definir:

\[
R = \{x \in U \mid x \notin x\}
\]

Tanto $R \in R$ como $R \notin R$. Para evitarla podríamos haber usado
estratificación.

****** El número de axiomas es numerable
Las fórmulas son sucesiones finitas de los símbolos que hemos usado
antes. Al haber una cantidad numerable de símbolos, las fórmulas son
numerables, y los axiomas que se generan en este esquema lo son.

****** NBG
En la teoría axiomática de Von-Neumann se usa un número finito de
axiomas.

****** Diferencia de conjuntos
\[A-B = \{x \in A \mid x \notin B\}\]

****** Intersección de conjuntos
Nótese que todavía no podemos definir la unión arbitraria.

\[
\bigcap {\cal F} = \{x \in A \mid \forall y \in {\cal F} x \in y\}
\]

***** 3. Axioma del par
Dados dos conjuntos, tenemos uno que los contiene a los dos:

\[
\forall a,b : \exists z:
(a\in z \vee b \in z)
\]

****** Naturales
Con este axioma podemos construir los naturales en su segunda 
construcción.

****** Hay conjuntos no vacíos
Hasta ahora, los axiomas eran consistentes con que sólo existiera
el conjunto vacío.

****** Pares ordenados
Definimos un par ordenado:

\[
(a,b) := \{a , \{a,b\}\}
\]

***** 4. Axioma de la unión
Para una colección de conjuntos, crearemos una unión:

\[
\forall {\cal F}: \exists A: \forall Y,x: (x \in Y \wedge Y \in {\cal F}) \implies x \in A
\]

***** 5. Axioma del infinito
Construye directamente los números naturales:

\[
\exists I: \varnothing \in I \wedge \forall x: x\in I \implies S(x) \in I \longrightarrow \exists \mathbb{N}
\]

Lleva a la existencia de cardinales grandes.

****** Finitud
Hasta ahora, podríamos trabajar suponiendo todos los conjuntos finitos.

***** 6. Axioma del conjunto potencia
Existencia del conjunto potencia:

\[
\forall x: \exists y: \forall z: z \subseteq x \implies z \in y
\]

****** Producto cartesiano
Podemos definir el producto cartesiano de $A,B$. Tenemos que todos los
elementos $a\in A,b \in B$ llevan a $\{a,b\} \in {\cal P}(A,B)$.

\[
A \times B = \{ x \in {\cal P}{\cal P}(A \cup B) \mid x = (a,b), a \in A, b \in B\}
\]

Nótese que así sólo hemos creado el producto cartesiano finito.

****** Funciones
Con el producto cartesiano, podemos pasar a ver las funciones como su
gráfico.
***** 7. Axioma de reemplazamiento
Con estos seis axiomas, que constituyen la teoría de Zermelo, no
podemos definir el conjunto con:

\[
\mathbb{N}, {\cal P}\mathbb{N}, {\cal P}{\cal P}\mathbb{N}, \dots
\]

Un predicado funcional es una fórmula con variables libres $\varphi(x,y)$ 
que se comporta como una función:

\[
\forall x: \exists! y: \varphi(x,y)
\]

Tenemos entonces:

\[
\forall z: \exists \omega: \forall x,y: (x \in z \wedge \varphi(x,y) \implies y \in \omega)
\]

****** Definiendo el conjunto de potencias
Usando la función $n \mapsto {\cal P}^n(\mathbb{N})$.

****** Definiendo la imagen por un funcional
Definimos $\{x \in A \mid \phi(x)\}$ partiendo en el caso de que exista y 
de que no.

****** No existe el conjunto de todos los conjuntos.
Si existiera, podríamos usar todas las topologías triviales y desde ahí
el conjunto universal.
***** 8. Axioma de elección
Para cualquier familia de conjuntos sin ninguno vacío,

\[
\forall {\cal F} : 
\left(
\forall x \in {\cal F} :\varnothing \neq x
\implies 
\exists f : {\cal F} \to \bigcup {\cal F}: f(a) \in A
\right)
\]

Siendo $f$ una función.

***** 9. Axioma de fundación
Para cualquier conjunto no vacío:

\[
\forall x: (x \neq \varnothing \implies \exists y: y \in x \wedge x \cap y = \varnothing)
\]
** Programming                                                                                           :programming:
*** Coq tactics
**** Difference Defined / Qed                                                                              :nodrill:
SCHEDULED: <2019-03-03 Sun>
:PROPERTIES:
:ID:       5cf0a7c8-363d-484d-a007-aa8105effeed
:DRILL_LAST_INTERVAL: 253.9188
:DRILL_REPEATS_SINCE_FAIL: 6
:DRILL_TOTAL_REPEATS: 5
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.8
:DRILL_EASE: 2.9
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-22 Fri 22:00]
:END:
What is the difference between =Defined= and =Qed=?

***** Answer
=Defined= produces a *transparent definition* whereas =Qed= provides
an *opaque one*.

Reference: http://gallium.inria.fr/blog/coq-eval/

**** Tactics
***** Coq Tactic                                                                                          :nodrill:
SCHEDULED: <2019-03-16 Sat>
:PROPERTIES:
:DRILL_CARD_TYPE: hide1cloze
:ID:       17c701dd-28d1-4e03-9b29-43cb7bc33359
:DRILL_LAST_INTERVAL: 266.5299
:DRILL_REPEATS_SINCE_FAIL: 6
:DRILL_TOTAL_REPEATS: 5
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.8
:DRILL_EASE: 2.9
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-22 Fri 22:07]
:END:

The [exact] tactic [solves a goal by providing an inhabitant].

***** Coq Tactic                                                                                          :nodrill:
SCHEDULED: <2019-06-13 Thu>
:PROPERTIES:
:DRILL_CARD_TYPE: hide1cloze
:ID:       5be5f1f6-d8ff-4e79-8032-11a14c6d193d
:DRILL_LAST_INTERVAL: 349.8314
:DRILL_REPEATS_SINCE_FAIL: 6
:DRILL_TOTAL_REPEATS: 8
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 4.125
:DRILL_EASE: 2.96
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-28 Thu 22:09]
:END:

The [split] tactic [introduces a conjunction].

***** Coq Tactic                                                                                          :nodrill:
SCHEDULED: <2019-01-24 Thu>
:PROPERTIES:
:DRILL_CARD_TYPE: hide1cloze
:ID:       3ee44b74-7bfb-46fd-bdf6-9095a0c7ddd0
:DRILL_LAST_INTERVAL: 215.7602
:DRILL_REPEATS_SINCE_FAIL: 6
:DRILL_TOTAL_REPEATS: 9
:DRILL_FAILURE_COUNT: 2
:DRILL_AVERAGE_QUALITY: 3.333
:DRILL_EASE: 2.62
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-22 Fri 22:11]
:END:

The [absurd] tactic [eliminates falsehood].

***** Coq Tactic                                                                                            :drill:
SCHEDULED: <2018-10-12 Fri>
:PROPERTIES:
:DRILL_CARD_TYPE: hide1cloze
:ID:       ef5486ca-801f-49cb-826b-db3e15806159
:DRILL_LAST_INTERVAL: 152.67
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 12
:DRILL_FAILURE_COUNT: 3
:DRILL_AVERAGE_QUALITY: 3.918
:DRILL_EASE: 3.1
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-05-12 Sat 17:45]
:END:

The [replace] tactic [substitutes all ocurrences of a term using a path].

****** Syntax
=replace {term} with {term2} by {tactic}=

where ={tactic}= solves ={term1 = term2}=.

***** Coq Tactic                                                                                          :nodrill:
SCHEDULED: <2019-03-16 Sat>
:PROPERTIES:
:DRILL_CARD_TYPE: hide1cloze
:ID:       ef5486ca-801f-49cb-826b-db3e15806159
:DRILL_LAST_INTERVAL: 305.2936
:DRILL_REPEATS_SINCE_FAIL: 6
:DRILL_TOTAL_REPEATS: 5
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 5.0
:DRILL_EASE: 3.0
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-05-15 Tue 23:14]
:END:

The [firstorder] tactic [automates first-order reasoning].

***** Coq Tactic                                                                                          :nodrill:
SCHEDULED: <2019-04-04 Thu>
:PROPERTIES:
:DRILL_CARD_TYPE: hide1cloze
:ID:       ef5486ca-801f-49cb-826b-db3e15806159
:DRILL_LAST_INTERVAL: 286.3133
:DRILL_REPEATS_SINCE_FAIL: 6
:DRILL_TOTAL_REPEATS: 5
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 5.0
:DRILL_EASE: 3.0
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-22 Fri 22:05]
:END:

The [set] tactic [defines a term that can be used later].

****** Syntax
set ({var} := {def}).
***** Coq Tactic                                                                                          :nodrill:
SCHEDULED: <2018-05-24 Thu>
:PROPERTIES:
:DRILL_CARD_TYPE: hide1cloze
:ID:       fbca0b6d-d8cd-4669-9f32-a2050dcf5824
:DRILL_LAST_INTERVAL: 107.9262
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 7
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 4.428
:DRILL_EASE: 3.0
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-02-05 Mon 22:49]
:END:

The [f_equal] tactic [proves {f x = f' x'} with {f = f'} and {x = x'}].

***** Coq Tactic                                                                                            :drill:
SCHEDULED: <2019-04-09 Tue>
:PROPERTIES:
:DRILL_CARD_TYPE: hide1cloze
:ID:       b84bd40d-3cef-4b97-b8f8-4d3ecfc5ff4f
:DRILL_LAST_INTERVAL: 290.942
:DRILL_REPEATS_SINCE_FAIL: 6
:DRILL_TOTAL_REPEATS: 5
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.8
:DRILL_EASE: 2.9
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-22 Fri 22:05]
:END:

The [ring] tactic [solves equations on a ring structure].
*** Algorithms
**** Data structures
***** Binary search tree                                                                                    :drill:
SCHEDULED: <2018-08-04 Sat>
:PROPERTIES:
:ID:       df4a8afe-3bf6-4ff8-997c-6598e693ba8b
:DRILL_LAST_INTERVAL: 83.8998
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.5
:DRILL_EASE: 2.7
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-05-12 Sat 17:41]
:END:
Definition of (unbalanced) Binary search tree (BST).

****** Definition

    8
   / \
  3   10
 /    / \
1    9   12

****** Complexity of searching in average and worst case
Searching is O(n) in the worst case (linear tree), but O(log n) in
average.

***** Red-black tree                                                                                      :nodrill:
SCHEDULED: <2018-05-19 Sat>
:PROPERTIES:
:ID:       83f6dfb9-a29a-400b-9ced-dff41732dae4
:DRILL_LAST_INTERVAL: 4.4178
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 5
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 2.8
:DRILL_EASE: 1.94
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-05-15 Tue 23:12]
:END:
Complexity of a red-black tree.

****** Complexity
Has O(log n) in worst case for searching, inserting and deleting.

****** Balancing properties                                                                                :extra:

 * It is a binary search tree.
 * Both children of a red node are black.
 * Every path to a leaf contains the same number of red and blacks.

These enforce that the path to the farthest leaf is no more than twice
the path to the nearest leaf.

**** Array sorting
***** Quicksort                                                                                             :drill:
SCHEDULED: <2018-07-09 Mon>
:PROPERTIES:
:ID:       ead02bcf-2b4c-412b-97da-485b069eb45a
:DRILL_LAST_INTERVAL: 12.2695
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 8
:DRILL_FAILURE_COUNT: 2
:DRILL_AVERAGE_QUALITY: 3.875
:DRILL_EASE: 2.76
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-27 Wed 13:11]
:END:
Complexity of quicksort.

****** Complexity
O(n^2) in the worst case, O(n log n) on average.

***** Mergesort                                                                                             :drill:
SCHEDULED: <2018-07-31 Tue>
:PROPERTIES:
:ID:       f8a18a27-422d-4fee-84a6-81b51a79fa4b
:DRILL_LAST_INTERVAL: 79.8424
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.5
:DRILL_EASE: 2.66
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-05-12 Sat 17:43]
:END:
Complexity of mergesort.

****** Complexity
O(n log n) in all cases.

***** Heapsort
Complexity of heapsort.

****** Complexity
O(n log n) in all cases.
*** Monads for functional programming - Philip Wadler                                          :paper:monads:haskell:
:PROPERTIES:
:INTERLEAVE_PDF: ~/pdf/wadler_monads_for_functional_programming.pdf
:END:
**** Notes for page 12
:PROPERTIES:
:interleave_page_note: 12
:END:

Monads can be defined in terms of unit, join and map. They can also be defined
in terms of unit and bind.
*** Qiaochu Yuan - [[https://qchu.wordpress.com/2018/02/07/gradient-descent/][Gradient descent]]                                                                        :analysis:
**** Problem with gradient descent                                                                           :drill:
SCHEDULED: <2018-07-03 Tue>
:PROPERTIES:
:ID:       ccf30e30-56c9-407c-b2cb-c1b7d364c07c
:DRILL_LAST_INTERVAL: 4.1408
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-29 Fri 22:27]
:END:
Problem with gradient descent and units.

***** Answer
It is not dimensionally consistent.  If the parameters you’re
optimizing over have units of length, and the loss function is
dimensionless, then the derivatives you’re subtracting have units of
inverse length.

** Computability and complexity                                                             :computability:complexity:
*** P?=NP - Scott Aaronson                                                                         :complexity:paper:
* Notes
** Ecuaciones diferenciales II
*** Temas de teoría

 1. Resultados del trabajo.
 2. Acotación con funciones guía.
 3. Lema de Gronwall.
 4. Unicidad de Peano.

*** Prerrequisitos
**** Prehaces y dominios
Conociendo el concepto de prehaz, parece que tiene sentido escribir
siempre o casi siempre las funciones con su dominio, $f|_D$.

**** TODO Teorema de la función inversa
**** Resolución de ecuaciones lineales no homogéneas
Dada una ecuación lineal $x' = xa(t) + b(t)$, la resolvemos con

\[
x = e^{A(t)} \left( k + \int_{t_0}^t b(s)e^{-A(s)}\,ds \right)
\]

donde $A$ es una primitiva de $a$. La constante $k$ ajustará
la condición inicial

***** Card                                                                                                  :drill:
SCHEDULED: <2018-07-13 Fri>
:PROPERTIES:
:ID:       5d987c6b-f319-4ee8-81ab-0371d66af4a6
:DRILL_LAST_INTERVAL: 30.7501
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.46
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-12 Tue 18:13]
:END:
Resolver la ecuación diferencial $x' = xa(t) + b(t)$.

****** Answer

\[
x = e^{A(t)} \left( k + \int_{t_0}^t b(s)e^{-A(s)}\,ds \right)
\]

donde $A$ es una primitiva de $a$.

**** Jacobiana
La aplicación lineal jacobiana en un punto, $J_F(p)$, cumple que

\[
\lim_{\|x-p\| \to 0} \frac{\|F(x)-F(p) -J_F(p)(x-p)\|}{\|x-p\|} = 0.
\]

En el caso de espacios finitos tenemos la matriz jacobiana

\[\begin{pmatrix}
\pdv{y_1}{x_1} & \dots & \pdv{y_1}{x_n} \\
\vdots & \ddots & \vdots \\
\pdv{y_m}{x_1} & \dots & \pdv{y_m}{x_n} \\
\end{pmatrix}
\]

En ocasiones notaremos simplemente a la jacobiana como $F'$.

***** Card: Jacobiana                                                                                       :drill:
SCHEDULED: <2018-09-12 Wed>
:PROPERTIES:
:ID:       4183447e-4b69-4117-a3bd-9181de1bd672
:DRILL_LAST_INTERVAL: 75.4403
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.25
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-29 Fri 17:48]
:END:
¿Qué propiedad define a la Jabobiana $\mathrm{Jac}(F)_p$ ó $F'(p)$?

****** Propiedad
Es la aplicación lineal cumpliendo

\[
\lim_{\|x-p\| \to 0} \frac{\|F(x)-F(p) - \mathrm{Jac}(F)_p(x-p)\|}{\|x-p\|} = 0.
\]

que existe cuando $F$ es diferenciable.

***** Card: construcción de la Jacobiana                                                                    :drill:
SCHEDULED: <2018-09-09 Sun>
:PROPERTIES:
:ID:       05dc6c9b-cb76-4ee7-85b5-a24f224aad1b
:DRILL_LAST_INTERVAL: 72.0671
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.5
:DRILL_EASE: 2.7
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-29 Fri 09:55]
:END:
¿Cómo construir la jacobiana en espacios finitos?

****** Construcción

\[\begin{pmatrix}
\displaystyle\pdv{f_1}{x_1} & \dots & 
\displaystyle\pdv{f_1}{x_n} \\
\vdots & \ddots & \vdots \\
\displaystyle\pdv{f_m}{x_1} & \dots & 
\displaystyle\pdv{f_m}{x_n} \\
\end{pmatrix}
\]

**** Hessiana
:PROPERTIES:
:ID:       0cebe934-5d31-494d-bfd6-891d9c4c81ec
:END:
La hessiana existe cuando lo hacen todas las segundas derivadas
parciales de una función $f \colon \mathbb{R}^n \to \mathbb{R}$.

\[\begin{pmatrix}
\pdv[2]{f}{x_1} & \dots & \pdv{f}{x_1}{x_n} \\
\vdots & \ddots & \vdots \\
\pdv{f}{x_n}{x_1} & \dots & \pdv[2]{f}{x_n} \\
\end{pmatrix}
\]

Por el [[https://es.wikipedia.org/wiki/Teorema_de_Clairaut][teorema de Schwarz-Clairaut]], es simétrica.

***** Card: definición                                                                                      :drill:
SCHEDULED: <2018-08-21 Tue>
:PROPERTIES:
:ID:       8d680bfb-66f0-4872-91bf-3011a3a19ec1
:DRILL_LAST_INTERVAL: 67.5636
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.25
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-14 Thu 11:49]
:END:
¿Qué es la Hessiana?¿cuándo existe?

****** Hessiana

\[\begin{pmatrix}
\pdv[2]{f}{x_1} & \dots & \pdv{f}{x_1}{x_n} \\
\vdots & \ddots & \vdots \\
\pdv{f}{x_n}{x_1} & \dots & \pdv[2]{f}{x_n} \\
\end{pmatrix}
\]

existe cuando lo hacen todas las segundas derivadas parciales.

***** Card: simetría                                                                                        :drill:
SCHEDULED: <2018-06-17 Sun>
:PROPERTIES:
:ID:       570c9701-1fb1-4c5c-b381-8bde318e961f
:DRILL_LAST_INTERVAL: 28.7981
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.46
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-05-19 Sat 11:01]
:END:
¿Cuándo es simétrica la Hessiana?¿por qué?

****** Respuesta
Cuando las derivadas parciales cruzadas segundas son además
continuas, por el [[https://es.wikipedia.org/wiki/Teorema_de_Clairaut][teorema de Schwarz-Clairaut]], es simétrica.
**** Convexidad
La función $e^x$ es convexa.

***** Card                                                                                                  :drill:
SCHEDULED: <2018-07-09 Mon>
:PROPERTIES:
:ID:       9bc614ac-a897-41af-be8f-c1035ab6c847
:DRILL_LAST_INTERVAL: 27.6005
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.667
:DRILL_EASE: 2.7
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-11 Mon 21:45]
:END:
La función $e^x$ es ¿cóncava o convexa?

****** Respuesta
Convexa.
**** Hessiana y convexidad
A continuous, twice differentiable function of several variables is
convex on a convex set if and only if its Hessian matrix of second
partial derivatives is positive semidefinite on the interior of the
convex set.

***** Card                                                                                                  :drill:
SCHEDULED: <2018-07-04 Wed>
:PROPERTIES:
:ID:       beace7dc-3d4d-4adf-932f-2a369b60d6a6
:DRILL_LAST_INTERVAL: 23.3996
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.46
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-11 Mon 21:43]
:END:
Caracterización de convexa de una función dos veces diferenciable de
varias variables en un conjunto convexo.

****** Caracterización
Es convexa si y sólo si la Hessiana es semidefinida positiva.
Nótese que eso no hace que tenga que ser forzosamente estrictamente
convexa y coerciva.

**** Wronskiana
La *wronskiana* no nula implica independencia lineal. Nótese sin
embargo que puede anularse incluso cuando son independientes.
(Contraejemplo de [[id:8e9ccec0-c9de-4d00-a08e-3de44d448ca5][Peano]])

\[
W(f_1,\dots,f_n)(x) = \begin{vmatrix}
f_1(x) & \dots & f_n(x) \\
\vdots & \ddots & \vdots \\
f_1^{n-1)}(x) & \dots & f_n^{n-1)}(x) \\
\end{vmatrix}
\]

Puede usarse la [[https://en.wikipedia.org/wiki/Abel%2527s_identity][identidad de Abel]] para calcular la wronskiana incluso
cuando no se conocen las soluciones.
**** Nociones de continuidad y convergencia
***** Continuidad uniforme
$f \colon I \to \mathbb{R}^d$ es *uniformemente continua* si 

\[
\forall \varepsilon \colon \exists \delta \colon |t-s|<\delta \implies \|f(t)-f(s)\| \leq \varepsilon.
\]

***** Convergencia puntual
$f_n \overset{c.p.}\longrightarrow f$ si $\forall t \in I\colon \{\| f_n(t) - f(t)\|\}_{n \in \mathbb{N}} \to 0$.

***** Convergencia uniforme
$f_n \overset{c.u.}\longrightarrow f$ si $\forall \varepsilon > 0\colon \exists n_0\colon \forall n > n_0\colon \forall t \in I\colon \|f_n(t)-f(t)\| < \varepsilon$.

**** Cards: tipos de ecuaciones                                                                           :noexport:
***** Ecuaciones homogéneas: forma                                                                          :drill:
SCHEDULED: <2018-08-26 Sun>
:PROPERTIES:
:ID:       87915c2b-ff33-4e9d-98c0-07e66a01ac68
:DRILL_LAST_INTERVAL: 97.434
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.25
:DRILL_EASE: 2.56
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-05-21 Mon 14:54]
:END:
Forma de una ecuación homogénea.

****** Forma
\[
x' = f \left( \frac{x}{t} \right)
\]

***** Ecuaciones homogéneas: resolución                                                                     :drill:
SCHEDULED: <2018-09-11 Tue>
:PROPERTIES:
:ID:       e558b5d7-7d81-4d91-9486-40352296fda2
:DRILL_LAST_INTERVAL: 90.6516
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 7
:DRILL_FAILURE_COUNT: 2
:DRILL_AVERAGE_QUALITY: 3.428
:DRILL_EASE: 2.7
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-12 Tue 18:22]
:END:
Cómo resolver una ecuación homogénea

\[
x' = f \left( \frac{x}{t} \right).
\]

****** Resolución
Aplicamos el cambio de variable $u = x/t$, que nos
lleva a 

\[u' = \frac{1}{t}(f(u) - u).\]

***** Ecuación lineal escalar                                                                               :drill:
SCHEDULED: <2018-07-14 Sat>
:PROPERTIES:
:ID:       ead2dfed-95a4-41ad-b65e-d09cf22fbd8d
:DRILL_LAST_INTERVAL: 32.2866
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 7
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 2.715
:DRILL_EASE: 1.66
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-12 Tue 14:48]
:END:
Cómo resolver, para $a,b \in {\cal C}(I,\mathbb{R})$;

\[
x' = a(t)x + b(t)
\]

****** Resolución
Una parte resuelve la homogénea, la otra es una solución
particular

\[
x = Ke^{(\int a)} + \left( \int_{t_0}^t b(z) e^{-(\int^{z} a)}\,dz \right) e^{(\int a)}
\]

Alternativamente, si $A$ es la primitiva de $a$, tenemos

\[x(t) = Ke^{A(t)} + \left( \int_{t_0}^t b(s) e^{-A(s)}\,ds \right) e^{A(t)}\]

***** Ecuación de Bernoulli                                                                                 :drill:
SCHEDULED: <2018-06-17 Sun>
:PROPERTIES:
:ID:       c7712582-1d68-4dd0-9ebf-9b9a2afcd463
:DRILL_LAST_INTERVAL: 4.633
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 8
:DRILL_FAILURE_COUNT: 2
:DRILL_AVERAGE_QUALITY: 3.125
:DRILL_EASE: 2.28
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-12 Tue 18:41]
:END:
Cómo resolver

\[
x' + ax + bx^n = 0.
\]

****** Resolución
Retiramos el caso trivial $x = 0$ y tomamos el cambio de
variable $u = x^{1-n}$, que la transforma en lineal

\[
u' + (1-n)au + (1-n)b = 0.
\]

***** Ecuación de Ricatti                                                                                   :drill:
SCHEDULED: <2018-08-28 Tue>
:PROPERTIES:
:ID:       1113da24-b90d-4ab0-94d8-e65ae4710470
:DRILL_LAST_INTERVAL: 76.692
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 8
:DRILL_FAILURE_COUNT: 3
:DRILL_AVERAGE_QUALITY: 2.75
:DRILL_EASE: 2.56
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-12 Tue 14:58]
:END:
Cómo resolver

\[
x' + ax + bx^2 = f(x).
\]

****** Resolución
Conociendo una solución de la ecuación tomamos el cambio

\[
u = \frac{1}{x - \varphi}
\]

suele ser una elección algo de la forma $\varphi = -1/x$.

***** Ecuación exacta                                                                                       :drill:
SCHEDULED: <2018-08-14 Tue>
:PROPERTIES:
:ID:       69ceda6b-32b1-4bc2-b8fd-71bc68c66072
:DRILL_LAST_INTERVAL: 61.6441
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 14
:DRILL_FAILURE_COUNT: 7
:DRILL_AVERAGE_QUALITY: 2.143
:DRILL_EASE: 2.28
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-13 Wed 10:01]
:END:
Dar la forma de una ecuación exacta, ¿cuál es la solución trivial?

****** Resolución
Una solución exacta es de la forma

\[
M + Nx' = 0
\]

donde son de la forma $M = \pdv{F}{t}$ y $N = \pdv{F}{x}$. 
Tiene solución trivial en $F = \mathrm{cte.}$
*** Tema 1. Existencia y unicidad. Ecuación de Volterra
**** 1.1. Definiciones
:PROPERTIES:
:ID:       ba5ec2ba-b54a-455b-9b6c-9fca85940234
:END:
Una *ecuación diferencial ordinaria* (EDO) $x' = f(t,x)$ viene
dada por un dominio (abierto conexo) $D \subseteq \mathbb{R} \times \mathbb{R}^d$ y una $f \colon D \to \mathbb{R}^d$.
Llamamos

 * $t$, a la variable independiente o temporal;
 * $x$, a la incógnita o variable dependiente;
 * $f$, al campo de vectores;
 * $D$, al dominio de la ecuación.

Dado $I$ intervalo abierto, una solución $\varphi \colon I \to \mathbb{R}^d$ de una EDO cumple

 * $(t,\varphi(t)) \in D$, se queda en el dominio;
 * $\varphi \in {\cal C}^1(I,\mathbb{R}^d)$, es derivable;
 * $\varphi'(t) = f(t,\varphi(t))$, es solución.

Un *problema de valores iniciales* (PVI) está dado como
una EDO con una condición inicial,

\[\left.\begin{aligned}
x' &= f(t,x) \\
x(t_0) &= x_0
\end{aligned}\right\}
\]

donde $(t_0,x_0) \in D$. Y una solución debe cumplir además

 * $\varphi(t_0) = x_0$ con $t_0 \in I$.

**** 1.2. Prolongación de soluciones
***** Solución prolongable y maximal
La solución de un PVI $\varphi \colon I \to \mathbb{R}^d$ es *prolongable* si existe
$\phi \colon J \to \mathbb{R}^d$ solución tal que $I \subset J$ y al restringir, $\phi_{|I} = \varphi$.
Una solución es *maximal* si no es prolongable.

***** Concatenación de soluciones
:PROPERTIES:
:ID:       078ac783-76bf-4445-ad46-3f91ea9d1ef6
:END:
Sean $\varphi_1 \colon I_1 \to \mathbb{R}^d$ y $\varphi_2 \colon I_2 \to \mathbb{R}^d$ soluciones de $x' = f(t,x)$.
Si $\varphi_1(\tau) = \varphi_2(\tau)$, entonces

\[\psi = \left\{\begin{aligned}
\varphi_1(t) &\ \text{ si } t \leq \tau \\
\varphi_2(t) &\ \text{ si } t > \tau \\
\end{aligned}\right.\]

es una solución.

****** Proof
Cumple

 * que se queda en el dominio trivialmente;
 * que es derivable en cada trozo por serlo las soluciones y
   derivable en el punto por coincidir sus dos derivadas laterales;
 * que coinciden porque ambas deben ser soluciones y en
   particular soluciones en el punto $\tau$, lo que hace a $\psi$ solución.

***** Garantías de maximalidad
Una solución $\varphi \colon (\alpha,\omega) \to \mathbb{R}^d$ es maximal cuando

 * $(\alpha,\omega) = (-\infty,\infty)$, *dominio infinito*;

 * $\omega < +\infty$ con $\lim_{t \to \omega} \|\varphi(t)\| = +\infty$, *explota en tiempo finito*;

 * $\omega < +\infty$ con $\lim_{t \to \omega}\varphi(t) = \xi \in \mathbb{R}^d$, pero $(\omega,\xi) \notin D$, *toca la frontera*.

 * $\omega < +\infty$ con $\not\exists \lim_{t \to \omega}\varphi(t)$, *ningún punto la prolonga*.

Análogamente con casos para $\alpha > -\infty$.

**** 1.3. Unicidad y soluciones maximales
***** Unicidad
Dado un problema de valores iniciales,

\[\left.\begin{aligned}
x' &= f(t,x) \\
x(t_0) &= x_0
\end{aligned}\right\}
\]

hay

 * *Unicidad local* si, para todo par de soluciones, existe un
   intervalo abierto conteniendo al instante inicial donde son
   iguales.

 * *Unicidad en un intervalo* $J$, cuando todo par de soluciones
   $\varphi_1 \colon I_1 \to \mathbb{R}^d$ y $\varphi_2 \colon I_2 \to \mathbb{R}^d$ son iguales en $J \cap I_1 \cap I_2$;

 * *unicidad en el futuro* es unicidad en $[t_0,+\infty)$,

 * *unicidad en el pasado* es unicidad en $(-\infty,t_0]$,

 * *unicidad global*, unicidad en todo $\mathbb{R}$.

****** Card: unicidad local                                                                                :drill:
SCHEDULED: <2018-07-10 Tue>
:PROPERTIES:
:ID:       0261396e-1324-4bde-b01b-842f881f869e
:DRILL_LAST_INTERVAL: 10.5298
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.25
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-29 Fri 17:52]
:END:
Dado un problema de valores iniciales,

\[\left.\begin{aligned}
x' &= f(t,x) \\
x(t_0) &= x_0
\end{aligned}\right\}
\]

define *unicidad local*.

******* Answer
Para todo par de soluciones existe un intervalo abierto conteniendo al
instante inicial donde son iguales.

******* Otra formulación
Para todo par de soluciones $\varphi_1 \colon I_1 \to \mathbb{R}^d$ y $\varphi_2 \colon I_2 \to \mathbb{R}^d$ existe
un intervalo *abierto* conteniendo al instante inicial, $t_0 \in J = \mathring{J}$,
donde $\varphi_1, \varphi_2$ son iguales.

****** Card: unicidad en un intervalo                                                                      :drill:
SCHEDULED: <2018-06-28 Thu>
:PROPERTIES:
:ID:       5024dcc3-fc4e-493b-a3d2-43a3c573855d
:DRILL_LAST_INTERVAL: 16.1373
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.5
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-12 Tue 14:38]
:END:
Dado un problema de valores iniciales,

\[\left.\begin{aligned}
x' &= f(t,x) \\
x(t_0) &= x_0
\end{aligned}\right\}
\]

define *unicidad en un intervalo* $J$.

******* Answer
Todo par de soluciones coincide en los puntos de $J$ en los que están
definidas ambas.

******* Otra formulación
Cuando todo par de soluciones $\varphi_1 \colon I_1 \to \mathbb{R}^d$ y $\varphi_2 \colon I_2 \to \mathbb{R}^d$ son iguales
en $J \cap I_1 \cap I_2$.

****** Card: unicidad en el futuro                                                                         :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       8bf16932-05b4-4fb2-810c-cc8f17c70743
:DRILL_LAST_INTERVAL: 11.4402
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-11 Mon 21:45]
:END:
Dado un problema de valores iniciales,

\[\left.\begin{aligned}
x' &= f(t,x) \\
x(t_0) &= x_0
\end{aligned}\right\}
\]

define *unicidad en el futuro*.

******* Answer
Unicidad en el intervalo $[t_0,+\infty)$.

****** Card: unicidad global                                                                               :drill:
SCHEDULED: <2018-07-10 Tue>
:PROPERTIES:
:ID:       ecc0e77c-4708-4b2c-aac6-f44115513990
:DRILL_LAST_INTERVAL: 28.4551
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.333
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-12 Tue 18:15]
:END:
Dado un problema de valores iniciales,

\[\left.\begin{aligned}
x' &= f(t,x) \\
x(t_0) &= x_0
\end{aligned}\right\}
\]

define *unicidad global*.

******* Answer
Unicidad en el intervalo $\mathbb{R}^d$.

******* Otra formulación
Todo par de soluciones coincide en los puntos en los que están
definidas ambas.

***** Lema 1. Unicidad global desde unicidad local
:PROPERTIES:
:ID:       0b968d38-72b0-41e4-bdbd-a19fd33ecd59
:END:
Si para todo $(t_{0},x_0) \in D$, el problema de valores iniciales
cumple unicidad local, entonces para todo $(t_{0},x_0) \in D$ se
cumple la unicidad global.

****** Proof
Sean $\varphi_1|_{I_1}$ y $\varphi_2|_{I_2}$ soluciones. Como $I_1 \cap I_2$ es conexo, basta
probar $H = \left\{ t \in I_1 \cap I_2 \mid \varphi_1(t) = \varphi_2(t) \right\}$ abierto y cerrado.
Es cerrado porque es núcleo de una continua. Es abierto respecto
a $I_1 \cap I_2$ porque dado $t_0 \in H \cap I_1 \cap I_2$, tomamos el problema con
el valor $x_0 = \varphi_1(t_0) = \varphi_2(t_0)$ y existirá un intervalo $t_0 \in J \subset H$
por unicidad local.

***** Lema 2. Unicidad global da única solución maximal
Si un PVI verifica unicidad global, tiene una única solución maximal.
# Si no existen soluciones, la solución vacía es maximal, entiendo.

****** Proof
Sea $\Sigma(P)$ el conjunto de soluciones, tomamos el conjunto
siguiente que es intervalo por unión de intervalos con
un punto común $(t_0,x_0),

\[
J = \bigcup_{\varphi|_I \in \Sigma(P)} I
\]

y definimos $\psi|_{J}(t)$ como el valor de una solución cualquiera en
$t$, que por unicidad global deberá ser siempre igual. Esta función es
solución, se queda en el dominio, es derivable por ser localmente
(usando que es abierto) una solución y es solución trivialmente; es
maximal por definición y cualquier otra maximal debería estar en el
mismo intervalo y por unicidad global, ser exactamente la misma.

****** Card                                                                                                :drill:
SCHEDULED: <2018-07-15 Sun>
:PROPERTIES:
:ID:       cc21bcb9-acde-4eec-aa64-945138de1035
:DRILL_LAST_INTERVAL: 33.3673
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.667
:DRILL_EASE: 2.7
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-12 Tue 18:10]
:END:
Si existen soluciones, ¿qué implica la unicidad global de solución
respecto de las maximales?

******* Answer
Unicidad global implica que hay una única solución maximal.

***** Unicidad local en ecuaciones de variables separadas
Dadas $a|_{J_1}$ y $g|_{J_{2}}$ continuas con $t_0 \in J_1$ y $x_0 \in J_2$, intervalos.

\[\left.\begin{aligned}
x' &= a(t)g(x) \\
x(t_0) &= x_0
\end{aligned}\right\} \mathit{(P)}
\]

Tenemos que

 1) el problema tiene soluciones;

 2) si $g(x_0) \neq 0$, hay unicidad local;

 3) si $g(x_0) = 0$, $a(t_0) \neq 0$, existe $G|_{J_2}$ derivable con $G(x_0) = 0$ 
    y además $G'(x) = \frac{1}{g(x)}$ para todo $x$ en un semientorno de $x_0$; entonces
    no hay unicidad local.

****** Proof
Consideraremos los dos casos, $g(x_0) = 0$ y $g(x_0) \neq 0$.

 * Cuando $g(x_0) \neq 0$, tenemos un intervalo en el que el signo se
   conserva. Sea $A$ la antiderivada de $a$ con $A(t_0)=0$ y $G$ la
   antiderivada de $1/g(x)$ con $G(x_0)=0$. Cualquier solución $x$
   debe cumplir

   \[
   G(x(t)) =
   \int_{x(t_0)}^{x(t)} \frac{du}{g(u)} =
   \int_{t_0}^{t} \frac{x'(s)}{g(x(s))} \; ds =
   \int_{t_0}^{t} a(s) \; ds.
   \]

   Aplicamos Teorema de la Función Inversa para obtener $G^{-1}$ 
   derivable y definir $\varphi = G^{-1} \circ A$. Puede definirse localmente 
   dentro del dominio por continuidad, es derivable, es solución

   \[
   \varphi'(t) = 
   a(t) \cdot \left( G^{-1} \right)' \left( A(t) \right) =
   a(t) \cdot g \left( G^{-1} \left( A(t) \right)  \right) =
   a(t) \cdot g(\varphi(t)).
   \]

   y además $\varphi(t_0) = G^{-1}(A(t_0)) = x_0$.

 * Cuando $g(x_0) = 0$, tenemos la solución trivial $\varphi(t) = x_0$. Además,
   asumiendo que tenemos $G$ en con derivada dada en un semientorno
   superior, usamos que $A$ es continua para definir en algún intervalo
   la siguiente solución.
   
   \[\varphi(t) = \left\{\begin{aligned}
   x_0 &\ \text{ si } t \leq t_0 \\
   G^{-1}(A(t)) &\ \text{ si } t > t_0 \\
   \end{aligned}\right.\]

   La solución es trivialmente continua en $t_0$. Es derivable porque
   ambas derivadas laterales son $0$. Esta solución es distinta de
   $x_0$ usando $a(t_0) \neq 0$ (?).

****** Card                                                                                                :drill:
SCHEDULED: <2018-06-17 Sun>
:PROPERTIES:
:ID:       61153ecb-7cb0-4c5f-9ab3-1c9866b643b5
:DRILL_LAST_INTERVAL: 4.8253
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 5
:DRILL_FAILURE_COUNT: 2
:DRILL_AVERAGE_QUALITY: 3.4
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-12 Tue 18:40]
:END:
¿Qué sabemos sobre existencia y unicidad en EDOs de variables separadas?

******* Answer
Para $x' = a(t)g(x)$.

 1) Existen soluciones.
 2) Si $g(x_0) \neq 0$; entonces hay unicidad local.
 3) Si $g(x_0) = 0$, $a(t_0) \neq 0$, y existe $G$ tal que $G(x_0) = 0$ y $G'(x) = 1/g(x)$;
    entonces no hay unicidad local.

**** 1.4. Teorema de Unicidad de Peano
:PROPERTIES:
:ID:       cc790c02-b622-4fc1-8bb1-ac3c05e73009
:END:
Sea un PVI dado por un campo continuo sobre un abierto $D \subset \mathbb{R} \times \mathbb{R}$,
al que llamamos $f \colon D \to \mathbb{R}$.

Para un PVI con $d=1$, es decir $f \colon D \subseteq \mathbb{R}\times \mathbb{R} \to \mathbb{R}$,

 1) si $\forall t \geq t_0$, $f(t,-)$ es decreciente, hay unicidad en el futuro;
 2) si $\forall t \leq t_0$, $f(t,-)$ es creciente, hay unicidad en el pasado.

***** Proof
En el caso de $f(t,x)$ decreciente, con dos soluciones $\varphi_1\colon I_1 \to \mathbb{R}$
y $\varphi_2 \colon I_2 \to \mathbb{R}$, definimos $h(t) = (\varphi_1(t)-\varphi_2(t))^2$ con derivada

\[\begin{aligned}
h'(t) &= 
2(\varphi_1(t)-\varphi_2(t))(\varphi_1'(t)-\varphi_2'(t)) \\&=
2(\varphi_1(t)-\varphi_2(t))(f(t,\varphi_1(t))-f(t,\varphi_2(t))) \leq 0,
\end{aligned}\]

que la hace decreciente. Pero $h(t) \geq 0$ en general y $h(t_0) = 0$, 
por lo que debe ser $0$ para $t \geq 0$. El segundo caso es análogo,
siendo $h'(t)$ positiva y por tanto $h(t)$ creciente con $h(t_0) = 0$.

***** Card: enunciado                                                                                       :drill:
SCHEDULED: <2018-09-24 Mon>
:PROPERTIES:
:ID:       d6ac89c9-f053-4b0d-a8e0-c0233c137e87
:DRILL_LAST_INTERVAL: 102.8547
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 7
:DRILL_FAILURE_COUNT: 2
:DRILL_AVERAGE_QUALITY: 3.571
:DRILL_EASE: 2.7
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-13 Wed 09:56]
:END:
Enuncia el teorema de Unicidad de Peano.

****** Enunciado
Para un PVI con $d=1$, es decir $f \colon \mathbb{R}\times \mathbb{R} \to \mathbb{R}$,

 1) si $\forall t \geq t_0$, $f(t,-)$ es decreciente, hay unicidad en el futuro;
 2) si $\forall t \leq t_0$, $f(t,-)$ es creciente, hay unicidad en el pasado.

***** Card: demostración                                                                                    :drill:
SCHEDULED: <2018-08-18 Sat>
:PROPERTIES:
:ID:       efae3e4f-a565-4023-bb0c-e1c762db3e1f
:DRILL_LAST_INTERVAL: 89.5744
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.46
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-05-20 Sun 23:25]
:END:
¿Cuál es la idea para demostrar el teorema de unicidad de Peano?
Supongamos $f(t,x)$ decreciente y dos soluciones $\varphi_1\colon I_1 \to \mathbb{R}$
y $\varphi_2 \colon I_2 \to \mathbb{R}$. Queremos ver unicidad en el futuro.

****** Idea
Definimos $h(t) = (\varphi_1(t)-\varphi_2(t))^2$ y calculamos su derivada para
ver que es decreciente.

**** 1.5. Problema dual en el tiempo
El problema dual en el tiempo hace una simetría del problema respecto
al eje temporal. Si $x(t)$ es solución de uno, $y(t) = x(-t)$ es la solución
del otro, definida en los intervalos correspondientes.

\[\left.\begin{aligned}
x' &= f(t,x) \\
x(t_0) &= x_0
\end{aligned}\right\}\qquad
\left.\begin{aligned}
y' &= -f(-t,y) \\
y(-t_0) &= x_0
\end{aligned}\right\}
\]

**** 1.6. Ecuación integral de Volterra
***** Operador integral de Volterra
Dada una Ecuación de Volterra, fijamos el operador de Volterra,
que tiene las soluciones como puntos fijos

\[
V(y)(t) = x_0 + \int_{t_0}^t f(s,y(s))\;ds.
\]

Lo consideramos $V \colon E \to E$ donde 

\[
E = \overline{B}(x_0,b) \subset {\cal C}([t_0-a,t_0+a];\mathbb{R}^d)
\]

es un espacio métrico completo con la norma infinito.

****** Card                                                                                                :drill:
SCHEDULED: <2018-07-08 Sun>
:PROPERTIES:
:ID:       d632fc17-20f9-4797-929d-05f51c4cd2ea
:DRILL_LAST_INTERVAL: 26.2679
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 8
:DRILL_FAILURE_COUNT: 2
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.08
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-12 Tue 14:57]
:END:
Define el operador integral de Volterra y su dominio

******* Definición

\[
V(y)(t) = x_0 + \int_{t_0}^t f(s,y(s))\;ds.
\]

Está en el dominio ${\cal C}([t_0-a,t_0+a];\mathbb{R}^d)$.
Puede probarse que es $V \colon E \to E$ donde $E = \overline{B_0}(x_0,b)$.

***** Solución de la ecuación de Volterra
:PROPERTIES:
:ID:       b43c8fe5-6fdb-487e-a609-5620610d23a0
:END:
Para $I$ intervalo, $\varphi \colon I \to \mathbb{R}$ es solución de la ecuación si

 1. $t_0 \in I$;
 2. $(t,\varphi(t)) \in D$, en el dominio;
 3. $\varphi$, es continua en $I$;
 4. $\varphi(t) = x_0 + \int^t_{t_0} f(s,\varphi(s))\; ds$, cumple la ecuación.

***** Lema de soluciones de Volterra
Cada PVI

\[\left.\begin{aligned}
x' &= f(t,x) \\
x(t_0) &= x_0
\end{aligned}\right\}
\]

tiene asociada la ecuación integral de Volterra

\[
x(t) = x_0 + \int_{t_0}^t f(s,x(s))\;ds.
\]

Sea $\varphi \colon I \to \mathbb{R}^d$ para $I$ intervalo abierto. Equivalen

 1. $\varphi$ es [[id:ba5ec2ba-b54a-455b-9b6c-9fca85940234][solución de un PVI]];
 2. $\varphi$ es [[id:b43c8fe5-6fdb-487e-a609-5620610d23a0][solución de la ecuación de Volterra]] asociada.
 
****** Demostración
1 a 2. Tenemos trivialmente las dos primeras condiciones. La
continudad surge de la derivabilidad y por regla de Barrow,
$\varphi(t) = \varphi(t_0) + \int_{t_0}^t f(s,\varphi(s))\;ds$.

2 a 1. Tenemos trivialmente las dos primeras condiciones y el
punto de evaluación. Por Teorema Fundamental del Cálculo, $\varphi$
es derivable con precisamente la derivada que la hace solución.

**** 1.7. Algunos resultados útiles de análisis
***** 1. Lema del primer instante
:PROPERTIES:
:ID:       a439476b-8c77-4994-a736-9062ee91e7d0
:END:
Para $f \in {\cal C}(I,\mathbb{R})$ con $f(t_0) > 0$, se da una de las alternativas.

 * $\forall t \geq t_0\colon f(t) > 0$.

 * $\exists \tau > t_0\colon \forall t \in [t_0,\tau)\colon  f(t) > 0,\ f(\tau) = 0$.

****** Proof
Si no se cumple la primera condición, el conjunto
$H = \left\{ t \in I \mid t > t_0, f(t) = 0 \right\}$ es no vacío por Bolzano,
cerrado y acotado inferiormente. Su mínimo es el $\tau$ buscado.

****** Card                                                                                                :drill:
SCHEDULED: <2018-07-22 Sun>
:PROPERTIES:
:ID:       b544c2e9-8d67-4c68-8587-26873148e533
:DRILL_LAST_INTERVAL: 62.8257
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.25
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-05-20 Sun 23:26]
:END:
Para $f \in {\cal C}(I,\mathbb{R})$ con $f(t_0) > 0$, enunciar el lema del primer
instante.

******* Enunciado
Se da una de las alternativas.

 * $\forall t \geq t_0\colon f(t) > 0$.

 * $\exists \tau > t_0\colon \forall t \in [t_0,\tau)\colon  f(t) > 0,\ f(\tau) = 0$.

***** 2. Teorema del valor medio real
:PROPERTIES:
:ID:       3efc40d6-3ca0-4a0d-ba1a-41e752bab364
:END:
Dada $f \colon \mathbb{R} \to \mathbb{R}$ con $f \in {\cal C}^1$, para $a,b \in \mathbb{R}$ se tiene que
existe $c \in [a,b]$ tal que 

\[
f(a) - f(b) = f'(c)(a-b).
\]

***** 2. Teorema del valor medio en funciones reales de varias variables
Dada $f \in {\cal C}^1(\mathbb{R}^n,\mathbb{R})$, para $a,b \in \mathbb{R}^n$, se tiene que existe $c \in [a,b]$ tal que

\[
f(b)-f(a) = \left\langle \grad f(c), b-a \right\rangle.
\]

****** Proof
Parametrizamos para obtener una función escalar ${\cal C}^1$

\[
h(t) = f((1-t)a + tb)
\]

para la que se por [[id:3efc40d6-3ca0-4a0d-ba1a-41e752bab364][Teorema del valor medio real]] existe $h(1)-h(0) = h'(d)$.
Derivando obtenemos, llamando $c = (1-d)a + db$,

\[
f(b) - f(a) = \left\langle \grad f(d) , b - a \right\rangle.
\]

****** Card                                                                                                :drill:
SCHEDULED: <2018-08-22 Wed>
:PROPERTIES:
:ID:       deccb6c2-471e-4d1a-baff-b96dc400f410
:DRILL_LAST_INTERVAL: 70.769
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 7
:DRILL_FAILURE_COUNT: 2
:DRILL_AVERAGE_QUALITY: 3.143
:DRILL_EASE: 2.42
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-12 Tue 14:58]
:END:
Para $f \in {\cal C}^1(\mathbb{R}^n,\mathbb{R})$ y $a,b \in \mathbb{R}^n$, enunciar el teorema del valor medio
para funciones *reales* de varias variables.

******* Enunciado
Existe $c \in [a,b]$ tal que

\[
f(b)-f(a) = \left\langle \grad f(c), b-a \right\rangle.
\]

***** 2. Teorema del valor medio multivariable (versión apuntes)
Dadas $[x,y]\subseteq \Omega$,

\[
f(x) - f(y) = \left( \int_0^1 f'(sy + (1-s)x) \,ds \right) \cdot (y-x)
\]

****** Proof
Para $g(s) = f(sy + (1-s)x)$ se tiene $g'(s) = f'(sy+(1-s)x) \cdot (y-x)$.
Integrando y aplicando regla de Barrow se tiene la igualdad.

****** Card                                                                                                :drill:
SCHEDULED: <2018-06-25 Mon>
:PROPERTIES:
:ID:       1c375733-5f2b-460c-9595-83e32e399f0b
:DRILL_LAST_INTERVAL: 12.5516
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-12 Tue 14:37]
:END:
Enuncia la versión del teorema del valor medio multivariable
que se sigue de la regla de Barrow.

******* Answer

\[
f(x) - f(y) = \left( \int_0^1 f'(sy + (1-s)x) \,ds \right) \cdot (y-x)
\]

O, de otra forma

\[
f(x) - f(y) = \left( \int_{[a,b]} f'(sy + (1-s)x) \,ds \right) \cdot (y-x)
\]

***** 3. Desigualdades integrales
Se tiene para cualquier función continua,

 * $\norm{\int_a^bf(s)\,ds} \leq \int_a^b\norm{f(s)}\,ds$

 * si $\norm{f(s)} \leq M$. entonces $\norm{\int_{t_0}^tf(s)\,ds} \leq M \abs{t-t_0}$

***** 4. Lema de Barbalat (versión débil)
Si $\lim_{t \to +\infty} f(t) = L \in \mathbb{R}$, entonces $\exists t_n \to +\infty$ con $f'(t_n) \to 0$.

****** Proof
Por [[id:3efc40d6-3ca0-4a0d-ba1a-41e752bab364][teorema del valor medio]], existen $t_n \in (n,n+1)$ tales
que $f'(t_n) = f(n+1) - f(n) \to 0$.

****** Card                                                                                                :drill:
SCHEDULED: <2018-07-10 Tue>
:PROPERTIES:
:ID:       d2b43cd1-b482-4954-828c-4e94ca50e0c1
:DRILL_LAST_INTERVAL: 27.6024
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.667
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-12 Tue 18:14]
:END:
Enuncia el Lema de Barbalat (versión débil).

******* Answer
Si $\lim_{t \to +\infty} f(t) = L \in \mathbb{R}$, entonces $\exists t_n \to +\infty$ con $f'(t_n) \to 0$.

****** Card                                                                                                :drill:
SCHEDULED: <2018-06-27 Wed>
:PROPERTIES:
:ID:       4a364dd0-415d-4b04-b73d-4c89d55664bf
:DRILL_LAST_INTERVAL: 15.054
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.5
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-12 Tue 14:37]
:END:
Demuestra el Lema de Barbalat. Si $\lim_{t \to +\infty} f(t) = L \in \mathbb{R}$,
entonces $\exists t_n \to +\infty$ con $f'(t_n) \to 0$.

******* Answer
Por [[id:3efc40d6-3ca0-4a0d-ba1a-41e752bab364][teorema del valor medio]], existen $t_n \in (n,n+1)$ tales
que $f'(t_n) = f(n+1) - f(n) \to 0$.

***** 4. Lema de Barbalat (versión fuerte)
Si $\lim_{t \to +\infty}f(t) = L \in \mathbb{R}$, y además $f'$ es uniformemente continua en
$(\alpha,\infty)$, entonces $\lim_{t \to +\infty}f'(t) = 0$.

****** TODO Proof                                                                                          :extra:
*** Tema 2. Lipschitzianidad. Picard-Lindelöf
**** 2.1. Lipschitzianidad
***** Lipschiztianidad global
$f \colon \Omega \subset \mathbb{R}^n \to \mathbb{R}^m$ es *globalmente lipschitziana (GL)* si

\[
\exists L \geq 0 \colon
\forall x,y \in \Omega\colon\quad
\norm{f(x)-f(y)} \leq L\|x-y\|.
\]

****** Card                                                                                                :drill:
SCHEDULED: <2018-07-12 Thu>
:PROPERTIES:
:ID:       e0db3e38-dc0f-42ff-9146-addb33fda380
:DRILL_LAST_INTERVAL: 30.1248
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.667
:DRILL_EASE: 2.7
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-12 Tue 18:10]
:END:
Definición globalmente lipschitziana.

******* Definición
Hay una constante de Lipschitz que acota la distancia
entre dos imágenes por la distancia de los argumentos.

\[
\forall x,y \in \Omega\colon\quad
\norm{f(x)-f(y)} \leq L\|x-y\|.
\]

***** Lipschiztianidad global, caracterización
:PROPERTIES:
:ID:       d89ce0be-e6df-4af0-a129-12b79008efc2
:END:
$f \colon \Omega \subset \mathbb{R}^n \to \mathbb{R}^m$ es globalmente lipschitziana si y sólo si no
existen sucesiones $x_n \neq y_{n}$ tales que

\[
\frac{\|f(x_n) - f(y_n)\|}{\|x_n-y_n\|} \to +\infty.
\]

****** Proof
Si existen las sucesiones, claramente no hay acotación. Si no hay
acotación posible, para cada $n$ existirán $x_n \neq y_n$ tales que el
cociente sea mayor que $n$; teniéndose la divergencia.

****** Card                                                                                                :drill:
SCHEDULED: <2018-06-24 Sun>
:PROPERTIES:
:ID:       b77b3357-33e1-40bb-af13-6296280ddfa7
:DRILL_LAST_INTERVAL: 12.8477
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.5
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-11 Mon 21:59]
:END:
Caracterización de lipschitzianidad global por sucesiones.

******* Caracterización
No existen sucesiones tales que

\[
\frac{\|f(x_n) - f(y_n)\|}{\|x_n-y_n\|} \to +\infty.
\]

***** Lipschiztianidad global para derivada continua acotada
:PROPERTIES:
:ID:       884a32d3-15b9-4193-8104-c7ce01c555f9
:END:
Sea $I \subseteq \mathbb{R}$ intervalo. Para $f \in {\cal C}^1(I,\mathbb{R}^m)$ equivalen

 1) $f$ globalmente lipschitziana.
 2) $\exists L \geq 0: \forall t \in I: |f'(t)| \leq L$.

****** Proof
Cuando $f$ es globalmente lipschitziana basta tomar $y \to x$. Cuando
tenemos una cota, usamos regla de Barrow

\[ |f(x)-f(y)| = 
\left|\int_x^y f'(t) \;dt\right| = 
L|x-y|.
\]

***** Lipschiztianidad global para derivada continua acotada a trozos
Sea $I \subseteq \mathbb{R}$ intervalo. Para $f \in {\cal C}^1_T(I)$ equivalen

 1) $f$ globalmente lipschitziana.
 2) $\exists L \geq 0:\forall t \in I^{\ast}: |f'(t)| \leq L$.

****** Funciones de clase uno a trozos
Tenemos $f \in {\cal C}^1_T(I)$ cuando existe un recubrimiento finito de $I$ por
intervalos cerrados $\left\{ I_i \right\}$ tales que $f|_{I_i} \in {\cal C}^1(I_i)$.

La función será derivable excepto en un conjunto finito de puntos
llamados *nodos*, llamamos $I^{\ast}$ a los puntos que no son nodos.

****** Proof
Repetimos la demostración anterior con la única diferencia
de que ahora la regla de Barrow deberá aplicarse teniendo
en cuenta las propiedades de la integral. Podemos tomar un
recubrimiento finito de intervalos disjuntos de $[x,y]$.

\[ |f(x)-f(y)| =
\left|\int_x^y f'(t) \;dt\right| = 
\sum_{i=0}^n\left|\int_{I_i} f'(t) \;dt\right| = L\left| \sum_{i=0}^n \mu(I_i) \right| = L|x-y|.
\]

***** Lipschiztianidad global para jacobiana continua acotada
:PROPERTIES:
:ID:       0bd3f16f-5d05-4135-98b5-70d27b46afa9
:END:
En $\Omega$ abierto convexo con $f \in {\cal C}^1(\Omega;\mathbb{R}^m)$ equivalen

 1) $f$ es globalmente lipschiztiana.
 2) $\exists L \geq 0: \forall x \in \Omega: \vertiii{f'(x)} \leq L$.

/Esto generaliza al [[id:884a32d3-15b9-4193-8104-c7ce01c555f9][caso escalar]]./

****** Proof
Usamos crucialmente que $[x,y] \subset \Omega$. Tomando una norma matricial
compatible tenemos

\[
\norm{f'(sx + (1-s)y) \cdot (x - y)} \leq \vertiii{f'(sx + (1-s)y)}\norm{x-y}.
\]

Podemos acotarla usando su derivada como

\[\begin{aligned}
\norm{f(x) - f(y)} &=
\norm{\Big[ f(sx+(1-s)y) \Big]^1_0} &=
\int_0^1 \norm{f'(sx + (1-s)y) \cdot (x - y)} &\leq
L\norm{x-y}\abs{1-0}.
\end{aligned}\]

# En el otro sentido (?) Se tiene que en un entorno se debería tener ese límite.

****** Card: caracterización de lipschitziana por el jacobiano                                             :drill:
SCHEDULED: <2018-08-04 Sat>
:PROPERTIES:
:ID:       4c53da16-5464-489d-8536-ddf06a659fd8
:DRILL_LAST_INTERVAL: 52.9818
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.75
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-12 Tue 18:12]
:END:
Caracteriza lipschitzianidad global en un abierto convexo $\Omega$
usando el jacobiano.

******* Caracterización
Si $f \in {\cal C}^1(\Omega;\mathbb{R}^m)$ equivalen

 1) $f$ es globalmente lipschiztiana.
 2) $\exists L \geq 0: \forall x \in \Omega: \vertiii{f'(x)} \leq L$.

***** Lipschitzianidad global respecto de una variable
:PROPERTIES:
:ID:       c50d9301-e9db-40a1-b25f-b726327f37bb
:END:
$f \colon \Omega \to \mathbb{R}^m$ es *globalmente lipschitziana respecto* de $x \in \mathbb{R}^d$
cuando existe $L \geq 0$ tal que

\[
\| f(x_1,y) - f(x_2,y) \| \leq L \| x_1 - x_2 \|.
\]

Dicho de otra forma, las secciones $f(-,y)$ son lipschitzianas con una
constante de lipschitz común.

****** Card: definición                                                                                    :drill:
SCHEDULED: <2018-07-05 Thu>
:PROPERTIES:
:ID:       ab5dfd96-99d3-499a-ac32-bbfb645bbd4e
:DRILL_LAST_INTERVAL: 22.5254
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 7
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.714
:DRILL_EASE: 2.42
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-12 Tue 14:56]
:END:
Una $f(x,y)$ definida en $\Omega \subseteq \mathbb{R}^d \times \mathbb{R}^n$ es [[id:c50d9301-e9db-40a1-b25f-b726327f37bb][globalmente lipschitziana respecto]]
de $x \in \mathbb{R}^d$ cuando

******* Definición
Existe $L \geq 0$ tal que

\[
\| f(x,y) - f(x',y) \| \leq L \| x - x' \|.
\]

******* De otra forma
Las secciones $f(-,y)$ son lipschitzianas con una constante de
lipschitz común.

***** Lipschiztianidad local
:PROPERTIES:
:ID:       c9318e14-3e65-49d1-935a-f26e56c912cf
:END:
$f \colon \Omega \to \mathbb{R}^m$ es *localmente lipschitziana* (LL) si 
para cada punto hay un entorno $p \in U \subset \Omega$ con $f|_U$
globalmente lipschitziana.

/Nota: ¡la constante de Lipschitz puede cambiar entre entornos!/

****** Card: localmente pero no globalmente lipschitz                                                      :drill:
SCHEDULED: <2018-09-08 Sat>
:PROPERTIES:
:ID:       9c7e258c-1ed7-45eb-bdc1-09c21a20bb94
:DRILL_LAST_INTERVAL: 87.0226
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 5.0
:DRILL_EASE: 2.9
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-13 Wed 10:09]
:END:
Dar un ejemplo de función localmente lipschitzana pero no globalmente
lipschitziana.

******* Ejemplo
$x^2$ no tiene derivada acotada y podemos ir tomando sucesiones de
diferencias por encima de cualquier cota. Sin embargo, es ${\cal C}^1$
en cada entorno y ahí podemos acotar su derivada.

****** Card: lipschitzianidad local                                                                        :drill:
SCHEDULED: <2018-07-24 Tue>
:PROPERTIES:
:ID:       a57b3f38-2607-4a32-9ffd-d9a04d663100
:DRILL_LAST_INTERVAL: 42.9603
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.667
:DRILL_EASE: 2.7
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-11 Mon 21:47]
:END:
Definición de $f \colon \Omega \to \mathbb{R}^m$ *localmente lipschitziana*.

******* Definición
Para cada punto hay un entorno $p \in U \subset \Omega$ con $f|_U$
globalmente lipschitziana.

******* Nota
La constante de Lipschitz puede cambiar entre entornos.

****** Card: no localmente lipschitz                                                                       :drill:
SCHEDULED: <2018-08-30 Thu>
:PROPERTIES:
:ID:       3eee05c0-75d5-4fa4-80be-dd99318ab95c
:DRILL_LAST_INTERVAL: 79.4168
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.5
:DRILL_EASE: 2.7
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-12 Tue 18:23]
:END:
Dar un ejemplo de función no localmente lipschitz.

******* Ejemplo
$\sqrt{x}$ tiene una sucesión contraviniendo la [[id:8e7d4d06-7b9f-4bbd-8e34-1e385dfdc439][caracterización]] en $0$.

***** Lipschiztianidad local, anticaracterización
:PROPERTIES:
:ID:       8e7d4d06-7b9f-4bbd-8e34-1e385dfdc439
:END:
$f \colon \Omega \to \mathbb{R}^m$ es localmente lipschitziana si y sólo si no
existen $x_n,y_n \in \Omega$ con $x_n\to p$ y $y_n \to p$ tales que

\[
\frac{\norm{f(x_n)-f(y_n)}}{\norm{x_n-y_n}} \to +\infty.
\]

****** Proof
Si es localmente lipschitziana, habrá un entorno de $p$ con el
cociente acotado; pero si $x_n,y_n$ convergen a $p$ a partir de
algún $n$ estarán dentro de ese entorno.

Si no lo es, tomamos ${\cal U}_n = B(1/n,p) \cap \Omega$ y deben exisitr

\[
\frac{\norm{f(x_n) - f(y_n)}}{\norm{x_n-y_n}} \geq n,
\]

formando dos sucesiones que tienden a $p$ y con cociente
divergente.

****** Card: caracterización                                                                               :drill:
SCHEDULED: <2018-08-03 Fri>
:PROPERTIES:
:ID:       5810c568-e044-447b-b6d4-0e1879deed84
:DRILL_LAST_INTERVAL: 52.4815
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.75
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-12 Tue 18:12]
:END:
Caracterización por sucesiones de $f \colon \Omega \to \mathbb{R}^m$ localmente
lipschitziana.

******* Caracterización
Es LL si y sólo si no existen $x_n,y_n \in \Omega$ con $x_n\to p$ y $y_n \to p$
tales que

\[
\frac{\norm{f(x_n)-f(y_n)}}{\norm{x_n-y_n}} \to +\infty.
\]

****** TODO Ejemplo: potencias localmente lipschitz                                                        :leech:
SCHEDULED: <2018-05-02 Wed>
:PROPERTIES:
:ID:       e84886df-626a-4e09-846b-572dabb83c40
:DRILL_LAST_INTERVAL: 3.95
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-04-28 Sat 16:00]
:END:
¿Para $p>0$, qué debe cumplir $|x|^p$ para ser localmente lipschitz?
# Repasar

******* Debe cumplir
$p \notin (0,1)$

***** Lipschitzianidad local para derivada continua
En $\Omega$ abierto, cualquier $f \in {\cal C}^1(\Omega,\mathbb{R}^m)$ es localmente lipschitziana.

****** Proof
Cada punto tiene un entorno cerrado convexo en el que podemos aplicar
Weierstrass para acotar $\vertiii{f'(x)}$ y aplicar la caracterización
[[id:0bd3f16f-5d05-4135-98b5-70d27b46afa9][global]] en un abierto dentro de él. 

****** Card: derivada continua y localmente lipschitz                                                      :drill: 
SCHEDULED: <2018-08-17 Fri>
:PROPERTIES:
:ID:       1d486c08-2683-48a2-8114-a6bd716eb758
:DRILL_LAST_INTERVAL: 65.7641
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.75
:DRILL_EASE: 2.32
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-12 Tue 18:22]
:END:
Cómo se relaciona la derivada continua con ser LL.

******* Relación
En $\Omega$ abierto, cualquier $f \in {\cal C}^1(\Omega,\mathbb{R}^m)$ es localmente lipschitziana.

***** Lipschitzianidad local respecto de una variable
$f \colon \Omega \subseteq \mathbb{R}^d \times \mathbb{R}^n \to \mathbb{R}^m$ es *localmente lipschitziana respecto* de $x \in \mathbb{R}^d$
si para cada punto existe un entorno $(p,q) \in U \subset \Omega$ tal que $f|_U$ es
globalmente lipschitziana respecto de $x \in \mathbb{R}^d$.

***** Lipschitzianidad local respecto de una variable para derivada continua
Si $\Omega$ abierto y $f_x$, derivada parcial respecto de $x$, es continua, entonces
$f$ es localmente lipschitziana respecto de la variable $x$.

****** Proof
Podemos tomar un entorno ${\cal U}$ donde $f_x$ está acotada, lo que hace que
todas las secciones $f(-,y)$ tengan derivada acotada uniformemente
respecto de $y$ y por la caracterización [[id:0bd3f16f-5d05-4135-98b5-70d27b46afa9][global]], tengan una constante
de Lipschitz común.

***** Lipschitzianidad local es global en compactos
Una función localmente lipschitziana en un compacto es globalmente
lipschitziana.

****** Proof
Usamos la caracterización, si no fuera globalmente lipschitziana,
[[id:d89ce0be-e6df-4af0-a129-12b79008efc2][existirían dos sucesiones]] donde el coeficiente crecería. Como
estamos en un compacto, esas dos sucesiones deberían converger
y deberían converger al mismo punto porque la función está
acotada en compactos por Weierstrass y la única forma de crecer
del cociente es que se acerquen.

Ahora, en ese punto podemos aplicar la caracterización de
[[id:c9318e14-3e65-49d1-935a-f26e56c912cf][lipschitzianidad local]].

https://math.stackexchange.com/questions/154721/if-locally-lipschitz-implies-lipschitz-on-compacts

****** Card                                                                                                :drill:
SCHEDULED: <2018-06-24 Sun>
:PROPERTIES:
:DRILL_CARD_TYPE: hide1cloze
:ID:       1b4ecf37-b2e0-42b6-bc5b-cab6e044a9ea
:DRILL_LAST_INTERVAL: 13.0352
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.7
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-11 Mon 21:41]
:END:
Una función [localmente lipschitziana] en un [compacto] es
[globalmente lipschitziana].

***** Propiedades de lipschitzianidad global
Ejemplos:

 * Suma de lipschitz es lipschitz.
 * Composición de lipscthiz es lipscthiz.
 * Lineal continua es lipschitz.
 * Valor absoluto es lipschitz.

Contraejemplos:

 * Producto de lipschitz no es lipschitz. $x^2$.


***** Propiedades de lipschitzianidad local
Ejemplos:

 * Suma de localmente lipschitz.
 * Producto (!) de localmente lipschitz.


**** 2.2. Lemas hacia Picard-Lindelöf
***** Teorema del punto fijo de Banach
Sea $(E,d)$ un espacio métrico completo con $F \colon E \to E$ con un $\alpha$ cumpliendo
$d(F(x),F(y)) \leq \alpha d(x,y)$ para todo $x,y \in E$. Entonces,
 
  1. $\exists! x^{\ast}\in E: F(x^{\ast}) = x^{\ast}$;
  2. y si $x_0 \in E$, entonces $\left\{ F \circ \overset{n}{\dots} \circ F (x_0) \right\}_{n \in \mathbb{N}} \longrightarrow x^{\ast}$.

Es decir, toda función contractiva en un espacio métrico completo tiene
un punto fijo y todas sus aplicaciones sucesivas convergen a él.

****** Proof                                                                                               :extra:
***** Entornos y espacios para Picard-Lindelöf
:PROPERTIES:
:ID:       44351076-d98f-4552-a229-a41405beb6b1
:END:
Dados $a,b \in \mathbb{R}^+$, definimos los siguientes entornos cerrados,
que pueden verse como la evolución de una bola cerrada dada en
un tiempo.

\[
R_{a,b}(t_0,x_0) = [t_0-a, t_0+a] \times {\overline B}(x_0,b).
\]

Definimos los siguientes espacios de funciones hacia los entornos,
que serán precisamente las funciones cumpliendo $(t,\varphi(t)) \in R_{a,b}$.

\[
E_{a,b}(t_0,x_0) = 
\left\{ \varphi \in {\cal C}([t_{0} - a, t_{0} + a], \mathbb{R}^{d}) 
\mid \varphi(t) \in {\overline B}(x_0,b)
\right\}.
\]

En este espacio tenemos el operador de Volterra $V : E \to {\cal C}([t_0-a,t_0+a];\mathbb{R}^d)$
definido por

\[
V(\varphi) = \int_{t_0}^t f(s,\varphi(s))\,ds.
\]

Es un espacio completo por ser un cerrado del espacio métrico de
funciones continuas acotadas.

***** Lema 1 de función contractiva
:PROPERTIES:
:ID:       552dd347-bd4b-41e0-9ba7-0ebf9e42a26a
:END:
Sea $M\geq 0$ tal que

\[
\forall (t,x) \in R_{a,b}\colon \|f(t,x)\| \leq M,
\]

Para cualquier $\varphi \in E$ se tiene $\|V(\varphi)-x_0\|_{\infty} \leq Ma$.

****** Proof
Tenemos que
\[
\| V(\varphi)-x_0 \|_{\infty} \leq
\left\| \int_{t_0}^t f(s,\varphi(s))\,ds \right\|_{\infty} \leq
M\|t-t_0\|_{\infty} \leq Ma.
\]

Nótese que usamos que $(t,\varphi(s)) \in R_{a,b}$.

***** Corolario 1 de función contractiva
:PROPERTIES:
:ID:       2b8c94be-2d60-45a0-aedf-715aa71fe67b
:END:
Sea $M \geq 0$ tal que

\[
\forall (t,x) \in R_{a,b}\colon \|f(t,x)\| \leq M.
\]

Si $aM \leq b$, entonces $V(E_{a,b}) \subset E_{a,b}$.

****** Proof
Aplicando el [[id:552dd347-bd4b-41e0-9ba7-0ebf9e42a26a][lema anterior]] para $\varphi \in E_{a,b}$ tenemos que $\|V(\varphi) - x_0\|_{\infty} \leq Ma \leq b$,
luego $V(\varphi) \in \overline{B}(x_0,b)$ y por [[id:44351076-d98f-4552-a229-a41405beb6b1][definición]] se tiene $V(\varphi) \in E_{a,b}$.

***** Lema 2 de función contractiva
:PROPERTIES:
:ID:       b3c86eea-1732-4df4-8f69-32b80a9510c0
:END:
Sea $M \geq 0$ tal que

\[
\forall (t,x) \in R_{a,b}\colon \|f(t,x)\| \leq M.
\]

Si $aM \leq b$, y $\varphi \colon [t_0-a,t_0+a] \to \mathbb{R}^d$ es solución de Volterra,
entonces $\varphi \in E_{a,b}$.

****** Proof
Afirmamos que $\|\varphi-x_0\|_{\infty} \leq b$. Si no fuera cierto, por el [[id:a439476b-8c77-4994-a736-9062ee91e7d0][Lema del primer instante]]
tendríamos un $b<\|\varphi(\tau) - x_0\|$ tal que $\forall t \in [t_0,\tau)\colon \|\varphi(t)-x_0\| \leq b$.
Aplicado en la dirección contraria lo tendríamos para $(\tau,t_0]$.

Pero entonces, $\forall t \in [t_0,\tau)\colon (t,\varphi(t)) \in {\cal R}_{a,b}$ y

\[\begin{aligned}
b < \|\varphi(\tau)-x_0\| &\leq
\left\| \int_{t_0}^t f(s,\varphi(s))\,ds \right\| \leq
\int_{t_0}^t \left\| f(s,\varphi(s)) \right\|\,ds \\&\leq
M|t-t_0| \leq
Ma \leq b.
\end{aligned}\]

Llegando a contradicción.

***** Lema 3 de función contractiva
:PROPERTIES:
:ID:       65fb9d51-29a8-4528-a9dc-eca1b77bf8e0
:END:
Sea $L \geq 0$ tal que

\[
\forall (t,x),(t,y) \in {\cal R}_{a,b}\colon \|f(t,x)-f(t,y)\| \leq L\|x-y\|.
\]

Si $\varphi,\psi \in E_{a,b}$, entonces $\|V(\varphi)-V(\psi)\|_{\infty} \leq aL\|\varphi-\psi\|_{\infty}$.

****** Proof
Para $t \in [t_0-a,t_0+a]$,

\[\begin{aligned}
\| V(\varphi)(t) - V(\psi)(t) \| &=
\left\| \int_{t_0}^t \left( f(s,\varphi(s)) - f(s,\psi(s)) \right)\,ds \right\| \\&\leq
\int_{t_0}^t \left\|  f(s,\varphi(s)) - f(s,\psi(s)) \right\|\,ds \\&\leq
\int_{t_0}^t L\left\| \varphi(s)-\psi(s) \right\|\,ds \\&\leq
La\|\varphi-\psi\|_{\infty}.
\end{aligned}\]

***** Proposición 1 de función contractiva
Sean $M,L \geq 0$ tales que

\[
\forall (t,x) \in R_{a,b}\colon \|f(t,x)\| \leq M,
\]

y que

\[
\forall (t,x),(t,y) \in {\cal R}_{a,b}\colon \|f(t,x)-f(t,y)\| \leq L\|x-y\|.
\]

Si $aM\leq b$ y $aL \leq 1$, entonces existe una única $\varphi\colon [t_0-a,t_0+a] \to \mathbb{R}^d$
solución de Volterra.

****** Proof
Usando $M$ en el [[id:2b8c94be-2d60-45a0-aedf-715aa71fe67b][Corolario 1]] tenemos $V(E_{a,b}) \subset E_{a,b}$, y usando $L$ 
en el [[id:65fb9d51-29a8-4528-a9dc-eca1b77bf8e0][Lema 3]],

\[
\| V(\varphi) - V(\psi) \|_{\infty} \leq aL\|\varphi-\psi\|_{\infty} \leq \|\varphi - \psi\|_{\infty}.
\]

Por el Teorema del punto fijo de Banach, $\exists \varphi \in E\colon V(\varphi) = \varphi$, solución
de Volterra. Si hubiera otra solución $\psi$ en mismo intervalo usamos el
[[id:b3c86eea-1732-4df4-8f69-32b80a9510c0][Lema 2]] para tener $\psi \in E$ y por Teorema de Banach, $\varphi = \psi$.

# TODO: ¿Cómo sabemos que E es completo?

**** 2.3. Norma de Bielecki
***** Norma de Bielecki
En el espacio $E_{a,b}(t_0,x_0)$, dada una constante $R > 0$, consideramos

\[
\| \varphi \|_{B} = \max_{t \in [t_0-a,t_0+a]} e^{-R|t-t_0|}\|\varphi(t)\|.
\]

****** Bien definida
Sabemos que existe por Teorema de Weierstrass.

****** Card: definición                                                                                    :drill:
SCHEDULED: <2018-07-18 Wed>
:PROPERTIES:
:ID:       7748c216-94a7-4d91-a824-6fd195ffe10f
:DRILL_LAST_INTERVAL: 59.5744
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 5
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.2
:DRILL_EASE: 2.18
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-05-19 Sat 11:01]
:END:
Define la norma de Bielecki para una $R > 0$ dada.

******* Definición
En $E_{a,b}(t_0,x_0)$, consideramos

\[
\| \varphi \|_{B} = \max_{t \in [t_0-a,t_0+a]} e^{-R|t-t_0|}\|\varphi(t)\|.
\]

***** Equivalencia con la norma infinito
La norma de Bielecki es equivalente a la norma infinito.

****** Proof
Tenemos las dos cotas dadas por $0 \leq |t - t_0| \leq a$.

\[
\max_{t \in [t_0-a,t_0+a]} e^{-R|t-t_0|}\|\varphi(t)\| \leq
\max_{t \in [t_0-a,t_0+a]} \|\varphi(t)\| 
\]

y

\[
\max_{t \in [t_0-a,t_0+a]} e^{-R|t-t_0|}\|\varphi(t)\| \geq
e^{-R|a|} \max_{t \in [t_0-a,t_0+a]} \|\varphi(t)\|.
\]

***** Lema 4 de función contractiva
:PROPERTIES:
:ID:       376ef232-7050-4306-abe7-b88843d13fcb
:END:
Sea $L \geq 0$ tal que

\[
\forall (t,x),(t,y) \in {\cal R}_{a,b}\colon \|f(t,x)-f(t,y)\| \leq L\|x-y\|.
\]

Si $\varphi , \psi \in E_{a,b}$ entonces $\|V(\varphi) - V(\psi)\|_B \leq \frac{L}{R} \| \varphi - \psi \|_{B}$.

****** Proof
# Comprobar, ¿no hay que partir en caso negativo y positivo?

Nótese primero que $\|V(\varphi)(t_0) - V(\psi)(t_0)\| = 0$. Fijado un $t \neq t_0$
usamos la cota de $L$ y la definición de la norma de Bielecki para tener

\[\begin{aligned}
\norm{V(\varphi)(t) - V(\psi)(t)} &=
\norm{\int_{t_0}^t f(s,\varphi(s)) - f(s,\psi(s))\,ds} \\&\leq
\int_{t_0}^t \norm{f(s,\varphi(s)) - f(s,\psi(s))}\,ds \\&\leq
L \int_{t_0}^t \norm{\varphi(s) - \psi(s)}\,ds \\&=
L \int_{t_0}^t \norm{\varphi(s) - \psi(s)} e^{-R\abs{s-t_0}}e^{R\abs{s-t_0}}\,ds \\&\leq
L \norm{\varphi - \psi}_{B} \int_{t_0}^t e^{R\abs{s-t_0}}\,ds \\&\leq
\frac{L}{R} \norm{\varphi - \psi}_{B} \left(e^{R\abs{t-t_0}} - 1\right) \\&\leq
\frac{L}{R} \norm{\varphi - \psi}_{B} e^{R\abs{t-t_0}}
\end{aligned}\]

ya que $e^{R|t-t_0|} > 0$. Dividiendo y uniendo ambos casos,
$\|V(\varphi) - V(\psi)\|_{\infty} \leq \frac{L}{R} \norm{\varphi - \psi}_{B} e^{R\abs{t-t_0}}$.

***** Proposición 2 de función contractiva
:PROPERTIES:
:ID:       51ed4957-d6c4-448f-bfe0-8a8d2afe218b
:END:
Sean $M,L \geq 0$ tales que

\[
\forall (t,x) \in R_{a,b}\colon \|f(t,x)\| \leq M,
\]

y que

\[
\forall (t,x),(t,y) \in {\cal R}_{a,b}\colon \|f(t,x)-f(t,y)\| \leq L\|x-y\|.
\]

Si $aM\leq b$, entonces existe una única $\varphi\colon [t_0-a,t_0+a] \to \mathbb{R}^d$
solución de Volterra.

****** Proof
Si tomamos un $R > L$ podemos aplicar el [[id:376ef232-7050-4306-abe7-b88843d13fcb][lema anterior]] para obtener
que $V$ es contractiva con la norma de Bielecki, luego por Teorema
de Banach, existe un único punto fijo de $V$.

**** 2.4. Picard-Lindelöf
***** Teorema de Picard-Lindelöf (versión local)
:PROPERTIES:
:ID:       1bf1287f-59b3-4a74-9bfc-4c7de6004d50
:END:
Si $f$ es localmente lipschiztiana respecto de $x$ en un entorno de $(t_0,x_0)$,
el PVI tiene solución y es única localmente.

****** Proof
Para algún $(t_0,x_0) \in {\cal U} \subset D$,

\[
\forall (t,x),(t,y) \in {\cal U}\colon  \|f(t,x)-f(t,y)\| \leq L\|x-y\|.
\]

Tomamos ${\cal R}_{\overline{a},b}(t_0,x_0) \subset {\cal U}$ y $f|_{{\cal R}_{\overline{a},b}}$ será globalmente lipschitz luego continua
y podemos aplicar Teorema de Weierstrass para tener

\[
M = \max_{(t,x) \in {\cal R}_{a,b}} \|f(t,x)\|.
\]

Recortamos $a = \min\left\{\overline{a}, b/M, 1/L \right\}$ para aplicar la [[id:51ed4957-d6c4-448f-bfe0-8a8d2afe218b][proposición]] 
anterior, sabiendo ${\cal R}_{a,b} \subseteq {\cal R}_{\overline{a},b}$. Por Banach tenemos $\varphi \colon [t_0-a,t_0+a] \to \mathbb{R}^d$
solución de Volterra, que nos da $\varphi \colon (t_0-a,t_0+a) \to \mathbb{R}^d$
solución del PVI, con $\varphi \in E_{a,b}$.

Sea ahora $\psi \colon I \to \mathbb{R}^d$ otra solución; por continuidad
existe un $\delta < a$ tal que para $|t - t_0| < \delta$ se tiene $\|\psi(t) - x_0\| \leq b$.
Tendríamos dos soluciones $\psi,\varphi$ en $E_{\delta,b}(t_0,x_0)$, donde $\delta M < b$, 
luego coincidirían en $[t_0-\delta,t_0+\delta]$.

***** Teorema de Picard-Lindelöf (versión global)
:PROPERTIES:
:ID:       bf38540e-3857-427e-9b27-e6c0bf0cfd73
:END:
Si $f$ es localmente lipschiztiana respecto de $x$ en todo el dominio,
el PVI tiene solución y es la única solución maximal.

****** Proof
Cualquier $(t_0,x_0)$ tiene un entorno (el dominio) donde aplicar la
[[id:1bf1287f-59b3-4a74-9bfc-4c7de6004d50][versión local]]. La unicidad local bajo cualquier condición inicial
[[id:0b968d38-72b0-41e4-bdbd-a19fd33ecd59][nos da]] la unicidad global bajo cualquier condición inicial.

***** Iterantes de Picard
Surgen como una aplicación repetida del operador de Volterra una vez que
sabemos que es contractivo.

\[
V(\varphi)(t) = x_0 + \int_{t_0}^t f(s,\varphi(s))\,ds.
\]

***** Contraejemplo de Müller
Sea el PVI

\[\left\{\begin{array}{l}
x' = f(t,x) \\
x(0) = 0
\end{array}\right.\]

para $f \colon \mathbb{R} \times \mathbb{R} \to \mathbb{R}$ definida como

\[ f(t,x) = \left\{
\begin{array}{ll}
  0 & \mbox{ si } t \leq 0, \\
  2t & \mbox{ si } t > 0 \mbox{ y } x < 0, \\
  2t - \frac{4x}{t} & \mbox{ si } t > 0 \mbox{ y } 0 \leq x < t^2, \\
  -2t & \mbox{ si } t > 0 \mbox{ y } x > t^2. \\
\end{array}\right.\]

****** Unicidad
Sabemos que la solución al PVI es única por tenerse unicidad
tanto en el futuro como en el pasado por [[id:cc790c02-b622-4fc1-8bb1-ac3c05e73009][
Teorema de Unicidad de Peano]].

La única solución puede encontrarse buscando solución
a
\[
x' = 2t - \frac{4x}{t}.
\]
Que es una ecuación lineal escalar que se resolverá como
$x = t^2/3 + A/t^4$ y a la que imponemos condiciones para
obtener $x = t^2/3$ solución cuando $t > 0$ y $x = 0$ cuando $t \leq 0$.

****** Sucesión de iterantes de Picard
La sucesión de iterantes de Picard lleva a $0,t^2,-t^2,t^2,\dots$.
Tiene parciales convergentes pero ninguna a la solución.

*** Tema 3. Teorema de Cauchy-Peano y Teorema de Arzelá-Ascoli
**** 3.1. Acotación uniforme y equicontinuidad
***** Sucesión uniformemente acotada
:PROPERTIES:
:ID:       23715dfb-0085-4d8e-9b93-26465cbbee91
:END:
$f_n \colon I \to \mathbb{R}^{d}$ es *uniformemente acotada* si existe $\|f_n(t)\|\leq M$
para todo $n \in \mathbb{N}$ y $t \in I$.

****** No uniformemente acotada
$f_n \colon I \to \mathbb{R}^d$ no es *uniformemente acotada* si existe $\left\{ \| f_{m_n}(t_n) \| \right\}_{n \in \mathbb{N}} \to \infty$.
Por definición.

***** Sucesión equicontinua
$f_n \colon I \to \mathbb{R}^d$ es *equicontinua* si 

\[
\forall \varepsilon\colon \exists \delta\colon |t-s|<\delta \implies \|f_n(t) - f_n(s)\| \leq \varepsilon.
\]

***** Caracterización de equicontinuidad
Una $f_n \colon I \to \mathbb{R}^d$ uniformemente continua no será equicontinua si
hay sucesiones $t_n$, $s_n$ tales que

\[
\exists (t_n,s_n)\colon \abs{ t_n-s_n} \to 0, \quad \|f_{m_n}(t_n)-f_{m_n}(s_n)\| \not\to 0.
\]

****** Proof
Sale al negar la definición.

****** TODO Variación
***** Lema 1. Derivada uniformemente acotada es equicontinua
:PROPERTIES:
:ID:       5b2c7b57-f17b-441f-a635-fddbb3e0c992
:END:
Si $f'_n$ es uniformemente acotada, $f_n \in {\cal C}^1(I,\mathbb{R}^d)$ es *equicontinua*.

****** Proof
Usamos teorema fundammental del cálculo, que necesita $f'_n$ continua

\[
\|f_n(t)-f_n(s)\| = \left\| \int_s^t f'_n(z)\,dz \right\| \leq M|t-s|.
\]

****** Card: enunciado                                                                                     :drill:
SCHEDULED: <2018-07-14 Sat>
:PROPERTIES:
:DRILL_CARD_TYPE: hide1cloze
:ID:       91181bc4-99ca-4e68-99f3-f5c4467f3c16
:DRILL_LAST_INTERVAL: 32.266
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.75
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-12 Tue 18:16]
:END:
Si $f'_n$ es [uniformemente acotada], $f_n \in$ [${\cal C}^1(I,\mathbb{R}^d)$] es [ *equicontinua* ].

****** Card: idea de la demostración                                                                       :drill:
SCHEDULED: <2018-07-19 Thu>
:PROPERTIES:
:ID:       40e3f231-b6d2-4980-9fa0-37d6a98dc700
:DRILL_LAST_INTERVAL: 36.7182
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.333
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-12 Tue 18:21]
:END:
¿Cómo se demuestra?

Si $f'_n$ es uniformemente acotada, $f_n \in$ ${\cal C}^1(I,\mathbb{R}^d)$ es *equicontinua*.

******* Demostración
Usamos teorema fundamental del cálculo, que necesita $f'_n$ continua

\[
\|f_n(t)-f_n(s)\| = \left\| \int_s^t f'_n(z)\,dz \right\| \leq M|t-s|.
\]

***** Lema 2. Convergencia puntual de equicontinuas es uniformemente continua
:PROPERTIES:
:ID:       09edde13-8c3f-49d5-9571-76483e3c2cd3
:END:
Si $f_n \overset{c.p.}\longrightarrow f$ y $f_n \colon I \to \mathbb{R}^{d}$ equicontinua, $f$ es uniformemente continua.

****** Proof
Tenemos para $|t-s| < \delta$, $\norm{f_n(t) - f_n(s)} < \varepsilon$, tomando límite en $n$,

\[\norm{f(t) - f(s)} \leq \varepsilon.\]

****** Card: enunciado                                                                                     :drill:
SCHEDULED: <2018-07-06 Fri>
:PROPERTIES:
:DRILL_CARD_TYPE: hide1cloze
:ID:       7be1e96f-5d20-4380-993f-cd23084f427e
:DRILL_LAST_INTERVAL: 24.3586
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.46
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-12 Tue 18:09]
:END:

Si [ $f_n \overset{c.p.}\longrightarrow f$ ] y $f_n\colon I \to \mathbb{R}^d$ [sucesión equicontinua], $f$ es [uniformemente continua].

****** Card: idea de la demostración                                                                       :drill:
SCHEDULED: <2018-07-07 Sat>
:PROPERTIES:
:ID:       7805ecf8-032a-4fbf-ac0e-2eeab3dd2f48
:DRILL_LAST_INTERVAL: 25.3869
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.25
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-12 Tue 18:13]
:END:
¿Cómo se demuestra?

Si $f_n \overset{c.p.}\longrightarrow f$ y $f_n$ equicontinua, $f$ es uniformemente continua.

******* Demostración
Tenemos para $|t-s| < \delta$, $\norm{f_n(t) - f_n(s)} < \varepsilon$, tomando límite en $n$,

\[\norm{f(t) - f(s)} \leq \varepsilon.\]

***** Lema 3. Convergencia uniforme de continuas es continua
:PROPERTIES:
:ID:       0828ef4f-b005-4cd4-a036-e6aa535b27f0
:END:
Si $f_n \overset{c.u.}\longrightarrow f$ y $f_n \colon I \to \mathbb{R}^d$ son continuas, $f$ es continua.

****** Proof

\[
\norm{f(t) - f(s)} \leq 
\norm{f_n(t) - f(t)} + 
\norm{f_n(t) - f_n(s)} + 
\norm{f_n(s) - f(s)}
\]

Elegimos el $n$ que por convergencia uniforme dé $\norm{f_n - f}_{\infty} \leq \varepsilon/3$.
Elegimos el $\delta$ que por continuidad de $f_n$ dé $\norm{f_n(t)-f_n(s)} \leq \varepsilon/3$.

****** Card                                                                                                :drill:
SCHEDULED: <2018-06-24 Sun>
:PROPERTIES:
:ID:       30c09570-1887-4a89-8c5e-e354d2fd18a9
:DRILL_LAST_INTERVAL: 12.9428
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-11 Mon 21:43]
:END:
La función a la que converge uniformemente una sucesión de funciones
continuas es [continua].

***** Lema 4. Convergencia de sucesiones desde la convergencia uniforme
:PROPERTIES:
:ID:       d2bb5e99-e7e9-4fa2-a8e2-38dcda39917e
:END:
Sea $f_n \overset{c.u.}\longrightarrow f$ y $t_n \to t_{\ast}$. Si $f$ continua en $t_{\ast}$, entonces $f_n(t_n) \to f(t_{\ast})$.

****** Proof

\[
\norm{f_n(t_n) - f(t_{\ast})} \leq
\norm{f_n(t_n) - f(t_n)} + \norm{f(t_n) - f(t)} \leq \varepsilon
\]

Podemos usar la continuidad de $f$ y la convergencia uniforme para obtener
dos $n_0,n_1$ donde cada sumando está acotado. Tomamos el máximo de ambos.

****** Card                                                                                                :drill:
SCHEDULED: <2018-07-09 Mon>
:PROPERTIES:
:DRILL_CARD_TYPE: hide1cloze
:ID:       ab2c5732-be11-41e0-aeef-6a4cdb65bed2
:DRILL_LAST_INTERVAL: 27.3535
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.333
:DRILL_EASE: 2.56
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-12 Tue 18:10]
:END:
Sea [ $f_n \overset{c.u.}\longrightarrow f$ ] y $t_n \to t_{\ast}$. Si [ $f$ continua en $t_{\ast}$ ], entonces [ $f_n(t_n) \to f(t_{\ast})$ ].

***** Corolario. Convergencia de sucesiones desde la convergencia uniforme de continuas
Sea $f_n \overset{c.u.}\longrightarrow f$ y $t_n \to t_{\ast}$. Si $f_n$ continuas, entonces $f_n(t_n) \to f(t_{\ast})$.

****** Proof
La [[id:0828ef4f-b005-4cd4-a036-e6aa535b27f0][convergencia uniforme de continuas es continua]], en particular,
continua en $t_{\ast}$. [[id:d2bb5e99-e7e9-4fa2-a8e2-38dcda39917e][Aplicamos el lema anterior]].

****** Card                                                                                                :drill:
SCHEDULED: <2018-06-29 Fri>
:PROPERTIES:
:DRILL_CARD_TYPE: hide1cloze
:ID:       b3d5bdc9-f233-4873-ac2b-6dc5c066ff6a
:DRILL_LAST_INTERVAL: 16.5566
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.333
:DRILL_EASE: 2.56
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-12 Tue 14:57]
:END:
Sea [ $f_n \overset{c.u.}\longrightarrow f$ ] y $t_n \to t_{\ast}$. Si $f_n$ continuas, entonces [ $f_n(t_n) \to f(t_{\ast})$].
****** Card                                                                                                :drill:
SCHEDULED: <2018-06-24 Sun>
:PROPERTIES:
:ID:       3c9e00f3-cbef-43fa-99bc-bef434ab5df5
:DRILL_CARD_TYPE: hide1cloze
:DRILL_LAST_INTERVAL: 11.5417
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.5
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-12 Tue 14:56]
:END:
Si $x_n \to x$ y tenemos [ $g_n \overset{c.u.}\longrightarrow g$ ], donde cada $g_n$ es continua,
entonces [ $g_n(x_n) \to g(x)$].

***** Ejemplos y contraejemplos
****** TODO Función continua no uniformemente continua
****** TODO Sucesión equicontinua
****** TODO Sucesión que converge puntualmente no uniformemente
****** Sucesión de uniformemente continuas no equicontinua
$f_n(t) = nt$ tiene cada función uniformemente continua (de hecho es lipschitz)
pero no es equicontinua porque

\[
\left\{ f_n\left(\frac{1}{n}\right) - f_n(0) \right\} \to 1.
\]

******* Card                                                                                              :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       49a7eaad-0bac-4e3f-b2d6-74e16b58bedc
:DRILL_LAST_INTERVAL: 11.1843
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.46
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-11 Mon 21:42]
:END:
¿Es equicontinua?

\[f_n(t) = nt\]

******** Answer                                                
:PROPERTIES:
:ID:       4aa943ea-e020-4f65-88d8-77aaedfe7bee
:END:
No. Se tiene

\[
\left\{ f_n\left(\frac{1}{n}\right) - f_n(0) \right\} \to 1.
\]

****** Derivada acotada uniformemente y equicontinua
La sucesión $\sin(n + t)$ tiene sucesión de derivadas $\cos(n+t)$
uniformemente acotada, luego es equicontinua.

******* Card                                                                                              :drill:
SCHEDULED: <2018-06-25 Mon>
:PROPERTIES:
:ID:       fcd52f7f-edcf-4c14-a859-44bdf5ea1ba5
:DRILL_LAST_INTERVAL: 10.5769
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.25
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-14 Thu 11:49]
:END:
Por qué es $\sin(n + t)$ equicontinua.

******** Answer
Tiene sucesión de derivadas $\cos(n+t)$ uniformemente acotada.

****** TODO Buscar ejemplos en matemapli
**** 3.2. Teorema de Ascoli-Arzelá
***** Teorema de Ascoli-Arzelá
:PROPERTIES:
:ID:       da2e68f3-95f5-4aa2-b265-234ab61750c5
:END:
Para $f_n \colon I \to \mathbb{R}^d$ uniformemente acotada y equicontinua, existe una
parcial $f_{\sigma(n)} \overset{c.p.}\longrightarrow f$; además, $f$ es uniformemente continua.

****** Demostración
******* Paso 1. Convergencia en un numerable denso
Sea $D = \mathbb{Q} \cap I = \left\{ t_k \mid k \in \mathbb{N} \right\}$ numerable.

Para cada $k \in \mathbb{N}$, $\left\{f_n(t_k)\right\}_{n\in\mathbb{N}$ es acotada (por [[id:23715dfb-0085-4d8e-9b93-26465cbbee91][uniformemente acotada]]), 
y por Bolzano-Weierstrass inductivamente en $k$ tenemos $\sigma_k$ tal
que $f_{\sigma_1\circ\dots\circ\sigma_k(n)}(t_k)$ converge. Definimos en $D$,

\[
f(t_k) = \lim_{n \to \infty} f_{\sigma_1\circ \dots\circ \sigma_k(n)}(t_k).
\]

Ahora llamamos $\sigma(n) = \sigma_1\circ\dots\circ\sigma_n (n)$ y vemos que es creciente
por tenerse $\sigma_{n+1}(n+1) > n+1 > n$, luego $\sigma(n+1) > \sigma(n)$.
Comprobamos que $f_{\sigma(n)} \overset{c.p. \text{ en } D}\longrightarrow f$ porque para $t_k$, a partir de $k$,
la serie es una parcial de la que define $f$.

******* Paso 2. Extensión al intervalo
Dado $t \in I$ y $\varepsilon>0$.
Por equicontinuidad, $\exists \delta > 0\colon |s'-s|<\delta \implies \|f_n(s')-f_n(s)\| \leq \varepsilon/3$ dos veces.
Por densidad $\exists t_k\colon |t_k - t| < \delta$.
Por convergencia, $\forall p,q \geq n_0\colon \| f_{\sigma(p)}(t_k) - f_{\sigma(q)}(t_k) \| < \varepsilon/3$ una vez

uniendo todo con desigualdad triangular,

\[
\| f_{\sigma(p)}(t) - f_{\sigma(q)}(t)} \| < \epsilon.
\]

Y así, $f_{\sigma(n)}(t)$ es de Cauchy y converge a un punto que usamos para
definir $f(t)$. [[id:09edde13-8c3f-49d5-9571-76483e3c2cd3][Sabemos que]] la convergencia puntual de equicontinuas
es uniformemente continua.

****** Card                                                                                                :drill:
SCHEDULED: <2018-08-08 Wed>
:PROPERTIES:
:ID:       a2f54cc4-d74f-4e72-be6a-bba39aab74a7
:DRILL_CARD_TYPE: multisided
:DRILL_LAST_INTERVAL: 56.9093
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.5
:DRILL_EASE: 2.18
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-12 Tue 18:19]
:END:
Enuncia el Teorema de Ascoli-Arzelá.

******* Enunciado
Para $f_n \colon I \to \mathbb{R}^d$ uniformemente acotada y equicontinua, existe una
parcial $f_{\sigma(n)} \overset{c.p.}\longrightarrow f$; además, $f$ es uniformemente continua.

******* Idea de demostración
:PROPERTIES:
:ID:       80a088fa-84cb-44e7-9d9f-e6222a4a2eef
:END:
Tomamos $D = \mathbb{Q} \cap I = \left\{ t_k \mid k \in \mathbb{N} \right\}$. Bolzano-Weierstrass 
inductivamente nos da una convergente en $D$.

\[
f(t_k) = \lim_{n \to \infty} f_{\sigma_1\circ \dots\circ \sigma_k(n)}(t_k).
\]

Extendemos a todo el intervalo usando *equicontinuidad*,
*densidad* y *convergencia en D*.

***** Corolario a Ascoli-Arzelá
:PROPERTIES:
:ID:       859883bd-15a4-4efd-9d61-7d501b592918
:END:
En $I$ compacto, para $f_n \colon I \to \mathbb{R}^d$ uniformemente acotada y equicontinua,
existe una parcial tal que $f_{\sigma(n)} \overset{c.u.}\longrightarrow f$; además, $f$ es uniformemente continua.

****** Demostración
Aplicamos [[id:da2e68f3-95f5-4aa2-b265-234ab61750c5][Teorema de Ascoli-Arzelá]] para obtener la $f$ uniformemente continua
y convergencia puntual hacia ella.

Por equicontinuidad, $\exists \delta_1\colon |t-s| < \delta_1 \implies \|f_n(t)-f_n(s)\| \leq \varepsilon/3$.
Por continuidad uniforme de $f$, $\exists \delta_2\colon |t-s| < \delta_2 \implies \|f(t) - f(s)\| \leq \varepsilon/3$.
Tomamos $\delta = \min \left\{ \delta_1,\delta_2 \right\}$.

Por compacidad,

\[
I = \bigcup_{t \in I} (t-\delta,t+\delta) = \bigcup_{i = 0}^k (t_k-\delta,t_k+\delta)
\]

Por convergencia puntual de cada $t_j$, $\exists n_j\colon \|f_{\sigma(n)}(t_j) - f(t_j)\| \leq \varepsilon/3$; y
tomamos $n_0 = \max\{n_1,\dots,n_k\}$. Finalmente, para $n \geq n_0$,

\[
\|f_{\sigma(n)}(t) - f(t)\| \leq 
\|f_{\sigma(n)}(t) - f_{\sigma(n)}(t_k)\| + 
\|f_{\sigma(n)}(t_k) - f(t_k)\| + 
\|f(t_k) - f(t)\| \leq \varepsilon.
\]

****** Card                                                                                                :drill:
SCHEDULED: <2018-08-23 Thu>
:PROPERTIES:
:ID:       cda99124-7715-4d0b-8892-d901da3817a7
:DRILL_LAST_INTERVAL: 72.4154
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.25
:DRILL_EASE: 2.56
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-12 Tue 15:01]
:END:
¿Qué dice Ascoli-Arzelá cuando se aplica sobre un compacto?

******* Corolario
En $I$ compacto, para $f_n \colon I \to \mathbb{R}^d$ uniformemente acotada y equicontinua,
existe una parcial tal que $f_{\sigma(n)} \overset{c.u.}\longrightarrow f$; además, $f$ es uniformemente continua.

***** Herramienta para ejercicios                                                                           :extra:
Si $f_n$ es sucesión de equicontinuas convergiendo puntualmente $f_n\to f$
a una $f$ uniformemente continua en un compacto $I$, entonces hay
convergencia uniforme.

****** Proof
Fijado un $\varepsilon$, hay por equicontinuidad y continuidad uniforme de $f$
un $\delta$ tal que tomamos bolas de radio $\delta$ en el compacto y creamos
un subrecubrimiento finito. Ahora tomamos un $n$ suficientemente grande
como para que todos los centros del subrecubrimiento $t^{\ast}_n$ estén más
cerca de $f(t^{\ast}_n)$ que  $\varepsilon/3$. Dado cualquier $t$, tiene a menos de $\delta$ a
un centro del subrecubrimiento. Aplicamos desigualdad triangular
para acotar la diferencia

\[
\norm{f_n(t) - f(t)} \leq
\norm{f_n(t) - f_n(t^{\ast})} +
\norm{f_n(t^{\ast}) - f(t^{\ast})} + 
\norm{f(t)-f(t^{\ast})}.
\]

**** 3.3. Convergencia e integración
***** Convergencia uniforme en integrales
Si $f_n \overset{c.u.}\longrightarrow f$ y $f_n$ continua en $[a,b]$, entonces $\int_a^b f_n \to \int_a^b f$.

****** Proof

\[
\norm{\int_a^b (f_n(s) - f(s))\,ds} \leq
\norm{f_n-f}_{\infty}(b-a) \to 0 
\]

***** Convergencia puntual desde acotada
Si $f_n \overset{c.p.}\longrightarrow f$ y $f_n$ continuas uniformemente acotadas, $\int_a^b f_n \to \int_a^b f$.

****** TODO Proof                                                                                          :extra:
Por el Teorema de convergencia dominada de Lebesgue. 

****** Card                                                                                                :drill:
SCHEDULED: <2018-06-17 Sun>
:PROPERTIES:
:DRILL_CARD_TYPE: hide1cloze
:ID:       eac30143-b758-4577-a6e3-1d0347a4d8a9
:DRILL_LAST_INTERVAL: 4.6711
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 5
:DRILL_FAILURE_COUNT: 2
:DRILL_AVERAGE_QUALITY: 3.6
:DRILL_EASE: 2.7
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-12 Tue 18:42]
:END:
Si $f_n \overset{c.p.}\longrightarrow f$ y [además $f_n$ continuas uniformemente acotadas en $(a,b)$], entonces $\int_a^b f_n \to \int_a^b f$.

******* Extra: caso particular
Si $f_n \overset{c.u.}\longrightarrow f$ y $f_n$ continua en $[a,b]$, entonces $\int_a^b f_n \to \int_a^b f$.

En particular podemos pedir continuidad a todas las $f_n$.

**** 3.4. Teorema de Cauchy-Peano
***** Teorema de Stone-Weierstrass                                                                          :extra:
:PROPERTIES:
:ID:       a786fcd1-033d-477b-865e-a8a1f0aef252
:END:
****** Álgebras de Banach separando puntos y que no se desvanecen
Una familia de funciones reales ${\cal A}$ sobre un conjunto $X$ se dice
*álgebra* si es cerrada para la suma y producto de funciones y
para el producto por escalares. 

Si consideramos el conjunto de funciones $X \to \mathbb{R}$ como un
espacio métrico con la norma del supremo, la convergencia es la
convergencia uniforme. En el caso en el que todas las funciones
de ${\cal A}$ están acotadas, podemos comprobar que la clausura bajo esta
norma de ${\cal A}$ es de nuevo un *álgebra*; de hecho, tenemos que para
$\lambda \in \mathbb{R}$ y $p_n,q_n \in {\cal A}$ con $p_n \overset{c.u.}\longrightarrow p$ y $q_n \overset{c.u.}\longrightarrow q$,

 * $p_n + q_n \overset{c.u.}\longrightarrow p + q$, ya que
   \[
   \norm{(p_n + q_n) - (p + q)}_{\infty} \leq
   \norm{p_n - p}_{\infty} + \norm{q_n - q}_{\infty} \longrightarrow 0;
   \]

 * $p_nq_n \overset{c.u.}\longrightarrow pq$ usando que todas ellas estarán acotadas y
   que $\norm{p}_{\infty} \leq \sup \left\{ \norm{p_n}_{\infty} \right\}$, que existe por la convergencia,
   \[
   \norm{p_nq_n - pq}_{\infty} \leq
   \norm{p_n - p}_{\infty}\norm{q_n}_{\infty} + 
   \sup \left\{ \|p_n\|_{\infty} \right\} \norm{q_n-q}_{\infty} \longrightarrow 0;
   \]

 * y $\lambda p_n \overset{c.u.}\longrightarrow \lambda p$, ya que
   \[
   \norm{\lambda p_n}_{\infty} \leq \abs{\lambda}\norm{p_{\infty}} \longrightarrow 0.
   \]

Decimos que el álgebra *separa puntos* si para cada par $x,y \in X$
existe $p \in {\cal A}$ tal que $p(x) \neq p(y)$. Decimos que no se *desvanece*
en ningún punto si para cada $x \in X$ hay una $p \in {\cal A}$ tal que $p(x) \neq 0$.
Cuando un álgebra separa puntos y no se devanece, dados dos reales
$\lambda,\mu \in \mathbb{R}$ y dos puntos $x,y \in X$ existe una $p \in {\cal A}$ que separa
los puntos y dos $q_x,q_y \in {\cal A}$, con $q_x(x) \neq 0$ y $q_y(y) \neq 0$; entonces
podemos definir

\[
a = pq_x - p(y)q_x, \quad
b = pq_y - p(x)q_y, 
\]

que cumplen $a(x) \neq 0$ y $b(y) \neq 0$, $b(x) = a(y) = 0$,; así, existe
siempre una función $r$ que vale exactamente $\lambda$ en $x$ y $\mu$ en $y$,
definida como

\[
r = \frac{\lambda b}{b(x)} + \frac{\mu a}{a(y)}.
\]

****** Teorema de Stone-Weierstrass
Sea ${\cal A}$ un álgebra de funciones continuas sobre un espacio
compacto $K$ que separa puntos y no se desvanece en ninguno.
La clausura bajo la norma del supremo es entonces ${\cal C}(K,\mathbb{R})$,
el conjunto de todas las funciones continuas reales sobre $K$.

******* Proof
******** Paso 1. Aproximación de la raíz cuadrada
Nuestro primer paso será aproximar uniformemente la raíz cuadrada
por una sucesión de polinomios. La serie de Taylor de la raíz
cuadrada en $t = 1$,
\[
\sum_{n\geq 0} \lambda_n(t-1)^n =
\sum_{n\geq 0} \frac{(t - 1)^n}{n!} \prod_{k=1}^n \left( \frac{3}{2} - k \right),
\]

tiene coeficientes $\lambda_n$ tales que
\[
\abs{\frac{\lambda_{n+1}}{\lambda_n}} = 
\abs{\frac{1/2 - n}{n+1}} \to 1,
\qquad
n \left( 1 - \abs{\frac{\lambda_{n+1}}{\lambda_n}} \right) \to 3/2 > 1;
\]

por lo que sabemos por criterio de Raabe que $\sum_{n \geq 1} \lambda_n$ es absolutamente
convergente y la suma converge para $t \in [0,1]$. Podemos definir
\[
\psi(t) = \sum_{n=0}^{\infty}\lambda_n(t-1)^n, \quad\mbox{ para } t \in [0,1];
\]

a la que convergen uniformemente las parciales por tenerse
\[
\abs{\psi(t) - \sum_{n=0}^{m} \lambda_n(t-1)^n} \leq
\sum_{n=m+1}^{\infty} \abs{\lambda_n},
\quad\mbox{ para } t \in [0,1].
\]

Si ahora consideramos sus derivadas, usando convergencia uniforme para
intercambiar derivada y suma infinita, tenemos la ecuación diferencial
\[\begin{aligned}
\psi'(t) &=
\sum_{n=0}^\infty n\lambda_n(t-1)^{n-1} =
\sum_{n=1}^\infty \left(\frac{1}{2} - (n-1)\right)\lambda_{n-1}(t-1)^{n-1} \\&=
\frac{1}{2}\psi(t) - (t-1)\psi'(t),
\end{aligned}\]

con $\psi(1) = 1$, que se resuelve como $\psi(t) = \sqrt{t}$.

******** Paso 2. Estructura de retículo
Dada $p \in \overline{{\cal A}}$, veamos que $\abs{p} \in {\overline{\cal A}}$. Al ser $K$ compacto, $p$ está acotado.
Dado un $\varepsilon > 0$, como $p(t)/\norm{p}_{\infty} \leq 1$ usamos la aproximación por polinomios
de la raíz cuadrada para existir algún $n$ tal que
\[
\abs{\sqrt{\left(\frac{p(x)}{\norm{p}_{\infty}}\right)^2} -
\sum_{i=1}^n \lambda_i \left(\frac{p(x)}{\norm{p}_{\infty}}-1\right)^i} < \varepsilon;
\quad
\mbox{ para } x \in K.
\]

Y desde aquí deducimos que $\abs{p}/\norm{p}_{\infty} \in \overline{{\cal A}}$ por poder aproximarse uniformemente
por sumas de funciones en el álgebra, luego $\abs{p} \in \overline{\cal A}$.

El ser cerrada para el valor absoluto hace que la clausura
sea un retículo con el orden parcial inducido punto a punto
desde los reales. En otras palabras, dados $p,q\in \overline{{\cal A}}$,
\[
\min(p,q) = \frac{p + q}{2} - \frac{\abs{p-q}}{2},\quad\text{y}\quad
\max(p,q) = \frac{p + q}{2} + \frac{\abs{p-q}}{2},
\]

pertenecen a $\overline{\cal A}$.

******** Paso 3. Aproximación
Dada $f \in {\cal C}(K,\mathbb{R})$, un punto $y \in K$, y un $\varepsilon > 0$, probaremos que
existe una $r_y \in {\overline{\cal A}}$ tal que $r_y(y) = f(y)$ y $\forall x \neq y \in K\colon r_{y}(x) > f(x) - \varepsilon$.
Por ser ${\cal A}$ separable y no desvanecerse, tenemos para cada $z \in K$ una
función $s_z \in {\cal A}$ tal que $s_{z}(y) = f(y)$ y además, $s_{z}(z) = f(z)$.

Por continuidad de $s_z$, existe un abierto $z \in J_z$ tal que
\[
\forall x \in J_z\colon\quad s_z(x) > f(x) - \varepsilon.
\]

Como $K = \bigcup_{z \in K} J_z$ es compacto, existen $z_1,\dots,z_n$ tales que
$K = J_{z_1} \cup \dots \cup J_{z_n}$; y podemos tomar $r_y = \max(s_{z_1},\dots,s_{z_n})$.

De nuevo, por continuidad de $r_y$, existe un abierto $y \in H_y$
tal que
\[
\forall x \in H_y\colon\quad r_y(x) < f(x) + \varepsilon;
\]

de nuevo por compacidad, existen $y_1,\dots,y_n$ con $K = H_{y_1} \cup \dots \cup H_{y_m}$;
y de nuevo podemos tomar $h = \min(r_{y_1},\dots,r_{y_m}) \in \overline{{\cal A}}$; que cumple
que $f(x) - \varepsilon < h(x) < f(x) + \varepsilon$, y por tanto $\norm{f - h}_{\infty} < \varepsilon$.

***** Lema de aproximación por localmente lipschitzianas
:PROPERTIES:
:ID:       6fb8c0d7-7c28-4d3f-a6ae-c781ac55cb4e
:END:
Sea $f \colon D = \mathring{D} \to \mathbb{R}^d$ continua y $M \geq 0$ tal que

 \[\forall (t,x) \in {\cal R}_{a,b}\colon \|f(t,x)\| \leq M,\]

entonces existen $f_n_{|_{R_{a,b}}} \overset{c.u.}\longrightarrow f_{|_{R_{a,b}}}$ localmente lipschitzianas y uniformemente
acotadas por

\[\forall (t,x) \in {\cal R}_{a,b}\colon 
\| f_n_{|_{R_{a,b}}}(t,x) \| \leq M.
\]

****** Proof
Aplicamos el Teorema de [[id:a786fcd1-033d-477b-865e-a8a1f0aef252][Stone-Weierstrass]] en el compacto ${\cal R}_{a,b}$, al
álgebra de los polinomios en varias variables
\[
  {\cal A} =
  \left\{ \sum_{(i_1,\dots,i_n) \in \mathbb{N}^{d+1}}
    \left(\lambda_{i_1,\dots,i_n} \prod_{j=1}^n x_j^{i_j}\right)
    \midd
    \lambda_{i_1,\dots,i_n} \in \mathbb{R}
  \right\},
\]
que es cerrada para la suma, el producto por escalares y el producto
de funciones y que además contiene funciones que separan puntos (con las
lineales basta) y funciones que no se desvanecen en cada uno de ellos.

Podemos aproximar tanto como queramos las $d$ componentes de la
función $f$ por polinomios y, por tanto, podemos aproximar la $f$ uniformemente
por una función polinomial, así que tomamos funciones polinomiales $\set{p_n}$
tales que $\norm{p_n - f}_\infty < 1/n$.
Nótese que cumplen $\norm{p_n}_\infty \leq M + 1/n$, por lo que podemos definir la
siguiente sucesión de funciones, que son localmente lipschitzianas por
ser polinomiales y por tanto de clase ${\cal C}^1$,
\[
  f_n = \frac{M}{M+1/n}p_n;\quad\mbox{ cumpliendo }\quad
  \norm{f_n}_\infty \leq M.
\]
Y tenemos finalmente la siguiente aproximación uniforme,
\[
  \norm{\frac{M}{M + 1/n} p_n - f}_\infty \leq
  \norm{\frac{1/n}{M + 1/n}p_n}_\infty + \norm{p_n - f}_\infty \leq
  \frac{1}{n} + \frac{1}{n} \to 0.\qedhere
\]

# Convolución, polinomios de Bessel o Bernstein

# http://www.mast.queensu.ca/~speicher/Section14.pdf <- Por bernstein
# https://math.stackexchange.com/questions/437145/lipschitz-continuous-polynomials <- polinomios son lipschitz
# http://lsec.cc.ac.cn/~xuzq/lecture%201.pdf <- Por convolución

***** Proposición de soluciones de Volterra
:PROPERTIES:
:ID:       cccfae5e-60f8-4f15-ba11-c14af22e54d8
:END:
Si $\|f_{|{\cal R}_{a,b}}(t,x)\| \leq M$ y $Ma \leq b$, entonces existe una $\varphi \colon [t_0-a,t_0+a] \to \mathbb{R}^d$ que
es solución de la ecuación de Volterra asociada.

****** Proof
Tomamos $f_n$ del lema [[id:6fb8c0d7-7c28-4d3f-a6ae-c781ac55cb4e][de aproximación por localmente lipschitzianas]], que son
lipschitzianas en ${\cal R}_{a,b}$ por ser compacto. Las Volterra asociadas tienen
solución $\varphi_n$ en $E_{a,b}$ por la [[id:51ed4957-d6c4-448f-bfe0-8a8d2afe218b][proposición a Picard-Lindelöf]]. Las $\varphi_n$ están uniformemente
acotadas allí por $\|x_0\| + b$ y las derivadas están uniformemente acotadas
$\|\varphi_n(t)\| = \|f_n(t,x)\| \leq M$, [[id:5b2c7b57-f17b-441f-a635-fddbb3e0c992][por lo que es]] sucesión equicontinua.

Aplicando el [[id:859883bd-15a4-4efd-9d61-7d501b592918][corolario a Ascoli-Arzelá]], tenemos $\varphi_{\sigma(n)} \overset{c.u.}\longrightarrow \varphi$ y podemos
usar convergencia dominada de Lebesgue y que $f_{\sigma(n)}(s,\varphi_{\sigma(n)}(s)) \to f(s,\varphi(s))$
[[id:d2bb5e99-e7e9-4fa2-a8e2-38dcda39917e][por ser convergencia uniforme]] para tener
\[\begin{aligned}
\varphi(t) &=
\lim_{n \to \infty} \left(x_0 + \int_{t_0}^t f_n(s,\varphi_n(s))\,ds\right) \\&=
x_0 + \int_{t_0}^t \lim_{n \to \infty} f_n(s,\varphi_n(s))\,ds =
x_0 + \int_{t_0}^t f(s,\varphi(s))\,ds,
\end{aligned}\]
solución continua por ser límite uniforme de continuas.

***** Teorema de Cauchy-Peano
:PROPERTIES:
:ID:       076910d4-3fd8-4447-9712-20c4e6cd2251
:END:
Todo PVI con campo continuo sobre abierto tiene solución.

Para $D = \mathring{D} \subset \mathbb{R} \times \mathbb{R}^d$ y $f \colon D \to \mathbb{R}^{d}$ continua con $(t_0,x_0) \in D$,
el PVI siguiente tiene solución

\[\left\{\begin{array}{c}
x' = f(t,x) \\
x(t_0) = x_0
\end{array}\right.\]

****** Demostración
Con $D$ abierto, existe ${\cal R}_{\overline{a},b} \subseteq D$. Por Weierstrass,

\[
\exists M\colon \forall (t,x) \in {\cal R}_{\overline{a},b}\colon \norm{f(t,x)} \leq M.
\]

Tomamos $a = \min \{b/M,\overline{a}\}$ y por la [[id:cccfae5e-60f8-4f15-ba11-c14af22e54d8][proposición anterior]] tenemos
solución de Volterra en intervalo $[t_0-a,t_0+a]$, solución al PVI
en $(t_0-a,t_0+a)$.

****** Card                                                                                                :drill:
SCHEDULED: <2018-08-02 Thu>
:PROPERTIES:
:ID:       dd272b8d-7028-46f1-93f3-f77b1f4ceb5e
:DRILL_LAST_INTERVAL: 51.4563
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.42
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-12 Tue 14:57]
:END:
Enuncia el Teorema de Cauchy-Peano.

******* Enunciado
Para $f \colon D = \mathring{D} \subset \mathbb{R} \times \mathbb{R}^d \to \mathbb{R}^{d}$ continua con $(t_0,x_0) \in D$,
el PVI siguiente tiene solución

\[\left\{\begin{array}{c}
x' = f(t,x) \\
x(t_0) = x_0
\end{array}\right.\]

*** Tema 4. Prolongación y acotación de soluciones
**** 4.1. Comportamiento de soluciones maximales
***** Contexto
Consideramos para este tema
 
 * $D \subset \mathbb{R} \times \mathbb{R}^d$, abierto,
 * $f \colon D \to \mathbb{R}^{d}$, continua,
 * $\varphi \colon (\alpha,\omega)\to\mathbb{R}^d$ solución maximal de $x' = f(t,x)$.
  
Estudiaremos resultados para $\omega$ que se traducirán directamente para $\alpha$.

***** Lema 1. El límite no infinito toca el borde
:PROPERTIES:
:ID:       304d100c-6e59-4ed7-b623-4714c361a3dc
:END:
Si $\omega < \infty$ y $\exists \lim_{t \to \omega} \varphi(t) = \xi \in \mathbb{R}^d$, entonces $(\omega,\xi) \in \partial D$.

****** Proof
Sabemos $\varphi$ [[id:ba5ec2ba-b54a-455b-9b6c-9fca85940234][solución]], luego $\forall t \in (\alpha,\omega): (t,\varphi(t)) \in D$, y tomando límite
obtendríamos $(\omega,\xi)\in \overline{D}$. Si se tuviera $(\omega,\xi)\in D$, entonces tomaríamos
el PVI con $x(\omega) = \xi$, y por [[id:076910d4-3fd8-4447-9712-20c4e6cd2251][Cauchy-Peano]] tendría una solución en entorno

\[
\psi \colon (\omega-a,\omega+a) \to \mathbb{R}^d.
\]

Pero entonces podríamos crear una solución mayor $\widetilde \varphi$ [[id:078ac783-76bf-4445-ad46-3f91ea9d1ef6][concatenando]] ambas,
lo que contraviene maximalidad.

****** Card                                                                                                :drill:
SCHEDULED: <2018-06-25 Mon>
:PROPERTIES:
:ID:       2de33c5f-62ce-4194-92a8-c6cd3f13b629
:DRILL_LAST_INTERVAL: 14.1176
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 5.0
:DRILL_EASE: 2.7
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-11 Mon 21:41]
:END:
Si $\omega < \infty$ y $\exists \lim_{t \to \omega} \varphi(t) = \xi \in \mathbb{R}^d$, entonces [ $(\omega,\xi) \in \partial D$ ].

***** Lema 2. El límite de una sucesión toca el borde
:PROPERTIES:
:ID:       36ad0e3b-9430-43b5-9dcd-45f042f63000
:END:
Si $\omega < \infty$ y tenemos $t_n \in (\alpha,\omega)$ con $t_n \to \omega$ y $\varphi(t_n)\to \xi \in \mathbb{R}^d$, entonces
$(\omega,\xi)\in \partial D$.

****** Proof
Sabemos $\varphi$ [[id:ba5ec2ba-b54a-455b-9b6c-9fca85940234][solución]], luego $\forall t \in (\alpha,\omega)\colon (t,\varphi(t)) \in D$, y tomando límite
obtendríamos $(\omega,\xi) \in \overline{D}$. Si se tuviera $(\omega,\xi) \in D$ abierto, entonces fijamos
$\varepsilon > 0$ y existe $R_{\overline{a},b}(\omega,\xi)\subseteq D$ con $b < \varepsilon$ por ser [[id:44351076-d98f-4552-a229-a41405beb6b1][base de entornos]].
Tomamos además un máximo por Teorema de Weierstrass

\[
M = \max_{(t,x) \in R_{\overline{a},b}(\omega,\xi)} \| f(t,x) \|,
\]

y tomamos $a < \overline{a}$ tal que $aM \leq b/2$.

Usando convergencia, podemos encontrar $N \in \mathbb{N}$ tal que

\[
\forall n > N\colon\quad t_n \in (\omega-a,\omega), \quad\mbox{ y }\quad 
\|\varphi(t_n) - \xi \| \leq b/2.
\]

Si no fuera verdad que $\forall t \in [t_N,\omega]\colon \varphi(t) \in B(\xi,b)$, por el
[[id:a439476b-8c77-4994-a736-9062ee91e7d0][Lema del primer instante]] se llegaría a

\[
\exists \tau \in (t_N,\omega)\colon \|\varphi(t) - \xi\| < b,\qquad \|\varphi(\tau)-\xi\| = b,
\]

pero entonces, 

\[\begin{aligned}
b &\leq 
\|\varphi(\tau)-\varphi(t_n)\| + \| \varphi(t_n) - \xi \| \\&<
\left\| \int_{t_N}^{\tau} \varphi'(s)\,ds \right\| + \frac{b}{2} \\&=
\left\| \int_{t_n}^{\tau}f(s,\varphi(s))\,ds \right\| + \frac{b}{2} \\&\leq
M(\tau - t_n) + \frac{b}{2} \\&<
Ma + b/2 \leq b.
\end{aligned}\]

Llegando a contradicción. Así, tenemos el límite $\lim_{t \to \omega} \varphi(t) = \xi \in \mathbb{R}^d$,
y podemos aplicar el [[id:304d100c-6e59-4ed7-b623-4714c361a3dc][Lema anterior]] para tener $(\omega,\xi) \notin D$.

****** Card                                                                                                :drill:
SCHEDULED: <2018-06-20 Wed>
:PROPERTIES:
:DRILL_CARD_TYPE: hide1cloze
:ID:       38226179-5572-4011-9c27-1bc2e7f2bb63
:DRILL_LAST_INTERVAL: 8.7389
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-11 Mon 21:46]
:END:
Si $\omega < \infty$ y tenemos $t_n \in (\alpha,\omega)$ con $t_n \to \omega$ y $\varphi(t_n)\to \xi \in \mathbb{R}^d$,
entonces [ $(\omega,\xi)\in \partial D$ ].

***** Alternativas de comportamiento en el extremo superior
:PROPERTIES:
:ID:       435b13ac-d20b-469c-bb0a-4915735b6c62
:END:
Si $\omega < +\infty$ se verifica una de las siguientes alternativas.

 * $\lim_{t \to \omega}\| \varphi(t)\| = \infty$, explota en tiempo finito;

 * $\exists (t_n,\varphi(t_n)) \to (\omega,\xi) \in \partial D$, tiende a tocar la frontera.

****** Proof
Supongamos que no se tiene la primera opción: debe existir un $R_0$
y una sucesión de $\tau_{n}$ tal que $\abs{\tau_n - \omega} < 1/n$ pero sin embargo
$\norm{\varphi(\tau_n)} \leq R_0$, rompiendo la convergencia.

Como $\varphi(\tau_n)$ es acotada, por Bolzano-Weierstrass, $\varphi(\tau_{\sigma(n)}) \to \xi \in \mathbb{R}^d$.
Pero ahora, $t_n = \tau_{\sigma(n)}$ cumple que $t_n \to \omega$ mientras que $\varphi(t_n) \to \xi$.
Estamos en las condiciones del [[id:36ad0e3b-9430-43b5-9dcd-45f042f63000][lema anterior]].

****** Card: ¿Cuáles son las tres alternativas?                                                            :drill:
SCHEDULED: <2018-08-07 Tue>
:PROPERTIES:
:ID:       44d857b1-d184-4611-a6b5-6df45fac65b0
:DRILL_LAST_INTERVAL: 79.9369
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.5
:DRILL_EASE: 2.7
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-05-19 Sat 11:00]
:END:
¿Cuáles son las tres alternativas de comportamiento
para el $\omega$ de una solución maximal?

******* Alternativas

 * $\omega = +\infty$, continúa indefinidamente;

 * $\lim_{t \to \omega}\| \varphi(t)\| = \infty$, explota en tiempo finito;

 * $\exists (t_n,\varphi(t_n)) \to (\omega,\xi) \in \partial D$, tiende a tocar la frontera.

***** Corolario 1
Si $\omega < \infty$ y el dominio no tiene borde, $D = \mathbb{R} \times \mathbb{R}^{d}$,
entonces $\lim_{t \to \infty} \|\varphi(t)\| = \infty$.

****** Proof
Al ser $\partial D = \varnothing$, el [[id:435b13ac-d20b-469c-bb0a-4915735b6c62][teorema anterior]] sólo da la primera alternativa.

****** Card                                                                                                :drill:
SCHEDULED: <2018-06-26 Tue>
:PROPERTIES:
:ID:       c5c0c521-3a1f-408e-a1c8-466aa6097c61
:DRILL_LAST_INTERVAL: 14.1292
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-12 Tue 14:43]
:END:
Si $\omega < \infty$ y el dominio no tiene borde, $D = \mathbb{R} \times \mathbb{R}^{d}$,
entonces [ $\lim_{t \to \infty} \|\varphi(t)\| = \infty$ ].

***** Corolario 2
Si $\omega < b < \infty$ y $D = (a,b) \times \mathbb{R}^d$, entonces $(\omega,\xi) \notin \partial D$ y $\lim_{t \to \omega} \|\varphi(t)\| = \infty$.

****** Proof
No se extiende indefinidamente y no puede tocar la frontera porque
$\omega < b$, debe explotar en tiempo finito.

***** Corolario 3
Si $\omega < \infty$ y $D = \mathbb{R} \times B$ para $B$ acotado, entonces
$\exists (t_n,\varphi(t_n)) \to (\omega,\xi) \in \partial D = \mathbb{R} \times \partial B$.

****** Proof
No se extiende indefinidamente y, como $B$ está acotado, no puede
explotar en tiempo finito.

**** 4.2. Crecimimento a lo sumo lineal
***** Lema de Gronwall (versión débil)
:PROPERTIES:
:ID:       23749801-6cfb-4efe-a808-aef93e33bc9a
:END:
Sea $y \in {\cal C}([t_0,\omega))$ con $C \in \mathbb{R}$ y $R \in \mathbb{R}^+$ tales que

\[
y(t) \leq
C + R \int_{t_0}^t y(s)\,ds.
\]

para todo $t \in [t_0,\omega[$. Entonces $y(t) \leq C e^{R(t-t_0)}$ para todo $t \in [t_0,\omega[$.

****** Proof
Caso $R = 0$ trivial. Si $R > 0$, tenemos por Teorema fundamental del
cálculo que $Y'(t) \leq C + RY(t)$ para $Y(t) = \int_{t_0}^t y(s)\,ds$. Calculamos

\[
\dv{}{t} \left( e^{-R(t-t_0)}Y(t) \right) = 
-Re^{-R(t-t_0)}Y(t) + e^{-R(t-t_0)}Y'(t) \leq
Ce^{-R(t-t_0)},
\]

e integramos a ambos lados usando $Y(t_0) = 0$ y $R > 0$,

\[
e^{-R(t-t_0)}Y(t) \leq \int_{t_0}^t Ce^{-R(t-t_0)}\,ds = \frac{C}{-R}(e^{-R(t-t_0)} - 1)
\]

\[
Y(t) \leq \frac{C}{R}(e^{R(t-t_0)} - 1)
\]

Y aplicamos en la desigualdad original,

\[
y(t) \leq C + R\frac{C}{R} \left( e^{R(t-t_0)} -1 \right) = Ce^{R(t-t_0)}.
\]

****** Card: Enunciar el Lema de Gronwall                                                                  :drill:
SCHEDULED: <2018-08-30 Thu>
:PROPERTIES:
:ID:       c6e5ae82-baf7-4eea-a47e-5d9f5dbb1ec3
:DRILL_LAST_INTERVAL: 78.5209
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 5
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.6
:DRILL_EASE: 2.46
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-12 Tue 14:43]
:END:
Enunciar el Lema de Gronwall, que acota una función cuando podemos
acotarla por su integral.

******* Enunciado
Sea $y \in {\cal C}([t_0,\omega),\mathbb{R})$ con $C \in \mathbb{R}$ y $R \in \mathbb{R}^+$ tales que

\[
\forall t \in [t_0,\omega)\colon
y(t) \leq
C + R \int_{t_0}^t y(s)\,ds.
\]

Entonces

\[
\forall t \in [t_0,\omega)\colon y(t) \leq C e^{R(t-t_0)}.
\]
 
***** Lema de Gronwall (fuerte)                                                                             :extra:
***** Crecimiento a lo sumo lineal
$f \colon (a,+\infty) \times \mathbb{R}^d = D \to \mathbb{R}^{d}$ tiene *crecimiento a lo sumo lineal*
si existen $m,n \in (a,+\infty) \to \mathbb{R}^+_0$ continuas tales que

\[
\forall (t,x) \in D \colon \norm{f(t,x)} \leq m(t)\norm{x} + n(t).
\]

****** Ejemplos

 * Las $f(t,x)$ globalmente lipschitzianas respecto $x$ son CSL.
 * Las $f(t,x)$ acotadas son CSL.
 * Las $f(t,x)$ lineales respecto de $x$ son CSL.

******* Lineales
******* Autónomas
****** Card                                                                                                :drill:
SCHEDULED: <2018-06-21 Thu>
:PROPERTIES:
:ID:       d38e7263-005a-4230-97d1-d1ac4568b375
:DRILL_LAST_INTERVAL: 9.8053
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.5
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-11 Mon 21:47]
:END:
¿Cuándo tiene $f\colon (a,+\infty)\times\mathbb{R}^d\to\mathbb{R}^{d}$ crecimiento a lo sumo
lineal?

******* Definición
Existen $m,n \in (a,+\infty) \to \mathbb{R}^+_0$ *continuas* tales que

\[
\forall (t,x) \in D \colon \norm{f(t,x)} \leq m(t)\norm{x} + n(t).
\]

***** Teorema de crecimiento a lo sumo lineal
Si $f \colon (a, +\infty)\times\mathbb{R}^d \to \mathbb{R}^d$ tiene crecimiento a lo sumo lineal,
entonces $\omega = +\infty$.

****** Card                                                                                                :drill:
SCHEDULED: <2018-06-23 Sat>
:PROPERTIES:
:ID:       76564c59-0fa4-421c-a3e7-efd830498553
:DRILL_LAST_INTERVAL: 10.9182
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.5
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-12 Tue 14:45]
:END:
¿Qué dice el teorema de crecimiento a lo sumo lineal?

******* Answer
Que si un campo sin fronteras en el futuro $f \colon (a,+\infty) \times \mathbb{R}^d \to \mathbb{R}^d$
tiene crecimiento a lo sumo lineal, entonces $\omega = +\infty$.

****** Proof
Si $\omega < +\infty$, por [[id:435b13ac-d20b-469c-bb0a-4915735b6c62][alternativa de comportamiento]] y sabiendo que no
puede tocar la frontera, debe explotar en tiempo finito.
$\lim_{t \to \omega} \|\varphi(t)\| = +\infty$. Aplicamos Weierstrass para tener $M = \max_{t_0 \leq t \leq \omega} m(t)$
y $N = \max_{t_0 \leq t \leq \omega} n(t)$. Ahora

\[\begin{aligned}
y(t) &= \norm{\varphi(t)} =
\norm{x_0 + \int_{t_0}^tf(s,\varphi(s))\,ds} \\&\leq
\norm{x_0} + \int_{t_0}^t\norm{f(s,\varphi(s))}\,ds \\&\leq
\norm{x_0}  + N(\omega-t_0) + M\int_{t_0}^ty(s)\,ds.
\end{aligned}\]

Y por [[id:23749801-6cfb-4efe-a808-aef93e33bc9a][Lema de Gronwall]], acotamos por una constante

\[
y(t) \leq \left( \|x_0\| + N(\omega-t_0) \right) e^{M(t-t_0)} \leq (\|x_0\| + N(\omega-t_0)) e^{M(\omega-t_0)}.
\]

Llegando a contradicción con la hipótesis de que explota en tiempo
finito.

***** Teorema de crecimiento a lo sumo lineal (hipótesis debilitada)
Si $f \colon D \to \mathbb{R}^d$ tiene crecimiento a lo sumo lineal en un $\Omega$
cerrado $[t_0,+\infty) \times \Omega \subset D$ con $\varphi(t) \in \Omega$ para cualquier $t \in [t_0,\omega)$,
entonces $\omega = +\infty$.

****** TODO Proof
**** 4.3. Acotación de soluciones. Funciones guía
***** Acotada en el futuro y acotada en el pasado
Decimos $\varphi$ *acotada en el futuro* si $\omega =+\infty$ y $\exists M\colon\forall t \geq t_0\colon \|\varphi(t)\| \leq M$.
Decimos $\varphi$ *acotada en el pasado* si $\omega = +\infty$ $\exists M\colon\forall t \leq t_0\colon \|\varphi(t)\| \leq M$.
Decimos $\varphi$ *acotada* si lo está en el futuro y en el pasado.

***** Funciones coercivas
:PROPERTIES:
:ID:       37022c48-c27d-4e11-aa9d-85c998a4b917
:END:
Decimos $V \in {\cal C}(\mathbb{R}^d, \mathbb{R})$ *coerciva* si todo conjunto de subnivel $\Omega_r$
es compacto.

****** Conjuntos de nivel y conjuntos de subnivel
El *conjunto de nivel* $r$ es $S_r = V^{-1}(r)$.
El *conjunto de subnivel* $r$ es $\Omega_r = V^{-1}([-\infty,r])$.

****** Caracterización por límite
Ser coerciva equivale a tenerse $\lim_{\|x\| \to +\infty}V(x) = +\infty$.

******* Proof
Sea $V$ coerciva, dado $K$, $V^{-1}(]-\infty,K])$ es compacto, luego
acotado y para $\|x\|$ suficientemente grande, será $V(x) > K$.

Si tenemos el límite, $V^{-1}(]-\infty,K])$ es cerrado por continuidad
y está acotado porque si no lo estuviera podríamos tomar una
sucesión que divergiera pero con sus imágenes acotadas por $K$.

****** Mínimo global
Nótese que una coerciva tiene mínimo global por Weierstrass sobre
un compacto para alguna cota.

****** Card: función coerciva                                                                              :drill:
SCHEDULED: <2018-06-17 Sun>
:PROPERTIES:
:ID:       6e44a52f-a72d-4288-85b7-3c7daa3ca1d4
:DRILL_LAST_INTERVAL: 35.3401
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 6
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.167
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-05-13 Sun 22:08]
:END:
Definición de función coerciva.

******* Definición
Todo conjunto de subnivel $\Omega_r$ es compacto.

****** Card: caracterización                                                                               :drill:
SCHEDULED: <2018-07-26 Thu>
:PROPERTIES:
:ID:       37d1fd0f-a7af-4a52-8be0-626e6968b6c2
:DRILL_LAST_INTERVAL: 43.8661
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.667
:DRILL_EASE: 2.7
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-12 Tue 18:16]
:END:
Caracteriza por límites una función coerciva

******* Caracterización
Ser coerciva equivale a

\[\lim_{\|x\| \to +\infty}V(x) = +\infty\]
***** Derivada a lo largo de un campo
La *derivada* de $V \in {\cal C}^1(\mathbb{R}^d,\mathbb{R})$ a lo largo de $f$ se define

\[
\bV(t,x) = \left\langle \nabla V(x),f(t,x) \right\rangle.
\]

Nótese en particular $\dv{}{t} \left[ V(\varphi(t)) \right]_{|_t} = \overset{\bullet}{V}(t,\varphi(t))$.

****** Card                                                                                                :drill:
SCHEDULED: <2018-08-19 Sun>
:PROPERTIES:
:ID:       170edc4f-ef66-4b1e-a3ef-3b1312feaeb5
:DRILL_LAST_INTERVAL: 66.5458
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.25
:DRILL_EASE: 2.08
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-13 Wed 11:29]
:END:
¿Cómo se define la derivada a lo largo de un campo $f$?

$\bV(t,x) = \dots$

******* Definición
Para $V \in {\cal C}^1(\mathbb{R}^d,\mathbb{R})$ se define

\[
\bV(t,x) = \left\langle \nabla V(x),f(t,x) \right\rangle.
\]
***** Proposición de acotación por coercivas
:PROPERTIES:
:ID:       82dab245-c6b0-4bd6-8746-98af9e2892c6
:END:
Sea $V \in {\cal C}^1(\mathbb{R}^d, \mathbb{R})$ coerciva. Si $S_r$ es un conjunto de nivel para
algún $r$, cumpliendo que $\bV(t,x) < 0$ para todo $(t,x) \in S_r$ y además,
$x_0 \in \Omega_r$, entonces $\forall t \geq t_0\colon \varphi(t) \in \Omega_r$, y está acotada en el futuro.

****** Proof
Partimos en casos según $V(x_0) < r$ ó $V(x_0) = r$.

******* Caso 1
Sea $V(x_0) < r$. Definimos $y = V \circ \varphi \in {\cal C}^1$ y tenemos $y'(t) = \bV(t,\varphi(t))$.
Si no se tuviera $y(t) < r$, por [[id:a439476b-8c77-4994-a736-9062ee91e7d0][Lema del primer instante]] se tendría
$y(\tau) = r$ y $\forall t \in [t_0,\tau[\colon y(t) < r$ para algún $\tau > t_0$. Ahí tendríamos
$y'(\tau) \geq 0$ pero $\bV(\varphi(\tau)) < 0$, llegando a contradicción.

Sabemos así que $\varphi([t_0,\omega[) \subset \Omega_r$, que es compacto por ser $V$ [[id:37022c48-c27d-4e11-aa9d-85c998a4b917][coerciva]],
luego está acotada.

******* Caso 2
Sea $V(x_0) = r$, tendríamos $y(t_0) = r$ y $y'(t_0) < 0$. Por definición de
derivada, para algún $\varepsilon$ tendremos $\forall t \in (t_0,t_0+\varepsilon)\colon y(t) < r$. Aplicamos
el primer caso en algún punto de ese intervalo.

***** Teorema. Acotación mediante funciones guía
:PROPERTIES:
:ID:       b1ed10c4-862c-4722-b481-6f83bf18c479
:END:
Si existe $V \in {\cal C}^1(\mathbb{R}^d)$ coerciva tal que $\bV(t,x)\leq 0$ para
cualesquiera $(t,x) \in D$ con $t \geq t_0$; entonces las soluciones
maximales de $x' = f(t,x)$, $x(t_0)=x_0$ están acotadas en el futuro.

Análogamente, si $\bV(t,x) \geq 0$ cuando $t \leq t_0$, estarán acotadas en
el pasado, y si $\bV(t,x) = 0$ siempre, estarán acotadas.

****** Proof
Definimos $y = V \circ \varphi \in {\cal C}^1$, decreciente por $y'(t) = \bV(t,\varphi(t)) \leq 0$.
Luego, por la [[id:82dab245-c6b0-4bd6-8746-98af9e2892c6][proposición anterior]], $\varphi([t_0,\omega[) \subset \Omega_{V(x_0)}$, compacto y
por tanto acotado, por ser $V$ [[id:37022c48-c27d-4e11-aa9d-85c998a4b917][coerciva]].

****** TODO Proof (independiente)
****** Card: enunciado                                                                                     :drill:
SCHEDULED: <2018-07-11 Wed>
:PROPERTIES:
:ID:       fbcbd5af-72f0-45e7-aeea-916ae98bc48f
:DRILL_LAST_INTERVAL: 11.6797
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-29 Fri 09:54]
:END:
Enunciado del teorema de acotación mediante funciones guía.

******* Enunciado
Si existe $V \in {\cal C}^1(\mathbb{R}^d)$ coerciva tal que $\bV(t,x)\leq 0$ para
cualesquiera $(t,x) \in D$ con $t \geq t_0$; entonces las soluciones
maximales de $x' = f(t,x)$, $x(t_0)=x_0$ están acotadas en el futuro.

Análogamente, si $\bV(t,x) \geq 0$ cuando $t \leq t_0$, estarán acotadas en
el pasado, y si $\bV(t,x) = 0$ siempre, estarán acotadas.

***** Acotación mediante funciones guía: corolario
Si existe $V \in {\cal C}^1(\mathbb{R}^d,\mathbb{R})$ coerciva tal que $\forall (t,x) \in D\colon \bV(t,x) = 0$,
las soluciones maximales están acotadas, teniéndose $\varphi(t) \in \Omega_{V(x_0)}$.

****** Proof
Aplicando los dos casos del [[id:b1ed10c4-862c-4722-b481-6f83bf18c479][teorema]] anterior.
***** Acotación mediante funciones guía: debilitación
Podemos aplicar dos debilitaciones a las hipótesis del teorema
de [[id:b1ed10c4-862c-4722-b481-6f83bf18c479][acotación mediante funciones guía]],

 * sólo necesitamos $\bV(t,x)\leq 0$ en $(t_0,+\infty) \times \left(\mathbb{R}^d \setminus B(p,r)\right)$ para
   algunos $p \in \mathbb{R}^d$ y $r > 0$;
 * podemos prescinidir de $V$ coerciva y pedir sólo que las
   componentes conexas de los $\Omega_r$ sean acotadas.

****** TODO Proof
***** Elección de funciones guía
Para $V,W\colon \mathbb{R}^d \to \mathbb{R}$ y $V_1,\dots,V_d \colon \mathbb{R} \to \mathbb{R}$ continuas se tiene

 * $V(x_1,\dots,x_d) = V_1(x_1) + \dots + V_d(x_d)$ coerciva ssi lo son las $V_i$;

 * $V(x) \geq W(x)$ coerciva si lo es $W$;

 * $V$ cuadrática es coerciva ssi $\mathrm{Hess}(V)$ es definida o semidefinida positiva;

 * $V$ coerciva si $V \in {\cal C}^1(\mathbb{R}^d)$ es convexa con único punto crítico.

Suelen funcionar el cuadrado de la norma euclídea, variables separadas
y, en el peor de los casos, una forma cuadrática definida positiva.

****** Card: cuadráticas coercivas                                                                         :drill:
SCHEDULED: <2018-06-19 Tue>
:PROPERTIES:
:ID:       c495ad82-f560-46dd-b9ab-677edf45aeee
:DRILL_LAST_INTERVAL: 7.1098
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.46
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-12 Tue 14:38]
:END:
En el caso particular de una forma cuadrática. ¿Cuando es una forma
cuadrática coerciva?

******* Answer
Ssi la parte cuadrática (coincide con la hessiana) es definida
positiva.

****** Card: última condición                                                                              :drill:
SCHEDULED: <2018-06-23 Sat>
:PROPERTIES:
:DRILL_CARD_TYPE: hide1cloze
:ID:       4134c0bb-2847-4c1c-b3ce-55807475a84b
:DRILL_LAST_INTERVAL: 11.1451
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.46
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-12 Tue 14:38]
:END:
Si $V \in {\cal C}^1(\mathbb{R}^d)$ es [convexa] con [un único punto crítico]; entonces [ $V$ es coerciva ]

*** Seminario 1. Ecuaciones autónomas ([[~/pdf/alonso_seminario_i_de_ecuaciones_diferenciales.pdf][PDF]])
**** Solución general
Trabajamos en una ecuación autónoma real con un campo localmente
lipschitziano definido en $(a,b)$. Llamamos $X(t;t_0,x_0)$ a la
*solución general*, la única solución maximal del PVI en esas
condiciones iniciales.

***** Proof
Sabemos que la solución maximal es única por [[id:bf38540e-3857-427e-9b27-e6c0bf0cfd73][Picard-Lindelöf]].
**** Puntos de equilibrio
Los ceros del campo, $Z_f = \left\{ p \in (a,b) \mid f(p) = 0 \right\}$, dan soluciones
únicas triviales llamadas *puntos de equilibrio*.

**** Propiedad 1. Soluciones no constantes son estrictamente monótonas
En una autónoma escalar, las soluciones no constantes son estrictamente
monótonas.

***** Proof
Si $\varphi(t) = X(t;t_0,x_0)$ no fuera monótona, se tendría algún
$\varphi'(\tau)=0$, y en ese punto se tendría $\varphi(\tau) \in Z_f$ y se rompería
la unicidad en el punto de equilibrio.

***** Card                                                                                                  :drill:
SCHEDULED: <2018-06-24 Sun>
:PROPERTIES:
:ID:       c289aec0-a546-4295-a571-556977c38e06
:DRILL_LAST_INTERVAL: 11.6107
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-12 Tue 14:44]
:END:
En una ecuación autónoma escalar, ¿por qué las soluciones no
constantes son estrictamente monótonas?

****** Answer
Si no lo fuera, en algún punto se tendría derivada nula.
Ese punto sería un punto de equilibrio y se rompería la
unicidad con la solución constante en ese mismo punto.

**** Propiedad 2,3. Si hay límite, es punto de equilibrio y está en infinito
En una autónoma escalar, la solución maximal cumple que
si $\lim_{t \to \omega} \varphi(t) = L \in (a,b)$, entonces $L \in Z_f$ y además $\omega = +\infty$.

En una autónoma escalar, la solución maximal cumple que
si $\lim_{t \to \alpha} \varphi(t) = L \in (a,b)$, entonces $L \in Z_f$ y además $\alpha = -\infty$.

De otra forma, si $\lim_{t \to \omega(t_0,x_0)} X(t;t_0,x_0) = L \in (a,b)$, entonces
$L \in Z_f$ y además $\omega(t_0,x_0) = +\infty$.

***** Proof
Aplicamos [[id:435b13ac-d20b-469c-bb0a-4915735b6c62][alternativas de comportamiento]] y descartamos que pueda
explotar en tiempo finito (tiene límite finito) y que pueda tocar
la frontera, que supondría $L \in \partial (a,b) = \left\{ a,b \right\}$. Así, $\omega = +\infty$.

Siendo $\varphi(t) = X(t;t_0,x_0)$, por Barbalat tenemos una sucesión
$f(L) \gets f(\varphi(t_n)) = \varphi'(t_n) \to 0$.

***** Card                                                                                                  :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       707d89c3-fd94-45a3-8898-959fd2fbccd2
:DRILL_LAST_INTERVAL: 8.1577
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.25
:DRILL_EASE: 2.32
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-14 Thu 11:49]
:END:
Para una solución maximal de ecuación autónoma escalar,
si $\lim_{t \to \omega} \varphi(t) = L \in (a,b)$, entonces $L \in Z_f$ y además $\omega = +\infty$.
¿Por qué?

****** Proof
La única alternativa de comportamiento positble es es
$\omega = +\infty$. Por Barbalat, $f(L) \gets f(\varphi(t_n)) = \varphi'(t_n) \to 0$.

**** Propiedad 4,5. Los ceros son barreras superiores
En una autónoma escalar, si $x_0 < p \in Z_f$, entonces la solución
maximal empezando en $x_0$ queda acotada, $\varphi(t) < p$.

En una autónoma escalar, si $x_0 > p \in Z_f$, entonces la solución
maximal empezando en $x_0$ queda acotada, $\varphi(t) > p$.


***** Proof
Si no se tuviera, por Bolzano tendríamos algún punto donde
$\varphi(\tau) = p$, y ahí se rompería la unicidad.

**** Propiedad 6,7. Sigmoides
Sea $f(p) = f(q) = 0$ con $p < q$ y con $f(x) > 0$ en $(p,q)$.
Se tiene para la solución empezando en $x_0 \in (p,q)$ que

 * queda atrapada en $(p,q)$,
 * es estrictamente creciente,
 * se extiende a $+\infty$ con límite $q$,
 * se exitende a $-\infty$ con límite $p$.

Si en esta misma situación se tiene $f(x) < 0$, la solución

 * queda atrapada en $(p,q)$,
 * es estrictamente decreciente,
 * se extiende a $+\infty$ con límite $p$,
 * se exitende a $-\infty$ con límite $q$.
 
**** Propiedad 8,9. Comportamiento en los bordes
**** Órbitas
La órbita de una ecuación escalar autónoma en el punto $x_0$ es la
imagen de la única solución maximal de un PVI desde $x_0$.

**** Propiedad 10. Órbitas posibles
Se tiene ${\cal O}(x_0) \subset (a,b)$. Si $f(x_0) = 0$ entonces ${\cal O}(x_0) = \left\{ x_0 \right\}$
y si $f(x_0) \neq 0$, entonces ${\cal O}(x_0)$ es un intervalo abierto.

**** Propiedad 11. Órbitas coincidentes
Cuando $f(x) \neq 0$ en $[x_0,x_1]$, tenemos órbitas coincidentes
${\cal O}(x_0) = {\cal O}(x_1)$ y existe algún desfase $X(t;t_1,x_1) = X(t + \tau,t_0,x_0)$.

***** Proof
La coincidencia de órbitas es porque no hay cero entre ellas
y el desfase se obtiene de la unicidad de solución.

**** Diagrama de fases
Algoritmo:

 1. Calcular puntos de equilibrio.
 2. Usar signo del campo para las direcciones del diagrama.
 3. Estudiar la infinitud de definición en algunos casos.

**** Propiedad 12. ¿Tocan la frontera?
Si $\lim_{x \to c} f(x) = L \neq 0$ para $c$ real en la frontera y $L \in \mathbb{R} \cup \left\{ \infty,-\infty \right\}$;
entonces 

 * si $\lim_{t \to \omega} \varphi(t) = c$, se tiene $\omega < +\infty$.
 * si $\lim_{t \to \alpha}\varphi(t) = c$, se tiene $\alpha > -\infty$.

***** Proof
Si $\omega = +\infty$ y $\lim_{t \to \infty} \varphi(t) = c$, por Barbalat tendríamos
$0 \gets \varphi'(t_n) = f(\varphi(t_n)) \to L$.

**** Propiedad 13. ¿Explotan en tiemepo finito? Orden de infinitud
Si $b = +\infty$, con $\lim_{t \to \omega} X(t;t_0,x_0) = +\infty$ y teniéndose

\[
\lim_{x \to {}+\infty} \frac{f(x)}{x^p} = L \in [0,+\infty]
\]

para $p \geq 1$.

 * Si $p = 1$ y $L \in \mathbb{R}$, entonces $\omega = +\infty$.
 * Si $p > 1$ y $L > 0$, entonces $\omega < +\infty$.
 
***** TODO Proof
**** Propiedad 14. Región de atracción
Para un punto de equilibrio $p \in Z_f$, la región de atracción es

\[
{\cal R}(p) = \left\{ x_0 \in (a,b) \mid \lim_{t \to \omega} X(t;t_0,x_0) = p \right\}.
\]

Sabemos que

 * $p \in {\cal R}(p)$,

 * $x_0 \in {\cal R}(p)$ implica $\omega(0,x_0) =+\infty$,

 * ${\cal R}(p)$ intervalo. 

**** Propiedad 15. Atractores
Un punto es *atractor* si está en el interior de su región de
atracción. Es *atractor global* si su región de atracción es
todo $(a,b)$.

Si $f$ es derivable en $p \in Z_f$.

 1. $f'(p)<0$ nos da $p$ atractor.
 2. $f'(p) > 0$ nos da $p$ no atractor.

*** Seminario 2. Ecuaciones diferenciales de segundo orden ([[~/pdf/alonso_seminario_ii_de_ecuaciones_diferenciales.pdf][PDF]])
**** 1. Ecuaciones sin rozamiento
***** Definición
Llamamos *ecuación sin rozamiento* a una de la forma

$mx'' + g(x) = 0$

donde $m > 0$, $g$ continua.  Equivale a 

\[\left\{\begin{array}{l}
x'_1 = x_2 \\
x'_2 = -\frac{1}{m}g(x_1)
\end{aligned}\right.\]

Cuando $g$ es lipschitziana, existe solución única por
Picard-Lindelöf.

****** Card                                                                                              :nodrill:
SCHEDULED: <2018-07-09 Mon>
:PROPERTIES:
:ID:       9fb6c5d6-730d-4297-a0fe-212c2b8f2b76
:DRILL_LAST_INTERVAL: 10.0479
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.75
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-29 Fri 17:52]
:END:
Forma de una ecuación sin rozamiento.

******* Answer

$mx'' + g(x) = 0$

donde $m > 0$, $g$ continua.

***** Acotación de soluciones, método de la energía
Llamamos *energía* a

\[
V(x_1,x_2) = V_1(x_1) + V_2(x_2) = G(x_1) + \frac{1}{2}mx^2_2
\]

Se tiene $\bV(x_1,x_2) = 0$.  Cuando $G$, primitiva de $g$ es coerciva,
todas las soluciones están acotadas en el futuro y en el pasado.

Esto es un principio de *conservación de la energía*.

**** 2. Ecuaciones con rozamiento
***** Definición
Llamamos *ecuación con rozamiento* a una de la forma

\[
mx'' + cx' + g(x) = 0
\]

donde $m,c > 0$, $g \in {\cal C}(\Omega,\mathbb{R}^d)$.  Equivale a

\[\left\{\begin{array}{l}
x'_1 = x_2 \\
x'_2 = -\frac{c}{m}x_2 - \frac{1}{m}g(x_1)
\end{aligned}\right.\]

Cuando $g$ es localmente lipschitziana, existe solución única
por Picard-Lindelöf.

***** Acotación de soluciones, método de la energía
Llamamos *energía* a

\[
V(x_1,x_2) = V_1(x_1) + V_2(x_2) = G(x_1) + \frac{1}{2}mx^2_2
\]

y ahora se tiene $\bV(x_1,x_2) \leq 0$. Cuando $G$ es coerciva, todas
las soluciones están acotadas en el futuro y la energía se
va perdiendo.

****** Card: ejercicio                                                                                     :drill:
SCHEDULED: <2018-07-11 Wed>
:PROPERTIES:
:ID:       7969a4bb-c897-4560-bd1b-984118b0b9f9
:DRILL_LAST_INTERVAL: 11.909
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.75
:DRILL_EASE: 2.7
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-29 Fri 17:44]
:END:
Demuestra que las soluciones de

\[
x'' + 2x' + x\abs{x} = 0
\]

están acotadas en el futuro.

******* Answer
Tenemos una ecuación con rozamiento $mx'' + cx' + g(x) = 0$ con 
$m = 1$, $c = 2$ y $g(x) = x\abs{x}$ donde la primitiva $G(x) = \frac{1}{3}\abs{x}^3$
es coerciva.
**** 4. Ecuación de Liénard
***** Planteamiento
Llamamos ecuación de Liénard a

\[
x'' + f(x)x' + g(x) = 0
\]

donde $f,g \in {\cal C}(\mathbb{R})$ son localmente lipschitzianas.  Tomamos el cambio
de variable $x'_1 = x_2 - F(x_1)$ para llegar a

\[\left\{\begin{array}{l}
x'_1 = x_2 - F(x_1) \\
x'_2 = - g(x_1)
\end{aligned}\right.\]

donde $F$ es una primitiva de $f$.

****** Card: ecuación                                                                                    :nodrill:
SCHEDULED: <2018-07-09 Mon>
:PROPERTIES:
:ID:       b30bc986-968e-4035-a702-5d5dd943c680
:DRILL_LAST_INTERVAL: 9.8018
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-29 Fri 17:52]
:END:
Forma de la ecuación de Liénard.

******* Answer

\[
x'' + f(x)x' + g(x) = 0
\]

donde $f,g \in {\cal C}(\mathbb{R})$ son localmente lipschitzianas

****** Card: cambio variable                                                                               :drill:
SCHEDULED: <2018-06-17 Sun>
:PROPERTIES:
:ID:       bdde7129-5d4d-4c8a-9d5c-db27651f4746
:DRILL_LAST_INTERVAL: 4.786
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 5
:DRILL_FAILURE_COUNT: 3
:DRILL_AVERAGE_QUALITY: 2.6
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-12 Tue 15:06]
:END:
¿Qué cambio de variable debe hacerse en la ecuación de Liénard
para plantearlo como un sistema de primer orden?

\[
x'' + f(x)x' + g(x) = 0
\]

******* Answer

\[\left\{\begin{array}{l}
x'_1 = x_2 - F(x_1) \\
x'_2 = - g(x_1)
\end{aligned}\right.\]

***** Función guía
Cuando $G$, primitiva de $g$ es coerciva y además $g$ tiene el mismo signo
que $F$, la primitiva de $f$, hay una función guía en sumandos separados
que nos da /acotación en el futuro/.

Puede comprobarse simplemente buscando la función guía.

****** Card: criterio                                                                                      :drill:
SCHEDULED: <2018-06-17 Sun>
:PROPERTIES:
:ID:       6b663f7a-48f4-4c30-aa68-e9ed409c278e
:DRILL_LAST_INTERVAL: 4.5718
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.333
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-12 Tue 15:03]
:END:
Cuál es el criterio para tener *acotación en el futuro* en una
Ecuación de Liénard.

\[
x'' + f(x)x' + g(x) = 0
\]

******* Answer
Cuando $G$, primitiva de $g$, es coerciva y además $g$ tiene el mismo
signo que $F$, primitiva de $f$.

****** Card: en Lienard                                                                                    :drill:
SCHEDULED: <2018-06-17 Sun>
:PROPERTIES:
:ID:       17cab3fb-5c21-409e-a827-a67ac309dcd1
:DRILL_LAST_INTERVAL: 4.1578
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-13 Wed 11:30]
:END:
Supongamos que tenemos una ecuación de Liénard

\[
x'' + f(x)x' + g(x) = 0
\]

y sabemos que $G$, primitiva de $g$, es coerciva y además $g$ tiene el
mismo signo que $F$, primitiva de $f$. ¿Qué sabemos?

******* Answer
Que podemos encontrar una función guía que nos dará acotación
en el futuro.

**** 3. Ecuaciones forzadas
Llamamos *ecuación forzada* a una de la forma

\[
mx'' + cx' + g(x) = p(t)
\]

donde $m>0$, $c \geq 0$, $g \in {\cal C}(\Omega,\mathbb{R}^d)$ es localmente lipschitziana
y $p \in {\cal C}(\mathbb{R},\mathbb{R}^d)$.  Equivale a

\[\left\{\begin{array}{l}
x'_1 = x_2 \\
x'_2 = \frac{p(t)}{m} -\frac{c}{m}x_2 - \frac{1}{m}g(x_1)
\end{aligned}\right.\]

La función guía debe buscarse. 

*** Tema 5. Continuidad y diferenciabilidad de la solución
**** 5.1. Entornos tubulares
***** Entorno tubular
Para $J \subset \mathbb{R}$ intervalo, $\varphi \colon {\cal C}(J, \mathbb{R})$ y $\rho > 0$,

\[
T_{\rho}(J,\varphi) = \left\{ (t,x) \in J \times \mathbb{R}^d 
\;\middle|\;
\norm{x - \varphi(t)} \leq \rho \right\}.
\]

****** Entornos para Picard-Lindelöf
Los [[id:44351076-d98f-4552-a229-a41405beb6b1][entornos]] de Picard-Lindelöf, son entornos tubulares sobre
una función constante.

\[
{\cal R}_{a,b}(t_0,x_0) = T_b([t_0-a,t_0+a],x_0).
\]

****** Card                                                                                                :drill:
SCHEDULED: <2018-07-17 Tue>
:PROPERTIES:
:ID:       0645fdf9-3254-44f3-9354-a00edd4af6a9
:DRILL_LAST_INTERVAL: 35.0078
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.46
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-12 Tue 14:39]
:END:
Entorno tubular, $T_{\rho}(J,\varphi)$.

******* Definición
Para $J \subset \mathbb{R}$ intervalo, $\varphi \colon {\cal C}(J, \mathbb{R})$ y $\rho > 0$,

\[
T_{\rho}(J,\varphi) = \left\{ (t,x) \in J \times \mathbb{R}^d 
\;\middle|\;
\norm{x - \varphi(t)} \leq \rho \right\}.
\]

****** Card: abiertos o cerrados                                                                           :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       59fa2dbc-7796-4cd4-91db-cc295bcec020
:DRILL_LAST_INTERVAL: 32.2101
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 5.0
:DRILL_EASE: 2.8
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-05-21 Mon 14:53]
:END:
¿Los entornos tubulares son abiertos o cerrados?

******* Respuesta
Cerrados

\[
T_{\rho}(J,\varphi) = \left\{ (t,x) \in J \times \mathbb{R}^d 
\;\middle|\;
\norm{x - \varphi(t)} \leq \rho \right\}.
\]

***** Lema 1. Homomorfismo del entorno tubular

\[
T_{\rho}(J,\varphi) \cong J \times \overline{B}(0,\rho).
\]

****** Card                                                                                                :drill:
SCHEDULED: <2018-09-12 Wed>
:PROPERTIES:
:ID:       b0afd4f3-2e7a-4222-8273-435a3ab7f163
:DRILL_LAST_INTERVAL: 74.9219
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.46
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-29 Fri 09:53]
:END:
¿A qué espacio más sencillo es homeomorfo el
entorno tubular $T_p(J,\varphi)$?

******* Respuesta

\[
T_{\rho}(J,\varphi) \cong J \times \overline{B}(0,\rho)
\]

***** Lema 2. Entorno tubular dentro de un dominio
Para $D \subset \mathbb{R}^d \times \mathbb{R}$ abierto con $(t,\varphi(t)) \in D$ y para $J$ compacto, existe
$\rho>0$ tal que $T_p(J,\varphi) \subset D$.

****** TODO Proof
***** Lema 3. Localmente lipschitziana en compacto es globalmente lipschitziana
Una función localmente lipschitziana en un compacto es globalmente
lipschitizana en el compacto.

****** Proof
Si no fuera globalmente lipschitziana podemos aplicar
Bolzano-Weierstrass para obtener sucesiones que hicieran que no
pudiera ser localmente lipschitziana.

***** TODO Lema 4. Globalmente lipschitziana en un entorno tubular
**** 5.2. Convergencia uniforme en compactos
***** Convergencia uniforme en compactos
Una sucesión de funciones definidas en intervalos, $f_n \colon I_n \to \mathbb{R}^d$;
*converge uniformemente en compactos* a $f \colon I \to \mathbb{R}$ cuando para
todo $[a,b] \subset I$, a partir de un $n_0$,

\[
[a,b] \subseteq I_n, \mbox{ y además }\quad
f_n_{|[a,b]} \overset{c.u.}\longrightarrow f_{|[a,b]}.
\]

****** Card                                                                                                :drill:
SCHEDULED: <2018-08-06 Mon>
:PROPERTIES:
:ID:       8b8c5241-89f5-4f08-b039-7e62f401a15f
:DRILL_LAST_INTERVAL: 53.9366
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.75
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-13 Wed 11:28]
:END:
Convergencia uniforme en compactos.

******* Definición
Tenemos $f_n_{|I_n} \overset{cuc}\longrightarrow f_{|I}$ si para todo $[a,b] \subset I$, a partir de un $n_0$,

 * $[a,b] \subseteq I_n$,

 * $f_n_{|[a,b]} \overset{cu}\longrightarrow f_{|[a,b]}$.

****** Card: convergencia uniforme en compactos pero no uniforme                                           :drill:
SCHEDULED: <2018-06-19 Tue>
:PROPERTIES:
:ID:       c69612d6-af02-41c5-82b5-abb4085409db
:DRILL_LAST_INTERVAL: 29.2476
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 5.0
:DRILL_EASE: 2.8
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-05-21 Mon 14:53]
:END:
Ejemplo de $f_n$ que convergen uniformemente en compactos pero
no uniformemente.

******* Ejemplo
En $f_n \colon \mathbb{R} \to \mathbb{R}$, trivialmente no convergen uniformemente pero
sí convergen en cualquier compacto.

\[
f_n(t) = \frac{1}{n}t
\]

****** Card: convergencia puntual no uniforme en compactos                                                 :drill:
SCHEDULED: <2018-07-11 Wed>
:PROPERTIES:
:ID:       a23dd345-50e1-4c73-a77a-9aa9abf4a93a
:DRILL_LAST_INTERVAL: 29.5063
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.667
:DRILL_EASE: 2.7
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-11 Mon 21:42]
:END:
Ejemplo de $f_n$ que converge puntual pero no uniformemente en
compactos.

******* Ejemplo
En $[0,1]$, las funciones $f_n = x^n$ convergen puntualmente a una
función no continua.

******* Ejemplo
En $[0,1]$, podemos tomar

\[
f_n(t) = n \left( t + \frac{1}{n} \right)_+ - n(t)_+
\]

que crean un escalón entre $[1/n,0]$, haciendo que no haya convergencia
uniforme en cualquier intervalo conteniendo a $0$.

***** Lema 5. Continuidad del límite de convergencia uniforme en compactos
Si $f_n \in {\cal C}(I_n)$ y $f_n \overset{cuc}\longrightarrow f$, entonces $f \in {\cal C}(I)$.

****** TODO Proof
# Por desigualdad triangular.
****** Card                                                                                                :drill:
SCHEDULED: <2018-06-18 Mon>
:PROPERTIES:
:ID:       c62d7140-be30-4f57-8c75-d10ff98b7c00
:DRILL_LAST_INTERVAL: 29.2661
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.333
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-05-20 Sun 23:27]
:END:
Para una secuencia $f_n \in {\cal C}(I_n)$, qué tipos de convergencia preservan
la continuidad.

******* Respuesta
Basta $f_n \overset{cuc}\longrightarrow f$ para tener $f \in {\cal C}(I)$. También se cumple con la
convergencia uniforme, que es más fuerte; pero no se cumple con
la puntual.

***** Lema 6. Convergencia de aplicaciones en convergencia uniforme
Si $f_n \overset{cuc}\longrightarrow f$, sabemos $t_n \in I_n$ con $t_n \to t_{\ast}$, y $f$ es continua en $t$,
entonces $f_n(t_n) \to f(t_{\ast})$.

**** 5.3. Continuidad de la solución general
Consideramos dominio abierto $D \subset \mathbb{R} \times \mathbb{R}^d$ y campo $f$ continuo y
localmente lipschitziano respecto $x$.

***** Proposición 1.
Sea ${\cal R}_{a,b}(t_0,x_0) \subset D$ donde $\norm{f(t,x)} \leq M$. Existe $\mu_0$ tal que
$\forall\mu \in (0,\mu_0)$, si $\overline{\varphi} \colon I \to \mathbb{R}^d$ es una solución maximal con condición inicial
$(t_1,x_1) \in {\cal R}_{\mu,\mu}(t_0,x_0)$; entonces $(t,\overline{\varphi}(t)) \in {\cal R}_{a,b}(t_0,x_0)$ para
$t \in [t_0-\mu,t_0+\mu]$ y además

\[
\norm{\overline{\varphi}(t)-x_0} \leq
\norm{x_1 - x_0} + M\abs{t-t_1} \leq
(1 + 2M)\mu.
\]

En particular, $\norm{\overline{\varphi}(t_0) - x_0} \leq (1 + M)\mu$.

****** Proof                                                                                               :extra:
***** Lema 7. Desigualdad fundamental
Sean $\varphi_i \colon I_i \to \mathbb{R}^{d}$ dos soluciones de $x' = f(t,x)$ tales que

\[
\forall t \in I_1\cap I_2 \colon\qquad
\norm{f(t,\varphi_1(t)) - f(t,\varphi_2(t))} \leq
L\norm{\varphi_1(t) - \varphi_2(t)},
\]

entonces para $t_0 \in I_1 \cap I_2$ se tiene

\[
\forall t \in I_1\cap I_2 \colon\qquad
\norm{\varphi_1(t) -\varphi_2(t)} \leq
\norm{\varphi_1(t_0) - \varphi_2(t_0)} e^{L\abs{t-t_0}}.
\]

****** TODO Proof
Volterra y Gronwall.
****** Card                                                                                              :nodrill:
SCHEDULED: <2018-07-10 Tue>
:PROPERTIES:
:ID:       d4e16b44-c476-4276-bccc-0a2d15a20555
:DRILL_LAST_INTERVAL: 10.8859
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.22
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-29 Fri 17:50]
:END:
Enunciar la *desigualdad fundamental*, que controla la diferencia entre
dos soluciones a una ecuación diferencial. ¿Qué condición necesita?

******* Answer
Para $\varphi_i \colon I_i \to \mathbb{R}^{d}$ soluciones de $x' = f(t,x)$ tales que

\[
\forall t \in I_1\cap I_2 \colon\qquad
\norm{f(t,\varphi_1(t)) - f(t,\varphi_2(t))} \leq
L\norm{\varphi_1(t) - \varphi_2(t)},
\]

se tiene 

\[
\forall t \in I_1\cap I_2 \colon\qquad
\norm{\varphi_1(t) -\varphi_2(t)} \leq
\norm{\varphi_1(t_0) - \varphi_2(t_0)} e^{L\abs{t-t_0}}.
\]

para $t_0 \in I_1 \cap I_2$ se tiene.

***** Proposición 2. Acotar una solución dentro de un entorno tubular
Para $(t_0,x_0) \in D$, sean $\alpha(t_0,x_0) < a < t_0 < b < \omega(t_0,x_0)$ y sea
$T_{\rho}([a,b],\varphi) \subset D$.  Entonces existe $\delta > 0$ tal que
$\forall (t_1,x_1) \in [t_0-\delta,t_0+\delta] \times \overline{B}(x_0,\delta)$, la solución desde
ellos está definida en $[a,b]$ y además

\[
(t,X(t;t_1,x_1)) \in T_{\rho},\quad\forall t\in [a,b].
\]

****** TODO Proof
# Usando la proposición 1 y la desigualdad fundamental.

***** Teorema 1. Continuidad de la solución general
El conjunto

\[
\Omega = \left\{ (t,t_0,x_0) \mid (t_0,x_0) \in D, \alpha(t_0,x_0) < t < \omega(t_0,x_0) \right\}
\]

es abierto y la solución general $X \colon \Omega \to \mathbb{R}^d$ es continua.

****** Card: conjunto                                                                                      :drill:
SCHEDULED: <2018-06-17 Sun>
:PROPERTIES:
:ID:       fb86730f-4593-425c-b828-234da37f0a0f
:DRILL_LAST_INTERVAL: 4.4024
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-13 Wed 10:07]
:END:
Describe el conjunto en el que está definida la solución general, ¿qué
propiedad topológica conocemos de él?

******* Answer
El conjunto

\[
\Omega = \left\{ (t,t_0,x_0) \mid (t_0,x_0) \in D, \alpha(t_0,x_0) < t < \omega(t_0,x_0) \right\}
\]

es abierto. Sobre este conjunto la solución general es continua.

****** TODO Proof

***** Corolario 1. Convergencia uniforme en compactos respecto condiciones iniciales
Para $(t_0,x_0) \in D$ consideramos la solución maximal $\varphi \colon (\alpha,\omega)\to \mathbb{R}^d$
y sucesiones $t_{0n}\to t_0$ y $x_{0n}\to x_0$. Si $\varphi_n$ es la solución con condiciones
iniciales $(t_{0n},x_{0n})$, hay convergencia uniforme en compactos $\varphi_n \overset{cuc}\longrightarrow \varphi$
en el intervalo $(\alpha,\omega)$.

***** Algoritmo con el corolario 1.
Si tenemos una sucesión de problemas $x' = f(t,x)$ con valores
iniciales $x(t_{0n}) = x_{0n}$, con soluciones $\varphi_n \colon (\alpha_n,\omega_n) \to \mathbb{R}^d$;
podemos calcular

$\varphi_n(\tau_n) \to \varphi(\lim \tau_n)$

donde $\varphi$ es al problema inicial con $x(\lim t_{0n}) = \lim x_{0n}$.

****** Card                                                                                                :drill:
SCHEDULED: <2018-06-17 Sun>
:PROPERTIES:
:ID:       dcb13d3c-67e0-4358-8a27-cab413ae9e95
:DRILL_LAST_INTERVAL: 4.0802
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-13 Wed 09:59]
:END:
Calcular $\lim_{n \to \infty} \varphi_n(\tau_n)$ donde $\tau_n = (1 + 1/n)^n$ y donde $\varphi_n$ es la
solución de

\[\left.\begin{aligned}
x' &= (x+t)x^2 \\
x(1 + 1/n) &= 1/n^2
\end{aligned}\right\}\]

******* Answer
Podemos usar convergencia uniforme en compactos de las soluciones respecto
de condiciones iniciales para buscar la solución $\varphi$ al sistema límite

\[\left.\begin{aligned}
x' &= (x+t)x^2 \\
x(1) &= 0
\end{aligned}\right\}\]

que en este caso es trivial, y aplicarla en $\varphi(e) = 0$, el límite
del los $\tau_n$.

**** 5.4. Dependencia continua respecto de parámetros
Consideramos dominio abierto $D \subset \mathbb{R} \times \mathbb{R}^d$ y campo $f$ continuo y
localmente lipschitziano respecto $x$ y un parámetro $\lambda$.

***** Teorema 2. Continuidad de la solución general respecto de parámetros
Si llamamos $X(t;t_0,x_0,\lambda_0)$ a la solución general del problema con
parámetros dado por $x' = f(t,x,\lambda_0)$ y por $x(t_0) = x_0$; definida
en el conjunto

\[
\Omega = \left\{ (t;t_0,x_0,\lambda_0) \mid 
((t_0,x_0),\lambda) \in D \times P,\ \alpha(t_0,x_0,\lambda_0) < t < \omega(t_0,x_0,\lambda_0) \right\}.
\]

Entonces el conjunto $\Omega$ es abierto y $X$ es *continua*. Hay además
convergencia uniforme en compactos $X(-;t_{0n},x_{0n},\lambda_{0n}) \overset{cuc}\longrightarrow X(-;t_0,x_0,\lambda_0)$
en el intervalo $(\alpha(t_0,x_0,\lambda_0),\omega(t_0,x_0,\lambda_0))$.

****** Card                                                                                                :drill:
SCHEDULED: <2018-06-18 Mon>
:PROPERTIES:
:ID:       f5867c8f-f14d-4f5d-9ca2-32c213da4ab3
:DRILL_LAST_INTERVAL: 4.9074
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-13 Wed 10:23]
:END:
Enunciar la continuidad de la solución general respecto de parámetros.

******* Answer
$X$ es continua sobre $\Omega$, que es abierto. Además,

$X(-;t_{0n},x_{0n},\lambda_{0n}) \overset{cuc}\longrightarrow X(-;t_0,x_0,\lambda_0)$

***** TODO Ejemplo. Conservación de signo
**** 5.5. Diferenciabilidad de la solución general
***** Hipótesis de regularidad
Consideramos

\[ \pdv{f}{x}\colon D \to {\cal M}_d \]

continua y bien definida. Esto nos da $f$ localmente lipschitziana
respecto de $x$.

****** Card: hipótesis de regularidad                                                                      :drill:
SCHEDULED: <2018-06-18 Mon>
:PROPERTIES:
:ID:       3c751cbd-8623-4e89-91ed-b6ef58b20aa0
:DRILL_LAST_INTERVAL: 5.0362
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 2.5
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-13 Wed 19:39]
:END:
¿Qué es la hipótesis de regularidad?¿Qué nos da?

******* Answer
Es tener $f \colon D \to \mathbb{R}^d$ continua con

\[ \pdv{f}{x}\colon D \to {\cal M}_d \]

continua y bien definida. Esto nos da $f$ localmente lipschitziana
respecto de $x$.

***** Teorema 3. Derivabilidad respecto condiciones iniciales
Con la hipótesis de regularidad.

 1. Se tiene $X \in {\cal C}^1(\Omega)$.
 2. Existen y son continuas

    \[\pdv[2]{X}{t}{t_0},\quad
    \pdv[2]{X}{t}{x_0},\quad
    \pdv[2]{X}{t_0}{t},\quad
    \pdv[2]{X}{x_0}{t}.
    \]

Debemos notar que las soluciones quedan determinadas por

\[
\pdv{X}{t} (t;t_0,x_0) = f(t,X(t;t_0,x_0)),\quad X(t_0,t_0,x_0) = x_0,
\]

y desde ellas usando [[https://es.wikipedia.org/wiki/Teorema_de_Clairaut][Schwarz-Clairaut]] podemos obtener una
*ecuación variacional* sobre la derivada parcial que queramos
calcular.

****** Card                                                                                                :drill:
SCHEDULED: <2018-06-17 Sun>
:PROPERTIES:
:ID:       7f78d326-04fd-4995-8167-ba24ad1b683b
:DRILL_LAST_INTERVAL: 3.7189
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-13 Wed 10:21]
:END:
Cuál es la hipótesis de regularidad sobre $f \colon D \to \mathbb{R}^d$ que debemos comprobar
antes de aplicar derivabilidad respecto de condiciones iniciales.

******* Answer
Pedimos $f \colon D \to \mathbb{R}^d$ continua con

\[ \pdv{f}{x}\colon D \to {\cal M}_d \]

continua y bien definida.

***** Niveles de diferenciabilidad
Para $f \colon D \to \mathbb{R}^m$ con $D \subset \mathbb{R}^m$ abierto y $a \in D$, consideramos
distintos niveles de diferenciabilidad, cada uno implicando
los anteriores.

 1. Existen las *derivadas parciales*,

    \[
    \pdv{f}{x_i} (a) = \lim_{h \to 0} \frac{f(a+he_i) - f(a)}{h} \in \mathbb{R}^m
    \]

 2. Existen todas las *derivadas direccionales*

    \[
    D_vf(a) = \lim_{h \to 0} \frac{f(a+hv) - f(a)}{h} \in \mathbb{R}^m
    \]

 3. *Diferenciabilidad de Gateaux*: $v \mapsto D_vf(a)$ es lineal y
    continua. $D_vf(a) = Tv$ para alguna $T \in {\cal M}_{m\times n}$.

 4. *Diferenciabilidad de Frechet*: tenemos

    \[
    \lim_{v \to 0} \frac{\norm{f(a+v) - f(a) - D_vf(a)}}{\norm{v}} = 0, \qquad \forall v \in \mathbb{R}^n
    \]

Si existen todas las derivadas parciales de $f$ y son continuas,
entonces $f$ es diferenciable en sentido de Frechet.

****** TODO Contraejemplo: Gateaux pero no Frechet
****** Card: Gateaux                                                                                       :drill:
SCHEDULED: <2018-06-17 Sun>
:PROPERTIES:
:ID:       7594c6e6-90c4-44ce-91e7-8cc0892f465c
:DRILL_LAST_INTERVAL: 4.0024
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-13 Wed 09:54]
:END:
Define diferenciabilidad de Gateaux.

******* Answer
La aplicación de las derivadas direccionales, $v \mapsto D_vf(a)$ es
lineal y continua. $D_vf(a) = Tv$ para alguna $T \in {\cal M}_{m\times n}$.

****** Card: Frechet                                                                                       :drill:
SCHEDULED: <2018-06-17 Sun>
:PROPERTIES:
:ID:       a7a6a587-2c1b-40d5-899c-acf77bd561a6
:DRILL_LAST_INTERVAL: 4.1818
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-13 Wed 11:33]
:END:
Define diferenciabilidad de Frechet.

******* Answer
Cuando tenemos

\[
\lim_{v \to 0} \frac{\norm{f(a+v) - f(a) - D_vf(a)}}{\norm{v}} = 0, \qquad \forall v \in \mathbb{R}^n
\]
***** Regla de Barrow multivariable
Para $G \in {\cal C}^{1}(A,\mathbb{R}^m)$ con $[p,q] \subset A \subset \mathbb{R}^n$,

\[
G(p) - G(q) = \left( \int_0^1 G'(sp + (1-s)q)\,ds \right)(p-q).
\]

****** Card                                                                                                :drill:
SCHEDULED: <2018-06-18 Mon>
:PROPERTIES:
:ID:       648d37c6-b4bd-41ab-a818-fd358b61a789
:DRILL_LAST_INTERVAL: 4.6646
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 2
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-13 Wed 19:41]
:END:
Enunciar la regla de Barrow multivariable para $G \in {\cal C}^{1}(A,\mathbb{R}^m)$
con $[p,q] \subset A \subset \mathbb{R}^n$. Esto es,

\[
G(p) - G(q) = \dots
\]

******* Answer

\[
G(p) - G(q) = \left( \int_0^1 G'(sp + (1-s)q)\,ds \right)(p-q).
\]

***** Teorema 4. Derivabilidad respecto condiciones iniciales y parámetros
Sea $f \colon D \times P \to \mathbb{R}^d$ dependiente de un parámetro y continua con la hipótesis
de regularidad, es decir,

\[
\pdv{f}{x}\colon D \times P \to {\cal M}_d,\qquad
\pdv{f}{\lambda}\colon D \times P \to {\cal M}_{d\times k},
\]

son continuas y bien definidas.

 1. Se tiene $X \in {\cal C}^1(\Omega)$.
 2. Existen y son continuas

    \[\pdv[2]{X}{t}{t_0},\quad
    \pdv[2]{X}{t}{x_0},\quad
    \pdv[2]{X}{t_0}{t},\quad
    \pdv[2]{X}{x_0}{t},\quad
    \pdv[2]{X}{t}{\lambda},\quad
    \pdv[2]{X}{\lambda}{t}.
    \]
 
***** TODO Ejemplo de cálculo y diagonalización
*** Tema 6. Estabilidad en el sentido de Lyapunov
Fijamos $D \subset \mathbb{R} \times \mathbb{R}^d$ dominio abierto y $f$ campo continuo y localmente
lipschitziano respecto de $x$.

**** 6.0. Estabilidad
***** Estable
Una solución $\varphi \colon (\alpha,+\infty) \to \mathbb{R}^d$ es *estable* si para cada $\varepsilon > 0$
existe un $\delta > 0$ tal que si $\norm{x_0 - \varphi(t_0)} < \delta$, entonces

 - $\omega(t_0,x_0) = \infty$, la solución llega a infinito,

 - para $t \geq t_0$, se tiene $\norm{X(t;t_0,x_0) - \varphi(t))} < \varepsilon$, está siempre
   suficientemente cerca de la original.

Dicho de otra forma, para todo entorno tubular de tamaño $\varepsilon$, existe
un $\delta$ tal que si la partícula empieza a menos distancia de $\delta$ de la
original, entonces la solución se mantiene en ese entorno tubular.

****** Card                                                                                                :drill:
SCHEDULED: <2018-07-10 Tue>
:PROPERTIES:
:ID:       fe0c06f5-3cd4-4b6b-b0f1-6d53475a34eb
:DRILL_LAST_INTERVAL: 11.3386
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.333
:DRILL_EASE: 2.46
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-29 Fri 17:46]
:END:
Definición de solución estable $\varphi \colon (\alpha,+\infty) \to \mathbb{R}^d$.

******* Answer
Si $\norm{x_0 - \varphi(t_0)} < \delta$,

 * $\omega(t_0,x_0) = \infty$,
 * $\norm{X(t;t_0,x_0) - \varphi(t))} < \varepsilon$.

******* Detallado
Para cada $\varepsilon > 0$ existe un $\delta > 0$ tal que si $\norm{x_0 - \varphi(t_0)} < \delta$,
entonces

 - $\omega(t_0,x_0) = \infty$, la solución llega a infinito,

 - para $t \geq t_0$, se tiene $\norm{X(t;t_0,x_0) - \varphi(t))} < \varepsilon$, la solución
   está cerca de la original.

***** Inestable
Una solución $\varphi \colon (\alpha,+\infty) \to \mathbb{R}^d$ es *inestable* si existe un $\varepsilon_0 > 0$
tal que podemos crear $x_n \to \varphi(t_0)$ cumpliendo que

 - o bien $\omega(t_0,x_n) < \infty$, la solución se corta,

 - o bien $\exists t_n \in [t_0,+\infty)\colon \norm{\varphi(t_n) - X(t_n;t_0,x_n)} \geq \varepsilon_0$ queda por
   encima del umbral en algún punto.

****** Card                                                                                                :drill:
SCHEDULED: <2018-07-09 Mon>
:PROPERTIES:
:ID:       660bb6be-01eb-44a3-9265-8621a73aca16
:DRILL_LAST_INTERVAL: 10.0376
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.5
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-29 Fri 17:50]
:END:
Definición de solución inestable $\varphi \colon (\alpha,+\infty) \to \mathbb{R}^d$.

******* Answer
Existe algún umbral $\varepsilon_0 > 0$ tal que podemos crear $x_n \to \varphi(t_0)$ que

 - $\omega(t_0,x_n) < \infty$, la solución se corta, o

 - existe algún punto $t_n \in [t_0,+\infty)$ para el que $\norm{\varphi(t_n) - X(t_n;t_0,x_n)} \geq \varepsilon_0$.

***** Atractor
Una solución $\varphi \colon (\alpha,+\infty) \to \mathbb{R}^d$ es un *atractor* (local) si existe
$\mu > 0$ tal que $\norm{x_0-\varphi(t_0)} < \mu$ implica

 - que $\omega(t_0,x_0) = \infty$,

 - $\lim_{t \to \infty} X(t;t_0,x_0) - \varphi(t) = 0$.

****** Card                                                                                                :drill:
SCHEDULED: <2018-07-08 Sun>
:PROPERTIES:
:ID:       c865d6ca-f89e-477d-92d6-0e46cbe041c6
:DRILL_LAST_INTERVAL: 9.2669
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.5
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-29 Fri 17:48]
:END:
Definición de solución atractor $\varphi \colon (\alpha,+\infty) \to \mathbb{R}^d$.

******* Answer
Existe $\mu > 0$ tal que $\norm{x_0-\varphi(t_0)} < \mu$ implica

 - que $\omega(t_0,x_0) = \infty$, continúa hasta infinito;

 - $\lim_{t \to \infty} X(t;t_0,x_0) - \varphi(t) = 0$, se acaba acercando a la
   solución.

***** Asintóticamente estable
Una solución es *asintóticamente estable* si es un atractor estable.

****** Card                                                                                                :drill:
SCHEDULED: <2018-07-08 Sun>
:PROPERTIES:
:ID:       0953e8b1-7f90-4df8-b9b6-c060bd52acf9
:DRILL_LAST_INTERVAL: 9.3206
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.5
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-29 Fri 17:44]
:END:
Definición de asintóticamente estable.

******* Answer
Atractor estable.

*Atractor*
Para $\varphi \colon (\alpha,+\infty) \to \mathbb{R}^d$ hay algún $\mu$ tal que $\norm{x_0-\varphi(t_0)} < \mu$ nos da

 - que $\omega(t_0,x_0) = \infty$, todas las soluciones cerca de el punto inicial
   están definidas;

 - $\lim_{t \to \infty} X(t;t_0,x_0) - \varphi(t) = 0$, todas las soluciones tienden en
   el futuro hacia la solución.

*Estable*
Para $\varphi \colon (\alpha,+\infty) \to \mathbb{R}^d$, y para cada $\varepsilon > 0$ existe un $\delta > 0$ tal que
si $\norm{x_0 - \varphi(t_0)} < \delta$, entonces

 - $\omega(t_0,x_0) = \infty$,

 - para $t \geq t_0$, se tiene $\norm{X(t;t_0,x_0) - \varphi(t))} < \varepsilon$.

**** 6.1. Estabilidad de ecuaciones lineales
***** Proposición 1. Estabilidad en ecuaciones lineales
:PROPERTIES:
:ID:       9a67a179-4e81-44c6-853e-8f54dea11422
:END:
Sea la ecuación lineal $x' = A(t)x + b(t)$ para $A,b$ continuas.
Equivalen,

 1. todas las soluciones de la general son estables;
 2. la general tiene una solución estable;
 3. las soluciones de la homogénea están acotadas en el futuro;
 4. la homogénea tiene una matriz fundamental acotada en el futuro.

****** Card                                                                                              :nodrill:
SCHEDULED: <2018-07-09 Mon>
:PROPERTIES:
:ID:       33092476-ce17-4d97-8c10-71d893194990
:DRILL_LAST_INTERVAL: 10.0192
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 2.333
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-29 Fri 17:51]
:END:
Estudiamos *estabilidad* en ecuaciones lineales. Para
$A,b$ continuas en la ecuación $x' = A(t)x + b(t)$, ¿qué 4
equivalencias hay?

******* Answer

 1. todas las soluciones de la general son estables;
 2. la general tiene una solución estable;
 3. las soluciones de la homogénea están acotadas en el futuro;
 4. la homogénea tiene una matriz fundamental acotada en el futuro.

****** Proof 1 to 2
Si todas las soluciones de la general son estables, sabiendo que
alguna existe, será estable.

****** Proof 2 to 3
Sea $\varphi$ solución de la general, $\psi$ solución de la homogénea. Tomamos
$\varepsilon = 1$ en la estabilidad y fijamos un $\lambda \norm{\psi(t_0)} < \delta$.  Tenemos que
$\varphi + \lambda \psi$ es solución de la general y que tiene el valor inicial dentro
de los valores de estabilidad. Desde aquí $\norm{\psi(t)} < 1/\lambda$ acotada.

****** Proof 3 to 4
Tomamos un sistema fundamental de soluciones. Todas las componentes de
la matriz fundamental estarán acotadas en el futuro, luego la matriz
lo estará.

****** Proof 4 to 1
Será $\vertiii{\Psi} < M$ una matriz fundamental, y $\vertiii{\Phi(t)} \leq \vertiii{\Psi(t)}\vertiii{\Psi(t_0)^{-1}}$
la matriz fundamental en $t_0$. Si tomamos

\[
M \vertiii{\Psi(t_0)^{-1}} \delta < \varepsilon
\]

tenemos que una solución de la general debe ser
$X(t;t_0,x_0) = \varphi(t) + \Phi(t)(x_0-\varphi(t_0))$, y que por tanto,

\[
\norm{X(t;t_0,x_0) - \varphi(t)} = \norm{\Phi(t)(x_0-\varphi(t_0))} \leq \vertiii{\Psi(t)}\vertiii{\Psi(t_0)^{-1}}\norm{x_0-\varphi(t_0)} \leq \varepsilon.
\]

***** Proposición 2. Estabilidad asintótica en ecuaciones lineales
:PROPERTIES:
:ID:       6293d367-8f82-4677-b692-2484008b7464
:END:
Sea la ecuación lineal $x' = A(t)x + b(t)$ para $a,b$ continuas.
Equivalen,

 1. todas las soluciones de la general son asintóticamente estables;
 2. la general tiene una solución atractor;
 3. las soluciones de la homogénea convergen a $0$ cuando $t \to \infty$;
 4. la homogénea tiene una matriz fundamental que converge a $0$ cuando $t \to \infty$.

****** Card                                                                                                :drill:
SCHEDULED: <2018-06-17 Sun>
:PROPERTIES:
:ID:       c22f1984-5237-424f-b646-1c1562d7b6d1
:DRILL_LAST_INTERVAL: 3.9808
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-13 Wed 10:23]
:END:
Estudiamos *estabilidad asintótica* en ecuaciones lineales. Para
$A,b$ continuas en la ecuación $x' = A(t)x + b(t)$, ¿qué 4
equivalencias hay?

******* Answer

 1. todas las soluciones de la general son asintóticamente estables;
 2. la general tiene una solución atractor;
 3. las soluciones de la homogénea convergen a $0$ cuando $t \to \infty$;
 4. la homogénea tiene una matriz fundamental que converge a $0$ en el futuro.

******* Compárese con estabilidad, donde equivalen

 1. todas las soluciones de la general son estables;
 2. la general tiene una solución estable;
 3. las soluciones de la homogénea están acotadas en el futuro;
 4. la homogénea tiene una matriz fundamental acotada en el futuro.

****** Proof                                                                                               :extra:
**** 6.2. Estabilidad de ecuaciones lineales con coeficientes constantes
***** Bloques de Jordan
Para $A \in {\cal M}_d(\mathbb{R})$ tenemos

 * $\sigma(A) = \left\{ \lambda_1,\dots,\lambda_d \right\}$, el *espectro* de valores propios $\lambda_i \in \mathbb{C}$, cada uno con
   su multiplicidad;

 * $\sigma_0(A) = \left\{ \lambda \in \sigma(A) \mid \mathrm{Re}(\lambda) = 0 \right\}$, el *espectro imaginario*;

 * $\nu(\lambda)$, el *índice* (tamaño) del mayor bloque de Jordan asociado a un valor
   propio; llamamos $\gamma(\lambda) = \nu(\lambda) - 1$ al número de unos supradiagonales.

Nótese que toda matriz puede diagonalizarse en forma normal de Jordan $A = PJP^{-1}$
y que $e^{At} = P e^{Jt} P^{-1}$. Además, la exponencial se calcula por bloques, siendo de
la forma siguiente.

\[
e^{J_it} = \begin{pmatrix}
e^{\lambda_it} & te^{\lambda_it} & \dots & \dots & \frac{t^{k-1}}{(k-1)!}e^{\lambda_it} \\
0 & e^{\lambda_it} & te^{\lambda_it} & \dots & \dots \\
\vdots & \vdots & \ddots & \ddots & \vdots \\
0 & \dots & \dots & \dots & e^{\lambda_it} \\
\end{pmatrix}
\]

****** Card: índice                                                                                        :drill:
SCHEDULED: <2018-06-18 Mon>
:PROPERTIES:
:ID:       02081431-5e2f-4fd1-8d3e-074080a59980
:DRILL_LAST_INTERVAL: 4.7525
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-13 Wed 11:31]
:END:
Define el índice $\nu$ y $\gamma$ de un valor propio $\lambda$.

******* Answer
$\nu(\lambda)$, es el tamaño del mayor bloque de Jordan asociado a un valor propio;
llamamos $\gamma(\lambda) = \nu(\lambda) - 1$ al número de unos supradiagonales.

****** Card: exponencial de un bloque de Jordan                                                            :drill:
SCHEDULED: <2018-06-17 Sun>
:PROPERTIES:
:ID:       330f0ad8-0d64-4d61-9911-30d343144ab9
:DRILL_LAST_INTERVAL: 3.5297
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-13 Wed 19:41]
:END:
Calcular la exponencial de un bloque de Jordan.

******* Answer

\[
e^{J_it} = \begin{pmatrix}
e^{\lambda_it} & te^{\lambda_it} & \dots & \dots & \frac{t^{k-1}}{(k-1)!}e^{\lambda_it} \\
0 & e^{\lambda_it} & te^{\lambda_it} & \dots & \dots \\
\vdots & \vdots & \ddots & \ddots & \vdots \\
0 & \dots & \dots & \dots & e^{\lambda_it} \\
\end{pmatrix}
\]
***** Teorema. Estabilidad para lineales con coeficientes constantes
Para el sistema $x' = Ax$, sea $\mu = \max\left\{ \mathrm{Re}(\lambda) \mid \lambda \in \sigma(A) \right\}$, entonces

 * si $\mu < 0$, todas las soluciones son /asintóticamente estables/;

 * si $\mu = 0$ y $\forall \lambda \in \sigma_0(A) \colon \nu(\lambda) = 1$, todas las soluciones son /estables/ 
   pero no /asintóticamente estables/;

 * si $\mu = 0$ y $\exists \lambda \in \sigma_0(A)\colon \nu(\lambda) > 1$, todas las soluciones son /inestables/;

 * si $\mu > 0$, todas las soluciones son /inestables/.

****** Proof
Podemos usar norma matricial de la suma (todas las normas son equivalentes)
sobre $e^{Jt}$ para ver si es una matriz fundamental de homogénea acotada en el futuro.

Por casos podremos aplicar [[id:9a67a179-4e81-44c6-853e-8f54dea11422][Proposición 1]] y [[id:6293d367-8f82-4677-b692-2484008b7464][Proposición 2]].

****** Card: teorema de estabilidad                                                                        :drill:
SCHEDULED: <2018-06-17 Sun>
:PROPERTIES:
:ID:       dc1978bc-4a68-4ae3-86ec-b84a8313cb22
:DRILL_LAST_INTERVAL: 4.0677
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-13 Wed 10:06]
:END:
Enuncia el Teorema de estabilidad para ecuaciones lineales con
coeficientes constantes aplicado sobre $x' = Ax$.

******* Answer
Sea $\mu = \max\left\{ \mathrm{Re}(\lambda) \mid \lambda \in \sigma(A) \right\}$, entonces

 * si $\mu < 0$, todas las soluciones son /asintóticamente estables/;

 * si $\mu = 0$ y $\forall \lambda \in \sigma_0(A) \colon \nu(\lambda) = 1$, todas las soluciones son /estables/ 
   pero no /asintóticamente estables/;

 * si $\mu = 0$ y $\exists \lambda \in \sigma_0(A)\colon \nu(\lambda) > 1$, todas las soluciones son /inestables/;

 * si $\mu > 0$, todas las soluciones son /inestables/.
****** Card: teorema de estabilidad en el caso de parte real nula                                          :drill:
SCHEDULED: <2018-07-06 Fri>
:PROPERTIES:
:ID:       f5d44679-e729-4478-a90d-be61e7b713cd
:DRILL_LAST_INTERVAL: 7.0929
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.5
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-29 Fri 17:52]
:END:
Caso particular. ¿Qué dice el Teorema de estabilidad para ecuaciones lineales
cuando $\mu = \max\left\{ \mathrm{Re}(\lambda) \mid \lambda \in \sigma(A) \right\} = 0$?

******* Answer
Lo que diferencia es el índice de los valores propios del espectro
imaginario.

 * si $\mu = 0$ y $\forall \lambda \in \sigma_0(A) \colon \nu(\lambda) = 1$, todas las soluciones son /estables/ 
   pero no /asintóticamente estables/;

 * si $\mu = 0$ y $\exists \lambda \in \sigma_0(A)\colon \nu(\lambda) > 1$, todas las soluciones son /inestables/;
***** Corolario. Estabilidad en el caso bidimensional en términos de traza y determinante
Para el sistema no nulo $x' = Ax$, bidimensional $A \in {\cal M}_2(\mathbb{R})$,

 1. si $\mathrm{det}(A) < 0$, es /inestable/;

 2. si $\mathrm{det}(A)>0$,

    1. si $\mathrm{traza}(A) < 0$, es /asintóticamente estables/;

    2. si $\mathrm{traza}(A) > 0$, es /inestable/;

    3. si $\mathrm{traza}(A) = 0$, es /estable/ no /asintóticamente estable/;

 3. si $\mathrm{det}(A) = 0$,

    1. si $\mathrm{traza}(A) > 0$, es /inestable/;

    2. si $\mathrm{traza}(A)<0$, es /estable/ no /asintóticamente estable/;

    3. si $\mathrm{traza}(A) = 0$, es /inestable/.

Podemos resumir en una tabla.

   - /Valores propios reales/.
     
     |----+----+-------+-----+------------------------------------|
     | λ₁ | λ₂ | Traza | Det | Clasificación                      |
     |----+----+-------+-----+------------------------------------|
     | -  | -  | -     | +   | Asintóticamente estable            |
     | +  | -  | ?     | -   | Inestable                          |
     | +  | +  | +     | +   | Inestable                          |
     | 0  | -  | -     | 0   | Estable no asintóticamente estable |
     | +  | 0  | +     | 0   | Inestable                          |
     | 0  | 0  | 0     | 0   | Inestable                          |
     |----+----+-------+-----+------------------------------------|

   - /Valores propios complejos/, deberán ser conjugados.

     |--------+-------+-----+------------------------------------|
     | Re(λ₁) | Traza | Det | Clasificación                      |
     |--------+-------+-----+------------------------------------|
     | -      | -     | +   | Asintóticamente estable            |
     | +      | +     | +   | Inestable                          |
     | 0      | 0     | +   | Estable no asintóticamente estable |
     |--------+-------+-----+------------------------------------|

****** Card: tabla de valores reales                                                                       :drill:
SCHEDULED: <2018-06-18 Mon>
:PROPERTIES:
:ID:       5139a49b-be48-4693-b4df-ab0a77cab754
:DRILL_LAST_INTERVAL: 4.8548
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-13 Wed 19:40]
:END:
Enuncia la tabla de estabilidad con valores propios *reales* para el sistema
bidimiensional lineal con coeficientes constantes $x' = Ax$, para $A \in {\cal M}_2(\mathbb{R})$.

******* Answer

|----+----+-------+-----+------------------------------------|
| λ₁ | λ₂ | Traza | Det | Clasificación                      |
|----+----+-------+-----+------------------------------------|
| -  | -  | -     | +   | Asintóticamente estable            |
| +  | -  | ?     | -   | Inestable                          |
| +  | +  | +     | +   | Inestable                          |
| 0  | -  | -     | 0   | Estable no asintóticamente estable |
| +  | 0  | +     | 0   | Inestable                          |
| 0  | 0  | 0     | 0   | Inestable                          |
|----+----+-------+-----+------------------------------------|

****** Card: tabla de valores complejos                                                                    :drill:
SCHEDULED: <2018-06-17 Sun>
:PROPERTIES:
:ID:       915f92a9-00ac-46c6-a20f-c6b073a4ad80
:DRILL_LAST_INTERVAL: 3.6296
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-13 Wed 10:04]
:END:
Enuncia la tabla de estabilidad con valores propios *complejos* para el sistema
bidimiensional lineal con coeficientes constantes $x' = Ax$, para $A \in {\cal M}_2(\mathbb{R})$.

******* Answer

|--------+-------+-----+------------------------------------|
| Re(λ₁) | Traza | Det | Clasificación                      |
|--------+-------+-----+------------------------------------|
| -      | -     | +   | Asintóticamente estable            |
| +      | +     | +   | Inestable                          |
| 0      | 0     | +   | Estable no asintóticamente estable |
|--------+-------+-----+------------------------------------|

***** Diagrama de Poincaré
Se puede hacer representación de diagramas de fases planos a papel.

**** 6.3. Primer método de Lyapunov
El primer método de Lyapunov estudia la estabilidad de las soluciones
constantes de ecuaciones escalares autónomas.

***** Test de la primera aproximación
Sea un campo $f \in {\cal C}^1(D)$ en un abierto $D \subset \mathbb{R}^d$, con $p \in D$ tal que $f(p)=0$;
sea

\[
\mu = \max\left\{ \mathrm{Re}(\lambda) \mid \lambda \in \sigma(f'(p)) \right\}
\]

entonces

 1. si $\mu <0$, la solución constantemente $p$ es /asintóticamente estable/;

 2. si $\mu > 0$, la solución constantemente $p$ es /inestable/;

 3. si $\mu = 0$, no podemos afirmar nada en general.

****** Proof                                                                                               :extra:
Se puede deducir de los teoremas de estabilidad.

****** Card                                                                                                :drill:
SCHEDULED: <2018-06-17 Sun>
:PROPERTIES:
:ID:       049ee33e-2bb5-4274-ba8c-66a684a2179d
:DRILL_LAST_INTERVAL: 4.2029
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-13 Wed 19:38]
:END:
Aplicar el primer método de Lyapunov (test de la primera aproximación)
a un punto de equilibrio $f(p) = 0$ con un campo $f \in {\cal C}^1(D)$.

******* Answer
Siendo $\mu = \max\left\{ \mathrm{Re}(\lambda) \mid \lambda \in \sigma(f'(p)) \right\}$ entonces la solución constantemente $p$ es

 1. si $\mu <0$, /asintóticamente estable/;

 2. si $\mu > 0$, /inestable/;

 3. si $\mu = 0$, no podemos afirmar nada en general.
***** Corolario. Primera aproximación en el caso bidimensional
Sea un campo $f \in {\cal C}^1(\Omega)$, con $f(p)=0$, entonces la solución constantemente $p$ es

 1. si $\mathrm{det}(f'(p)) > 0$ y $\mathrm{traza}(f'(p)) < 0$, /asintóticamente estable/;
 2. si $\mathrm{det}(f'(p)) < 0$ o $\mathrm{traza}(f'(p))>0$, /inestable/.

****** Card                                                                                                :drill:
SCHEDULED: <2018-06-17 Sun>
:PROPERTIES:
:ID:       f5ad6236-bb1b-462a-8140-7eb72f774ff8
:DRILL_LAST_INTERVAL: 4.4073
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 2.5
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-13 Wed 09:54]
:END:
Aplicar el primer método de Lyapunov (test de la primera aproximación)
a un punto de equilibrio $f(p) = 0$ con un campo $f \in {\cal C}^1(D)$.
*EN EL CASO BIDIMENSIONAL*, $d=2$, de un sistema plano.

En términos de traza y determinante.

******* Answer

 1. si $\mathrm{det}(f'(p)) > 0$ y $\mathrm{traza}(f'(p)) < 0$, es /asintóticamente estable/;

 2. si $\mathrm{det}(f'(p)) < 0$ o $\mathrm{traza}(f'(p))>0$, es /inestable/.

***** Comentario sobre diagramas de Poincaré
La estructura del diagrama de fases se mantiene cuando se realiza una
perturbación pequeña en el entorno de un punto de equilibrio.  Excepto
en un caso, cuando hay $\mu = 0$ y un centro en $p$, la perturbación
puede romper las órbitas.

Hay casos de órbitas interesantes como

 - *órbitas heteroclinas*, conectando dos puntos de equilibrio;
 - *órbitas homoclinas*, conectando un punto de equilibrio consigo mismo;
 - *ciclos límite*, tal que otras órbitas se enrollan en torno a
   ellos.

***** TODO Ejemplo del péndulo
**** 6.4. Segundo método de Lyapunov
Tomamos $f \colon D \to \mathbb{R}^{d}$ campo localmente lipschitziano en un abierto.
Suponemos un punto de equilibrio $f(p)=0$.

***** Teorema 1. Estabilidad de Lyapunov
:PROPERTIES:
:ID:       ee768b41-dd65-4f94-a6bb-a8804729ec36
:END:
Si existe $V \in {\cal C}^1(D)$ tal que

 1. $V$ alcanza en $p$ un mínimo local *estricto*,
 2. $\bV_f$ alcanza en $p$ un máximo local;

entonces $p$ es punto /estable/ de la autónoma $x' = f(x)$.

****** Proof
Nos quedamos en una bola suficientemente pequeña donde se cumplan
todas las propiedades con radio $\varepsilon$ o menor.  Por Weiestrass, $V$ tiene
mínimo $m$ en el borde de este disco. Tomamos un disco menor de radio
$\delta$ donde $V$ sea siempre menor que $m$.

Tomamos $x_0$ en el disco y una solución $\varphi$. Afirmamos $\varphi(t) \in B(p,\varepsilon)$
porque, si no, por Primer Instante tendríamos $T > 0$ con $\varphi(T)$ en
el borde del disco por primera vez. Entonces $y(t) = V(\varphi(t))$ sería
derivable y decreciente, pero entonces llegamos a contradicción

\[
m \leq V(\varphi(T)) = y(T) \leq y(0) = V(x_0) < m.
\]

****** Card                                                                                                :drill:
SCHEDULED: <2018-06-17 Sun>
:PROPERTIES:
:ID:       ad47708f-d84f-471a-99b2-3090ab5d71a7
:DRILL_LAST_INTERVAL: 4.1708
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-13 Wed 09:57]
:END:
Enuncia el Teorema de estabilidad de Lyapunov para la autónoma $x' = f(x)$ con
$f \in {\cal C}^1(D)$ localmente lipschitziana y con $f(p)=0$.

******* Answer
Si existe $V \in {\cal C}^1(D)$ tal que

 1. $V$ alcanza en $p$ un mínimo local *estricto*,
 2. $\bV_f$ alcanza en $p$ un máximo local;

entonces $p$ es punto estable.

***** Corolario de estabilidad no asintótica de Lyapunov
Si existe $V \in {\cal C}^1(D)$ tal que

 1. $V$ alcanza en $p$ un mínimo local *estricto*,
 2. $\bV_f = 0$ en $D$;

entonces $p$ es un punto /estable no asintóticamente estable/ de
la autónoma $x' = f(x)$.

****** Proof
Sabemos que es estable.  Si fuera asintóticamente estable, habría
un $\mu$ tal que en un entorno las soluciones tenderían a $p$.  Pero
ahora $y$ es derivable y constante y entonces por ser asintóticamente
estable se llegaría a contradicción,

\[
V(p) < V(x_0) = y(0) = y(t) = \lim_{t \to \infty} V(X(t,x_0)) = V(p).
\]

****** Card                                                                                                :drill:
SCHEDULED: <2018-06-17 Sun>
:PROPERTIES:
:ID:       a7ac04a2-3db7-44d1-87d6-0901935e0037
:DRILL_LAST_INTERVAL: 3.998
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 2.5
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-13 Wed 09:55]
:END:
Si para un punto de equilibrio de un campo localmente lipschitziano en un
abierto tenemos que existe $V \in {\cal C}^1(D)$ tal que

 1. $V$ alcanza en $p$ un mínimo local *estricto*,
 2. $\bV_f = 0$ en $D$;

¿qué sabemos?

******* Answer
$p$ es un punto /estable no asintóticamente estable/ de
la autónoma $x' = f(x)$.
***** Lema hacia estabilidad asintótica de Lyapunov
:PROPERTIES:
:ID:       93519983-9322-405b-94ef-a471d42b6537
:END:
Si $\varphi \colon (\alpha,+\infty)\to\mathbb{R}^d$ solución y

 1. queda en una bola $\varphi(t) \in \overline{B}(p,R)$, para $t \geq t_0$;
 2. existe $V \in {\cal C}(\overline{B}(p,R))$ con mínimo estricto en $p$;
 3. $\lim_{t \to \infty} V(\varphi(t)) = V(p)$.

Entonces $\lim_{t \to \infty} \varphi(t) = p$.

****** Proof
Suponemos $\varepsilon < R$. Tomamos la corona $C(p,\varepsilon,R) = \left\{ x \in \mathbb{R}^d\mid \varepsilon \leq \norm{x-p} \leq R \right\}$,
donde $V(x) > V(p)$ y por Weiestrass tomamos mínimo $m > V(p)$. Por definición
de límite $V(\varphi(t)) < m$ a partir de algún $t \geq T$, luego $\varphi(t)$ no estará en
la corona. Esto funciona para $\varepsilon$ arbitrario, dándonos el límite.

***** Teorema 2. Estabilidad asintótica de Lyapunov
Si existe $V \in {\cal C}^1(D)$ tal que

 1. $V$ alcanza en $p$ un mínimo local *estricto*,
 2. $\bV_f$ alcanza en $p$ un máximo local *estricto*;

entonces $p$ es punto /asintóticamente estable/ de la autónoma $x' = f(x)$.

****** Proof
Tomamos una bola suficientemente pequeña para aplicar el [[id:ee768b41-dd65-4f94-a6bb-a8804729ec36][Teorema de
Estabilidad]], que nos dará un $\mu$ donde podemos tomar soluciones y tener
estabilidad. Tomamos una solución allí $\varphi(t) = X(t,x_0)$, veremos que
$\lim_{t \to \infty} V(\varphi(t)) = V(p)$ y aplicaremos el [[id:93519983-9322-405b-94ef-a471d42b6537][lema previo]].

Tenemos $y(t) = V(\varphi(t))$ derivable decreciente y acotada inferiormente
por $V(p)$, luego tiene límite $L \geq V(p)$. Si no fuera exactamente $V(p)$,
tendríamos una bola alrededor de $p$ donde $V$ sería menos que $L$. De nuevo
tomamos la corona $C(p,\delta,R) = \left\{ x \in \mathbb{R}^d\mid \delta \leq \norm{x-p} \leq R \right\} \subset D$ y
como $\bV$ es continua tiene un máximo negativo $-M$ en la corona. La solución
se quedaría en la corona.

Pero entonces $y(t)-y(0) \leq -Mt$ integrando, y $y(t) \leq V(x_0)-Mt$, una
función acotada inferiormente queda por debajo de una recta de pendiente
negativa. Imposible.

****** Card                                                                                                :drill:
SCHEDULED: <2018-06-17 Sun>
:PROPERTIES:
:ID:       e007d816-29c8-48d2-99d0-cb2cd3d34f4e
:DRILL_LAST_INTERVAL: 3.6459
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 2.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-13 Wed 09:55]
:END:
Enuncia el Teorema de estabilidad *asintótica* de Lyapunov para la
autónoma $x' = f(x)$ con $f \in {\cal C}^1(D)$ localmente lipschitziana y con $f(p)=0$.

Nótese que es distinto del Teorema de estabilidad de Lyapunov (!).

******* Answer
Si existe $V \in {\cal C}^1(D)$ tal que

 1. $V$ alcanza en $p$ un mínimo local *estricto*,
 2. $\bV_f$ alcanza en $p$ un máximo local *estricto*;

entonces $p$ es punto /asintóticamnete estable/ de la
autónoma $x' = f(x)$.
***** Teorema 3. Inestabilidad de Lyapunov
Si existe $V \in {\cal C}^1(D)$ tal que

 1. $V$ alcanza en $p$ un mínimo local *estricto*,
 2. $\bV_f$ alcanza en $p$ un mínimo local *estricto*;

entonces $p$ es un punto /inestable/ de la
autónoma $x' = f(x)$.

****** Proof
Tomamos un disco donde se cumplan las condiciones.  Si $p$ es
estable habría un $\mu$ tal que si $x_0 \in B(p,\mu)$, entonces
$\omega = +\infty$. Tomamos un $x_0 \in B(p,R) - \left\{ p \right\}$, y como $V(x_0)>V(p)$,
hay un $\delta > 0$ tal que $V(x)<r$ en el disco dado por ese $\delta$.
Definimos $y(t) = V(\varphi(t)) > 0$, creciente y llegamos a que
$X(t,x_0) \in B(p,\delta)$, luego está en la corona $C(p,\delta,R)$.

La corona es compacta y tomamos $M$ máximo de $V$ y $m$ mínimo
de $\bV$. Integrando llegamos a $M \geq r + mt$, donde estaríamos
acotando una recta con pendiente positiva.

****** Card                                                                                                :drill:
SCHEDULED: <2018-06-18 Mon>
:PROPERTIES:
:ID:       852b6852-ecc7-4f88-8fa5-f84211725c7c
:DRILL_LAST_INTERVAL: 5.3094
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-13 Wed 10:24]
:END:
Enuncia el Teorema de *Inestabilidad de Lyapunov* para la
autónoma $x' = f(x)$ con $f \in {\cal C}^1(D)$ localmente lipschitziana
y con $f(p)=0$.

******* Answer
Si existe $V \in {\cal C}^1(D)$ tal que

 1. $V$ alcanza en $p$ un mínimo local *estricto*,
 2. $\bV_f$ alcanza en $p$ un mínimo local *estricto*;

entonces $p$ es un punto /inestable/ de la
autónoma $x' = f(x)$.

***** Teorema 4. Inestabilidad de Chetaev
Si existe $V \in {\cal C}^1(D)$ tal que

 1. existe $x_n \to p$ tal que $V(x_n) > V(p)$,

 2. $\bV_f$ alcanza en $p$ mínimo local *estricto*.

Entonces $p$ es un punto /inestable/ de la autónoma $x' = f(x)$.

****** TODO Proof
****** Card                                                                                                :drill:
SCHEDULED: <2018-06-17 Sun>
:PROPERTIES:
:ID:       f10ab18a-f000-46ba-b74a-dfd64261caae
:DRILL_LAST_INTERVAL: 3.8485
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 1.5
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-13 Wed 19:37]
:END:
Enuncia el Teorema de *Inestabilidad de Chetaev* para la
autónoma $x' = f(x)$ con $f \in {\cal C}^1(D)$ localmente lipschitziana
y con $f(p)=0$.

******* Answer
Si existe $V \in {\cal C}^1(D)$ tal que

 1. existe $x_n \to p$ tal que $V(x_n) > V(p)$,

 2. $\bV_f$ alcanza en $p$ mínimo local *estricto* .

Entonces $p$ es un punto /inestable/ de la autónoma $x' = f(x)$.
***** Elección de funciones de Lyapunov

 - Buscar funciones con variables separadas. $V(x) = V(x_1) + \dots + V(x_n)$.
 - Usar funcionales energía en ecuaciones que provienen de EDOs
   segundo orden.
 - $V(x,y) = x^2+y^2$ para Lyapunov.
 - $V(x,y) = x^2-y^2$,  $V(x,y) = -x^2+y^2$, $V(x,y) = xy$ para Chetaev.
 - Forma cuadrática más general $V(x,y) = ax^2 + bxy + cy^2$.
 - Distancia a un punto, $V(x) = \norm{x-p}^2$.
***** Ejemplos
****** Ejemplo: ecuación de Duffing en el segundo método
****** Ejemplo de examen
*** Ejercicios
# La mayoría en papel

**** Matemapli
***** 19 de marzo                                                                                           :drill:
SCHEDULED: <2018-07-07 Sat>
:PROPERTIES:
:ID:       dc14004e-7a0a-422f-88f7-d97989f41784
:DRILL_LAST_INTERVAL: 7.6901
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 2.667
:DRILL_EASE: 2.46
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-29 Fri 17:48]
:END:
La sucesión $f_n \colon \mathbb{R} \to \mathbb{R}$ dada por

\[
f_n(t) = \frac{1}{n}\cos(n^2t)
\]

¿tiene alguna parcial que converja puntualmente hacia una función
continua $f \colon \mathbb{R} \to \mathbb{R}$?

****** Answer
Sí, trivialmente se calcula punto a punto como la constante $0$.

***** 20 de marzo                                                                                           :drill:
SCHEDULED: <2018-06-18 Mon>
:PROPERTIES:
:ID:       e18b2038-e1a0-4770-aa02-0e7554a4ffc4
:DRILL_LAST_INTERVAL: 4.8236
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-13 Wed 11:30]
:END:
Por qué es cierto

\[
\lim_{n \to \infty} \int_0^1 \frac{x}{e^{x/n} +x^2}\,dx = 
\int_0^1 \frac{x}{1 +x^2}\,dx
\]

****** Answer
Hay convergencia puntual de la sucesión y están uniformemente
acotadas, eso basta para asegurar que conmuta límite e integral.

***** 16 de abril                                                                                           :drill:
SCHEDULED: <2018-06-17 Sun>
:PROPERTIES:
:ID:       8ce0d643-faa5-4e08-9fbd-58c157ca5429
:DRILL_LAST_INTERVAL: 4.2214
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-13 Wed 09:58]
:END:
Cuántas órbitas tiene

\[
x' = (x^2 + 2)(x-1)(x-3)
\]

****** Answer
5. Nota que el polinomio tiene dos raíces.

***** 24 de abril                                                                                           :drill:
SCHEDULED: <2018-06-17 Sun>
:PROPERTIES:
:ID:       c2a28d7e-b184-4bb5-8cc9-0f7b646b8404
:DRILL_LAST_INTERVAL: 4.1906
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-13 Wed 11:28]
:END:
Por qué sabemos que todas las soluciones de

\[
x'' + x^2x' + \mathrm{senh}(x) = 0
\]

¿están acotadas en el futuro?

****** Answer
Sabemos que $\mathrm{cosh}$ es coerciva y tenemos que $x^3/3$
es del mismo signo que $\mathrm{senh}$.

**** Relación 1 [6/6]
***** DONE Ejercicio 1
#+begin_statement
Calcula una solución maximal del PVI

\[\left.\begin{aligned}
x' &= x^2 \\
x(t_0) &= x_0
\end{aligned}\right\}
\]
#+end_statement

Calculamos usando [[*Condiciones para la unicidad local en variables separadas][variables separadas]].

 * En el caso $x_0 = 0$, tenemos la solución constante $0$ en $\mathbb{R}$.
   Es trivialmente maximal por estar definida en todo $\mathbb{R}$.

 * En el caso $x_0 \neq 0$, calculamos
   
   \[
   A(t) = \int_{t_0}^tds = t - t_0, \qquad
   G(t) = \int_{x_0}^x \frac{1}{z^2} \;dz = \frac{-1}{x} + \frac{1}{x_0},
   \]
   
   e igualando obtenemos

   \[
   x(t) = \frac{1}{\frac{1}{x_0} + t_0 - t}
   \]
  
   que sólo da problemas de definición en $t = 1/x_0 + t_0$. Cuando
   $x_0 > 0$, tenemos $t_0 \in (-\infty, 1/x_0 + t_0)$; y cuando $x_0 < 0$, tenemos
   que $t_0 \in (1/x_0 + t_0, +\infty)$. Elegimos el intervalo adecuado en cada
   caso. Tenemos maximalidad porque la función explota en
   \[
   \lim_{t \to (1/x_0 + t_0)} \varphi(t) = +\infty.
   \]
***** DONE Ejercicio 2
***** DONE Ejercicio 3
***** DONE Ejercicio 4
***** DONE Ejercicio 6
***** DONE Ejercicio 7
**** Relación 2 [4/5]
***** DONE Ejercicio 1
***** DONE Ejercicio 2
***** TODO Ejercicio 3
***** DONE Ejercicio 4
***** DONE Ejercicio 5
**** Relación 3 [4/6]
***** DONE Ejercicio 1
***** DONE Ejercicio 2
***** TODO Ejercicio 3
***** DONE Ejercicio 4
***** DONE Ejercicio 5
***** TODO Ejercicio 6
**** Relación 4 [4/5]
***** DONE Ejercicio 1
***** TODO Ejercicio 2
***** DONE Ejercicio 3
***** DONE Ejercicio 4
***** DONE Ejercicio 5
**** Relación 5 [2/3]
***** DONE Ejercicio 1 (crecimiento supralineal)
Si $\varphi$ es solución maximal y existe $f(t,x) \geq mx^p$ para $m,p,x_0 >0$;
entonces explota en tiempo finito (crecimiento supralineal).

Si $\varphi$ es solución maximal y existe $f(t,x) \leq -m\abs{x}^p$ con $m,p>0$
pero $x_0 < 0$; entonces explota en tiempo finito.

****** Card                                                                                              :nodrill:
SCHEDULED: <2018-07-09 Mon>
:PROPERTIES:
:ID:       da96001f-dc6f-4219-b3b4-c05bd10b7273
:DRILL_LAST_INTERVAL: 10.1514
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 2.75
:DRILL_EASE: 2.22
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-29 Fri 17:46]
:END:
Qué es y qué nos da el crecimiento supralineal de una ecuación
diferencial.

******* Answer
Si $f(t,x) \geq mx^p$ para $m,p >0$; entonces la solución maximal
empezando en $x_0 > 0$ explota en tiempo finito.

***** DONE Ejercicio 2
***** TODO Ejercicio 3
**** Relación 6 [6/8]
***** DONE Ejercicio 1.a
***** TODO Ejercicio 1.b
***** TODO Ejercicio 2
***** DONE Ejercicio 3
***** DONE Ejercicio 4
***** DONE Ejercicio 5
***** DONE Ejercicio 6
***** DONE Ejercicio 7
** Modelos matemáticos II
http://www.ugr.es/~jjmnieto/docencia.html

*** 0. Preliminares
**** Identidades trigonométricas
Las identidades trigonométricas

\[\left\{\begin{array}{l}
\sin(x)^2 + \cos(x)^2 = 1 \\
\sin(a+b) = \sin(a)\cos(b) + \cos(a)\sin(b) \\
\cos(a+b) = \cos(a)\cos(b) - \sin(a)\sin(b)
\end{array}\right\}\]

son [[id:893398fe-a78e-45a4-b0dd-d4e36bc98d78][suficientes]] para caracterizar al seno y al coseno.

**** Fórmula de DeMoivre
Sabemos que

\[
\left( \cos x + i \sin x \right)^n = \cos(nx) + i\sin(nx)
\]

puede ser expresada usando que

\[
e^{i\theta} = \cos \theta + i \sin \theta
\]

**** Método de variación de constantes
**** Método de coeficientes indeterminados
**** Ecuación diferencial de Euler
**** Teorema de Fubini
**** Teorema de Tonelli
**** Norma en Lp                                                                                             :drill:
SCHEDULED: <2018-07-19 Thu>
:PROPERTIES:
:ID:       ceb95e11-f3e9-4928-9690-7f625454045f
:DRILL_LAST_INTERVAL: 42.6818
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.46
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-06 Wed 12:13]
:END:
Describe la norma en $L^p(S)$,

\[
\norm{f}_p
\]

***** Norma

\[
\norm{f}_p = \left(\int_S \abs{f^p} \,d\mu \right)^{1/p} < \infty
\]

**** Lp cuando 0 < p < 1                                                                                     :drill:
SCHEDULED: <2018-06-27 Wed>
:PROPERTIES:
:ID:       c6c30efb-81ce-4d04-8926-767c1685ca97
:DRILL_LAST_INTERVAL: 33.5873
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.667
:DRILL_EASE: 2.7
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-05-24 Thu 23:46]
:END:
¿Qué ocurre con $L^p$ cuando $0 < p < 1$? 

***** Respuesta
El operador

\[
N_p(f) = \int_S \abs{f}^p \,d\mu < \infty
\]

no es una norma, es sólo una quasinorma.

**** Teorema de Riesz
Sea $H$ un espacio de Hilbert. Para todo $f \in H^{\ast}$ existe un
único $v \in H$ tal que $f(x) = \langle x,v \rangle$ para todo $x \in H$.
Además, $\|f\| = \|v\|$.

**** Teorema de Lax-Milgram
Sea $H$ un espacio de Hilbert y sea $a \colon H \times H \to \mathbb{R}$ una
forma bilineal tal que
 
 1. es /continua/, existe $C$ tal que $| a(x,y) | \leq C\|x\|\|y\|$;
 2. y es /coerciva/, existe $\alpha$ tal que $|a(x,x)| \geq \alpha\|x\|^{2}$.

Entonces, para todo $f \in H^{\ast}$ existe un único $y_0\in H$ tal que
$a(x,y_0) = f(x)$ para cualquier $x \in H$.

**** Tipos de ecuación diferencial ordinaria
Nombres de las ecuaciones

 * Son *ordinarias* aquellas que no involucran derivadas parciales.

 * Son *autónomas* aquellas que no dependen de $x$ directamente.

 * Son *lineales* si la derivada mayor depende linealmente de las demás.
   $a_0(x) y(x) + \dots + a_n(x) y^{(n)}(x) + b(x) = 0$. Dentro de las lineales, las
   lineales con coeficientes constantes se resuelven fácilmente.

Tipos explícitos de ecuación

 * Lineal de primer orden, homogénea: $y' + P(x)y = 0$.

 * Lineal de primer orden, no homogénea: $y' + P(x)y = Q(x)$.

 * [[https://en.wikipedia.org/wiki/Cauchy%25E2%2580%2593Euler_equation][Ecuación de Euler]]: $a_nx^ny^{(n)}(x) + \dots + a_0y(x) = 0$.

 * [[https://en.wikipedia.org/wiki/Bernoulli_differential_equation][Ecuación de Bernoulli]]: $y' + P(x)y = Q(x)y^n$

**** Cambio de variables en varias variables

\[
\int_{\varphi(U)}f(x)\,dx = \int_{U} f(\varphi(x)) \abs{\mathrm{Jac}_{\varphi}(x)}\,dx
\]

**** Integración en polares
:PROPERTIES:
:ID:       8b7c51f7-5499-4cd3-a1c6-cab635bd0015
:END:
Para integrar en una bola vectores $x \in \mathbb{R}^N$, podemos tomar
el cambio de variables

 * $r = |x|$

 * $\theta = x/|x|$

 * $dx = r^{N-1}\,drd\theta$

**** TODO Lineales
***** Forma autoadjunta de una ecuación lineal
Una ecuación lineal de orden 2 para $[x_0,x_1]$ es de la forma

\[
y''(x) + a(x)y'(x) + b(x)y(x) = c(x).
\]

Si multiplicamos por $P(x) = e^{\int_{x_0}^x a(s) \; ds}$, obtenemos la ecuación

\[
P(x)y''(x) + P(x)a(x)y'(x) + P(x)b(x)y(x) = P(x)c(x)
\]

que puede escribirse uniendo los dos primeros sumandos como

\[
\left( P(x)y'(x) \right)' + Q(x)y(x) = R(x)
\]

lo que llamamos su *forma autoadjunta*.

***** Forma variacional
El funcional

\[
{\cal F}[y] = \int_{x_0}^{x_1} \frac{P(y')^2}{2} - Q\frac{y^2}{2} + Ry \;dx
\]

tiene como ecuación de Euler-Lagrange asociada a la forma
autoadjunta de una ecuación lineal

\[
(Py')' + (-Qy + R) = 0.
\]

***** De problema de contorno a coordenadas homogéneas
Sea un problema de contorno y condiciones de contorno Dirichlet no
homogéneas.

\[\left\{\begin{array}{l}
(Py')' + Qy = R \\
y(x_0) = y_0 \\
y(x_1) = y_1
\end{array}\]

Podemos obtener un problema de contorno con coordenadas homogéneas.

****** Construcción
Proponemos un cambio de variables $z(x) = y(x) - (Ax + B)$ y buscamos
$A$, $B$ y $\widetilde R$ tales que

\[\left\{\begin{array}{l}
(Pz')' + Qz = {\widetilde R} \\
z(x_0) = 0 \\
z(x_1) = 0
\end{array}\]

Lo que nos da resolviendo el sistema lineal dado por las condiciones
de contorno

\[
B = \frac{y_1x_0-y_0x_1}{x_0-x_1}
\]

\[
A = \frac{y_1-y_0}{x_1-x_0}
\]

Luego el cambio de variable correcto es

\[
z(x) = y(x) + \left( \frac{y_1(x-x_0) + y_0(x-x_1)}{x_0-x_1} \right).
\]

Que nos lleva al sustituir en la ecuación inicial a tener
${\widetilde R} = R - P' \cdot A - Q \cdot (Ax + B)$.

**** CARDS
***** Ecuación de Euler: forma                                                                              :drill:
SCHEDULED: <2018-08-05 Sun>
:PROPERTIES:
:DRILL_CARD_TYPE: twosided
:ID:       d8bb9dc5-ce37-4775-a7d6-5faae2b8da03
:DRILL_LAST_INTERVAL: 59.9578
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 6
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.333
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-06 Wed 12:19]
:END:

Forma y técnica de resolución de una Ecuación de Euler.

****** Forma

\[ a_nx^ny^{(n)}(x) + \dots + a_0y(x) = 0
\]

****** Técnica de resolución
Se puede aplicar sustitución $x =e^s$, $z(s) =y(x)$ para reducirla a
una lineal con coeficientes constantes, teniendo cuidado con los
coeficientes, que cambian.

***** Integral del seno al cuadrado                                                                         :drill:
SCHEDULED: <2018-08-05 Sun>
:PROPERTIES:
:ID:       a5c02ef6-79c6-4b32-943b-dd064732749e
:DRILL_LAST_INTERVAL: 83.7282
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.75
:DRILL_EASE: 2.8
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-05-13 Sun 22:21]
:END:
Encontrar y comprobar primitivas de

\[
\int \sin^2(x)\,dx
\]

****** Primitiva

\[
\frac{1}{2}(x - \sin(x)\cos(x))
\]

Puede obtenerse usando

\[
\sin^2x = \frac{1-\cos(2x)}{2}.
\]

*** 1. Motivación y fundamentos del cálculo variacional
*** 2. Cálculo de variaciones
**** 2.1. Teorema 1. Lema fundamental del cálculo de variaciones
:PROPERTIES:
:ID:       652bdddb-0853-4a9a-8060-28a730928816
:END:
Para $f \colon {\cal C}([a,b], \mathbb{R})$ equivalen

 1. $f \equiv 0$,
 2. $\forall \phi \in {\cal C}^1_0(a,b)\colon \int_a^b f\phi = 0$.

***** Proof
Si tuviéramos en algún punto $f(x_0) > 0$; por conservación del
signo, tenemos un entorno de $x_0$ contenido en $(a,b)$ donde la
función es estrictamente positiva, sea $(x_0-\varepsilon,x_0+\varepsilon)$. Tomamos

\[\phi(x) = \left\{\begin{array}{lr}
e^{\frac{1}{(x-x_0-\varepsilon)(x-x_0+\varepsilon)}}, & 
\mbox{ si } x \in (x_0-\varepsilon, x_0 + \varepsilon), \\
0, & \mbox{ en otro caso.}
\end{array}\right.\]

Esta función es no analítica pero continua con derivadas continuas.
Por contradicción, $f = 0$.

***** Card: enunciado                                                                                       :drill:
SCHEDULED: <2018-08-13 Mon>
:PROPERTIES:
:ID:       5184345f-67cf-402b-8732-6baf557e13b6
:DRILL_LAST_INTERVAL: 87.1379
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 5
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.8
:DRILL_EASE: 2.66
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-05-18 Fri 22:14]
:END:
Enuncia el lema fundamental del cálculo de variaciones para una
$f \colon [a,b] \to \mathbb{R}$. ¿Cuál es la idea de la demostración?

****** Enunciado
Para $f \colon [a,b] \to \mathbb{R}$ *continua* equivalen

 1. $f(x) = 0$ para todo $x \in (a,b)$;
 2. $\int_a^b f(x)\phi(x)\,dx = 0$ para toda $\phi \in {\cal C}_0^\infty(a,b)$.

****** Idea de demostración
La función siguiente ese infinitamente diferenciable pero
nos permite aprovechar que un punto de $f$ no fuera cero
para integrar por conservación de signo sólo esa zona.

\[
\phi(x) = e^{\frac{1}{(x-x_0-\varepsilon)(x-x_0+\varepsilon)}}
\]

**** 2.2. Ecuación de Euler-Lagrange
***** Teorema 2. Ecuación de Euler-Lagrange
:PROPERTIES:
:ID:       a197ab8c-e2fa-4327-a265-1ece45f66c23
:END:
Para $F(x,y,p) \colon [x_0,x_1] \times \Omega \to \mathbb{R}$, con $\Omega \subseteq \mathbb{R}^2$ dominio, dos veces
derivable en $p$ y en $y$, consideramos

\[
{\cal F}[y] = \int_{x_0}^{x_1} F(x,y(x),y'(x))\,dx,
\]

sobre

\[
{\cal D} = \left\{ \begin{array}{c} 
y \in {\cal C}^1(x_0,x_1), \\
y(x_0) = y_0, \\
y(x_1) = y_1, \\
\forall x \in [x_0,x_1]: (y(x),y'(x)) \in \Omega.
\end{array}\right\}
\]

Cualquier $\overline{y} \in {\cal D} \cap {\cal C}^2(x_0,x_1)$ (*extremal*) mínimo de ${\cal F}$ sobre ${\cal D}$
verifica

\[
F_y - \dv{}{x}F_p = 0.
\]

****** Proof
:PROPERTIES:
:ID:       d1ff00ca-9b61-4a83-9016-35f8fca5866a
:END:
Dado $y \in {\cal D}$, para cualquier $\phi \in {\cal C}^1_0(x_0,x_1)$ sabemos por compacidad
de $(x_0,x_1)$ que $\phi$ está acotado y podemos tomar un $s$ suficientemente
pequeño para que $y + s\phi \in {\cal D}$, cumpliendo condiciones de contorno.

Definimos $g(s) = {\cal F}[\oy + s\phi]$ y usando que $\oy$ es mínimo y su
derivabilidad,

\[\begin{aligned}
0 = g'(0) &= 
\dv{}{s} \int_{x_0}^{x_1}F(x,\oy + s\phi(x), \oy'(x)+s\phi'(x))\,dx \\&=
\int_{x_0}^{x_1} \dv{}{s} F(x,\oy + s\phi(x), \oy'(x)+s\phi'(x))\,dx \\&=
\int_{x_0}^{x_1} F_y(\dots)\phi(x) + F_p(\dots)\phi'(x) \,dx \\&=
\int_{x_0}^{x_1} F_y(\dots)\phi(x) \,dx + \int_{x_0}^{x_1}F_p(\dots)\phi'(x) \,dx \\&=
\int_{x_0}^{x_1} F_y(\dots)\phi(x) \,dx + \cancel{\left[ \phi(x) F_p(\dots) \right]^{x_1}_{x_0}} - \int_{x_0}^{x_1} \dv{}{x}F_p(\dots)\phi(x) \,dx
\end{aligned}\]

Habiendo usado la integrabilidad de $F$ y $\dv{}{s}F$, la regla de la cadena
multivariable, el hecho de que $\phi$ se anula en $x_0,x_1$ e integración por
partes. Aquí aplicamos el [[id:652bdddb-0853-4a9a-8060-28a730928816][lema fundamental]].

****** Card                                                                                                :drill:
SCHEDULED: <2018-07-08 Sun>
:PROPERTIES:
:ID:       86b89cab-3163-477b-bdad-49a3d129ef5e
:DRILL_LAST_INTERVAL: 11.2281
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 5.0
:DRILL_EASE: 2.7
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-27 Wed 13:21]
:END:
Ecuación de Euler-Lagrange.

******* Answer
Todo $y$ extremal del funcional

\[
{\cal F}[y] = \int_{x_0}^{x_1} F(x,y(x),y'(x))\,dx,
\]

verifica

\[
F_y - \dv{}{x}F_p = 0.
\]

****** Card: derivabilidad para Euler-Lagrange                                                             :drill:
SCHEDULED: <2018-09-08 Sat>
:PROPERTIES:
:ID:       cd2cc1ba-0d03-4f95-871f-a4b27229bf39
:DRILL_LAST_INTERVAL: 106.823
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 8
:DRILL_FAILURE_COUNT: 2
:DRILL_AVERAGE_QUALITY: 3.875
:DRILL_EASE: 3.0
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-05-24 Thu 23:57]
:END:
Condiciones de derivabilidad de la $F$ para Euler-Lagrange.

******* Características
Dos veces derivable en $p$ y en $y$.

****** Card: Dominio de Euler-Lagrange                                                                     :leech:
SCHEDULED: <2018-07-10 Tue>
:PROPERTIES:
:ID:       7c4a6835-9dea-4a2a-a944-4ed5540545ee
:DRILL_LAST_INTERVAL: 66.2476
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 5
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.6
:DRILL_EASE: 2.46
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-05-05 Sat 20:07]
:END:
${\cal D}$ del funcional al que se aplica Euler-Lagrange.

******* Dominio

\[{\cal D} = \left\{ \begin{array}{c} 
y \in {\cal C}^1(x_0,x_1) \\
y(x_0) = y_0 \\
y(x_1) = y_1 \\
\forall x \in [x_0,x_1]: (y(x),y'(x)) \in \Omega
\end{array}\right\}\]

***** Teorema 3. Condiciones para conjuntos sin condiciones de contorno
:PROPERTIES:
:ID:       094690c8-7f15-424a-89aa-126400e3d0c6
:END:
Si no tenemos condiciones de contorno, el extremal cumple

\[
F_p(x_0,\oy(x_0),\oy'(x_0)) = 0 = F_p(x_1,\oy(x_1),\oy'(x_1).
\]

Cuando sólo una viene fijada, la otra puede fijarse también así

****** Proof
La [[id:d1ff00ca-9b61-4a83-9016-35f8fca5866a][demostración]] de Euler-Lagrange puede repetirse para cualquier
$\phi \in {\cal C}^1(x_0,x_1)$ para obtener

\[
0 = 
\int_{x_0}^{x_1} F_y(\dots)\phi(x) \,dx + 
\left[ \phi(x) F_p(\dots) \right]^{x_1}_{x_0} - 
\int_{x_0}^{x_1} \dv{}{x}F_p(\dots)\phi(x) \,dx.
\]

Como esto se cumple en particular para $\phi \in {\cal C}^1_0(x_0,x_1)$, estamos en
las condiciones del teorema anterior y se tiene la ecuación de
Euler-Lagrange. Pero entonces

\[\left[ \phi(x) F_p(\dots) \right]^{x_1}_{x_0} = 0\]

y tomando en particular funciones cumpliendo $\phi(x_j) = \delta_{ij}$ para
$i,j = 0,1$ tenemos las condiciones de contorno buscadas.

****** Card: Condiciones de contorno para problemas sin ellas                                              :drill:
SCHEDULED: <2018-07-30 Mon>
:PROPERTIES:
:ID:       742721a0-1edb-47c7-aabc-bb203354d4bc
:DRILL_LAST_INTERVAL: 81.1591
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 6
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.833
:DRILL_EASE: 2.8
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-05-10 Thu 23:44]
:END:
¿Qué condiciones de contorno verifica un extremal si no vienen dadas?

******* Condiciones de contorno

\[
F_p(x_0,\oy(x_0),\oy'(x_0)) = 0 = F_p(x_1,\oy(x_1),\oy'(x_1).
\]

******* Extra
Si viene dada solo una de ellas, puede fijarse la otra así.

***** Teorema 4. Euler-Lagrange para F independiente de y
En [[id:a197ab8c-e2fa-4327-a265-1ece45f66c23][Euler-Lagrange]], si $F_y = 0$, el extremal cumple

\[
F_p = \mathrm{cte.}
\]

****** Proof
Trivialmente integrando en la ecuación de Euler-Lagrange.

****** Card: Euler-Lagrange para F independiente de y                                                      :drill:
SCHEDULED: <2018-08-01 Wed>
:PROPERTIES:
:ID:       b5ac284c-b322-4cf6-996f-c70db55e891b
:DRILL_LAST_INTERVAL: 79.9878
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 7
:DRILL_FAILURE_COUNT: 2
:DRILL_AVERAGE_QUALITY: 3.571
:DRILL_EASE: 2.9
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-05-13 Sun 22:19]
:END:
Reescribe Euler-Lagrange sabiendo $F_y = 0$.

******* Euler-Lagrange

\[
F_p(x,\oy'(x)) = \mathrm{cte.}
\]

***** Teorema 5. Euler-Lagrange para F independiente de x
En [[id:a197ab8c-e2fa-4327-a265-1ece45f66c23][Euler-Lagrange]], si $F_ x= 0$, el extremal cumple

\[
F - y'F_p = \mathrm{cte.}
\] 

****** Proof
Tenemos que, aplicando [[id:a197ab8c-e2fa-4327-a265-1ece45f66c23][Euler-Lagrange]]

\[
\dv{}{x}\left( F - y'F_p \right) = y'\left(F_y - \dv{}{x}F_p\right) = 0.
\]

****** Card: Euler-Lagrange para F independiente de x                                                      :drill:
SCHEDULED: <2018-07-13 Fri>
:PROPERTIES:
:ID:       22e8b4d8-c306-4927-9a7f-159725999cbd
:DRILL_LAST_INTERVAL: 63.7384
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 10
:DRILL_FAILURE_COUNT: 3
:DRILL_AVERAGE_QUALITY: 2.65
:DRILL_EASE: 2.32
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-05-10 Thu 23:44]
:END:
Reescribe Euler-Lagrange sabiendo $F_x = 0$.

******* Euler-Lagrange

\[
F - y'F_p = \mathrm{cte.}
\]

**** 2.3. Ejemplos
***** Oscilador armónico
***** Longitud mínima
***** Longitud mínima usando un caso particular
***** Superficie minimal de revolución
****** Card                                                                                                :drill:
SCHEDULED: <2018-07-06 Fri>
:PROPERTIES:
:ID:       3c7fbd05-0ff4-4169-b50b-a0cf2e328b71
:DRILL_LAST_INTERVAL: 32.3061
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.333
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-04 Mon 22:18]
:END:
Solución de 

\[
y(x) = c \sqrt{1 + y'(x)^2}
\]

******* Solución
\[
y(x) = c_0 \cosh \left( \frac{x-k}{c_0}  \right)
\]

**** 2.4. Convexidad
***** Convexidad
$\Omega \subseteq V$ es *convexo* cuando

\[
\forall x,y \in \Omega: \forall 0 \leq t \leq 1:\quad tx + (1-t)y \in \Omega.
\]

$f \colon \Omega \to \mathbb{R}$ es *convexa* cuando cumple la desigualdad de Jensen,

\[\forall x,y \in \Omega: \forall 0 \leq t \leq 1:\quad
f(tx + (1-t)y) \leq tf(x) + (1-t)f(y).
\]

****** Card                                                                                                :drill:
SCHEDULED: <2018-07-23 Mon>
:PROPERTIES:
:ID:       a8a0d061-c728-48f3-a08b-93a1b1b625f8
:DRILL_LAST_INTERVAL: 46.8681
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.667
:DRILL_EASE: 2.7
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-06 Wed 12:07]
:END:
Desigualdad de Jensen

******* Desigualdad

\[
f(tx + (1-t)y) \leq tf(x) + (1-t)f(y).
\]

***** Teorema 6. Existencia de mínimo con convexidad
:PROPERTIES:
:ID:       89c9e4a0-cc09-4962-b3e5-8fc1cfbb0c4e
:END:
En [[id:a197ab8c-e2fa-4327-a265-1ece45f66c23][Euler-Lagrange]], si ${\cal D}$ y ${\cal F}$ convexos, extremal es mínimo global.

****** Proof
Dado $z \in {\cal D}$, llamamos $\phi =z-y$ y tenemos

\[
{\cal F}[\oy - t\phi] \leq t{\cal F}[z] + (1-t){\cal F}[\oy].
\]

Tomando límites y usando que es extremal,

\[
0 = \dv{t} \left( {\cal F}[\oy + t\phi] \right) =
\lim_{t \to 0}\frac{{\cal F}[\oy-t\phi] - {\cal F}[\oy]}{t} \leq
{\cal F}[z] - {\cal F}[y].
\]

***** Teorema 7. Los mínimos locales son globales con convexidad
:PROPERTIES:
:ID:       c46055cc-5d8b-4772-8af3-48057d7e45a4
:END:
En [[id:a197ab8c-e2fa-4327-a265-1ece45f66c23][Euler-Lagrange]], si ${\cal F}$ y ${\cal D}$ convexos, un mínimo local (estricto) 
es mínimo global (estricto).

****** Proof
Sea $\oy$ mínimo local, $\forall \|z - \oy\| \leq \varepsilon\colon {\cal F}[\oy] \leq {\cal F}[z]$. Para $v \in {\cal D}$ tomamos $t_0 = \frac{\varepsilon}{\| v - \oy\|}$

\[
{\cal F}[\oy] \leq
{\cal F}[t_0v + (1 - t_0)\oy] \leq t_0{\cal F}[v] + (1-t_0){\cal F}[\oy],
\]

teniendo $t_0 {\cal F}[\oy] \leq t_0{\cal F}[v]$.

***** Teorema 8. Condición de convexidad
:PROPERTIES:
:ID:       4d623017-26e1-4e3e-82ec-325f4b6c0b38
:END:
En [[id:a197ab8c-e2fa-4327-a265-1ece45f66c23][Euler-Lagrange]], si $F$ convexo en $\Omega$ convexo, ${\cal F}$ convexo.

****** TODO No es condición necesaria
Tenemos $F = y^2(1-p)$ no convexa, pero su ${\cal F}$ es convexo.

****** Proof
Usando linealidad y acotación de la integral tenemos

\[\begin{aligned}
{\cal F}[\lambda y + (1-\lambda) z] &=
\int_{x_0}^{x_1} F\Big(x,\lambda y + (1-\lambda)z, \lambda y' + (1-\lambda)z'\Big)\,dx \\&\leq
\lambda \int_{x_0}^{x_1} F\Big(x,y,y'\Big)\,dx + (1 - \lambda)\int_{x_0}^{x_1} F\Big(x,z,z'\Big)\,dx.
\end{aligned}\]

*** 3. Cálculo de extremales: problemas de contorno
**** TODO Euler-Lagrange con segunda derivada
:PROPERTIES:
:ID:       1d1082d8-cb7a-4e0c-868c-5d734cd8949b
:END:
**** 3.1. Existencia y unicidad
***** Problema de contorno
Un *problema de contorno* consiste encontrar una solución
de una EDO (o EDP) en un intervalo $[x_0,x_1]$ (o dominio $\Omega$)
verificando condiciones en $x_0,x_1$ (o en $\partial\Omega$).

***** TODO Ejemplos
**** 3.2. Tipos de condiciones de contorno
Tipos de condiciones de contorno

 * Dirichlet:            $y(x_0) = y_0$, $y(x_1) = y_1$.

 * Dirichlet homogéneas: $y(x_0) = 0$, $y(x_1) = 0$.

 * Newmann:              $y'(x_0) = z_0$, $y'(x_1) = z_1$.

 * Newmann homogéneas:   $y'(x_0) = 0$, $y'(x_1) = 0$.

 * Periódicas:           $y(x_0) = y(x_1)$, $y'(x_0) = y'(x_1)$.

**** 3.3. El problema de la viga
***** Ecuación de la viga
:PROPERTIES:
:ID:       afb30645-46b6-4087-bf43-bf765d53719b
:END:
La *ecuación de la viga*, para $M > 0$, constante $N$ y
densidad $f(x)$ es

\[
Mu'''' + Nu'' = f.
\]

****** Tipos de sujección de una viga
Existen los siguientes tipos de sujección:

 * Empotramiento:   $u(0)=0$,  $u'(0) = 0$.
 * Apoyo:           $u(0)=0$,  $u''(0) = 0$.
 * Voladizo:        $u''(0) = 0$, $u'''(0) = 0$.

****** Card: ecuación                                                                                      :drill:
SCHEDULED: <2018-08-09 Thu>
:PROPERTIES:
:ID:       d370b290-0054-4558-ac81-0da896782fbe
:DRILL_LAST_INTERVAL: 76.8573
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.5
:DRILL_EASE: 2.66
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-05-24 Thu 23:54]
:END:
Cuál es la ecuación diferencial del problema de la viga.

******* Ecuación diferencial

\[
Mu''''(x) + Nu''(x) = f(x)
\]

constantes $M,N$ y función $f$. Se complementa con cuatro condiciones
de contorno, según sujeción. Con otra notación,

\[
Mu'''' + Nu'' = f
\]

***** Problema variacional de la viga

\[
{\cal F}[u] = \int_0^L \left( \frac{M}{2}(u''(x))^2 - \frac{N}{2}(u'(x))^2 - f(x)u(x) \right)\,dx.
\]

Aplicando [[id:1d1082d8-cb7a-4e0c-868c-5d734cd8949b][Euler-Lagrange en la segunda derivada]] se llega a la
[[id:afb30645-46b6-4087-bf43-bf765d53719b][ecuación de la viga]].

****** Card: forma variacional                                                                             :drill:
SCHEDULED: <2018-06-21 Thu>
:PROPERTIES:
:ID:       6d3c077e-63c9-4376-b35a-4b5158236b39
:DRILL_LAST_INTERVAL: 28.0398
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 12
:DRILL_FAILURE_COUNT: 6
:DRILL_AVERAGE_QUALITY: 2.75
:DRILL_EASE: 2.7
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-05-24 Thu 23:46]
:END:
Da el funcional a minimizar en el problema de la viga.

******* Funcional

\[
{\cal F}[u] = \int_0^L \left(\frac{M}{2}(u'')^2 - \frac{N}{2}(u')^2 - f(x) \right)\,dx,
\]

con cuatro condiciones de contorno para la $u$.

****** Card: obtención de la ecuación                                                                    :nodrill:
SCHEDULED: <2018-06-11 Mon>
:PROPERTIES:
:ID:       df2d59fc-26e4-43e7-b955-e1251a820cdb
:DRILL_LAST_INTERVAL: 29.0223
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 9
:DRILL_FAILURE_COUNT: 3
:DRILL_AVERAGE_QUALITY: 3.111
:DRILL_EASE: 2.66
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-05-13 Sun 22:20]
:END:
En el problema de la viga, dar $F$ y Euler-Lagrange para segunda
derivada.

******* Función
\[
F(x,y,p,q) = \frac{M}{2}q^2 - \frac{N}{2}p^2 - f(x)y.
\]

******* Euler-Lagrange en segunda derivada

\[
F_y - 
\dv{}{x}F_p + 
\dv[2]{}{x}F_{q} = 0.
\]

******* Ecuación final

\[
Mu''''(x) + Nu''(x) = f(x).
\]

**** 3.4. Forma autoadjunta de algunos problemas de contorno
Cualquier EDO lineal de segundo orden

\[
y''(x) + a(x)y'(x) + b(x)y(x) = c(x)
\]

puede escribirse en *forma autoadjunta* o *forma de Sturm-Liouville*

\[
\Big( P(x)y' \Big)' + Q(x)y(x) = R(x),
\]

haciendo el cambio

 * $P(x) = \exp \left( \int_{x_0}^xa(z)\,dz \right)$

 * $Q(x) = P(x)b(x)$

 * $R(x) = P(x)c(x)$

****** Card: paso a forma autoadjunta                                                                      :drill:
SCHEDULED: <2018-08-19 Sun>
:PROPERTIES:
:ID:       a1c6ef44-0fb4-43aa-9b09-10427e5ba538
:DRILL_LAST_INTERVAL: 52.1526
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.75
:DRILL_EASE: 2.32
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-28 Thu 22:09]
:END:
¿Cómo pasar una EDO lineal de segundo orden a forma autoadjunta?

\[
y''(x) + a(x)y'(x) + b(x)y(x) = c(x)
\]

******* Respuesta
Puede escribirse en *forma autoadjunta* o *forma de Sturm-Liouville*

\[
\Big( P(x)y' \Big)' + Q(x)y(x) = R(x),
\]

haciendo el cambio

 * $P(x) = \exp \left( \int_{x_0}^xa(z)\,dz \right)$

 * $Q(x) = P(x)b(x)$

 * $R(x) = P(x)c(x)$

**** 3.5. Relación con cálculo de variaciones
***** Paso a problema variacional
Dada una EDO en forma autoadjunta

\[
\Big( P(x)y' \Big)' + Q(x)y(x) = R(x),
\]

existe un funcional que la tiene como Euler-Lagrange asociada

\[
{\cal F}[y] = 
\int_{x_0}^{x_1} \left( 
P(x)\frac{y'(x)^2}{2} - Q(x)\frac{y(x)^2}{2} + R(x)y(x)
\right)\,dx,
\]

con

\[
F(x,y,p) = P\frac{p^2}{2} - Q\frac{y^2}{2} + Ry.
\]

****** Card: paso a forma variacional                                                                      :drill:
SCHEDULED: <2018-08-09 Thu>
:PROPERTIES:
:ID:       a8c3472f-302b-42e0-be27-cdf7bcb96c3d
:DRILL_LAST_INTERVAL: 63.7746
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 5
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.4
:DRILL_EASE: 2.32
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-06 Wed 12:17]
:END:
¿Cómo pasar una EDO en forma autoadjunta a un problema
variacional?

\[
\Big( P(x)y' \Big)' + Q(x)y(x) = R(x),
\]

******* Funcional
Existe un funcional que la tiene como Euler-Lagrange asociada

\[
{\cal F}[y] = 
\int_{x_0}^{x_1} \left( 
P\frac{(y')^2}{2} - Q\frac{y^2}{2} + Ry
\right)\,dx.
\]

con

\[
F(x,y,p) = P\frac{p^2}{2} - Q\frac{y^2}{2} + Ry.
\]

***** Teorema 9. Condición de unicidad para el problema variacional
Si $P,Q,R \in {\cal C}[x_0,x_1]$ con $P > 0$, $Q < 0$, entonces ${\cal F}$ es convexo.
Bajo *condiciones quasi-Dirichlet*,

\[\left.\begin{array}{l}
a_0y(x_0) + b_0y'(x_0) = c_0 \\
a_1y(x_1) + b_1y'(x_1) = c_1
\end{array}\right\}\quad
\mbox{ con }|a_0| + |a_1| > 0 \mbox{ y con } a_0b_0 \geq 0, a_1b_1 \geq 0\]

existe una única extremal solución del problema de contorno y
mínimo de ${\cal F}$.

****** Proof
******* Convexidad
La [[id:0cebe934-5d31-494d-bfd6-891d9c4c81ec][hessiana]] de $F(x,y,p) = \frac{P}{2}p^2 - \frac{Q}{2}y^2 + Ry$ en sus dos primeras
variables es definida positiva, luego $F$ es convexa

\[\mathrm{Hess}(F) = \begin{pmatrix}
-Q & 0 \\
0 & P
\end{pmatrix}.\]

Por [[id:4d623017-26e1-4e3e-82ec-325f4b6c0b38][Teorema 8]], ${\cal F}$ es convexa. Si existe extremal sería única.

******* Extremal única y solución (caso Dirichlet)
Por [[id:568bcd38-4589-424c-8f17-71f3c2df75d0][Alternativa de Fredholm]], hay extremal (solución de la ecuación
completa) única, cuando sólo existe la solución trivial al sistema
homogéneo

\[
\Big( P(x)y' \Big)' + Q(x)y(x) = 0.
\]

Si hubiera solución distinta de $0$, por unicidad del PVI asociado,
debería tenerse $y'(x_0) = 0 > 0$, luego $y(x) > 0$ en algún entorno a
la derecha de $x_0$. Como $y(x_1) = 0$, debe haber un máximo interno y
un punto crítico donde llegaríamos a contradicción.

******* Extremal única y solución (caso quasi-Dirichlet)                                                  :extra:
****** Card: condiciones quasi-Dirichlet                                                                 :nodrill:
SCHEDULED: <2018-08-02 Thu>
:PROPERTIES:
:ID:       49074f9d-fd25-49ae-a5f3-f04ed9d610c1
:DRILL_LAST_INTERVAL: 35.8713
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 9
:DRILL_FAILURE_COUNT: 3
:DRILL_AVERAGE_QUALITY: 2.556
:DRILL_EASE: 1.8
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-27 Wed 13:23]
:END:
*Describe las condiciones de contorno quasi-Dirichlet* que se usan
para asegurar unicidad en un problema variacional obtenido desde
una EDO autoadjunta

\[
{\cal F}[y] = 
\int_{x_0}^{x_1} \left( 
P(x)\frac{y'(x)^2}{2} - Q(x)\frac{y(x)^2}{2} + R(x)y(x)
\right)\,dx,
\]

******* Condiciones quasi-Dirichlet

\[\left.\begin{array}{l}
a_0y(x_0) + b_0y'(x_0) = c_0 \\
a_1y(x_1) + b_1y'(x_1) = c_1
\end{array}\right\}\quad
\mbox{ con }|a_0| + |a_1| > 0 \mbox{ y con } a_0b_0 \geq 0, a_1b_1 \geq 0\]

****** Card: enunciar el Teorema 9                                                                       :nodrill:
SCHEDULED: <2018-06-13 Wed>
:PROPERTIES:
:ID:       1506e11a-fd0e-41db-b339-bdce782014bb
:DRILL_LAST_INTERVAL: 19.6194
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 7
:DRILL_FAILURE_COUNT: 3
:DRILL_AVERAGE_QUALITY: 2.571
:DRILL_EASE: 1.94
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-05-24 Thu 23:45]
:END:
Enuncia el Teorema 9 sobre unicidad de extremales en un funcional

\[
{\cal F}[y] = 
\int_{x_0}^{x_1} \left( 
P(x)\frac{y'(x)^2}{2} - Q(x)\frac{y(x)^2}{2} + R(x)y(x)
\right)\,dx,
\]

obtenido del PC de una EDO autoadjunta

\[
\Big( P(x)y' \Big)' + Q(x)y(x) = R(x),
\]

******* Enunciado
Si $P,Q,R \in {\cal C}[x_0,x_1]$ con $P > 0$, $Q < 0$, entonces ${\cal F}$ es convexo.
Bajo *condiciones quasi-Dirichlet*, existe una única extremal solución
del problema de contorno y mínimo de ${\cal
F}$.

******* Condiciones quasi-Dirichlet

\[\left.\begin{array}{l}
a_0y(x_0) + b_0y'(x_0) = c_0 \\
a_1y(x_1) + b_1y'(x_1) = c_1
\end{array}\right\}\quad
\mbox{ con }|a_0| + |a_1| > 0 \mbox{ y con } a_0b_0 \geq 0, a_1b_1 \geq 0\]

***** Condiciones de contorno
Tenemos condiciones Newmann homogéneas sin imponer nada en el problema
variacional. Las condiciones Dirichlet sí deben ser añadidas.

****** Proof
En conjuntos [[id:094690c8-7f15-424a-89aa-126400e3d0c6][sin condiciones de contorno]] tendríamos

\[\begin{aligned}
0 = F_p(x_{0},y(x_0),y'(x_0)) = y'(x_0)P(x_0),\\
0 = F_p(x_1,y(x_1),y'(x_1)) = y'(x_1)P(x_1),
\end{aligned}\]

y como $P > 0$, se tienen las condiciones.

***** Teorema 10. Paso a Dirichlet homogéneas
Dada una ecuación en forma autoadjunta con condiciones Dirichlet
no homogéneas,

\[\left.\begin{array}{l}
\Big( P(x)y'(x) \Big)' + Q(x)y(x) = R(x),\ x \in [x_0,x_1] \\
y(x_0) = y_0, \\
y(x_1) = y_1.
\end{array}\right\}\]

podemos aplicar el cambio $z(x) = y(x) - (ax+b)$, con
$a = (y_1-y_0)/(x_1-x_0)$, con $b = (y_0x_1-y_1x_0)/(x_1-x_0)$ y con
${\tilde R} = R - aP' - (ax + b)Q$ para llegar a

\[\left.\begin{array}{l}
\Big( P(x)z'(x) \Big)' + Q(x)z(x) = {\tilde R}(x),\ x \in [x_0,x_1] \\
z(x_0) = 0, \\
z(x_1) = 0.
\end{array}\right\}\]

****** Proof
Calculando se verifica la equivalencia. Nótese que hemos
tomado la recta que anula la $y$ en justo esos puntos.

***** Ejemplo 14. Paso a Newmann homogéneas
Realizado en el [[id:de1af79c-3a0b-410e-8cca-d26c92021ec8][Ejercicio 4]].

**** 3.6. Soluciones de un PC en forma autoadjunta
***** Caso homogéneo
Las soluciones de la *ecuación homogénea*

\[
\left( P(x)y'(x) \right)' + Q(x)y(x) = 0
\]

forman un espacio vectorial.

***** Caso no homogéneo: definiciones
Llamamos *ecuación completa* a

\[
\left( P(x)y'(x) \right)' + Q(x)y(x) = R(x).
\]

*Condiciones de contorno separadas*

\[\left.\begin{array}{l}
a_0y(x_0) + b_0y'(x_0) = 0 \\
a_1y(x_1) + b_1y'(x_1) = 0
\end{array}\right\}\quad\]

y *condiciones de contorno periódicas*

\[\left.\begin{array}{l}
y(x_0) = y(x_1) \\
y'(x_0) = y'(x_1)
\end{array}\right\}\quad\]

****** Card: condiciones de contorno                                                                       :nodrill:
SCHEDULED: <2018-06-14 Thu>
:PROPERTIES:
:ID:       833872e8-5496-40d0-a969-d24dc2a5ad00
:DRILL_LAST_INTERVAL: 20.7715
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 5
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 2.6
:DRILL_EASE: 1.94
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-05-24 Thu 23:45]
:END:
Bajo qué tipos de condiciones de contorno se puede aplicar
Alternativa de Fredholm a

\[
\left( P(x)y'(x) \right)' + Q(x)y(x) = R(x).
\]

******* Condiciones
*Condiciones de contorno separadas homogéneas*

\[\left.\begin{array}{l}
a_0y(x_0) + b_0y'(x_0) = 0 \\
a_1y(x_1) + b_1y'(x_1) = 0
\end{array}\right\}\quad\]

y *condiciones de contorno periódicas*

\[\left.\begin{array}{l}
y(x_0) = y(x_1) \\
y'(x_0) = y'(x_1)
\end{array}\right\}\quad\]

***** Teorema 11. Alternativa de Fredholm
:PROPERTIES:
:ID:       568bcd38-4589-424c-8f17-71f3c2df75d0
:END:
En un PC con condiciones de contorno separadas homogéneas o
periódicas, necesariamente se verifica una de las siguientes
alternativas

 1. El problema homogéneo sólo admite la solución trivial, y
    entonces el completo sólo admite una solución única.

 2. El problema homogéneo admite varias soluciones $y_h$ y el
    completo admitirá tantas como él si y sólo si para toda
    solución,

    \[
    \int_{x_0}^{x_1}R(x)y_h(x)\,dx = 0.
    \]

****** Proof                                                                                               :extra:
Sea $\left\{ \phi_1,\phi_2 \right\}$ sistema fundamental de soluciones de la homogénea.
Por fórmula de variación de constantes, cualquier solución de la
completa es

\[
y = y_h + y_p = A\phi_1 + B\phi_2 + \int_{x_0}^x \frac{R(z)}{W(x_0)P(x_0)}
\left( \phi_2(x)\phi_1(z) - \phi_2(z)\phi_1(x) \right)\,dz
\]

Usando la fórmula de variación de constantes y aplicando
propiedades del Wronskiano.

****** Card                                                                                                :drill:
SCHEDULED: <2018-08-04 Sat>
:PROPERTIES:
:ID:       a683d1ef-c516-4d88-aa81-89961fd3780c
:DRILL_LAST_INTERVAL: 58.9299
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.5
:DRILL_EASE: 2.18
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-06 Wed 12:20]
:END:

Enuncia la Alternativa de Fredholm para

\[
\left( P(x)y'(x) \right)' + Q(x)y(x) = R(x).
\]

con condiciones separadas homogéneas o periódicas.

******* Alternativa de Fredholm
Se cumple una de dos alternativas

 1. El problema homogéneo sólo admite la solución trivial, y
    entonces el completo sólo admite una solución única.

 2. El problema homogéneo admite varias soluciones $y_h$ y el
    completo admitirá tantas como él si y sólo si para toda
    solución,

    \[
    \int_{x_0}^{x_1}R(x)y_h(x)\,dx = 0.
    \]

*** 4. Ligaduras, extremos condicionados
**** 4.1. Teorema 12. Euler-Lagrange para funcionales de varias funciones
:PROPERTIES:
:ID:       cf95308e-1cfe-4d08-af55-b2fb3956f471
:END:
Para $F \colon [x_0,x_1] \times \Omega \to \mathbb{R}$ continua, $\Omega \subseteq \mathbb{R}^{2n}$ dominio, minimizar

\[
{\cal F}(y) = \int_{x_0}^{x_1} F(x,y_1(x),\dots,y_n(x),y'_1(x), \dots, y'_n(x))\,dx.
\]

sobre

\[
{\cal D} = \left\{\begin{array}{c}
\vec{y}(x) = (y_1(x),\dots,y_n(x)) \\
y_i \in {\cal C}^1[x_0,x_1] \\
\vec{y}(x_0) = \vec{y}_0 \\
\vec{y}(x_1) = \vec{y}_1 \\
\forall x \in [x_0,x_1]\colon (\vec{y}(x),\vec{y}'(x)) \in \Omega
\end{array}\right\}
\]

Para $\oy \in {\cal D} \cap \left( {\cal C}^2[x_0,x_1] \right)^n$ extremal se tiene Euler-Lagrange

\[
F_{y_i} - \dv{}{x}\Big( F_{p_i} \Big) = 0, \quad i = 1,\dots,n.
\]

***** Proof
Seguimos un razonamiento similar al Teorema 2, tomando $g(s) = {\cal F}[y +s\phi]$
con $\phi = (\phi_1,\dots,\phi_n)$. Llegamos a

\[
0 = \sum_{i=1}^n \int_{x_0}^{x_1} \left( F_{y_i} - \dv{}{x} F_{p_i} \right) \phi_i(x)\,dx
\]

y tomamos funciones test en cada componente para obtener las ecuaciones.

***** Card: ecuaciones                                                                                      :drill:
SCHEDULED: <2018-09-15 Sat>
:PROPERTIES:
:ID:       c03c7dca-f9ba-4bc7-9dcd-2a1ea5dd1bcb
:DRILL_LAST_INTERVAL: 78.2524
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.25
:DRILL_EASE: 2.56
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-29 Fri 09:56]
:END:
Ecuaciones de Euler-Lagrange para funcionales dependientes de
varias funciones.

****** Ecuaciones

\[
F_{y_i} - \dv{}{x}\Big( F_{p_i} \Big) = 0, \quad \mbox{ para }i = 1,\dots,n.
\]

***** TODO Card: dominio                                                                                    :leech:
SCHEDULED: <2018-05-07 Mon>
:PROPERTIES:
:ID:       2303fc9e-f13d-4b4f-90e1-78e0bcc5fca3
:DRILL_LAST_INTERVAL: 4.1868
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-05-03 Thu 20:18]
:END:
Dominio de un funcional dependiente de varias funciones.

\[
{\cal F}(y) = \int_{x_0}^{x_1} F(x,y_1(x),\dots,y_n(x),y'_1(x), \dots, y'_n(x))\,dx.
\]

****** Dominio

\[
{\cal D} = \left\{\begin{array}{c}
\vec{y}(x) = (y_1(x),\dots,y_n(x)) \\
y_i \in {\cal C}^1[x_0,x_1] \\
\vec{y}(x_0) = \vec{y}_0 \\
\vec{y}(x_1) = \vec{y}_1 \\
\forall x \in [x_0,x_1]\colon (\vec{y}(x),\vec{y}'(x)) \in \Omega
\end{array}\right\}
\]

**** 4.2. Teorema 13. Ligaduras algebraico-diferenciales
:PROPERTIES:
:ID:       2e02f30e-7a39-472d-bbec-47c949e5b641
:END:
${\cal F}$ en [[id:cf95308e-1cfe-4d08-af55-b2fb3956f471][varias funciones]], con $m < n$, sobre

\[
{\cal D}_{\varphi} = {\cal D} \cap \left\{\begin{array}{c}
\varphi_1(x,y_1,\dots,y_n,y_1',\dots,y_n') = 0\\
\vdots\\
\varphi_m(x,y_1,\dots,y_n,y_1',\dots,y_n') = 0\\
\end{array}\right\}
\]

para $\oy \in {\cal D}_{\varphi} \cap \left( {\cal C}^2[x_0,x_1] \right)^n$ extremal, existen *multiplicadores* $\lambda_j(x)$,

\[
F^{\ast} = F - \sum_{j=1}^m \lambda_j(x) \varphi_j(x,y_1,\dots,y_n,y_1',\dots,y_n')
\]

con $(\oy,\lambda_1,\dots,\lambda_n)$ extremales de ${\cal F}^{\ast}[y,\lambda] = \int_{x_0}^{x_1} F^{\ast}\,dx$.  Por Euler-Lagrange,

\[\left\{\begin{array}{l}
F^{\ast}_{y_i} - \dv{}{x} \left( F^{\ast}_{p_i}\right) = 0,\quad i = 1,\dots,n; \\
\varphi_j = 0, \quad j = 1,\dots,m.
\end{array}\]

***** Proof                                                                                                 :extra:
# Demostración en el libro de Elsgoltz.

***** Card: dominio en ligaduras algebraicas                                                                :drill:
SCHEDULED: <2018-07-18 Wed>
:PROPERTIES:
:ID:       84993bca-f28f-4487-bd43-a16b443f2c51
:DRILL_LAST_INTERVAL: 43.82
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.75
:DRILL_EASE: 2.32
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-04 Mon 22:19]
:END:
Describe un dominio con ligaduras algebraicas.

****** Dominio

\[
{\cal D} = \left\{\begin{array}{c}
\vec{y}(x) = (y_1(x),\dots,y_n(x)) \\
y_i \in {\cal C}^1[x_0,x_1] \\
\vec{y}(x_0) = \vec{y}_0 \\
\vec{y}(x_1) = \vec{y}_1 \\
\forall x \in [x_0,x_1]\colon (\vec{y}(x),\vec{y}'(x)) \in \Omega \\
\varphi_1(x,y_1,\dots,y_n) = 0\\
\vdots\\
\varphi_m(x,y_1,\dots,y_n) = 0\\
\end{array}\right\}
\]

***** Card: ligaduras algebraicas                                                                           :drill:
SCHEDULED: <2018-06-19 Tue>
:PROPERTIES:
:ID:       71146515-8346-4743-829e-487b2e4ef9d0
:DRILL_LAST_INTERVAL: 31.8129
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.25
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-05-18 Fri 22:02]
:END:
Cómo buscar el mínimo de un funcional de varias variables ${\cal F}$

\[
{\cal F}(y) = \int_{x_0}^{x_1} F(x,y_1(x),\dots,y_n(x),y'_1(x), \dots, y'_n(x))\,dx.
\]

En un conjunto con ligaduras algebraicas

\[
{\cal D} = \left\{\begin{array}{c}
\vec{y}(x) = (y_1(x),\dots,y_n(x)) \\
y_i \in {\cal C}^1[x_0,x_1] \\
\vec{y}(x_0) = \vec{y}_0 \\
\vec{y}(x_1) = \vec{y}_1 \\
\forall x \in [x_0,x_1]\colon (\vec{y}(x),\vec{y}'(x)) \in \Omega \\
\varphi_1(x,y_1,\dots,y_n) = 0\\
\vdots\\
\varphi_m(x,y_1,\dots,y_n) = 0\\
\end{array}\right\}
\]

****** Método
Definimos

\[
F^{\ast} = F - \sum_{j=1}^m \lambda_j(x) \varphi_j(x,y_1,\dots,y_n)
\]

Buscamos $(\oy,\lambda_1,\dots,\lambda_n)$ extremales de ${\cal F}^{\ast}[y,\lambda] = \int_{x_0}^{x_1} F^{\ast}\,dx$ sobre
un conjunto sin restricciones. En estos puntos tenemos las ecuaciones
de Euler Lagrange

\[\left\{\begin{array}{l}
F^{\ast}_{y_i} - \dv{}{x} \left( F^{\ast}_{p_i}\right) = 0,\quad i = 1,\dots,n; \\
\varphi_j = 0, \quad j = 1,\dots,m.
\end{array}\]

***** Card: dominio en ligaduras algebro-diferenciales                                                    :nodrill:
SCHEDULED: <2018-06-12 Tue>
:PROPERTIES:
:ID:       e8794a70-7d98-469e-907d-16b566f467ba
:DRILL_LAST_INTERVAL: 25.1192
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.46
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-05-18 Fri 22:01]
:END:
Describe un dominio con ligaduras algebro-diferenciales.

****** Dominio

\[
{\cal D}'_{\varphi} = \left\{\begin{array}{c}
\vec{y}(x) = (y_1(x),\dots,y_n(x)) \\
y_i \in {\cal C}^1[x_0,x_1] \\
\vec{y}(x_0) = \vec{y}_0 \\
\vec{y}(x_1) = \vec{y}_1 \\
\forall x \in [x_0,x_1]\colon (\vec{y}(x),\vec{y}'(x)) \in \Omega \\
\varphi_1(x,y_1,\dots,y_n,y'_1,\dots,y'_n) = 0\\
\vdots\\
\varphi_m(x,y_1,\dots,y_n,y'_1,\dots,y'_n) = 0\\
\end{array}\right\}
\]

***** Card: completo                                                                                        :drill:
SCHEDULED: <2018-08-29 Wed>
:PROPERTIES:
:ID:       9165da91-53b4-4f99-a4bd-aedd91cab3c5
:DRILL_LAST_INTERVAL: 62.7939
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-27 Wed 13:16]
:END:
Cómo buscar el mínimo de un funcional sobre varias funciones ${\cal F}$
sobre un conjunto con ligaduras algebro-diferenciales.

****** Método
Definimos

\[
F^{\ast} = F - \sum_{j=1}^m \lambda_j(x)\varphi_j(x,y_1,\dots,y_n,y'_1,\dots,y'_n)
\]

y le buscamos extremales sin restricciones con Euler-Lagrange

\[\left\{\begin{array}{l}
F^{\ast}_{y_i} - \dv{}{x} \left( F^{\ast}_{p_i}\right) = 0,\quad i = 1,\dots,n; \\
\varphi_j = 0, \quad j = 1,\dots,m.
\end{array}\]

**** 4.3. Teorema 14. Ligaduras integrales
Sea ${\cal F}$ en [[id:cf95308e-1cfe-4d08-af55-b2fb3956f471][varias funciones]], con $m < n$ o $m \geq n$, sobre

\[
{\cal D}_{\varphi} = {\cal D} \cap \left\{\begin{array}{c}
\int_{x_0}^{x_1} G_1(x,y_1,\dots,y_n,y_1',\dots,y_n') = L_1\\
\vdots\\
\int_{x_0}^{x_1} G_m(x,y_1,\dots,y_n,y_1',\dots,y_n') = L_m\\
\end{array}\right\}
\]

para $\oy \in {\cal D}_{\varphi} \cap \left( {\cal C}^2[x_0,x_1] \right)^n$ extremal, hay *multiplicadores constantes* $\lambda_j$,

\[
F^{\ast} = F - \sum_{j=1}^m \lambda_j G_j,
\]

cumpliendo por Euler-Lagrange,

\[
F^{\ast}_{y_i} - \dv{}{x} \Big( F^{\ast}_{p_i} \Big) = 0, \qquad i=1,\dots,n.
\]

***** Principio de reciprocidad
La $F^{\ast}$ se mantiene cuando multiplicamos todo por $\mu \in \mathbb{R}$ y 
cambiamos $F$ por alguna de las $G_j$.

El *principio de reciprocidad* dice que equivale maximiar el área
fijada una longitud y minimizar la longitud fijada un área.

***** Proof
Tomamos $\tilde{\cal F}[y,z_1,\dots,z_m] = {\cal F}[y]$ con restricciones que sirven para
fijar las $z_j$ como primitivas, pero que son tipo algebraico-diferencial,

\[
{\cal D}_{\varphi}' = \left\{\begin{array}{c}
\vec{y}(x) \in {\cal D} \\
z_i \in {\cal C}^1[x_0,x_1] \\
\vec{z}(x_0) = 0 \\
\vec{z}(x_1) = \vec{L} \\
G_1(x,y_1,\dots,y_n,y'_1,\dots,y'_n) - z_1'(x) = 0 \\
\vdots\\
G_m(x,y_1,\dots,y_n,y'_1,\dots,y'_n) - z_m'(x) = 0
\end{array}\right\}
\]

y aplicando el teorema sobre [[id:2e02f30e-7a39-472d-bbec-47c949e5b641][ligaduras diferenciales]], tenemos

\[
\tilde{F}^{\ast} = \tilde{F} - \sum_{j=1}\lambda_j(x)(G_j - z_j')
\]

y llegamos a

\[\left\{\begin{aligned}
\tilde{F}^{\ast}_{y_i} - \dv{}{x} \left( \tilde{F}^{\ast}_{p_i} \right) = 0, \\
\dv{}{x} \left( \lambda_j(x) \right) = 0,\\
\int_{x_0}^{x_1}G_j\,dx = L_j
\end{aligned}\right.\]

que se corresponden a las ligaduras que marca el enunciado.

***** Card: dominio en ligaduras integrales                                                                 :drill:
SCHEDULED: <2018-07-14 Sat>
:PROPERTIES:
:ID:       d6f0bf2b-96a3-4aa7-97cf-a10986b4ca1b
:DRILL_LAST_INTERVAL: 38.0072
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 7
:DRILL_FAILURE_COUNT: 2
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.32
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-06 Wed 12:06]
:END:
Describe un dominio con ligaduras integrales.

****** Dominio

\[
{\cal D}_{G} = \left\{\begin{array}{c}
\vec{y}(x) = (y_1(x),\dots,y_n(x)) \\
y_i \in {\cal C}^1[x_0,x_1] \\
\vec{y}(x_0) = \vec{y}_0 \\
\vec{y}(x_1) = \vec{y}_1 \\
\forall x \in [x_0,x_1]\colon (\vec{y}(x),\vec{y}'(x)) \in \Omega \\
\int_{x_0}^{x_1} G_1(x,y_1,\dots,y_n,y'_1,\dots,y'_n)\, dx = L_1 \\
\vdots\\
\int_{x_0}^{x_1} G_m(x,y_1,\dots,y_n,y'_1,\dots,y'_n)\, dx = L_m
\end{array}\right\}
\]

****** Detalle importante
Aquí los $L_i$ no tienen por qué ser $0$.
***** TODO Card                                                                                             :drill:
:PROPERTIES:
:ID:       2b3f9246-bbdd-45b3-9684-6ee284f3bbc4
:END:
**** 4.4. Ejemplos
***** Ejemplo: Problema de Dido
Queremos maximizar el área que encierra una curva cerrada de longitud
finita.

****** Planteamiento
Consideramos $\Gamma$ la traza de $\alpha \colon [0,1] \to \mathbb{R}^2$ en sentido antihorario llamando 
$\alpha(t) = (x(t),y(t))$, y cumpliendo que $\alpha(0) = \alpha(1)$. El área que
encierra $\alpha$ es

\[
A(x,y) = \frac{1}{2}\int^1_0 x(t)y'(t) - x'(t)y(t)\,dt.
\]

Y queremos minimizar este funcional sobre el siguiente conjunto.

\[
{\cal D}_{G} = \left\{\begin{array}{c}
x,y \in {\cal C}^1[x_0,x_1] \\
x_0=x_1 \\
y_0=y_1 \\
\int_0^1 \sqrt{(x'(t))^2 + (y'(t))^2} \,dt = L
\end{array}\right\}
\]

Tenemos por tanto $n = 2$ incógnitas y $m = 1$ ligaduras integrales.
Tenemos definidas las funciones

 * $F(t,x,y,p,q) = \frac{1}{2}(xq - yp)$

 * $G(x,y,p,q) = \sqrt{p^2 + q^2}$

****** Lagrangiana
Teniendo la lagrangiana

\[
F^{\ast} = F - \lambda G = \frac{1}{2}(xq-yp) - \lambda \sqrt{p^2 + q^2}
\]

podemos aplicar el [[id:e37d89ff-11da-493c-ab46-2000fe221da9][Teorema 14]] sobre ligaduras integrales para tener
las siguientes ecuaciones asociadas.

\[\pdv{F^{\ast}}{x} - \dv{}{t}\pdv{F^{\ast}}{p} = 0\]

\[
\pdv{F^{\ast}}{y} - \dv{}{t}\pdv{F^{\ast}}{p} = 0
\]

Desde ellas podemos obtener dos constantes

\[
y + \lambda \frac{x'}{\sqrt{x'^2 + y'^2}} = y_0, \qquad
x + \lambda \frac{y'}{\sqrt{x'^2 + y'^2}} = x_0;
\]

que dan como solución una circunferencia de centro $(x_0,y_0)$ y radio $|\lambda|$.

***** Ejemplo: Catenaria
Queremos hallar la forma de una cuerda de longitud $L > 1$ colgando de
dos postes a altura $h$ separados a $1$ unidad de distancia. 

****** Planteamiento
Minimizaremos

\[
{\cal F}[y] = \int_0^1 y(x) \sqrt{1 + (y'(x))^2}\,dx
\]

sujeto a

\[
{\cal D}_{G} = \left\{\begin{array}{c}
y \in {\cal C}^1[0,1] \\
y(0) = y(1) = h,\\
\int_0^1 \sqrt{1 + (y'(x))^2} \,dx = L
\end{array}\right\}
\]

Tenemos por tanto $n = 1$ incógnitas y $m = 1$ ligaduras integrales.
Tenemos definidas las funciones

 * $F(x,y,p) = y\sqrt{1 + p^2}$,

 * $G(x,y,p) = \sqrt{1 + p^2}$.

****** Lagrangiana
Tenemos la lagrangiana

\[
F^{\ast} = (y - \lambda)\sqrt{1 + p^2}
\]

que al no depender de $x$ directamente, simplifica su condición de
Euler-Lagrange a $F - y'F_p = \mathrm{cte.} = C$. Resolviendo obtenemos

\[
y = \lambda + C\sqrt{1+y'^2}.
\]

Esta es una ecuación diferencial que hemos tratado anteriormente
con solución

\[
y(x) = \lambda + C \cosh \left( \frac{x-k}{C} \right).
\]

****** Determinación de las constantes
Imponiendo la ligadura $y(0) = y(1)$ obtenemos $k = 1/2$. Imponiendo
la ligadura integral tenemos

\[
L = \int_0^1 \sqrt{1 + \sinh(\dots)^2}\,dx = \int_0^1 \cosh(\dots)\,dx = 2C \sinh\frac{1}{2C}
\]

que determina $C$ de forma única cuando $L > 1$.

****** Dato extra
Si además imponemos $y(0) = h$, entonces

\[
\lambda = h - C_0 \cosh \left( \frac{1}{2C_0} \right)
\] 

y podemos demostrar que

\[
\lambda = h - \frac{1}{2}\sqrt{4C_0^2 + L}.
\]

*** 5. Funcionales dependientes de funciones de varias variables
**** 5.0. Ecuación de Euler-Lagrange dependiente de varias variables
***** Ecuación de Euler-Lagrange con funciones de varias variables
Para

\[
{\cal F}[u] = \int_{\Omega} F \left( x_1,x_2,u(x),u_{x_1}(x),u_{x_2}(x) \right) \,dx,
\]

actuando en ${\cal D} = \left\{ u \in {\cal C}^1(\overline{\Omega}) \;\middle|\; \forall x \in \partial \Omega\colon u(x) = \gamma(x)  \right\}$. Los extremales
$u \in {\cal C}^2(\Omega)$ cumplen

\[
F_u - \dv{}{x_1} F_p - \dv{}{x_2}F_q = 0.
\]

****** Card: caso considerado                                                                              :drill:
SCHEDULED: <2018-08-05 Sun>
:PROPERTIES:
:ID:       d3ca9936-b4c5-4eba-a576-293beefb4226
:DRILL_LAST_INTERVAL: 59.746
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.25
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-06 Wed 12:19]
:END:
Da la ecuación de Euler-Lagrange para un funcional

\[
{\cal F}[u] = \int_{\Omega} F \left( x_1,x_2,u(x),u_{x_1}(x),u_{x_2}(x) \right) \,dx,
\]

******* Ecuación

\[
F_u - \dv{}{x_1} F_p - \dv{}{x_2}F_q = 0.
\]

****** Card: caso con tres variables                                                                       :drill:
SCHEDULED: <2018-06-27 Wed>
:PROPERTIES:
:ID:       a66957ab-1847-466f-b93c-813e5cb671b3
:DRILL_LAST_INTERVAL: 40.3114
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-05-18 Fri 22:07]
:END:
Da la ecuación de Euler-Lagrange para un funcional

\[
{\cal F}[u] = \int_{\Omega} F(t,x,y,u,u_t,u_x,u_y) \,dt\,dx\,dy
\]

******* Ecuación

\[
F_u - \dv{}{t}F_r - \dv{}{x}F_p - \dv{}{y}F_q
\]

***** Teoremas análogos de convexidad
Se tienen en estas condiciones

 * el [[id:89c9e4a0-cc09-4962-b3e5-8fc1cfbb0c4e][Teorema 6]],
 * el [[id:c46055cc-5d8b-4772-8af3-48057d7e45a4][Teorema 7]], y
 * el [[id:4d623017-26e1-4e3e-82ec-325f4b6c0b38][Teorema 8]].

**** 5.1. La membrana vibrante
***** Laplaciana
:PROPERTIES:
:ID:       1ef43534-3455-4e69-bd5f-c9cb72a1eb85
:END:
La *laplaciana* es la suma de todas las segundas derivadas
sin mezclar.

\[
\Delta f = \sum_{i=1}^n{\pdv[2]{f}{x_i}}.
\]

****** Card                                                                                                :drill:
SCHEDULED: <2018-08-29 Wed>
:PROPERTIES:
:ID:       a5ac910f-d07f-4938-afb0-2eba7a25e7c9
:DRILL_LAST_INTERVAL: 63.3234
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.46
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-27 Wed 13:20]
:END:
Da la definición de laplaciana y distínguela de la definición
de gradiente.

******* Laplaciana
La *laplaciana* es la suma de todas las segundas derivadas
sin mezclar:

\[
\Delta f = \sum_{i=1}^n{\pdv[2]{f}{x_i}}.
\]

******* Gradiente
El *gradiente* es el vector de las primeras derivadas, una
particularización del jacobiano.

\[
(\nabla f)(p) = \left( \pdv{f}{x_1}(p), \dots, \pdv{f}{x_n}(p) \right) = 
(f_{x_1}(p), \dots,f_{x_n}(p)).
\]

***** Divergencia
La *divergencia* es la suma de todas las primeras derivadas en
cada una de las componentes de un campo vectorial $\mathbb{R}^n \to \mathbb{R}^n$,

\[
\mathrm{div}(f) = \sum_{i=1}^n \pdv{f_i}{x_i}
\]

****** Card                                                                                                :drill:
SCHEDULED: <2018-06-17 Sun>
:PROPERTIES:
:ID:       9ceb6b3f-39fd-45f8-8d13-6d6c857f5ada
:DRILL_LAST_INTERVAL: 30.3428
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.333
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-05-18 Fri 22:14]
:END:
Define la *divergencia* en cálculo vectorial, $\mathrm{div}(f)$.

******* Divergencia

\[
\mathrm{div}(f) = \sum_{i=1}^n \pdv{f_i}{x_i}
\]

***** Marco del problema
Consideramos una membrana sujeta por el borde, llamando $u(t,x)$ al
a la *altura* de un punto de la membrana, que estará en $\Omega \subseteq \mathbb{R}^N$.
Llamamos $\varphi(x) \in {\cal C}^1(\Omega)$ a la *posición de reposo o equilibrio* de la
que parte, que usualmente se toma constante cero.

****** Modelo inicial

\[\begin{aligned}
{\cal F}[u] =
C(\varphi) &+ \frac{1}{2} \int_0^{\infty}\int_{\Omega} m \abs{\pdv{u}{t}}^2 \,d(x,y)dt 
\\& + \int_0^{\infty}\int_{\Omega} -\sigma 
  \sqrt{1 + \abs{\nabla u}^2} + f(x)u - \frac{\alpha}{2}(u - \varphi)^2\,dxdt
\\& + \int_0^{\infty} \int_{\partial\Omega} g_1(x)u - \frac{\alpha_1}{2}(u - \varphi)^2\,dSdt
\end{aligned}\]

Normalmente sólo aparecerá este funcional simplificado.

****** Simplificación 1: equilibrio nulo.
Asumimos la posición de equilibrio $\varphi(x) = 0$ horizontal.

****** Simplificación 2: deformaciones pequeñas (Taylor).
Utilizamos el desarrollo de Taylor

\[
\sqrt{1 + s^2} = 1 + \frac{s^2}{2} - \frac{s^4}{8} + {\cal O}(s^6).
\]

para simplificar el término $\sqrt{1 + \abs{\nabla u}^2}$ despreciando ${\cal O}(\abs{\nabla u}^4)$
para aproximar

\[
\int_{\Omega}\sigma \sqrt{1 + \abs{\nabla u}^2 \,dx} \sim C + \frac{1}{2}\int_{\Omega} \sigma \abs{\nabla u}^2\,dx.
\]

****** Simplificación 3: caso estacionario.
La $u$ es independiente del tiempo.

***** Modelo de la membrana simplificado
:PROPERTIES:
:ID:       f0ac6c21-d9c3-4298-b48e-8602ca0948a5
:END:
Si asumimos todas las simplificaciones posibles,

\[
{\cal F}[u] = \int_{\Omega} \left( 
\frac{\sigma(x)}{2}\abs{\nabla u}^2 + \frac{\alpha}{2}u^2 - f(x)u
\right)\,dx
\]

sobre $u \in {\cal C}^1_0(\Omega)$. Si no asumimos borde nulo tendremos $u \in {\cal C}^1(\overline{\Omega})$
con $u = \gamma = \varphi$ en $\partial\Omega$.

****** Ecuación
Desde el que llegamos a

\[
-\mathrm{div}(\sigma\Delta_x u) = f - \alpha u.
\]

# Comprobar, en los apuntes usa la divergencia y no parece que salga
# el mismo resultado ni lo que sale haciendo Euler-Lagrange cuando 
# la sigma no es constante.

Suponiendo $\sigma$ constante llegamos a

\[
-\sigma \Delta_{x} = f - \alpha u
\]

******* Laplaciana en variables espaciales
Nótese que en este caso nos interesa sólo la [[id:1ef43534-3455-4e69-bd5f-c9cb72a1eb85][laplaciana]] respecto de
las variables no temporales.

\[
\Delta_xu := \sum_{i=1}^n \pdv[2]{u}{x_i}
\]

Nótese que $u$ no depende del tiempo por las simplificaciones.

****** Proof
La $F$ asociada está en los apuntes. La ecuación se obtiene
usando la definición de la laplaciana $\Delta u$.
****** Card: modelo simplificado de la membrana                                                            :leech:
SCHEDULED: <2018-05-07 Mon>
:PROPERTIES:
:ID:       41429f6b-f4a0-496b-9f2b-d3c27f11c3eb
:DRILL_LAST_INTERVAL: 3.7493
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-05-03 Thu 12:42]
:END:
Enuncia el funcional del modelo simplificado de la membrana.

******* Funcional

\[
{\cal F}[u] = \int_{\Omega} \left( 
\frac{\sigma(x)}{2}\abs{\nabla u}^2 + \frac{\alpha}{2}u^2 - f(x)u
\right)\,dx
\]

****** Card: ecuación de la membrana                                                                       :drill:
:PROPERTIES:
:ID:       87e0aead-2a8b-4392-a283-3030da911c37
:END:
***** Ecuación de Poisson
Tomando $\sigma = \mathrm{cte}$ (nula sería trivial) y $\alpha = 0$ en el modelo de la
[[id:f0ac6c21-d9c3-4298-b48e-8602ca0948a5][membrana]] tenemos la *Ecuación de Poisson*.

\[
-\Delta_x u = f/\sigma.
\]

****** TODO Card: ecuación de Poisson                                                                      :leech:
SCHEDULED: <2018-05-28 Mon>
:PROPERTIES:
:ID:       72b375cf-bcc8-4ca6-aeea-8e220904f72f
:DRILL_LAST_INTERVAL: 9.7942
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 6
:DRILL_FAILURE_COUNT: 2
:DRILL_AVERAGE_QUALITY: 3.167
:DRILL_EASE: 2.56
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-05-18 Fri 22:10]
:END:
Enuncia la Ecuación de Poisson.

******* Ecuación

\[
-\Delta_x u = f/\sigma.
\]

****** Card: proviene de                                                                                   :drill:
SCHEDULED: <2018-06-18 Mon>
:PROPERTIES:
:ID:       2a969466-4703-47e1-974b-eb5ea28a3bd0
:DRILL_LAST_INTERVAL: 30.885
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-05-18 Fri 22:10]
:END:
¿De dónde proviene la ecuación de Poisson?

\[
-\Delta_x u = f/\sigma.
\]

******* Respuesta
Del modelo simplificado de la membrana.

\[
{\cal F}[u] = \int_{\Omega} \left( 
\frac{\sigma(x)}{2}\abs{\nabla u}^2 + \frac{\alpha}{2}u^2 - f(x)u
\right)\,dx
\]

Tomando $\sigma$ constante tenemos Euler-Lagrange

\[
-\sigma \Delta_{x}u = f - \alpha u
\]

Tomando $\alpha = 0$ tenemos la Ecuación de Poisson.

***** Modos de vibración                                                                                    :extra:
***** Problema de Dirichlet
:PROPERTIES:
:ID:       8e9ccec0-c9de-4d00-a08e-3de44d448ca5
:END:
Tomando $\alpha = f = 0$, $\sigma = \mathrm{cte.}$ en el modelo de la [[id:8e9ccec0-c9de-4d00-a08e-3de44d448ca5][membrana]], y no
asumiendo borde fijo llamamos *funcional de Dirichlet* al

\[
{\cal F}[u] = \int_{\Omega} \abs{\nabla u}^2\,dx.
\]

que lleva a

\[\left\{\begin{array}{ll}
\Delta_x u(x) = 0 &\mbox{ si } x \in \Omega\\
u(x) = \gamma(x) &\mbox{ si } x \in \partial\Omega
\end{array}\right.\]

y podemos comprobar por convexidad que la solución es única.

****** Proof
Tenemos

$F = \sum_i p_i^2$

convexa, [[id:4d623017-26e1-4e3e-82ec-325f4b6c0b38][luego]] ${\cal F}$ convexa y los [[id:89c9e4a0-cc09-4962-b3e5-8fc1cfbb0c4e][extremales]] son mínimos globales.

***** TODO Superficie minimal
***** Ecuación de ondas
:PROPERTIES:
:ID:       6412aa5f-6f69-4458-9832-134ab22707b3
:END:
La *ecuación de ondas* sin el caso estacionario. Tomando $\alpha$ y $\sigma$ constantes,

\[
{\cal F}[u] = \int_0^{\infty}\int_{\Omega}
\left(\frac{(\partial_t u)^2}{2} - \frac{\sigma}{2}\abs{\nabla u}^2 + fu - \alpha\frac{u^2}{2}\right)
\,dx\,dt.
\]

Sobre

\[{\cal D} = \left\{\begin{array}{lr}
u \in {\cal C}^1([0,T] \times \Omega), &\\
u(0,x) = \varphi(x),& x\in \Omega \\
u(T,x) = \mathrm{dado},& x \in \Omega \\
u(t,x) = \varphi(x), & t \geq 0, x \in \partial\Omega
\end{array}\right\}\]

Luego

\[
F = \frac{1}{2}
\left( r^2 - \sigma(p^2+q^2) + 2fu - \alpha u^2 \right).
\]

Y la condición de Euler-Lagrange se llama *ecuación de ondas*.

\[
\partial^2_{tt}u = f(x) - \alpha u  + \sigma \Delta_x u.
\]

****** Card                                                                                              :nodrill:
SCHEDULED: <2018-08-26 Sun>
:PROPERTIES:
:DRILL_CARD_TYPE: multisided
:ID:       d2737759-5b77-4e0f-8860-769f0dae8897
:DRILL_LAST_INTERVAL: 58.9259
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 6
:DRILL_FAILURE_COUNT: 2
:DRILL_AVERAGE_QUALITY: 2.667
:DRILL_EASE: 1.94
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-28 Thu 22:13]
:END:
Ecuación de ondas.

******* Ecuación

\[
u_{tt} = f - \alpha u + \sigma \Delta_x u.
\]

******* Funcional

\[
{\cal F}[u] = \int_0^{\infty}\int_{\Omega}
\left(\frac{u^2_t}{2} - \frac{\sigma}{2}\abs{\nabla u}^2 + fu - \alpha\frac{u^2}{2}\right)
\,dx\,dt.
\]

******* Dominio del funcional

\[{\cal D} = \left\{\begin{array}{lr}
u \in {\cal C}^1([0,T] \times \Omega), &\\
u(0,x) = \varphi(x),& x\in \Omega \\
u(T,x) = \mathrm{dado},& x \in \Omega \\
u(t,x) = \varphi(x), & t \geq 0, x \in \partial\Omega
\end{array}\right\}\]

**** 5.2. Resolución: separación de variables y necesidad del desarrollo en serie
***** Ecuación de ondas unidimensional simplificada
:PROPERTIES:
:ID:       e3c0e5df-d8b2-495c-9993-bd2b93d4782e
:END:
Sea [[id:6412aa5f-6f69-4458-9832-134ab22707b3][ecuación de ondas]] unidimensional con $\sigma = c^2$ y $\alpha = f = 0$,

\[
{\cal F}[u] = 
\frac{1}{2}\int_0^{\infty}\int_{0}^L
\left( u_t^2 - c^2 u_x^2 \right)\,dxdt.
\]

Obteniendo

\[
u_{tt} = c^2 u_{xx}.
\]

Compensando el no fijar condición en $T = \infty$, fijamos derivada inicial.

\[\left\{\begin{array}{lr}
u(0,x) = u_0(x) \in {\cal C}^2, & x \in [0,L], \\
u_t(0,x) = v_0(x) \in {\cal C}^1, & x \in [0,L], \\
u(t,0) = u(t,L) = 0, & t \geq 0.
\end{array}
\right\}\]

****** Card                                                                                                :drill:
SCHEDULED: <2018-07-02 Mon>
:PROPERTIES:
:DRILL_CARD_TYPE: multisided
:ID:       5c25baff-dce3-4454-b5e5-baf0ac520cdc
:DRILL_LAST_INTERVAL: 27.7362
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 8
:DRILL_FAILURE_COUNT: 3
:DRILL_AVERAGE_QUALITY: 3.125
:DRILL_EASE: 2.32
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-04 Mon 22:06]
:END:
Ecuación de ondas unidimensional simplificada.

******* Funcional

\[
{\cal F}[u] = 
\frac{1}{2}\int_0^{\infty}\int_{0}^L
\left( u_t^2 - c^2 u_x^2 \right)\,dx\,dt.
\]

******* Ecuación

\[
u_{tt} = c^2 u_{xx}.
\]

******* Dominio del funcional

\[{\cal D} = \left\{\begin{array}{lr}
u(0,x) = u_0(x) \in {\cal C}^2, & x \in [0,L], \\
u_t(0,x) = v_0(x) \in {\cal C}^1, & x \in [0,L], \\
u(t,0) = u(t,L) = 0, & t \geq 0.
\end{array}
\right\}\]

***** Solución de la ecuación de ondas
La única solución de la [[id:e3c0e5df-d8b2-495c-9993-bd2b93d4782e][ecuación de ondas simplificada]] es la serie

\[
\sum_{n \geq 1} \left( 
a_n\cos\left(\frac{nc\pi t}{L}\right) +
\frac{b_nL}{nc\pi} \sin \left( \frac{nc\pi t}{L} \right)
\right)
\sin \left( \frac{n\pi x}{L} \right)
\]

donde hemos desarrollado

\[
u_0(x) = \sum_{n \geq 1} a_n \sin \left( \frac{n\pi x}{L} \right),
\qquad
v_0(x) = \sum_{n \geq 1} b_n \sin \left( \frac{n\pi x}{L} \right).
\]

****** Proof: separación de variables y principio de superposición
Buscamos una solución de la forma $u(t,x) = T(t)W(x)$, que
si es solución debe cumplir

\[
T''(t)W(x) = c^2T(t)W''(x),
\]

por lo que, se tienen las dos funciones siguientes independientes
de la otra variable y constantes $T''(t)/T(t) = c^2W''(x)/W(x) = -\lambda$.

Si existieran deberían de cumplir

 * $T'(t) + \lambda T(t) = 0$,

 * $W'(t) + \frac{\lambda}{c^2} W(t) = 0$,

donde además $W(0) = W(L) = 0$ si $T$ no es nula. El problema de resolver
una ecuación de este tipo es un problema de [[id:1e2009c1-db10-4490-af5c-db57a46dab0f][Sturm-Liouville]] que hemos
[[id:e15aa2f8-76b4-4aa6-82bb-c0b424bda884][tratado ya]] y con soluciones $\lambda_n = (nc\pi/L)^2$ y $W_n(x) = \sin(n\pi x/L)$.

Ahora, al resolver la primera ecuación para $T$ obtendríamos

\[
T_n(t) = A_n \cos(\frac{nc\pi t}{L}) + B_n \sin(\frac{nc\pi t}{L})
\]

dándonos finalmente

\[
u_n(t,x) = 
\sin(\frac{n\pi x}{L}) 
\left( A_n\cos(\frac{nc\pi t}{L}) + B_n\sin(\frac{nc\pi t}{L}) \right).
\]

El problema es que al imponer las condiciones de contorno que teníamos
llegamos a un punto en el que no está claro cómo seguir.

  * $u_n(0,x) = A_n\sin(\frac{n\pi x}{L}) = u_0(x)$,

  * $\partial_t u_n(0,x) = B_n \frac{nc\pi}{L}\sin(\frac{n \pi x}{L}) = v_0(x)$.

Para solucionar esto usaremos que la suma de dos soluciones cualesquiera
de [[id:e3c0e5df-d8b2-495c-9993-bd2b93d4782e][nuestro problema]] vuelve a ser solución, y que toda función con cierta
regularidad y con $u_0(0) = u_0(L) = 0$ será una serie de la forma

\[
u_0(x) = \sum_{n=1}^{\infty} a_n\sin(\frac{n\pi x}{L}).
\]

Si ajustamos los coeficientes llegamos a la solución buscada.

****** Card: procedimiento                                                                                 :drill:
SCHEDULED: <2018-09-20 Thu>
:PROPERTIES:
:ID:       8be7d27b-0a8a-43b6-a7a1-3086967a27e5
:DRILL_LAST_INTERVAL: 82.9064
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.42
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-29 Fri 09:56]
:END:
¿Cuál es el procedimiento de resolución de la ecuación de ondas
simplificada?

\[
u_{tt} = c^2 u_{xx}.
\]

\[\left\{\begin{array}{lr}
u(0,x) = u_0(x) \in {\cal C}^2, & x \in [0,L], \\
u_t(0,x) = v_0(x) \in {\cal C}^1, & x \in [0,L], \\
u(t,0) = u(t,L) = 0, & t \geq 0.
\end{array}
\right\}\]

******* Procedimiento

1. Buscamos solución $u(t,x) = T(t)W(x)$.

2. Llegamos a un Sturm-Liouville en $W$ que nos da
   $\lambda_n = (nc\pi / L)^2$ y $W_n(x) = \sin(n\pi x/L)$. Resolvemos
   para $T$.

3. Desarrollamos en serie de senos $u_0$ y $v_0$.

4. Por principio de superposición ajustamos coeficientes para
   llegar a la solución.

**** 5.3. Problemas de Sturm-Liouville
***** Problema de Sturm-Liouville
:PROPERTIES:
:ID:       1e2009c1-db10-4490-af5c-db57a46dab0f
:END:
Un *problema de Sturm-Liouville* consiste en encontrar las
$\lambda \in \mathbb{R}$ donde el PC tiene soluciones no nulas.

\[\left.\begin{array}{c}
\forall x \in [x_0,x_1]\colon\qquad (Py')' + (Q + \lambda S) y = 0 \\
a_0y(x_0) + b_0y'(x_0) = 0,\\
a_1y(x_1) + b_1y'(x_1) = 0.
\end{array}\right\}\]

Con $Q,S \in {\cal C}^0$, $P \in {\cal C}^1$ positivas $P > 0$, y $S > 0$;
y condiciones de contorno no triviales,
$|a_0| + |b_0| > 0$ y $|a_1|+|b_1|> 0$.

****** Card                                                                                              :nodrill:
SCHEDULED: <2018-06-08 Fri>
:PROPERTIES:
:DRILL_CARD_TYPE: multisided
:ID:       dac10bbc-2e51-40da-a9e4-4a7e80bb50cf
:DRILL_LAST_INTERVAL: 4.0623
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 6
:DRILL_FAILURE_COUNT: 2
:DRILL_AVERAGE_QUALITY: 2.833
:DRILL_EASE: 2.08
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-04 Mon 22:20]
:END:
¿Qué es un problema de Sturm-Liuville?

******* Problema
Encontrar $\lambda \in \mathbb{R}$ para los cuales la siguiente
ecuación tiene soluciones no nulas.

\[\left.\begin{array}{c}
\forall x \in [x_0,x_1]\colon\qquad (Py')' + (Q + \lambda S) y = 0 \\
a_0y(x_0) + b_0y'(x_0) = 0,\\
a_1y(x_1) + b_1y'(x_1) = 0.
\end{array}\right\}\]

Se asumen además ciertas condiciones.

******* Condiciones

 1. $Q,S$ continuas, $P \in {\cal C}^1$,

 2. $P > 0$ y $S > 0$,

 3. las condiciones de contorno no son triviales, teniéndose
    $|a_0| + |b_0| > 0$ y $|a_1|+|b_1|> 0$

****** Card                                                                                                :drill:
:PROPERTIES:
:ID:       8f362b9c-11c5-4954-b4f1-c4384b474a29
:END:
Ecuación de un Sturm-Liouville.

******* Answer
Buscamos lambdas para que la siguiente ecuación tenga solución no nula.

\[
(Py')' + (Q + \lambda S) y = 0
\]

***** Teorema 15. Teoría de Sturm-Liouville
Los valores propios de un problema de Sturm-Liouville forman una
sucesión creciente y divergente $\lambda_1< \lambda_2< \dots\to \infty$. Sus funciones
propias normalizadas $\|y_n\|_{L^2_S} = 1$ 

 * son únicas salvo signo

 * $y_n$ tiene $n-1$ ceros en $(x_0,x_1)$,

 * son ortogonales, para $n \neq m$

   \[
   \pair{y_n,y_m} = \int_{x_0}^{x_1} y_n(x)y_m(x) S(x)\,dx = 0;
   \]

 * cualquier función $y \in L^2_S(x_0,x_1)$ puede ser desarrollada en serie
   de funciones propias

   \[
   y(x) = \sum_{n=1}^{\infty}\pair{y,y_n}y_n.
   \]

En el caso de condiciones periódicas en el problema, un mismo valor
propio puede tener dos funciones propias y la ortogonalidad no se
tiene directamente.

****** Proof                                                                                               :extra:
# Fuera de los objetivos del curso.
****** Card: los valores propios                                                                           :drill:
SCHEDULED: <2018-09-01 Sat>
:PROPERTIES:
:ID:       3458d9e8-3283-4f9c-908d-52ac8c553a42
:DRILL_LAST_INTERVAL: 64.7041
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.25
:DRILL_EASE: 2.56
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-28 Thu 22:09]
:END:
Los valores propios de un Sturm-Liouville $\lambda_i$ forman
una sucesión [creciente y divergente $\lambda_1< \lambda_2< \dots\to \infty$].

****** Card: funciones propias                                                                             :drill:
SCHEDULED: <2018-06-19 Tue>
:PROPERTIES:
:ID:       ea61c9ca-13ef-4a74-8c5e-14ced1b5a060
:DRILL_LAST_INTERVAL: 32.4906
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.25
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-05-18 Fri 22:13]
:END:
Qué cuatro propiedades verifican las funciones propias $f_n$ de un
Sturm-Liouville.

******* Propiedades
Cuando las *normalizamos*, $\|y_n\|_{L^2_S} = 1$, verifican

 * su normalizada es única salvo signo,

 * la $y_n$ tiene $n-1$ ceros en $(x_0,x_1)$

 * son ortogonales,

 * toda función $L^2_S(x_0,x_1)$ se desarrolla en serie de funciones
   propias.

****** Card: el caso periódico                                                                           :nodrill:
SCHEDULED: <2018-06-08 Fri>
:PROPERTIES:
:ID:       d398f6f5-55e9-4dfc-98ad-ef48ad0d3039
:DRILL_LAST_INTERVAL: 20.9843
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.667
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-05-18 Fri 22:04]
:END:
¿Qué cambia en la teoría de Sturm-Liouville en el caso periódico?

******* Respuesta
Cada valor propio puede tener asociadas dos funciones y la
ortogonalidad no se tiene directamente.

***** Cálculo variacional en Sturm-Liouville
:PROPERTIES:
:ID:       99594c9a-d729-4e87-b886-c4ee6899d0d7
:END:
Dado el funcional

\[
{\cal F}[y] = \int_{x_0}^{x_1} \Big( P(x)(y'(x))^2 - Q(x)y(x)^2 \Big)\,dx
\]

en

\[{\cal D}_1 = \left\{\begin{array}{c}
y \in {\cal C}^1(x_0,x_1) \\
y(x_0) = y(x_1) = 0 \\
\|y\|^2_{L^2_S} = \int_{x_0}^{x_1} y^2(x)S(x)\,dx = 1.
\end{array}\right\}
\]

podemos aplicar el [[id:e37d89ff-11da-493c-ab46-2000fe221da9][Teorema 14]] para obtener que un mínimo debe cumplir

\[\left\{\begin{array}{c}
(Py')' + (Q + \lambda S)y = 0, \\
y(x_0) = y(x_1) = 0, \\
\int_{x_0}^{x_1} y^2(x)S(x)\,dx = 1.
\end{array}\right.\]

****** Card                                                                                                :drill:
SCHEDULED: <2018-06-16 Sat>
:PROPERTIES:
:ID:       78956ad4-f53c-484e-b5c2-59b62ad5f391
:DRILL_LAST_INTERVAL: 22.662
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 5
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.2
:DRILL_EASE: 2.22
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-05-24 Thu 23:48]
:END:
¿Qué funcional bajo qué condiciones nos da un problema de
Sturm-Liouville?

\[\left\{\begin{array}{c}
(Py')' + (Q + \lambda S)y = 0, \\
y(x_0) = y(x_1) = 0, \\
\int_{x_0}^{x_1} y^2(x)S(x)\,dx = 1.
\end{array}\right.\]

******* Funcional

\[
{\cal F}[y] = \int_{x_0}^{x_1} \Big( P(x)(y'(x))^2 - Q(x)y(x)^2 \Big)\,dx
\]

******* Condiciones

\[{\cal D}_1 = \left\{\begin{array}{c}
y \in {\cal C}^1(x_0,x_1) \\
y(x_0) = y(x_1) = 0 \\
\|y\|^2_{L^2_S} = \int_{x_0}^{x_1} y^2(x)S(x)\,dx = 1.
\end{array}\right\}
\]

***** Teorema 16: problemas variacionales con Sturm-Liouville
En las condiciones de un problema de Sturm-Liouville, las funciones
propias $y_n$ se obtienen al minimizar el ${\cal F}$ [[id:99594c9a-d729-4e87-b886-c4ee6899d0d7][anterior]] sobre

\[
{\cal D}_n = \left\{\begin{array}{c}
y \in {\cal C}^1(x_0,x_1) \\
y(x_0) = y(x_1) = 0, \\
\int_{x_0}^{x_1} y^2(x)S(x)\,dx = 1 \\
\int_{x_0}^{x_1} y(x)y_1(x)S(x)\,dx = 0 \\
\vdots\\
\int_{x_0}^{x_1} y(x)y_{n-1}(x)S(x)\,dx = 0
\end{array}\right\}
\]

teniéndose además que ${\cal F}[y_n] = \lambda_n$.

****** Card                                                                                                :drill:
SCHEDULED: <2018-07-08 Sun>
:PROPERTIES:
:DRILL_CARD_TYPE: multisided
:ID:       b29a89a5-093b-41e9-84d3-c47685ee9ad9
:DRILL_LAST_INTERVAL: 34.2454
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 11
:DRILL_FAILURE_COUNT: 4
:DRILL_AVERAGE_QUALITY: 2.455
:DRILL_EASE: 1.8
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-04 Mon 22:11]
:END:

Sturm-Liouville y problemas variacionales

******* Funcional

\[
{\cal F}[y] = \int_{x_0}^{x_1} \Big( P(x)(y'(x))^2 - Q(x)y(x)^2 \Big)\,dx
\]

sobr el dominio

\[{\cal D}_1 = \left\{\begin{array}{c}
y \in {\cal C}^0(x_0,x_1) \\
y(x_0) = y(x_1) = 0 \\
\|y\|^2_{L^2_S} = \int_{x_0}^{x_1} y^2(x)S(x)\,dx = 1.
\end{array}\right\}
\]

******* Problema asociado

\[\left\{\begin{array}{c}
(Py')' + (Q + \lambda S)y = 0, \\
y(x_0) = y(x_1) = 0, \\
\int_{x_0}^{x_1} y^2(x)S(x)\,dx = 1.
\end{array}\right.\]

******* Teorema de caracterización de valores propios
Las funciones propias $y_n$ se obtienen al minimizar el ${\cal F}$ [[id:99594c9a-d729-4e87-b886-c4ee6899d0d7][anterior]]
sobre

\[
{\cal D}_n = \left\{\begin{array}{c}
y \in {\cal C}^1(x_0,x_1) \\
y(x_0) = y(x_1) = 0, \\
\int_{x_0}^{x_1} y^2(x)S(x)\,dx = 1 \\
\int_{x_0}^{x_1} y(x)y_1(x)S(x)\,dx = 0 \\
\vdots\\
\int_{x_0}^{x_1} y(x)y_{n-1}(x)S(x)\,dx = 0
\end{array}\right\}
\]

teniéndose además que ${\cal F}[y_n] = \lambda_n$.

****** Card: enunciado                                                                                     :drill:
SCHEDULED: <2018-08-29 Wed>
:PROPERTIES:
:ID:       35437f0b-383e-45ab-ba01-c030fbeb1d98
:DRILL_LAST_INTERVAL: 63.493
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.75
:DRILL_EASE: 2.32
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-27 Wed 13:20]
:END:
Enuncia el Teorema de caracterización variacional de funciones
y valores propios de un Sturm-Liouville.

******* Enunciado
En las condiciones de un problema de Sturm-Liouville, las funciones
propias $y_n$ se obtienen al minimizar el ${\cal F}$ [[id:99594c9a-d729-4e87-b886-c4ee6899d0d7][anterior]] sobre

\[
{\cal D}_n = \left\{\begin{array}{c}
y \in {\cal C}^1(x_0,x_1) \\
y(x_0) = y(x_1) = 0, \\
\int_{x_0}^{x_1} y^2(x)S(x)\,dx = 1 \\
\int_{x_0}^{x_1} y(x)y_1(x)S(x)\,dx = 0 \\
\vdots\\
\int_{x_0}^{x_1} y(x)y_{n-1}(x)S(x)\,dx = 0
\end{array}\right\}
\]

teniéndose además que ${\cal F}[y_n] = \lambda_n$.

******* Funcional

\[
{\cal F}[y] = \int_{x_0}^{x_1} \Big( P(x)(y'(x))^2 - Q(x)y(x)^2 \Big)\,dx
\]

*** 5b. Series de Fourier
**** 5.4. Fundamentos del análisis funcional                                                                 :extra:
***** Espacio considerado
Consideramos el espacio de Hilbert $L^2(I)$ con producto escalar

\[
\pair{u,v} = \int_I u(x)v(x)\,dx.
\]

***** Base hilbertiana
Un *sistema ortonormal* es una sucesión $\left\{ y_n \right\}_{n \in \mathbb{N}}$ tales que

\[
\pair{y_n,y_m} = \delta_{n,m}.
\]

Se le llama *base hilbertiana* si genera un subespacio denso.

\[
\overline{L(y_1,y_2,\dots)} = L^2(I).
\]

***** Teorema 17. Proyección ortogonal y mejor aproximación
Dado un espacio de Hilbert $H$ y un sistema ortonormal $\left\{ y_n \right\}$,
si llamamos $Y_n = L(y_1,\dots,y_{N})$, tenemos la *proyección ortogonal*
de $v$ sobre $Y_N$ dada por

\[
P_N(v) = \sum_{i=1}^N \pair{v,y_n}y_n.
\]

La proyección se caracteriza por

 * $v - P_N(v)$ es ortogonal a $Y_n$,
 * $\| v - P_N(v)\|_{H} \leq \|v - y\|_H$ para todo $y \in Y_n$.

Si además el sistema es base hilbertiana se tiene

\[
\lim_{N \to \infty} \|v - P_N(v)\|_H = 0.
\]

Llamamos *serie de Fourier* de $v$ relativa al sistema ortonormal
a la que define el límite anterior

\[
\sum_{i=1}^{\infty} \pair{v,y_n} y_n = v.
\]

***** Teorema 18. Desigualdad de Bessel e Igualdad de Bessel
Para un espacio de Hilbert $H$ y un sistema ortonormal $\left\{ y_n \right\}$ se
tiene la *Desigualdad de Bessel*: para cualquier $v \in H$,

\[
\sum_{i=0}^{\infty} |\pair{v,y_n}^2| \leq \|v\|^2_H.
\]

El sistema es completo (la base es Hilbertiana) si y sólo si
se tiene la *identidad de Bessel*: para cualquier $v \in H$,

\[
\sum_{i=0}^{\infty} |\pair{v,y_n}^2| = \|v\|^2_H.
\]

***** TODO Nota 19. Caracterizaciones de base hilbertiana

***** Teorema 19. Series de Fourier
Dado un espacio de Hilbert $L^2_S(x_0,x_1)$, un sistema ortonormal
completo $\left\{ y_n(x) \right\}$, una función $y \in L^2_S(x_0,x_1)$ y su serie de Fourier
$P_N(x)$, se cumplen.

 1. para $y$ continua y $P_N(y)$ uniformemente convergente, la suma
    de la serie es continua;

 2. si $P_N(y)$ es uniformemente convergente entonces la integral
    conmuta con la suma

    \[
    \int_{x_0}^{x_1}\sum_{n=1}^{\infty} c_ny_n(x)\,dx =
    \sum_{n=1}^{\infty} c_n\int_{x_0}^{x_1} y_n(x)\,dx.
    \]

    Nótese que si $(x_0,x_1)$ es infinito, hay que pedir integrabilidad
    de $y_n$.

 3. Si las $y_n(x)$ son derivables, $P_N(x)$ converge puntualmente y $P'_N(x)$
    converge uniformemente, entonces $y$ es derivable y la derivada
    conmuta con la suma.

    \[
    y'(x) = \sum_{n=1}^{\infty}c_ny'_n(x).
    \]

***** TODO Test de Cauchy de convergencia uniforme
***** TODO Test de Weierstrass de convergencia uniforme
**** 5.5. Series trigonométricas de Fourier
***** Teorema 20. de Riesz-Fischer
:PROPERTIES:
:ID:       a1f0e87e-9bd8-468d-ad43-7e7fb16c1b67
:END:
El conjunto de funciones trigonométricas $\left\{ y_n \right\}^{\infty}_{n =0}$ dado por

\[
y_0(x) = \frac{1}{\sqrt{T}}, \quad 
y_{2n}(x) = \sqrt{\frac{2}{T}}\cos \left( \frac{2n\pi x}{T} \right), \quad
y_{2n-1}(x) = \sqrt{\frac{2}{T}}\sen \left( \frac{2n\pi x}{T} \right)
\]

forma un sistema ortonormal completo de $L^2(0,T)$. Nótese que la
convergencia es cpd en este espacio.

****** Proof                                                                                            :exercise:
Se debe comprobar que es base normal y que son ortornormales en el
espacio $L^2(0,T)$ integrando y usando identidades trigonométricas.

****** Card                                                                                                :leech:
SCHEDULED: <2018-06-17 Sun>
:PROPERTIES:
:ID:       5b0b3868-b27b-4e52-baa0-a215080509fa
:DRILL_LAST_INTERVAL: 30.0495
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 5
:DRILL_FAILURE_COUNT: 2
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-05-18 Fri 22:06]
:END:
Dar la base ortonormal de $L^2(0,T)$ del Teorema de Riesz-Fischer.

******* Base

\[
y_0(x) = \frac{1}{\sqrt{T}}, \quad 
y_{2n}(x) = \sqrt{\frac{2}{T}}\cos \left( \frac{2n\pi x}{T} \right), \quad
y_{2n-1}(x) = \sqrt{\frac{2}{T}}\sen \left( \frac{2n\pi x}{T} \right)
\]

***** Desarrollo de una función en Serie de Fourier
Es habitual escribir el desarrollo de una función $y \in L^2(0,T)$ como

\[
y(x) = \frac{a_0}{2} + 
\sum^{\infty}_{n=1} 
a_n\cos \left( \frac{2\pi nx}{T} \right) + 
b_n\sin \left( \frac{2\pi nx}{T} \right).
\]

donde

 * \[a_0 = \frac{2}{T} \int_0^T y(x)\,dx \]

 * \[a_n = \frac{2}{T} \int_0^T y(x) \cos \left( \frac{2n\pi x}{T} \right)\,dx \]

 * \[b_n = \frac{2}{T} \int_0^T y(x) \sin \left( \frac{2n\pi x}{T} \right)\,dx \]

# TODO: Comprobar que este es efectivamente el desarrollo y calcular
# el valor de los coeficientes a_n para comprobar que cuadran con los
# dados en los apuntes.

# TODO: Comprobar que es un sistema ortonormal usando identidades
# trigonométricas.

***** Convergencia puntual: condición necesaria
Todas las $y_n$ son periódicas, así que para tener convergencia
puntual habrá que tener periodicidad en la función aproximada.

****** Card                                                                                                :drill:
SCHEDULED: <2018-06-19 Tue>
:PROPERTIES:
:ID:       31ad5eda-567d-4b54-b25f-e2e95e24a0b3
:DRILL_LAST_INTERVAL: 31.9059
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.333
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-05-18 Fri 22:07]
:END:
Por Riesz-Fischer tenemos convergencia casi por doquier de la serie de
Fourier.  ¿Cuál es la primera condición necesaria para tener
convergencia en todo punto?

******* Condición necesaria
La periodicidad de la función aproximada.

***** Convergencia puntual: a trozos
Para una función continua a trozos $y(x)$, la serie converge en todo punto
de continuidad y en los puntos de discontinuidad $a_i$ se tiene el
*fenómeno de Gibbs*,

\[
\lim_{N\to\infty} P_N(a_i) = \frac{f(a_i^+) - f(a_i^-)}{2}.
\] 

****** Card                                                                                              :nodrill:
SCHEDULED: <2018-06-11 Mon>
:PROPERTIES:
:ID:       e1a64429-139b-4b76-a77e-dbf1c41fcd9c
:DRILL_LAST_INTERVAL: 24.0119
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.32
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-05-18 Fri 22:03]
:END:
Convergencia de la serie de Fourier de una función continua a trozos.
¿Qué ocurre en los puntos de discontinuidad?

******* Convergencia
Tenemos convergencia en todo punto de continuidad, y en los puntos
de discontinuidad se produce el fenómeno de Gibbs con

\[
\lim_{N\to\infty} P_N(a_i) = \frac{f(a_i^+) - f(a_i^-)}{2}.
\] 

***** Convergencia uniforme
Para $y \in {\cal C}$ con $y(0) = y(L)$ y $y'$ continua a trozos, la serie de
Fourier converge uniformemente.

****** Proof                                                                                               :extra:
:PROPERTIES:
:ID:       55291685-9a8a-4c19-9338-570d037dd93c
:END:
Usando criterio de Weierstrass.

http://math.ucr.edu/~res/math153/fourier-uniform.pdf

****** Card                                                                                              :nodrill:
SCHEDULED: <2018-06-08 Fri>
:PROPERTIES:
:ID:       f7a7e291-c6f6-40dd-9008-3c54fd86d012
:DRILL_LAST_INTERVAL: 4.1707
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 6
:DRILL_FAILURE_COUNT: 2
:DRILL_AVERAGE_QUALITY: 3.667
:DRILL_EASE: 2.7
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-04 Mon 22:20]
:END:
¿Cuándo converge uniformemente la serie de Fourier?

******* Respuesta 
Basta tener $y \in {\cal C}$, periódica $y(0) = y(L)$ y $y'$ continua a trozos.
Es decir,

 1. continua,
 2. periódica,
 3. derivada continua a trozos.

****** TODO Ejemplo de convergencia uniforme

***** Teorema 21. Convergencia de derivadas superiores
Si $y \in {\cal C}^k[0,T]$, tiene periodicidad $y^{n)}(0) = y^{n)}(T)$ para $n = 0,\dots,k$
y la derivada $k+1$ es continua a trozos, entonces las derivadas hasta
la $k$ convergen uniformemente.

****** Proof
En este caso, iterando el resultado, tendremos que

\[
\sum_{n \geq 1} n^k(|a_n| + |b_n|),
\]

converge uniformemente para $a_n$ y $b_n$ coeficientes de Fourier.
Se aplicará un razonamiento similar al aplicado [[id:55291685-9a8a-4c19-9338-570d037dd93c][anteriormente]].

****** Card                                                                                                :drill:
SCHEDULED: <2018-09-08 Sat>
:PROPERTIES:
:ID:       3566f799-f086-4e6f-9b1c-6be4a775beae
:DRILL_LAST_INTERVAL: 70.7902
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 5
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.6
:DRILL_EASE: 2.46
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-29 Fri 09:50]
:END:
Enunciar el Teorema 21 sobre convergencia de derivadas superiores
en series de Fourier.

******* Enunciado
Si $y \in {\cal C}^k[0,T]$, tiene periodicidad $y^{n)}(0) = y^{n)}(T)$ para $n = 0,\dots,k$
y la derivada $k+1$ es continua a trozos, entonces las derivadas hasta
la $k$ convergen uniformemente.

***** Convergencia en media
La convergencia en media la da la igualdad de Bessel

\[
\frac{2}{T}\int_0^T y(x)^2\,dx = \frac{a_0^2}{2} + \sum_{n=1}^{\infty}a^2_n + b^2_n.
\]

****** Card                                                                                                :drill:
SCHEDULED: <2018-07-05 Thu>
:PROPERTIES:
:ID:       7fd53585-d7a3-4da3-8087-77d8ff760eb6
:DRILL_LAST_INTERVAL: 31.0459
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 8
:DRILL_FAILURE_COUNT: 3
:DRILL_AVERAGE_QUALITY: 2.875
:DRILL_EASE: 2.46
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-04 Mon 22:03]
:END:
Enuncia la igualdad de Bessel que da la convergencia en
media de la serie de Fourier.

******* Igualdad

\[
\frac{2}{T}\int_0^T y(x)^2\,dx = \frac{a_0^2}{2} + \sum_{n=1}^{\infty}a^2_n + b^2_n.
\]

***** TODO Cambio de intervalo
***** Teorema 22. Serie de Fourier en el intervalo (-T,T)
:PROPERTIES:
:ID:       b0018ca3-1e81-42e1-8938-727ad480fc40
:END:
Para $y \in L^2(-T,T)$ podemos desarrollar

\[
y(x) = \frac{a_0}{2} +
\sum_{n=1}^{\infty} 
a_n\cos \left( \frac{n\pi x}{T} \right) +
b_n\sin \left( \frac{n\pi x}{T} \right)
\]

siendo

 * \[a_0 = \frac{1}{T}\int_{-T}^T y(x) \,dx \]

 * \[a_n = \frac{1}{T}\int_{-T}^T y(x)\cos \left( \frac{n\pi x}{T} \right) \,dx \]

 * \[b_n = \frac{1}{T}\int_{-T}^T y(x)\sin \left( \frac{n\pi x}{T} \right) \,dx \]

****** Card                                                                                                :drill:
SCHEDULED: <2018-07-09 Mon>
:PROPERTIES:
:ID:       f254979e-2fbc-4b1d-928b-336f633977b4
:DRILL_LAST_INTERVAL: 32.7988
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 6
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.5
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-06 Wed 12:16]
:END:
Desarrollo en Serie de Fourier de $y \in L^2(-T,T)$.
(Coeficientes de ayuda).

******* Desarrollo

\[
y(x) = \frac{a_0}{2} +
\sum_{n=1}^{\infty} 
a_n\cos \left( \frac{n\pi x}{T} \right) +
b_n\sin \left( \frac{n\pi x}{T} \right)
\]

******* Coeficientes

 * \[a_0 = \frac{1}{T}\int_{-T}^T y(x) \,dx \]

 * \[a_n = \frac{1}{T}\int_{-T}^T y(x)\cos \left( \frac{n\pi x}{T} \right) \,dx \]

 * \[b_n = \frac{1}{T}\int_{-T}^T y(x)\sin \left( \frac{n\pi x}{T} \right) \,dx \]

****** Card: coeficientes                                                                                  :drill:
SCHEDULED: <2018-06-23 Sat>
:PROPERTIES:
:ID:       da80a0c6-bbfb-4437-8438-29c5af8dd817
:DRILL_LAST_INTERVAL: 30.269
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 5
:DRILL_FAILURE_COUNT: 2
:DRILL_AVERAGE_QUALITY: 2.4
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-05-24 Thu 23:49]
:END:
Determina los coeficientes del desarrollo en Serie de Fourier
en el intervalo $y \in L^2(-T,T)$.

\[
y(x) = \frac{a_0}{2} +
\sum_{n=1}^{\infty} 
a_n\cos \left( \frac{n\pi x}{T} \right) +
b_n\sin \left( \frac{n\pi x}{T} \right)
\]

******* Coeficientes

 * \[a_0 = \frac{1}{T}\int_{-T}^T y(x) \,dx \]

 * \[a_n = \frac{1}{T}\int_{-T}^T y(x)\cos \left( \frac{n\pi x}{T} \right) \,dx \]

 * \[b_n = \frac{1}{T}\int_{-T}^T y(x)\sin \left( \frac{n\pi x}{T} \right) \,dx \]

***** Teorema 23. Serie de cosenos/senos
Para $y \in {\cal C}^1(0,T)$, su serie de cosenos converge absoluta y
uniformemente (extensión par)

\[
\frac{a_0}{2} + \sum_{n=1}^{\infty}a_n\cos \left( \frac{n\pi x}{T} \right)
\]

si además $y(0) = y(T)$, su serie de senos converge absoluta y
uniformemente (extensión impar)

\[
\sum_{n=1}^{\infty} b_n \sin \left( \frac{n\pi x}{T} \right).
\]

Los coeficientes en estos casos son

 * \[a_0 = \frac{2}{T}\int_{0}^T y(x) \,dx \]

 * \[a_n = \frac{2}{T}\int_{0}^T y(x)\cos \left( \frac{n\pi x}{T} \right) \,dx \]

 * \[b_n = \frac{2}{T}\int_{0}^T y(x)\sin \left( \frac{n\pi x}{T} \right) \,dx \]


****** Extensiones par e impar
Definimos las extensiones par e impar de $y \in {\cal C}[0,T]$ al
intervalo $[-T,T]$. Nótese que en el desarrollo de una función
impar no aparecerán cosenos y en el desarrollo de una función
par no aparecerán senos.

La extensión par es siempre continua, pero la extensión
impar requiere $y(0) = y(T) = 0$. Aplicando el desarrollo en
[[id:b0018ca3-1e81-42e1-8938-727ad480fc40][serie de Fourier]] a estas extensiones es como obtenemos el
desarrollo en senos y cosenos.

**** 5.6. Solución de la ecuación de ondas
***** Teorema 24. Solución de la ecuación de ondas
Para $u_0 \in {\cal C}^2(0,L)$ con $u_0'''$ continua a trozos y $v_0 \in {\cal C}^1(0,L)$ con $v_0''$
continua a trozos, anulándose $u_0,u_0'',v_0$ en los extremos, el problema
de la ecuación de ondas simplificada

\[\left\{\begin{array}{lr}
u_{tt} = c^2 u_{xx} & t \geq 0, x \in [0,L] \\
u(0,x) = u_0(x) \in {\cal C}^2, & x \in [0,L], \\
u_t(0,x) = v_0(x) \in {\cal C}^1, & x \in [0,L], \\
u(t,0) = u(t,L) = 0, & t \geq 0.
\end{array}
\right\}\]

Tiene candidato a solución

\[
u(t,x) = \sum_{n \geq 1} 
\left( b_n\cos \left( \frac{nc\pi t}{L} \right) +
\frac{b'_nL}{nc\pi} \sin \left( \frac{n c \pi t}{L} \right) \right)
\sin \left( \frac{n\pi x}{L} \right)
\]

donde tenemos los desarrollos en senos

 * \[u_0(x) = \sum_{n \geq 1} b_n\sin \left( \frac{n \pi x}{L} \right),\quad b_n = \frac{2}{L}\int_0^L u_0(x) \sin \left( \frac{n \pi x}{L} \right),\] 

 * \[v_0(x) = \sum_{n \geq 1} b_n'\sin \left( \frac{n \pi x}{L} \right),\quad b_n' = \frac{2}{L}\int_0^L v_0(x) \sin \left( \frac{n \pi x}{L} \right).\] 

Tenemos convergencia uniforme hasta la segunda derivada.

***** 5.6.1. Unicidad y método de la energía
La unicidad de solución se demuestra comprobando que la *energía*
es constante en soluciones y la diferencia de soluciones debe ser
nula porque su energía lo es.

\[
E[u](t) = \frac{1}{2}\int_0^L \left( u_t^2 + c^2u_x^2 \right)\,dx = 0.
\]

****** Card                                                                                                :drill:
SCHEDULED: <2018-06-18 Mon>
:PROPERTIES:
:ID:       4f851785-c8d4-4153-a88c-f6460f3c860b
:DRILL_LAST_INTERVAL: 25.1088
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 6
:DRILL_FAILURE_COUNT: 3
:DRILL_AVERAGE_QUALITY: 2.333
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-05-24 Thu 23:50]
:END:
Enuncia la energía en la ecuación de ondas.

******* Energía

\[
E[u](t) = \frac{1}{2}\int_0^L \left( u_t^2 + c^2u_x^2 \right)\,dx.
\]

***** 5.6.2. Soluciones de la ecuación de ondas en R, fórmula de D'Alembert
La *ecuación de ondas* unidimensional,

\[\left\{ \begin{array}{lr}
u_{tt} = c^2u_{xx}, & t > 0, x \in \mathbb{R}, \\
u(0,x) = u_0(x) \in {\cal C}^2(\mathbb{R}), \\
u_t(0,x) = v_0(x) \in {\cal C}^1(\mathbb{R}),
\end{aligned}\right.\]

se resuelve con la Fórmula de D'Alembert.

\[
u(t,x) = \frac{u_0(x+ct) - u_0(x-ct)}{2} + \frac{1}{2c}\int_{x-ct}^{x+ct}v_0(y)\,dy.
\]

****** Resolución
Tomamos $\xi = x + ct$, $\eta = x - ct$, por lo que $x = \frac{\xi + \eta}{2}$ y $t = \frac{\xi - \eta}{2c}$.
Definimos $U(\xi,\eta) = u \left( \frac{\xi + \eta}{2} , \frac{\xi - \eta}{2} \right)$, luego $u(x,t) = U(x + ct, x -ct)$.
Calculamos, evaluando $u$ en $(x,t)$ y $U$ en $(\xi,\eta)$,

\[ \left\{\begin{array}{l}
u_{tt} = c^2U_{\xi\xi} - c^2U_{\xi\eta} - c^2U_{\eta\xi} + c^2U_{\eta\eta} \\
u_{xx} = U_{\xi\xi} + U_{\xi\eta} + U_{\eta\xi} + U_{\eta\eta}
\right.\end{array}\]

Por lo que $0 = u_{tt} - c^2u_{xx} = -4U_{\xi\eta}$. El que esta derivada sea nula
implica que $U_{\xi},U_{\eta}$ dependen de una sola de las variables, e integrando
y pasando constantes tendremos que $U$ es de la forma

\[
U(\xi,\eta) = g(\xi) + h(\eta).
\]

Deshaciendo el cambio de variables, tenemos las condiciones iniciales

\[\left\{\begin{array}{l}
u_0(x) = g(x) + h(x), \\
v_0(x) = c(g'(x) - h'(x)).
\end{array}\right.\]

Resolviendo e integrando,

\[\left\{\begin{aligned}
g(x) = K_1 + \frac{u_0(x)}{2} + \frac{1}{2c}\int_0^x v(y)}\,dy\\
h(x) = K_2 + \frac{u_0(x)}{2} - \frac{1}{2c}\int_0^x v(y)}\,dy
\end{aligned}\right.\]

y para que se cumpla la condición, $K_1 + K_2 = 0$. Sustituyendo obtenemos
la fórmula de d'Alembert.

\[
u(t,x) = \frac{u_0(x+ct) - u_0(x-ct)}{2} + \frac{1}{2c}\int_{x-ct}^{x+ct}v_0(y)\,dy.
\]

****** Comentario: cono de luz
**** 5.7. Solución de la ecuación de Dirichlet
***** Laplaciano en polares
Aplicando el cambio de variable $U(\rho,\theta) = u(\rho\cos(\theta), \rho\sin(\theta))$, tenemos
el laplaciano en polares

\[
\left( U_{\rho\rho} + \frac{U_{\theta\theta}}{\rho^2} + \frac{U_{\rho}}{\rho} \right)(\rho,\theta) =
(\Delta_x u)(\rho\cos(\theta),\rho\sin(\theta)).
\]

***** Ecuación de Dirichlet en el disco
Viendo la [[id:8e9ccec0-c9de-4d00-a08e-3de44d448ca5][ecuación de Dirichlet]] en el disco $D$ tenemos $\mathbb{S}^1 = \partial D$
y definimos $\overline{\gamma}(\theta) = \gamma(\cos(\theta),\sin(\theta))$. El problema de Dirichlet queda
como

\[\left\{\begin{array}{ll}
U_{\rho\rho} + \frac{U_{\theta\theta}}{\rho^2} + \frac{U_{\rho}}{\rho} = 0, &
\forall(\rho,\theta) \in (0,1] \times [0,2\pi],\\
U(1,\theta) = \overline{\gamma}(\theta), & \theta \in [0,2\pi], \\
U(\rho,0) = U(\rho,2\pi), & \rho \in (0,1], \\
\end{array}\right.\]

La resolución se hace por separación de variables $U(\rho,\theta) = v(p)w(\theta)$.

***** Ecuación de Dirichlet en el rectángulo
*** 6. Formulación débil
**** 6.1. Derivada generalizada y débil
***** Fórmula de Green
Para $u \in {\cal C}^1(\overline{\Omega})$, $v \in {\cal C}^1_0(\overline{\Omega})$, la derivada la caracteriza la
*Fórmula de Green*

\[
\int_{\Omega} u_{x_i}(x) v(x) \,dx = 
-\int_{\Omega} u(x)v_{x_i}(x)\,dx.
\]

****** Clave 1: derivadas caracterizadas
:PROPERTIES:
:ID:       893398fe-a78e-45a4-b0dd-d4e36bc98d78
:END:
Dados $u \in {\cal C}^1(\overline{\Omega})$ y $g \in {\cal C}^0(\overline{\Omega})$, si para cualquier $v \in {\cal C}^1_0(\Omega)$

\[
\int_{\Omega} g(x)v(x)\,dx = - \int_{\Omega} u(x)v_{x_i}(x)\,dx,
\]

entonces $u_{x_i} = g$.

******* Proof
Consecuencia directa del [[id:652bdddb-0853-4a9a-8060-28a730928816][lema fundamental]].
****** Clave 2: operador lineal de Green
:PROPERTIES:
:ID:       c34bbc56-aa81-404b-a6ea-0670000f306b
:END:
Para $u \in L_{loc}^1(\Omega)$ (integrable sobre compactos), se define un
operador lineal $L \colon {\cal C}^1_0(\Omega) \to \mathbb{R}$ como

\[
L_u[v] = - \int_{\Omega} u(x)(\partial_{x_i}v(x))\,dx.
\]

Que caracteriza propiedades de la derivada sin necesitar
derivabilidad.

****** Caso general                                                                                        :extra:
Dadas $u,v \in {\cal C}^1(\overline{\Omega})$, para $\Omega \subset \mathbb{R}^N$, si llamamos $n_i(x)$ a la
componente del vector $n(x)$ normal a $\partial\Omega$ en $x$, tenemos la
siguiente generalización de la regla de la cadena.

\[\int_{\Omega} u(x) v_{x_i}(x) \,dx = 
-\int_{\Omega} u_{x_i}(x)v(x)\,dx +
\int_{\partial\Omega} u(x)v(x)n_i(x)\,dS.
\]

****** Card                                                                                                :drill:
SCHEDULED: <2018-08-02 Thu>
:PROPERTIES:
:ID:       2f8ab0e2-d672-4822-8957-da14137f3350
:DRILL_LAST_INTERVAL: 70.427
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 7
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.857
:DRILL_EASE: 2.56
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-05-24 Thu 23:53]
:END:
Enunciar la fórmula de Green para $u \in {\cal C}^1(\overline{\Omega})$ y $v \in {\cal C}^1_0(\overline{\Omega})$; es decir,
para el caso de frontera nula.

******* Enunciado
La fórmula de Green es un análogo a la integración por partes para
varias variables. Normalmente tiene un término más, pero cuando
$v$ se anula en la frontera,

\[
\int_{\Omega} u(x) (\partial_{x_i}v(x)) \,dx = 
-\int_{\Omega} (\partial_{x_i}u(x))v(x)\,dx.
\]

***** Derivada generalizada o distribucional
Para $u \in L_{loc}^1(\Omega)$, la *derivada generalizada* $\pair{u_{x_i},-} \colon {\cal C}^{\infty}_0(\Omega) \to \mathbb{R}$
se define

\[
\left\langle u_{x_i}, v \right\rangle =
-\left\langle u, v_{x_i} \right\rangle =
-\int_{\Omega} u(x)v_{x_i}(x)\,dx.
\]

***** Derivada débil
Para $u \in L_{loc}^1(\Omega)$, decimos $u_{x_i} = g \in L^1_{loc}(\Omega)$ en sentido *débil* si

\[
\forall v \in {\cal C}^{\infty}_0(\Omega)\colon\quad \pair{u_{x_i},v} = \pair{g,v}.
\]

****** Card                                                                                                :drill:
SCHEDULED: <2018-06-21 Thu>
:PROPERTIES:
:ID:       29496071-ee41-4f3e-94f0-15f048942995
:DRILL_LAST_INTERVAL: 16.9877
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 5
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.8
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-04 Mon 22:07]
:END:
Decimos $u_{x_i} = g \in L^1_{loc}(\Omega)$ en sentido *débil* si

******* Respuesta

\[
\forall v \in {\cal C}^{\infty}_0(\Omega)\colon\quad 
\pair{u_{x_i},v} := -\pair{u,v_{x_i}} = \pair{g,v}.
\]

***** Función Heaviside y Delta de Dirac
La *función de Heaviside* $H(x) = \max\left\{ 0,x/|x| \right\}$ está definida
c.p.d. Su derivada generalizada puede calcularse sabiendo $v \in {\cal C}^{\infty}_0(\mathbb{R})$
como

\[\left\langle H',v \right\rangle = 
-\int_{\mathbb{R}} H(x)v'(x)\,dx =
-[v(x)]^{\infty}_0 = v(0).\]

Es decir, su derivada débil es la *Delta de Dirac*, $\delta_0(v) = v(0)$.

**** 6.1.1. Espacios de Sobolev
***** Espacio de Sobolev
Para $\Omega \subseteq \mathbb{R}^N$ dominio, $p \in [1,\infty]$, se define el *espacio de Sobolev*

\[
W^{m,p}(\Omega) = \left\{ u \in L^p(\Omega) \;\middle|\;
\pdv[\abs{\alpha}]{u}{x} \in L^p(\Omega),\, \forall 0 \leq \alpha \leq m \in \mathbb{N} \right\}.
\]

/El espacio de las m-derivadas p-integrables./

****** Card                                                                                                :drill:
SCHEDULED: <2018-07-07 Sat>
:PROPERTIES:
:ID:       e5522b23-1312-4980-b0ac-2d736e86d2e7
:DRILL_LAST_INTERVAL: 44.4198
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 5
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.4
:DRILL_EASE: 2.32
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-05-24 Thu 23:56]
:END:
Para $\Omega \subseteq \mathbb{R}^N$ dominio, define el *espacio de Sobolev* $W^{m,p}(\Omega)$.

******* Espacio de Sobolev
El espacio de las m-derivadas p-integrables.

\[
W^{m,p}(\Omega) = \left\{ u \;\middle|\;
\pdv[\abs{\alpha}]{u}{x} \in L^p(\Omega),\, \forall 0 \leq \alpha \leq m \right\}.
\]

***** Norma de espacios de Sobolev
:PROPERTIES:
:ID:       192a4ee0-0514-42cb-96e6-e4eb68c3ab41
:END:
El espacio $W^{m,p}(\Omega)$ con la norma

\[
\|u\|_{W^{m,p}(\Omega)} = 
\left( \|u\|^{p}_p +
\sum_{0 \leq \alpha \leq m} \norm{\pdv[\abs{\alpha}]{u}{x}}^p_p \right)^{1/p}
\]

es un espacio de Banach. En el caso $p=2$ notamos como $H^m(\Omega) = W^{m,2}(\Omega)$
y es un espacio de Hilbert. En particular

\[
H^1(\Omega) = \left\{ u \in L^2(\Omega) \mid \pdv{u}{x_i} \in L^2(\Omega), \forall i = 1,\dots,N \right\}
\]

teniendo el producto escalar

\[
\pair{u,v}_{H^1(\Omega)} = 
\int_{\Omega} (uv + \nabla u \cdot \nabla v)\,dx.
\]

****** Card                                                                                                :drill:
SCHEDULED: <2018-06-17 Sun>
:PROPERTIES:
:ID:       99ab3e47-4a1e-4f57-bb0c-f498dd36cc38
:DRILL_LAST_INTERVAL: 24.2486
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.667
:DRILL_EASE: 2.32
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-05-24 Thu 23:46]
:END:
¿Cuál es el producto escalar en $H^1(\Omega)$?

******* Respuesta

\[
\pair{u,v}_{H^1(\Omega)} = 
\int_{\Omega} (uv + \nabla u \cdot \nabla v)\,dx.
\]

***** Ejemplo 32. Espacios de integrabilidad
Para $\beta \in \mathbb{R}$ y $\overline{B} \subset \mathbb{R}^{N}$ una bola centrada en el origen

 * $\frac{1}{\abs{x}^{\beta}} \in L^p(\overline{B})$ si y sólo si $\beta p < N$,

 * $\frac{1}{\abs{x}^{\beta}} \in L^q(\mathbb{R}^n - \overline{B})$ si y sólo si $\beta q > N$, con $q < +\infty$.

****** Proof
Integramos usando la fórmula de [[id:8b7c51f7-5499-4cd3-a1c6-cab635bd0015][integración en polares]] y
llegaremos hasta una integral que es finita sólo cuando
$\beta p + 1 - N < 1$.

****** Card                                                                                                :drill:
SCHEDULED: <2018-07-27 Fri>
:PROPERTIES:
:ID:       62ba0268-3776-4f16-9fdd-0dab96753381
:DRILL_LAST_INTERVAL: 51.0746
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 5
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.8
:DRILL_EASE: 2.56
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-06 Wed 12:12]
:END:
Estudia integrabilidad de $1/|x|^{\beta}$ en $\overline{B}$ y en $\mathbb{R}^N-\overline{B}$.

******* Respuesta

 * \[\frac{1}{\abs{x}^{\beta}} \in L^p(\overline{B}) \iff \beta p < N\]

 * \[\frac{1}{\abs{x}^{\beta}} \in L^q(\mathbb{R}^n - \overline{B}) \iff \beta q > N\], 

con $q < +\infty$.

**** 6.2. Repaso de análisis funcional
***** Teorema fundamental del cálculo
Dada $f \in L_{loc}^1(a,b)$ y un $c \in (a,b)$, definimos la *primitiva* de $f$
que se anula en $c$ como

\[
F(x) = \int_c^x f(s)\,ds.
\]

Sabemos que $F$ es continua y tiene derivada débil en $(a,b)$ que
es igual a $f$ c.p.d.

****** Proof
Por definición, partiendo la integral,

\[
\left\langle F',\phi \right\rangle =
\int_a^c\int_x^c f(s)\phi'(x)\,dsdx -
\int_c^b\int_c^x f(s)\phi'(x)\,dsdx.
\]

Aplicamos Teorema de Fubini independientemente en las dos
variabes, sabiendo que $f\phi' \in L_{loc}^1$,

\[
\left\langle F',\phi \right\rangle =
\int_a^c f(s) \int_a^s \phi'(x)\,dxds -
\int_c^b f(s) \int_s^b \phi'(x)\,dxds.
\]

Usamos Barrow dos veces en la integral interna para tener,
sabiendo que $\phi(a)=\phi(b)=0$,

\[
\left\langle F',\phi \right\rangle =
\int_a^c f(s)\phi(s)\,ds -
\int_c^b f(s)(-\phi(s))\,ds = \left\langle f,\varphi \right\rangle.
\]

En un caso más general del [[id:893398fe-a78e-45a4-b0dd-d4e36bc98d78][comentado anteriormente]], esto
nos da que $f = F'$ c.p.d.

# Tenemos que no son continuas, sólo integrables. Cómo se generaliza a
# este caso no queda del todo claro, porque usábamos crucialmente antes
# la conservación del signo de funciones continuas.

****** Card                                                                                                :drill:
SCHEDULED: <2018-08-15 Wed>
:PROPERTIES:
:ID:       48323a75-8295-4d00-af02-7a57721d5269
:DRILL_LAST_INTERVAL: 89.3989
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 8
:DRILL_FAILURE_COUNT: 2
:DRILL_AVERAGE_QUALITY: 3.625
:DRILL_EASE: 2.76
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-05-18 Fri 22:13]
:END:
Enunciar el teorema fundamental del cálculo en su versión débil
para una $f \in L_{loc}^1(a,b)$ y un $c \in (a,b)$.

******* Enunciado
La función

\[
\int_c^x f(s)\,ds
\]

 * es continua
 * y tiene derivada débil en $(a,b)$ igual a $f$ c.p.d.

***** Desigualdad de Poincaré
:PROPERTIES:
:ID:       9d2c746b-11e7-4055-9608-3d1e6b0cc136
:END:
Para $\Omega$ dominio acotado y $u \in H_0^1(\Omega)$ existe una constante $C$
dependiente solo de $\Omega$ tal que

\[
\int_{\Omega} u^2\,dx \leq C \int_{\Omega} |\nabla u|^2\,dx.
\]

****** Proof
:PROPERTIES:
:ID:       7d0050e4-8d08-4e26-9aef-f6a4572748a9
:END:
En una variable, si minimizamos la integral de la derivada
al cuadrado fijando el módulo al cuadrado, llegamos a una
[[id:e15aa2f8-76b4-4aa6-82bb-c0b424bda884][Sturm-Liouville]] que hemos resuelto. Aplicamos esa minimización
a cualquier funcional normalizado para tener la desigualdad
con la cota

\[
C = \left(\frac{x_1-x_0}{n\pi}\right)^2.
\]

Todo esto lo prueba para funciones ${\cal C}_0^{\infty}$, pero podemos
usar que $H_0^1 = \overline{{\cal C}_0^{\infty}}^{H^1}$ para tener una convergencia $\norm{u_n-u}^2_H \to 0$,
que nos da, sabiendo la [[id:7d0050e4-8d08-4e26-9aef-f6a4572748a9][norma]] de este Hilbert

\[
\int_{x_0}^{x_1} \left( u'_n-u' \right)^2\,dx + \int_{x_0}^{x_1} \left( u_n -u \right)^2\,dx \to 0.
\]

luego $\norm{u_n' - u'}_{L^2} \to 0$ y $\norm{u_n - u}_{L^2} \to 0$, por lo que

\[
\int_{x_0}^{x_1} u_n^2\,dx \to \int_{x_0}^{x_1} u^2\,dx.
\]

\[
\int_{x_0}^{x_1} u_n'^2\,dx \to \int_{x_0}^{x_1} u'^2\,dx.
\]

y tomando límites en el caso ${\cal C}_0^\infty$, se tiene lo buscado.sss

****** Card                                                                                                :drill:
SCHEDULED: <2018-08-18 Sat>
:PROPERTIES:
:ID:       132abd02-1210-4329-b150-e7bdbd5fe70b
:DRILL_LAST_INTERVAL: 50.3547
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.75
:DRILL_EASE: 2.32
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-29 Fri 09:51]
:END:
Enuncia la desigualdad de Poincaré para $u \in H^1_0(\Omega)$.

******* Enunciado

\[
\int_{\Omega} u^2\,dx \leq C \int_{\Omega} |\nabla u|^2\,dx.
\]

donde $C$ depende de $\Omega$.

****** Card                                                                                                :drill:
:PROPERTIES:
:ID:       ec463032-b0df-40eb-8423-4758b7d57763
:END:
Idea de la demostración de la desigualdad de Poincaré.

\[
\int_{\Omega} u^2\,dx \leq C \int_{\Omega} |\nabla u|^2\,dx.
\]


******* Idea
En una variable, si minimizamos la integral de la derivada
al cuadrado fijando el módulo al cuadrado, llegamos a una
[[id:e15aa2f8-76b4-4aa6-82bb-c0b424bda884][Sturm-Liouville]] que hemos resuelto.

Todo esto lo prueba para funciones ${\cal C}_0^{\infty}$, pero podemos
usar que $H_0^1 = \overline{{\cal C}_0^{\infty}}^{H^1}$ para tener una convergencia $\norm{u_n-u}^2_H \to 0$,
que nos implica $\norm{u_n' - u'}_{L^2} \to 0$ y $\norm{u_n - u}_{L^2} \to 0$.

***** Norma equivalente en el Sobolev de Hilbert
Para $\Omega$ acotado, 

\[
\vertiii{u} = \sqrt{ \int_{\Omega} \abs{\nabla u}^2\,dx }
\]

es una norma de $H_0^1(\Omega) \leq H^1(\Omega)$, equivalente a la heredada.

****** Proof
Por [[id:9d2c746b-11e7-4055-9608-3d1e6b0cc136][desigualdad de Poincaré]].

***** Teorema de Riesz
Para $H$ hilbert, toda lineal continua viene representada por un
único elemento con su misma norma.

***** Propiedades de los Hilbert
 * Para $A \subset H$, se tiene $A^{\bot}^{\bot} = \overline{\pair{A}}$.
 * Para $V \leq H$ denso, $V^{\bot} = \left\{ 0 \right\}$.

**** 6.3. Teorema de Lax-Milgram
***** Ejemplo de la membrana
El problema de la [[id:f0ac6c21-d9c3-4298-b48e-8602ca0948a5][membrana simplificado]] puede escribirse como 
tres problemas equivalentes.

****** Problema variacional
Buscar $u \in H_0^1(\Omega)$ que minimice

\[
{\cal E}[u] = \int_{\Omega} \left( 
\frac{\sigma(x)}{2}\abs{\nabla u}^2 + \frac{\alpha}{2}u^2 - f(x)u
\right)\,dx.
\]

****** Ecuación diferencial
Encontrar extremales $u \in H_0^1(\Omega)$ que resuelvan

\[
\sigma \Delta_x u = \alpha u  - f.
\]

****** Formulación débil
Buscar $u \in H^1_0$ tal que el razonamiento que lleva a Euler-Lagrange
sea cierto para todo $\phi \in H_0^1$.

\[
\int_{\Omega} \left(
\sigma\nabla u \cdot \nabla \phi + \alpha u \phi
\right)\,dx - 
\int_{\Omega} \left(
f \phi
\right)\,dx = 0
\]

Podemos observar una parte cuadrática $\alpha(u,\phi)$ en el primer sumando
y una parte lineal $\tf(\phi)$ en el segundo. Es decir,

\[
a(u,\phi) - \tf(\phi) = 0.
\]

Si consideramos $J(u) = \frac{1}{2}a(u,u) - \tf(u)$, minimizar este operador
es de nuevo el problema variacional.

***** TODO Tipos de solución

 * Clásica.
 * Distribucional. $L^1_{loc}(\Omega)$ $a(u,v) = \tf(v)$.
 * Débil. $H_0^1(\Omega)$, $a(u,v) = \tf(v)$.
 * Variacional. $H^1_0(\Omega)$ con $J(u) \leq J(v)$.

***** Teorema 30. Teorema de Lax-Milgram
$a \colon H \times H \to \mathbb{R}$ bilineal continua coerciva $\exists \alpha \colon \forall v \in H\colon  \alpha \norm{v}^2_H \leq a(v,v)$
sobre un Hilbert. Sea $\tf \colon H \to \mathbb{R}$ lineal continua. Hay solución única de

\[(\text{\textit{Formulación débil}})\left\{\begin{array}{l}
\overline{u} \in H, \\
\forall v \in H\colon\ a(\overline{u},v) = {\tilde f}(v).
\end{aligned}\right.\]

Y la solución cumple,

\[
\norm{u_{\tf}}_H \leq \frac{1}{\alpha}\norm{\tilde f}_{H'},
\]

por lo que $\tf\mapsto u_{\tf}$ es continua.

Cuando $a$ simétrica, $u_\tf$ es la única solución de

\[(\text{\textit{Problema variacional}})\left\{\begin{array}{l}
\overline{u} \in H, \\
\forall v \in H\colon\ J(\overline{u}) \leq J(v),
\end{aligned}\right.\]

donde $J(u) = \frac{1}{2} a(u,u) - \tf(u)$.

****** Demostración: parte 1
Fijado $u \in H$, por Riesz sobre $a(u,-) \colon H \to \mathbb{R}$, lineal continua,
tenemos $Au$, lineal, con $\pair{Au,v} = a(u,v)$ para cualquier $v \in H$.
Por Riesz y por continuidad de $a$ tenemos

\[
\|Au\|_H = \|a(u,-)\|_{H'} = \sup \frac{|a(u,v)|}{\|v\|_H} \leq
\sup \frac{C\norm{u}\norm{v}}{\|v\|} \leq C \|u\|
\]

y $A$ es *continua*. Tenemos *inyectividad* de $A$ por coercividad

\[
\alpha \norm{v}^2_H \leq
a(v,v) = \pair{Av,v} \leq
\norm{Av}_H\norm{v}_H,\quad
\|v\|_H \leq \frac{1}{\alpha}\|Av\|_H
\]

Tenemos $A(H)$ *denso* de nuevo por coercividad, porque si $v_0 \in A(H)^{\bot}$,
$a(v_0,v_0) = 0$ y $A(H)^{\bot} = 0$; esto da densidad en un Hilbert.
Tenemos $A(H)$ *cerrado* porque la inversa de $A$ en su imagen
es continua por la desigualdad anterior, luego $H \cong A(H)$ y $H$ es completo.
Así $H = A(H)^{\bot^{\bot}} = \overline{A(H)} = A(H)$ y es *sobreyectiva*.

También por Riesz tenemos $\tilde{f} = \pair{f,v}$, el PD es $Au = f$, con solución
única por biyectividad. La desigualdad se tiene por Riesz,

\[
\norm{u_f} =
\norm{A^{-1}(f)}_H \leq
\frac{1}{\alpha}\norm{f}_H =
\frac{1}{\alpha}\norm{\tilde f}_{H'}.
\]

****** Demostración: parte 2
Cuando $a$ es simétrica tenemos

\[
J(u+v) = J(u) + \left( a(u,v)-{\tilde{f}}(v) \right) + \frac{1}{2}a(v,v)
\]

y cuando $u_f$ es solución del PD, aplicamos coercividad para
obtener el único mínimo global

\[
J(u_f+v) = J(u_f) + \frac{1}{2}a(v,v) \geq J(u_f) + \frac{\alpha}{2}\norm{v}_H > J(u_f).
\]

****** Card                                                                                                :drill:
SCHEDULED: <2018-06-19 Tue>
:PROPERTIES:
:ID:       54bc4de7-db60-426c-bcbb-08e80dbc2824
:DRILL_LAST_INTERVAL: 31.8409
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.22
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-05-18 Fri 22:05]
:END:
Enuncia Lax-Milgram

******* Enunciado
$a \colon H \times H \to \mathbb{R}$ bilineal continua coerciva, $\exists \alpha \colon \forall v \in H\colon  \alpha \norm{v}^2_H \leq a(v,v)$,
sobre un Hilbert. Sea $\tf \colon H \to \mathbb{R}$ lineal continua. Hay solución única de

\[(\text{\textit{Formulación débil}})\left\{\begin{array}{l}
\overline{u} \in H, \\
\forall v \in H\colon\ a(\overline{u},v) = {\tilde f}(v).
\end{aligned}\right.\]

Y la solución cumple,

\[
\norm{u_{\tf}}_H \leq \frac{1}{\alpha}\norm{\tilde f}_{H'},
\]

por lo que $\tf\mapsto u_{\tf}$ es continua.

Cuando $a$ simétrica, $u_\tf$ es la única solución de

\[(\text{\textit{Problema variacional}})\left\{\begin{array}{l}
\overline{u} \in H, \\
\forall v \in H\colon\ J(\overline{u}) \leq J(v),
\end{aligned}\right.\]

donde $J(u) = \frac{1}{2} a(u,u) - \tf(u)$.

*** 7. Ley de acción de masas
**** 7.1. Ley de acción de masas
***** Formulación
La *ley de acción de masas* dice que, en una reacción

\[
A+B \overset{k}\longrightarrow C
\]

donde las concentraciones de material se escriben como $a,b,c$, la
velocidad de reacción es proporcional al producto de las
concentraciones de las sustancias que la originan.

\[
c'(t) = ka(t)b(t)
\]

***** Formulación en reacciones bidireccionales
Dada una fórmula bidireccional,

\[A+B \xrightleftharpoons[k_2]{k_1} C\]

la ley de acción de masas se aplica sobre cada una
de las reacciones, cada una con una constante

 * $a'(t) = k_2c(t) - k_1a(t)b(t)$,

 * $b'(t) = k_2c(t) - k_1a(t)b(t)$,

 * $c'(t) = k_1a(t)b(t) - k_2c(t)$.

Existe una *constante de equilibrio* entre concentraciones sobre la
que no se mueve la reacción.

\[
k_{eq} := \frac{k_2}{k_1} = \frac{[A]_{eq}[B]_{eq}}{[C]_{eq}}
\]

****** Card                                                                                                :drill:
SCHEDULED: <2018-07-28 Sat>
:PROPERTIES:
:ID:       0ff2edea-e9e8-4899-bc7a-5483b34ca087
:DRILL_LAST_INTERVAL: 28.5434
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-29 Fri 10:23]
:END:
Aplica la ley de acción de masas sobre la fórmula.

\[A+B \xrightleftharpoons[k_2]{k_1} C\]

******* Answer

  $a' = k_2c - k_1ab$,

  $b' = k_2c - k_1ab$,

  $c' = k_1ab - k_2c$.

**** 7.2. Modelo de Michaelis-Menten
***** Modelo inicial de Michaelis-Menten
El modelo de Michaelis-Merten queda determinado por

 * $S+E \xrightleftharpoons[k_{-1}]{k_1} SE$

 * $SE \overset{k_2}\longrightarrow P + E$

Llamamos en este caso

 * $s(t) = [S]$, nutrientes,
 * $e(t) = [E]$, receptores libres,
 * $c(t) = [SE]$, receptores ocupados,
 * $p(t) = [P]$, producto.

Con condiciones iniciales

 * $s(0) = s_0$, alimento inicial,
 * $e(0) = e_0$, enzimas iniciales,
 * $c(0) = 0$, sin enzimas llenas iniciales,
 * $p(0) = 0$, sin producto inicial.

Llegamos a las ecuaciones

 * $s' = -k_1se + k_{-1}c$
 * $e' = -k_1se + k_{-1}c + k_2c$
 * $c' = k_1se - k_{-1}c - k_2c$
 * $p' = k_2c$

****** Card                                                                                              :nodrill:
SCHEDULED: <2018-07-23 Mon>
:PROPERTIES:
:ID:       521ee441-1af7-44a6-a91f-f16440121990
:DRILL_LAST_INTERVAL: 23.8294
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 5
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.4
:DRILL_EASE: 2.32
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-29 Fri 17:43]
:END:
Reacciones del modelo de Michaelis-Merten.

******* Reacciones

 * $S+E \xrightleftharpoons[k_{-1}]{k_1} SE$

 * $SE \overset{k_2}\longrightarrow P + E$

***** Modelo simplificado de Michaelis-Menten
Simplificamos.

 * La $p$ está desacoplada, resolvemos en función de $c$

   \[
   p(t) = \int_0^tk_2c(s)\,ds.
   \]

 * La suma de enzimas libres y ocupadas no varía

     \[
   \dv{c}{t} + \dv{e}{t} = 0,\qquad
   e(t) = e_0 - c(t).
   \]

Obtenemos finalmente,

 * $s' = -k_1e_0s + (k_1s + k_{-1})c$,
 * $c' = k_1e_0s - (k_1s + k_{-1} + k_2)c$.

Con condiciones iniciales, $s(0)=s_0$ y $c(0) = 0$.

***** Adimensionalización de Michaelis-Menten
Consideramos unidades de tiempo $\brck{T}$ y unidades de concentración $\brck{C}$.
Calculamos

 * $\brck{k_1} = \brck{T}^{-1}\brck{C}^{-1}$,
 * $\brck{k_{-1}} = \brck{T}^{-1}$,
 * $\brck{k_{2}} = \brck{T}^{-1}$.

Definimos el tiempo adimensional $\tau = k_1e_0t$ y tomamos.

\[
u(\tau) = \frac{1}{s_0}s \left( \frac{\tau}{k_1e_0} \right)
\]

\[
v(\tau) = \frac{1}{e_0}c \left( \frac{\tau}{k_1e_0} \right)
\]

Derivando y tomando $\lambda = \frac{k_2}{k_1s_0}$, $k=\frac{k_{-1}+k_2}{k_1s_0}$ y $\epsilon = \frac{e_0}{s_0}$,

\[
u' = -u + (u+k-\lambda)v
\]

\[
\epsilon v' = u - (u + k)v
\]

con condiciones $u(0)=1$ y $v(0)=0$. Podemos probar que están acotadas
con $0 \leq u \leq 1$ y con $0 \leq v < 1/\epsilon$. Concluimos $\omega = +\infty$. Por Picard-Lindelöf
hay solución única.

****** TODO Proof

***** Positividad y acotación en Michaelis-Menten
Puede comprobarse 

 - *unicidad* con Picard-Lindelöf,
 - *positividad* con lema de primer instante,
 - *acotación* definiendo $h = u+\varepsilon v$, que tiene $h' \leq 0$,
 - *comportamiento en infinito*, $u,v \to 0$ cuando $t \to \infty$ por Barbalat.

*** 8. Dinámica de poblaciones y Ley de Fick
**** 8.1. Modelo
***** Teorema de la divergencia de Gauss
:PROPERTIES:
:ID:       c87531f2-0004-425a-9b15-058eb2854731
:END:
Dada $F \colon \Omega \to \mathbb{R}^N$ con $\partial\Omega$ suficientemente regular, tenemos

\[
\int_{\Omega} \mathrm{div}(F)\,dx = \int_{\partial \Omega} F \cdot n \,dS,
\]

donde el operador de *divergencia* está definido como

\[
\mathrm{div}(F) = \pdv{F_1}{x_1} + \dots + \pdv{F_N}{x_N}.
\]

****** Card: divergencia                                                                                   :drill:
SCHEDULED: <2018-07-26 Thu>
:PROPERTIES:
:ID:       42fe30e9-4824-4592-8874-d687ea2a6ac7
:DRILL_LAST_INTERVAL: 26.8781
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.667
:DRILL_EASE: 2.7
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-29 Fri 09:52]
:END:
Define el operador de divergencia

\[
\mathrm{div}(F) = \dots
\]

******* Answer

\[
\mathrm{div}(F) = \pdv{F_1}{x_1} + \dots + \pdv{F_N}{x_N}.
\]

****** Card: teorema                                                                                       :drill:
SCHEDULED: <2018-07-30 Mon>
:PROPERTIES:
:ID:       4fcc3170-b015-4315-a725-6cedd121e585
:DRILL_LAST_INTERVAL: 31.476
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-29 Fri 09:53]
:END:
Enuncia el teorema de la divergencia de Gauss.

******* Answer
Dada $F \colon \Omega \to \mathbb{R}^N$ con $\partial\Omega$ suficientemente regular, tenemos

\[
\int_{\Omega} \mathrm{div}(F)\,dx = \int_{\partial \Omega} F \cdot n \,dS,
\]

***** Modelo
Dada una *densidad de población* $u$, consideramos que la población
cambia por crecimiento y por movimiento

\[
\dv{}{t}\int_{\Omega} u(t,x)\,dx = 
\int_{\Omega} f(u)\,dx + \int_{\partial \Omega} -J(t,x) \cdot n(x)\,dS,
\]

aplicando el [[id:c87531f2-0004-425a-9b15-058eb2854731][Teorema de la divergencia]], nos queda

\[
\dv{}{t}u + \mathrm{div}(J) = f.
\]

***** Primera Ley de Fick y segunda Ley de Fick
Consideramos que la corriente en un punto fluye de las zonas más densas
a las menos densas, *Ley de Fick*,

\[
J(x,t) = -D \nabla_x u.
\]

Desde aquí, en el caso $f = 0$, se obtiene la *ecuación del calor* o
*segunda Ley de Fick*,

\[
\dv{}{t}u = D \Delta u.
\]

****** Proof
Usamos crucialmente que la divergencia del gradiente es el laplaciano.

\[
\mathrm{div}(\nabla u) = \Delta u.
\]

***** Ley de conservación
**** 8.2. Modelos de dinámica de poblaciones
***** Modelo de Malthus
Tasa positiva constante de crecimiento fijada una población inicial $u(0) = u_0$.

\[
u'(t) = \alpha u(t)
\]

La solución sería exponencial $u(t) = u_0e^{\alpha t}$. Dependiendo
del valor de $\alpha$, llegamos a *sobrepoblación* exponencial o a
*extinción*.

****** Card                                                                                                :drill:
SCHEDULED: <2018-06-19 Tue>
:PROPERTIES:
:ID:       3053bb75-f914-4410-856b-b1c77728f2b5
:DRILL_LAST_INTERVAL: 15.4559
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 5.0
:DRILL_EASE: 2.7
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-04 Mon 22:16]
:END:
Ecuación del modelo de Malthus.

******* Answer

\[
u'(t) = \alpha u(t)
\]

***** Modelo logístico de Verlhust
Tasa cambiante según los recursos.  Tenemos una *capacidad máxima de carga*
$u_{\infty}$ a partir de la cual vuelve a decrecer la población. Sólo tenemos una
constante $\alpha$ que marca la *tasa intrínseca*.

\[
u'(t) = \alpha \left( 1 - \frac{u(t)}{u_{\infty}} \right)u(t)
\]

Tenemos una ecuación autónoma con equilibrio en $0$ y en $u_{\infty}$, siendo el
segundo un atractor.

****** Derivación del modelo                                                                               :extra:
Suponemos que $\alpha(t) = k_1c(t)$, donde $c$ es la cantidad de
recursos y suponemos que la reproducción consume recursos, 
$c'(t) = -k_2u'(t)$. Obtenemos $\alpha(t) = k_1(c_0+k_2u_0-k_2u(t))$,
que nos lleva a llamar a toda la constante $\alpha = k_1(c_0 + k_2u_0)$ y
llamar $u_{\infty} = k_2/(c_0 + k_2u_0)$ para obtener la fórmula.

****** Card                                                                                                :drill:
SCHEDULED: <2018-07-26 Thu>
:PROPERTIES:
:ID:       c5c6cf39-5ee7-4fe8-97cd-7d3c6d339190
:DRILL_LAST_INTERVAL: 26.724
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 5.0
:DRILL_EASE: 2.8
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-29 Fri 09:52]
:END:
Ecuación del modelo logístico de Verlhust.

******* Answer

\[
u'(t) = \alpha \left( 1 - \frac{u(t)}{u_{\infty}} \right)u(t)
\]

***** Efecto Alle fuerte
Tasa cambiante y con un mínimo inferior $u_{min}$. 

\[
u(t) = \alpha \left( 1 - \frac{u}{u_{\infty}} \right) \left( \frac{u}{u_{min}} - 1 \right).
\]

De nuevo la resolución nos da una ecuación autónoma con equilibrios
estables en $u_{\infty}$ y en $0$, pero equilibrio inestable en $u_{min}$.

****** Card                                                                                                :drill:
SCHEDULED: <2018-07-31 Tue>
:PROPERTIES:
:ID:       f6ebc901-c8ae-4ee8-b3fc-6df77c73ffdf
:DRILL_LAST_INTERVAL: 31.7039
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.667
:DRILL_EASE: 2.7
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-29 Fri 17:51]
:END:
Ecuación del modelo con efecto Alle fuerte.

******* Answer 

\[
u(t) = \alpha \left( 1 - \frac{u}{u_{\infty}} \right) \left( \frac{u}{u_{min}} - 1 \right).
\]

***** Efecto Alle débil
Podemos debilitar el efecto Alle tomando una potencia y no dejando
ningún punto de extinción

\[
u(t) = \alpha \left( 1 - \frac{u}{u_{\infty}} \right) \left( \frac{u}{u_{min}} \right)^k u.
\]

****** Card                                                                                                :drill:
SCHEDULED: <2018-06-17 Sun>
:PROPERTIES:
:ID:       fba88321-65e9-4bf7-b90e-608b10608f7e
:DRILL_LAST_INTERVAL: 13.021
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.5
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-04 Mon 22:16]
:END:
Ecuación del modelo con efecto Alle *débil*.

******* Answer
\[
u(t) = \alpha u\left( 1 - \frac{u}{u_{\infty}} \right) \left( \frac{u}{u_{min}} \right)^k
\]

**** 8.3. Transformada de Fourier
***** Clase de Schwartz
La *clase de Schwartz* es el espacio de las funciones complejas
infinitamente diferenciables que tienen, ella y sus derivadas,
decrecimiento más rápido que cualquier polinomio en infinito.

\[
{\cal S}(\mathbb{R}) =
\left\{ f \in {\cal C}^{\infty}(\mathbb{R},\mathbb{C}) \mid
\sup_{x \in \mathbb{R}} \abs{x^kf^{(n)}(x)} < \infty,
\forall k,n \geq 0
\right\}
\]

****** Card                                                                                                :drill:
SCHEDULED: <2018-07-30 Mon>
:PROPERTIES:
:ID:       ee0ff838-94f3-4200-bfe8-8b104c8b3f04
:DRILL_LAST_INTERVAL: 33.213
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.333
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-27 Wed 13:17]
:END:
Clase de Schwartz.

******* Answer

\[
{\cal S}(\mathbb{R}) =
\left\{ f \in {\cal C}^{\infty}(\mathbb{R},\mathbb{C}) \mid
\sup_{x \in \mathbb{R}} \abs{x^kf^{(n)}(x)} < \infty,
\forall k,n \geq 0
\right\}
\]

Espacio de las funciones complejas infinitamente diferenciables que
tienen, ella y sus derivadas, decrecimiento más rápido que cualquier
polinomio en infinito.

***** Función de Gauss
La *función de Gauss* está en ${\cal S}(\mathbb{R})$ y es un punto fijo
de la transformada de Fourier.

\[
G(x) = e^{-\pi x^2}
\]

****** Card: definición                                                                                    :drill:
SCHEDULED: <2018-08-13 Mon>
:PROPERTIES:
:ID:       b3bc2aba-9d48-4ece-bfd1-b326b55f2db0
:DRILL_LAST_INTERVAL: 47.3129
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 5.0
:DRILL_EASE: 2.8
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-27 Wed 13:21]
:END:
Cuál es la función de Gauss, punto fijo de la transformada de Fourier.

******* Definición

\[
G(x) = e^{-\pi x^2}
\]

****** Card: integral                                                                                      :drill:
SCHEDULED: <2018-07-01 Sun>
:PROPERTIES:
:ID:       89250ba0-0c07-4417-a4af-deb2c7a043e9
:DRILL_LAST_INTERVAL: 4.1245
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 5
:DRILL_FAILURE_COUNT: 2
:DRILL_AVERAGE_QUALITY: 3.4
:DRILL_EASE: 2.7
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-27 Wed 13:24]
:END:
Calcula la integral

\[
\int^{+\infty}_{-\infty} e^{-\pi x^2}\,dx = \dots
\]

******* Integral

\[
\int^{+\infty}_{-\infty} e^{-\pi x^2}\,dx = 1
\]

***** Transformada de Fourier
Se define la *transformada de Fourier* de $f \in {\cal S}(\mathbb{R})$ como
la función $\hat{f} \in {\cal S}(\mathbb{R})$ siguiente

\[
\hat{f}(y) = {\cal F}[f](y) = \int_{-\infty}^{+\infty} f(x) e^{-2\pi i xy}\,dx.
\]

****** Card                                                                                                :drill:
SCHEDULED: <2018-08-03 Fri>
:PROPERTIES:
:ID:       122f1a79-d63b-4d44-8943-47b0cc09d663
:DRILL_LAST_INTERVAL: 36.9634
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.667
:DRILL_EASE: 2.7
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-27 Wed 13:20]
:END:
Calcula la transformada de Fourier de $f$.

******* Answer

\[
\hat{f}(y) = \int_{-\infty}^{+\infty} f(x) e^{-2\pi i xy}\,dx.
\]

***** Transformada inversa de Fourier
Se define la *transformada inversa de Fourier* de $g \in {\cal S}(\mathbb{R})$ como
la función $\check{g} \in {\cal S}(\mathbb{R})$ siguiente

\[
\check{g}(x) = {\cal F}^{-1}[g](x) = \int_{-\infty}^{+\infty}g(y) e^{2\pi i xy}\,dy
\]

****** Card                                                                                                :drill:
SCHEDULED: <2018-08-01 Wed>
:PROPERTIES:
:ID:       3a53e04d-fbe2-4208-aff0-fe746fea4d70
:DRILL_LAST_INTERVAL: 34.5136
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.667
:DRILL_EASE: 2.7
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-27 Wed 13:17]
:END:
Calcula la transformada inversa de Fourier de $g$.

******* Answer

\[
\check{g}(x) = \int_{-\infty}^{+\infty}g(y) e^{2\pi i xy}\,dy
\]

***** TODO Distribuciones temperadas
***** Convolución de funciones
Definimos la convolución de $f,g \in {\cal S}(\mathbb{R})$ como

\[
(f \ast g)(x) = (g \ast f)(x) = \int_{\mathbb{R}} f(x-y)g(y)\,dy.
\]

****** Card                                                                                                :drill:
SCHEDULED: <2018-08-08 Wed>
:PROPERTIES:
:ID:       104c0f7b-d8c4-448a-8486-3af033bba368
:DRILL_LAST_INTERVAL: 42.4715
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 5.0
:DRILL_EASE: 2.8
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-27 Wed 13:22]
:END:
Define la convolución $(f \ast g)$

******* Definición

\[
(f \ast g)(x) = \int_{\mathbb{R}} f(x-y)g(y)\,dy.
\]

***** Teorema 31. Propiedades de Fourier y la convolución
Para $f,g \in {\cal S}(\mathbb{R})$ se tiene

 1. $F$ es una biyección sobre la clase de Swartz,

    \[
    f(x) = \int_{-\infty}^{\infty} e^{2\pi ixy} \left( \int_{-\infty}^{\infty}f(z)e^{-2\pi izy}\,dz \right)\,dy.
    \]

 2. La función de Gauss es un punto fijo de la transformada,

    \[
    F[G] = G.
    \]

 3. La transformada convierte derivadas en polinomios multiplicando

    \[
    F[f'](y) = 2\pi iy F[f](y).
    \]

 4. Convierte dilataciones en homotecias y dilataciones. Dada $h_af(x) = f(ax)$,
    se tiene
    
    * \[F[h_af](y) = \frac{1}{\abs{a}}F[f] \left( \frac{y}{a} \right)\]

    * \[F^{-1}[h_ag](x) = \frac{1}{\abs{a}}F^{-1}[g] \left( \frac{x}{a} \right)\]

 5. Convierte convoluciones en productos y productos en convoluciones,

    \[
    F[f \ast g] = F[f]F[g],\quad F[fg] = F[f]\ast F[g].
    \]

 6. Si $f \in L^2(\mathbb{R})$ y para $G_{\varepsilon}(x) = \frac{1}{\sqrt{\varepsilon}}G \left( \frac{x}{\sqrt{\varepsilon}} \right)$, se tiene $f \ast G_{\varepsilon} \in {\cal C}^{\infty}(\mathbb{R})$,
    y además converge a $f$ en $L^2$ cuando $\varepsilon \to 0$. Cuando $f$ es continua, la
    convergencia es uniforme en compactos.

 7. Transformada de la Delta de Dirac

    \[
    F[\delta_0] = 1,\quad\mbox{ y }\quad
    G_{\varepsilon} \overset{\varepsilon \to 0}\longrightarrow \delta_0.
    \] 

****** Proof 1                                                                                             :extra:
****** TODO Proof 2
****** Proof 3
Integrando por partes.

****** Proof 4
Integración por sustitución.

****** Proof 5
Usando Fubini con las integrales y haciendo una cambio de variable
para que una no dependa del valor de $z$.

****** Proof 6                                                                                             :extra:

****** Proof 7
Interpretando la transformada de Fourier en el sentido débil.

****** Card: transformada de derivada                                                                      :drill:
SCHEDULED: <2018-06-26 Tue>
:PROPERTIES:
:ID:       6e04de59-3992-46f7-b0a7-a9e9f54d4c95
:DRILL_LAST_INTERVAL: 20.121
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.667
:DRILL_EASE: 2.32
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-06 Wed 12:13]
:END:
Calcula la transformada de una derivada.

\[F[f'](y) = \dots\]

******* Answer
La transformada convierte derivadas en polinomios multiplicando

\[
F[f'](y) = 2\pi iy F[f](y).
\]

**** 8.4. Resolución de la ecuación del calor
Resolvemos la ecuación del calor

\[\left.\begin{aligned}
v_t &= Dv_{xx} \\
v_t(0,x) &= f(x),
\end{aligned}\right\}\]

simplificamos primero tomando $u(t,x) = v(t,\sqrt{D} x)$ quedando

\[\left.\begin{aligned}
u_t &= u_{xx} \\
u_t(0,x) &= f(\sqrt{D}x).
\end{aligned}\right\}\]

***** Solución fundamental
La versión fundamental de la ecuación, con Delta de Dirac

\[\left.\begin{aligned}
U_t &= U_{xx} \\
U_t(0,x) &= \delta_0(x).
\end{aligned}\right\}\]

Tiene solución

\[
U = \frac{1}{\sqrt{4\pi t}}e^{-\frac{x^2}{4t}}.
\]

****** Resolución
Tomamos Fourier en espacio

\[
\hat{u}(t,y) = \int_{-\infty}^{+\infty} e^{-2\pi i xy}u(t,x)\,dx
\]

y obtenemos una ecuación que tiene como solución a $h_{\sqrt{4\pi t}}G$; al
volver a aplicar la transformada inversa de Fourier obtenemos
la solución.

***** Solución general
La ecuación del calor

\[\left.\begin{aligned}
v_t &= Dv_{xx} \\
v_t(0,x) &= f(x),
\end{aligned}\right\}\]

tiene solución explícita

\[
v(t,x) = \frac{1}{\sqrt{4\pi Dt}} \int_{-\infty}^{+\infty} e^{-\frac{(x-y)^2}{4tD}} f(y)\,dy
\]

****** Proof
Tomando $u(t,x) = v(t,\sqrt{D} x)$ queda

\[\left.\begin{aligned}
u_t &= u_{xx} \\
u_t(0,x) &= f(\sqrt{D}x) = f_D(x).
\end{aligned}\right\}\]

pero como tenemos resuelta la versión fundamental

\[\left.\begin{aligned}
U_t &= U_{xx} \\
U_t(0,x) &= \delta_0(x).
\end{aligned}\right\}\]

por

\[
U = \frac{1}{\sqrt{4\pi t}}e^{-\frac{x^2}{4t}}.
\]

tomamos convoluciones, aprovechando que la derivada entra y sale
de las convoluciones para resolver la $u$ como

\[
u(t,x) = \frac{1}{\sqrt{4\pi t}}\int_{\mathbb{R}} e^{-\frac{(x-y)^2}{4t}}f_D(y)\,dy
\]

y finalmente aplicamos un cambio de variables para tener la solución
explícita

\[
v(t,x) = \frac{1}{\sqrt{4\pi Dt}} \int_{-\infty}^{+\infty} e^{-\frac{(x-y)^2}{4tD}} f(y)\,dy.
\]

****** Card                                                                                                :drill:
SCHEDULED: <2018-06-18 Mon>
:PROPERTIES:
:ID:       b2aab25a-7757-4e23-91f4-eab49a0dc98c
:DRILL_LAST_INTERVAL: 14.3904
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.333
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-04 Mon 22:15]
:END:
Solución explícita de la ecuación del calor.

\[\left.\begin{aligned}
v_t &= Dv_{xx} \\
v_t(0,x) &= f(x),
\end{aligned}\right\}\]

******* Answer

\[
v(t,x) = \frac{1}{\sqrt{4\pi Dt}} \int_{-\infty}^{+\infty} e^{-\frac{(x-y)^2}{4tD}} f(y)\,dy
\]

***** Comentarios sobre unicidad
En general no tendríamos unicidad salvo que impusiéramos una condición
sobre decaimiento en infinito. Tenemos de hecho una familia de
soluciones

\[
u(x,t) = \sum_{k=0}^{\infty} \frac{x^{2k}}{(2k)!} \dv[k]{}{t} e^{-\frac{1}{t^2}}.
\]

***** Propiedades de las soluciones del calor

 1. *Conservación del signo y principio del máximo*. Si $f \geq 0$ y no es nula,
    entonces $v > 0$. En general, si $f_1,f_2$ tienen soluciones $v_1,v_2$, no son
    idénticas y $f_1 \geq f_2$, entonces $v_1 > v_2$.

 2. *Conservación de la masa*. La masa es constante en todos los
    instantes de tiempo.

    \[
    \int v(t,x)\,dx = \int f(x)\,dx.
    \]

 3. *Difusión final*. Existe $c_f$ tal que para cualquier $t > 0$,
    
    \[
    \abs{v(t,x)} \leq \frac{c}{\sqrt{t}}.
    \]

 4. *Soporte infinito*. Aunque el soporte de $f\neq 0$ sea finito, el de $v$
    es instantáneamente infinito, la difusión es instantánea a todos
    los puntos.

 5. *Disipación de la energía*. La energía se va disipando, porque se
    cumple

    \[
    \dv{}{t} \left( \frac{1}{2}\int_{\mathbb{R}} (v(t,x))^2\,dx \right) =
    -D \int_{\mathbb{R}} \abs{v_x(t,x)}^2\,dx.
    \]

**** 8.5. Ecuaciones de reacción-difusión

\[
\dv{}{t} \left( \int_{\Omega} u(t,x)\,dx \right) =
\int_{\Omega} f(u)\,dx + \int_{\partial\Omega} (- J \cdot n)\,dx
\]

***** FKPP
Es una ecuación reacción-difusión en dimensión $n = 1$. Se obtiene
tomando *crecimiento logístico* $f(u) = \alpha ( 1 - \frac{u}{u_{\infty}}) u$,

\[
u_t - D u_{xx} = \alpha u \left( 1 - \frac{u}{u_{\infty}} \right).
\]

Adimensionalizando,

\[
v_t = v_{yy} + (1-v)v.
\]

****** Card                                                                                                :drill:
SCHEDULED: <2018-06-21 Thu>
:PROPERTIES:
:ID:       f5e1e842-dfc2-48f6-af9f-c1b6fa6f7a57
:DRILL_LAST_INTERVAL: 14.7985
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.5
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-06 Wed 12:06]
:END:
Forma adimensionalizada de una FKPP.

******* Answer

\[
v_t = v_{yy} + (1-v)v.
\]

***** Biestable
Se obtiene introduciendo el efecto Alle,

\[
u_t - Du_{xx} = \alpha u \left( 1 - \frac{u}{u_{\infty}} \right) \left( \frac{u}{u_{min}} - 1 \right)
\]

adimensionalizando y llamando $\beta = u_{min}/u_{\infty}$, obtenemos

\[
v_{\tau} = v_{yy} + v(1-v)(v-\beta).
\]

****** Card                                                                                              :nodrill:
SCHEDULED: <2018-06-11 Mon>
:PROPERTIES:
:ID:       e40e461b-ca97-43f6-a141-d4ade2fc4077
:DRILL_LAST_INTERVAL: 7.3791
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.5
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-04 Mon 22:15]
:END:
Forma adimensionalizada de una biestable.

******* Answer

\[
v_{\tau} = v_{yy} + v(1-v)(v-\beta).
\]

**** 8.6. Ondas viajeras
***** Ondas viajeras
Las *ondas viajeras* son soluciones de reacción-difusión en el caso
unidimensional de la forma $u(\tau,y) = \phi(y - c\tau)$. Cumplirán

\[
\phi'' + c\phi' + f(\phi) = 0
\]

con condiciones $\phi(-\infty) = 1$, $\phi(+\infty)=0$. Y multiplicando podemos
comprobar que

\[\mathrm{sgn}(c) = \mathrm{sgn}\left(\int_0^1f\right).\]

Luego,

 * en la FKPP, las ondas tienen $c$ positiva y avanzan;
 * en la biestable, las ondas pueden retroceder.

***** Ondas viajeras de la biestable
Las ondas viajeras para $u(1-u)(u-\alpha)$ se buscan con una
constante $A$ que cumpla $\phi' = A\phi(1-\phi)$. Derivando y aplicando
en la ecuación de ondas viajeras, sabiendo que la solución queremos
que sea decreciente, llegamos a $A = -1/\sqrt{2}$ y a $c = \sqrt{2}(1/2-\beta)$.
Finalmente, puede resolverse con variables separadas para llegar a

\[
\phi(y) = \frac{1}{1 + ke^{(y-y_0)/\sqrt{2}}}.
\]

***** Ondas viajeras de la FKPP
*** Ejercicios
**** Examen 25 mayo 2016 (López) [1/3]
***** TODO Ejercicio 1
***** CHECK [#A] Ejercicio 2
La derivada clásica es derivada débil cuando todo es ${\cal C}^1$. Hay
que comprobar los $L^p$ para $1 < p <\infty$ pero se hace fácil porque
se puede acotar todo dentro de $\Omega$.

***** TODO [#A] Ejercicio 3
**** Examen 24 junio 2016 [3/3]
***** DONE Ejercicio 1

 1. Derivada débil de una función con derivada clásica.  Acotamos a la
    $f$ y trabajamos con eso.

 2. Poincaré sobre ella y sobre su derivada.

 3. Linealidad y continuidad por Cauchy-Schwartz.

 4. Lax-Milgram por lo anterior.

 5. Hay que realizar todo el Euler-Lagrange para obtener las condiciones
    de contorno.

***** DONE Ejercicio 2
Nos fijamos que tenemos un Problema Sturm-Liouville implícito y podemos,
o buscar los autovalores, o darnos cuenta de que 0 lo es y debe ser el
primer autovalor.

***** DONE Ejercicio 3
Aplicamos resolución de la ecuación de ondas.

***** Ejercicio 4 (Parte II)

**** Examen 15 septiembre 2016 (López) [0/4]
***** TODO Ejercicio 1
***** TODO Ejercicio 2
***** TODO Ejercicio 3
***** TODO Ejercicio 4
**** Examen 3 mayo 2017 [3/5]
***** TODO Ejercicio 1
Muy interesante porque tiene todo lo que se estudia, pero es Fourier y
Liouville.

***** DONE Ejercicio 2
***** DONE Ejercicio 3
***** TODO Ejercicio 4
***** DONE Ejercicio 5
**** Examen 31 mayo 2017 [6/6]
***** DONE Ejercicio 1.1 (Skellam)
***** DONE Ejercicio 1.2 (Skellam)
***** DONE Ejercicio 1.3 (Skellam)
***** DONE Ejercicio 2.1 (Robertson)
***** DONE Ejercicio 2.2 (Robertson)
***** DONE Ejercicio 2.3 (Robertson)
**** Examen 19 junio 2017 [2/2]
***** DONE 2. Lax-Milgram
***** DONE 3. Sturm-Liouville
**** Examen 8 septiembre 2017 [6/6]
***** DONE Ejercicio 1
***** DONE Ejercicio 2

 * El punto 2.3 es especialmente importante porque recuerda que no vale
   con $L_{loc}$ para que la derivada débil y clásica sean iguales. Necesitamos
   derivabilidad y continuidad respecto una variable.

***** DONE Ejercicio 3
***** DONE Ejercicio 4.a
***** DONE Ejercicio 4.b
***** DONE Ejercicio 4.c
**** Ejemplos de los apuntes [1/1]
***** DONE Problema de Dido
**** Resolver ondas
#+begin_statement
Resolver la ecuación de ondas en $[0,\infty) \times [0,L]$  con condiciones
\[\left\{\begin{array}{c}
u(t,0) = u(t,L) = 0 \\
u(0,x) = u_0(x),\\ 
u_t(0,x) = v_0(x).
\end{array}\right\}\]
en el caso $c = 1$, $L = \pi$, $u_0(x) = \sin(175x)$ y $v_0=\sin(3x)$.
#+end_statement

Notamos que la serie de Fourier de $u_0$ tiene coeficiente $b_{175}=1$ pero
$b_m = 0$ en cualquier $m \neq 175$. Mientras que la serie de $v_0$ tiene $a_3 = 1$
y $a_m = 0$ en otro caso.

La solución es por tanto,

\[\begin{aligned}
u(t,x) &= \sum_{n \geq 1} \sin(nx)
\left(
\frac{a_n}{n} \sin(nt) + b_n \cos(nt)
\right) \\&=
\sin(175x)\cos(175t) + \frac{1}{3}\sin(3x)\sin(3t).
\end{aligned}\]

*** Entregas
# Escribir nombre y apellidos, curso, asignatura, año, firma.

**** Ejercicio 1
#+begin_statement
Encontrar una función $\phi \in {\cal C}^{\infty}_{0}[x_0,x_1]$ tal que $\phi(x) > 0$ únicamente en
$(x_2-\varepsilon,x_2+\varepsilon) \subset [x_0,x_1]$ y $\phi(x) = 0$ en otro caso, para un $x_2$ dado.
#+end_statement

Sin pérdida de generalidad, tratamos sólo el caso $(-1,1)$,
recuperando el resto de casos restringiendo la función y usando
homotecias y traslaciones, que son funciones suaves.  Buscaremos
una función tal que todas sus derivadas se aproximen a
cero en los extremos para concatenarla con la función constantemente
cero.  Tomamos por tanto,
\[
f(x) = \left\{
\begin{array}{cl}
\exp({\frac{-1}{(1-x)(1+x)}}) & \mbox{ si } -1 < x < 1, \\
0 & \mbox{ en otro caso.} 
\end{array}\right.
\]

Comprobaremos que es ${\cal C}^{\infty}$ trabajando en $-1 < x < 1$.
Si llamamos $y = 1/(1-x^2)$, la función es de la forma $P(x)y^ne^{-y}$
con $n \in \mathbb{N}_0$ y $P$ polinomio. Sabiendo que $y' = 2xy^2$, la derivada de una
función así vuelve a ser de la misma forma para otro polinomio $Q$.
\[
\dv{}{x} \left( P(x)\frac{y^n}{e^y} \right) = 
P'(x) \frac{y^n}{e^y} + 
P(x) \left( 2xy^2n \frac{y^{n-1}}{e^y} + 2xy^2\frac{y^n}{e^y} \right) =
\frac{y^{n+2}}{e^y}Q(x)
\]

Finalmente, por regla de L'Hôpital, cualquier función de esta forma
tiene, para $z = -1^+ \text{ ó }1^-$,
\[\lim_{x \to z}
\left( P(x) y^n e^{-y} \right) =
P(z) \lim_{y \to +\infty}
\left(\frac{y^n}{e^y} \right) = 0.
\]

Así, nuestra $f$ es continua y derivable por coincidir en $-1$ y $1$ las
derivadas laterales, y cada una de sus derivadas vuelve a serlo por
el mismo razonamiento.

**** Ejercicio 2
#+attr_latex: :options [Teorema 4]
#+begin_statement
Dado un funcional ${\cal F} \colon D \to \mathbb{R}$ donde
\[
D = \left\{ y \in {\cal C}^1[x_0,x_1] \mid y(x_0) = y_0, y(x_1) = y_1 \right\},
\]
para $x_0 < x_1, y_0 < y_1 \in \mathbb{R}$, de la forma
\[
{\cal F}(y) = \int_{x_0}^{x_1} F(x,y(x),y'(x)) \; dx
\]
para una $F : [x_0,x_1] \times \Omega \to \mathbb{R}$ con $\Omega$ dominio de $\mathbb{R}^2$, continua
y derivable respecto $x$ e $y$; tenemos que cualquier $\overline{y} \in {\cal D} \cap {\cal C}^2[x_0,x_1]$
que minimice el funcional cumple la Ecuación de Euler-Lagrange.
\[
\pdv{F}{y} \left( x,\overline{y}(x), \overline{y}'(x) \right) -
\dv{}{x}\left( \pdv{F}{p} (x, \overline{y}(x), \overline{y}'(x)) \right) = 0.
\]

En estas condiciones, si además $\pdv{F}{y} = 0$, entonces tenemos
que $F_p(x,\overline{y}'(x)) = \mathrm{cte.}$
#+end_statement
#+begin_proof
Por la Ecuación de Euler-Lagrange se tiene
\[-\dv{}{x}\left( \pdv{F}{p} (x, \overline{y}(x), \overline{y}'(x)) \right) = 0,
\]
y por ser derivable con derivada nula es constante.
#+end_proof

#+attr_latex: :options [Teorema 5]
#+begin_statement
En las mismas condiciones anteriores, si se tiene $\pdv{F}{x} = 0$, entonces
se cumple
\[
F(\overline{y}(x),\overline{y}'(x)) - y'(x) F_p(\overline{y}(x),\overline{y}'(x)) = \mathrm{cte.}
\]
#+end_statement
#+begin_proof
Derivamos usando linealidad y regla de la cadena, siendo la última
igualdad la ecuación de Euler-Lagrange.
\[\begin{aligned}
\dv{}{x} &\Big(F\big(\oy,\oy'\big) -
\oy' \pdv{F}{p} \big(\oy,\oy'\big) \Big) \\&=
\oy' \cdot \pdv{F}{y} (\oy, \oy') +
\oy'' \cdot \pdv{F}{p} (\oy, \oy')
-\oy'' \cdot \pdv{F}{p} (\oy, \oy') - 
\oy' \cdot \dv{}{x} \pdv{F}{p} (\oy, \oy') \\&=
\oy' \left( \pdv{F}{y} (\oy, \oy') - 
\dv{}{x} \pdv{F}{p} (\oy, \oy') \right) \\&= 0.
\end{aligned}\]
De nuevo, por tener derivada nula, debe ser constante.
#+end_proof

**** Ejercicio 3: sólo en clase
#+begin_statement
Encontrar funciones $y \colon [x_0,x_1]\to \mathbb{R}$ que minimicen la superficie de
revolución de la gráfica fijado $y(x_1) = y_1 > 0$ and $y(x_0) = y_0$.
#+end_statement

El área bajo la gráfica se mide como

\[
A(y) = \int_{x_0}^{x_1} 2\pi y(x) \sqrt{1 + y'(x)^2} \;dx
\]

Por Euler-Lagrange tenemos $F - y' F_p = \mathrm{cte}$. Es decir,

\[
\frac{2 \pi y(x)}{\sqrt{1 + y'(x)^2}} = \mathrm{cte}.
\]

Asi que resolvemos la ecuación diferencial $y = C \sqrt{1 + y'^2}$.
Es una ecuación de Lagrange que se resuelve llamando $p(x) = y'(x)$,
y derivando respecto de $x$

\[
p = C \left( \frac{pp'}{\sqrt{1 + p^2}} \right)
\]

Llegando a la ecuación diferencial siguiente para una constante $D$
excepto en el caso $C=0$, que daría $y' = 0$ como solución; o el caso
$p = 0$, (???) que llevaría a lo mismo.

\[
p' = D\sqrt{1 + p^2}
\]

Resolvemos por variables separadas

\[
\int \frac{D}{\sqrt{1+p^2}} \;dp = D\log|\sqrt{1 + p^2} + p| = x + E
\]

Despejamos, quitando el caso $D = 0$,

**** Ejercicio 4
:PROPERTIES:
:ID:       de1af79c-3a0b-410e-8cca-d26c92021ec8
:END:
#+begin_statement
Hemos probado que cada problema de contorno con condiciones de
Dirichlet no homogéneas es equivalente a otro con condiciones de
Dirichlet homogéneas.  Enunciar y demostrar un resultado análogo para
condiciones tipo Neumann no homogéneas.
#+end_statement

Dado un problema con condiciones de contorno tipo Newmann
\[\left\{\begin{array}{l}
(Py')' + Qy = R, \\
y'(x_0) = y'_0, \\
y'(x_1) = y'_1,
\end{array}\]
construiremos un problema equivalente tomando un cambio de variable
de la forma $z(x) = y(x) - (Ax^2 + Bx)$. Buscamos que las condiciones
sean homogéneas,
\[\left\{\begin{array}{l}
z'(x_0) = y'_0 - (2Ax_0 + B) = 0, \\
z'(x_1) = y'_1 - (2Ax_1 + B) = 0, \\
\end{array}\]
por lo que obtenemos $A = (y'_1 - y'_0)/(2(x_1 - x_0))$ y
$B = (y'_0x_1-x_0y'_1)/(x_1-x_0)$. Si además buscamos $(Pz')' + Qz = {\widetilde R}$.
\[\begin{aligned}
{\widetilde R} &= (Pz')' + Qz \\
               &= (Py')' - (P(2Ax + B))' + Qy - Q(Ax^2 + Bx) \\
               &= R - (P(2Ax + B))' - Q(Ax^2 + Bx) \\
               &= R - P'(2Ax + B) - 2AP - Q(Ax^2 + Bx).
\end{aligned}\]
Así, hemos llegado a que el problema original es equivalente a otro
de la forma siguiente, con la $\widetilde R$ dada anteriormente.
\[\left\{\begin{array}{l}
(Pz')' + Qz = {\widetilde R}, \\
z'(x_0) = 0, \\
z'(x_1) = 0.
\end{array}\]

**** Ejercicio 5
#+begin_statement
Demostrar que la ecuación general de la viga, $Mu^{iv}(x) + Nu''(x) = f(x)$ 
necesariamente la verifica un mínimo del funcional siguiente.
\[
{\cal F}(u) = \int_0^L  \left(
\frac{M}{2}(u''(x))^2 -
\frac{N}{2}(u'(x))^2 -
f(x)u(x) 
\right)\;dx
\]
#+end_statement

Empezamos llamando
\[
F(x,y,p,q) = \frac{M}{2}q^2 - \frac{N}{2}p^2 - f(x)y.
\]
Si $\overline{u}$ fuera un máximo, consideramos $g(s) = {\cal F}(\overline{u} + s\phi)$ tomando
$|s| < \varepsilon$ suficientemente pequeño para que se cumpla $\overline{u} + s\phi \in \Omega$
y $\phi \in D_0 = \left\{ \phi \in {\cal C}^2[0,L] \mid \phi(0)=\phi(L), \phi'(0)=\phi'(L) \right\}$. La condición
de minimalidad nos da $g'(0) = 0$. Usando regla de derivación bajo una
integral y regla de la cadena en varias variables.
\[\begin{aligned}
g'(s) &= \dv{}{s} \left( \int_0^L 
F(x;\overline{u}(x) + s\phi(x), \overline{u}'(x) + s\phi'(x), \overline{u}''(x) + s\phi''(x))
\;dx\right) \\&=
\int_0^L  \dv{}{s}
F(x;\overline{u}(x) + s\phi(x), \overline{u}'(x) + s\phi'(x), \overline{u}''(x) + s\phi''(x))
\;dx \\&=
\left( \int_0^L F_y(...)\phi(x) \;dx \right) +
\left( \int_0^L F_p(...)\phi'(x) \;dx \right) +
\left( \int_0^L F_q(...)\phi''(x) \;dx \right)
\end{aligned}\]
Usando integración por partes y las condiciones sobre $\phi$ para
anular los términos.
\[\begin{aligned}
g'(s) &= 
 \int_0^L F_y(...)\phi(x)\;dx -
 \int_0^L \dv{}{x}F_p(...)\phi(x)\;dx +
 \int_0^L \dv[2]{}{x}F_q(...)\phi(x)\;dx \\&=
\int_0^L \left( F_y(...) - \dv{}{x}F_p(...) + \dv[2]{}{x}F_{q}(...) \right)\phi(x)\;dx
\end{aligned}\]
Podemos evaluar en $s = 0$ y aplicar la construcción del Teorema 1
para encontrar una $\phi \in D_0$ anulándose en los extremos y con derivada
nula en los extremos tal que si el primer factor fuera distinto de
cero en algún punto, la integral debería ser distinta de cero.
Tenemos entonces
\[
F_y(x,\overline{u},\overline{u}',\overline{u}'') - 
\dv{}{x}F_p(x,\overline{u},\overline{u}',\overline{u}'') + 
\dv[2]{}{x}F_{q}(x,\overline{u},\overline{u}',\overline{u}'') = 0.
\]
Calculando obtenemos $F_y(...) = -f(x)$, $F_p(...) = -Nu'(x)$, $F_q(...) = Mu''(x)$,
por lo que la ecuación final es precisamente
\[
Mu^{iv}(x) + Nu''(x) - f(x) = 0.
\]

**** Ejercicio 6
:PROPERTIES:
:ID:       e15aa2f8-76b4-4aa6-82bb-c0b424bda884
:END:
#+begin_statement
Calcular los valores y vectores propios del problema de Sturm-Liouville
en $L^2(x_0,x_1)$: $y'' + \lambda y = 0$, con $y(x_0) = 0 = y(x_1)$.
#+end_statement

Tratamos por casos el problema según el signo de $\lambda$.
En el caso $\lambda < 0$, el polinomio característico $\mu^2 + \lambda = 0$ tiene
soluciones $\mu = \pm \sqrt{-\lambda}$, que dan lugar a soluciones de la
ecuación de la forma

\[
y = Ae^{\sqrt{-\lambda} x} + Be^{-\sqrt{-\lambda}x};
\]

que al exigir $y(x_0) = y(x_1) = 0$ nos llevan a un sistema
\[\begin{pmatrix}
e^{\sqrt{-\lambda} x_0} & e^{-\sqrt{-\lambda} x_0} \\
e^{\sqrt{-\lambda} x_1} & e^{-\sqrt{-\lambda} x_1} 
\end{pmatrix}
\begin{pmatrix} A \\ B \end{pmatrix} =
\begin{pmatrix} 0 \\ 0 \end{pmatrix}\]

donde, al tener la matriz determinante $e^{\sqrt{-\lambda}(x_0-x_1)} - e^{\sqrt{-\lambda}(x_1-x_0)} = 0$,
sabemos que si $x_0 \neq x_1$ sólo tendrá la solución trivial.
En el caso $\lambda = 0$ tendríamos soluciones de la forma $y = Ax + B$,
y al imponer las condiciones, llegaríamos a la solución trivial.

En el caso $\lambda > 0$, tendríamos soluciones del polinomio $\mu = i\sqrt{\lambda}$ que
darían lugar a soluciones de la ecuación de la forma
\[
y = A \cos(\sqrt{\lambda}x) + B \sin(\sqrt{\lambda} x)
\]

que al exigir $y(x_0) = y(x_1) = 0$ nos llevan a un sistema
\[\begin{pmatrix}
\cos(\sqrt{\lambda}x_0) & \sin(\sqrt{\lambda}x_0) \\
\cos(\sqrt{\lambda}x_1) & \sin(\sqrt{\lambda}x_1) \\
\end{pmatrix}\begin{pmatrix} A \\ B \end{pmatrix} =
\begin{pmatrix} 0 \\ 0 \end{pmatrix}\]

donde, para que la matriz tenga determinante nulo y existan soluciones
no triviales, debe tenerse
\[
\cos(\sqrt{\lambda} x_0)\sin(\sqrt{\lambda} x_1) - 
\sin(\sqrt{\lambda} x_0)\cos(\sqrt{\lambda} x_1) = 0
\]

que equivale a $\tan(\sqrt{\lambda} x_1) = \tan(\sqrt{\lambda} x_0)$ o $\cos(\sqrt{\lambda}x_0) = \cos(\sqrt{\lambda}x_1) = 0$.
En ambos casos se debe tener $\sqrt{\lambda}(x_1-x_0) = n\pi$ para algún $n \in \mathbb{N}$ y por tanto
$\lambda_n = \left( n\pi/(x_1-x_0) \right)^2$.

Resolviendo el sistema lineal para este valor de $\lambda$ llegamos a
$A = -C_n\sin(n\pi x_0/(x_1-x_0))$ y $B = C_n\cos(n\pi x_0/(x_1-x_0))$
para algún $C_n$. Esto se traduce en soluciones
\[\begin{aligned}
y &= 
-C_n\sin(n\pi\frac{x_0}{x_1-x_0})\cos(n\pi\frac{x}{x_1-x_0}) +
C_n\cos(n\pi\frac{x_0}{x_1-x_0})\sin(n\pi\frac{x}{x_1-x_0}) \\&=
C_n\sin(n\pi\frac{x-x_0}{x_1-x_0}).
\end{aligned}\]

Finalmente, para obtener las funciones propias normalizadas,
integramos
\[
\int_{x_0}^{x_1} C_n^2\sin^2\left(n\pi\frac{x-x_0}{x_1-x_0}\right)\,dx =
C^2_n\frac{(x_1-x_0)}{n\pi}\int_{0}^{n\pi} \sin^2\left(s\right)\,ds =
\frac{1}{2}C^2_n(x_1-x_0) = 1,
\]

y tenemos $C_n = \sqrt{\frac{2}{x_1-x_0}}$. Es decir los valores propios son $\lambda_n = (n\pi/(x_1-x_0))^2$
y las funciones propias normalizadas son
\[
y_n = \sqrt{\frac{2}{x_1-x_0}} \sin(n\pi\frac{x-x_0}{x_1-x_0}).
\]

Nótese que este resultado particulariza al obtenido en clase para $L^2(0,L)$ en el caso $x_0 = 0$
y $x_1 = L$; y que además puede ser obtenido desde él aplicándolo en el caso
$L = x_1-x_0$ a la función $\widetilde y(x) = y(x+x_0)$, que cumple $\widetilde{y}(0) = 0 = \widetilde y(L)$.

***** Card                                                                                                  :drill:
SCHEDULED: <2018-07-01 Sun>
:PROPERTIES:
:ID:       cb97f1a8-a3de-415d-9770-7b22e287d9f3
:DRILL_LAST_INTERVAL: 27.0722
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-04 Mon 22:02]
:END:
Valores propios de $y'' + \lambda y = 0$, con $y(x_0) = 0 = y(x_1)$.

/Sturm-Liouville en funciones de cuadrado integrable/.

****** Valores

\[\lambda_n = \left( \frac{n\pi}{x_1-x_0} \right)^2\]

**** Ejercicio 7
#+begin_statement
Calcula $B_n$ para que la función $y_n(x) = B_n\sin(n\pi \log(x))$ cumpla

\[
\int_1^e \frac{y^2_n(x)}{x} \,dx = 1
\]
#+end_statement

Aplicando un cambio de variables tenemos

\[
B^2_n\int_1^e \sin^2 \left( n\pi \log(x) \right) \frac{1}{x}\,dx = 
\frac{B^2_n}{n\pi}\int_0^{n\pi} \sin^2 \left(  s \right) \,ds = 
\frac{B^2_n}{2} = 1.
\]

Luego $B_n = \sqrt{2}$.

\medskip

/(Nótese que este ejercicio lo realizamos en clase en un caso más general)/

**** Ejercicio 8
#+begin_statement
Dado $\alpha \in \mathbb{R}$, calcula la derivada débil de $\abs{x}^{\alpha}$ en $\mathbb{R}^{N}\setminus \left\{ 0 \right\}$.
#+end_statement

Tomamos una función $\phi \in {\cal C}^{\infty}_0(\mathbb{R}^N)$ y calculamos, para $u(x) = \abs{x}^{\alpha}$ usando
Fubini
\[\begin{aligned}
\left\langle \pdv{u}{x_i}, \phi \right\rangle = 
-\int_{\mathbb{R}^N} u(x) \pdv{\phi}{x_i}(x)\,dx =
-\int_{\mathbb{R}^{N-1}}\int_{-\infty}^{\infty} 
\left(\sqrt{\abs{\widetilde x}^2 + x_i^2}\right)^{\alpha} 
\pdv{\phi}{x_i}(x) \,dx_i\,d{\widetilde x}
\end{aligned}\]
donde $\widetilde x \in \mathbb{R}^{N-1}$ es la proyección del vector $x$ sin la componente $x_i$,
calculamos
\[\begin{aligned}
=-\int_{\mathbb{R}^{N-1}}
\left(
\int_{-\infty}^{0} 
\left(\sqrt{\abs{\widetilde x}^2 + x_i^2}\right)^{\alpha} 
\pdv{\phi}{x_i}(x) \,dx_i +
\int_{0}^{\infty} 
\left(\sqrt{\abs{\widetilde x}^2 + x_i^2}\right)^{\alpha} 
\pdv{\phi}{x_i}(x) \,dx_i\right)\,d{\widetilde x}
\end{aligned}\]
por partes, y derivando donde sabemos que $|x| \neq 0$ porque $x_i \neq 0$,
\[\begin{aligned}
=& -\int_{\mathbb{R}^{N-1}} \Bigg(
\left[ \abs{x}^{\alpha}\phi(x) \right]^{x_i = \infty}_{x_i = 0}
-\int_{-\infty}^{0} 
\frac{x_i}{|x|}\alpha \abs{x}^{\alpha-1} 
\phi(x) \,dx_i \\&+
\left[ \abs{x}^{\alpha}\phi(x) \right]^{x_i = 0}_{x_i = -\infty} -
\int_{0}^{\infty}
\frac{x_i}{|x|} \alpha \abs{x}^{\alpha-1} 
\phi(x) \,dx_i\Bigg)\,d{\widetilde x}
\end{aligned}\]
donde usamos que $\phi \in {\cal C}^{\infty}_0$ se anula en infinito y ambos términos $|x|^{\alpha}\phi(x)_{|_{x_i=0}}$
se cancelan para tener finalmente
\[
= \int_{\mathbb{R}} \alpha x_i|x|^{\alpha-2}\phi(x)\,dx.
\]
Tenemos entonces el mismo razonamiento para cualquier componente y 
\[
\nabla \abs{x}^{\alpha} = \alpha x |x|^{\alpha-2}
\]
en sentido débil.

***** Card                                                                                                  :drill:
SCHEDULED: <2018-06-28 Thu>
:PROPERTIES:
:ID:       7697631c-8f3b-4517-97fe-02cbf69ec0e4
:DRILL_LAST_INTERVAL: 35.3492
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-05-24 Thu 23:47]
:END:
Cuál es la derivada débil de $|x|^{\alpha}$ para $x \in \mathbb{R}^n$.

****** Derivada

\[
\nabla |x|^{\alpha} = \alpha x|x|^{\alpha-2}
\]

**** Ejercicio 9
#+begin_statement
Prueba que

 1. $\widehat{f \ast g} = \widehat{f}\widehat{g}$,

 2. $\widecheck{f \ast g} =\widecheck{f}\widecheck{g}$,

 3. $\widehat{fg} = \widehat{f}\ast\widehat{g}$,

 4. $\widecheck{fg} = \widecheck{f}\ast\widecheck{g}$.
#+end_statement

1. Usando Fubini y un cambio de variable $x - z \mapsto x$.
  \[\begin{aligned}
  \widehat{f \ast g}(y) &=
  \int (f \ast g)(x) e^{-2\pi ixy}\,dx =
  \int \int f(x-z)g(z) e^{-2\pi ixy}\,dz\,dx \\&=
  \int g(z) \int f(x-z) e^{-2\pi ixy}\,dx\,dz =
  \int g(z) \int f(x) e^{-2\pi i(x+z)y}\,dx\,dz \\&=
  \int g(z)e^{-2\pi izy} \int f(x) e^{-2\pi ixy}\,dx\,dz =
  \widehat{f}(y)\widehat{g}(y).
  \end{aligned}\]

2. Repetimos el argumento, cambiando el signo de la exponencial.
  \[\begin{aligned}
  \widecheck{f \ast g}(y) &=
  \int (f \ast g)(x) e^{2\pi ixy}\,dx =
  \int \int f(x-z)g(z) e^{2\pi ixy}\,dz\,dx \\&=
  \int g(z) \int f(x-z) e^{2\pi ixy}\,dx\,dz =
  \int g(z) \int f(x) e^{2\pi i(x+z)y}\,dx\,dz \\&=
  \int g(z)e^{2\pi izy} \int f(x) e^{2\pi ixy}\,dx\,dz =
  \widecheck{f}(y)\widecheck{g}(y).
  \end{aligned}\]

3. Aplicamos (2) a $\hat{f}$ y $\hat{g}$ y usamos que la transformada de Fourier
   es una biyección con su inversa.

4. Aplicamos (1) a $\check{f}$ y $\check{g}$ y usamos que la transformada de Fourier
   es una biyección con su inversa.

** Curvas y superficies
*** Datos de la asignatura
César Rosales - crosales@ugr.es
Lunes, Martes y Miércoles de 12 a 14.
http://www.ugr.es/~crosales/cys1718.html

*** Preliminares ([[~/pdf/Rosales_Preliminares%20a%20curvas%20y%20superficies.pdf][PDF]])
**** 0. Extra
***** Biyección continua de compacto a Hausdorff es homeomorfismo
Sea $f \colon A \to B$ biyección continua. Si $A$ es compacto y $B$ es Hausdorff,
$f$ es homeomorfismo.

****** Card                                                                                                :drill:
SCHEDULED: <2018-06-27 Wed>
:PROPERTIES:
:DRILL_CARD_TYPE: hide1cloze
:ID:       d1143d39-749d-4560-8789-7ec31fa25f47
:DRILL_LAST_INTERVAL: 32.4358
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.75
:DRILL_EASE: 2.56
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-05-26 Sat 22:26]
:END:
Biyección continua de [compacto] a [Hausdorff] es [homeomorfismo].

****** Proof
Tomamos $g = f^{-1}$; sea $U \subset A$ un cerrado. Por ser cerrado de un compacto,
será compacto y $f(U)$ será compacto por continuidad. Por ser $B$ Hausdorff,
un compacto suyo será cerrado. Así $g^{-1}(U) = f(U)$ es cerrado y tenemos
continuidad.

**** 1. Geometría afín euclídea
***** Producto escalar
***** Orientación
Una base $B = \left\{ u_1,\dots,u_n \right\}$ es *positiva* si la matriz de cambio de 
base de $B$ a $B_u$ es positiva. Es decir,

\[\mathrm{det}(u_1 & \dots & u_n) > 0.
\]

****** Card: definición de base positiva                                                                   :drill:
SCHEDULED: <2018-08-23 Thu>
:PROPERTIES:
:ID:       e15a4412-930d-4f6a-aa20-d64196a6f4e2
:DRILL_LAST_INTERVAL: 89.1296
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 6
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 4.167
:DRILL_EASE: 2.9
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-05-26 Sat 22:31]
:END:
Fijada la orientación de la base usual, ¿cuándo es una base
$B = \left\{ u_1,\dots,u_n \right\}$ positiva?

******* Definición
Cuando la matriz de cambio de base de $B$ a $B_u$ es positiva. Es
decir,

\[\mathrm{det}(u_1 & \dots & u_n) > 0.
\]

***** Bases ortonormales
Para $B= \left\{ u_1,\dots,u_n \right\}$ base ortonormal,

\[\left| v \right|^2 = \sum_{i=1}^n \left\langle v,u_i \right\rangle^2.
\]

En general,

\[
\left\langle u,v \right\rangle = \sum_{i=1}^n \left\langle u,u_i \right\rangle \left\langle v,u_i \right\rangle.
\]

***** Movimientos rígidos
:PROPERTIES:
:ID:       92d75a96-b872-4ea6-ae5a-b83d975e2b37
:END:
Todo movimiento rígido es de la forma

\[
\phi(p) = \vec{\phi}(p) + b,
\]

para $\vec{\phi}$ una isometría lineal.

****** Isometrías lineales
Una aplicación $\vec\phi$ es isometría lineal si $\left\langle \vec{\phi}(u),\vec{\phi}(v) \right\rangle = \left\langle u,v \right\rangle$, para
cualesquiera $u$ y $v$.

Esto equivale a $|\vec{\phi}(u)| = u$ para cualquier $u$.

****** Matriz asociada, movimientos directos o inversos
La matriz asociada a una isometría lineal es ortogonal, $A^{-1} = A^t$,
luego su determinante es $|A| = \pm 1$. La isometría es *directa* si
es positivo, e *inversa* si es negativo.

***** Movimientos rígidos de R2

|----------------------+----------------+--------------+----------|
| Tipo de movimiento   | Isometría      | Puntos fijos | Carácter |
|----------------------+----------------+--------------+----------|
| Identidad            | Identidad      | Plano        | directo  |
| Traslación           | Identidad      | ninguno      | directo  |
| Giro                 | Giro           | Punto        | directo  |
| Reflexión            | Simetría axial | Recta        | inverso  |
| Reflexión deslizante | Simetría axial | ninguno      | inverso  |
|----------------------+----------------+--------------+----------|

****** Card: tabla de movimientos en R2                                                                    :drill:
SCHEDULED: <2018-07-30 Mon>
:PROPERTIES:
:DRILL_CARD_TYPE: hide2cloze
:ID:       16a826aa-c93d-4e46-afb4-05682a832bb1
:DRILL_LAST_INTERVAL: 82.1164
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.75
:DRILL_EASE: 2.8
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-05-09 Wed 13:36]
:END:
|----------------------+------------------+--------------+-----------|
| Tipo de movimiento   | Isometría        | Puntos fijos | Carácter  |
|----------------------+------------------+--------------+-----------|
| Identidad            | Identidad        | Todo R2      | directo   |
| Traslación           | Identidad        | [ninguno]    | directo   |
| Giro                 | Giro             | [Centro]     | directo   |
| Reflexión            | [Simetría axial] | [Eje]        | [inverso] |
| Reflexión deslizante | Simetría axial   | [ninguno]    | inverso   |
|----------------------+------------------+--------------+-----------|

****** Card: lista de movimientos                                                                          :drill:
SCHEDULED: <2018-08-10 Fri>
:PROPERTIES:
:ID:       836f3f1e-b3f5-4f41-80f1-58203b69513f
:DRILL_LAST_INTERVAL: 63.2101
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.75
:DRILL_EASE: 2.32
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-08 Fri 14:36]
:END:
Lista los movimientos rígidos de $\mathbb{R}^2$.

******* Movimientos

 1. Identidad.
 2. Traslación.
 3. Giro o rotación.
 4. Simetría. (Reflexión)
 5. Simetría deslizante. (Reflexión deslizante)

***** Movimientos rígidos de R3
Movimientos rígidos de $\mathbb{R}^3$.

|-----------------------+--------------------+--------------+----------|
| Tipo de movimiento    | Isometría          | Puntos fijos | Carácter |
|-----------------------+--------------------+--------------+----------|
| Identidad             | identidad          | Espacio      | directo  |
| Traslación            | identidad          | ninguno      | directo  |
| Rotación              | Rotación           | Recta        | directo  |
| Movimiento helicoidal | Rotación           | ninguno      | directo  |
| Reflexión             | Simetría especular | Plano        | inverso  |
| Relfexión deslizante  | Simetría especular | ninguno      | inverso  |
| Rotación y reflexión  | Giro y simetría    | Punto        | inverso  |
|-----------------------+--------------------+--------------+----------|

****** Card                                                                                                :drill:
SCHEDULED: <2018-09-02 Sun>
:PROPERTIES:
:DRILL_CARD_TYPE: hide2cloze
:ID:       e3a04df3-1d89-49c7-a0e1-77559f0989f1
:DRILL_LAST_INTERVAL: 67.3146
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.25
:DRILL_EASE: 2.56
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-27 Wed 13:18]
:END:

|-------------------------+----------------------+--------------+----------|
| Tipo de movimiento      | Isometría            | Puntos fijos | Carácter |
|-------------------------+----------------------+--------------+----------|
| Identidad               | identidad            | Espacio      | directo  |
| [Traslación]            | identidad            | ninguno      | directo  |
| Rotación                | [Rotación]           | Recta        | directo  |
| [Movimiento helicoidal] | Rotación             | ninguno      | directo  |
| Reflexión               | [Simetría especular] | [Plano]      | inverso  |
| [Reflexión deslizante]  | Simetría especular   | [ninguno]    | inverso  |
| Rotación y reflexión    | [Giro y simetría]    | Punto        | inverso  |
|-------------------------+----------------------+--------------+----------|

****** Card: lista de movimientos                                                                          :drill:
SCHEDULED: <2018-07-04 Wed>
:PROPERTIES:
:ID:       0b376393-635e-4b49-a699-418212970a3f
:DRILL_LAST_INTERVAL: 30.0148
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 6
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.5
:DRILL_EASE: 2.32
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-04 Mon 14:48]
:END:
Lista los movimientos rígidos de $\mathbb{R}^3$.

******* Movimientos

 1. Identidad.
 2. Traslación.
 3. Rotación.
 4. Movimiento helicoidal.
 5. Reflexión respecto un plano.
 6. Reflexión deslizante.
 7. Rotación (del eje) y reflexión (de su plano tangente).

**** 2. Producto vectorial en R3
***** Producto vectorial
Llamamos *producto vectorial* $u \times v$ al único vector tal que

\[
\forall w:\quad \mathrm{det}(u,v,w) = \left\langle u\times v,w \right\rangle.
\]

***** Propiedades del producto vectorial
Tenemos

 1. $\times$ bilineal antisimétrica,
 2. $\left\langle u \times v, u \right\rangle = \left\langle u \times v,v \right\rangle = 0$,
 3. $|u \times v|^2 = \mathrm{det}(u,v,u \times v) = |u|^2|v|^2 - \left\langle u,v \right\rangle^2$,
 4. $u \times v = 0$ si y sólo si son linealmente independientes,
 5. para $\left\{ u,v \right\}$ independientes, $\left\{ u,v,u \times v \right\}$ es base positiva,
 6. para $\left\{ u,v \right\}$ ortonormales, $\left\{ u,v,u \times v \right\}$ es base positiva ortonormal.

****** Proof 1
Desde las propiedades del determinante.

****** Proof 2
Por definición y por las propiedades del determinante.

****** Proof 3
Se comprueba calculando explícitamente $|u \times v|^2$.

****** TODO Proof 4

****** TODO Proof 5

****** Card: norma del producto vectorial                                                                  :drill:
SCHEDULED: <2018-07-13 Fri>
:PROPERTIES:
:ID:       1fd12884-9b75-47ec-ac19-dcb6e51931da
:DRILL_LAST_INTERVAL: 65.64
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-05-08 Tue 14:02]
:END:
Da la fórmula de $\left| u \times v \right|^2$ 

 * en función de $|u|,|v|,\left\langle u,v \right\rangle$,

 * y en función de $\mathrm{det}(u,v,-)$.

******* Fórmula

\[ |u \times v|^2 = 
\mathrm{det}(u,v,u \times v) = 
\left| u \right|^2|v|^2 - \left\langle u,v \right\rangle^2 
\]

**** 3. Distancia con signo asociada a un hiperplano
**** 4. Reglas de derivación para funciones de una variable
Para $\alpha , \beta \colon I \to \mathbb{R}^{n}$ curvas ${\cal C}^{\infty}$, dado un $\lambda \colon I \to \mathbb{R}$ diferenciable, se tiene

 1. $\left\langle \alpha(t),\beta(t) \right\rangle' = \left\langle \alpha'(t),\beta(t)  \right\rangle + \left\langle \alpha(t)\beta'(t) \right\rangle$,

 2. $(|\alpha(t)|^2)' = 2 \left\langle \alpha'(t),\alpha(t) \right\rangle$

 3. $|\alpha(t)|' = \pair{\alpha'(t), \frac{\alpha(t)}{|\alpha(t)|}}$ cuando $\alpha(t) \neq 0$ para cada $t \in I$

 4. $(\lambda(t)\alpha(t))' = \lambda'(t)\alpha(t) + \lambda(t)\alpha'(t)$

 5. $(\alpha(t) \times \beta(t))' = \alpha'(t) \times \beta(t) + \alpha(t) \times \beta'(t)$ cuando $n = 3$

**** 5. Diferenciabilidad de funciones de varias variables
***** Diferenciabilidad de una función real de varias variables
:PROPERTIES:
:ID:       d3a1f687-19f0-4129-90a1-04976ef88344
:END:
Una $f \colon O \subset \mathbb{R}^n \to \mathbb{R}$ es *infinitamente diferenciable* $f \in {\cal C}^{\infty}$ si
tiene derivadas parciales continuas de todos los órdenes. En tal
caso tenemos el *gradiente*,

\[
(\nabla f)(p) = \left( \pdv{f}{x_1}(p), \dots, \pdv{f}{x_n}(p) \right) = 
(f_{x_1}(p), \dots,f_{x_n}(p))
\]

que puede verse como una función $\mathbb{R}^n \to \mathbb{R}$.

***** Diferenciabilidad de una función de varias variables
Decimos $f \in {\cal C}^{\infty}(O,\mathbb{R}^m)$ *diferenciable* si cada $f_i \in {\cal C}^{\infty}(O,\mathbb{R})$ es
[[id:d3a1f687-19f0-4129-90a1-04976ef88344][diferenciable]].

****** Card                                                                                                :drill:
SCHEDULED: <2018-06-17 Sun>
:PROPERTIES:
:ID:       7c7a55ed-a5e9-43fd-8bb1-d3830db44c33
:DRILL_LAST_INTERVAL: 21.7992
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 5
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.2
:DRILL_EASE: 2.46
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-05-26 Sat 22:16]
:END:
¿Cuándo es $f \in {\cal C}^{\infty}(O,\mathbb{R}^m)$, de varias variables, diferenciable?

******* Diferenciable
Cuando cada una de sus componentes lo es, $f_i \in {\cal C}^{\infty}(O,\mathbb{R})$.

***** Diferencial de una función de varias variables
La *diferencial* de $f \colon \mathbb{R}^n \to \mathbb{R}^m$ es la aplicación lineal $(df)_p\colon \mathbb{R}^n \to \mathbb{R}^m$
que mejor aproxima a $f$ cerca de $p$, es decir

\[
\lim_{h \to 0} \frac{\abs{f(p+h) - f(p) - (df)_p(h)}}{\abs{h}} = 0,
\]

esta viene dada por el Jacobiano, que generaliza al gradiente componente
a componente

\[
(\operatorname{Jac} f)_p = \left( \pdv{f}{x_1} (p), \dots \pdv{f}{x_n} (p) \right);
\]

dicho de otra forma, las filas del jacobiano son los gradientes $(\nabla f_i)(p)$.

**** 6. Difeomorfismos entre abiertos. Teorema de la función inversa
***** Difeomorfismo
:PROPERTIES:
:ID:       ef28dfb1-a3fc-4730-b21c-8dbd06e6988b
:END:
Una aplicación entre abiertos $\phi \colon O \to O'$ es *difeomorfismo* cuando es
diferenciable y biyectiva con inversa diferenciable $\phi^{-1} \colon O' \to O$.

****** Card                                                                                                :drill:
SCHEDULED: <2018-06-21 Thu>
:PROPERTIES:
:ID:       5fc5ff28-bffc-441c-9161-f13889ed291a
:DRILL_LAST_INTERVAL: 39.3578
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.333
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-05-13 Sun 20:47]
:END:
Definición de *difeomorfismo*.

******* Definición
Una aplicación entre abiertos $\phi \colon O \to O'$ es *difeomorfismo* cuando es
diferenciable y biyectiva con inversa diferenciable $\phi^{-1} \colon O' \to O$.

***** Difeomorfismo local
Una aplicación entre abiertos $\phi \colon O \to O'$ es *difeomorfismo local* en
un punto $p \in O$ si existen entornos $p \in U \subset O$ y $\phi(p) \in U' \subset O'$ tales
que $\phi|_U \colon U \to U'$ es difeomorfismo.

****** Card                                                                                                :drill:
SCHEDULED: <2018-08-28 Tue>
:PROPERTIES:
:ID:       a226eca2-2050-4936-bf74-5ba70a400d57
:DRILL_LAST_INTERVAL: 62.1563
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.75
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-27 Wed 13:16]
:END:
Cuándo es $\phi \colon O \to O'$ *difeomorfismo local* en $p \in O$.

******* Answer
Cada punto tiene un entorno en el que la aplicación es difeomorfismo.

******* Definición
Cuando existen entornos $p \in U \subset O$ y $\phi(p) \in U' \subset O'$
tales que $\phi|_U \colon U \to U'$ es difeomorfismo.

***** Difeomorfismos locales y globales
Un difeomorfismo global es un difeomorfismo local en todo punto trivialmente,
pero no todo difeomorfismo local en todo punto es difeomorfismo global.

****** Contraejemplo
:PROPERTIES:
:ID:       1395d142-5681-4763-bd06-a7f307c486a5
:END:
No todo difeomorfismo local en todo punto es un difeomorfismo global.
Podríamos tener el jacobiano con determinante no nula en cada punto y
que la función no fuera siquiera inyectiva. Por ejemplo,

\[
f(x,y) = (e^x \sin(y), e^x \cos(y))
\]

[[https://math.stackexchange.com/questions/39142/a-local-diffeomorphism-of-euclidean-space-that-is-not-a-diffeomorphism][Ejemplo en SE.]]

****** Card: difeomorfismo local no global                                                                 :drill:
SCHEDULED: <2018-08-08 Wed>
:PROPERTIES:
:ID:       2125fe6e-2af6-4d4d-a641-7e1e9759f42e
:DRILL_LAST_INTERVAL: 92.3211
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.75
:DRILL_EASE: 2.8
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-05-08 Tue 14:03]
:END:
¿Cómo podemos construir un difeomorfismo local en cada punto que no
sea difeomorfismo global?

******* Construirlo
Podríamos tener una función con Jacobiano con determinante no nulo
en cada punto pero que no fuera siquiera inyectiva.

\[
f(x,y) = (e^x \sin(y), e^x \cos(y))
\]

Desde [[id:1395d142-5681-4763-bd06-a7f307c486a5][aquí]]. Se tiene isomorfismo por $\det Df(x,y)=e^{2x}$.

***** Difeomorfismo local biyectivo es difeomorfismo
$\phi\colon O \to O'$ es difeomorfismo ssi es difeomorfismo local biyectivo.

****** Proof
En un sentido es trivial. En el otro, tendríamos una función biyectiva,
que sería diferenciable por serlo localmente. Su inversa es localmente
diferenciable también en todo punto, por lo que sería diferenciable.

****** Card                                                                                                :drill:
SCHEDULED: <2018-07-23 Mon>
:PROPERTIES:
:ID:       0867560c-e572-4ef7-84e8-01ff5154571a
:DRILL_LAST_INTERVAL: 49.1467
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.75
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-04 Mon 14:54]
:END:
Caracterización de difeomorfismo por difeomorfismo local.

******* Caracterización
$\phi\colon O \to O'$ difeomorfismo ssi es difeomorfismo local en todo
punto *y biyectiva*.

***** Difeomorfismo local es abierta
Una aplicación entre abiertos $\phi\colon O \to O'$ que es difeomorfismo es abierta.

****** Proof
Dado un abierto $U \subset O$, lo enviará a $\phi(U)$. Todos los puntos ahí tendrán
una preimagen y esta tendrá un entorno, en particular un entorno contenido
en $U$, tal que $\phi$ sea difeomorfismo entre él y un entorno del punto. Este
entorno estará contenido en $O'$, lo que lo hará abierto.

***** Difeomorfismo tiene diferencial isomorfismo
:PROPERTIES:
:ID:       6a2928b0-e787-4240-b76c-1856d14421bb
:END:
Si una aplicación entre abiertos $\phi \colon O \to O'$ es [[id:ef28dfb1-a3fc-4730-b21c-8dbd06e6988b][difeomorfismo]], se tiene
para cada $p \in O$ que $(d\phi)_p \colon \mathbb{R}^n\to \mathbb{R}^n$ es isomorfismo lineal y que
$(d\phi)^{-1}_p = (d\phi^{-1})_{\phi(p)}$.

****** Proof
Usando que $d \mathrm{Id}_p = \mathrm{Id}$ y que $\phi^{-1} \circ \phi = \mathrm{Id}$, tenemos por regla de la
cadena clásica que

\[\mathrm{Id} =
d(\phi^{-1} \circ \phi)_p = (d\phi^{-1})_{\phi(p)} \circ (d\phi)_p
\]

y $(d\phi)_p$ es isomorfismo.

****** Card                                                                                                :drill:
SCHEDULED: <2018-07-12 Thu>
:PROPERTIES:
:ID:       92ff4784-7391-448d-8248-0f984f6e1b98
:DRILL_LAST_INTERVAL: 47.0707
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 5
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 4.4
:DRILL_EASE: 2.9
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-05-26 Sat 22:21]
:END:
Si $\phi$ es difeomorfismo, ¿qué sabemos de $(d\phi)_p$?

******* Sabemos que
es un isomorfismo.
***** Teorema de la función inversa
:PROPERTIES:
:ID:       16bd6b42-7b91-4fcf-8979-faabc0acd594
:END:
Una aplicación entre abiertos $\phi \colon O \to O'$ diferenciable tal que para $p \in O$
se tiene $(d\phi)_p \colon \mathbb{R}^n \to \mathbb{R}^n$ isomorfismo lineal, es difeomorfismo local en $p$.

****** TODO Proof

****** Card                                                                                                :drill:
SCHEDULED: <2018-06-20 Wed>
:PROPERTIES:
:ID:       63d019ff-edf9-4e64-aed4-9a0823572061
:DRILL_LAST_INTERVAL: 43.471
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.25
:DRILL_EASE: 2.08
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-05-08 Tue 14:00]
:END:
Enuncia el teorema de la función inversa para una aplicación entre
abiertos $\phi \colon O \to O'$ diferenciable.

/Hint/: hay que dar una condición sobre $(d\phi)_p$.

******* Enunciado
Una aplicación entre abiertos $\phi \colon O \to O'$ diferenciable tal que para $p \in O$
se tiene $(d\phi)_p \colon \mathbb{R}^n \to \mathbb{R}^n$ isomorfismo lineal, es difeomorfismo local en $p$.

***** Corolarios al teorema de la función inversa
Una aplicación entre abiertos $\phi \colon O \to O'$ diferenciable cumple

 1) que es difeomorfismo local si y sólo si $(d\phi)_p \colon \mathbb{R}^n \to \mathbb{R}^n$ es
    isomorfismo lineal para cada $p \in O$;

 2) que es difeomorfismo si y sólo si $\phi$ es biyectiva y $(d\phi)_p \colon \mathbb{R}^n \to \mathbb{R}^n$
    es isomorfismo lineal para cada $p \in O$.

****** Proof 1
Si es un isomorfismo lineal para cada $p \in O$, por el [[id:16bd6b42-7b91-4fcf-8979-faabc0acd594][teorema]] de la
función inversa es difeomorfismo local en cada punto.

Si es un difeomorfismo local, en cada entorno es un difeomorfismo y
entonces en ese entorno [[id:6a2928b0-e787-4240-b76c-1856d14421bb][la derivada es un isomorfismo]] lineal. Si un
isomorfismo lineal lo es en un entorno, lo es globalmente.

****** TODO Proof 2

*** Tema 1. Curvas ([[~/pdf/Rosales_Curvas.pdf][PDF]])
**** 1.1. Curvas regulares y longitud de arco
***** 1.1.1. Definiciones
****** Curva, traza y curva regular
:PROPERTIES:
:ID:       7fbe4138-469a-4d17-a2d8-a04434cf8489
:END:
Una *curva* es $\alpha\colon I \to \mathbb{R}^n$, con $\alpha \in {\cal C}^{\infty}$ para $I$ intervalo abierto.
Llamamos *traza* a su imagen. Es *curva regular* si su velocidad $\alpha'$
es no nula. Toda curva regular tiene rectas tangentes en todo punto,

\[
\alpha(t) + L(\alpha'(t)) =
\left\{ \alpha(t) + \lambda \alpha'(t) \mid
\lambda \in \mathbb{R} \right\}.
\]

******* Card                                                                                              :drill:
SCHEDULED: <2018-07-01 Sun>
:PROPERTIES:
:ID:       68445172-0dfd-4e02-a7ee-8306eb327ce9
:DRILL_LAST_INTERVAL: 26.8725
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 5.0
:DRILL_EASE: 2.8
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-04 Mon 14:50]
:END:
Definición de curva regular.

******** Definición
$\alpha \colon I \to \mathbb{R}^n$ con $\alpha \in {\cal C}^{\infty}$, $I$ intervalo abierto es curva.
Es regular si $|\alpha'(t)| \neq 0$ para cualquier $t \in I$.

******* Card                                                                                              :drill:
SCHEDULED: <2018-07-11 Wed>
:PROPERTIES:
:ID:       38f704fa-7ee0-4aac-89e8-93153ed48971
:DRILL_LAST_INTERVAL: 37.3865
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.667
:DRILL_EASE: 2.7
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-04 Mon 14:49]
:END:
Sea $\alpha$ curva regular, da la ecuación de su recta tangente
en un instante $t$.

******** Respuesta

\[
\alpha(t) + L(\alpha'(t))
\]

****** Embebimiento
$\alpha\colon I \to \mathbb{R}^n$ es *embebimiento* si $\alpha \colon I \to \alpha(I)$ es homeomorfismo.

******* Card                                                                                              :drill:
SCHEDULED: <2018-10-10 Wed>
:PROPERTIES:
:ID:       47cb18d3-b024-48e7-9b40-9fd5efa6c87a
:DRILL_LAST_INTERVAL: 124.432
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 7
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 4.571
:DRILL_EASE: 3.1
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-08 Fri 14:36]
:END:
¿Cuándo es $\alpha\colon I \to \mathbb{R}^n$ un embebimiento?

******** Definición
Cuando $\alpha \colon I \to \alpha(I)$ es un homeomorfismo.

******* Contraejemplo                                                                                     :drill:
SCHEDULED: <2018-10-09 Tue>
:PROPERTIES:
:ID:       52adbafb-00f1-4b63-b08a-1e89cf23b94b
:DRILL_LAST_INTERVAL: 122.9907
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 7
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 4.286
:DRILL_EASE: 3.1
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-08 Fri 14:36]
:END:
Dar un ejemplo de curva inyectiva que no sea embebimiento.

******** Ejemplo
La curva siguiente, en un intervalo bien escogido

\[
\alpha(t) = \left( \frac{3t}{1+t^3}, \frac{3t^2}{1+t^3} \right)
\]

es inyectiva, pero al tender a infinito se acerca tanto como queramos
al $(0,0)$, por el que ya había pasado antes, lo que hace que no podamos
tener un homeomorfismo.

****** Ejemplos de curvas regulares
Son regulares,

 * rectas $\alpha(t) = p + tv$.

 * circunferencias $\alpha(t) = p + r(\cos(t),\sin(t))$.

 * grafos diferenciables $\alpha(t) = (t,\varphi(t))$.

 * hélices circulares de eje vertical $\alpha(t) = (x_0 + r\cos(t), y_0 + r\sin(t), qt)$.

***** 1.1.2. Reparametrización de curvas
****** Reparametrización
Para $\alpha\colon I \to \mathbb{R}^n$ curva, $\phi\colon J \to I$ difeomorfismo (*cambio de parámetros*),
$\beta =\alpha \circ \phi$ es una *reparametrización*.

 * Tiene la misma traza.
 * Conserva regularidad.

******* Card                                                                                              :drill:
SCHEDULED: <2018-06-20 Wed>
:PROPERTIES:
:ID:       ff9c749b-25a9-4000-8716-25e18dbf6b9b
:DRILL_LAST_INTERVAL: 24.6143
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.333
:DRILL_EASE: 2.22
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-05-26 Sat 22:17]
:END:
¿Qué es una reparametrización de una curva $\alpha$?

******** Respuesta
Una curva $\alpha \circ \phi$ donde $\phi$ es un difeomorfismo de
intervalos abiertos.

***** 1.1.3. Longitud de un arco de curva
****** 1.11. Longitud
Definimos la longitud de una función continua $\alpha \colon [a,b] \to \mathbb{R}^n$ como

\[
L_a^b(\alpha) = \sup\left\{
\sum_{k=0}^m |\alpha(t_k+1) - \alpha(t_{k})| \;\middle|\;  
\left\{ k_0,\dots,k_{m+1} \right\} \mbox{ partición de } [a,b] 
\right\}
\]

******* Las rectas tienen longitud mínima
Por definición, usando la partición trivial $\left\{ a,b \right\}$.

******* La longitud de una curva continua puede ser infinita
La longitud de una curva /continua/ puede ser infinita, pero
si es una curva ${\cal C}^1$, [[id:6c8461d6-7792-4a55-b2eb-9e3e719d1f21][tiene longitud finita]]. Un ejemplo de curva
continua con longitud infinita es

\[
\alpha(t) = \left\{\begin{array}{ll}
(t,\cos(\pi/t)), & \mbox{ si } t \neq 0, \\
0, & \mbox{ si } t = 0.
\end{array}\right.
\]

****** 1.12. Longitud en compactos
:PROPERTIES:
:ID:       6c8461d6-7792-4a55-b2eb-9e3e719d1f21
:END:
Para $\alpha \colon [a,b] \subseteq I \to \mathbb{R}^n$ diferenciable ${\cal C}^1$, tenemos

\[
L_a^b(\alpha) = \int_a^b |\alpha'(t)|\,dt < \infty.
\]

Así, las curvas tienen longitud finita en intervalos compactos.

******* TODO Proof                                                                                        :extra:
******** Acotación
Por ser $\alpha'$ continua, está acotada en el compacto $[a,b]$ y la
integral entera es finita. Para cualquier parición se tiene,
usando Teorema fundamental del cálculo, una cota uniforme

\[\begin{aligned}
L(\alpha,P) &= \sum_{k=0}^{m-1} |\alpha(t_{k+1}) - \alpha(t_k)| \\
&= \sum_{k=0}^{m-1} \abs{\int_{t_k}^{t_{k+1}} \alpha'(s)\,ds} \\
&\leq \sum_{k=0}^{m-1} \int_{t_k}^{t_{k+1}} \abs{\alpha'(s)}\,ds \\
&= \int_{a}^{b} \abs{\alpha'(s)}\,ds.
\end{aligned}\]

******** TODO Igualdad
Lo que nos queda por demostrar es que se tiene la igualdad,
viendo que para cualquier $\varepsilon > 0$, hay una partición $P$ tal
que

\[
\int_a^b |\alpha'(t)|\,dt - L(\alpha,P) < \varepsilon.
\]

Para cualquier partición $P = \left\{ t_0<t_1<\dots<t_m \right\}$, podemos
aplicar el Teorema del Valor Medio a las componentes $\alpha(t) = (x_1(t),\dots,x_n(t))$
para tener $c_{ik} \in [t_k,t_{k+1}]$ tales que

\[
x_i(t_{k+1}) - x_i(t_k) = x'_i(c_{ik})(t_{k+1}-t_k), \quad \forall i = 1,\dots,n.
\]

Definimos $f(s_1,\dots,s_n) = \sqrt{x_1'(s_1)^2 + \dots + x_n'(s_n)^2}$
******* Card: longitud de una curva                                                                       :drill:
SCHEDULED: <2018-08-18 Sat>
:PROPERTIES:
:ID:       3fb16a48-0357-42f8-98c2-c74d4562bc49
:DRILL_LAST_INTERVAL: 68.8101
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 7
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.715
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-10 Sun 13:57]
:END:
Para $\alpha\colon I \to \mathbb{R}^n$ diferenciable ${\cal C}^1$, calcula la longitud entre
$[a,b]$ como una integral.

******** Longitud

\[
L_a^b(\alpha) = \int_a^b |\alpha'(t)|\,dt < \infty.
\]

****** 1.14. Preservación de la longitud
Para $\alpha\colon I \to \mathbb{R}^n$ curva con $[a,b] \subseteq I$, tenemos

 1. que si $\phi\colon \mathbb{R}^n \to \mathbb{R}^n$ es un movimiento rígido, $L_a^b(\phi \circ \alpha) = L_a^b(\alpha)$;

 2. que si $\phi\colon J \to I$ es un difeomorfismo y $\beta = \alpha\circ\phi$, entonces
    $L_c^d(\beta) = L_a^b(\alpha)$, para $[c,d] = \phi^{-1}[a,b]$.

Es decir, la longitud se preserva por [[id:92d75a96-b872-4ea6-ae5a-b83d975e2b37][movimientos rígidos]] y
reparametrizaciones.

******* Card                                                                                              :drill:
SCHEDULED: <2018-07-01 Sun>
:PROPERTIES:
:ID:       102ec980-bf93-4cac-be57-c3b34b2bdd68
:DRILL_LAST_INTERVAL: 26.6744
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.667
:DRILL_EASE: 2.7
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-04 Mon 14:51]
:END:
¿La composición de qué morfismos preserva la longitud de una
curva?

******** Clase de morfismos

 * Movimientos rígidos, $L_a^b(\phi \circ \alpha) = L_a^b(\alpha)$.

 * Reparametrizaciones, $L_c^d(\beta) = L_a^b(\alpha)$.

******* TODO Proof
***** 1.1.4. Curvas parametrizadas por el arco
****** Definición 1.16. Curva parametrizada por el arco
:PROPERTIES:
:ID:       cb6ea57b-b063-4959-9a36-44a2662b6fce
:END:
 $\alpha\colon I \to \mathbb{R}^n$ [[id:7fbe4138-469a-4d17-a2d8-a04434cf8489][curva]] es *parametrizada por el arco* (p.p.a) si $|\alpha'(t)| = 1$.
Las p.p.a. son regulares.

******* Card                                                                                              :drill:
SCHEDULED: <2018-07-08 Sun>
:PROPERTIES:
:ID:       976be4e8-a312-4644-bb1b-5b699363607c
:DRILL_LAST_INTERVAL: 33.853
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 5.0
:DRILL_EASE: 2.8
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-04 Mon 14:54]
:END:
Definición de curva p.p.a.

******** Definición
$\alpha\colon I \to \mathbb{R}^n$ [[id:7fbe4138-469a-4d17-a2d8-a04434cf8489][curva]] es *parametrizada por el arco* (p.p.a) si $|\alpha'(t)| = 1$.

****** Proposición 1.17. Lema de reparametrización
:PROPERTIES:
:ID:       1e330295-fe16-4262-a88b-af5a84c66fb8
:END:
$\alpha\colon I \to \mathbb{R}^n$ regular, existe $\phi\colon J \to I$ difeomorfismo 
creciente de intervalos abiertos tal que $\beta = \alpha\circ \phi$ es [[id:cb6ea57b-b063-4959-9a36-44a2662b6fce][p.p.a.]]

/La demostración da una construcción explícita./ Definimos

\[
\psi(t) = L_a^t(\alpha) = \int_a^t |\alpha'(s)|\,ds.
\]

y tomamos $\phi =\psi^{-1}$.

******* Proof
Para un $a \in I$ fijo, definimos $\psi \colon I \to \mathbb{R}$ por

\[
\psi(t) = L_a^t(\alpha) = \int_a^t |\alpha'(s)|\,ds.
\]

Como $\alpha \in {\cal C}^{\infty}$, por Teorema fundamental del cálculo $\psi'(t) = |\alpha'(t)| > 0$
por regularidad. Queda $\psi \in {\cal C}^{\infty}$ estrictamente creciente e inyectiva.
Así, $J = \psi(I)$ intervalo y $\psi \colon I \to J$ biyectiva. Por Teorema de la
función inversa, es difeomorfismo y llamamos $\phi =\psi^{-1}$. Ahora,

\[
\phi'(s) = \frac{1}{|\alpha'(\phi(s))|} > 0
\]

que implica

\[\abs{\beta'(s)} = 
\abs{(\alpha \circ \phi)'(s)} = 
\abs{\frac{\alpha'(\phi(s))}{ |\alpha'(\phi(s))|}} = 
1.\]

******* Card                                                                                              :drill:
SCHEDULED: <2018-07-16 Mon>
:PROPERTIES:
:ID:       ff49f39c-0657-4411-86da-a586b9673753
:DRILL_LAST_INTERVAL: 50.8001
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.5
:DRILL_EASE: 2.22
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-05-26 Sat 22:19]
:END:
Enuncia el lema de reparametrización para $\alpha\colon I \to \mathbb{R}^n$ regular.

******** Lema
Existe $\phi\colon J \to I$

 * difeomorfismo,
 * creciente,
 * de intervalos abiertos,

tal que $\alpha \circ \phi$ es [[id:cb6ea57b-b063-4959-9a36-44a2662b6fce][p.p.a.]]

******* Card: cálculo                                                                                     :drill:
SCHEDULED: <2018-08-11 Sat>
:PROPERTIES:
:ID:       5b34db3c-8a95-4c74-9965-b87e184b414a
:DRILL_LAST_INTERVAL: 76.896
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.46
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-05-26 Sat 22:19]
:END:
Dada una $\alpha\colon I \to \mathbb{R}^n$ buscar la reparametrización $\phi\colon J \to I$ que
hace que $\beta = \alpha\circ \phi$ sea una curva p.p.a.

******** Reparametrización
Fijamos algún $t_0$ y calculamos la integral

\[
\psi(t) = L_{t_0}^t(\alpha) =\int_{t_0}^t |\alpha'(s)|\,ds;
\]

y la inversa $\phi =\psi^{-1}$ es la reparametrización buscada.

**** 1.2. Geometría de curvas regulares en el plano
***** 1.2.1. Diedro de Frenet y curvatura de curvas p.p.a.
****** 2.0. Diedro de Frenet
:PROPERTIES:
:ID:       b0a55e94-4a63-4257-a7b5-9641d848d4e5
:END:
Sea $\alpha$ p.p.a., el *diedro de Frenet* es $\left\{ T(s),N(s) \right\}$, base ortonormal
positiva con

 * el tangente $T(s) = \alpha'(s)$;
 * y el normal $N(s) = J(T(s))$, donde $J(x,y) = (-y,x)$.

****** 2.1. Definición de curvatura
Sea $\alpha$ p.p.a., se define la curvatura $k \colon I \to \mathbb{R}$ como

\[
k(s) = \left\langle T'(s),N(s) \right\rangle = \left\langle \alpha''(s),J(\alpha'(s)) \right\rangle.
\]

Nótese que $k \in {\cal C}^{\infty}$.

****** 2.0. Ecuaciones de Frenet
Sea $\alpha$ p.p.a., las coordenadas de $T'(s),N'(s)$ en el [[id:b0a55e94-4a63-4257-a7b5-9641d848d4e5][diedro de Frenet]] son

 * $T'(s) = k(s)N(s)$,
 * $N'(s) = -k(s)T(s)$.

******* Proof
Derivando $|T(s)|^2 = |N(s)|^2 = 1$ obtenemos $\pair{T(s),T'(s)} = \pair{N(s),N'(s)} = 0$,
simplemente usamos que $T,N$es una base ortonormal.

****** 2.2. Expresión alternativa de la curvatura
Sea $\alpha$ p.p.a.,

\[
k(s) = \mathrm{det}(\alpha'(s),\alpha''(s)).
\]

******* Proof
Como $\mathrm{det}(T(t),N(t)) = 1$, tenemos

\[
k(t) = \mathrm{det}(T(t),k(s)N(t)) = \mathrm{det}(T(t),T'(t)) = \mathrm{det}(\alpha'(t),\alpha''(t)).
\]

****** 2.4. Curvatura de rectas y circunferencias
La curvatura de una recta es nula, la curvatura de una circunferencia
de radio $R$ es constante $k(s) = 1/R$.

***** 1.2.2. Diedro de Frenet y curvatura de curvas regulares
****** 2.5. Definiciones para curvas regulares
Para $\alpha \colon I \to \mathbb{R}^2$ regular consideramos una reparametrización
a p.p.a. $\beta = \alpha\circ\phi$ y definimos

 * $T_{\alpha}(t) = T_{\beta}(\phi^{-1}(t))$,
 * $N_{\alpha}(t) = N_{\beta}(\phi^{-1}(t))$,
 * $k_{\alpha}(t) = k_{\beta}(\phi^{-1}(t))$.

Nótese que una reparametrización así [[id:1e330295-fe16-4262-a88b-af5a84c66fb8][existe]] siempre.

****** 2.5. Ecuaciones para curvas regulares en el plano
:PROPERTIES:
:ID:       fc237c54-3cf6-446e-9c62-1e256a3684ff
:END:
Para $\alpha \colon I \to \mathbb{R}^2$ curva regular se tiene el siguiente diedro de Frenet
y la siguiente curvatura

\[
T(t) = \frac{\alpha'(t)}{|\alpha'(t)|},\quad
N(t) = \frac{J(\alpha'(t))}{|\alpha'(t)|},\quad
k(t) = \frac{\mathrm{det}(\alpha'(t),\alpha''(t))}{|\alpha'(t)|^3}.
\]

y además se cumplen las siguientes ecuaciones de Frenet

 * $T'(t) = |\alpha'(t)|k(t)N(t)$,

 * $N'(t) = -|\alpha'(t)|k(t)T(t)$,

y como consecuencia, la curvatura orientada se escribe como

\[
k(t) = \frac{\left\langle T'(t),N(t) \right\rangle}{|\alpha'(t)|}.
\]

Como corolario hemos demostrado además que $T_{\alpha},N_{\alpha},k_{\alpha}$ no
dependen de la reparametrización elegida.

******* Proof
Reparametrizamos la curva p.p.a. $\beta = \alpha\circ\phi$ con un difeomorfismo
creciente y usamos que

\[
\abs{\phi'(s)}\abs{\alpha'(\phi(s))} = 1
\]

para comprobar las igualdades.

******* Card: diedro                                                                                      :drill:
SCHEDULED: <2018-08-05 Sun>
:PROPERTIES:
:ID:       dc77cdaa-f13a-4306-960e-f63531e65620
:DRILL_LAST_INTERVAL: 70.544
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 5
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.66
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-05-26 Sat 22:35]
:END:
Dar el diedro de Frenet de una curva regular $\alpha(t) \colon I \to \mathbb{R}^2$.

******** Diedro

\[
T_{\alpha}(t) = \frac{\alpha'(t)}{|\alpha'(t)|},\quad
N_{\alpha}(t) = \frac{J(\alpha'(t))}{|\alpha'(t)|}
\]

******* Card: curvatura                                                                                   :drill:
SCHEDULED: <2018-08-20 Mon>
:PROPERTIES:
:ID:       054cec15-5c54-4d1f-84f7-56cb9df2ede5
:DRILL_LAST_INTERVAL: 71.3774
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 12
:DRILL_FAILURE_COUNT: 5
:DRILL_AVERAGE_QUALITY: 2.417
:DRILL_EASE: 2.38
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-10 Sun 13:57]
:END:
Dar dos fórmulas de la curvatura de una curva regular en
el plano, $\alpha(t)\colon I \to\mathbb{R}^2$.

******** Curvatura

\[ k_{\alpha}(t) 
= \frac{\mathrm{det}(\alpha'(t),\alpha''(t))}{|\alpha'(t)|^3}
= \frac{\left\langle T'(t),N(t) \right\rangle}{|\alpha'(t)|}
\]

******* Card: ecuaciones de Frenet                                                                        :drill:
SCHEDULED: <2018-10-01 Mon>
:PROPERTIES:
:ID:       cca9ded0-aa24-4138-bbb8-c057e5d1015b
:DRILL_LAST_INTERVAL: 94.4685
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 10
:DRILL_FAILURE_COUNT: 3
:DRILL_AVERAGE_QUALITY: 3.1
:DRILL_EASE: 2.66
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-29 Fri 17:45]
:END:
Enunciar las ecuaciones de Frenet para una curva regular en el plano.

******** Ecuaciones de Frenet
Son las coordenadas de los derivados del tangente y del
normal en el diedro de Frenet.

\[\left\{\begin{array}{l}
T'_{\alpha}(t) = |\alpha'(t)| k_{\alpha}(t) N_{\alpha}(t) \\
N'_{\alpha}(t) = -|\alpha'(t)| k_{\alpha}(t) T_{\alpha}(t) 
\end{array} \right.\]

****** 2.8. Propiedades de la curvatura en el plano
La curvatura es

 1. *Local*, para $\alpha \colon I \to \mathbb{R}^2$ y $\beta \colon J \to \mathbb{R}^2$, si $\alpha = \beta$ en
    $(t_0-\varepsilon,t_0+\varepsilon)\subseteq I \cap J$, entonces $k_{\alpha}(t_0) = k_{\beta}(t_0)$.
    
 2. *Invariante a movimientos rígidos directos*, si $\alpha \colon I \to \mathbb{R}^2$
    regular, $\phi \circ \alpha$ regular con $k_{\phi \circ \alpha} = k_{\alpha}$ si $\phi$ es directo y
    $k_{\phi \circ \alpha} = -k_{\alpha}$ si $\phi$ es inverso.

 3. *Invariante a reparametrizaciones*, para $\alpha \colon I \to \mathbb{R}^2$
    regular y $\phi\colon J \to I$ difeomorfismo, $\alpha \circ \phi$ es regular 
    y $k_{\alpha\circ\phi} = k_{\alpha} \circ \phi$ si $\phi$ es creciente o $k_{\alpha \circ \phi} = - k_{\alpha} \circ \phi$ si
    $\phi$ es decreciente.

******* Proof 1
Tenemos una [[id:fc237c54-3cf6-446e-9c62-1e256a3684ff][fórmula de la curvatura]] que sólo depende de las
derivadas que son locales.

******* Proof 2
Tomamos $\phi = Ax + b$ para alguna $A \in {\cal O}(2)$, que tendrá $|A| = \pm 1$
dependiendo de si es directa o inversa y calculamos.

******* Proof 3
Calculando la curvatura nos queda que depende del signo de $\phi'(t)^3$
y la fórmula buscada.

******* Card: curvatura en el plano bajo reparametrizaciones                                              :drill:
SCHEDULED: <2018-07-06 Fri>
:PROPERTIES:
:ID:       f42e0f4d-e16f-48fd-b03c-ad07c94bf795
:DRILL_LAST_INTERVAL: 31.6821
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.5
:DRILL_EASE: 2.46
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-04 Mon 14:52]
:END:
¿Cómo varía la curvatura en el plano bajo reparametrizaciones?
Calcular $k_{\alpha \circ \phi}$.

******** Answer

 1. Compone con reparametrizaciones crecientes, $k_{\alpha \circ \phi} = k_{\alpha} \circ \phi$.
 2. Opuesta de componer con decrecientes, $k_{\alpha \circ \phi} = - k_{\alpha} \circ \phi$.

******* Card: curvatura en el plano bajo movimientos rígidos                                              :drill:
SCHEDULED: <2018-06-30 Sat>
:PROPERTIES:
:ID:       906e3710-34fb-4a1b-9307-b0080cc5ab7b
:DRILL_LAST_INTERVAL: 26.3376
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.667
:DRILL_EASE: 2.7
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-04 Mon 14:51]
:END:
¿Cómo varía la curvatura en el plano bajo movimientos rígidos?
Calcular $k_{\phi \circ \alpha}$.

******** Answer

 1. Invariante a movimientos rígidos directos, $k_{\phi \circ \alpha} = k_{\alpha}$.
 2. Opuesta bajo movimientos rígidos inversos, $k_{\phi \circ \alpha} = -k_{\alpha}$.

****** 2.9. Curvas de curvatura constante
Si $\alpha \colon I \to \mathbb{R}^2$ tiene curvatura constante $k(t) = c$,

 1. si $c = 0$, $\alpha(I)$ está en una recta afín;
 2. si $c \neq 0$, $\alpha(I)$ está en una circunferencia de radio $1/|c|$.

******* Proof 1
Por Frenet, $T'(t) = 0$, luego $\alpha'(t) = |\alpha'(t)|v$, e integramos
para tener $\alpha(t) = p + f(t)v$ para algunos $p$ y $f$.

******* Proof 2
Derivando y usando Frenet en 

\[
f(t) = \alpha(t) + \frac{1}{c}N(t)
\]

tenemos $f$ constante y $\abs{\alpha(t) - v} = 1/c$.

**** 1.3. Geometría de curvas regulares en el espacio
***** 1.3.1. Triedro de Frenet, curvatura y torsión de curvas p.p.a.
****** 3.1. Curvatura de una curva p.p.a.
Sea $\alpha$ p.p.a., su *curvatura* es

\[
k(s) = |T'(s)| = |\alpha''(s)|.
\]

En este caso, y a diferencia de $\mathbb{R}^2$, la curvatura es
siempre no negativa. Es diferenciable en todos los puntos
en los que es positiva.

****** Vector normal a la curva p.p.a. en un punto
El *normal* a $\alpha \colon I \to \mathbb{R}^3$ p.p.a. en $s$ se define cuando $k(s) > 0$
como

\[
N(s) = \frac{T'(s)}{\abs{T'(s)}} = \frac{T'(s)}{k(s)} = \frac{\alpha''(s)}{|\alpha''(s)|}.
\]

****** Vector binormal a la curva p.p.a. en un punto
El *binormal* a $\alpha \colon I \to \mathbb{R}^3$ p.p.a. en $s$ se define cuando $k(s) > 0$
como

\[
B(s) = T(s) \times N(s).
\]

****** Triedro de Frenet de una curva p.p.a. en un punto
Llamamos *triedro de Frenet* a la base ortonormal positiva
dada por $\left\{ T(s),N(s),B(s) \right\}$.

****** Rectas afines y plano afín osculador

 * *Recta afín tangente* $\alpha(s) + L(T(s))$,
 * *Recta afín normal* $\alpha(s) + L(N(s))$,
 * *Recta afín binormal* $\alpha(s) + L(B(s))$,
 * *Plano afín osculador* $\alpha(s) + L(T(s),N(s))$.

Nótese que $B(s)$ es vector normal unitario al plano osculador.
Tendremos que $|B'(s)| = \tau(s)$, medida de cómo cambia el plano
osculador.

****** Torsión de una curva p.p.a.
Para $\alpha \colon I \to \mathbb{R}^3$ curva p.p.a. con $k > 0$, definimos

\[
\tau(s) = \left\langle B'(s), N(s) \right\rangle.
\]

******* Card: buena definición                                                                            :drill:
SCHEDULED: <2018-07-11 Wed>
:PROPERTIES:
:ID:       651ce58d-4284-4b21-a958-e42dac558cca
:DRILL_LAST_INTERVAL: 36.6461
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.667
:DRILL_EASE: 2.7
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-04 Mon 14:54]
:END:
¿Dónde están definidas la torsión, el normal y el binormal
para una curva p.p.a. en el espacio?

******** Respuesta
En los puntos en los que la curvatura es no nula.

****** Cálculo de la torsión
Tenemos

\[
\tau(s) = -\frac{\mathrm{det}(\alpha'(s),\alpha''(s),\alpha'''(s))}{k(s)^2}.
\]

******* Proof
Desde la definición usando $B = T \times N$ y propiedades del
determinante.

****** 3.4. Ejemplo: rectas
La normal, binormal y torsión no están definidos en el caso de rectas.
La tangente la da la propia recta y la curvatura es nula.

****** 3.5. Ejemplo: las curvas planas tienen torsión nula
Una curva (no recta) contenida en un plano afín tiene torsión nula.

******* Proof
Derivando tenemos $T$ y $N$ en el plano y $B$ ortogonal a él. El plano
es constante y sólo tiene dos vectores normales unitarios $\pm n$; por
conexión del intervalo, $B$ será uno de ellos.

****** Ejemplo: hélices
Las hélices circulares de eje vertical con parámetros $R > 0$ y $Q \neq 0$ tienen

\[
k(s) = \frac{R}{R^2 + Q^2},\quad \tau(s) = \frac{-Q}{R^2+Q^2}.
\]

***** 1.3.2. Triedro de Frenet, curvatura y torsión de curvas regulares
****** Definiciones para curvas regulares en el espacio
Para $\alpha \colon I \to \mathbb{R}^3$ regular consideramos un difeomorfismo *creciente* $\phi\colon J \to I$
reparametrización a $\beta = \alpha\circ \phi$ curva p.p.a. y definimos las
características de la curva según ella.

 * $T_{\alpha}(t) = T_{\beta}(\phi^{-1}(t))$,
 * $N_{\alpha}(t) = N_{\beta}(\phi^{-1}(t))$,
 * $B_{\alpha}(t) = B_{\beta}(\phi^{-1}(t))$,
 * $k_{\alpha}(t) = k_{\beta}(\phi^{-1}(t))$,
 * $\tau_{\alpha}(t) = \tau_{\beta}(\phi^{-1}(t))$.

Nótese que esa reparametrización [[id:1e330295-fe16-4262-a88b-af5a84c66fb8][existe]] siempre.

****** 3.7. Ecuaciones para curvas regulares en el espacio
:PROPERTIES:
:ID:       6efcd992-f089-4c91-ac08-446846840c0b
:END:
Para $\alpha \colon I \to \mathbb{R}^3$ curva regular se tiene el siguiente triedro de
Frenet

\[
T_{\alpha} = \frac{\alpha'}{|\alpha'|},\quad
N_{\alpha} = B_{\alpha} \times T_{\alpha},\quad
B_{\alpha} = \frac{\alpha' \times \alpha''}{|\alpha' \times \alpha''|}
\]

y la siguiente cruvatura y torsión

\[
k_{\alpha}(t) = \frac{|\alpha' \times \alpha''|}{|\alpha'|^3},\quad
\tau_{\alpha} = - \frac{\mathrm{det}(\alpha',\alpha'',\alpha''')}{|\alpha'\times \alpha''|^2}
\]

y además se cumplen las siguientes ecuaciones de Frenet

 * $T'_{\alpha} = |\alpha'|k_{\alpha}N_{\alpha}$,
 * $N'_{\alpha} = -|\alpha'|k_{\alpha}T_{\alpha} - |\alpha'|\tau_{\alpha}B_{\alpha}$,
 * $B'_{\alpha} = |\alpha'|\tau_{\alpha}N_{\alpha}$.

******* TODO Proof
******* Card: triedro                                                                                     :drill:
SCHEDULED: <2018-06-26 Tue>
:PROPERTIES:
:ID:       dfe88e2d-9b42-44ed-ae62-2bac55c7c108
:DRILL_LAST_INTERVAL: 31.3733
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 5
:DRILL_FAILURE_COUNT: 2
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-05-26 Sat 22:24]
:END:
Triedro de Frenet $T,N,B$ de una curva regular en el espacio.

******** Triedro

\[
T_{\alpha} = \frac{\alpha'}{|\alpha'|},\quad
N_{\alpha} = B_{\alpha} \times T_{\alpha},\quad
B_{\alpha} = \frac{\alpha' \times \alpha''}{|\alpha' \times \alpha''|}
\]

******* Card: curvatura                                                                                 :nodrill:
SCHEDULED: <2018-08-16 Thu>
:PROPERTIES:
:ID:       920516ed-24b4-4506-ae4d-41d505077bae
:DRILL_LAST_INTERVAL: 48.0707
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 7
:DRILL_FAILURE_COUNT: 2
:DRILL_AVERAGE_QUALITY: 2.571
:DRILL_EASE: 2.18
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-29 Fri 17:43]
:END:
Curvatura de una curva regular en el *espacio*.

******** Curvatura

\[
k_{\alpha} = \frac{|\alpha' \times \alpha''|}{|\alpha'|^3}
\]

******* Card: torsión                                                                                   :nodrill:
SCHEDULED: <2018-06-12 Tue>
:PROPERTIES:
:ID:       be660965-a5df-4345-b491-2e73601a8069
:DRILL_LAST_INTERVAL: 4.3149
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 9
:DRILL_FAILURE_COUNT: 5
:DRILL_AVERAGE_QUALITY: 2.667
:DRILL_EASE: 2.42
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-08 Fri 14:35]
:END:
Torsión de una curva regular en el espacio.

******** Torsión

\[
\tau_{\alpha} = -\frac
{\mathrm{det}(\alpha',\alpha'',\alpha''')}
{|\alpha'\times \alpha''|^2}
\]

******* Card: ecuaciones de Frenet                                                                        :drill:
SCHEDULED: <2018-07-06 Fri>
:PROPERTIES:
:ID:       afe3152a-639e-4a7f-9e69-74f74f00c3ce
:DRILL_LAST_INTERVAL: 40.9431
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.25
:DRILL_EASE: 2.46
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-05-26 Sat 22:33]
:END:
Ecuaciones de Frenet. Dar $T',N',B'$ de una curva regular en
el espacio.

******** Ecuaciones

 * $T' = |\alpha'|kN$,
 * $N' = -|\alpha'|kT - |\alpha'|\tau B$,
 * $B' = |\alpha'|\tau N$.

****** 3.9. Propiedades de la curvatura y torsión en el espacio
La curvatura y la torsión son

 1. *Locales*, para $\alpha \colon I \to \mathbb{R}^2$ y $\beta \colon J \to \mathbb{R}^2$, si $\alpha = \beta$ en
    $(t_0-\varepsilon,t_0+\varepsilon)\subseteq I \cap J$, entonces $k_{\alpha}(t_0) = k_{\beta}(t_0)$ y $\tau_{\alpha}(t_0) = \tau_{\beta}(t_0)$
    cuando está definida.

 2. *Invariante a movimientos rígidos directos*, si $\alpha \colon I \to \mathbb{R}^3$
    regular, $\phi \circ \alpha$ regular con $k_{\phi \circ \alpha} = k_{\alpha}$, y con $\tau_{\alpha} = \tau_{\beta}$
    si $\phi$ es directo y $\tau_{\phi \circ \alpha} = -\tau_{\alpha}$ si $\phi$ es inverso cuando está definido.

 3. *Invariante a reparametrizaciones*, para $\alpha \colon I \to \mathbb{R}^3$
    regular y $\phi\colon J \to I$ difeomorfismo, $\alpha \circ \phi$ regular y
    $k_{\beta} = k_{\alpha} \circ \phi$ y $\tau_{\beta} = \tau_{\alpha}\circ\phi$.

******* TODO Proof
****** 3.10. Curvas de curvatura o torsión nulas
Si $\alpha \colon I \to \mathbb{R}^3$ es regular

 1. y $k_{\alpha}=0$, la curva está contenida en una recta afín;
 2. y si $k_{\alpha} > 0$ y $\tau_{\alpha} = 0$, entonces la curva está contenida en un 
    plano afín.
   
******* Proof 1
Por ser la [[id:6efcd992-f089-4c91-ac08-446846840c0b][curvatura]] nula tenemos $|\alpha'(t) \times \alpha''(t)|$ y entonces
$\alpha''(t) = \lambda(t)\alpha'(t)$ para escalares

\[
\lambda(t) = \frac{\pair{\alpha'(t),\alpha''(t)}}{|\alpha'(t)|^2}.
\]

Dada una ecuación diferencial de la forma $x'(t) = \lambda(t)x(t)$, las
soluciones son de la forma 

\[
x(t) = x_0 \exp \left( \int_{t_0}^t \lambda(s)\,ds \right);
\]

así que si aplicamos esto componente a componente tenemos un
vector $v$ tal que

\[
\alpha'(t) = v \exp \left( \int_{t_0}^t \lambda(s)\,ds \right),
\]

que además es no nulo porque $\alpha'$ es regular.  Integrando en cada
componente tenemos que $\alpha(t) = p + f(t)v \subseteq p + L(v)$ para algún 
$p$ fijo y $f(t)$ escalar.

******* Proof 2
Tenemos $B'_{\alpha}(t) = 0$ por [[id:6efcd992-f089-4c91-ac08-446846840c0b][Frenet]], luego $B(t) = B_0$. Fijamos un punto
en la curva $p_0 = \alpha(t_0)$ y tomamos el plano $P = \left\{ p \in \mathbb{R}^3 \mid \left\langle p-p_0, B_0 \right\rangle \right\} = 0$.

Finalmente comprobamos que $f(t) = \pair{\alpha(t) - p_0,B_0}$ es constante
derivando

\[
f'(t) = \pair{\alpha'(t),B_0} = |\alpha'(t)| \pair{T(t),B(t)} = 0,
\]

y que es trivialmente nula en $f(t_0) = 0$.

**** 1.4. Teorema fundamental de curvas en el plano y en el espacio
***** 1.4.1. Teorema fundamental de curvas
****** 4.1. Lema: resolución de ecuaciones lineales
Si $A \colon I \to M_n(\mathbb{R})$ y $b \colon I \to \mathbb{R}^n$ diferenciables sobre intervalo abierto,
para $s_0 \in I$, $c_0 \in \mathbb{R}^n$ existe una única $c \colon I \to \mathbb{R}^n$ tal que $c(s_0) = c_0$ y
tal que $c'(s) = A(s)c(s) + b(s)$.

****** 4.2. Teorema fundamental de curvas en el espacio
:PROPERTIES:
:ID:       a6da951d-2a14-4818-be6c-0b39a732b12d
:END:
Para $I \subseteq \mathbb{R}$ intervalo abierto y $k,\tau\in {\cal C}^{\infty}(I)$ con $k > 0$;

 1. existe $\alpha \colon I \to \mathbb{R}^3$ p.p.a. con $k_{\alpha} = k$ y $\tau_{\alpha} = \tau$;

 2. para cualquier otra $\beta \colon I \to \mathbb{R}^3$ p.p.a. con $k_{\beta} = k$ y $\tau_{\beta} = \tau$, existe un
    movimiento rígido directo $\phi \colon \mathbb{R}^3 \to \mathbb{R}^3$ con $\beta = \phi \circ \alpha$.

Es decir, dada una curvatura positiva y una torsión, existe una curva
p.p.a. que las realiza, única p.p.a. salvo movimientos rígidos
directos.

******* TODO Proof
******* Card                                                                                              :drill:
SCHEDULED: <2018-07-19 Thu>
:PROPERTIES:
:ID:       bb2b3785-52de-4496-b89e-f0d9862b0019
:DRILL_LAST_INTERVAL: 72.2864
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.25
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-05-08 Tue 14:02]
:END:
Enuncia con palabras el teorema fundamental de curvas.

******** Enunciado
Dada una curvatura positiva y una torsión en un intervalo, existe una
curva p.p.a. que las realiza, única p.p.a. salvo movimientos rígidos
directos.

****** 4.5. Curvas en el espacio de curvatura y torsión constantes
Si $\alpha \colon I \to \mathbb{R}^3$ tiene curvatura positiva constante $k_0 > 0$ y torsión
constante $\tau_0$, entonces 

 * si $\tau_0 = 0$, está en una circunferencia $\alpha(I) \subseteq C$,
 * si $\tau_0 \neq 0$, está en una hélice circular $\alpha(I) \subseteq H$.

******* Proof
Siendo regulares, podemos reparametrizarlas en p.p.a. con una
[[id:1e330295-fe16-4262-a88b-af5a84c66fb8][reparametrización positiva]]; que mantendrá curvatura y torsión.
La circunferencia tiene curvatura positiva y torsión nula, y
una curva queda [[id:a6da951d-2a14-4818-be6c-0b39a732b12d][determinada]] salvo movimientos rígidos, que
llevan circunferencias en circunferencias.

Las hélices tienen curvatura y torsión constantes, por Teorema
fundamental, quedan determinadas por ellas salvo movimientos
rígidos.

****** 4.7. Teorema fundamental de curvas en el plano
Para $I \subseteq \mathbb{R}$ intervalo abierto y $k \in {\cal C}^{\infty}(I)$, 

 1. existe $\alpha \colon I \to \mathbb{R}^2$ p.p.a. con $k_{\alpha}=k$;

 2. para cualquier otra $\beta \colon I \to \mathbb{R}^2$ p.p.a. con $k_{\beta}=k$ y $\tau_{\beta}=\tau$, existe un
    movimiento rígido directo $\phi \colon\mathbb{R}^2\to\mathbb{R}^2$ con $\beta = \phi \circ \alpha$.

Es decir, dada una curvatura cualquiera, existe una curva p.p.a.
que la realiza, salvo movimientos rígidos directos.

******* TODO Demostración
******* Demostración explícita de existencia
Tomamos $\theta$ una primitiva de $k$ y

\[
\alpha = \left( \int_{s_0}^s \cos \theta(t)\,dt , \int_{s_0}^s \sin \theta(t)\,dt \right).
\]

Tenemos que $\alpha$ es claramente diferenciable y p.p.a. y su
curvatura es

\[
k_{\alpha}(s) = 
\pair{ T_{\alpha}'(s) , N_{\alpha}(s) } =
k(s)(\sin^2 \theta(s) + \cos^2 \theta(s)) =
k(s).
\]

*** Tema 2. Superficies ([[~/pdf/Rosales_Superficies.pdf][PDF]])
**** 2.1. Definición de superficie y ejemplos
***** 2.1.0. Definición de superficie
****** 1.1. Superficie
:PROPERTIES:
:ID:       061e98dc-b077-4e5d-a7fd-f114f6908ed5
:END:
Un $\varnothing \neq S \subseteq \mathbb{R}^3$ es *superficie* si para cada $p \in S$ tiene un entorno
abierto $V \subseteq S$ (*entorno coordenado*) y una *parametrización* desde
$X \colon U \to S$ para un abierto $U \subset \mathbb{R}^2$ tal que

 1. $X \colon U \to \mathbb{R}^3$ es diferenciable,
 2. $(dX)_q\colon \mathbb{R}^2 \to \mathbb{R}^3$ es inyectiva para cada $q \in U$,
 3. $X(U) = V$ con $X \colon U \to X(U)$ homeomorfismo.

******* Card: superficie                                                                                  :drill:
SCHEDULED: <2018-06-17 Sun>
:PROPERTIES:
:ID:       ca91733a-9d55-4b63-997a-79aad4762897
:DRILL_LAST_INTERVAL: 22.2251
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.667
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-05-26 Sat 22:23]
:END:
Definición de superficie $S$.

******** Definición
Cada $p \in S$ tiene entorno abierto $V_p \subseteq S$ con una parametrización
$X \colon U \to S$ desde $U \subset \mathbb{R}^2$.

******* Card: parametrización                                                                             :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       1b03debc-6865-4b76-af7a-ac8de199ff7a
:DRILL_LAST_INTERVAL: 13.7426
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 5
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.8
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-08 Fri 14:36]
:END:
Qué significa $X \colon U \to S$ parametrización.

******** Respuesta
Embebimineto diferenciable con diferencial inyectiva.

 1. $X \colon U \to \mathbb{R}^3$ es *diferenciable*,

 2. $(dX)_q\colon \mathbb{R}^2 \to \mathbb{R}^3$ es inyectiva para cada $q \in U$, *diferencial inyectiva*,

 3. $X(U) = V$ con $X \colon U \to V$ *embebimiento*.

****** 1.2. Notas sobre la definición de superficie
:PROPERTIES:
:ID:       39a8bc2e-b4b9-4131-9fe4-7c1ed8fa3d87
:END:

 1. Consideramos la topología inducida de $\mathbb{R}^3$, las superficies son
    Hausdorff IIAN localmente euclídeos.

 2. La diferenciabilidad $X \in {\cal C}^{\infty}(U)$ nos da
    $X(u,v) = (x(u,v),y(u,v),z(u,v))$ con derivadas parciales
    como componentes.

 3. Equivalen
   
    1. $(dX)_q$ inyectiva,

    2. $\left\{ X_u(q), X_v(q) \right\}$ linealmente independientes,

    3. $\abs{X_u(q) \times X_v(q)}^2 > 0$,

    4. $\mathrm{rango}(\mathrm{Jac}\ X(q)) = 2$.

 4. Llamamos *atlas* a $X_i$ parametrizaciones locales recubriendo $S$.

******* Card: comprobar inyectividad de la diferencial                                                    :drill:
SCHEDULED: <2018-07-11 Wed>
:PROPERTIES:
:ID:       136c1adf-f85e-45ac-bc4a-19150882eabc
:DRILL_LAST_INTERVAL: 36.7265
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.667
:DRILL_EASE: 2.7
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-04 Mon 14:55]
:END:
Dos formas de comprobar $dX_{q}$ inyectiva para $X \colon U \to \mathbb{R}^3$.

******** Formas
Equivalen
   
    1. $(dX)_q$ inyectiva,

    2. $\left\{ X_u(q), X_v(q) \right\}$ linealmente independientes,

    3. $\abs{X_u(q) \times X_v(q)}^2 > 0$,

    4. $\mathrm{rango}(\mathrm{Jac}\ X(q)) = 2$.

****** 1.3. Abiertos de superficie, componentes conexas
:PROPERTIES:
:ID:       798b32ea-aeca-4f78-9265-53ce523e0630
:END:
Un abierto no vacío de una superficie es superficie.  En particular,
las componentes conexas de una superficie son superficies.

******* Proof
Para cada punto, tomamos $p \in V$, y restringimos la parametrización
que nos dé a $X^{-1}(V \cap S')$, que es abierto.

******* Card: componentes conexas                                                                         :drill:
SCHEDULED: <2018-06-25 Mon>
:PROPERTIES:
:ID:       a29b9077-f8cf-4178-9979-c709f6c1ff8f
:DRILL_LAST_INTERVAL: 29.9261
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.75
:DRILL_EASE: 2.56
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-05-26 Sat 22:26]
:END:
¿Por qué las componentes conexas de una superficie son
superficies?

******** Respuesta
Porque son abiertos de la superficie. Todo abierto de
una superficie es superficie.

****** 1.3. Superficie bajo difeomorfismos
:PROPERTIES:
:ID:       2e12aed9-1de2-4dcf-a729-8068eae76532
:END:
Para $S \subset O$ superficie, $\phi \colon O \to O'$ difeomorfismo entre abiertos,
$\phi(S)$ es superficie.

******* Proof
Tomaremos $\phi \circ X$ eligiendo en los entornos abiertos adecuados y
comprobaremos diferenciabilidad y homeomorfismo con regla de la
cadena.

****** Ej.3. Superficie ssi cada punto tiene entorno superficie
:PROPERTIES:
:ID:       b0e77770-60d2-4de6-9cd9-10f4d1f35cf1
:END:
Si $S = \bigcup_{i \in I} S_i$ unión de abiertos de $S$; $S$ es superficie ssi
$S_i$ es siempre superficie.

******* Proof
Un abierto de superficie es abierto, y las parametrizaciones son
locales.

****** Ej.4. Construcción desde parametrizaciones globales
:PROPERTIES:
:ID:       11ae111c-e696-4a21-9f13-c7345aa83461
:END:
Sea $X \in {\cal C}^{\infty}(U,\mathbb{R}^3)$ no vacío con $(dX)_q$ inyectiva y $U \cong X(U)$.
Entonces $X(U)$ superficie con esa parametrización global.

******* Proof
Cada punto tendría como entorno a $S$, con $X$ diferenciable
con diferencial inyectiva y homeomorfismo. Sería parametrización
global directamente.

***** 2.1.1. Grafos diferenciables
****** 1.4. Grafos
:PROPERTIES:
:ID:       1f5dceca-fdfe-4278-b8f4-7d4ccec964f3
:END:
El *grafo* de $\varphi \in {\cal C}^{\infty}(U)$ abierto de $\mathbb{R}^2$ es superficie,

\[
G^z(\varphi) = \left\{ x,y,z \mid (x,y) \in U, z = \varphi(x,y) \right\}.
\]

Análogamente sobre los grafos $G^x(\varphi)$ y $G^y(\varphi)$.

******* 1.5. Consecuencias
Los planos son grafos, el paraboloide elíptico, el
paraboloide hiperbólico y el cilindro parabólico son
grafos. Se sigue que todos son superficies.

******* Proof
Construimos una [[id:11ae111c-e696-4a21-9f13-c7345aa83461][parametrización global]].
Tenemos $X(u,v) = (u,v,\varphi(u,v))$ diferenciable con
inversa $\pi(u,v,w) = (u,v)$ que la hace homeomorfismo
y con $X_u(u,v) = (1,0,\varphi_u(u,v))$, $X_v(u,v) = (0,1,\varphi_v(u,v))$
independientes.

******* Card: paraboloide hiperbólico                                                                     :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       702ca00b-5bde-424b-96c8-ac7f5a8687d5
:DRILL_LAST_INTERVAL: 27.0485
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.333
:DRILL_EASE: 2.56
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-05-26 Sat 22:26]
:END:
¿Por qué es el *paraboloide hiperbólico* una superficie?

$\left\{ x,y,z \mid z = x^2-y^2 \right\}$

******** Respuesta
Es un grafo sobre $\mathbb{R}^2$.

******* Card: por qué grafo es superficie                                                                 :drill:
SCHEDULED: <2018-07-19 Thu>
:PROPERTIES:
:ID:       3dbc7c1c-592b-45cd-b0dd-52b4f4395ffe
:DRILL_LAST_INTERVAL: 38.9819
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.5
:DRILL_EASE: 2.66
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-10 Sun 13:58]
:END:
¿Por qué un grafo con $\varphi \in {\cal C}^{\infty}(U)$ es una superficie?

\[
G^z(\varphi) = \left\{ x,y,z \mid (x,y) \in U, z = \varphi(x,y) \right\}.
\]

******** Respuesta
Hay una parametrización global.

$X(u,v) = (u,v,\varphi(u,v))$ diferenciable con
inversa $\pi(u,v,w) = (u,v)$ luego embebimiento.
Tiene $X_u(u,v) = (1,0,\varphi_u(u,v))$, $X_v(u,v) = (0,1,\varphi_v(u,v))$
independientes que dan diferencial inyectiva.

***** 2.1.2. Superficies en forma implícita
****** 1.7. Teorema de la función implícita
:PROPERTIES:
:ID:       d513ba34-c5ce-4662-8e88-f6ab6779a7c2
:END:
Si $f \in {\cal C}^{\infty}(O \subseteq \mathbb{R}^3, \mathbb{R})$ en abierto con $f(x_0,y_0,z_0) = a$ y $f_z(x_0,y_0,z_0) \neq 0$;
existen $(x_0,y_0) \in U \subseteq \mathbb{R}^2$ entorno abierto, $z_0 \in I \subseteq \mathbb{R}$ intervalo abierto
y $\varphi \in {\cal C}^{\infty}(U)$ con $\varphi(U) \subseteq I$, tales que

 1. $U \times I \subseteq O$,

 2. $\varphi(x_0,y_0) = z_0$,

 3. $f^{-1}(a) \cap U \times I = G^z(\varphi)$.

******* Proof                                                                                             :extra:
# Se asume.

******* Card: implícita                                                                                   :drill:
SCHEDULED: <2018-07-11 Wed>
:PROPERTIES:
:ID:       b95d941e-d94a-403d-bc35-cf7a8b1e0fbd
:DRILL_LAST_INTERVAL: 37.1359
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.46
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-04 Mon 14:49]
:END:
Consecuencia práctica del teorema de la función implícita
sobre $\nabla f$.

******** Respuesta
Si $\nabla f(p) \neq 0$, la ecuación $\left\{ f(x,y,z) = f(p) \right\}$ es *localmente*
un grafo diferenciable sobre un plano coordenado.

****** 1.8. Valores singulares y valores regulares
Sea $O \subseteq \mathbb{R}^3$ abierto y $f \in {\cal C}^{\infty}(O)$. Un $a \in \mathbb{R}$ es *valor singular* si
es la imagen de un punto crítico, $f(p) = a$ con $(\nabla f)(p) = 0$. En otro
caso, es un *valor regular*. $VS(f)$ es el conjunto de valores
singulares y $VR(f)$ el conjuto de valores regulares.

******* Card: singular                                                                                    :drill:
SCHEDULED: <2018-06-21 Thu>
:PROPERTIES:
:ID:       c52b65a4-ad12-41e4-83a7-779f0f73f8c3
:DRILL_LAST_INTERVAL: 26.1369
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.667
:DRILL_EASE: 2.7
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-05-26 Sat 22:24]
:END:
Valor singular de $f \in {\cal C}^{\infty}(O,\mathbb{R})$.

******** Definición
$a$ es valor singular si es imagen de punto crítico, $f(p) = a$
con $\nabla f(p) = 0$.

******* Card: regular                                                                                     :drill:
SCHEDULED: <2018-06-20 Wed>
:PROPERTIES:
:ID:       58a580dd-5aa1-491c-9a7a-e9f04172e3a0
:DRILL_LAST_INTERVAL: 24.8425
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.46
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-05-26 Sat 22:24]
:END:
Valor regular de $f \in {\cal C}^{\infty}(O,\mathbb{R})$.

******** Definición
$a$ es valor regular si no es singular, es decir, si no es
imagen de un punto crítico. Para cada $\nabla f(p) = 0$ se tiene
que $f(p) \neq a$.

****** 1.9. Teorema de Sard                                                                                :extra:
$VS(f)$ tiene medida nula. $VR(f)$ es denso en $\mathbb{R}$.

******* Card                                                                                              :drill:
SCHEDULED: <2018-08-10 Fri>
:PROPERTIES:
:ID:       034c652e-0f0d-4c3f-8c7b-d358ec404110
:DRILL_LAST_INTERVAL: 43.1634
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.5
:DRILL_EASE: 2.18
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-28 Thu 22:13]
:END:
Enuncia el Teorema de Sard.

******** Enunciado
El conjunto de los valores singulares $VS(f)$ tiene medida
nula. $VR(f)$ es denso en $\mathbb{R}$.

Un $a \in \mathbb{R}$ es *valor singular* si es la imagen de un punto
crítico, $f(p) = a$ con $(\nabla f)(p) = 0$. En otro caso, es un
*valor regular*.

****** 1.10. Superficies implícitas
$f \in {\cal C}^{\infty}(O \subset \mathbb{R}^3)$ en abierto. Si $a \in VR(f)$, entonces $f^{-1}(a)$
es vacío o una superficie de $\mathbb{R}^3$.

Además, admite un atlas formado por parametrizaciones locales
de grafos.

******* 1.11. Recíproco falso: inversa de singular puede ser superficie
$f(x,y,z) = z^2$ tiene $0 \in VS(f)$ pero $f^{-1}(0)$ es un plano.

******* Proof
Si $p \in S \neq \varnothing$, como $\nabla f(p) \neq 0$ tomamos $f_z(p) \neq 0$ s.p.g. y por
[[id:d513ba34-c5ce-4662-8e88-f6ab6779a7c2][Teorema de Función Implícita]] tenemos $p \in f^{-1}(a) \cap U \times I = G^z(\varphi)$,
que es grafo [[id:1f5dceca-fdfe-4278-b8f4-7d4ccec964f3][luego superficie]] y como [[id:b0e77770-60d2-4de6-9cd9-10f4d1f35cf1][cada punto tiene entorno
superficie]], es una superficie.

****** 1.12. Ejemplos
Las esferas son superficies implícitas y pueden tener atlas con
proyecciones estereográficas o con seis proyecciones. Los cilindros
son superficies con un atlas de cuatro proyecciones.

***** 2.1.3. Superficies de revolución
****** 1.13. Subconjunto de revolución
$A \subset \mathbb{R}^3$ es de *revolución* si $\mathrm{rot}_{\theta}(A) = A$ para $\theta \in \mathbb{R}$.
Equivalentemente, $\mathrm{rot}_{\theta}(A) \subseteq A$.

******* Card                                                                                              :drill:
SCHEDULED: <2018-06-19 Tue>
:PROPERTIES:
:ID:       40312210-08af-43e1-8a80-7f3db9927644
:DRILL_LAST_INTERVAL: 24.4752
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.333
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-05-26 Sat 22:21]
:END:
Conjunto de revolución $A \subset \mathbb{R}^3$.

******** Definición
$A \subset \mathbb{R}^3$ es de *revolución* si $\mathrm{rot}_{\theta}(A) = A$ para $\theta \in \mathbb{R}$.
Equivalentemente, $\mathrm{rot}_{\theta}(A) \subseteq A$.

******* Proof
Usamos $\mathrm{rot}_{-\theta}(A) \subset A$.

****** 1.13. Superficie de revolución
Sea $\alpha \colon I \to \mathbb{R}^3$ regular y embebida en $\alpha(I) \subseteq P^+$, el semiplano
abierto $x > 0$ de $y = 0$. Definimos

\[
S_{\alpha} =
\left\{ \phi_{\theta}(\alpha(t))
\mid t \in I, \theta \in \mathbb{R}
\right\},
\]

y $X \colon I \times \mathbb{R} \to \mathbb{R}^3$ dada por

\[
X(t,\theta) = \varphi_{\theta}(\alpha(t)) = (x(t)\cos(\theta), x(t)\sin(\theta), z(t)),
\]

para $\alpha(t) = (x(t),0,z(t))$.

Aquí $S_{\alpha}$ es *superficie de revolución generada* respecto del eje Z.
Para $U_1 = I \times (0,2\pi)$ y $U_2 = I \times (-\pi,\pi)$ tenemos
un atlas dado por $X_{|U_1}$ y $X_{|U_2}$.

******* Proof: es de revolución
Si $p \in S_{\alpha}$, entonces $p = \phi_{\theta}(\alpha(t))$, luego $\phi_{\theta}(\phi_{\theta'}(\alpha(t))) = \phi_{\theta + \theta'}(\alpha(t)) \in S_{\alpha}$.

******* Proof: atlas
Tenemos $X(t,\theta) = (x(t)\sin(\theta), x(t)\cos(\theta), z(t)) \in {\cal C}^{\infty}$, sabemos que tiene
diferencial inyectiva porque

\[\abs{X_t(t,\theta) \times X_{\theta}(t,\theta)} =
\abs{x(t)}\abs{\alpha'(t)}.
\]

La inyectividad se tiene porque $X(t_1,\theta_1) = X(t_2,\theta_2)$ daría $x(t_1)^2 = x(t_2)^{2}$
(siendo $x$ positivo) y $z(t_1) = z(t_2)$; tendremos $\theta_1,\theta_2$ con mismo seno y coseno,
así que será inyectiva en intervalos de longitud $2\pi$.

Finalmente queda comprobar $X^{-1}_1,X^{-1}_2$ continuas, que se puede hacer
calculándolas explícitamente con la arcotangente o usando cálculo
[[id:cfc42651-eabd-4024-8fe6-6ce2b4284e3c][diferencial de superficies]].

****** 1.14. Paralelos y meridianos
En una superficie de revolución generada, un *paralelo* es la curva $X(t_0,\theta)$,
un *meridiano* es la curva $X(t,\theta_0)$.

****** TODO 1.15. Revolución sobre grafos de funciones

**** 2.2. Cambio de parámetros
***** 2.2.1. Lema técnico para el cambio de parámetros
:PROPERTIES:
:ID:       e55cb9c9-d19d-4a7a-8c3b-910e4f0ca5bf
:END:
$S$ superficie, $X \colon U \to S$ parametrización local y $q \in U$. Existen
$q \in U_q \subset U$, $X(q) \in V_q \subset S$ entornos abiertos, $\pi \colon \mathbb{R}^3 \to \mathbb{R}^2$ proyección
coordenada, $(\pi \circ X)(q) \in D_q \subset \mathbb{R}^2$ entorno abierto y $\varphi \in {\cal C}^{\infty}(D_q)$ tales
que

 1. $\pi \circ X \colon U_q \to D_q$ difeomorfismo

 2. $\pi \colon V_q \to D_q$ biyectiva con $V_q = G(\varphi)$ grafo.

\[\begin{tikzcd}
& V_q\dar{\pi} \\
U_q \urar{X} & D_q \uar[bend right=90,swap]{\mathrm{id} \times \varphi}
\end{tikzcd}\]

****** Proof
******* Primer punto
Por $X = (x,y,z)$ [[id:061e98dc-b077-4e5d-a7fd-f114f6908ed5][parametrización]], $dX_{(u,v)}$ tiene rango 2 y un menor

\[\begin{vmatrix}
x_u(q) & x_v(q) \\
y_u(q) & y_v(q)
\end{vmatrix} \neq 0\]

Ahora, la Jacobiana de $\pi \circ X$ es esta, y $d(\pi \circ X)$ es isomorfismo.
Por [[id:16bd6b42-7b91-4fcf-8979-faabc0acd594][Teorema de la función inversa]], es difeomorfismo local, luego
tenemos entornos donde $(\pi \circ X)_{|U_q}\colon U_q \to D_q$ es un difeomorfismo.

******* Segundo punto
$V_q = X(U_q)$ es abierto de $S$ porque $U_q \subset U$ es abierto, $X \colon U \to X(U)$
es homeomorfismo y $X(U)$ es un [[id:061e98dc-b077-4e5d-a7fd-f114f6908ed5][entorno coordenado]] y por tanto abierto.
Llamamos $Y = X \circ (\pi \circ X)^{-1} = (\alpha,\beta,\varphi)$, diferenciables por $Y \in {\cal C}^{\infty}(D_q)$ por
regla de la cadena clásica. Como $\pi \circ Y = \id$, debe tenerse $Y_{|D_q}(u,v) = (u,v,\varphi(u,v))$,
luego $V_q = G^z(\varphi)$.

******* Tercer punto
$\pi(V_q) = (\pi \circ X)(U_{q}) = D_q$ y es biyectiva porque tiene como
inversa a la $Y$.

****** Card                                                                                                :drill:
SCHEDULED: <2018-06-17 Sun>
:PROPERTIES:
:ID:       ab744492-3f4c-464e-bb8d-1801809037c2
:DRILL_LAST_INTERVAL: 22.2662
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.333
:DRILL_EASE: 2.22
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-05-26 Sat 22:34]
:END:
Describe el diagrama de la demostración del lema técnico para el
cambio de parámetros.

******* Respuesta
Para $q \in U$ tenemos la construcción $q \in U_q \subset U$ siguiente

\[\begin{tikzcd}
& V_q\dar{\pi} \\
U_q \urar{X} & D_q \uar[bend right=90,swap]{\mathrm{id} \times \varphi}
\end{tikzcd}\]

***** 2.2.2. Corolario: una superficie es localmente un grafo
:PROPERTIES:
:ID:       e4c73e71-b439-499e-b722-d67eee8ac318
:END:
Para $p \in S$ superficie, existe un $p \in V \subset S$ entorno que es
el grafo de una función diferenciable. Esto puede usarse para
probar que ciertos conjuntos no son superficies.

****** Proof
Para $p \in S$, aplicamos el lema técnico al $q = X^{-1}(p)$ y tenemos
$X(U_q)$ grafo.

****** Ejemplo de uso: el cono no es superficie
El semicono circular no es una superficie porque no es localmente
el grafo de una función diferenciable en el punto $(0,0,0)$.

***** 2.2.4. Cambio de parámetros
:PROPERTIES:
:ID:       3b537594-9c48-4d88-b979-cb841d93f776
:END:
Sean $X \colon U \to S$ e $Y \colon U' \to S$ parametrizaciones locales
con $W = X(U) \cap Y(U') \neq \varnothing$. Entonces el *cambio de parámetros*
$h = X^{-1} \circ Y \colon Y^{-1}(W) \to X^{-1}(W)$ es un difeomorfismo.

****** Proof
Sea $q' \in Y^{-1}(W)$ y $q = h(q')$. Por el [[id:e55cb9c9-d19d-4a7a-8c3b-910e4f0ca5bf][lema de cambio de parámetros]]
tenemos $q \in U_q \subset X^{-1}(W)$, $X(q) \in V_q \subset W$ entornos y una proyección
$\pi \colon V_q \to D_q$ biyectiva con $\pi \circ X \colon U_q \to D$ difeomorfismo.

Ahora, en $B' = Y^{-1}(V_q)$ tenemos

\[
h_{|B'} = (X^{-1} \circ Y)_{|B'} = (\pi \circ X)^{-1} \circ \pi \circ Y
\]

composición de difeomorfismos. Como cada $q'$ tiene un entorno
$B'$ donde $h$ es diferenciable y la diferenciabilidad es local,
tenemos $h$ diferenciable. Sabemos $h$ homeomorfismo por [[id:061e98dc-b077-4e5d-a7fd-f114f6908ed5][definición]]
de parametrización y un argumento similar nos da $h^{-1}$ diferenciable,
luego $h$ es difeomorfismo por definición.

\[\begin{tikzcd}
& V_q \subset W \dar{\pi} & \\
U_q \urar{X} & D_q & B' \ular[swap]{Y}
\end{tikzcd}\]

**** 2.3. El plano tangente
***** 2.3.1. Plano invariante a cambios de parámetros
Sean $X\colon U \to S$, $Y \colon U' \to S$ parametrizaciones con $p \in X(U) \cap Y(U')$.
Si $q = X^{-1}(p)$ y $q' = Y^{-1}(p)$, entonces

\[
(dX)_q(\mathbb{R}^2) = (dY)_{q'}(\mathbb{R}^2).
\]

****** Proof
Sea $W = XU \cap YU'$, por [[id:3b537594-9c48-4d88-b979-cb841d93f776][cambio de parámetros]], $h = X^{-1} \circ Y \colon Y^{-1}(W) \to X^{-1}(W)$
es difeomorfismo, $Y_{|Y^{-1}(W)} = X \circ h$ , y por regla de la cadena clásica,

\[
(dY)_{q'}(\mathbb{R}^2) = ((dX)_{q} \circ (dh)_{q'}) (\mathbb{R}^2) = (dX)_q (\mathbb{R}^2)
\]

porque $(dh)_{q'}$ es [[id:6a2928b0-e787-4240-b76c-1856d14421bb][isomorfismo por]] ser $h$ difeomorfismo.

***** 2.3.2. Espacio tangente
$v \in \mathbb{R}^n$ es *vector tangente* a $A$ en $p \in A \subset \mathbb{R}^n$ si existe $\alpha \colon (-\varepsilon,\varepsilon) \to A$
con $\alpha(0) = p$ y $\alpha'(0) = v$. El *espacio tangente* $T_pA$ es el conjunto de los
vectores tangentes a $A$ en $p$.

****** Card                                                                                                :drill:
SCHEDULED: <2018-09-17 Mon>
:PROPERTIES:
:ID:       f157e9c9-1f94-45c9-bc9a-fa82e35cf8c7
:DRILL_LAST_INTERVAL: 80.6142
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.46
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-28 Thu 22:14]
:END:
Definición de *espacio tangente* $T_p(A)$.

******* Definición
El *espacio tangente* $T_pA$ es el conjunto de los $v \in \mathbb{R}^n$ tales que
existe $\alpha \colon (-\varepsilon,\varepsilon) \to A$ con $\alpha(0) = p$ y $\alpha'(0) = v$.

***** 2.3.3. Propiedades del espacio tangente

1. $0 \in T_pA$.

2. Monotonía, $A \subset B \implies T_pA \subset T_pB$.

3. $O\subset \mathbb{R}^n$ abierto implica $T_pO = \mathbb{R}^n$.

4. En general, $T_pA$ no es espacio vectorial. (Contraejemplo en la unión 
   de dos rectas.

****** Card: contraejemplo de espacio tangente no vectorial                                                :drill:
SCHEDULED: <2018-10-16 Tue>
:PROPERTIES:
:ID:       3eac5216-6c28-4763-8cd7-856bdd12a1c6
:DRILL_LAST_INTERVAL: 110.1017
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.75
:DRILL_EASE: 2.8
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-28 Thu 22:10]
:END:
Da un ejemplo donde $T_pA$ no es espacio vectorial.

******* Contraejemplo
La unión de dos rectas es su propio espacio tangente pero
no es espacio vectorial.

***** 2.3.4. El espacio tangente es un plano tangente
:PROPERTIES:
:ID:       477f9b05-a00e-4c40-84b6-9dd312b90b86
:END:
Para $X \colon U \to S$ parametrización con $X(q) = p$,

\[
(dX)_q(\mathbb{R}^2) = T_pS.
\]

En particular, $T_pS$ es plano vectorial con base $B_q = \left\{ X_u(q),X_v(q) \right\}$.

****** Proof
******* Primera inclusión
Si $v \in (dX)_q(u)$, como $T_pU = \mathbb{R}^2$, $u \in T_pU$ gracias a una curva $\alpha$.
Definimos $X \circ \alpha$ y comprobamos derivando que hace tangente a $v$.

******* Segunda inclusión
$V = X(U)$ es [[id:e4c73e71-b439-499e-b722-d67eee8ac318][locamente un grafo]] y hay un entorno $p \in V_p$ donde es grafo,
$\pi \colon V_p \to D_p$ proyección con inversa $Y \colon D_p \to V$. Si $v \in T_pS$ gracias a $\alpha$,
tenemos $\alpha(-\delta,\delta) \subset V_p$ para algún $\delta$ y llamamos $\beta_{|(-\delta,\delta)} = X^{-1}\circ \alpha$. Es
diferenciable por tenerse

\[
\beta = X^{-1} \circ \alpha = (X^{-1} \circ Y) \circ (\pi \circ \alpha)
\]

diferenciable por ser composición de [[id:3b537594-9c48-4d88-b979-cb841d93f776][cambio de parámetros]] y funciones
diferenciables. Finalmente comprobamos que 

\[
v = \alpha'(0) = (X \circ \beta)'(0) = (dX)_q(\beta'(0)).
\]

******** Esquema
Para comprobar $\beta$ diferenciable,

\[\begin{tikzcd}
& \mathbb{R}\dar{\alpha}\ar[bend right,swap]{ddl}{\beta}\\
& V_p\dar[bend left]{\pi}\dlar[swap]{X^{-1}} \\
U & D_p\lar{h}\uar[bend left]{Y}
\end{tikzcd}\]

****** Card: espacio tangente cuando es parametrización                                                    :drill:
SCHEDULED: <2018-09-18 Tue>
:PROPERTIES:
:ID:       bcd93e24-5a7c-46bc-a8d6-39719007e6b1
:DRILL_LAST_INTERVAL: 83.1766
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 5
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.7
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-27 Wed 13:23]
:END:
Dada $X \colon U \to S$ parametrización, da el espacio tangente
a $X(q) = p$.

******* Espacio tangente

\[
T_pS = (dX)_q(\mathbb{R}^2)
\]

****** Card: base del plano tangente                                                                :drill:curvas:
SCHEDULED: <2018-09-17 Mon>
:PROPERTIES:
:ID:       426e5b5a-7e3f-453e-b172-2526547e6ca4
:DRILL_LAST_INTERVAL: 82.0468
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.5
:DRILL_EASE: 2.7
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-27 Wed 13:24]
:END:
¿Cuál es la base del plano $T_pS$ en función de una
parametrización $X$?

******* Base
$B_q = \left\{ X_u(q),X_v(q) \right\}$, donde $X(q) = p$.

***** 2.3.6. Plano afín tangente y recta afín normal
El *plano afín tangente* de $S$ en $p$ es $p + T_pS$. La *recta afín normal*
de $S$ en $p$ es $p + (T_pS)^{\bot}$.

***** 2.3.7. Propiedades del plano tangente

 1. $dX_q \colon \mathbb{R}^2 \to T_pS$ es un isomorfismo lineal.

 2. El plano afín es el que mejor aproxima a $S$ cerca de $p$,

    \[
    \lim_{h \to 0} \frac{\abs{X(q+h) - X(q) - dX_q(h)}}{\abs{h}} = 0.
    \]

***** 2.3.8. El plano tangente es local
Si $S' \subseteq S$ entonces $T_pS' \subseteq T_pS$.

****** Proof
Por definición $T_pS' \subseteq T_pS$, siendo ambos planos se tiene igualdad.

***** 2.3.9. Planos bajo difeomorfismos
$\phi \colon O \to O'$ difeomorfismo y $S \subseteq O$ superficie,

\[
T_{\phi(p)}\phi(S) = (d\phi)_p(T_pS)
\]

****** Card                                                                                                :drill:
SCHEDULED: <2018-07-09 Mon>
:PROPERTIES:
:ID:       11cf5e7c-ff50-4c64-b6a0-a9b455bb3024
:DRILL_LAST_INTERVAL: 29.465
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.46
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-10 Sun 13:57]
:END:
Sea $\phi \colon O \to O'$ difeomorfismo, calcula en función de la 
diferencial

\[
T_{\phi(p)}\phi(S)
\]

******* Respuesta

\[
T_{\phi(p)}\phi(S) = (d\phi)_p(T_pS)
\]

****** Proof                                                                                               :extra:
Tenemos para $p$ con parametrización $X$, que $\phi \circ X$ es
[[id:2e12aed9-1de2-4dcf-a729-8068eae76532][parametrización de]] $\phi(S)$, luego

\[
d\phi_p(T_pS) = d(\phi \circ X)_q(\mathbb{R}^2) = T_{\phi(p)}\phi(S).
\]

****** TODO Proof: apuntes
***** 2.3.10 Ejemplo: plano tangente de un grafo
Para $S = G^z(\varphi)$ tenemos el plano

\[
p + T_pS = \left\{ 
(x,y,z) \mid 
z = \varphi(q) + \varphi_x(q)(x-x_0) + \varphi_y(q)(y-y_0) 
\right\}.
\]

****** Proof
Se comprueba usando $(dX)_q(\mathbb{R}^2) = T_pS$.

****** Card                                                                                                :drill:
SCHEDULED: <2018-06-20 Wed>
:PROPERTIES:
:ID:       f3e06ea3-900a-4b48-9714-b58d50465f0f
:DRILL_LAST_INTERVAL: 25.4211
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.333
:DRILL_EASE: 2.22
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-05-26 Sat 22:30]
:END:
Ecuación del plano tangente a una superficie grafo $S = G^z(\varphi)$
en $p$ con $X^{-1}(p) = q = (x_0,y_0)$.

******* Plano

\[
p + T_pS = \left\{ 
(x,y,z) \mid 
z = \varphi(q) + \varphi_x(q)(x-x_0) + \varphi_y(q)(y-y_0) 
\right\}.
\]

***** 2.3.11. Ejemplo: plano tangente de una superficie implícita
Sea $S = f^{-1}(a) \neq \varnothing$ con $a \in \mathrm{VR}(f)$, $f \in {\cal C}^{\infty}(O)$. Entonces

\[
T_pS = (\nabla f(p))^{\bot}
\]

****** Proof
Si $v \in T_pS$ gracias a $\alpha$, $f(\alpha(t)) = a$ constante y

\[
\pair{\nabla f(a), v} = (f \circ \alpha)'(0) = 0.
\]

Luego $v \in (\nabla f)(p)^{\bot}$ y tenemos dos planos uno contenido en otro.

****** Card                                                                                                :drill:
SCHEDULED: <2018-07-10 Tue>
:PROPERTIES:
:ID:       db778307-cfe6-45e9-ae36-2becb553fe9a
:DRILL_LAST_INTERVAL: 11.6809
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 6
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.5
:DRILL_EASE: 2.32
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-28 Thu 22:11]
:END:
Si $S = f^{-1}(a) \neq \varnothing$ es superficie implícita dada por un valor
regular, ¿cuál es el plano $T_p(S)$?

******* Plano

\[
T_p(S) = (\nabla f(p))^{\bot}
\]

***** Ej.10. Corte al eje normal
Todas las rectas afines normales de una superficie de revolución
creada por una curva $\alpha(t) = (x(t),0,z(t))$ con $z'(t) \neq 0$ cortan al
eje $Z$. 

****** Proof
Calculamos $p + (T_pS)^{\bot}$ usando las parametrizaciones usuales de
una superficie de revolución y comprobamos que en el caso dado
se tiene la intersección.

***** 2.3.14. Primera forma fundamental
La restricción a $T_pS$ de $\pair{-,-}$ se llama *primera forma fundamental*.
Es una métrica definida positiva.

**** 2.4. Superficies y cálculo diferencial
***** 2.4.1. Aplicaciones diferenciables
****** 2.4.1. Aplicaciones diferenciables
:PROPERTIES:
:ID:       230b03e1-ea5a-487e-9b27-f497edd8b400
:END:
Dados $S,S'$ superficies, $O \subset \mathbb{R}^n, O' \subset \mathbb{R}^m$ abiertos. Definimos
*diferenciabilidad* en los siguientes casos

 * $f \in {\cal C}^{\infty}(S,\mathbb{R}^m)$ si $f \circ X \in {\cal C}^{\infty}(U,\mathbb{R}^m)$ para cualquier parametrización.

 * $f \in {\cal C}^{\infty}(S,O')$ si $i \circ f \in {\cal C}^{\infty}(S, \mathbb{R}^m)$, donde $i$ es la inclusión.

 * $f \in {\cal C}^{\infty}(S,S')$ si $i \circ f \in {\cal C}^{\infty}(S,\mathbb{R}^3)$, donde $i$ es la inclusión.

 * $f \in {\cal C}^{\infty}(O,S')$ si $i \circ f \in {\cal C}^{\infty}(O,\mathbb{R}^3)$, donde $i$ es la inclusión.

******* Card                                                                                              :drill:
SCHEDULED: <2018-07-17 Tue>
:PROPERTIES:
:ID:       d5eeb9fd-2b74-47d4-8a94-11d8d4216455
:DRILL_LAST_INTERVAL: 42.9311
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 5
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.4
:DRILL_EASE: 2.46
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-04 Mon 14:54]
:END:
Definir diferenciabilidad en los cuatro casos

 * $f \in {\cal C}^{\infty}(S,\mathbb{R}^m)$ 

 * $f \in {\cal C}^{\infty}(S,O')$ 

 * $f \in {\cal C}^{\infty}(S,S')$ 

 * $f \in {\cal C}^{\infty}(O,S')$ 

******** Definición

 * $f \in {\cal C}^{\infty}(S,\mathbb{R}^m)$ si $f \circ X \in {\cal C}^{\infty}(U,\mathbb{R}^m)$ para cualquier parametrización.

 * $f \in {\cal C}^{\infty}(S,O')$ si $i \circ f \in {\cal C}^{\infty}(S, \mathbb{R}^m)$, donde $i$ es la inclusión.

 * $f \in {\cal C}^{\infty}(S,S')$ si $i \circ f \in {\cal C}^{\infty}(S,\mathbb{R}^3)$, donde $i$ es la inclusión.

 * $f \in {\cal C}^{\infty}(O,S')$ si $i \circ f \in {\cal C}^{\infty}(O,\mathbb{R}^3)$, donde $i$ es la inclusión.

****** 2.4.2. Diferenciabilidad de parametrizaciones
:PROPERTIES:
:ID:       38f14c25-5a11-44aa-971c-240238dbd2a7
:END:
Para $X\colon U \to S$ parametrización local, $X \in {\cal C}^{\infty}(U,XU)$ y $X^{-1} \in {\cal C}^{\infty}(XU,U)$.

******* Proof
$X \colon U \to V = XU$ es diferenciable por serlo $i \circ X$ por
definición de [[id:061e98dc-b077-4e5d-a7fd-f114f6908ed5][parametrización]].

$X^{-1}$ es diferenciable [[id:be30c69b-44e3-428c-a5a9-9f055fff8b24][si]] lo es $j \circ X^{-1} \colon V \to \mathbb{R}^2$, donde
$V$ es superficie [[id:798b32ea-aeca-4f78-9265-53ce523e0630][por ser abierto]] no vacío de $S$. Esta lo
[[id:230b03e1-ea5a-487e-9b27-f497edd8b400][es]] si cada parametrización $Y \colon U' \to V$ hace $(j \circ X^{-1}) \circ Y$
diferenciable, pero $j \circ (X^{-1} \circ Y)$ es una composición de
inclusión y de [[id:3b537594-9c48-4d88-b979-cb841d93f776][cambio de parámetros]].

******* Cards                                                                                             :drill:
SCHEDULED: <2018-09-22 Sat>
:PROPERTIES:
:ID:       4cf91a32-d1d8-43a8-929c-873dbe42351f
:DRILL_LAST_INTERVAL: 84.7624
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 5
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.7
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-29 Fri 09:51]
:END:
Diferenciabilidad (no clásica) de las parametrizaciones locales y sus inversas.

******** Diferenciabilidad
Para $X$ parametrización local, $X \in {\cal C}^{\infty}(U,S)$ y $X^{-1} \in {\cal C}^{\infty}(XU,U)$.
Nótese que sabíamos por definición $X \in {\cal C}^{\infty}(U,\mathbb{R}^3)$.

Esta diferenciabilidad lo es en el sentido no clásico.

****** Ej. 11 y 12. Inclusión e identidad diferenciables
$i \colon S \to \mathbb{R}^3$ e identidad $\mathrm{Id}\colon S \to S$ son diferenciables. La inclusión
$i \colon S' \to S$ para una subsuperficie es diferenciable.

******* Proof
La inclusión es diferenciable por definición de [[id:061e98dc-b077-4e5d-a7fd-f114f6908ed5][parametrización]].
La identidad lo es por serlo la inclusión. Nótese que en el caso
de una subsuperficie, una parametrización de $S'$ es diferenciable
también después de la inclusión, que no es siquiera relevante.

****** 2.4.3. Caracterización de diferenciable por atlas
Equivalen

 * $f \in {\cal C}^{\infty}(S,\mathbb{R}^m)$,

 * existe un [[id:39a8bc2e-b4b9-4131-9fe4-7c1ed8fa3d87][atlas]] tal que $f \circ X_i \colon U_i \to \mathbb{R}^m$ es siempre diferenciable.

******* Proof
******** Primera implicación
Existe un atlas por [[id:061e98dc-b077-4e5d-a7fd-f114f6908ed5][definición de superficie]] y allí $f \circ X_i$ es
diferenciable por [[id:230b03e1-ea5a-487e-9b27-f497edd8b400][definición de diferenciabilidad]] de superficies.

******** Segunda implicación
Dada $Y \colon U' \to S$ parametrización con $q' \in U'$, en $Y(q') = p$ debe existir
una parametrización local del atlas $X \colon U \to S$, con $p \in U$ y $f \circ X$ diferenciable.
Tomamos $W = X(U) \cap Y(U')$ y tenemos

\[
(f \circ Y)_{|Y^{-1}(W)} = (f \circ X) \circ (X^{-1} \circ Y)
\]

diferenciable por regla de la cadena clásica por ser composición de
difernciable y [[id:3b537594-9c48-4d88-b979-cb841d93f776][cambio de parámetros]].

******* Card                                                                                              :drill:
SCHEDULED: <2018-09-25 Tue>
:PROPERTIES:
:ID:       688ed1e0-d2a2-4639-a681-1ce01f696780
:DRILL_LAST_INTERVAL: 88.961
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.75
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-28 Thu 22:12]
:END:
Da una caracterización de $f \in {\cal C}^{\infty}(S,\mathbb{R}^m)$ usando atlas.

******** Caracterización
Existe un atlas tal que $f \circ X_i \colon U_i \to \mathbb{R}^m$ es siempre
diferenciable.

****** 2.4.4. Propiedades de aplicaciones diferenciables
:PROPERTIES:
:ID:       c57ee25a-ece7-4c4a-92a5-253ff821001b
:END:

 1) Toda diferenciable es continua.

 2) $f+g$, $\varphi f$, $\lambda f$, $\pair{f,g}$, $\varphi/\psi$ son diferenciables con $\psi(p) \neq 0$.

 3) para $S \subset O$, se tiene $f \in {\cal C}^{\infty}(O,\mathbb{R}^m) \implies f_{|S} \in {\cal C}^{\infty}(S,\mathbb{R}^m)$

 4) para $S = \bigcup S_i$, se tiene $f \in {\cal C}^{\infty}(S_i,\mathbb{R}^m) \iff f \in {\cal C}^{\infty}(S,\mathbb{R}^m)$

 5) regla de la cadena $f \in {\cal C}^{\infty}(S,S'), g\in {\cal C}^{\infty}(S',S'') \implies f \circ g\in {\cal C}^{\infty}(S,S'')$.

******* Proof 1
Dado $p$ con parametrización $X \colon U \to V$, consideramos

\[
f_{|V} = (f \circ X) \circ X^{-1},
\]

composición de diferenciable (clásica) y homeomorfismo.
Así $f$ es continua en $p$ arbitrario.

******* Proof 2
Se usan las propiedades de diferenciabilidad. Por ejemplo,

\[
(f + g) \circ X = f \circ X + g \circ X
\]

es suma de diferenciables (en sentido clásico).

******* Proof 3
Tenemos $f_{|S} = f \circ (i \circ X)$ composición de diferenciables luego
diferenciable por regla de la cadena clásica.

******* TODO Proof 4
******* TODO Proof 5
En el caso $S'$ superficie y $S=O$, $S''=O''$ abiertos 
[...]

\[
(i \circ g\circ f)_{|B} = (i \circ g \circ I_{V'}\circ f)_{|B} = (i\circ g \circ Y) \circ (\pi \circ f)_{|B}
\]
***** 2.4.2. Diferencial de una aplicación diferenciable
****** 2.4.6. Diferencial de una aplicación diferenciable
:PROPERTIES:
:ID:       51f883ea-541f-41ae-bfba-ebb99bc64622
:END:
La diferencial de $f \colon S \to S'$ en $p \in S$ es la aplicación
$(df)_p \colon T_pS \to T_{f(p)}S'$ dada por

\[
(df)_p(v) := (f \circ \alpha)'(0)
\]

donde $\alpha \colon (-\varepsilon,\varepsilon) \to S$ es una curva $\alpha(0) = p$ y $\alpha'(0) = v$.
Esto da una aplicación lineal independiente de $\alpha$.

******* Proof: dominios
Tenemos $f \circ \alpha \colon (-\varepsilon,\varepsilon) \to S'$ curva con $f(\alpha(0)) = f(p)$, luego
$(f \circ \alpha)'(0) \in T_{f(p)}S'$. Nótese que una curva $\alpha$ así existe para
cualquier $v \in T_pS$ por definición.

******* Card                                                                                              :drill:
SCHEDULED: <2018-07-23 Mon>
:PROPERTIES:
:ID:       e8520435-9cb6-4b93-8d2f-bf62c5ae7a19
:DRILL_LAST_INTERVAL: 44.786
:DRILL_REPEATS_SINCE_FAIL: 5
:DRILL_TOTAL_REPEATS: 6
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.167
:DRILL_EASE: 2.32
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-08 Fri 14:49]
:END:
Define la diferencial de $f \colon S \to S'$ en $p \in S$.

******** Definición
La aplicación $(df)_p \colon T_pS \to T_{f(p)}S'$ dada por

\[
(df)_p(v) := (f \circ \alpha)'(0)
\]

donde $\alpha \colon (-\varepsilon,\varepsilon) \to S$ es una curva $\alpha(0) = p$ y $\alpha'(0) = v$.
Se puede demostrar que así está bien definida y no depende de $\alpha$.

****** 2.4.8. La diferencial está bien definida
La [[id:51f883ea-541f-41ae-bfba-ebb99bc64622][diferencial]] no depende de la curva escogida.

******* Proof
Tomamos $X \colon U \to S$, $Y \colon U' \to S'$ parametrizaciones tales que
$f(X(U)) \subseteq Y(U')$ con $X(q) = p$. Dada una curva $\alpha$ definimos a$\beta = X^{-1} \circ \alpha$
diferenciable por regla de la cadena con

\[
v = \alpha'(0) = (X \circ \beta)'(0) = dX_q(\beta'(0))
\]

siendo $dX_q$ isomorfismo, $\beta'(0) = dX_q^{-1}(v)$. Finalmente,

\[
(f \circ \alpha)'(0) = 
(Y \circ (Y^{-1} \circ f \circ X) \circ (X^{-1}\circ \alpha))'(0) =
(dY_{q'} \circ d(Y^{-1}\circ f\circ X)_q \circ dX_q) (v),
\]

donde tenemos tres diferenciales no dependientes de $\alpha$.

****** 2.4.9. Diferencial de constante es nula
Si $f \colon S \to S'$ es constante, $df_p\colon T_pS \to T_{f(p)}S$ es nula.

******* Proof
Trivial calculando.

****** 2.4.10. Diferencial de inclusión es inclusión
Si $i \colon S \to \mathbb{R}^3$ es la inclusión, $di_p \colon T_pS \to \mathbb{R}^3$ es la inclusión.

******* Proof
Trivial calculando.

****** 2.4.11. Diferencial de identidad es identidad
La diferencial de la identidad en $S$ es la identidad en $T_pS$.

****** 2.4.12. Diferencial de inclusión de superficies es identidad
Si $S' \subseteq S$ abierto, entonces la diferencial de $p \in S$ de la inclusión
es la identidad en $T_pS$.

****** 2.4.13. Propiedades de la diferencial
La diferencial cumple

 1. Para $f,g \in {\cal C}^{\infty}(S,\mathbb{R}^m)$, $\varphi \in {\cal C}^{\infty}(S)$,

    1. $d(f+g)_p(v) = df_p(v) + dg_p(v)$,

    2. $d(\varphi f)_p(v) = (d\varphi_p(v)) f(p) + \varphi(p) (df_p(v))$,

    3. $d\pair{f,g}_p(v) = \pair{(df)_p(v),g(p)} + \pair{f(p),(dg)_p(v)}$,

    4. $d(f \times g)_p(v) = df_p(v) \times g(p) + f(p) \times dg_p(v)$

 2. Para $p \in S \subset O$ con $f \in {\cal C}^{\infty}(O,\mathbb{R}^m)$, se tiene $(df_{|S})_p = (df_p)_{|T_pS}$.

 3. Para $f \colon S \to S'$ con $V \subset S$, se tiene $(df_{|V})_p = df_p$.

 4. $d(g \circ f)_p = dg_{f(p)} \circ df_p$.

******* TODO Proof

******* Card: diferencial del producto vectorial                                                          :drill:
SCHEDULED: <2018-07-18 Wed>
:PROPERTIES:
:ID:       797e93ca-a758-4751-9ce4-a7d532280cc9
:DRILL_LAST_INTERVAL: 39.8571
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.667
:DRILL_EASE: 2.32
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-08 Fri 14:37]
:END:
Calcular $d(f \times g)_p(v)$.

******** Resultado

\[
df_p(v) \times g(p) + f(p) \times dg_p(v)
\]

****** 2.4.14. Diferencial nula es aplicación constante
:PROPERTIES:
:ID:       280958a3-c918-492b-8f0e-697d515101d4
:END:
Si $f \colon S \to S'$ cumple $df_p = 0$ para cada $p \in S$, entonces $f$ es constante
en cada componente conexa.

******* Proof
Sea $f(p_0) = a$, tenemos $f^{-1}(a) \subset S$ cerrado relativo no vacío.

Para $p \in f^{-1}(a)$, tomamos parametrizaciones $X \colon U \to S$ e $Y \colon U' \to S'$
con $p = X(q)$ y $a = Y(q')$; podemos suponer $U$ conexo, $f(X(U)) \subset Y(U')$.
Se tiene $F = Y^{-1}\circ f \circ X$ diferenciable por regla de la cadena con

\[
dF_q = (dY^{-1})_{f(X(q))} \circ (df)_{X(q)} \circ (dX)_q = 0
\]

y por tanto $F$, aplicación entre abiertos, es constante. Así,
$f = Y \circ F \circ X^{-1}$ es constante en $X(U)$, entorno abierto de $p$.

Por tanto, $f^{-1}(a)$ es abierto y cerrado y debe ser todo $S$.

****** 2.4.15. Extremos locales
Para $f \colon S \to \mathbb{R}$ sobre superficie o abierto, consideramos

 * *mínimo local* a $p_0$ si hay un entorno abierto $p_0 \in V \subset S$
   con $f(p) \geq f(p_0)$; análogamente *máximo local*;

 * *punto crítico* a $p_0$ si $f$ es diferenciable y $(df)_{p_0} = 0$.

****** TODO [#A] 2.4.17. Puntos críticos en extremos locales
Si $f \in {\cal C}^{\infty}(S)$ alcanza en $p_0 \in S$ extremo local, entonces $\nabla f(p) = 0$,
siendo punto crítico.

******* TODO Proof
***** 2.4.3. Difeomorfismos. Teorema de la función inversa
****** 4.18. Difeomorfismo
:PROPERTIES:
:ID:       f2a430ff-2f4b-485f-802e-6333afbbb337
:END:
$f \colon S \to S'$ entre superficies es *difeomorfismo* si es
diferenciable, biyectiva y con inversa diferenciable.

****** Ej.13. Difeomorfismo es relación de equivalencia
La identidad, el inverso de difeomorfismo y la composición de
difeomorfismos son difeomorfismos. Ser difeomorfos es relación
de equivalencia.

******* Proof
Trivial desde la [[id:f2a430ff-2f4b-485f-802e-6333afbbb337][definición]].

****** Ej.14. Difeomorfismo restringido sobre superficie es difeomorfismo
Si $\phi \colon O \to O'$ es difeomorfismo y $S \subsetP$ es superficie, entonces
$\phi_{|S} \colon S \to \phi(S)$ es difeomorfismo.

******* Proof
Trivial considerando que $\phi^{-1} \colon \mathbb{R}^3 \to \mathbb{R}^3$ es también diferenciable
y que la [[id:c57ee25a-ece7-4c4a-92a5-253ff821001b][restricción a superficie de diferenciable es diferenciable]].

****** 4.19. Parametrizaciones son difeomorfismos
Las parametrizaciones de una superficie son difeomorfismos por ser
ellas y sus inversas [[id:38f14c25-5a11-44aa-971c-240238dbd2a7][diferenciables]]. Así las superficies son
subconjuntos localmente difeomorfos a abiertos del plano.

****** 4.20. Difeomorfismo local
$f \colon S \to S'$ es difeomorfismo local en $p \in S$ si hay entornos abiertos
$p \in V \subset S$ y $f(p) \in V' \subset S'$ tales que $f_{|V}\colon V \to V'$ es difeomorfismo.
Es un *difeomorfismo local* si lo es en cada punto.

****** 4.21. Difeomorfismo local es abierta
:PROPERTIES:
:ID:       3c74d759-f8e6-4497-8eb3-5af5996a840d
:END:
Si $f \colon S \to S'$ es difeomorfismo local, es aplicación abierta.

******* Proof
Sea $V \subset S$ abierto. Para $q \in f(V)$, si $f(p) = q$ tenemos por ser
difeomorfismo local que $f_{|W}$ es difeomorfismo, donde $p \in W$ y $q \in W'$
entornos abiertos. Ahora $f(V \cap W)$ por difeomorfismo (y en particular
homeomorfismo) es un abierto de $W$ y por tanto de $S$ que está en 
$f(V)$ y contiene a $q$.

****** 4.22. Difeomorfismo es difeomorfismo local biyectivo
:PROPERTIES:
:ID:       1c6c3936-2bbb-4237-804e-072c1ea05d02
:END:
$f \colon S \to S'$ difeomorfismo ssi es difeomorfismo local biyectivo.

******* Proof
Si es difeomorfismo local biyectivo, sólo falta probar $f^{-1}$
diferenciable, pero eso [[id:c57ee25a-ece7-4c4a-92a5-253ff821001b][lo podemos hacer localmente]] en un
recubrimiento de abiertos de $S'$. Si $q \in S'$ con $f(p) = q$,
tomamos los entornos haciendo $f_{|V_p}\colon V_p \to V'_q$ difeomorfismo,
que nos da $f^{-1}$ diferenciable.

****** 4.23. Teorema de la función inversa
:PROPERTIES:
:ID:       8e0b57e0-deed-4aac-8e29-e5b43406c141
:END:
Para $f \colon S \to S'$ diferenciable, si $(df)_p \colon T_pS \to T_{f(p)}S'$ es
isomorfismo, entonces $f$ es difeomorfismo local en $p$.

******* TODO Proof
******* Card                                                                                              :drill:
SCHEDULED: <2018-06-30 Sat>
:PROPERTIES:
:ID:       e2083ec1-dfff-4974-a684-a2611c6f5c70
:DRILL_LAST_INTERVAL: 25.5324
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.25
:DRILL_EASE: 2.32
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-04 Mon 14:55]
:END:
Enuncia el teorema de la función inversa entre superficies.

******** Enunciado
Para $f \colon S \to S'$ diferenciable, si $(df)_p \colon T_pS \to T_{f(p)}S'$ es
isomorfismo, entonces $f$ es difeomorfismo local en $p$.

******** Nota extra
Nótese que si es difeomorfismo local, debe tener diferencial
isomorfismo.

****** 4.24. Corolarios al teorema de la función inversa
:PROPERTIES:
:ID:       2568912c-5677-40ac-873e-e49d08c26a5c
:END:
Sea $f \colon S \to S'$ diferenciable

 1. $f$ difeomorfismo local ssi $df_p$ siempre isomorfismo.
 2. $f$ difeomorfismo ssi $f$ biyectiva y $df_p$ siempre isomorfismo.

****** 4.25. Superficie contenida en superficie es abierto relativo
Si $S' \subset S$, entonces $S'$ es abierto de $S$.

******* Card                                                                                              :drill:
SCHEDULED: <2018-07-21 Sat>
:PROPERTIES:
:ID:       35427325-1210-4286-a7be-9d5ff9231027
:DRILL_LAST_INTERVAL: 46.9166
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.667
:DRILL_EASE: 2.7
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-04 Mon 14:55]
:END:
Si tenemos $S' \subset S$, ¿qué información topológica nos da?

******** Respuesta
Sabemos $S'$ abierto relativo de $S$.

******* Proof
Tomamos $i \colon S' \to S$ inclusión con $di_p \colon T_pS \to T_pS' = T_pS$ la
identidad. Por [[id:8e0b57e0-deed-4aac-8e29-e5b43406c141][Teorema de la función inversa]] es difeomorfismo
local en todo punto; y [[id:1c6c3936-2bbb-4237-804e-072c1ea05d02][siendo biyectiva es difeomorfismo]].
Pero un [[id:3c74d759-f8e6-4497-8eb3-5af5996a840d][difeomorfismo es aplicación abierta]], luego $i(S')$ es
abierto relativo de $S$.

****** 4.26. Caracterización de parametrización
:PROPERTIES:
:ID:       cfc42651-eabd-4024-8fe6-6ce2b4284e3c
:END:
Si $X \colon U \to \mathbb{R}^3$ con $X(U) \subset S$ es diferenciable, inyectiva, y con
diferencial inyectiva $(dX)_q \colon \mathbb{R}^2 \to \mathbb{R}^3$, es una parametrización
local de $S$.

/Estamos ganando el ser homeomorfismo./

******* Proof
Tenemos $dX_q \colon \mathbb{R}^2 \to T_{X(q)}S$ inyectiva luego isomorfismo, así,
$X$ es difeomorfismo local y por tanto abierto. $X(U)$ es un
abierto de $S$ y $X \colon U \to X(U)$ es difeomorfismo local biyectivo
luego difeomorfismo, siendo en particular homeomorfismo.

**** 2.5. Superficies orientables
***** 2.5.1. Campo de vectores
Un *campo de vectores* es un $F \colon S \to \mathbb{R}^3$. Es

 * *diferenciable* si $F \in {\cal C}^{\infty}(S,\mathbb{R}^3)$,
 * *tangente* si $F(p) \in T_p(S)$,
 * *normal* si $F(p) \in (T_p(S))^{\bot}$,
 * *unitario* si $X(S) \subset \mathbb{S}^2$.

***** 2.5.2. Orientación
:PROPERTIES:
:ID:       18f9a9b7-8def-49c2-a185-a536b9bea052
:END:
Una *orientación* es un campo normal, unitario y diferenciable.
Una superficie es orientable si admite una orientación.

****** Card                                                                                                :drill:
SCHEDULED: <2018-07-05 Thu>
:PROPERTIES:
:ID:       564f702b-78ce-48bf-9a67-02e0a4b51a16
:DRILL_LAST_INTERVAL: 30.5675
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.333
:DRILL_EASE: 2.56
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-04 Mon 14:51]
:END:
Orientación de una superficie.

******* Definición
Un campo de vectores $F \colon S \to \mathbb{R}^3$ normal, unitario y
diferenciable.

****** Card                                                                                                :drill:
SCHEDULED: <2018-06-30 Sat>
:PROPERTIES:
:ID:       5c3f56c5-cdb3-4d7c-b09a-4ba12c642c2f
:DRILL_LAST_INTERVAL: 35.0266
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 5
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.8
:DRILL_EASE: 2.8
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-05-26 Sat 22:19]
:END:
Superficie orientable.

******* Definición
Admite un campo de vectores normal, unitario y diferenciable.

***** 2.5.4. Una superficie orientable tiene dos orientaciones
Si $N_1,N_2 \colon S \to \mathbb{R}^3$ son dos orientaciones de $S$ conexa, $N_1 = \pm N_2$.
Una superficie conexa y orientable tiene dos orientaciones.

****** Card                                                                                                :drill:
SCHEDULED: <2018-07-09 Mon>
:PROPERTIES:
:ID:       d172d5aa-810b-43b9-81d2-02a8a3071acb
:DRILL_LAST_INTERVAL: 35.4275
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.667
:DRILL_EASE: 2.7
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-04 Mon 14:47]
:END:
Tenemos dos orientaciones de una superficie conexa, 

\[
N_1,N_2 \colon S \to \mathbb{R}^3,
\]

¿qué sabemos?

******* Respuesta
Sabemos que son iguales o opuestas, $N_1 = \pm N_2$.

****** TODO Proof
Por conexión.

***** TODO 2.5.5. Cinta de Möbius no es orientable                                                          :extra:
***** 2.5.6. Orientabilidad es local
Si $S$ es orientable, entonces $S' \subset S$ abierta es orientable con
la restricción de la orientación.

****** Proof
Nótese que la restricción seguirá siendo diferenciable (la
diferenciabilidad es local) y unitaria. Además, $T_pS = T_pS'$,
luego si era normal, seguirá siendo normal.

***** 2.5.7. Orientabilidad es invariante diferenciable
Calcular la orientación tras un difeomorfismo en general no es
sencillo.  Sólo en el caso de movimiento rígido es fácil.

****** TODO Proof
***** 2.5.8. Orientabilidad de entornos coordenados
Si $X \colon U \to S$ es parametrización, $X(U)$ es orientable con
$N_X = n_X \circ X^{-1}$, donde

\[
n_X(q) = \frac{X_u(q) \times X_v(q)}{\abs{X_u(q) \times X_v(q)}}.
\]

****** Proof
Tenemos $n_X(q) \perp T_{X(q)}S$ y es unitario. Por regla de la cadena,
tenemos $N_X$ diferenciable.

****** Corolario: toda superficie es orientable localmente
****** Corolario: parametrización global da orientabilidad
****** Corolario: los grafos son orientables
Para $X(u,v) = (u,v,\varphi(u,v))$, tenemos la orientación,

\[\begin{aligned}
N_X(u,v,w) &=
(n_X \circ X^{-1})(u,v,w) = n_X(u,v) \\&=
\frac{(-\varphi_u(u,v), -\varphi_v(u,v), 1)}{\sqrt{1 + |\nabla \varphi(u,v)|^2}}
\end{aligned}\]

***** 2.5.9. Orientabilidad de superficies implícitas
Para $a \in VR(f)$, $f \in {\cal C}^{\infty}(O)$, si $S = f^{-1}(a) \neq \varnothing$, tenemos

\[
N(p) = \frac{\nabla f(p)}{\abs{\nabla f(p)}}
\]

orientación.

****** Proof
Es un campo unitario que sabemos que es normal por tenerse
$T_pS = (\nabla f(p))^{\bot}$. La aplicación es diferenciable porque
$f \in {\cal C}^{\infty}(O)$.

*** Tema 3. Curvatura de superficies ([[file:~/pdf/rosales_curvaturas.pdf][PDF]])
**** 3.1. Aplicación de Gauss, endomorfismo de Weingarten y curvaturas
***** 1.1. Aplicación de Gauss
La restricción de una [[id:18f9a9b7-8def-49c2-a185-a536b9bea052][orientación]] a la esfera $N \colon S \to \mathbb{S}^2$
se llama *aplicación de Gauss*. Una superficie conexa y
orientable tiene exactamente dos aplicaciones de Gauss,
$N$ y $-N$.

****** Card                                                                                                :drill:
SCHEDULED: <2018-06-20 Wed>
:PROPERTIES:
:ID:       25fbcbe6-bd07-4c93-be6d-4676de47efe9
:DRILL_LAST_INTERVAL: 12.3841
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.5
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-08 Fri 14:45]
:END:
Una superficie [conexa y orientable] tiene exactamente [dos] aplicaciones
de Gauss.

***** 1.2. Endomorfismo de Weingarten
La aplicación $A_p = -dN_p$ es un endomorfismo de $T_pS$ llamado 
*endomorfismo de Weingarten*.

****** Proof
Tenemos $dN_p \colon T_pS \to T_{N(p)}\mathbb{S}^2$. Como en la esfera una
orientación viene determinada por direcciones que une el origen
con el punto, $T_{N(p)}\mathbb{S}^2 = N(p)^{\bot} = T_p\mathbb{S}^2$.

****** Card: es un endomorfismo                                                                            :drill:
SCHEDULED: <2018-06-18 Mon>
:PROPERTIES:
:ID:       85038fce-1ba9-40e5-bf9a-804cac2cf6b3
:DRILL_LAST_INTERVAL: 10.1339
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-08 Fri 14:40]
:END:
¿Por qué el endomorfismo de Weingarten es un endomorfismo?

******* Answer
Tenemos $dN_p \colon T_pS \to T_{N(p)}\mathbb{S}^2$. Como en la esfera una
orientación viene determinada por direcciones que une el origen
con el punto, $T_{N(p)}\mathbb{S}^2 = N(p)^{\bot} = T_pS^2$.

El endomorfismo es $A_p = -dN_p$.

****** Card: definición                                                                                    :drill:
SCHEDULED: <2018-06-19 Tue>
:PROPERTIES:
:ID:       d7231d09-7b51-4da7-af79-37990a773acd
:DRILL_LAST_INTERVAL: 11.4736
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.5
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-08 Fri 14:42]
:END:
Definición del endomorfismo de Weingarten.

******* Answer
$A_p = -dN_p$, donde $N$ es una orientación de la superficie.

***** 1.4. Segunda forma fundamental
La *segunda forma fundamental* es $\sigma_p = II_p \colon T_pS \times T_pS \to \mathbb{R}$ dada
por

\[
\sigma_p(u,v) = \pair{A_p(u),v} = -\pair{dN_p(u),v}.
\]

La forma $\sigma_p$ es una métrica sobre $T_pS$, esto es, una aplicación
bilineal simétrica. En particular tenemos, para la base de una
parametrización,

 * $\pair{N(p),X_{vu}(q)} = \sigma_p(X_u(q),X_v(q))$,
 * $\pair{N(p),X_{uv}(q)} = \sigma_p(X_v(q),X_u(q))$.

****** Proof: simetría
Bilineal por definición. Comprobamos simetría sobre la base dada por
una parametrización $X$ y extendemos por bilinealidad.

Por definición de orientación, $\pair{N \circ X, X_v} = 0$; derivando
$\pair{(N \circ X)_u,X_v} + \pair{N \circ X,X_{vu}} = 0$; y evaluando en $q = X^{-1}(p)$,

 * $\pair{N(p),X_{vu}(q)} = \sigma_p(X_u(q),X_v(q))$
 * $\pair{N(p),X_{uv}(q)} = \sigma_p(X_v(q),X_u(q))$

por Schwarz-Clairaut, tenemos la simetría.

****** Card: definición                                                                                    :drill:
SCHEDULED: <2018-07-04 Wed>
:PROPERTIES:
:ID:       f9d7f47e-ccbe-43f2-b654-db6b6e1ef7ea
:DRILL_LAST_INTERVAL: 26.4288
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.333
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-08 Fri 14:46]
:END:
Define la segunda forma fundamental $\sigma_p(u,v)$.

******* Answer
La aplicación $\sigma_p = II_p \colon T_pS \times T_pS \to \mathbb{R}$ definida por

\[
\sigma_p(u,v) = \pair{A_p(u),v} = -\pair{dN_p(u),v}.
\]

****** Card: fórmula                                                                                       :drill:
SCHEDULED: <2018-07-27 Fri>
:PROPERTIES:
:DRILL_CARD_TYPE: hide1cloze
:ID:       1b7f1bd4-af26-4ddb-809b-bf8b039cf9ef
:DRILL_LAST_INTERVAL: 27.8933
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.46
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-29 Fri 09:55]
:END:

[ $\sigma_p(X_v(q),X_u(q))$ ] = [ $\pair{N(p),X_{uv}(q)}$ ]

****** Card: simetría                                                                                    :nodrill:
SCHEDULED: <2018-07-07 Sat>
:PROPERTIES:
:ID:       c52637a8-c5b5-4974-b9a3-3ffc1bd75806
:DRILL_LAST_INTERVAL: 8.5527
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 2.667
:DRILL_EASE: 2.22
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-28 Thu 22:12]
:END:
¿Por qué sabemos que $\sigma$, la segunda forma fundamental, es simétrica?

******* Answer
Comprobamos la simetría sobre la base dada por una parametrización,

 * $\pair{N(p),X_{vu}(q)} = \sigma_p(X_u(q),X_v(q))$
 * $\pair{N(p),X_{uv}(q)} = \sigma_p(X_v(q),X_u(q))$

por Schwarz-Clairaut, tenemos la simetría.

***** 1.6. El endomorfismo de Weingarten es autoadjunto
$A_p$ es autoadjunto en el espacio euclídeo $(T_pS,I_p)$.

En particular existe una base ortonormal de vectores propios y es
diagonalizable con valores propios reales. Llamamos
*curvaturas principales* a sus valores propios

\[
A_p = \begin{pmatrix}
k_1(p) & 0 \\
0 & k_2(p)
\end{pmatrix}.
\]

****** Proof
Usamos que $\sigma_p$ y el producto escalar son simétricos.

****** Card: endomorfismo                                                                                  :drill:
SCHEDULED: <2018-08-02 Thu>
:PROPERTIES:
:ID:       15643ff5-968c-47a5-a5af-fcb5c8a4fdb6
:DRILL_LAST_INTERVAL: 33.548
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.333
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-29 Fri 09:56]
:END:
Por qué sabemos que $\pair{A_p(a),b} = \pair{a,A_p(b)}$.

******* Answer
El endomorfismo de Weingarten es autoadjunto. Se deduce del hecho de que
$\sigma_p(u,v) = \pair{A_p(u),v}$ es simétrica y el producto escalar lo es.
El que $\sigma$ sea simétrica viene de Schwartz-Clairaut.

****** Card: curvaturas                                                                                    :drill:
SCHEDULED: <2018-06-17 Sun>
:PROPERTIES:
:ID:       e9ce52f0-87c8-4e32-8ccf-0c05547db768
:DRILL_LAST_INTERVAL: 9.4025
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-08 Fri 14:42]
:END:
Cómo se definen las curvaturas de una superficie en un punto.

******* Answer
Son los valores propios del endomorfismo de Weingarten.
El endomorfismo de Weingarten es autoadjunto luego diagonalizable,
tomamos

\[
A_p = \begin{pmatrix}
k_1(p) & 0 \\
0 & k_2(p)
\end{pmatrix}.
\]

Recuérdese que $A_p = - dN_p$, donde $N$ es la orientación.

***** 1.7. Curvaturas de una superficie

 * Llamamos *curvaturas principales* a $k_1(p)$ y a $k_2(p)$, tomamos
   por convención $k_1(p) \leq k_2(p)$.

 * Llamamos *direcciones principales* a los vectores propios de $A_p$.

 * La *curvatura de Gauss* es el cuadrado de la media geométrica
   de las curvaturas, el determinante del endomorfismo de Weingarten,
   $K(p) = k_1(p)k_2(p) = \mathrm{det}(A_p)$.

 * La *curvatura media* es la media aritmética de las curvaturas,
   la traza del endomorfismo de Weingarten
   $H(p) = (k_1(p) + k_2(p))/2 = \mathrm{traza}(A_p)/2$.

 * Una superficie es *llana* si $K(p)=0$ para cualquier $p \in S$.

 * Una superficie es *minimal* si $H(p)=0$ para cualquier $p \in S$.

****** Card: llana                                                                                         :drill:
SCHEDULED: <2018-06-21 Thu>
:PROPERTIES:
:ID:       f20774c6-2bd4-4608-8aea-c1728c400366
:DRILL_LAST_INTERVAL: 13.2789
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 5.0
:DRILL_EASE: 2.7
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-08 Fri 14:37]
:END:
Superficie llana.

******* Definition
Tiene la curvatura de Gauss nula, $K(p)=0$ para cualquier $p \in S$.

****** Card: minimal                                                                                       :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       70697a18-d8cc-4043-8a24-d2b1215e60c9
:DRILL_LAST_INTERVAL: 13.9383
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 5.0
:DRILL_EASE: 2.7
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-08 Fri 14:49]
:END:
Superficie minimal.

******* Definition
Tiene la curvatura media nula, $H(p)=0$ para cualquier $p \in S$.

****** Card: definición de curvatura de Gauss                                                              :drill:
SCHEDULED: <2018-06-23 Sat>
:PROPERTIES:
:ID:       654716d6-a356-465c-9062-d2bef5e0ba8f
:DRILL_LAST_INTERVAL: 14.9361
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.5
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-08 Fri 14:46]
:END:
Curvatura de Gauss.

******* Definition
Producto de las curvaturas principales. Dicho de otra forma, cuadrado
de la media geométrica de las curvaturas principales

$K(p) = k_1(p)k_2(p) = \mathrm{det}(A_p)$.

****** Card: definición de curvatura media                                                                 :drill:
SCHEDULED: <2018-06-17 Sun>
:PROPERTIES:
:ID:       931c9037-0868-458e-b028-5157a3ded78e
:DRILL_LAST_INTERVAL: 9.4062
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.5
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-08 Fri 14:40]
:END:
Curvatura media.

******* Definition
Media aritmética de las curvaturas principales

$H(p) = (k_1(p) + k_2(p))/2 = \mathrm{traza}(A_p)/2$.

***** 1.8. Nota. Calcular las curvaturas principales desde Gauss y media
Siendo raíces del polinomio, podemos calcular las curvaturas
principales como

\[
k_1 = H - \sqrt{H^2 - K},
\qquad
k_2 = H + \sqrt{H^2 - K}.
\]

Sabemos por desigualdad de las medias (considerando los casos negativos)
que $K(p) \leq H(p)^2$.

****** Card: cálculo                                                                                       :drill:
SCHEDULED: <2018-06-19 Tue>
:PROPERTIES:
:ID:       c2b14d22-21b7-4090-b6d6-b569b7e58461
:DRILL_LAST_INTERVAL: 10.8021
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.5
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-08 Fri 14:45]
:END:
Calcular curvaturas principales desde la curvatura de Gauss y
curvatura media.

******* Answer

\[
k_1 = H - \sqrt{H^2 - K},
\qquad
k_2 = H + \sqrt{H^2 - K}.
\]

****** Card: desigualdad                                                                                   :drill:
SCHEDULED: <2018-06-17 Sun>
:PROPERTIES:
:ID:       d90f6395-c496-421d-8dcd-98a8a152e390
:DRILL_LAST_INTERVAL: 9.3348
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-08 Fri 14:40]
:END:
Por qué sabemos que $K(p) \leq H(p)^2$.

******* Answer 
Podemos aplicar la desigualdad de las medias a las curvaturas
principales, teniendo en cuenta los casos negativos.

***** 1.9. Punto umbilical
$p \in S$ es *umbilical* si $k_1(p) = k_2(p)$.

****** Card: punto umbilical                                                                               :drill:
SCHEDULED: <2018-06-19 Tue>
:PROPERTIES:
:ID:       566d963c-5455-43cc-be54-c1a747778a7b
:DRILL_LAST_INTERVAL: 10.8104
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 5.0
:DRILL_EASE: 2.7
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-08 Fri 14:37]
:END:
Punto umbilical.

******* Answer
Punto donde las curvaturas principales coinciden, $p \in S$ es
*umbilical* si $k_1(p) = k_2(p)$.

***** Ej.1. Caracterizaciones de punto umbilical
:PROPERTIES:
:ID:       7dd64b5f-efdb-420c-b173-d388c47e8c44
:END:
Equivalen

 - $p$ punto umbilical,

 - $H(p)^2 = K(p)$, caso de igualdad en las medias,

 - $A_p = H(p) \mathrm{Id}$,

 - $\sigma_p = H(p) I_p$.

****** Proof
Ssi es umbilical, se da el caso de igualdad en la desigualdad de las
medias.  Como podemos diagonalizar con dos valores propios iguales
y la identidad conmuta, tenemos $A_p = PH(p) \mathrm{Id} P^{-1} = H(p) \mathrm{Id}$ y
la última igualdad es equivalente. Nótese que si se da alguna de
estas igualdades, la diagonalización es trivial.

****** Card                                                                                                :drill:
SCHEDULED: <2018-07-28 Sat>
:PROPERTIES:
:ID:       f6b5acef-e53a-4ecc-ba46-d13e217e2a47
:DRILL_LAST_INTERVAL: 28.776
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.667
:DRILL_EASE: 2.7
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-29 Fri 09:53]
:END:
Dar la caracterización y definición de punto umbilical.

******* Answer

 * $A_p = H(p) \mathrm{Id}$, curvaturas principales iguales.
 * $H(p)^2 = K(p)$, caso de igualdad en las medias.

***** Ej.2. Elementos geométricos de la orientación contraria
Se puede comprobar que si se toma la orientación $-N$, el endomorfismo
de Weingarten, la segunda forma fundamental, las curvaturas
principales y la curvatura media se invierten; pero la curvatura de
Gauss permanece igual.

****** Card                                                                                                :drill:
SCHEDULED: <2018-06-24 Sun>
:PROPERTIES:
:ID:       9d2c3dcb-d8f4-44cb-ada5-07d243bfece2
:DRILL_LAST_INTERVAL: 15.7637
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 5.0
:DRILL_EASE: 2.7
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-08 Fri 14:46]
:END:
¿Qué elemento geométrico permanece con el mismo signo si tomamos la
orientación opuesta en una superficie?

******* Answer
La curvatura de Gauss. La media y las curvaturas se invierten.

***** Ej.3. Aplicación de Gauss en una superficie contenida
Si $S' \subset S$ es superficie, probar que los elementos geométricos coinciden
en los puntos $p \in S'$.

****** Proof
Sabemos que ${\widetilde A}_p \colon T_pS' \to T_pS'$ puede ser vista como un endomorfismo
de $T_pS = T_pS'$.  Su valor es el mismo por el carácter local de la
diferenciabilidad.

***** 1.10. Ej.4. Clasificación de puntos de una superficie
Un punto es 

 - *Elíptico* si $K(p) > 0$. Equivale a $\sigma_{p}$ definida positiva o
   negativa.

 - *Hiperbólico* si $K(p)<0$. Equivale a $\sigma_{p}$ indefinida.

 - *Parabólico* si $K(p) = 0$ con $H(p) \neq 0$. Nos da $\sigma_{p}$ semidefinida positiva o
   negativa.

 - *Plano* si $K(p) = 0$ con $H(p)=0$. Nos da $\sigma_{p}$ nula.

Nótese que la clasificación es invariante a cambio de orientación.

****** Card                                                                                                :drill:
SCHEDULED: <2018-06-18 Mon>
:PROPERTIES:
:ID:       e286e2f1-3fdc-4f2b-ba92-0d5da844d623
:DRILL_LAST_INTERVAL: 10.4829
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.46
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-08 Fri 14:43]
:END:
Clasifica los puntos de una superficie según sus curvaturas.

******* Answer

 - *Elíptico* si $K(p) > 0$.

 - *Hiperbólico* si $K(p)<0$.

 - *Parabólico* si $K(p) = 0$ con $H(p) \neq 0$.

 - *Plano* si $K(p) = 0$ con $H(p)=0$.

***** Ej.5. Puntos de superficies llanas y minimales

 - Los puntos umbilicales son elípticos o planos.
 - Una superficie llana tiene solo puntos parabólicos o planos.
 - Una superficie minimal tiene solo puntos hiperbólicos o planos.

****** Card: tipo de puntos umbilicales                                                                    :drill:
SCHEDULED: <2018-07-30 Mon>
:PROPERTIES:
:ID:       ad298a68-119d-4ee0-9464-be4595ce0bbd
:DRILL_LAST_INTERVAL: 30.5786
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.667
:DRILL_EASE: 2.7
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-29 Fri 09:56]
:END:
¿Qué tipo de puntos puede ser un punto umbilical?

******* Answer
Puede ser sólo elíptico o plano.

****** Card: puntos de una superficie llana                                                                :drill:
SCHEDULED: <2018-06-20 Wed>
:PROPERTIES:
:ID:       3be0d1e8-0383-4254-9636-686092c4e169
:DRILL_LAST_INTERVAL: 11.8947
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.5
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-08 Fri 14:49]
:END:
¿Qué tipo de puntos puede tener una superficie llana?

******* Answer
Parabólicos y planos.

****** Card: puntos de una superficie minimal                                                              :drill:
SCHEDULED: <2018-08-08 Wed>
:PROPERTIES:
:ID:       26d13b01-746b-4d1a-a063-9b5fc8ae5059
:DRILL_LAST_INTERVAL: 40.2505
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 5.0
:DRILL_EASE: 2.8
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-29 Fri 17:50]
:END:
¿Qué tipo de puntos puede tener una superficie minimal?

******* Answer
Hiperbólicos o planos.

***** TODO Ejemplo 1.12. Planos afines
***** TODO Ejemplo 1.13. Esferas
***** TODO Ejemplo 1.14. Cilindros circulares
***** TODO Ejemplo 1.15. Punto hiperbólico en el paraboloide hiperbólico
***** TODO Ej.6. Paraboloide elíptico
***** 1.17. Movimientos rígidos y elementos geométricos
Dada $S$ superficie con orientación $N\colon S \to \mathbb{S}^2$ y $\phi \colon \mathbb{R}^3\to \mathbb{R}^3$ movimiento
rígido, 

 * ${\tilde N} = \vec{\phi} \circ N \circ \phi^{-1}$ es orientación de $\phi(S)$, en particular,
   $A'_{\phi(p)} = \vec{\phi}\circ A_p\circ (\vec{\phi})^{-1}$ es el endomorfismo de Weingarten;

 * $\phi(e_1),\phi(e_2)$ son base de direcciones principales de $\phi(S)$.

 * ${\tilde \sigma_{\phi(p)}}(d\phi_pu,d\phi_pv) = \sigma_p(u,v)$,

 * las curvaturas se preservan.

***** 1.18. Curvatura de Gauss de una superficie cualquiera
***** TODO Ej.7. Problemas de la curvatura media de una superficie cualquiera
***** TODO Ej.8. Curvatura invariante a movimientos rígidos
**** 3.2. Expresiones locales y diferenciabilidad de las curvaturas
***** 2.0. Matriz de la primera forma fundamental respecto de parametrización
Para una parametrización local $X \colon U \to S$, consideramos la
base $B_q = \left\{ X_u(q),X_v(q) \right\}$. La primera forma fundamental tiene matriz

\[
M_q = \begin{pmatrix}
E & F \\
F & G
\end{pmatrix}(q).
\]

Los coeficientes de la primera forma fundamental son

\[E = \abs{X_u}^2,
\qquad
F = \pair{X_u,X_v},
\qquad
G = \abs{X_v}^2.\]

****** Card: coeficientes de la primera forma fundamental                                                :nodrill:
SCHEDULED: <2018-07-16 Mon>
:PROPERTIES:
:ID:       fbfd7142-995b-48a7-8f58-96a7c41e3f01
:DRILL_LAST_INTERVAL: 16.6908
:DRILL_REPEATS_SINCE_FAIL: 4
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.333
:DRILL_EASE: 2.22
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-29 Fri 17:44]
:END:
Da los coeficientes de la primera forma fundamental respecto de la base 
$\left\{X_u(q),X_v(q) \right\}$ dada por una parametrización.

\[
M_q = \begin{pmatrix}
E & F \\
F & G
\end{pmatrix}(q),\qquad
\]

******* Answer

\[E = \abs{X_u}^2,\qquad F = \pair{X_u,X_v},\qquad G = \abs{X_v}^2\]

***** 2.0. Matriz de la segunda forma fundamental repecto de parametrización
Para una parametrización local $X \colon U \to S$, consideramos la
base $B_q = \left\{ X_u(q),X_v(q) \right\}$. La segunda forma fundamental
respecto de la aplicación de Gauss $N_X$ tiene matriz

\[\Sigma_q = \begin{pmatrix}
e & f \\ f & g
\end{pmatrix}(q).\]

Los coeficientes de la segunda forma fundamental son

\[
e = \frac{\mathrm{det}(X_u,X_v,X_{uu})}{\sqrt{EG-F^2}},\qquad
f = \frac{\mathrm{det}(X_u,X_v,X_{uv})}{\sqrt{EG-F^2}},\qquad
g = \frac{\mathrm{det}(X_u,X_v,X_{vv})}{\sqrt{EG-F^2}}.
\]

Nótese que son diferenciables.

****** TODO Proof: cálculo
****** TODO Proof: diferenciabilidad
****** Card                                                                                                :drill:
SCHEDULED: <2018-06-24 Sun>
:PROPERTIES:
:ID:       80cc9bc1-11c8-44e7-9a7b-16bb7f5def8e
:DRILL_LAST_INTERVAL: 15.7721
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.46
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-08 Fri 23:35]
:END:
Coeficientes de la segunda forma fundamental respecto de la base 
$\left\{X_u(q),X_v(q) \right\}$ dada por una parametrización.

******* Answer

\[
e = \frac{\mathrm{det}(X_u,X_v,X_{uu})}{\sqrt{EG-F^2}},\qquad
f = \frac{\mathrm{det}(X_u,X_v,X_{uv})}{\sqrt{EG-F^2}},\qquad
g = \frac{\mathrm{det}(X_u,X_v,X_{vv})}{\sqrt{EG-F^2}}.
\]

***** 2.0. Curvatura media y de Gauss en función de coeficientes
Para una parametrización local $X \colon U \to S$, consideramos la
base $B_q = \left\{ X_u(q),X_v(q) \right\}$. Tenemos curvaturas respecto de la
aplicación de Gauss $N_X$ dadas por

\[
K = \frac{eg - f^2}{EG-F^2},
\qquad
H = \frac{1}{2}\frac{eG-2fF+gE}{EG-F^2}.
\]

Ambas $K \circ X$ y $H \circ X$ son diferenciables.

****** TODO Proof
****** Card: curvatura media y de Gauss en función de coeficientes                                       :nodrill:
SCHEDULED: <2018-07-12 Thu>
:PROPERTIES:
:ID:       26690650-3be6-456a-8531-26880aefaad5
:DRILL_LAST_INTERVAL: 13.7639
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 6
:DRILL_FAILURE_COUNT: 3
:DRILL_AVERAGE_QUALITY: 2.5
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-28 Thu 22:13]
:END:
Da la curvatura media y la curvatura de Gauss en función de los
coeficientes de la primera y segunda formas normales, para poder
calcularlas en un entorno coordenado.

******* Answer

\[
K = \frac{eg - f^2}{EG-F^2},
\qquad
H = \frac{1}{2}\frac{eG-2fF+gE}{EG-F^2}.
\]

***** 2.2. Ejemplo. Curvatura media y de Gauss en una superficie grafo
:PROPERTIES:
:ID:       b007b192-89c8-4ff5-a19d-989e9a401ecf
:END:
En general,

\[
K = \frac{\varphi_{xx}\varphi_{yy}-\varphi_{xy}^2}{\left(1 + \abs{\nabla\varphi}^2\right)^2},
= \frac{\abs{\nabla^2\varphi}}{\left(1 + \abs{\nabla\varphi}^2\right)^2},
\qquad
H = \frac{1}{2}
\frac{(1 + \varphi_y^2)\varphi_{xx} - 2\varphi_{xy}\varphi_x\varphi_y + (1 + \varphi_x^2)\varphi_{yy}}
{\left( 1 + \abs{\nabla \varphi}^2 \right)^{3/2}}.
\]

Pero además, cuando tenemos un punto crítico con $\nabla\varphi(x,y)=(0,0)$,
obtenemos $K = \abs{\nabla^2\varphi}$ y $H = \Delta\varphi / 2$.

****** Card: curvatura media y de Gauss en una superficie grafo                                            :drill:
SCHEDULED: <2018-06-18 Mon>
:PROPERTIES:
:ID:       6c2ce13a-db7b-4978-826b-64ecdeb8510f
:DRILL_LAST_INTERVAL: 10.0697
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-08 Fri 14:59]
:END:
Calcular la curvatura media y la curvatura de Gauss de una superficie
grafo desde la orientación usual de los grafos. *En un punto cualquiera*

******* Answer

\[
K = \frac{\varphi_{xx}\varphi_{yy}-\varphi_{xy}^2}{\left(1 + \abs{\nabla\varphi}^2\right)^2},
= \frac{\abs{\nabla^2\varphi}}{\left(1 + \abs{\nabla\varphi}^2\right)^2},
\qquad
H = \frac{1}{2}
\frac{(1 + \varphi_y^2)\varphi_{xx} - 2\varphi_{xy}\varphi_x\varphi_y + (1 + \varphi_x^2)\varphi_{yy}}
{\left( 1 + \abs{\nabla \varphi}^2 \right)^{3/2}}.
\]

****** Card: curvaturas en el caso de punto crítico de un grafo                                            :drill:
SCHEDULED: <2018-06-20 Wed>
:PROPERTIES:
:ID:       3019e94e-7a0f-497b-ad3f-741c87fe42da
:DRILL_LAST_INTERVAL: 12.0594
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.5
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-08 Fri 23:33]
:END:
*En un punto crítico*. Calcular la curvatura media y la curvatura de
Gauss de una superficie grafo desde la orientación usual de los
grafos.

******* Answer

\[
K = \abs{\nabla^2\varphi},\qquad
H = \frac{1}{2}\Delta\varphi
\]

***** 2.3. Nota. Grafos llanos y minimales
Por los cálculos [[id:b007b192-89c8-4ff5-a19d-989e9a401ecf][anteriores]], un grafo es llano ssi

\[
\abs{\nabla^2 \varphi} = \varphi_{xx}\varphi_{yy} - \varphi_{xy}^2 = 0.
\]

Y un grafo es minimal ssi

\[
    (1+\varphi_y^2)\varphi_{xx} - 
    2\varphi_{xy}\varphi_x\varphi_y + 
    (1+\varphi_x^2)\varphi_{yy} = 0.
\]

****** Card: condición de minimalidad                                                                      :drill:
SCHEDULED: <2018-06-19 Tue>
:PROPERTIES:
:ID:       871e7133-1d9d-410d-b533-44fff118cca2
:DRILL_LAST_INTERVAL: 10.6778
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.333
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-08 Fri 14:57]
:END:
¿Cuándo es un grafo *minimal*? Nótese que preguntamos el caso específico
de grafos.

******* Answer
Si y sólo si

\[
    (1+\varphi_y^2)\varphi_{xx} - 
    2\varphi_{xy}\varphi_x\varphi_y + 
    (1+\varphi_x^2)\varphi_{yy} = 0.
\]

Recuérdese que la curvatura media de un grafo es

\[
H = \frac{1}{2}
\frac{(1 + \varphi_y^2)\varphi_{xx} - 2\varphi_{xy}\varphi_x\varphi_y + (1 + \varphi_x^2)\varphi_{yy}}
{\left( 1 + \abs{\nabla \varphi}^2 \right)^{3/2}}.
\]

****** Card: condición de llanitud                                                                         :drill:
SCHEDULED: <2018-06-19 Tue>
:PROPERTIES:
:ID:       2cda9781-d5aa-4ade-853a-75aaf00fae40
:DRILL_LAST_INTERVAL: 11.1319
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.667
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-08 Fri 23:32]
:END:
¿Cuándo es una superficie *grafo* llana? Estudiar sólo el caso
particular de una superficie grafo.

******* Answer
Si y sólo si

\[
\abs{\nabla^2 \varphi} = \varphi_{xx}\varphi_{yy} - \varphi_{xy}^2 = 0.
\]

***** 2.4. Curvaturas diferenciables en superficies orientables
:PROPERTIES:
:ID:       a111157d-1652-4d3a-b661-f5252e9e6126
:END:
En $S$ orientable, se tiene $K,H \in {\cal C}^{\infty}(S)$, y además $k_i \in {\cal C}^{\infty}(S -A)$,
donde $A = \left\{ k_1(p) = k_2(p) \right\}$.

****** TODO Proof
***** TODO 2.5.
***** TODO 2.6.
***** 2.7. Curvatura de Gauss diferenciable
Para cualquier $S$, tenemos $K \in {\cal C}^{\infty}(S)$.

**** 3.3. Curvaturas y geometría local de superficies
***** 3.1. Lema del grafo
Para $S$ superficie con $p \in S$ existe $\phi \colon \mathbb{R}^3\to \mathbb{R}^3$ movimiento rígido tal
que $S' = \phi(S)$ cumple

 * $0 = \phi(p_0) \in S'$, envía el punto al origen,

 * $T_0S' = \phi(T_{p_0}S) = \left\{ (u,v,w) \mid w =0 \right\}$, tangente al plano horizontal,

 * Tenemos entorno $W'$ y disco $U'$ centrado en $0$ tales que hay un $\varphi \in {\cal C}^{\infty}(U')$
   cumpliendo $\varphi(0)=0$, $\nabla \varphi (0)=0$, y además $W' = G^z(\varphi)$.

****** Proof
Tomamos el único movimiento rígido $\phi$ que mueve una base ortonormal de $T_{p_0}S$
con un vector normal hacia la base usual de $\mathbb{R}^3$ en $0$. Aplicar un movimiento
rígido a una superficie nos da una superficie con $0 \in S'$. Además,

\[
T_0S' = T_{\phi(p_0) \phi(S)} = d\phi_{p_0}(T_{p_0}S) = \vec{\phi}_{p_0}(T_{p_0}S) = \left\{ (u,v,w)\mid w=0 \right\}.
\]

Sea $\pi \colon S' \to \mathbb{R}^2$ proyección en el eje $z$, sabemos $d\pi_0 \colon T_0S' \to \mathbb{R}^2$
isomorfismo y por [[id:16bd6b42-7b91-4fcf-8979-faabc0acd594][Teorema de la función inversa]] es difeomorfismo local
en $0$ y tenemos entornos (podemos restringir a un disco) donde $\pi \colon W' \to U'$
es difeomorfismo.

Finalmente, $X = \pi^{-1} \colon U' \to W'$ es diferenciable y tomamos $X(x,y)=(x,y,\varphi(x,y))$
para alguna $\varphi \in C^{\infty}(U)$, lo que nos da $\varphi(0) = 0$. Como además $X_x(0),X_y(0)$ forman
una base del plano $T_0S'$, tenemos $\varphi_x(0)=\varphi_y=0$.

***** 3.3. Posición local de una superficie respecto curvatura
Para $S$ superficie con $p_0 \in S$, si llamamos $P = p_0 + T_{p_0}S$ y tomamos $P^+,P^{-}$
como los semiplanos determinados por el normal.

 - Si $K(p_0) > 0$, hay un entorno tal que $V -\{p_0\} \subset P^+$ ó $V -\{p_0\} \subset P^-$.

 - Si $K(p_0) < 0$, para todo entorno, $V \cap P^+ \neq \varnothing$ y $V \cap P^- \neq \varnothing$.

****** Proof
Usamos el lema del grafo para colocar la superficie y luego aplicamos
herramientas del análisis real en un entorno suficientemente
pequeño. Usamos que el determinante de la hessiana es la curvatura de
Gauss en el caso de un punto crítico.

***** 3.5. La intersección de superficie y plano afín es una curva
Para $S$ superficie con $p_0 \in S$, $n$ unitario ortonormal a $T_{p_0}S$, y $P$ plano
afín de $\mathbb{R}^3$ con $p_0 \in P$ y $n \in \vec{P}$; existen un entorno $W$ de $p_0$ y una curva
p.p.a. $\alpha \colon I \to S$ tales que $\alpha(0) = p_0$ y que $\alpha(I) = W \cap P$.

****** Proof
Aplicamos el lema del grafo.  En el entorno podemos despejar la curva
usando el grafo y la parametrización de un plano para obtener una
curva regular.  El movimiento rígido que devuelve la superficie a la
posición original preserva curvas regulares. Reparametrizamos.

***** 3.6. La intersección de superficie y plano transverso es una curva
En general, si $p_0 \in S_1\cap S_2$ con $T_{p_0} S_1 \neq T_{p_0}S_2$, decimos
que son superficies transversas en $p_0$ y su intersección es localmente
una curva regular.

****** Proof                                                                                               :extra:
***** 3.7. Sección normal
Dada $S$ con orientación $N \colon S \to \mathbb{S}^2$, con $p_0 \in S$ y con $v \in T_{p_0}S$ unitario;
sabemos que existe una curva p.p.a. $\alpha_v(I_v) = W_v \cap (p_0 + L(v,N(p_0))$ para
algún entorno abierto $W_v$.  Se llama *sección normal*.

Comprobamos además $\alpha'(0) = \pm v$.

***** 3.8. Interpretación de la segunda forma fundamental
La curvatura de una sección normal es $k_v(0) = \sigma_{p_0}(v,v)$.

****** TODO Proof
Usando que los normales coinciden, derivando y despejando.

***** 3.9. Signo de la segunda forma fundamental
Sabiendo $\sigma_{p_0}(v,v) = k_v(0)$,

 - si $\sigma_{p_0}(v,v) > 0$, entonces $\alpha_v$ se dobla hacia $N_v(0)$;

 - si $\sigma_{p_0}(v,v) < 0$, entonces $\alpha_v$ se dobla hacia $-N_v(0)$.

****** TODO Proof

***** TODO 3.10. Signo de la curvatura de Gauss
***** 3.10. Fórmula de Euler
Escribimos un vector en coordenadas de la base de direcciones principales
como $v = xe_1 + ye_2$.  Si $\abs{v}=1$ entonces $x^2+y^2 = 1$ y tenemos

\[
\sigma_{p_0}(v,v) = k_1(p_0)\cos^2(\theta) + k_2(p_0)\sin^2(\theta).
\]

Como esta expresión alcanza máximo y mínimo absolutos y $\cos(\theta)e_1 + \sin(\theta)e_2$
tneemos que las curvaturas de sección normal están en $k_1(p_0) \leq k_v(p_0) \leq k_2(p_0)$.

***** Ejercicio 10. Secciones normales en planos, esferas y cilindros
***** Ejercicio 11. Indicatriz de Dupin
***** 3.11. Existencia de puntos elípticos
:PROPERTIES:
:ID:       3e527821-5a65-4d06-b1c1-2508ef410b71
:END:
Para $S$ compacta, existe $S' = \mathbb{S}^2(0,R)$ y un $p_0 \in S$ tales que

 - $S$ y $S'$ son tangentes en $p_0 \in S \cap S'$, teniéndose $T_{p_0}S = T_{p_0}S'$.

 - $K(p_0)\geq 1/R^2 = K'(p_0)$.

Por lo tanto $K(p_0)>0$ y $p_0$ es un punto elíptico.

****** TODO Proof

***** 3.13. No hay superficies compactas orientables minimales
No existen superficies compactas orientables y minimales.

****** Proof
Toda superficie compacta tiene un punto elíptico, pero las superficies
orientables minimales no pueden tener puntos elípticos.

**** 3.4. Curvaturas y geometría global de superficies
***** 4.1. Caracterización de superficies totalmente umbilicales
:PROPERTIES:
:ID:       90b211e5-17c4-4167-8873-5abfd20858f6
:END:
Sea $S$ superficie orientable, conexa y totalmente umbilical. Entonces,
es un abierto de un plano o de una esfera.

****** Proof
Por [[id:7dd64b5f-efdb-420c-b173-d388c47e8c44][caracterización de punto umbilical]], en una superficie umbilical
tenemos $A_p(v) = H(p)v$. [[id:a111157d-1652-4d3a-b661-f5252e9e6126][Sabemos]] que $H \in {\cal C}^{\infty}$ en una superficie
orientable, y tenemos que $-(N\circ X)_u(z) = (H\circ X)(z) \cdot X_u(z)$
y que $-(N\circ X)_v(z) = (H\circ X)(z) \cdot X_v(z)$. Derivando ambos y
usando Schwarz-Clairaut, llegamos a

\[
0 = (H \circ X)_v(q) X_u(q) + (H\circ X)_u(q) X_{v}(q),
\]

que por independencia lineal de la base, nos dan
$dH_p(X_u(q)) = dH_p(X_v(q)) = 0$. La función $dH_p$, por ser nula
en una base, es nula. Por [[id:280958a3-c918-492b-8f0e-697d515101d4][conexión y diferencial nula]], tenemos
$H(p) = H_0$ constante.

 * En el caso $H_0 = 0$, tendríamos $dN_p \equiv 0$ y de nuevo por conexión,
   $N$ sería constante. Si todas las rectas afines normales son paralelas,
   la superficie debe ser el abierto de un plano (Ejercicio 10, Tema 2).

 * En el caso $H_0 \neq 0$, definimos $f(p) = p + N(p)/H_0$, que es diferenciable
   por construcción con diferencial nula

   \[
   (df_p)(v) = v + \frac{dN_p(v)}{H_0} = v - \frac{H_0}{H_0}v = 0.
   \]

   Siendo constante, $\abs{p - p_0} = 1/H_0$, por lo que la superficie es abierto
   de una esfera.

****** Card                                                                                              :nodrill:
SCHEDULED: <2018-07-07 Sat>
:PROPERTIES:
:DRILL_CARD_TYPE: hide1cloze
:ID:       debf9527-ba14-4f4a-aae3-b7954ec6cb0b
:DRILL_LAST_INTERVAL: 8.9726
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 2.75
:DRILL_EASE: 2.22
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-28 Thu 22:13]
:END:

Una superficie [orientable, conexa, y totalmente umbilical] es
[un abierto de un plano o de una esfera].

***** 4.3. Caracterización de superficies totalmente umbilicales completas
Sea $S$ superficie *cerrada* orientable, conexa, y totalmente umbilical.
Entonces, es un plano afín o una esfera. Si es compacta, debe ser
una esfera.

****** Proof
Por el [[id:90b211e5-17c4-4167-8873-5abfd20858f6][teorema anterior]], debe ser un abierto de plano o de esfera,
pero por ser cerrada, debe ser cerrada relativa al plano o a la 
esfera, y entonces por conexión del plano y de la esfera, debe
ser la superficie completa.

Si además es compacta, sólo puede ser una esfera.

****** Card                                                                                                :drill:
SCHEDULED: <2018-06-20 Wed>
:PROPERTIES:
:ID:       fcb9e233-50c9-488b-99e0-4ceb25f73f40
:DRILL_CARD_TYPE: hide1cloze
:DRILL_LAST_INTERVAL: 12.0691
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.5
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-08 Fri 23:34]
:END:
Una superficie [cerrada, orientable, conexa, y totalmente umbilical] es
[un plano o una esfera].

***** 4.4. Orientabilidad de superficies con curvatura siempre positiva
:PROPERTIES:
:ID:       fa4736f0-e81a-4a6f-a2d2-18dde905ac47
:END:
Una $S$ con curvatura de Gauss siempre positiva es orientable.

****** TODO Proof

****** Card                                                                                                :drill:
SCHEDULED: <2018-06-21 Thu>
:PROPERTIES:
:ID:       1ac1f904-1081-4bec-bee3-f7d5c234cc64
:DRILL_LAST_INTERVAL: 12.7555
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 5.0
:DRILL_EASE: 2.7
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-08 Fri 14:57]
:END:
Qué podemos decir de una superficie con curvatura de Gauss siempre
positiva.

******* Answer
Es orientable.  La curvatura y más concretamente el signo de las dos
curvaturas principales, nos dan un criterio para elegir una
orientación en cada entorno de forma que podemos crear una orientación
global.

***** 4.5. Teorema de Hilbert-Chern
:PROPERTIES:
:ID:       b4a8fa29-b6fe-4948-996d-39d57f574507
:END:
Si $S$ es orientable y existe $p_0 \in S$ donde ocurren /a la vez/,

 - $k_1$ tiene un mínimo local en $p_0$,
 - $k_2$ tiene un máximo local en $p_0$,
 - $K(p_0)>0$;

entonces $k_1(p_0)=k_2(p_0)$ y $p_0$ es umbilical.

****** Proof (Montiel-Ros)                                                                                 :extra:
***** 4.7. Teorema de Hilbert-Liebmann
Una superficie compacta y conexa con curvatura de Gauss constante es
una esfera.

****** Proof
Por compacidad, [[id:3e527821-5a65-4d06-b1c1-2508ef410b71][existen]] puntos elípticos y la curvatura es constante
positiva, [[id:fa4736f0-e81a-4a6f-a2d2-18dde905ac47][luego orientable]]. Sabemos que las curvaturas principales son
[[id:a111157d-1652-4d3a-b661-f5252e9e6126][continuas]]. Por Weierstrass, $k_1$ tendrá un mínimo que llamamos $p_0$. Como
$k_1(p)k_2(p) > 0$, ambas curvaturas conservarán el signo y tendrán el
mismo. Entonces $k_2(p) = c/k_1(p) \leq c/k_1(p_0) = k_2(p_0)$ y tenemos un
máximo. Aplicamos [[id:b4a8fa29-b6fe-4948-996d-39d57f574507][Hilbert-Chern]] para tener $p_0$ umbilical. Pero entonces,
usando que ambos son extremos absolutos,

\[
k_1(p_0) \leq k_1(p) \leq k_2(p) \leq k_2(p_0) = k_1(p_0).
\]

Una superficie orientable, conexa, compacta y totalmente umbilical debe
ser una esfera.

****** Card                                                                                                :drill:
SCHEDULED: <2018-07-08 Sun>
:PROPERTIES:
:ID:       fa02015c-e452-47cf-8f46-f1b195f491ec
:DRILL_LAST_INTERVAL: 8.7464
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.22
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-29 Fri 09:52]
:END:
Enuncia el Teorema de Hilbert-Liebmann.

******* Answer
Una superficie compacta y conexa con curvatura de Gauss constante es
una esfera.

****** Card                                                                                                :drill:
SCHEDULED: <2018-07-11 Wed>
:PROPERTIES:
:DRILL_CARD_TYPE: hide1cloze
:ID:       15fa8856-164a-4f43-aa45-cf8999f2fc4d
:DRILL_LAST_INTERVAL: 12.163
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.5
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-29 Fri 09:54]
:END:
Una superficie [compacta y conexa] con curvatura de Gauss constante es
una esfera.

***** 4.9. Bonnet: Cerrada conexa y curvatura de Gauss constante da una esfera
Una superficie cerrada y conexa con curvatura de Gauss constante *positiva* es
una esfera.

****** Card                                                                                              :nodrill:
SCHEDULED: <2018-07-11 Wed>
:PROPERTIES:
:ID:       e99468bd-c836-403e-8a9a-0d44f1a1475d
:DRILL_LAST_INTERVAL: 11.5349
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 2.333
:DRILL_EASE: 2.22
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-29 Fri 09:54]
:END:
Caso de Bonnet sobre Hilbert-Liebmann.

******* Answer
Una superficie cerrada y conexa con curvatura de Gauss constante
*positiva* es una esfera.

***** 4.10. Ovaloide
Un *ovaloide* es una superficie compacta, conexa y con curvatura de
Gauss positiva.

****** Card                                                                                                :drill:
SCHEDULED: <2018-06-19 Tue>
:PROPERTIES:
:ID:       74159b04-057a-45c8-887c-078abf6e0f75
:DRILL_LAST_INTERVAL: 11.2415
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 4
:DRILL_FAILURE_COUNT: 2
:DRILL_AVERAGE_QUALITY: 3.25
:DRILL_EASE: 2.7
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-08 Fri 23:33]
:END:
Definición de ovaloide.

******* Answer
Superficie compacta, conexa y con curvatura de Gauss positiva.

***** 4.10. Teorema de Jellet-Liebmann
Un ovaloide con curvatura media constante es una esfera.

****** TODO Proof

****** Card                                                                                                :drill:
SCHEDULED: <2018-07-05 Thu>
:PROPERTIES:
:DRILL_CARD_TYPE: hide1cloze
:ID:       548234b4-b011-42ee-977a-12c54726bfd2
:DRILL_LAST_INTERVAL: 8.2809
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 5
:DRILL_FAILURE_COUNT: 2
:DRILL_AVERAGE_QUALITY: 3.4
:DRILL_EASE: 2.56
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-27 Wed 13:21]
:END:
[Un ovaloide] con [curvatura *media* constante] es [una esfera].

****** Card                                                                                                :drill:
SCHEDULED: <2018-07-10 Tue>
:PROPERTIES:
:ID:       09612ba7-c6bf-4013-b75e-e9f5d29ab715
:DRILL_LAST_INTERVAL: 10.5797
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.5
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-29 Fri 09:52]
:END:
Enunciar el teorema de Jellet-Liebmann

******* Answer
Un ovaloide con curvatura media constante es una esfera.

***** 4.11. Teorema de Alexandrov
Una superficie compacta y conexa con curvatura media constante es una
esfera.

****** TODO Proof

****** Card                                                                                                :drill:
SCHEDULED: <2018-07-03 Tue>
:PROPERTIES:
:ID:       0d2139eb-35d3-43ff-8314-4389ae1a083f
:DRILL_LAST_INTERVAL: 4.1207
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 2.667
:DRILL_EASE: 2.22
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-29 Fri 10:25]
:END:
Enunciar el Teorema de Alexandrov.

******* Answer
Una superficie compacta y conexa con curvatura media constante es una
esfera.

****** Card                                                                                                :drill:
SCHEDULED: <2018-07-12 Thu>
:PROPERTIES:
:ID:       faad79ab-e6e6-4ba0-9542-6bdf774dacf9
:DRILL_LAST_INTERVAL: 13.2191
:DRILL_REPEATS_SINCE_FAIL: 3
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.5
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-29 Fri 09:55]
:END:
¿En qué se diferencian el Teorema de Jellet-Liebmann y el teorema de
Alexandrov?

******* Answer
Jellet-Liebmann pide, dentro de la definición de ovaloide, que la curvatura
de Gauss sea positiva en cada punto.

*Jellet-Liebmann:* Un ovaloide con curvatura media constante es una esfera.
*Alexandrov:* Una compacta y conexa con curvatura media constante es una esfera.

***** Ej.12. Curvatura media constante no nula
Una superficie conexa, cerrada de curvatura media constante no nula no
tiene por qué ser una esfera. El cilindro es un contraejemplo.

*** Tema 4. Geodésicas
*** Notas sueltas
**** Catenaria y paraboloide hiperbólico
¿En qué se diferencian la catenoide del paraboloide hiperbólico?

***** Answer
La catenoide es minimal no reglada, el paraboloide hiperbólico es
reglado no minimal.

*** Ejercicios
**** Ejercicios de clase
***** Ejercicio 20-Feb A
#+begin_statement
Probar que no existe un plano afín conteniendo a la traza de
una hélice circular de eje vertical.
#+end_statement

Si un plano contiene a dos puntos, contiene a la recta entre ellos,
luego en particular el plano contiene a todos los puntos de la
forma $(\sin(t), \cos(t), k)$.

En particular, contendría a un círculo $(\sin(t), \cos(t), 0)$, por
tanto a tres de sus puntos y debería ser el plano que determinan
esos tres puntos, $L(x,y,0)$; pero también a $(1,0,1)$, por ejemplo,
lo que es imposible.

***** Ejercicio 20-Feb B
#+begin_statement
Probar que las rectas afines a la hélice forman un ángulo constante
con el eje z.
#+end_statement
**** Ejercicios apuntes 2
***** Ejercicio 1
Si fuera homeomorfa a abierto del plano, sería abierto, cerrado y
acotado del plano luego vacío.

***** Ejercicio 2
Se comprueban las propiedades de una [[id:061e98dc-b077-4e5d-a7fd-f114f6908ed5][parametrización]].

***** TODO Ejercicio 8
***** TODO Ejercicio 9

**** Relación Tema 1 [12/24]
***** DONE Ejercicio 1
***** DONE Ejercicio 2
***** DONE Ejercicio 3
***** DONE Ejercicio 4
***** TODO Ejercicio 5
***** DONE Ejercicio 6
***** DONE Ejercicio 7
***** DONE Ejercicio 8
***** TODO Ejercicio 9
***** TODO Ejercicio 10
***** DONE Ejercicio 11
La circunferencia osculatriz está en la dirección de la normal
con radio $1/k(s_0)$.

***** TODO Ejercicio 12
***** TODO Ejercicio 13
***** TODO Ejercicio 14
***** TODO Ejercicio 15
***** TODO Ejercicio 16
***** TODO Ejercicio 17
***** TODO Ejercicio 18
***** TODO Ejercicio 19
***** DONE Ejercicio 20
***** TODO Ejercicio 21
***** DONE Ejercicio 22
#+begin_statement
Sean $\alpha,\beta \colon I \to \mathbb{R}^3$ dos curvas p.p.a. tales que $k_{\beta}(s) = k_{\alpha}(s) > 0$ y $\tau_{\beta}(s) = -\tau_{\alpha}(s)$
para cada $s \in I$. Probar que existe un movimiento rígido inverso $\phi \colon \mathbb{R}^3 \to \mathbb{R}^3$ tal
que $\beta = \phi \circ \alpha$.
#+end_statement

Aplicamos simetría respecto de un plano a una de ellas, comprobamos que
se mantiene la curvatura y que cambia la torsión usando propiedades de
los determinantes. Aplicamos el Teorema fundamental.

***** DONE Ejercicio 23
#+begin_statement
Sea $\alpha \colon \mathbb{R} \to \mathbb{R}^2$ una curva plana p.p.a. Utilizar el teorema fundamental de
curvas en $\mathbb{R}^2$ para probar que, si la curvatura de $\alpha$ es una función par, entonces
la traza de $\alpha$ es simétrica con respecto a la recta afín normal $R$ de $\alpha$ en $s=0$.
#+end_statement

Tomamos la reparametrización $\beta(t) = \alpha(-t)$, que nos da una curva plana $\beta \colon \mathbb{R}\to\mathbb{R}^2$ 
que además es p.p.a., por tenerse $|\beta'(t)| = |-\alpha'(t)| = |\alpha'(t)| = 1$. Sabiendo que la
curvatura cambia de signo con reparametrizaciones decrecientes y que es una
función par, $k_{\beta}(t) = -k_{\alpha}(-t) = -k_{\alpha}(t)$.

Por otro lado, eligiendo un movimiento rígido inverso cualquiera, $\psi \colon \mathbb{R}^2 \to \mathbb{R}^2$, sabemos 
que $k_{\psi \circ \alpha}(t) = -k_{\alpha}(t) = k_{\beta}(t)$ y podemos aplicar el teorema fundamental de curvas
en el plano para obtener un movimiento rígido directo $\psi'$ tal que
$\psi' \circ \psi \circ \alpha = \beta$. En otras palabras, existe un movimiento rígido inverso $\phi$ tal
que $\phi\circ \alpha = \beta$, porque la composición de un movimiento rígido inverso con un
movimiento rígido directo cualquiera es un movimiento rígido inverso.

Ahora, si llamamos $\alpha(0) = p_0$, tenemos que $\phi(p_0) = p_0$, y al tener un punto
fijo sólo puede ser una simetría. Además, aplicando la regla de la cadena
en varias variables y siendo $\vec{\phi}$ la parte lineal de $\phi$, tenemos
\[\begin{aligned}
T_{\alpha}(0) &= \alpha'(0) = -\beta'(0) = -(\phi \circ \alpha)'(0) = - \mathrm{Jac}_{\phi}(\alpha(0)) (\alpha'(0))
\\&= -\vec{\phi}(\alpha'(0)) = -\vec{\phi}(T_{\alpha}(0))
\end{aligned}\]

por lo que el eje de simetría es perpendicular a $T_{\alpha}(0)$, que es no nulo por
regularidad, y es por tanto paralelo a $N_{\alpha}(0)$. El movimiento $\phi$ es una
simetría de eje paralelo a $N_{\alpha}(0)$ pasando por $p_0$.

Finalmente, si $q \in \alpha(\mathbb{R})$ entonces existe $s \in \mathbb{R}$ tal que $\alpha(s) = q$ y
tenemos que $\phi(q) = \phi(\alpha(s)) = \alpha(-s) \in \alpha(\mathbb{R})$.

***** DONE Ejercicio 24
**** Relación Tema 2 ([[~/pdf/Rosales_Relaci%C3%B3n%20de%20ejercicios%202.pdf][PDF]]) [6/20]
***** TODO Ejercicio 1
***** DONE Ejercicio 2
***** DONE Ejercicio 3
***** TODO Ejercicio 4
***** DONE Ejercicio 5
***** DONE Ejercicio 6
***** DONE Ejercicio 7
***** TODO Ejercicio 8
***** TODO Ejercicio 9
***** TODO Ejercicio 10
***** DONE Ejercicio 11
***** TODO Ejercicio 12
***** TODO Ejercicio 13
***** TODO Ejercicio 14
***** TODO Ejercicio 15
***** TODO Ejercicio 16
***** TODO Ejercicio 17
***** TODO Ejercicio 18
***** TODO Ejercicio 19
***** TODO Ejercicio 20
**** Relación Tema 3 ([[file:~/pdf/rosales_relaci%C3%B3n_de_ejercicios_3.pdf][PDF]])
***** Ejercicio 1                                                                                           :drill:
:PROPERTIES:
:ID:       4ba4f439-8f53-4266-8342-8072e3feb0e4
:END:
¿Qué debe cumplir la curvatura de Gauss $K$ para que la aplicación de
Gauss $N$ sea difeomorfismo local?

****** Answer
Ser distinta de cero en todo punto, $K(p) \neq 0$.

***** Ejercicio 7                                                                                           :drill:
:PROPERTIES:
:ID:       65c8bdaa-f028-4e0c-ac37-6f31cd1a277d
:END:
¿Cómo afecta a las curvaturas principales la homotecia de una superficie?

******* Answer
La homotecia $\phi(p) = \lambda p$ cambia las curvaturas a ${\tilde k}_i(p) = k_i(p)/\lambda$.

***** Ejercicio 11
¿Qué sabemos de la aplicación de Gauss $N \colon S \to \mathbb{S}^2$ de un ovaloide?

****** Answer
Es sobreyectiva.  Se puede ver que es difeomorfismo local luego
abierta y cerrada por ser continua de compacto a Hausdorff. La
conexión da la sobreyectividad.

***** Ejercicio 22
#+begin_statement
Supongamos que las curvaturas principales de un ovaloide $S$
satisfacen $k_2 = f(k_1)$, donde $f \colon \mathbb{R}\to \mathbb{R}$ es una función decreciente.
Probar que $S$ es una esfera. Deducir que

 - un ovaloide con la propiedad de que $H/K$ es constante es
   necesariamente una esfera;

 - un ovaloide con una de sus curvaturas principales constante
   es una esfera.
#+end_statement

Un ovaloide es una superficie compacta, conexa y con curvatura de
Gauss positiva en cada punto. Sabemos que una superficie con curvatura
de Gauss positiva en cada punto es orientable, por lo que los
ovaloides son orientables. Consideramos una aplicación de Gauss
$N\colon S \to \mathbb{S}^2$ fijada.

Por otro lado, las curvaturas principales en una superficie orientable
son continuas. Por Teorema de Weierstrass, la función continua $k_1$ tendrá
un mínimo absoluto en el compacto $S$, en un punto que llamamos $p_0$. Usamos que $f$ es
decreciente para comprobar que $k_2$ tiene un máximo absoluto en $p_0$, ya que
para cualquier $p \in S$ tenemos que $k_1(p) \geq k_1(p_0)$ y por tanto,
\[
k_2(p) = f(k_1(p)) \leq f(k_1(p_0)) = k_2(p_0).
\]
Nótese que un razonamiento similar se podría realizar si tuviéramos
la condición $k_1 = f(k_2)$ para $f$ decreciente, en lugar de la condición del
enunciado. Podríamos tomar $p_0$ como el máximo de $k_2$ en el 
compacto $S$ y comprobar que $k_1$ tiene un mínimo absoluto en él ya que
para cualquier $p \in S$ tendríamos que $k_2(p) \leq k_2(p_0)$ y por tanto,
\[
k_{1}(p) = f(k_2(p)) \geq f(k_2(p_0)) = k_1(p_0).
\]

En cualquiera de estos dos casos podemos aplicar el Teorema de Hilbert-Chern,
sabiendo que $k_1$ tiene un mínimo global (y, en particular, local) en $p_0$; que $k_2$ tiene un máximo
global (y, en particular, local) en $p_0$; y que por definición de ovaloide,
$K(p_0) > 0$. Tenemos que $p_0$ es así un punto umbilical. Veamos que esto
implica que la superficie debe ser totalmente umbilical, ya que, para
cualquier $p \in S$, se tiene
\[
k_1(p_0) \leq k_1(p) \leq k_2(p) \leq k_2(p_0) = k_1(p_0).
\]
Por último, aplicamos que toda superficie orientable, conexa, compacta
y totalmente umbilical es una esfera.

 - Si $H(p)/K(p) = c$, tenemos que $k_1(p) + (1 - 2ck_1(p))k_2(p) = 0$, y como
   ninguna de las curvaturas principales puede ser nula en un ovaloide
   porque tiene curvatura de Gauss positiva, sabemos en particular que
   $1 - 2ck_1(p) \neq 0$ para cualquier $p \in S$. Así, si definimos $f(x) = x / (1 - 2cx)$, que es una
   función definida en $\mathbb{R} - \left\{ 1/2c \right\}$, diferenciable por construcción, y
   decreciente por tenerse $f'(x) = -1/(1-2cx)^2 < 0$, estamos en las
   condiciones del enunciado, con $k_2 = f(k_1)$.

 - En caso de que $k_2$ fuera constantemente $c$, tendríamos $k_2 = f(k_1)$ para
   la función $f(x) = c$, que es decreciente, y volveríamos a estar en
   las condiciones del enunciado.  En caso de que $k_1$ fuera constantemente $c$,
   podemos aplicar las condiciones del caso $k_1 = f(k_2)$ que 
   hemos estudiado antes, tomando de nuevo $f(x) = c$.

**** Repaso final
 - [X] 1
 - [X] 2
 - [X] 3
 - [X] 4
 - [X] 5
 - [X] 6
 - [X] 7
 - [X] 8
 - [X] 9
 - [X] 10
 - [X] 11
 - [X] 12
 - [X] 13
 - [X] 14
 - [X] 15
 - [ ] 16 (ver página)
 - [X] 17
 - [X] 18
 - [X] 19
 - [X] 20
 - [X] 21
 - [X] 22
 - [X] 23
 - [X] 24

** Modelos avanzados de computación
Serafín Morales
smc@decsai.ugr.es
decsai.ugr.es

*** Presentación
L ⊂ NL ⊂ P ⊂ NP ⊂ PSPACE

*** Tema 1: Máquinas de Turing. Funciones y lenguajes calculables
**** Definición, lenguajes calculables
***** Definición de máquina de Turing                                                                       :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       39340ed9-dafe-4bdc-8d65-a3d02950185a
:DRILL_LAST_INTERVAL: 3.7999
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 11:41]
:END:
Define máquina de Turing.

****** Answer
Séptupla,

 * Q conjunto finito de estados,
 * A alfabeto de entrada,
 * B alfabeto de símbolos de la cinta, A ⊂ B,
 * δ función de transición, δ : Q × B → Q × B × {L,R},
 * q₀ estado inicial,
 * # símbolo blanco,
 * F conjunto de estados finales.
 
***** Configuración de una máquina de Turing                                                                :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       b6602529-dd6d-4ba1-a691-9aa72482fb60
:DRILL_LAST_INTERVAL: 3.6643
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 11:59]
:END:
Configuración de una máquina de Turing.

****** Answer
Tripleta de estado y representación finita de las cintas a ambos
lados, (q,w₁,w₂). Nótese que w₂ contiene el cabezal.

***** Lenguaje aceptado por una máquina de Turing                                                           :drill:
SCHEDULED: <2018-06-20 Wed>
:PROPERTIES:
:ID:       0f58d3ce-5c70-46c8-b6ba-a0ead31d57ec
:DRILL_LAST_INTERVAL: 3.1983
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-17 Sun 21:40]
:END:
Lenguaje aceptado por una máquina de Turing.

****** Answer
Si M es una máquina de Turing, L(M) son las palabras tales que desde
su configuración inicial se puede llegar mediante pasos de cálculo a
una configuración en un estado final.

***** Lenguaje recursivamente enumerable                                                                    :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       9f3567c6-561c-4ed2-ab41-7d27ae8c26bd
:DRILL_LAST_INTERVAL: 4.0499
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 01:12]
:END:
Lenguaje recursivamente enumerable.

****** Answer
Existe una máquina de Turing que lo tiene como lenguaje aceptado.

***** Parada en máquinas de Turing                                                                          :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       04db91b1-d990-464a-81c0-22c9025f0c3d
:DRILL_LAST_INTERVAL: 4.2726
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 12:03]
:END:
¿Cuándo para una máquina de Turing?¿Cómo afecta a la clase de lenguajes
aceptados?

****** Answer
Una máquina para si no hay transiciones definidas. Podríamos decir que
una máquina de Turing acepta un lenguaje si para en esas entradas; la
clase de lenguajes recursivamente enumerables permanecería invariante.

***** Lenguaje recursivo                                                                                    :drill:
SCHEDULED: <2018-06-21 Thu>
:PROPERTIES:
:ID:       dd51cb5b-aea5-4a75-944b-59cdba1e5dea
:DRILL_LAST_INTERVAL: 4.3031
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-17 Sun 21:40]
:END:
Lenguaje recursivo.

****** Answer
Un lenguaje es recursivo si lo acepta una máquina de Turing que
siempre para.

**** Programación en máquinas de Turing
***** Variantes                                                                                             :drill:
SCHEDULED: <2018-06-21 Thu>
:PROPERTIES:
:ID:       81ba498a-c551-4979-9e47-69a7c0400edc
:DRILL_LAST_INTERVAL: 4.0934
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-17 Sun 21:44]
:END:
¿Qué extensiones aplicamos a la MT básica?

****** Answer

 * MTs que se quedan en la misma posición tras un paso.
 * MTs con múltiples cintas.
 * MTs no deterministas.
 * MTs con cintas semiilimitadas.

***** Extensión: quedarse en la misma posición                                                              :drill:
SCHEDULED: <2018-06-23 Sat>
:PROPERTIES:
:ID:       603ab8e1-c603-4890-86f3-bffb5160e175
:DRILL_LAST_INTERVAL: 4.7012
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 5.0
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 01:05]
:END:
Extensión de máquina de Turing: ¿por qué podemos quedarnos en la misma
posición en una máquina de Turing?

****** Answer
Podríamos tener un estado asociado a cualquier estado de la máquina
original que simplemente se moviera a la derecha y luego pasara al
nuevo estado. Las transiciones se harían en dos pasos.

***** Extensión: múltiples pistas                                                                           :drill:
SCHEDULED: <2018-06-21 Thu>
:PROPERTIES:
:ID:       266225bf-f436-45d6-85d6-60ec7719bfa1
:DRILL_LAST_INTERVAL: 4.0145
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 5.0
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-17 Sun 21:44]
:END:
¿En qué consiste extender con múltiples pistas una MT?

****** Answer
Consideramos un alfabeto de cinta producto para simular que escribimos
sobre varias pistas paralelas.

***** Extensión: múltiples cintas                                                                           :drill:
SCHEDULED: <2018-06-23 Sat>
:PROPERTIES:
:ID:       3bf69a7c-0ddd-4f74-b4aa-03ffa5d20ed3
:DRILL_LAST_INTERVAL: 5.2668
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 11:57]
:END:
¿En qué consiste la extensión en múltiples cintas?

****** Answer
Consideramos k cintas ilimitadas independientes. La configuración de
la máquina debe almacenar una configuración en cada una de ellas. Los
movimientos deben especificarse en cada una de las cintas.

***** Lenguaje aceptado por múltiples cintas                                                                :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       f43ba876-37eb-4ea2-baa5-8d2277addf4e
:DRILL_LAST_INTERVAL: 4.3873
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 11:55]
:END:
Lenguaje aceptado por una máquina de múltiples cintas.

****** Answer
Conjunto de palabras tales que empezando en una configuración en la
que está la palabra en la primera cinta y el resto vacías, termina en
aceptación.

***** Función calculada por múltiples cintas                                                                :drill:
SCHEDULED: <2018-06-21 Thu>
:PROPERTIES:
:ID:       654e80ad-dd9e-4311-9401-aa581dfc4d2e
:DRILL_LAST_INTERVAL: 3.9358
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-17 Sun 21:33]
:END:
Función calculada por una máquina de múltiples cintas.

****** Answer
Para una función f : D → B*.  Comienza con la entrada u ∈ D en la
primera cinta y debe acabar con la f(u) en la última cinta
aceptando. Si u ∉ D, no debe parar.

***** Equivalencia con varias cintas                                                                        :drill:
SCHEDULED: <2018-06-23 Sat>
:PROPERTIES:
:ID:       0d9c9913-add3-402d-a92e-e6f712f64144
:DRILL_LAST_INTERVAL: 5.1175
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 11:23]
:END:
Todo lenguaje aceptado por una máquina con varias cintas es
recursivamente enumerable, ¿por qué?

****** Answer
Para una máquina con k cintas, podemos tomar una máquina con 2k
pistas, usando las impares para señalar con un símbolo el cabezal
de cada una de las máquinas de varias cintas.

Luego necesitaríamos también poder almacenar el estado concreto de
todo antes de ejecutar un paso. Para eso podemos /memorizar/ símbolos.

***** Complejidad en tiempo de simular múltiples cintas                                                     :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       6ac42f2a-21b1-4248-af2a-b3815ad0c6ee
:DRILL_LAST_INTERVAL: 4.2694
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 2.5
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 12:34]
:END:
Tiempo empleado por una MT en simular n pasos de una MT con k cintas.

****** Answer
O(n²)

**** Máquinas no deterministas
***** Diferencia                                                                                            :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       54820fae-a7fc-4d43-bef5-fe081fd93eb7
:DRILL_LAST_INTERVAL: 3.953
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 00:52]
:END:
Diferencia entre máquinas de Turing deterimnistas y no deterministas.

****** Answer
La función de transición es en máquinas no deterministas capaz de
devolver un conjunto finito de tripletas Q × B × {L,R}.

***** Equivalencia no deterministas                                                                         :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       c94c66f6-9a92-4509-88be-297158c2d003
:DRILL_LAST_INTERVAL: 4.6741
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-17 Sun 21:40]
:END:
Un lenguaje aceptado por una no determinista es recursivamente
enumerable, ¿por qué?

****** Answer
Podemos usar dos cintas para hacer búsqueda en anchura con en el
espacio de estados. En la primera guardamos las configuraciones
(q,u,v) y en la segunda simulamos un paso de cada una de ellas.

**** Codificación de cadenas
***** Codificar un alfabeto en naturales                                                                    :drill:
SCHEDULED: <2018-06-23 Sat>
:PROPERTIES:
:ID:       5481ba4a-6ae4-4651-a9ef-956b407c640c
:DRILL_LAST_INTERVAL: 4.754
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.5
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 23:19]
:END:
Da la aplicación $Z \colon A^{\ast} \to \mathbb{N}$ que codifica
palabras de $A$ como naturales.

****** Answer

\[
Z(a_{i_k}\dots a_{i_1}) = \sum_{j=1}^k i_jn^{j-1}
\]

***** Alfabetos intercambiables                                                                             :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       adbb76a6-9410-4032-981b-56040dbd9461
:DRILL_LAST_INTERVAL: 4.0993
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 5.0
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 23:14]
:END:
¿Por qué los distintos alfabetos son intercambiables?

****** Answer
Tenemos biyecciones de cualquier alfabeto hacia y desde los naturales.

**** Propiedades de lenguajes recursivos
***** Lenguaje de diagonalización                                                                           :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       3ba75eca-17b0-41ac-ad97-95d24c8a298e
:DRILL_LAST_INTERVAL: 3.948
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 00:52]
:END:
Define el lenguaje de diagonalización. ¿Qué clase de lenguaje es?

****** Answer
w ∈ Ld si y sólo si la MT cuya codificación es w no acepta w.  No es
recursivamente enumerable, la existencia de una MT que lo aceptara
lleva a contradicción.

***** Lenguaje y complementario recursivamente enumerables                                                  :drill:
SCHEDULED: <2018-06-21 Thu>
:PROPERTIES:
:ID:       0eb33063-64eb-48e2-a0c3-46183a934dfb
:DRILL_LAST_INTERVAL: 3.933
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-17 Sun 21:36]
:END:
Si $L$ y su complementario $\overline{L}$ son recursivamente enumerables, entonces $L$ es
recursivo. ¿Por qué?

****** Answer
Podemos construir una máquina producto de la que acepta L y la que
acepta el complementario y ejecutarla en paralelo, cuando termine en
alguno de los dos sabremos si aceptar o no. Nótese que siempre termina
porque una palabra cualquiera está en L o en su complementario.

***** Lenguaje universal                                                                                    :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       8a7e2c5e-b1d2-458f-b17e-263d57d63d7f
:DRILL_LAST_INTERVAL: 3.6692
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 11:07]
:END:
Define el lenguaje universal. ¿Qué clase de lenguaje es?

****** Answer
El lenguaje universal consta de las parejas (M,w) donde M es una
máquina que acepta w. Es recursivamente enumerable (simulación), pero
no recursivo (por reducción al absurdo con el lenguaje de
diagonalización).

**** Teorema de Rice
***** Propiedad trivial                                                                                     :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       917822bd-6044-48eb-9263-2a1e758dd741
:DRILL_LAST_INTERVAL: 4.3438
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 5.0
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 12:15]
:END:
Propiedad trivial.

****** Answer
Una propiedad de los lenguajes r.e. es trivial si todos los r.e. la
verifican o si no la verifica ninguno.

***** Teorema de Rice                                                                                       :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       67e74b42-e272-402d-a582-ee7ba4a048c4
:DRILL_LAST_INTERVAL: 3.8979
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 11:05]
:END:
Enuncia el Teorema de Rice.

****** Answer
Toda propiedad no trivial sobre los lenguajes r.e. es indecidible.
(No trivial quiere decir que existe un r.e. que no la cumple y un r.e.
que la cumple)

***** Demostración de Rice                                                                                  :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       79eb42ef-24f0-483b-a753-61629f1a5fbd
:DRILL_LAST_INTERVAL: 3.8738
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 23:10]
:END:
Demuestra el Teorema de Rice.

****** Answer
Podemos suponer s.p.g. que el vacío no cumple la propiedad y $L$, con
una $M_L$ que lo reconoce, sí.  Reducimos el lenguaje universal a el
reconocer esta propiedad. Si tenemos (M,w), creamos una máquina que
empieza simulando M sobre w; si acepta, toma su entrada y simula $M_L$
sobre ella. Comprobamos si el lenguaje de esta máquina creada cumple
la propiedad.

Si la cumple, entonces es porque es $L$ y (M,w) ha aceptado; en
cualquier otro caso sería el vacío y no cumpliría la propiedad.

**** Problema de las correspondencias de Post
***** Problema de las correspondencias                                                                      :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       5c9b3a6b-ba4a-450f-8e67-593ec234132f
:DRILL_LAST_INTERVAL: 3.7513
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 5.0
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 23:16]
:END:
Enuncia el problema de las correspondencias de Post.

****** Answer
Dadas dos listas w₁,...,wₖ y u₁,...,uₖ de palabras sobre A, determinar
si existe una secuencia de índices tal que

\[
w_{i_1}\dots w_{i_m} = u_{i_1}\dots u_{i_m}.
\]

Podemos pensar cada pareja como un bloque de construcción, debemos
conseguir la misma palabra en las dos filas.

|--------|
| ( wᵢ ) |
|--------|
| ( uᵢ ) |
|--------|

***** Problema de las correspondencias (versión modificada)                                                 :drill:
SCHEDULED: <2018-06-24 Sun>
:PROPERTIES:
:ID:       a524dfd5-8401-4e1d-9709-572ac9927d67
:DRILL_LAST_INTERVAL: 5.6026
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 5.0
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 23:13]
:END:
En qué se diferencia la versión modificada del problema de las
correspondencias de Post.

****** Answer
Se fija un bloque por el que se debe comenzar y las palabras son todas
no vacías.

***** Reducción: Lenguaje universal ∝ Post modificado (2 símbolos)                                          :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       6c282ced-298b-400f-ad11-9e3192a99ffd
:DRILL_LAST_INTERVAL: 4.38
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 5.0
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 23:14]
:END:
El problema de las correspondencias de Post modificado con al menos
dos símbolos es indecidible, ¿cómo reducimos el lenguaje universal a
él?

****** Answer
Dada (M,w), tomamos un alfabeto con los estados, un símbolo adicional
⋆ y símbolos de la cinta y empezamos por el bloque siguiente.

|---------------|
| (     ⋆     ) |
|---------------|
| (⋆q₀a₁...aₙ⋆) |
|---------------|

Cada transición a derecha da un bloque que mete un estado arriba a
cambio de pasarlo abajo.

Cada transición a izquierda permite meter ~cqa~ arriba para cualquier
~c~.

Permitimos meter cualquier bloque doble para ~a~ y ~⋆~.

|---|
| a |
|---|
| a |
|---|

Permitimos que cualquier estado final ~qᵤ~ meta símbolos cualesquiera
arriba.

|-----| 
| aqᵤ |
|-----|
| qᵤ  |
|-----|

|-----|
| qᵤa |
|-----|
| qᵤ  |
|-----|

***** Reducción: PCP(modificado) ∝ PCP                                                                      :drill:
SCHEDULED: <2018-06-24 Sun>
:PROPERTIES:
:ID:       d361417f-abdf-430e-a6e6-914f3753f37b
:DRILL_LAST_INTERVAL: 5.5806
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 5.0
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 23:15]
:END:
¿Cómo se reduce el problema de Post modificado al problema de Post
original?

****** Answer
Incluimos dos símbolos nuevos y los usamos para forzar empezar por un
bloque dado y acabar corrigiendo esto al final.

◆u₁  | ... |◆uᵢ| ... |◆■
◆v₁◆ | ... |vᵢ◆| ... |■ 

**** Problemas sobre gramáticas
***** Saber si una gramática independiente del contexto es ambigua                                          :drill:
SCHEDULED: <2018-06-21 Thu>
:PROPERTIES:
:ID:       8e9a1f00-5025-4949-ad9b-87f75da9253f
:DRILL_LAST_INTERVAL: 4.0358
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-17 Sun 21:35]
:END:
¿Qué clase de problema es saber si una gramática independiente del
contexto es ambigua?

****** Answer
Semidecidible. Puede reducirse desde el problema de las
correspondencias de Post para verse que no es decidible; pero además
puede elegirse de forma no determinista una palabra y construir sus
árboles de derivación para ver si es ambigua.

*** Tema 2: Otros modelos de cálculo. Tesis de Church-Turing
**** Lenguaje Post Turing
***** Instrucciones de un lenguaje Post Turing                                                              :drill:
SCHEDULED: <2018-06-21 Thu>
:PROPERTIES:
:ID:       c27bbf93-29b1-4cc7-8ba7-f26c73099c12
:DRILL_LAST_INTERVAL: 3.9073
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-17 Sun 21:35]
:END:
Da las instrucciones de un lenguaje Post Turing. Aparte de ellas
existirán las etiquetas.

****** Answer
PRINT a, imprime el símbolo a.
IF a GOTO l, si el símbolo en cinta es a va a la etiqueta l.
RIGHT, mueve cabezal a izquierda.
LEFT, mueve cabezal a derecha.
HALT, termina y acepta.

***** Lenguaje aceptado por un programa Post Turing                                                         :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       e17ee57b-9e26-4f42-ad10-2679ea7ec7c2
:DRILL_LAST_INTERVAL: 3.8823
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 11:44]
:END:
Lenguaje aceptado por un programa Post Turing.

****** Answer
Cadenas del alfabeto de entrada que comenzando en la configuración
inicial llegan a la instrucción HALT.

***** Función calculada                                                                                     :drill:
SCHEDULED: <2018-06-21 Thu>
:PROPERTIES:
:ID:       116932ec-cde9-408e-88bd-bc9496cf805a
:DRILL_LAST_INTERVAL: 4.0439
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-17 Sun 21:33]
:END:
Función calculada por un programa Post Turing.

****** Answer
f : D ⊂ A* → B* es parcialmente calculable por un Post Turing si para
todo u ∈ A*, el programa llega a HALT con f(u) en la cinta si u ∈ D y
no termina si u ∉ D.

**** Programas con variables
***** Instrucciones de programas con variables                                                              :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       bd3dbf5c-b67e-40c3-8f8c-edd14fb2576e
:DRILL_LAST_INTERVAL: 4.1953
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 11:55]
:END:
Da las instrucciones de un programa con variables. Aparte de ellas
existirá una variable X de entrada, una variable Y de salida y 
un conjunto finito de variables de trabajo.

****** Answer
A ← aA, añade el símbolo a al principio de A.
A ← A-, elimina el último símbolo de A si no es vacía.
IF A ENDS a GOTO L, si A termina en a, va a la etiqueta L.
HALT.

***** Macros                                                                                                :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       ebd0c850-a43e-4d3f-aee8-8728caec011b
:DRILL_LAST_INTERVAL: 3.9391
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 2.5
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 11:33]
:END:
Di al menos tres macros que definimos sobre un lenguaje con variables.
Las instrucciones básicas son

  A ← aA
  A ← A-
  IF A ENDS a GOTO L
  HALT

****** Answer

  IF V ≠ ε GOTO L
  V ← ε
  GOTO L
  IF V ENDS aᵢ GOTO Lᵢ
  U ← V

***** Entradas múltiples                                                                                    :drill:
SCHEDULED: <2018-06-23 Sat>
:PROPERTIES:
:ID:       a5ef48ff-4337-4597-8ff2-6c45fb731537
:DRILL_LAST_INTERVAL: 5.3464
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 5.0
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 12:02]
:END:
Cómo tratar con entradas múltiples en programas Post Turing y en
programas con variables.

****** Answer
Dos opciones

 1. Se puede hacer depender de un parámetro y separar los argumentos
    por un símbolo delimitador.
 2. En variables, se pueden asumir varias variables de entrada.

**** Tesis de Church-Turing
***** Tesis de Church-Turing                                                                                :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       3273f000-d5c6-40e5-9aee-1a14e2f5c946
:DRILL_LAST_INTERVAL: 3.6825
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 00:57]
:END:
Enuncia la Tesis de Church-Turing.

****** Answer
Toda función efectivamente calculable puede ser calculada por una
Máquina de Turing.

*** Tema 3: Clases de complejidad
**** Problemas de ejemplo
***** Flujo máximo                                                                                          :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       74b107e3-61c6-4f26-a1ee-ac17b759ea4a
:DRILL_LAST_INTERVAL: 4.2788
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 5.0
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 20:27]
:END:
Describir el problema de flujo máximo. ¿En qué clase de complejidad
está?

****** Answer
Dado un grafo dirigido con capacidad de flujo en cada arista, un
origen y un destino, calcular el flujo máximo posible entre origen y
destino.

Usando *Ford-Fulkenson* con elección del camino mínimo sabemos que
está en P.

***** Problema de colorear un grafo                                                                         :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       899c69c7-d671-4abf-b00d-51a44e1ebb53
:DRILL_LAST_INTERVAL: 3.87
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 20:35]
:END:
Describir el problema de colorear un grafo (decisión). ¿En qué clase
de complejidad está?

****** Answer
Dado un grafo y un entero K, encontrar una K-coloración.

Es NP, no se sabe que esté en P.

***** Problema de las parejas                                                                               :drill:
SCHEDULED: <2018-06-21 Thu>
:PROPERTIES:
:ID:       917ceb77-cd0d-405a-982f-ca2ef35118de
:DRILL_LAST_INTERVAL: 3.3086
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 20:21]
:END:
Describir el problema de las parejas. Clase de complejidad.

****** Answer
Damos dos conjuntos del mismo tamaño y una lista de posibles parejas,
decidir si existe un subconjunto de esa lista de parejas que deje a
cada elemento emparejado únicamente.

Está en P. Se reduce al problema del flujo máximo.

***** Reducción: parejas ∝ flujo máximo                                                                     :drill:
SCHEDULED: <2018-06-21 Thu>
:PROPERTIES:
:ID:       fdc49819-dcbc-4d94-901b-b39736c0c4f1
:DRILL_LAST_INTERVAL: 3.4501
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 5.0
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 23:19]
:END:
¿Cómo se reduce el problema de las parejas al flujo máximo?

****** Answer
Se coloca el source conectado a la primera fila, y el target a la
segunda. Si hay m parejas, pedimos flujo m.

**** Definiciones de complejidad
***** Complejidad                                                                                           :drill:
SCHEDULED: <2018-06-21 Thu>
:PROPERTIES:
:ID:       26de031f-c920-4379-aceb-3e40f7b56d9b
:DRILL_LAST_INTERVAL: 4.4256
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-17 Sun 17:14]
:END:
¿Cuándo es una máquina de Turing de complejidad $f(n)$?
(Puede ser en tiempo o en espacio)

****** Answer
Una máquina de Turing es *de complejidad* $f(n)$ si para cualquier
entrada de longitud $n$, acepta o rechaza en menos de $f(n)$ unidades.

 * Unidades de complejidad en tiempo: pasos de cálculo.
 * Unidades de complejidad en espacio: casillas en la cinta.

***** Complejidad de un lenguaje                                                                            :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       da792daa-e620-470b-a4af-517035c0adb1
:DRILL_LAST_INTERVAL: 4.9669
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-17 Sun 17:21]
:END:
¿Cuándo es un lenguaje de complejidad $f(n)$?

****** Answer
Un lenguaje es de complejidad $f(n)$ si existe una máquina de Turing
de complejidad $f(n)$ que lo acepta.

 * Unidades de complejidad en tiempo: pasos de cálculo.
 * Unidades de complejidad en espacio: casillas en la cinta.

***** Teorema: lenguaje aceptado por máquina de varias cintas                                               :drill:
SCHEDULED: <2018-06-21 Thu>
:PROPERTIES:
:ID:       c219368f-6cd3-437a-a71e-33c07aa9c221
:DRILL_LAST_INTERVAL: 3.7394
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-17 Sun 21:43]
:END:
Si L es aceptado por una Máquina de k cintas, existe una Máquina
con k+1 cintas aceptando el mismo lenguaje en tiempo...

****** Answer

\[
\frac{1}{2^m}t(n) + n
\]

para cualquier $m$.

***** Complejidad en problemas de grafos                                                                    :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       f81aa3e0-f142-42df-b558-e31016eea522
:DRILL_LAST_INTERVAL: 5.0987
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-17 Sun 17:46]
:END:
Por qué da igual la representación para estudiar la complejidad
polinómica de un problema en grafos.

****** Answer
La longitud de entrada $n$ y los vértices $v$ cumplen que $v \leq n \leq v^3$.

***** Reglas para medir complejidad en espacio                                                              :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       b3627e60-6650-41a9-b883-1eb7d4b8d31e
:DRILL_LAST_INTERVAL: 3.7348
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 00:57]
:END:
Da las reglas para medir el número de unidades que se tienen en cuenta
en una máquina de Turing.

****** Answer

 * Se cuentan las casillas sobre las que se pasa o escribe.
 * Si nunca se escribe sobre entrada, no se cuenta.
 * Si nunca se vuelve atrás en salida, no se cuenta.

***** Búsqueda de caminos en grafos                                                                         :drill:
SCHEDULED: <2018-06-21 Thu>
:PROPERTIES:
:ID:       d1e1b612-c28a-402c-8e81-c0d664d4cb2f
:DRILL_LAST_INTERVAL: 3.9712
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 1.5
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-17 Sun 17:20]
:END:
Buscamos un camino entre dos nodos de un grafo. ¿Qué complejidad
en espacio tiene?

****** Answer
*Teorema de Savitch*, su complejidad es del orden ${\cal O}(\log^2(n))$,
sobre número de nodos. Se resuelve

CAMINO(x,y,i), existencia de camino de longitud ≤2ⁱ entre x,y.

Nótese que era trivial saber que los algoritmos de búsqueda en
grafos nos dan tiempo polinómico y espacio lineal, este teorema
lo mejora.

***** TODO Búsqueda de caminos en grafos: espacio no determinista
***** Complejidad no determinista                                                                           :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       02b8cbdb-6370-4944-8b4e-373ea5c98984
:DRILL_LAST_INTERVAL: 4.2671
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 11:48]
:END:
¿Cuándo es una máquina de Turing *no determinista* de complejidad
$f(n)$?

****** Answer
Una máquina de Turing es *de complejidad* $f(n)$ si para cualquier
entrada de longitud $n$, todas las posibles opciones de cálculo 
aceptan o rechazan en menos de $f(n)$ pasos.

**** Clases de complejidad básicas
***** Clases de complejidad básicas                                                                         :drill:
SCHEDULED: <2018-06-21 Thu>
:PROPERTIES:
:ID:       071896e8-410d-47ee-8e98-a82d929ee204
:DRILL_LAST_INTERVAL: 4.219
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-17 Sun 17:21]
:END:
Define

 * $\mathrm{TIEMPO}(f)$
 * $\mathrm{ESPACIO}(f)$
 * $\mathrm{NTIEMPO}(f)$
 * $\mathrm{NESPACIO}(f)$
 
****** Answer

 * $\mathrm{TIEMPO}(f)$, aceptados por una determinista en tiempo ${\cal O}(f(n))$.
 * $\mathrm{ESPACIO}(f)$, aceptados por una determinista en espacio ${\cal O}(f(n))$.
 * $\mathrm{NTIEMPO}(f)$, aceptados por una no determinista en tiempo ${\cal O}(f(n))$.
 * $\mathrm{NESPACIO}(f)$, aceptados por una no determinista en espacio ${\cal O}(f(n))$.

***** Clase L                                                                                               :drill:
SCHEDULED: <2018-06-21 Thu>
:PROPERTIES:
:ID:       2a26cd67-4005-46bf-aa0c-b3dce484dde8
:DRILL_LAST_INTERVAL: 4.3954
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-17 Sun 17:11]
:END:
Define $\mathrm{L}$.

****** Answer
Clase de espacio logarítmico determinista.

\[
\mathrm{L} = \mathrm{ESPACIO}(\log(n))
\]

***** Clase NL                                                                                              :drill:
SCHEDULED: <2018-06-21 Thu>
:PROPERTIES:
:ID:       588e49c9-347d-4e55-9e31-c1c6a628c1c4
:DRILL_LAST_INTERVAL: 4.0935
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-17 Sun 17:07]
:END:
Define NL.

****** Answer
Clase de espacio logarítmico no determinista.

NL = NESPACIO(log(n))

***** Clase P                                                                                               :drill:
SCHEDULED: <2018-06-21 Thu>
:PROPERTIES:
:ID:       c3fd1fcb-f4f1-49ba-b38d-cd0a4786a88d
:DRILL_LAST_INTERVAL: 4.3611
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-17 Sun 17:39]
:END:
Define $\mathrm{P}$.

****** Answer
Clase de tiempo polinómico.

\[
\mathrm{P} = \bigcup_{j > 0} \mathrm{TIEMPO}(n^j)
\]

***** Clase NP                                                                                              :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       beae6842-f842-43a1-a01a-0cb9ede8bf41
:DRILL_LAST_INTERVAL: 3.9523
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 11:28]
:END:
Define $\mathrm{NP}$.

****** Answer
Clase de tiempo polinómico no determinista.

\[
\mathrm{NP} = \bigcup_{j > 0} \mathrm{NTIEMPO}(n^j)
\]

***** Clase PESPACIO                                                                                        :drill:
SCHEDULED: <2018-06-21 Thu>
:PROPERTIES:
:ID:       a22787ec-6163-41e3-97ec-3a03e316d1cf
:DRILL_LAST_INTERVAL: 4.0559
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 5.0
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-17 Sun 17:10]
:END:
Define $\mathrm{PSPACE}$.

****** Answer
Clase de espacio polinómico determinista.

\[
\mathrm{PSPACE} = \bigcup_{j > 0} \mathrm{ESPACIO}(n^j)
\]

***** Clase NPESPACIO                                                                                       :drill:
SCHEDULED: <2018-06-21 Thu>
:PROPERTIES:
:ID:       74ebe4ff-2e1a-46c1-be5f-ec7ddaa9eff9
:DRILL_LAST_INTERVAL: 3.5239
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-17 Sun 17:12]
:END:
Define $\mathrm{NPESPACIO}$.

****** Answer
Clase de espacio polinómico determinista.

\[
\mathrm{NPESPACIO} = \bigcup_{j > 0} \mathrm{NESPACIO}(n^j)
\]

***** Clase EXP                                                                                             :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       317523a6-2dac-483b-b16f-8a9f00396924
:DRILL_LAST_INTERVAL: 3.9152
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 01:14]
:END:
Define $\mathrm{EXP}$.

****** Answer

\[
\mathrm{EXP} = \bigcup_{j > 0} \mathrm{TIEMPO}(2^{n^j})
\]

***** Funciones de complejidad propias                                                                      :drill:
SCHEDULED: <2018-06-23 Sat>
:PROPERTIES:
:ID:       f4682aba-1cc4-4b66-ad9d-e3d8765765f8
:DRILL_LAST_INTERVAL: 5.1068
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 23:16]
:END:
Definición de función propia en complejidad.

****** Answer
Son crecientes $f(n+1) \geq f(n)$ y existe una máquina de Turing
calculadora que para una entrada de longitud $n$ imprime $f(n)$
ceros en tiempo ${\cal O}(n+f(n))$.

**** Simulaciones y tesis fuerte de Church-Turing
***** Tesis de Church-Turing fuerte                                                                         :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       18cc3418-8c2c-4d0e-b9b4-cb1f32b3b637
:DRILL_LAST_INTERVAL: 3.7238
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 11:42]
:END:
Enuncia la Tesis de Church-Turing fuerte.

****** Answer
Todo procedimiento físicamente realizable se puede simular por una
máquina de Turing con sobrecarga polinómica en el número de pasos.
Si una da $f(n)$, la otra puede dar hasta $f^k(n)$ pasos.

/No se verificaría para ordenadores cuánticos./

***** TODO Máquina RAM
***** Simulación de máquinas no-deterministas                                                               :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       b06381c8-22ed-4735-90c0-309381d13597
:DRILL_LAST_INTERVAL: 3.8525
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 20:34]
:END:
Supongamos L decidido por una máquina de Turing no determinista en
tiempo f(n) ≥ n, entonces es decidido por una máquina de Turing
determinista con tres cintas en tiempo...

****** Answer

${\cal O}(d^{f(n)})$ para alguna constante $d$.

**** Complementarios de clases
***** Complementario de clase                                                                               :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       c4d55d6a-b795-4435-a0b6-00f4d34d2cf9
:DRILL_LAST_INTERVAL: 3.7009
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 01:07]
:END:
Define la clase $Co\mathrm{C}$ dada una clase $\mathrm{C}$.

****** Answer
Es la clase de los lenguajes complementarios de la clase $\mathrm{C}$.
Si $L \in \mathrm{C}$, entonces $\overline{L} \in Co\mathrm{C}$.

***** Complementario de clase determinista                                                                  :drill:
SCHEDULED: <2018-06-21 Thu>
:PROPERTIES:
:ID:       e3895850-63a9-4fbd-b214-0dfdc56fd0fb
:DRILL_LAST_INTERVAL: 3.9886
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-17 Sun 17:41]
:END:
Por qué el complementario de una clase determinista coincide con esa
misma clase.

****** Answer
Desde la definición de complejidad de un lenguaje. Tenemos que debe
aceptar o rechazar cada instancia.
***** Relación calculable polinómicamente                                                                   :drill:
SCHEDULED: <2018-06-21 Thu>
:PROPERTIES:
:ID:       4f749115-400a-4726-b16f-c315b77f8fd2
:DRILL_LAST_INTERVAL: 3.3987
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 12:15]
:END:
¿Cuándo es una relación $R$ calculable polinómicamente?

****** Answer
Acepta el lenguaje de pares de la relación en tiempo polinómico.

***** Caracterización por verificador/certificado de NP                                                     :drill:
SCHEDULED: <2018-06-23 Sat>
:PROPERTIES:
:ID:       3cb61b03-74e8-4dc5-babe-3e101c576c6b
:DRILL_LAST_INTERVAL: 4.7226
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 11:59]
:END:
Dar la caracterización verificador/certificado de NP.

****** Answer
Un lenguaje L está en NP ssi existe R relación calculable en tiempo
polinómico y p polinomio tal que

L = { x ∈ A* ∣ ∃ y ∈ A* : |y| ≤ p(|x|), R(x,y) }

El algoritmo calculando R es un /verificador/, el y se llama /certificado/.

***** Caracterización por verificador/certificado de CoNP                                                   :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       dae9b434-98dd-4b76-94e5-f471a6b9b8b6
:DRILL_LAST_INTERVAL: 4.3939
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 11:57]
:END:
Dar la caracterización verificador/certificado de CoNP.

****** Answer
Un lenguaje L está en CoNP ssi existe R relación calculable en tiempo
polinómico y p polinomio tal que

L = {x ∈ A* ∣ ∀ y ∈ A* : |y| ≤ p(|x|), R(x,y) }
***** Ejemplo: saber si un número es compuesto                                                              :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       30ece1a6-5a03-4e5f-8e97-713bbf5f199a
:DRILL_LAST_INTERVAL: 4.1677
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 5.0
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 20:26]
:END:
Saber si un número es compuesto es trivialmente ¿NP o CoNP?

****** Answer
Es trivialmente NP, consiste en encontrar un número que lo divida
propiamente.

**** Relaciones entre clases de complejidad
***** Relaciones básicas                                                                                    :drill:
SCHEDULED: <2018-06-23 Sat>
:PROPERTIES:
:ID:       a34d95a0-6d7c-4de8-a320-fbdc47dc14cd
:DRILL_LAST_INTERVAL: 4.8043
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 23:13]
:END:
Relaciones básicas son

ESPACIO(f(n)) ⊆ NESPACIO(f(n))
TIEMPO(f(n))  ⊆ NTIEMPO(f(n))
NTIEMPO(f(n)) ⊆ ESPACIO(f(n))

¿por qué la última? En particular, ¿por qué NP ⊆ PSPACE?

****** Answer
Podemos simular una máquina no determinista en el espacio que gasta en
la mayor de las ejecuciones, que necesariamente debe ser menos que el
tiempo. Para eso, llevamos en una cinta aparte un contador con las
opciones no deterministas que toma.

***** Método de la alcanzabilidad: resultado                                                                :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       157d1aee-90a4-4422-aefa-43d21afdce06
:DRILL_LAST_INTERVAL: 4.1324
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 23:20]
:END:
¿Qué resultado nos da el método de la alcanzabilidad?

****** Answer
Obtenemos que

\[
\mathrm{NESPACIO}(f(n)) \subseteq \mathrm{TIEMPO}(k^{\log(n)+f(n)}).
\]

***** Método de la alcanzabilidad: método                                                                   :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       c5ccda2e-c2f9-4d4e-8d69-16daf7cd213a
:DRILL_LAST_INTERVAL: 4.3614
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 20:33]
:END:
¿Cuál es el método de la alcanzabilidad? Sirve para obtener lo
siguiente,

\[
\mathrm{NESPACIO}(f(n)) \subseteq \mathrm{TIEMPO}(k^{\log(n)+f(n)}).
\]

****** Answer
Representar una máquina de Turing como un grafo y conectar con los
arcos configuraciones tales que se pueda pasar de una a otra en un
paso de cálculo. Como el número máximo de configuraciones, sabiendo
que estamos acotados por espacio $f(n)$ es

\[ |Q||A|^{(2k-2)f(n)}(n+1)
\],

tenemos que será del orden de $k^{\log(n)+f(n)}$.

***** Teorema de la jerarquía                                                                               :drill:
SCHEDULED: <2018-06-23 Sat>
:PROPERTIES:
:ID:       21eae27e-aaf5-4117-b515-5e6cde76b521
:DRILL_LAST_INTERVAL: 4.5654
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 1.5
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 12:06]
:END:
Teorema de la jerarquía (en tiempo).

****** Answer
Si $f(n) \geq n$ es una función propia,

 - $\mathrm{TIEMPO}(f(n)) \subset \mathrm{TIEMPO}(f^2(n))$,
 - $\mathrm{TIEMPO}(f(n)) \neq \mathrm{TIEMPO}(f^2(n))$.

***** P ≠ EXP                                                                                               :drill:
SCHEDULED: <2018-06-23 Sat>
:PROPERTIES:
:ID:       bff038a1-de63-4107-8f45-97f7d77677c8
:DRILL_LAST_INTERVAL: 5.127
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 2.5
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 12:07]
:END:
¿Por qué sabemos P ≠ EXP?

****** Answer
Usamos el [[id:21eae27e-aaf5-4117-b515-5e6cde76b521][teorema de la jerarquía]].

\[
P \subseteq \mathrm{TIEMPO}(2^n) \subsetneq \mathrm{TIEMPO}((2^n)^2) \subseteq \mathrm{EXP}.
\]

***** Teorema de la jerarquía en espacio                                                                    :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       ab8fdd1d-65be-4a7d-8c0d-080d950adeac
:DRILL_LAST_INTERVAL: 3.7528
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 23:18]
:END:
Teorema de la jerarquía en espacio.

****** Answer
Si $f(n)$ es una función propia,

ESPACIO(f(n)) ⊂ ESPACIO(f(n)log(f(n))).
ESPACIO(f(n)) ≠ ESPACIO(f(n)log(f(n))).

***** Inclusión de clases                                                                                   :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       c60beb7d-5797-4b47-bf9f-069410c07677
:DRILL_LAST_INTERVAL: 4.1444
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 11:53]
:END:
Cadena de inclusión de clases de complejidad básicas. ¿Cuál es estricta?

****** Answer

L ⊆ NL ⊆ P ⊆ NP ⊆ PESPACIO

Sabemos que NL ⊊ PESPACIO.

***** Teorema del espacio no determinista                                                                   :drill:
SCHEDULED: <2018-06-23 Sat>
:PROPERTIES:
:ID:       33fb0049-5e89-4778-876e-6cbc8ddbeb66
:DRILL_LAST_INTERVAL: 5.2255
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 23:20]
:END:
Teorema del espacio no determinista.

****** Answer
Si $f(n) \geq \log(n)$ es propia,

NESPACIO(f(n)) ⊆ ESPACIO(f²(n)).

***** PESPACIO = NPESPACIO                                                                                  :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       a95eda0f-37a2-47ef-a7bd-ea1ef934b16e
:DRILL_LAST_INTERVAL: 4.0487
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 20:29]
:END:
¿Por qué sabemos PESPACIO = NPESPACIO?

****** Answer
Por el teorema del espacio no determinista

NESPACIO(f(n)) ⊆ ESPACIO(f²(n)),

y entonces en el caso polinómico tenemos la igualdad buscada.

***** Teorema del co-espacio no determinista                                                                :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       5812c170-d707-40fd-8ec5-004e2fabb042
:DRILL_LAST_INTERVAL: 4.0615
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 23:08]
:END:
Teorema del co-espacio no determinista.

****** Answer
Si $f(n) \geq \log(n)$ es propia,

NESPACIO(f(n)) = coNESPACIO(f(n)).

***** coNL = NL                                                                                             :drill:
SCHEDULED: <2018-06-23 Sat>
:PROPERTIES:
:ID:       3b05c32d-f5b9-47ef-9340-5cc9770e4ded
:DRILL_LAST_INTERVAL: 4.9641
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 5.0
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 23:15]
:END:
Sabemos coNL=NL, ¿por qué?

****** Answer
Porque si $f(n) \geq \log(n)$ es propia,

NESPACIO(f(n)) ⊆ coNESPACIO(f(n)).

***** TODO Sistemas interactivos de demostración                                                            :drill:
:PROPERTIES:
:ID:       fe7623a5-dc87-4be6-bab2-71b097e99582
:END:

**** Ejemplo: Primality is in NP ∩ coNP
[[http://www.cmi.ac.in/~ramprasad/lecturenotes/comp_numb_theory/lecture17.pdf]]
**** Sistemas interactivos de demostración

*** Tema 4: NP-Completitud
**** Reducción
***** Problema de decisión                                                                                  :drill:
SCHEDULED: <2018-06-21 Thu>
:PROPERTIES:
:ID:       d898e65c-20db-46b0-99b4-fa1ba0d10873
:DRILL_LAST_INTERVAL: 3.5844
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-17 Sun 21:36]
:END:
Problema de decisión Π.

****** Answer
Un *problema de decisión* $\Pi$ consta de $D_{\Pi}$ conjunto de ejemplos
del problema, y de $Y_{\Pi} \subseteq D_{\Pi}$, conjunto de ejemplos positivos contenido
en el conjunto de instancias del problema.

***** Reducción en términos de lenguajes                                                                    :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       88393d02-8a50-4376-a089-4e1ed9147c6c
:DRILL_LAST_INTERVAL: 3.926
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 12:01]
:END:
Reducción L₁ ∝ L₂.

****** Answer
$L_1 \propto L_2$ si existe una máquina de Turing en espacio logarítmico
calculando una función $f \colon A^{\ast} \to B^{\ast}$ tal que

\[
x \in L_1 \iff f(x) \in L_2.
\]

***** Reducción en términos de problemas                                                                    :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       0235eb36-5292-4a12-9923-99b827ffdb22
:DRILL_LAST_INTERVAL: 3.9947
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 12:18]
:END:
Reducción de problemas Π₁ ∝ Π₂.

****** Answer
$\Pi_1 \propto \Pi_2$ si existe una máquina de Turing determinista en espacio
logarítmico calculando $f \colon D_{\Pi_1} \to D_{\Pi_2}$ tal que

\[
x \in Y_{\Pi_1} \iff f(x) \in Y_{\Pi_2}.
\]
***** CH - Problema del circuito hamiltoniano                                                               :drill:
SCHEDULED: <2018-06-21 Thu>
:PROPERTIES:
:ID:       5f1f5700-0d1d-4f60-a19a-715a55d6e65e
:DRILL_LAST_INTERVAL: 4.2004
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-17 Sun 21:34]
:END:
Enunciar el problema del circuito hamiltoniano (CH).

****** Answer
Un ciclo hamiltoniano es una sucesión de aristas visitando todos los
vértices del grafo una sola vez. Determinar si existe un ciclo
hamiltoniano.

Es NP-completo.

***** TSP - Problema del viajante de comercio                                                               :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       0aeb6294-e9a9-49dc-98e0-1e36c415c6bc
:DRILL_LAST_INTERVAL: 4.4751
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 20:23]
:END:
Enuncia el problema del viajante de comercio.

****** Answer
Dado un conjunto C de ciudades, una distancia d : C × C → ℕ, y una
cota B ∈ ℕ. Determinar una permutación de las ciudades que al
recorrerla dé distancia menor a B.
***** Reducción: CH ∝ TSP                                                                                   :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       6cc47af4-0d30-48da-a226-81c76325d1b3
:DRILL_LAST_INTERVAL: 4.3484
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 5.0
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 20:28]
:END:
Reducir: circuito hamiltoniano a viajante de comercio. Hamilton ∝ TSP.

****** Answer
Para m vértices damos una instancia del TSP con distancia 1 en
vértices conectados y 2 en no conectados. Tomamos la cota acorde.

 * Es en espacio logarítmico.
 * Hay solución en uno si y sólo si hay solución en el otro.

***** Composición de reducciones                                                                            :drill:
SCHEDULED: <2018-06-21 Thu>
:PROPERTIES:
:ID:       e40d577a-4fd4-4e2c-ae6b-120c4c6b0e8a
:DRILL_LAST_INTERVAL: 4.0099
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-17 Sun 17:09]
:END:
Si L₁ ∝ L₂, y además L₂ ∝ L₃, ¿qué sabemos?

****** Proof
Las reducciones se componen, L₂ ∝ L₃. La demostración no es
trivial.

***** Composición de reducciones: técnica                                                                   :drill:
SCHEDULED: <2018-06-20 Wed>
:PROPERTIES:
:ID:       759e98fd-2b1a-4b87-8366-a94ed5ce0a2f
:DRILL_LAST_INTERVAL: 2.9668
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 2.5
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-17 Sun 17:18]
:END:
Hablamos de complejidad. Si $L_1 \propto L_2$ y $L_2 \propto L_3$,
entonces $L_1 \propto L_3$. ¿Por qué?

****** Proof
La composición no es trivial. Si la primera máquina calcula
una salida y la usa la segunda, el espacio intermedio no será
logarítmico.

Lo que hacemos es que cada vez que $M_2$ necesita una casilla
de la entrada, se simula $M_1$ hasta esa casilla y se envía a
$M_2$.

**** Complitud. SAT
***** Lenguaje completo para una clase                                                                      :drill:
SCHEDULED: <2018-06-21 Thu>
:PROPERTIES:
:ID:       c3722f05-acf3-4275-892e-9639c88f81d4
:DRILL_LAST_INTERVAL: 4.2547
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-17 Sun 17:20]
:END:
Lenguaje completo para una clase.

****** Answer
L es *completo* para C si L ∈ C, y además, ∀ L' ∈ C:  L' ∝ L.

***** Equivalencia                                                                                          :drill:
SCHEDULED: <2018-06-21 Thu>
:PROPERTIES:
:ID:       08d5b61c-e6df-4346-8447-01ee124784c5
:DRILL_LAST_INTERVAL: 3.1134
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 00:58]
:END:
Lenguajes equivalentes.

****** Answer
Si $L_1 \propto L_2$, y $L_2 \propto L_1$, se dicen *equivalentes*.
***** SAT                                                                                                   :drill:
SCHEDULED: <2018-06-21 Thu>
:PROPERTIES:
:ID:       f572c6cc-aa6d-49ed-847c-dda840b80501
:DRILL_LAST_INTERVAL: 3.9144
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-17 Sun 17:43]
:END:
Enuncia el problema SAT.

****** Answer
Se da un conjunto $U = \left\{ p_1,\dots,p_m \right\}$ de símbolos proposicionales y una
colección $C$ de cláusulas (disyunción y negación) sobre estos símbolos.
Decidir si son consistentes.

***** Teorema de Cook-Levine                                                                                :drill:
SCHEDULED: <2018-06-21 Thu>
:PROPERTIES:
:ID:       589381c5-6ad4-4edc-ae38-86b26cb581a6
:DRILL_LAST_INTERVAL: 3.9148
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-17 Sun 17:14]
:END:
Enuncia el Teorema de Cook-Levine.

****** Proof
SAT es NP-completo, donde SAT es el problema de la consistencia de
cláusulas en lógica proposicional.

***** Teorema de Cook-Levine                                                                                :drill:
SCHEDULED: <2018-06-21 Thu>
:PROPERTIES:
:ID:       e1140d15-2396-4d29-bf38-2ede346a8d4a
:DRILL_LAST_INTERVAL: 3.4195
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 20:31]
:END:
Idea de la demostración del Teorema de Cook-Levine, que dice que SAT
es NP-completo.

****** Answer
Podemos expresar todo el funcionamiento de una máquina de Turing no
determinista tomando cláusulas que representen:

 * Q[i,k], estados en cada momento;
 * H[i,j], posición del cabezal en cada momento;
 * S[i,j,v], símbolos en la cinta en cada posición en cada momento;
 * O[i,n], opciones de no determinismo tomadas en cada momento.

Necesitamos calcular el polinomio que acota el número de pasos que
dará $p(n)$ para tomar el número de instantes necesario. El espacio
es logarítmico porque dependemos como mucho de índices en $\log(p(n))$.

**** Variantes de SAT
***** 3-SAT                                                                                                 :drill:
SCHEDULED: <2018-06-21 Thu>
:PROPERTIES:
:ID:       9acf9fd6-6725-4523-af07-a72a1079c7ad
:DRILL_LAST_INTERVAL: 3.6077
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-17 Sun 17:23]
:END:
Enuncia el problema 3-SAT.

****** Answer
Se da un conjunto U = {p₁,...,pₘ} de símbolos proposicionales y una
colección C de cláusulas de a lo sumo 3 literales. Decidir si son
consistentes.

Puede restringirse a exactamente 3 literales.

Es NP-completo en ambos casos.

***** Reducción: SAT ∝ 3-SAT                                                                                :drill:
SCHEDULED: <2018-06-23 Sat>
:PROPERTIES:
:ID:       dd3951a1-e8f9-415a-98ca-d4b9e7b673b6
:DRILL_LAST_INTERVAL: 4.5225
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 5.0
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 20:27]
:END:
Idea de la reducción SAT ∝ 3-SAT.

****** Answer
P ∨ Q se satisface ssi se satisface (P ∨ x), (Q ∨ ¬ x). Esto nos permite
ir partiendo 

l₁ ∨ l₂ ∨ ... ∨ lₖ

en

(l₁ ∨ l₂ ∨ x₂), (¬ x₂ ∨ l₃ ∨ x₃), (¬ x₃ ∨ l₄ ∨ x₄), ...

Esa reducción se hace en espacio logarítmico, ¡no se debe hacer
recursivamente sino iterativamente!

***** Reducción: 3-SAT ∝ 3-SATexacto                                                                        :drill:
SCHEDULED: <2018-06-23 Sat>
:PROPERTIES:
:ID:       848632d1-19de-4ab4-9fc8-3be24fa810ac
:DRILL_LAST_INTERVAL: 5.0463
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 5.0
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 20:27]
:END:
Idea de la reducción 3-SAT ∝ 3-SATexacto.

****** Answer
Añadimos variables nuevas a las cláusulas que falten y luego forzamos
a las variables a ser falsas, añadiendo todas las combinaciones
posibles de esas tres excepto la que las hace verdaderas a las tres a
la vez (x₁ ∨ x₂ ∨ x₃).

***** 2-SAT                                                                                                 :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       0bd56a7d-078f-4269-93cf-9885c9fb84c6
:DRILL_LAST_INTERVAL: 4.054
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 2
:DRILL_AVERAGE_QUALITY: 2.333
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 11:38]
:END:
Enuncia el problema 2-SAT. ¿Qué clase de complejidad tiene?

****** Answer
Se da un conjunto de símbolos y una colección de cláusulas. Decidir si
son consistentes.

/2-SAT está en NL./

***** 2-SAT es NL                                                                                           :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       9de963d3-f352-4651-9a9e-c5ed240f8ee7
:DRILL_LAST_INTERVAL: 4.3627
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 20:24]
:END:
¿Por qué 2-SAT está en NL?

****** Answer
2-SAT permite escribir un grafo de implicaciones que es no consistente
ssi podemos encontrar un camino entre (x) y (¬x).
Nótese que NL = coNL.

***** Cláusulas de Horn                                                                                     :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       7136c0b8-a13d-45a8-96dd-bb9d5569db47
:DRILL_LAST_INTERVAL: 4.1733
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 5.0
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 23:14]
:END:
¿Qué es una cláusula de Horn?

****** Answer
Aquella en la que como máximo existe un literal positivo.

***** Horn-SAT                                                                                              :drill:
SCHEDULED: <2018-06-23 Sat>
:PROPERTIES:
:ID:       7ce4b2a1-56c6-4678-b218-c2c5935229b8
:DRILL_LAST_INTERVAL: 4.6474
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 5.0
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 23:13]
:END:
El resolver SAT para cláusulas de Horn es P-completo, ¿cuál es un
algoritmo polinómico?

****** Answer
Partimos las cláusulas en $C_1$ (todos los literales negativos) y
$C_2$ (algún literal positivo). Tomamos un conjunto $H$ de variables
que sabemos que son necesariamente verdad e incluimos los literales
positivos aislados. Mientras $H$ cambie le incluimos todas las
implicaciones $(z_{1} \wedge  \dots \wedge z_n) \to y$ que se deduzcan de las cláusulas
de $C_2$. Podemos terminar haciendo $H$ verdad y todo lo demás mentira.

La consistencia equivale a que después de este proceso, todas las
cláusulas en $C_1$ tengan algún literal fuera de $H$.

***** MAX2SAT                                                                                               :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       3cd3c25e-41c0-4b1c-a708-29a325e856c9
:DRILL_LAST_INTERVAL: 4.4805
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 2
:DRILL_AVERAGE_QUALITY: 2.333
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 11:30]
:END:
Enuncia MAX2SAT. ¿Clase de complejidad?

****** Answer
Dado un conjunto de cláusulas de dos literales y un K ≥ 0,
¿pueden satisfacerse al menos K cláusulas?

Es NP-completo.

***** Reducción: 3-SAT ∝ MAX2SAT                                                                            :drill:
SCHEDULED: <2018-06-23 Sat>
:PROPERTIES:
:ID:       8ae2f16d-95c1-490c-a476-9f1fab03bdaf
:DRILL_LAST_INTERVAL: 4.7355
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 20:26]
:END:
Idea de la reducción 3-SAT ∝ MAX2SAT.

****** Answer
Cada (x ∨ y ∨ z) puede transformarse en

x,y,z,w, ¬x∨¬y, ¬y∨¬z, ¬z∨¬x, x∨¬w, y∨¬w, z∨¬w

y se toma k=7m, se puede comprobar que si x∨y∨z es verdadero, se
pueden llegar a las 7 cláusulas (no más), y que en otro caso no se
puede.

***** 3-SATrestricción                                                                                      :drill:
SCHEDULED: <2018-06-21 Thu>
:PROPERTIES:
:ID:       661674d6-af50-4ae0-8a17-26a8fe4bfe1d
:DRILL_LAST_INTERVAL: 3.3528
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 20:27]
:END:
Enunciar 3-SATrestricción.

****** Answer
3-SAT haciendo que cada literal nunca aparezca más de dos
veces. Pueden existir cláusulas de longitud menor que 3.

***** Reducción: 3-SAT ∝ 3-SATrestricción                                                                   :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       f73cf18b-94cf-4e08-9bbc-0329882bea9f
:DRILL_LAST_INTERVAL: 3.9824
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 20:23]
:END:
Cómo se reduce 3-SAT a 3-SATrestricción. Es decir, a 3-SAT haciendo
que cada literal nunca aparezca más de dos veces y cada variable más
de tres veces.

****** Answer
Si x aparece varias veces se sustituye por x₁→x₂→...→xₖ. Esto se
consigue sabiendo que x₁→x₂ es una cláusula de dos literales.

***** NAESAT                                                                                                :drill:
SCHEDULED: <2018-06-20 Wed>
:PROPERTIES:
:ID:       fca08a72-6a23-4e6f-94cc-910f12b1dabf
:DRILL_LAST_INTERVAL: 2.9569
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-17 Sun 17:14]
:END:
Enunciar NAESAT. ¿Clase de complejidad?

****** Answer
Dadas cláusulas de longitud 3, dar una asignación de valores tal que
para cada cláusula alguno, pero no todos los literales sean ciertos.

NAESAT es NP-completo.

***** Reducción: 3-SAT ∝ NAESAT                                                                             :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       30584957-b7a1-4107-9452-664387a264e0
:DRILL_LAST_INTERVAL: 4.0305
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 5.0
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 23:16]
:END:
Idea de la reducción 3-SAT a NAESAT.

****** Answer
Tomamos una nueva variable z y para cada p∨q∨r añadimos una nueva
variable s y las cláusulas

s∨r∨z, p∨q∨¬s, ¬p∨s∨z, ¬q∨s∨z.

Si hay solución a este NAESAT, tomamos la solución que deja z falso y
es una solución del original.  Si hay una solución al original,
tomamos z falso y s de acuerdo a que p∨q sea verdad y tenemos solución
al NAESAT.

**** Problemas de grafos y conjuntos
***** GI - Isomorfismo de grafos                                                                            :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       8f2070c6-db8c-445b-ad90-1cdd14a2ba97
:DRILL_LAST_INTERVAL: 3.655
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 11:09]
:END:
Enunciar el problema de isomorfismo de grafos. ¿Clase de complejidad?

****** Answer
Dados dos grafos G₁ y G₂, determinar si existe una biyección
f : V₁ → V₂ tal que (u,v) ∈ E₁ si y sólo si (f(u),f(v)) ∈ E₂.

Se supone que ni está en P ni es NP-completo. Se define la
clase GI de isomorfismo de grafos.

***** ACTRI                                                                                                 :drill:
SCHEDULED: <2018-06-21 Thu>
:PROPERTIES:
:ID:       e5fa3703-ddff-4b96-9551-693adec849f8
:DRILL_LAST_INTERVAL: 4.0583
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-17 Sun 17:42]
:END:
Enunciar ACTRI. ¿Clase de complejidad?

****** Answer
Tres conjuntos disjuntos W,X,Y de cardinalidad q, y un subconjunto de
compatibilidades M ⊆ W × X × Y. ¿Existe un M' ⊆ M con q elementos tal
que cubra todos los elementos y no se solape?

ACTRI es NP-completo.

***** Reducción: 3-SAT ∝ ACTRI                                                                              :drill:
SCHEDULED: <2018-06-21 Thu>
:PROPERTIES:
:ID:       769832e5-5417-47d6-ae55-1123788c71a5
:DRILL_LAST_INTERVAL: 3.2333
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 20:23]
:END:
Idea de la reducción 3-SAT ∝ ACTRI.

****** Answer
Dado un 3-SAT con variables u₁,...,uₙ, y cláusulas c₁,...,cₘ, para 1≤j≤m,

 * metemos uᵢ[j], ¬uᵢ[j] en W,
 * añadimos aᵢ[j] a X,
 * añadimos bᵢ[j] a Y.

Hacemos un ciclo concatenado de tripletas usando aᵢ,bᵢ para obligarnos a elegir
uᵢ o ¬uᵢ en todas las cláusulas. Luego

 * añadimos s₁[j] a X,
 * añadimos s₂[j] a Y,
 * añadimos (uᵢ[j],s₁[j],s₂[j]) si está en la cláusula o (¬uᵢ[j],s₁[j],s₂[j])
   si está su negación.

Esto nos fuerza a elegir que al menos se cumple uno de esos tres en la
cláusula. Finalmente, para 1≤k≤m(n-1),

 * añadimos g₁[k] a X,
 * añadimos g₂[k] a Y,

permitiendo todas las compatibilidades, es decir todas las (uᵢ[j],g₁[k],g₂[k])
y todas las (¬uᵢ[j],g₁[k],g₂[k]). Esto sirve para dar salida a las que son
verdad pero no se necesitan para satisfacer cláusulas.

Todo esto se hace en espacio logarítmico y se comprueba equivalencia.

***** 3-SET                                                                                                 :drill:
SCHEDULED: <2018-06-21 Thu>
:PROPERTIES:
:ID:       1c82d410-9b87-45fe-aa50-266900f6055b
:DRILL_LAST_INTERVAL: 4.2866
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-17 Sun 17:43]
:END:
Enunciar 3-SET. ¿Clase de complejidad?

****** Answer
Sea |X| = 3q y un conjunto dado de tripletas (subconjuntos de tres
elementos). Encontrar tripletas entre las dadas que cubran el conjunto
y sean disjuntas.

3-SET es NP-completo.

***** Reducción: ACTRI ∝ 3-SET                                                                              :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       7e1c57ac-a5db-4026-a7db-17eab06bcc4d
:DRILL_LAST_INTERVAL: 4.0426
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 20:27]
:END:
Idea de la reducción ACTRI ∝ 3-SET.

****** Answer
Simplemente dados W,Y,Z los unimos X = W ∪ Y ∪ Z y tomamos las mismas
tripletas.

***** Clique - Problema del clique máximo                                                                   :drill:
SCHEDULED: <2018-06-21 Thu>
:PROPERTIES:
:ID:       b6d07972-dbf6-4b1c-abcd-d15fb0233ab3
:DRILL_LAST_INTERVAL: 3.7855
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 2.5
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-17 Sun 17:46]
:END:
Enuncia el problema del clique máximo.

****** Answer
Un clique es un subconjunto maximal totalmente conectado. Dado un
grafo y un número natural J ≤ |V|, determinar si existe un clique
de tamaño mayor o igual que J.

***** CV - Cubrimiento por vértices                                                                         :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       bb5dfaa3-b828-4aab-89f9-4a40c7b590c5
:DRILL_LAST_INTERVAL: 4.3388
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 00:48]
:END:
Enunciar el problema de cubrimiento por vértices.

****** Answer
Un conjunto de vértices Vₐ /cubre el grafo/ si toda arista tiene un
extremo en ellos.  Determinar si existe un recubrimiento de tamaño
menor o igual que un K dado.

Es NP-completo.

***** CI - Conjunto independiente                                                                           :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       be313e92-e7f3-4698-a194-b7f15b624519
:DRILL_LAST_INTERVAL: 5.0789
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-17 Sun 22:02]
:END:
Enunciar el problema del conjunto independiente.

****** Answer
Un subconjunto de vértices de un grafo Vᵢ ⊆ V es *independiente*
si no hay ninguna arista entre vértices de Vᵢ. ∀u,v ∈ Vᵢ: (u,v) ∉ E.
Dado un grafo y un natural, determinar si existe un conjunto
independiente de tamaño mayor o igual que un J dado.

***** Equivalencia de tres problemas de grafos                                                              :drill:
SCHEDULED: <2018-06-21 Thu>
:PROPERTIES:
:ID:       29d879cc-e99b-42ff-b053-9bc32e85accc
:DRILL_LAST_INTERVAL: 3.9901
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-17 Sun 17:53]
:END:
Qué tres problemas de grafos son equivalentes.

****** Answer

 1. Clique de tamaño mayor o igual que n-K en el complemento de G.
 2. Cubrimiento de vértices de tamaño menor o igual que K.
 3. Conjunto independiente de tamaño mayor o igual que n-K.

***** Reducción: 3-SAT ∝ CV                                                                                 :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       ea83d9ea-cc25-41ef-a15f-ad4a4ef341da
:DRILL_LAST_INTERVAL: 4.1065
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 20:22]
:END:
Idea de la reducción 3-SAT ∝ CV (cubrimiento por vértices).

****** Answer
Representamos las u₁,...,uₙ uniendo cada una con su opuesta, tendremos
que elegir una de las dos. Cada cláusula viene dada por un triángulo,
conectado a sus tres literales; tendremos que tomar al menos 2 vértices
del triángulo y el tercero nos lo podemos ahorrar si tiene el valor de
verdad correcto.

Si y sólo si hay satisfacibilidad podremos llegar a cubrir con n+2m.
***** Reducción: CV ∝ CH                                                                                    :drill:
SCHEDULED: <2018-06-23 Sat>
:PROPERTIES:
:ID:       812c2028-236a-487d-b804-4406d5dfa715
:DRILL_LAST_INTERVAL: 4.9712
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 20:25]
:END:
Idea de la reducción CV ∝ CH. (cubrimiento por vértices a circuito hamiltoniano)

****** Answer
Hay que construir un gadget por cada arista en el CV y luego poner
puntos sueltos que sirven para enlazarlos. El gadget permite cruzar por los
dos sitios (si está cubierta dos veces la arista) o sólo por uno (si sólo una
vez está cubierta).

***** Problema de la partición                                                                              :drill:
SCHEDULED: <2018-06-21 Thu>
:PROPERTIES:
:ID:       19a81ec7-0136-4176-85bc-06f6b8ec967a
:DRILL_LAST_INTERVAL: 3.2625
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 00:49]
:END:
Enunciar el problema de la partición.

****** Answer
Dado un conjunto y una función tamaño s : A → ℕ, determinar si existe
un A' ⊆ A tal que

\[
\sum_{a\in A'}s(a) = \sum_{a \in A\setminus A'} s(a).
\]

***** Reducción: ACTRI ∝ Partición                                                                          :drill:
SCHEDULED: <2018-06-23 Sat>
:PROPERTIES:
:ID:       1cb9605a-5607-4325-8635-af83ffefbb50
:DRILL_LAST_INTERVAL: 5.0866
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 20:26]
:END:
Idea de la reducción ACTRI ∝ Partición.

****** Answer
Para cada tripleta mᵢ, ponemos un elemento aᵢ que en su peso codifica
en binario varias zonas independientes en cuanto acarreo. Cada zona
tiene un 1 al final si la tripleta cubre el elemento asociado. Así,
tendrá tres 1s en las tres posiciones que cubre. Sea B el número que
tiene un uno en cada zona, un recubrimiento suma B.

Además de estos, incluimos en el conjunto A un b₁ de peso Σs(aᵢ) y un
b₂ de peso 2B. Una partición tendría que encontrar elementos que
sumaran B + Σs(aᵢ), y alguna de ellas debería contener a b₁, así
encontrando elementos de los aᵢ que sumen B.
**** Técnicas de reducción
***** Problema de la mochila
***** TODO Reducción: Partición ∝ Mochila
# Usando técnica de la restricción.

***** TODO Reducción: Partición ∝ Asignación en multiprocesador
# Usando técnica de la restricción.
***** Partición de triángulos (PARTRI)                                                                      :drill:
SCHEDULED: <2018-06-23 Sat>
:PROPERTIES:
:ID:       02189a51-0b3f-48ba-a666-a524531370a5
:DRILL_LAST_INTERVAL: 4.5201
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 00:48]
:END:
Enunciar el problema de partición de triángulos.

****** Answer
Damos un grafo con |V| = 3q vértices. ¿Existe una partición de V en q
conjuntos distintos siendo cada uno de ellos un triángulo?

***** Reducción: 3-SET ∝ PARTRI                                                                             :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       56ecd170-d2e1-498e-a224-c0641c169fe2
:DRILL_LAST_INTERVAL: 3.8535
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 23:14]
:END:
Idea de la reducción 3-SET ∝ PARTRI.

****** Answer
Tomamos un grafo que tiene los elementos de la partición como vértices
y además para cada tripleta de 3-SET creamos una triple torre de
triángulos de 9 vértices que permite elegir alternativamente los tres
o no elegir ninguno al cubrir por triángulos.

***** Conjunto mínimo de tests (CMT)                                                                        :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       2031cafb-4518-4cb0-8036-0318f1fb75a6
:DRILL_LAST_INTERVAL: 4.6855
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-17 Sun 17:19]
:END:
Enunciar el problema del conjunto mínimo de tests.

****** Answer
Damos un conjunto A de posibles diagnósticos, un conjunto C de subconjuntos de A
de /posibles tests/ y J natural número de tests admisibles.  ¿Existe una subfamilia
C' ⊆ C con |C'| ≤ J tal que para cada par de elementos de aᵢ,aⱼ ∈ A haya un test
en C' cuya pertenencia los distinga?

***** Reducción: ACTRI ∝ CMT                                                                                :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       3e972a53-0f7e-4136-834c-c77841d8d965
:DRILL_LAST_INTERVAL: 4.1262
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 23:19]
:END:
Idea de la reducción ACTRI ∝ CMT.

****** Answer
Dado un ACTRI con M ⊆ W × X × Y, de tamaño |W|=|X|=|Y|=q,
tomamos A = W ∪ X ∪ Y ∪ {w₀,x₀,y₀} y tomamos tests

C = {{w,x,y} ∣ (w,x,y)∈M} ∪ {W ∪ {w₀}} ∪ {X ∪ {x₀}}.

Nótese que tenemos dos tests que separan las x's, las w's y las
y's. Además, para poder separar cada una de ellas, necesitaremos
que cada una esté en algún {w,x,y}, asegurándonos así que la
partición cubre.

Pedimos que haya J=q+2 tests, para asegurar que no duplicamos en el
cubrimiento, si lo hiciéramos, no llegaríamos a cubrir todo.

**** TODO Listado de Problemas NP-Completos
**** Reducibilidad Turing
***** Reducibilidad Turing                                                                                  :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       8483b9ae-0d98-40c6-ac63-5d27f7770c31
:DRILL_LAST_INTERVAL: 3.9325
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 00:54]
:END:
¿Cuándo se *reduce Turing* un problema Π a un problema Π'? Escribimos
Π ∝ₜ Π'.

****** Answer
Cuando Π puede resolverse en tiempo polinómico con un oráculo que
resuelve Π' en un paso de cálculo.

**** NP-hard, CoNP, certificados
***** Problemas NP-difíciles                                                                                :drill:
SCHEDULED: <2018-06-21 Thu>
:PROPERTIES:
:ID:       42a4c9ed-5012-4e3c-899c-b7d27f9b49d9
:DRILL_LAST_INTERVAL: 4.135
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.5
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-17 Sun 17:54]
:END:
Definición de problema NP-difícil.

****** Answer
Π es NP-difícil si existe un NP-completo Π' que se puede reducir-Turing
a Π.  Si un problema NP-difícil se resuelve en tiempo polinómico, entonces
P = NP.

***** Relación entre NP-completo y CoNP completo                                                            :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       705575c0-040c-470e-bfb6-371ecbb31fa9
:DRILL_LAST_INTERVAL: 4.0067
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 11:07]
:END:
¿Cuál es la relación entre NP-completo y CoNP completo?

****** Answer
$\mathrm{L}$ es NP-completo si y sólo si su complemento $\overline{\mathrm{L}}$ es CoNP completo.

***** Relación entre P, NP y CoNP                                                                           :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       aa72321c-0d12-4bdc-a5f2-1aa0f1f39243
:DRILL_LAST_INTERVAL: 3.8653
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 12:21]
:END:
¿Cuál es la relación entre P, NP y CoNP?¿Qué pasaría si P = NP?

****** Answer
Si P = NP entonces CoNP = NP.
***** Teorema de Pratt                                                                                      :drill:
SCHEDULED: <2018-06-20 Wed>
:PROPERTIES:
:ID:       3331c3f1-4479-434b-a719-c2260eb50cdd
:DRILL_LAST_INTERVAL: 3.3456
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-17 Sun 21:43]
:END:
Enuncia el Teorema de Pratt.

****** Answer
El determinar si un número es primo está en NP.
**** Problemas de funciones
***** Problema de función                                                                                   :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       1c0a5d62-7064-40fd-bd85-b2c84281d683
:DRILL_LAST_INTERVAL: 3.9279
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 11:52]
:END:
¿Qué es el problema de función asociado a una relación R?

****** Answer
Dado un ejemplo x ∈ A*, calcular un y tal que R(x,y) si existe o
devolver ε si no.
***** Clase FNP                                                                                             :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       d2f147a7-f1b9-4322-8d8b-652984616ba0
:DRILL_LAST_INTERVAL: 3.538
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 2.5
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 11:36]
:END:
Clase FNP.

****** Answer
Un problema de función está en FNP ssi está asociado a una relación R
decidible en tiempo polinómico y tal que si R(x,y), entonces |y| ≤ p(|x|)
para un polinomio p.

***** Clase FP                                                                                              :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       dc97dd2f-f485-4c47-a460-4626f3b0770a
:DRILL_LAST_INTERVAL: 3.9305
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 11:07]
:END:
Clase FP.

****** Answer
(Function Polynomial-Time) Clase de problemas FNP tales que existe una
máquina de Turing determinista que las calcula en tiempo polinómico.

***** Clase FNPT                                                                                            :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       8b31d502-dce5-4028-8b4d-4c60b46896ea
:DRILL_LAST_INTERVAL: 3.8023
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 2.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 12:33]
:END:
Clase FNPT.

****** Answer
Clase de los problemas FNP totales; tales que para todo x sabemos que
existe un y con |y| ≤ p(|x|) tal que R(x,y) = 1.

/Ejemplo: encontrar una descomposición en números primos./
/Ejemplo: red feliz./

***** FNP-completos                                                                                         :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       84429db9-3517-424b-a157-b5caa12c5600
:DRILL_LAST_INTERVAL: 4.1801
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 11:36]
:END:
Problema FNP-completo. Dar un ejemplo.

****** Answer
Está en FNP y cualquier otro problema de esta clase de puede reducir a
él. 

/Un ejemplo es FSAT, dado un conjunto de cláusulas, encontrar una/
/asignación que haga a todas las cláusulas verdaderas./

***** P = NP ssi FP = FNP                                                                                   :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       2fa7c942-b809-4f1a-b191-e5a0457e71e4
:DRILL_LAST_INTERVAL: 3.9281
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 12:05]
:END:
¿Por qué sabemos que P = NP ssi FP = FNP?

****** Answer
Si FP = FNP, trivialmente P = NP.  En el otro sentido, si P = NP,
entonces podríamos resolver SAT tiempo polinómico, y sabiendo
resolver SAT, resolver FSAT se hace en tiempo polinómico probando
asignaciones. FSAT es FNP-completo.

***** Reducciones en FNP                                                                                    :drill:
:PROPERTIES:
:ID:       41f5d701-676b-4137-b4f3-af8b3a943ddb
:END:
Concepto de reducción en FNP.

****** Answer
Un Π se reduce a Π' ssi existe R y S calculables en espacio logarítmico tal que
si x es ejemplo de Π, entonces R(x) es ejemplo de Π'; y si z es solución correcta
de R(x), entonces S(z) es solución correcta de x.

***** TODO Resolver el viajante de comercio en versión de funciones 
***** La red feliz                                                                                          :drill:
SCHEDULED: <2018-06-23 Sat>
:PROPERTIES:
:ID:       af69a46d-7f3d-4227-81f4-ddbf8cb7a720
:DRILL_LAST_INTERVAL: 4.0718
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-19 Tue 10:26]
:END:
Enunciar el problema de la red feliz.

****** Answer
Dado un grafo $(V,E)$ pesado en las aristas por $w$, un estado es una
aplicación $s \colon V \to \left\{ -1,1 \right\}$. El nodo $i$ es feliz bajo un estado si

\[
s(i) \sum_{(i,j) \in E} s(j)w(i,j) \geq 0.
\]

Buscamos un estado en el que todos los nodos sean felices.

***** Clase de la red feliz                                                                                 :drill:
SCHEDULED: <2018-06-23 Sat>
:PROPERTIES:
:ID:       d5d1c882-b2a4-40fa-b451-3ca47a2a8215
:DRILL_LAST_INTERVAL: 4.1898
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-19 Tue 09:58]
:END:
¿En qué clase está la red feliz?

****** Answer
Está en FNPT.

***** La red feliz es total                                                                                 :drill:
SCHEDULED: <2018-06-23 Sat>
:PROPERTIES:
:ID:       c880e9ff-9e9d-45db-859b-55862751ebf7
:DRILL_LAST_INTERVAL: 4.4882
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 5.0
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-19 Tue 10:08]
:END:
¿Por qué la red feliz es total?

****** Answer
Tomamos

\[
\Phi(s) = \sum_{(i,j) \in E} s(i)s(j)w(i,j).
\]

Si hubiera algún nodo infeliz $i$ entonces


\[
s(i) \sum_{(i,j) \in E} s(j)w(i,j) = -k < 0,
\]

y lo cambiaríamos de signo para que la suma pasara a ser $\Phi(s) + 2k$. 
Este valor no puede crecer indefinidamente (está acotado tomando
valores absolutos), luego el proceso termina en una red feliz.

Está en FNPT

**** Técnicas de reducción de problemas
***** Reemplazamiento local
***** Reemplazamiento local con refuerzo

*** Tema 5: Complejidad de problemas de optimización aproximados
**** Aproximación y optimización
***** Algoritmo ε-aproximado                                                                                :drill:
SCHEDULED: <2018-06-20 Wed>
:PROPERTIES:
:ID:       29b0079a-cd28-4c67-b95e-076f33f852da
:DRILL_LAST_INTERVAL: 3.3958
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-17 Sun 17:13]
:END:
¿Cuándo es ε-aproximado un algoritmo?

****** Answer
M es un algoritmo ε-aproximado si

\[
\frac{\abs{c(M(x)) - opt(x)}}{\max\{ opt(x), c(M(x)) \}} \leq \varepsilon
\]

***** Razón de eficacia                                                                                     :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       4b81e602-a98c-4bf5-aa8d-5dc2d642dc16
:DRILL_LAST_INTERVAL: 4.4428
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 01:06]
:END:
Razón de eficacia de un problema de maximización.

****** Answer
Un problema de maximización tiene razón δ si 

\[
\delta \geq \frac{\mathrm{opt}(x)}{C(M(x))}
\]

y un problema de minimización tiene razón δ si

\[
\delta \geq \frac{C(M(x))}{\mathrm{opt}(x)}
\]

***** Umbral de aproximación                                                                                :drill:
SCHEDULED: <2018-06-21 Thu>
:PROPERTIES:
:ID:       b1c8df40-fb7a-4f19-a2d6-73ab04c953c3
:DRILL_LAST_INTERVAL: 4.1359
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 2.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-17 Sun 17:47]
:END:
¿Cuál es el umbral de aproximación de un problema?

****** Answer
El ínfimo de la razón de eficacia mediante algoritmos polinómicos.

***** Esquema de aproximación polinómico                                                                    :drill:
SCHEDULED: <2018-06-21 Thu>
:PROPERTIES:
:ID:       3a0cc88b-e2a9-41bb-af2d-520da3cbfd8a
:DRILL_LAST_INTERVAL: 4.0526
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-17 Sun 17:10]
:END:
¿Qué es un esquema de aproximación polinómico?

****** Answer
Familia de algoritmos parametrizada en δ > 1 tal que para cada ejemplo
x del problema Π puede devolver una aproximación de grado δ del óptimo
en tiempo polinómico en función de |x|.

***** Esquema de aproximación polinómico total                                                              :drill:
SCHEDULED: <2018-06-21 Thu>
:PROPERTIES:
:ID:       64ea37fa-86ca-4cf7-9b01-9138fcc45731
:DRILL_LAST_INTERVAL: 4.3041
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-17 Sun 17:22]
:END:
¿Cuándo es un esquema de aproximación polinómico *total*?

****** Answer
La dependencia de δ de la familia de algoritmos que dan el esquema de
aproximación se puede expresar como un polinomio en 1/(δ-1).

**** Problemas de aproximación
***** 2-aproximado cubrimiento por vértices                                                                 :drill:
:PROPERTIES:
:ID:       99c3b361-93b5-4522-a30c-5b241a5226f7
:END:
Dar un algoritmo 2-aproximado para cubrimiento por vértices.

****** Answer
Mientras haya aristas tomar una arista cualquiera y añadir sus dos
extremos, se borra entonces la arista, los dos nodos, y todas las
aristas conectadas a ellos.

Es 2-aproximado porque todas las aristas tienen que tener al menos un
extremo en $C$, y esta familia de aristas no comparte ninguno.

***** Problema: Corte máximo                                                                                :drill:
:PROPERTIES:
:ID:       e758bcf7-cca4-432b-af89-f34b01f72daf
:END:
Enuncia el problema del corte máximo. Como problema de decisión ¿en
qué clase está?¿Como problema de optimización, dónde está?

****** Answer
Dado un grafo no dirigido, partir sus vértices en dos conjuntos de
forma que el número de aristas de un conjunto al otro sea máximo.

Es NP-completo como problema de decisión. En optimización está
en APX.

***** 2-aproximado corte máximo                                                                             :drill:
SCHEDULED: <2018-06-24 Sun>
:PROPERTIES:
:ID:       b7760225-0274-4e9b-8e4c-49f007498741
:DRILL_LAST_INTERVAL: 4.586
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-19 Tue 10:07]
:END:
Corte máximo es 2-aproximado, dar el algoritmo.

****** Answer
Se toma un conjunto arbitrario de vértices. Mientras el conjunto
cambie, se comprueba para cada vértice si estaría mejor al otro lado
del conjunto (si tiene más arcos hacia la otra parte del grafo) y se
cambia si sí. Esto es polinómico |E|.

Que es 2-aproximado se comprueba asumiendo que llegamos a la propiedad
buscada y usando allí desigualdades, partiendo en cuatro conjuntos de
vértices que nos den el heurístico y el óptimo.

***** Problema: GMAXSAT                                                                                     :drill:
:PROPERTIES:
:ID:       a77d047f-76f4-4d73-a6bb-b6ca962a1cf3
:END:
Enunciar el problema de máxima satisfacción GMAXSAT. ¿En qué clase está?

****** Answer
Para $m$ fórmulas booleanas con $n$ variables, encontrar una
asignación de valores que maximice el número de fórmulas.

/Está en APX./

***** Algoritmo aproximado para GMAXSAT                                                                     :drill:
:PROPERTIES:
:ID:       ae8c9088-ce4b-46f7-a660-dae9ff2b99ba
:END:
Da la idea del algoritmo aproximado para GMAXSAT.

****** Answer
Calculamos la probabilidad de que una asignación de valores sea cierta
para cada cláusula $\phi_i$ como

\[
P(\phi_i) = \frac{t_i}{2^k}
\]

y elegimos a cada paso la asignación que maximice probabilidades. Esto
nunca decrece el valor esperado de fórmulas que se satisfacen, que es con
el que llegamos al final,

\[
P(\Phi) = \sum_{i=1}^m P(\phi_i).
\]

El óptimo lo podemos acotar por el número de cláusulas que empiezan por
probabilidad no nula. Esto nos acaba dando

\[
\delta = \frac{1}{\min \left\{ P(\phi_i) \mid P(\phi_i) > 0 \right\}}.
\]

Para fórmulas con $k$ variables, llegamos a $\delta = 2^{k}$.

***** No aproximación del viajante de comercio                                                              :drill:
SCHEDULED: <2018-06-23 Sat>
:PROPERTIES:
:ID:       a66321cb-da30-4ec2-92c4-f3770c44c9cb
:DRILL_LAST_INTERVAL: 3.8702
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-19 Tue 09:57]
:END:
¿Qué sabemos de las aproximaciones del viajante de comercio?

****** Answer
Si $P \neq NP$, entonces el viajante de comercio no tiene algoritmos
polinómicos con factor $\delta$ para ningún valor de $\delta$. Su umbral de
aproximación es $\infty$.

***** No aproximación del viajante de comercio: idea                                                        :drill:
:PROPERTIES:
:ID:       42f29a3e-98c4-4e90-8f6e-bf7a6a797b9c
:END:
Por qué sabemos que el viajante de comercio tiene umbral de
aproximación $\infty$.

****** Answer
Si tuviera alguna aproximación polinómica de factor $\delta$, dado un
grafo, podríamos obtener su circuito hamiltoniano; para eso asignamos
un $1$ a las aristas del grafo y $\delta|V|$ a las que no están en el
grafo.

Aplicamos la aproximación, y excepto que encontrara un circuito de
coste $|V|$, tendría que devolver uno con más coste que $\delta|V|$. Entonces
sabríamos que no hay ninguno de coste $|V|$ (por aproximación) y no
habría circuito hamiltoniano.

***** Problema de la mochila (de función)                                                                   :drill:
SCHEDULED: <2018-06-23 Sat>
:PROPERTIES:
:ID:       7cebf32a-f727-4c4c-b48a-fb3d1047909c
:DRILL_LAST_INTERVAL: 3.8845
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-19 Tue 10:24]
:END:
Enuncia el problema de la mochila. ¿Qué tipo de algoritmo se le puede dar?

****** Answer
Dados pesos w₁,...,wₙ y valores v₁,...,vₙ; además de un peso límite W,
encontrar el subconjunto de objetos S ⊆ {1,...,n} tal que la suma de
pesos es menor del límite y el valor es máximo.

Se le puede dar un algoritmo pseudopolinómico ${\cal O}(n^2V)$ donde
$V$ es el máximo de los valores.

***** Clase del problema de la mochila                                                                      :drill:
:PROPERTIES:
:ID:       c8495ee2-98da-4096-bac1-de3ef94f3c6c
:END:
En qué clase está el problema de la mochila en su versión de
aproximación.

****** Answer
Está en FPTAS. Tiene un esquema de aproximación polinómico total,
de orden

\[
{\cal O}\left( \frac{n^3}{\delta-1} \right)
\]

***** Algoritmos al problema de la mochila                                                                  :drill:
:PROPERTIES:
:ID:       ad9d357a-25cc-42fc-af1c-ccd2785fad8f
:END:
¿Qué dos algoritmos podemos dar para el problema de la mochila en su
versión de aproximación?¿Qué característica tiene cada uno?

****** Answer

 * Uno que es pseudopolinómico en ${\cal O}(nV)$.

 * Un esquema de aproximación polinómico total de complejidad

   \[
   {\cal O}\left(\frac{n^3}{\delta - 1}\right)
   \]

***** Teorema del esquema del conjunto independiente                                                        :drill:
:PROPERTIES:
:ID:       7b215d83-1c2c-4898-acb4-9d5b36a0def7
:END:
Si el máximo conjunto independiente está en APX, entonces estará en
PTAS, ¿por qué?

****** Answer
Dado un $\delta$ podemos considerar el algoritmo que toma el $G^2$, que tiene
un independiente de tamaño $k^2$ ssi el $G$ lo tiene de tamaño $k$. Calculando,
podemos deducir un factor $\sqrt{\delta}$ así.

**** Sobre las clases NPO y PO
***** Clase NPO                                                                                             :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       c9f72540-a4c4-48f4-b84d-fb0bbd163b56
:DRILL_LAST_INTERVAL: 4.1524
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 01:16]
:END:
Define la clase NPO. Da un ejemplo de problema.

****** Answer
(NP Optimization)
Problemas cumpliendo:

 1. Las entradas correctas se *reconocen* en tiempo polinómico.
 2. Existe q polinomio tal que para cada caso x y cada solución
    factible y, se cumple |y| ≤ q(|x|). Además, para cada |y| ≤ q(|x|)
    podemos decidir en tiempo polinómico si es una solución factible.
 3. La función de *costo* se calcula en tiempo polinómico.

/Ejemplo: viajante de comercio en optimización./

***** Clase PO                                                                                              :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       b3b88cdc-e96b-462a-8596-38cccde44cc5
:DRILL_LAST_INTERVAL: 3.7223
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 12:18]
:END:
Define la clase PO. Da un ejemplo de problema.

****** Answer
Está en NPO y existe un algoritmo polinómico tal que para cada x
calcula la solución óptima y su coste.

/Ejemplo: distancia mínima en grafos/

***** Relación NP vs NPO                                                                                    :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       bd7ca7ae-53c7-4950-9dca-fa20548b3459
:DRILL_LAST_INTERVAL: 3.9631
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 11:27]
:END:
Relación entre clases NP y NPO.

****** Answer
Cualquier problema de optimización de NPO tiene su correspondiente
problema de decisión en NP.

***** Relación optimización, decisión                                                                       :drill:
SCHEDULED: <2018-06-21 Thu>
:PROPERTIES:
:ID:       87031856-8a25-4b49-8055-553d095a0f5b
:DRILL_LAST_INTERVAL: 4.3514
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-17 Sun 21:42]
:END:
¿Qué teorema relaciona problemas de optimización y de decisión?

****** Answer
Si P ≠ NP entonces PO ≠ NPO.

**** La clase APX
***** Clase APX                                                                                             :drill:
SCHEDULED: <2018-06-21 Thu>
:PROPERTIES:
:ID:       bb345650-df81-4b42-aea4-530895973224
:DRILL_LAST_INTERVAL: 3.2314
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 00:58]
:END:
Clase APX.

****** Answer
(Approximable)
La clase APX es de problemas que admiten un algoritmo δ-aproximado
polinómico para algún δ < ∞.

***** Ejemplos en APX                                                                                       :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       382598c2-5593-4dc9-82f5-f036aabbd483
:DRILL_LAST_INTERVAL: 3.979
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 2
:DRILL_AVERAGE_QUALITY: 2.333
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 11:05]
:END:
Da tres ejemplos de problema en APX, la clase de problemas que admiten
un algoritmo δ-aproximado polinómico para algún δ < ∞.

****** Answer
Cubrimiento mínimo por vértices, problema de la mochila, corte máximo,
máximo número de cláusulas satisfechas en SAT,...

***** Ejemplos que no están en APX                                                                          :drill:
SCHEDULED: <2018-06-21 Thu>
:PROPERTIES:
:ID:       76c9465f-cdb0-488f-a4d9-e6efa693a635
:DRILL_LAST_INTERVAL: 3.4901
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 12:13]
:END:
Da tres ejemplos de problema *que no esté* en APX, la clase de
problemas que admiten un algoritmo δ-aproximado polinómico para algún
δ < ∞.

****** Answer
Viajante de comercio, máximo clique (este es especialmente interesante porque
podría parecer lo contrario, pero hay que jugar con la diferencia entre δ para
optimización y minimización), máximo conjunto independiente.

***** Relación aproximación, decisión                                                                       :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       a989a2db-bd9b-4756-8e09-56b2ec9928e9
:DRILL_LAST_INTERVAL: 4.34
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 11:38]
:END:
Teorema que relaciona decisión y esquemas de aproximación polinómicos.

****** Answer
Si P ≠ NP, entonces PO ≠ NPO.

**** La clase PTAS y FPTAS
***** Clase PTAS                                                                                            :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       17f9aed8-071f-45ec-9c40-de2797bea332
:DRILL_LAST_INTERVAL: 3.6117
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 01:13]
:END:
Definición de PTAS. Ejemplos de problema en PTAS.

****** Answer
(Polynomial-Time Approximation Scheme)
Problemas con esquema de aproximación polinómico.

/Ejemplo: el problema de la mochila con copias ilimitadas./
/Ejemplo: cubrimiento mínimo de grafos planares./
/Ejemplo: viajante de comercio ¡en el plano euclídeo!/

***** Lista de inclusiones                                                                                  :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       28527796-437b-4d0d-b2b3-fc57abb5843c
:DRILL_LAST_INTERVAL: 3.7476
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 11:27]
:END:
Da la lista de inclusiones entre FPTAS, APX, PO, NPO y PTAS.

****** Answer

PO ⊂ FPTAS ⊂ PTAS ⊂ APX ⊂ NPO

***** APX fuera de PTAS                                                                                     :drill:
SCHEDULED: <2018-06-21 Thu>
:PROPERTIES:
:ID:       7c7d6c48-c36f-4c53-8627-40fd62c9419c
:DRILL_LAST_INTERVAL: 3.2371
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 2.5
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 01:16]
:END:
Dar un problema en APX que no esté en PTAS (asumimos P ≠ NP).

****** Answer
El corte máximo. El cubrimiento mínimo en general.

***** Cubrimiento mínimo en grafos planares                                                                 :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       a96326b9-518b-4d9b-a026-6381746b35e5
:DRILL_LAST_INTERVAL: 4.019
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 01:01]
:END:
¿En qué clase de complejidad de aproximación está el problema del
cubrimiento mínimo?¿Qué cambia en el caso de grafos planares?

****** Answer
El cubrimiento mínimo está en APX. Sólo en el caso de grafos planares,
está en PTAS.

***** Clase FPTAS                                                                                           :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       01c8ada7-8c4c-4e9b-860f-04e910167d0e
:DRILL_LAST_INTERVAL: 4.3085
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 2.5
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 12:09]
:END:
Definición de la clase FPTAS.

****** Answer
(Fully Polynomial-Time Approximation Scheme)
Son problemas con un esquema de aproximación polinómico total. Para
cada ejemplo x de Π y cada δ > 1, el algoritmo devuelve una solución
que es polinómica en |x| y en 1/(δ-1).

***** Problema acotado polinómicamente                                                                      :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       1a7e1140-3c9d-4c88-9a94-30d933b8318b
:DRILL_LAST_INTERVAL: 3.7841
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 2.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 01:16]
:END:
Problema acotado polinómicamente. Ejemplo de problema que esté y de
problema que seguramente no esté.

****** Answer
(NPOPB - NPO Polinomially Bounded)
Un problema de optimización está acotado polinómicamente si existe un
polinomio p tal que para todo ejemplo x y toda solución factible y,
se tiene coste acotado polinómicamente, C(x,y) ≤ p(|x|).

/Ejemplo: el cubrimiento mínimo por vértices es NPOPB./
/Contraejemplo: el viajante de comercio NO está en NPOPB./

***** FPTAS y PTAS                                                                                          :drill:
SCHEDULED: <2018-06-21 Thu>
:PROPERTIES:
:ID:       ff0ec66c-1172-425b-917b-b2ea93b67e91
:DRILL_LAST_INTERVAL: 4.2708
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-17 Sun 22:03]
:END:
Teorema que relaciona FPTAS y PTAS.

****** Answer
No existe un problema NP-difícil acotado polinómicamente (NPOPB) con
un esquema de aproximación polinómico total.

En particular, si P ≠ NP, entonces PTAS ≠ FPTAS.

**** Pseudopolinómicos
***** Pseudopolinómicos                                                                                     :drill:
:PROPERTIES:
:ID:       218323d9-16ce-4a45-a5bb-36795c0a4533
:END:
¿Qué es un algoritmo pseudopolinómico?

****** Answer
Aquel que para cada ejemplo del problema, da la respuesta correcta un
tiempo que depende polinómicamente de |x| y del mayor entero en la
especificación de x, que llamamos $\mathrm{max}(x)$.

***** Teorema de pseudopolinómicos                                                                          :drill:
SCHEDULED: <2018-06-23 Sat>
:PROPERTIES:
:ID:       c82af765-2f19-4b10-a17d-b04a24fd0fc1
:DRILL_LAST_INTERVAL: 4.4148
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 2.5
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-19 Tue 10:25]
:END:
Enuncia el teorema de pseudopolinómicos.

****** Answer
Si un problema está en FPTAS y tiene un pseudopolinomio verificando

\[
\mathrm{opt}(x) \leq p(|x|, \mathrm{max}(x))
\]

entonces el problema es pseudopolinómico.

**** L-reducciones y AP-reducciones
***** L-reducción                                                                                           :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       ed54bad5-dfd0-46ef-9a13-55bff76f5531
:DRILL_LAST_INTERVAL: 4.9122
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 2.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-17 Sun 22:02]
:END:
Definir L-reducción.

****** Answer
El problema de optimización Π₁ se L-reduce a Π₂, y se escribe Π₁ ∝ Π₂,
si y sólo si existen R y S espacio logarítmicas con constantes α y β
tales que
 
 * si x es ejemplo de Π₁, entonces R(x) es ejemplo de Π₂ con

   opt(R(x)) ≤ α opt(x);

 * si s es solución factible de R(x), entonces S(s,x) es solución
   factible de x con

   ∣opt(x) - C(S(s,x))∣ ≤ β ∣opt(R(x)) - C(s)∣.

***** TODO AP-reducción                                                                                     :drill:
:PROPERTIES:
:ID:       2843d6e8-8735-4aa2-b58d-f32ca8bf37bb
:END:
**** Problemas completos                                                                                     :extra:
*** Tema 6: Complejidad en espacio. Jerarquía polinómica
**** Clase DP                                                                                                :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       b0ad156d-465c-4780-8da4-385cec85072b
:DRILL_LAST_INTERVAL: 4.0767
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 12:27]
:END:
Definición de la clase DP.

***** Answer
(Difference Polynomial Time) Un lenguaje está en DP si es L = L₁ ∩ L₂
con L₁ en NP y L₂ en CoNP.

**** Problemas DP-completos                                                                                  :drill:
SCHEDULED: <2018-06-21 Thu>
:PROPERTIES:
:ID:       037aad50-1103-4695-a80f-83d52e6441df
:DRILL_LAST_INTERVAL: 3.2474
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 2
:DRILL_FAILURE_COUNT: 1
:DRILL_AVERAGE_QUALITY: 2.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 12:06]
:END:
Dar dos problemas DP-completos.

***** Answer
*Problema del viajante de comercio exacto:* dado un mapa y un
valor X, determinar si la solución es de coste exactamente X.

*Problema SAT-UNSAT:* Dados dos conjuntos de cláusulas, determinar si
el primero es consistente y el segundo inconsistente.

*Consistencia crítica:* Dado un conjunto de cláusulas, determinar si
es inconsistente y si se puede hacer consistente quitándole una
cláusula.

*Consistencia única:* Dada una fórmula booleana, determinar si existe
una /única/ asignación de valores de verdad que la satisfaga.

*Circuito hamiltoniano crítico:*

*3 colores crítico:*

**** Oráculos y clases relativas
***** Oráculo                                                                                               :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       c4a03a13-81ac-47dc-a90f-a4420d02cada
:DRILL_LAST_INTERVAL: 3.9123
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 11:06]
:END:
¿Qué es un oráculo?

****** Answer
Un programa que resuelve un problema determinado y al que se puede
llamar en la resolución de otro problema, contando la llamada como
un sólo paso.

***** Clase Pᴺᴾ                                                                                             :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       d67cb758-6c5c-4548-a631-14855bfbe6de
:DRILL_LAST_INTERVAL: 3.721
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 11:06]
:END:
Definición de clase Pᴺᴾ.

****** Answer
Problemas que se resuelven en tiempo polinómico pudiendo llamar a un
oráculo que resuelve un problema NP.

***** Clase FPᴺᴾ                                                                                            :drill:
SCHEDULED: <2018-06-22 Fri>
:PROPERTIES:
:ID:       7ff805d6-11c9-4b47-9f24-f29f718d6e52
:DRILL_LAST_INTERVAL: 3.9816
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 4.0
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-18 Mon 12:26]
:END:
Definición de clase FPᴺᴾ.

****** Answer
Problemas *de funciones* que se resuelven en tiempo polinómico
pudiendo llamar a un oráculo que resuelve un problema NP.

***** Problemas FPᴺᴾ-completos                                                                              :drill:
SCHEDULED: <2018-06-24 Sun>
:PROPERTIES:
:ID:       24e5ca94-bea4-4a87-aada-926bf3c10708
:DRILL_LAST_INTERVAL: 4.5273
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 3
:DRILL_FAILURE_COUNT: 2
:DRILL_AVERAGE_QUALITY: 2.667
:DRILL_EASE: 2.5
:DRILL_LAST_QUALITY: 4
:DRILL_LAST_REVIEWED: [2018-06-19 Tue 10:27]
:END:
Di cuatro problemas FPᴺᴾ-completos.

****** Answer

 * *MAXSAT con peso:* dado un conjunto de cláusulas con pesos, dar una
   asignación de verdad que maximice la suma de pesos de las que
   satisface.

 * *Salida máxima de MT no-determinista:* dada una máquina de Turing
   no determinista M y una entrada 1ⁿ de forma que termina en tiempo O(n)
   y escribe un entero en binario, determinar el mayor entero que puede
   escribir.

 * *Problema de optimización en el viajante de comercio:* dado un
   problema de viajante de comercio, determinar circuito de coste
   óptimo.

 * *Problema de coste en el viajante de comercio:* dado un problema
   del viajante de comercio, determinar el mínimo coste de un
   circuito.
 
**** Jerarquía polinómica
***** Definición                                                                                            :drill:
:PROPERTIES:
:ID:       d432d64c-38b5-4374-b307-196d800c56e8
:END:
Cómo se define la jerarquía polinómica.

****** Answer
Δ₀ = P
Σ₀ = P
Π₀ = P

Δᵢ₊₁ = P^Σᵢ
Σᵢ₊₁ = NP^Σᵢ
Πᵢ₊₁ = CoNP^Σᵢ

***** Clase PH                                                                                              :drill:
SCHEDULED: <2018-06-24 Sun>
:PROPERTIES:
:ID:       8d24850f-7611-4af2-b5e0-429d0a5e2bbb
:DRILL_LAST_INTERVAL: 4.7385
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 5.0
:DRILL_EASE: 2.6
:DRILL_LAST_QUALITY: 5
:DRILL_LAST_REVIEWED: [2018-06-19 Tue 10:08]
:END:
Definir la clase PH. ¿Dónde está contenida?

****** Answer

\[
PH = \bigcup_{i \geq 0} \Sigma_i
\]

si hubiera un problema PH-completo, la jerarquía polinómica colapsaría
en un nivel.

PH está en PSPACE.

*** Tema 7: Complejidad en modelos de computación paralela
*** Relaciones
**** Relación 1

***** Ejercicio 1
****** Apartado a
#+BEGIN_SRC turing
; Acepta las palabras con el mismo número de ceros que de unos.
; Usa un alfabeto 0, 1, %.

; En el estado inicial, lee el primer 0 o el primer 1.
; Si la entrada está vacía, termina directamente.
0 0 _ r b1
0 1 _ r b0
0 % _ r 0
0 _ _ * accept

; En el estado b0 busca un 0.
; En el estado b1 busca un 1.
b0 0 % * f
b0 _ _ r reject
b0 * * r b0

b1 1 % * f
b1 _ _ r reject
b1 * * r b1

; En el estado f vuelve hasta el principio de la cadena.
f _ _ r 0
f * * l f 

; Estados de aceptación o rechazo.
accept * : r accept2
accept2 * ) * halt-accept

reject _ : r reject2
reject * _ l reject
reject2 * ( * halt-reject
#+END_SRC
****** Apartado b
#+BEGIN_SRC turing
; Acepta las palabras de la forma A^nB^nC^n.
; Nótese que acepta la cadena vacía.

; Busca la primera A
0 % _ r 0
0 A _ r 1
0 _ _ * accept
0 * * * reject

; Busca la primera B
1 A * r 1
1 % * r 1
1 B % r 2
1 _ * * reject

; Busca la primera C
2 B * r 2
2 % * r 2
2 C % * f
2 _ * * reject

; En el estado f vuelve hasta el principio de la cadena.
f _ _ r 0
f * * l f 

; Estados de aceptación o rechazo.
accept * : r accept2
accept2 * ) * halt-accept

reject _ : r reject2
reject * _ l reject
reject2 * ( * halt-reject
#+END_SRC
****** Apartado c
#+BEGIN_SRC turing
; Acepta palíndromos

; Busca una letra
0 0 _ r a0
0 1 _ r a1
0 _ _ * accept
0 * * * reject

a0 _ _ l b0
a0 * * r a0

a1 _ _ l b1
a1 * * r a1

b0 0 _ l f
b0 _ * * accept
b0 * * * reject

b1 1 _ l f
b1 _ * * accept
b1 * * r reject

; En el estado f vuelve hasta el principio de la cadena.
f _ _ r 0
f * * l f 

; Estados de aceptación o rechazo.
accept * : r accept2
accept2 * ) * halt-accept

reject _ : r reject2
reject * _ l reject
reject2 * ( * halt-reject
#+END_SRC
****** Apartado d
#+BEGIN_SRC turing
; Acepta las palabras con el mismo número de ceros que de unos.
; Usa un alfabeto 0, 1, %.

; En el estado inicial, lee el primer 0 o el primer 1.
; Si la entrada está vacía, termina directamente.
0 0 _ r bc0
0 1 _ r bc1
0 % _ r 0
0 c _ r aif
0 _ _ * accept

bc0 c * r b0
bc0 * * r bc0
bc1 c * r b1
bc1 * * r bc1

; En el estado b0 busca un 0.
; En el estado b1 busca un 1.
b0 0 % * f
b0 % * r b0
b0 * * r reject

b1 1 % * f
b1 % * r b1
b1 * * r reject

; En este último estado se comprueba que no quede nada detrás de la c
aif % _ r aif
aif _ * r accept
aif * * * reject

; En el estado f vuelve hasta el principio de la cadena.
f _ _ r 0
f * * l f 

; Estados de aceptación o rechazo.
accept * : r accept2
accept2 * ) * halt-accept

reject _ : r reject2
reject * _ l reject
reject2 * ( * halt-reject
#+END_SRC
***** Ejercicio 2
***** Ejercicio 3
#+BEGIN_SRC text
; Mueve una cadena de 0s y 1s a la derecha

;; Estado inicial
0 _ * l leer
0 * * r 0

;; Lee una posición
leer 0 * r escribir0
leer 1 * r escribir1
leer _ * r final

;; Escribe un 0 o un 1 según lo que hubiera leído
escribir0 * 0 l mover
escribir1 * 1 l mover

;; Estado auxiliar para moverse dos posiciones a la izquierda
mover * * l leer

;; Estado final
final * _ * halt-accept
#+END_SRC

***** Ejercicio 4
#+begin_statement
Escribir una subrutina que comience en una posición con un cero y se
mueva a la derecha de todos los ceros hasta que alcance un uno o un
blanco. Se suponen que en la cinta solo hay caracteres del conjunto
{0, 1, #}. Si se comienza con un carácter que es distinto de cero, la
subrutina de la MT debe de pararse. Utilizar dicha rutina para
escribir una MT que acepte todas las cadenas de ceros y unos, que no
tengan dos unos consecutivos.
#+end_statement

Siendo =q= el estado que llama al estado inicial =i= de la subrutina.

#+BEGIN_SRC text
-- Estado i inicial, que comprueba que empieza en 0.
d(i;0) = (j,0,R)
d(i,1) = (reject)
d(i,#) = (reject)

-- Mueve a la derecha mientras haya ceros.
d(j,0) = (j,0,R)
d(j;1) = (q,1,S)
d(j;#) = (q,#,S)
#+END_SRC

La MT que acepta cadenas sin dos unos consecutivos es la siguiente.

#+BEGIN_SRC text
d(u;0) = (u,0,R)
d(u;#) = (u,#,R) -- (accept)
d(u;1) = (i,1,R)
#+END_SRC

***** Ejercicio 5
#+attr_latex: :options [Ejercicio 5]
#+begin_statement
Diseñar una MT con dos cintas que dada una sucesión de ceros de
longitud n en la primera cinta, calcula en la segunda cinta n en
binario.
#+end_statement

Una máquina $T = \left( \left\{ i,s,r, \mathrm{accept} \right\} , \left\{ 0,1,\_ \right\} , d, i,\_, \left\{ \mathrm{accept} \right\} \right)$.
Tiene un estado inicial =i= que lee los ceros de la primera cinta,
luego pasa a una subrutina de sumar 1 en el estado =s=, llevándose
uno en cada suma. Finalmente el estado =r= vuelve a colocar el
cabezal de la segunda cinta al principio.

#+begin_src text
d(i;_,*) = (accept)
d(i;0,*) = (s;0,*,R,S)

d(s;*,0) = (r;*,1,S,S)
d(s;*,_) = (r;*,1,S,S)
d(s;*,1) = (s;*,0,S,R)

d(r;*,_) = (i;*,_,S,R)
d(r;*,0) = (r;*,0,S,L)
d(r;*,1) = (r;*,1,S,L)
#+end_src

***** Ejercicio 6
#+attr_latex: :options [Ejercicio 6]
#+begin_statement
Escribir una MT con múltiples cintas que sume dos números en
binario. Se supone que aparecen en la cinta de entrada separados por
un sı́mbolo especial c.
#+end_statement

#+BEGIN_SRC text
-- Estado inicial, busca la C.
d(m;0,*) = (m;0,*,R,S)
d(m;1,*) = (m;1,*,R,S)
d(m;C,*) = (c;C,*,R,S)

-- Copia en la cinta de abajo.
d(c;0,*) = (c;0,0,R,R)
d(c;1,*) = (c;1,1,R,R)
d(c;_,*) = (r1;_,*,S,S)

-- Regresa en ambas cintas.
d(r1;0,*) = (r1;_,*,L,L)
d(r1;1,*) = (r1;_,*,L,L)
d(r1;C,*) = (r2;_,*,L,S)

-- Regresa sólo en la superior.
d(r2;0,*) = (r2;0,*,L,S)
d(r2;1,*) = (r2;1,*,L,S)
d(r2;_,*) = (s;_,*,R,R)

-- Suma sin llevadas
d(s;0,0) = (s;*,0,R,R)
d(s;1,0) = (s;*,1,R,R)
d(s;0,1) = (s;*,1,R,R)
d(s;_,0) = (s;*,0,R,R)
d(s;0,_) = (s;*,0,R,R)
d(s;1,_) = (s;*,1,R,R)
d(s;_,1) = (s;*,1,R,R)
d(s;1,1) = (sl;*,0,R,R)
d(s;_,_) = (accept)

-- Suma con llevadas
d(sl;0,0) = (s,*,1,R,R)
d(sl;1,0) = (sl,*,0,R,R)
d(sl;0,1) = (sl,*,0,R,R)
d(sl;_,0) = (s,*,1,R,R)
d(sl;0,_) = (s,*,1,R,R)
d(sl;1,_) = (sl,*,0,R,R)
d(sl;_,1) = (sl,*,0,R,R)
d(sl;1,1) = (sl,*,1,R,R)
d(sl;_,_) = (s,*,1,R,R)
#+END_SRC

***** Ejercicio 7
#+begin_statement
Describir una MT que dada una palabra ucw donde u y w son dos palabras
sobre el alfabeto {0, 1} y c es un sı́mbolo adicional, calcule u
repetido tantas veces como indique la palabra w interpretándola como
un entero escrito en binario.
#+end_statement

Usamos dos cintas. Movemos hasta el símbolo c, luego decrementamos
uno y copiamos en la cinta de abajo; repetimos hasta llegar a 0 en 
el número.

#+BEGIN_SRC text
-- Estado inicial, busca la C en la cinta superior
d(i;0,*) = (i;0,*,R,S)
d(i;1,*) = (i;1,*,R,S)
d(i;C,*) = (m;C,*,R,S)

-- Estado en el que busca el primer uno para decrementarlo.
-- Si no lo encuentra, ha terminado.
d(m;0,*) = (m;0,*,R,S)
d(m;1,*) = (c;0,*,L,S)
d(m;_,*) = (accept)

-- Estado en el que resta escribiendo los unos anteriores.
d(e;0,*) = (e;1,*,L,S)
d(e;C,*) = (r;e,*,L,S)

-- Estado en el que regresa al principio de la cinta superior.
d(r;0,*) = (r;0,*,L,S)
d(r;1,*) = (r;1,*,L,S)
d(r;_,*) = (c;_,*,R,S)

-- Estado para copiar la palabra. Termina volviendo al estado
-- en el que decrementa un 1.
d(c;0,*) = (c;0,0,R,R)
d(c;1,*) = (c;1,1,R,R)
d(c;C,*) = (m;C,*,R,S)
#+END_SRC

***** Ejercicio 9
#+begin_statement
Describir MTND que acepten los siguientes lenguajes

 a) Conjunto de palabras que contienen una subcadena de longitud 100
    que se repite aunque no necesariamente de forma consecutiva.

 b) El conjunto de las cadenas $w_1 \circ w_2 \circ \dots \circ w_{n}$ donde $w_i \in \left\{ 0,1 \right\}^{\ast}$ y 
    para algún $j$, $w_j$ coincide con la representación en binario de $j$.
 
 c) El conjunto de las cadenas $w_1 \circ w_2 \circ \dots \circ w_{n}$ donde $w_i \in \left\{ 0,1 \right\}^{\ast}$ y 
    para al menos dos valores de $j$, $w_j$ coincide con la representación
    en binario de $j$.

 d) Palabras que contienen a un palíndromo de longitud mayor o igual
    a 5 como subcadena.
#+end_statement

a) Al principio, a cada paso, la máquina puede elegir avanzar una
   casilla o marcarla en una segunda multipista y pasar a un estado en
   el que

   - avanza 100 casillas usando 100 estados dedicados a esto; luego
     puede elegir a cada paso entre avanzar o entrar a un estado
     en el que marca la casilla y entonces simplemente tiene que
     comprobar que haya 100 caracteres iguales empezando desde ambas
     marcas.
     
   Comprobar que hay 100 caracteres iguales empezando de ambas marcas
   puede hacerse memorizando (en el estado) a cada paso un número del
   0 al 100 y el caracter después de la primera marca. Se mueve la
   primera marca a la derecha, busca la segunda marca y comprueba que
   sea el mismo; acaba moviendo la segunda marca a la derecha y
   volviendo a buscar el primer caracter.

b) Usamos una máquina con dos cintas y empezamos escribiendo un 1 en
   la segunda. En cada paso, la máquina puede elegir entre 

   - empezar una subrutina que incremente el valor binario de la
     segunda cinta en 1 y luego mueva la primera cinta hasta el
     próximo símbolo $\circ$, o

   - empezar una subrutina que comprueba que el número de la segunda
     cinta sea igual que el de la primera hasta el próximo símbolo
     $\circ$; aceptando si lo es.
 
c) Usamos la misma máquina del apartado anterior, pero en este caso,
   en lugar de aceptar, vuelve el cabezal de ambas cintas al principio
   de la comprobación, ejecuta la rutina que incrementa y pasa al siguiente
   bloque y pasa a un estado inicial en una réplica exacta de todos los
   estados de la máquina.

d) A cada paso, la máquina puede elegir entre moverse a la derecha o
   pasar a un estado en el que
   
     - deja una marca (asumiendo multipista), pasa primero por cinco
       estados numerados en los que sólo puede moverse a la derecha,
       para llegar a un estado en el que puede elegir si marcar una
       casilla y comprobar palíndromo entre las dos marcas o avanzar
       una casilla.

   Comprobar un palíndromo entre dos marcas es algo que podemos hacer
   yendo a la primera marca y empezando el caso de palíndromos del
   ejercicio 1 como subrutina.

***** Ejercicio 10
Acepta todas las cadenas que no empiecen por 1.

***** Ejercicio 11
#+begin_statement
Un autómata con pila de fuerza $k$ es un autómata con $k$ pilas (generalizando
la definición de autómata con pila). Demostrar que la clase de lenguajes
aceptados por los autómatas con pila de fuerza $k$ para $k \geq 2$ coincide con
la clase de lenguajes aceptados por las MT.
#+end_statement

Si podemos usar más de una pila, dada una MT, podemos hacer que el
autómata lea la entrada a la primera pila, la pase a la segunda pila
y, a partir de ahí, actúe como la MT usando ambas pilas como cinta
para la MT. Pasar a la izquierda o derecha se corresponde con mover
el símbolo a una pila u otra.

Un autómata con pila de fuerza $k$ puede reproducirse con una máquina
de Turing con $k$ cintas donde los movimientos de la pila pueden
reproducirse escribiendo o borrando en el tope de esas cintas
y avanzando en la primera, la de entrada.

***** Ejercicio 12
# EJERCICIO HECHO EN CLASE

#+begin_statement
Una MT de escritura simple es una MT que, a lo más, puede escribir en
cada casilla una vez. Demostrar que la clase de lenguajes aceptados por
las MT de escritura simple coincide con la clase de lenguajes aceptados
por las MT.
#+end_statement

Demostraremos que coincide con la clase de lenguajes aceptados por las
MT semilimitadas. Dada una MT semilimitada, tomamos su palabra de entrada
$\rhd a_1a_2\dots a_n$ y después de ella, la escribimos con dos espacios entre cada letra,
$\rhd \#\downarrow a_1\#\#a_2\#\#\dots a_n$.


Ahora, ejecutamos la misma máquina en cinta ilimitada pero
moviéndonos dos pasos a izquierda o derecha cada vez que nos queramos mover
y haciendo lo siguiente cada vez que queramos escribir:

 * memorizamos el símbolo que queremos escribir
   nuestro símbolo, $\rhd \#\downarrow a_1\#\#a_2\#\#\dots A_j\# a_i \dots \#\# a_n$ y copiamos de nuevo
   la palabra separada por espacios simplemente cambiando el $a_i$ por
   el $a_j$ y marcando a su lado que allí está el cursor. 

    * $\rhd \#\#a_1\#\#a_2\#\#\dots A_j\#a_i \dots \#\# a_n$
    * $\rhd \#\#a_1\#\#a_2\#\#\dots \#\downarrow a_j \dots \#\# a_n$
 
   Podemos usar los espacios en blanco para ir marcando por dónde
   vamos en la copia sin tener que escribir dos veces en ninguna
   casilla.  Nos quedamos finalmente en el punto que hayamos cambiado,
   que podemos escribir el último.

Nótese que cada transición con escritura y movimiento puede partirse en
una con escritura y otra con movimiento.  O podemos memorizar el movimiento
y escribir el cursor $\downarrow$ de forma adecuada.

Falta tener en cuenta que para la copia necesitamos saber por dónde íbamos.

***** Ejercicio 13
#+begin_statement
Sea $L$ el lenguaje que contiene una sola palabra: $0$ si no hay vida fuera
de la tierra y $1$ si hay vida fuera de la tierra. ¿Es $L$ calculable por una
MT?
#+end_statement

Asumiendo tercio excluso; en ambos casos el lenguaje es computable.

***** Ejercicio 14
#+begin_statement
Diseñar una MT que dada una palabra $u$ calcule una palabra formada por todos
los símbolos que ocupan las posiciones pares de $u$.
#+end_statement

Podemos usar dos cintas.

#+BEGIN_SRC text
d(a;0,*) = (b;0,0,L,L)
d(a;1,*) = (b;1,1,L,L)
d(b;*,*') = (a;*,*',L,S)
#+END_SRC

Similar al ejercicio 15.

***** Ejercicio 15
#+begin_statement
Diseñar una MT con varias cintas que dada una palabra $u$ calcule una palabra
formada por todos los símbolos que ocupan las posiciones pares de $u$ seguidos
por todos los símbolos que ocupan las posiciones impares de $u$. Por ejemplo para
la entrada 0101 calcularía 1100.
#+end_statement

Podemos usar cuatro cintas. La máquina tiene dos estados, y a cada paso avanza
en la primera cinta y cambia entre ellos. El estado decide a cuál de las cintas
copiará. Hará esto hasta encontrar un blanco.

Finalmente copiará los contenidos de cada una de las cintas a la cinta final.

**** Relación 2
***** Ejercicio 1
#+begin_statement
Sobre el alfabeto $A = \left\{ a,b,c \right\}$, calcular las palabras $C(143)$ y $C(100)$.
#+end_statement

Tenemos

 * $C(143) = aacbb = 2+3\cdot 2+ 3^2\cdot 3 + 3^3 \cdot 1 + 3^4\cdot 1$,
 * $C(100) = c\;a\;c\;a = 1 + 3 + 3^2 + 3^3 \cdot 3$.

***** Ejercicio 2
#+begin_statement
Sobre el alfabeto $A = \left\{ a,b,c \right\}$, calcular las palabras $Z(aabc)$ y $Z(bac)$.
#+end_statement

Tenemos

 * $Z(aabc) = 3 + 2 \cdot 3 + 1 \cdot 3^2 + 1 \cdot 3^3 = 45$,
 * $Z(bac) = 3 + 1 \cdot 3 + 2 \cdot 3^2= 24$.

***** Ejercicio 3
#+begin_statement
Discutir la posibilidad de asignar un número natural a cada MT con independencia
del alfabeto de entrada.
#+end_statement

***** Ejercicio 4
#+begin_statement
Construir una MT que dada una entrada $w$, la convierte en una salida $w111w$.
#+end_statement

Usando multicinta, se copia una vez, se escribe 111 y se copia otra vez.

***** Ejercicio 5
#+begin_statement
Demostrar que el problema de la parada: determinar el conjunto de parejas
$(M,w)$ tales que la MT $M$ para cuando tiene a $w$ como entrada es r.e. pero
no recursivo.
#+end_statement

Para comprobar que es r.e. simplemente usamos que podemos simular una
máquina de Turing dada en una entrada dada. Si la simulación para la
máquina de Turing original pararía.

No puede ser recursivo porque en otro caso resolveríamos el problema
de la parada.

# Usando reducción de problemas y entrando en bucle si fuéramos a
# rechazar.

***** Ejercicio 6
# dejando máquinas en paralelo

#+begin_statement
Describir de manera informal MTs con varias cintas que enumeren
(produzcan como salida una lista que contenga todas sus palabras)
los siguientes lenguajes (se supone que los números se escriben
en binario):

 1. El conjunto de los cuadrados perfectos.
 2. El conjunto de todos los naturales primos.
 3. El conjunto de todos los números naturales $n$ tales que la
    MT cuya descripción es la palabra $w_n$ acepta la palabra $w_n$
    como entrada ($w_n$ es la palabra sobre $\{0,1\}$ cuyo número asociado
    es $n$.
#+end_statement

*Apartado 1.* La máquina escribirá en la segunda cinta un 1 y en la
tercera un 0. Para conseguir cada cuadrado, sumará la segunda cinta con la
tercera dejando el resultado en la tercera e incrementará dos veces el
contenido de la segunda cinta. Finalmente, escribirá el contenido de la tercera
en la primera. Nótese que usamos crucialmente que
\[
1 + 3 + \dots + (2n - 1) = n^2.
\]

*Apartado 2.* Conocemos una máquina que comprueba si un entero dado
es primo comprobando que no sea divisible por ningún número mayor que
1 y menor que él. La comprobación de divisibilidad $a \mid b$ podríamos
hacerla escribiendo $0$ en una cinta y a cada paso sumando $a$ de nuevo
a esa cinta y comprobando si el contenido de esa cinta es igual que $b$
(en cuyo caso sería divisible) o mayor que $b$ (en cuyo caso no lo sería).

Podemos ir comprobando si cada número es primo en otras cintas y, en
caso de que lo sea, escribirlo en la primera.

*Apartado 3.* Podemos simular una máquina de Turing arbitraria con
entrada arbitraria con la máquina de Turing universal. Lo que
haremos será simular todas las máquinas de Turing $w_{n}$ sobre entrada
$w_n$ en paralelo. Para poder simular varias en paralelo cambiaremos de
máquina entre ellas guardando el estado de las máquinas en una
cinta para pasar a simular otra máquina.

En paralelo, ejecutaremos el primer paso de $w_1$ sobre $w_{1}$. Después, 
ejecutaremos el primer paso de $w_2$, el segundo paso de $w_1$ y guardamos
el estado en la cinta. Después ejecutamos el primer paso de $w_3$, el
segundo de $w_2$ y el tercero de $w_1$. Así sucesivamente, nos aseguramos
que el n-ésimo paso de cualquier máquina se ejecutará eventualmente
para cualquier $n$.

Si el n-ésimo paso se ejecuta eventualmente, cualquier máquina que
pare lo hará eventualmente en la simulación; y podremos escribir su
número natural asociado en la cinta. Nótese que la salida así obtenida
no proporciona necesariamente los números del lenguaje en orden (habrá
máquinas que tarden menos en terminar en la simulación en paralelo que
otras con un número asociado menor).

***** Ejercicio 7
#+begin_statement
Sean $L_1,\dots,L_k$ con $k \geq 2$ un conjunto de lenguajes sobre el alfabeto
$A$ tales que:

  1. Para cada $i \neq j$, tenemos que $L_i \cap L_j = \varnothing$.
  2. $\bigcup_{i=1}^k L_i = A^{\ast}$.
  3. $\forall i \in \left\{ 1,\dots,k \right\}$, el lenguaje $L_i$ es r.e.

Demostrar que $\forall i \in \left\{ 1,\dots,k \right\}$, el lenguaje $L_i$ es recursivo.
#+end_statement

Sabemos que $L_i$ es r.e., veremos que $\overline{L_i}$ es también r.e.; probando
así que $L_i$ es recursivo. Usando las dos primeras condiciones, tenemos
que
\[
\overline{L_i} = \bigcup_{j = 1, j \neq i}^{k} L_j.
\]
Como $\overline{L_i}$ es una unión finita de lenguajes r.e., será r.e.; para
comprobar esto, podríamos usar una máquina que simule las máquinas
que reconocen a cada uno de los lenguajes $L_j$ en paralelo, aceptando
en cuanto una de ellas acepte. Si una palabra pertenece a la unión,
pertenecerá forzosamente a uno de los lenguajes y una de las máquinas
de la simulación parará aceptándola.

***** Ejercicio 8
# usando reducción entre L y L' y luego razonando al complementario.
#+begin_statement
Sea $L$ r.e., pero no recursivo. Considérese el lenguaje
\[
L' = \left\{ 0w \mid w \in L \right\} \cup \left\{ 1w \mid w \not\in L \right\}.
\]
¿Puede asegurarse que $L'$ o su complementario son recursivos, r.e. o no r.e.?
#+end_statement

El complementario de $L'$ es
\[
\overline{L'} = 
\left\{ 0w \mid w \not\in L \right\} 
\cup 
\left\{ 1w \mid w \in L \right\}
\cup \left\{ \varepsilon \right\}.
\]

Tenemos que $\overline{L}$ puede reducirse al lenguaje $L'$ con una máquina de
Turing que toma una palabra $w$ y la desplaza a la derecha para
escribir $1w$. $L'$ no podría ser por tanto r.e., porque entonces
lo sería también $\overline{L}$ y $L$ sería recursivo.

Además, $\overline{L}$ puede reducirse al lenguaje $\overline{L'}$ con una máquina de
Turing que toma una palabra $w$ y la desplaza a la derecha para
escribir $0w$. $\overline{L'}$ no podría ser por tanto r.e., porque entonces
lo sería también $\overline{L}$ y $L$ sería recursivo.

En particular, $L'$ y $\overline{L'}$ no pueden ser recursivos al no ser
r.e.

***** TODO Ejercicio 9                                                                                  :important:
#+begin_statement
Estudiar si las clases de lenguajes recursivos y r.e. son cerradas para
las siguientes operaciones.

 1. Unión.
 2. Intersección
 3. Concatenación
 4. Clausura.
 5. Homomorfismo.
 6. Homomorfismo inverso.
#+end_statement

1. La unión de r.e. es r.e.
   La unión de recursivos es recursiva.
2. La intersección de r.e. es r.e.
   La intersección de recursivos es recursivo.

***** Ejercicio 10
Rice.

***** Ejercicio 12
#+begin_statement
Demostrar que es indecidible (no recursivo) saber si una MT
termina escribiendo un $1$ cuando comienza con una cinta completamente
en blanco.
#+end_statement

Vamos a reducir el problema $L_U$ a esta propiedad. Dado $(M,w)$,
construimos $M'$ como una máquina que empieza escribiendo la
entrada $w$ en la cinta, ejecuta $M$ sobre ella, y cada vez que
llega en $M$ a un estado de aceptación, escribe un $1$ y para.
Cada vez que llega a un estado de rechazo, escribe un $0$ y para.

Entonces, si $M'$ escribe un $1$ y para, es porque $(M,w) \in L_U$; 
si $M'$ no escribe un $1$ y para, es porque $(M,w) \notin L_U$.

***** Ejercicio 13
#+begin_statement
Determinar si los siguientes lenguajes son recursivos, r.e. o
no r.e.:

  1. Determinar si el lenguaje de una MT contiene, al menos, dos
     palabras distintas.

  2. Determinar si el lenguaje de una MT es finito o infinito.

  3. Determinar si el lenguaje de una MT es independiente del
     contexto.
#+end_statement

# Está mal la reducción y está corregida en el folio. ¡Tener cuidado
# con reducciones!

1. Es semidecidible, porque podemos probar pares
   de palabras de forma no determinista y parar cuando acepte
   ambas y sean distintas.

   Por Teorema de Rice, existe una máquina de Turing que acepta
   un lenguaje con al menos dos palabras distintas (la que acepta
   todos); y una que acepta un lenguaje sin dos palabras distintas
   (la que rechaza siempre); así que esta es una propiedad no trivial
   de los lenguajes r.e. y es indecidible.

2. Reduciremos el complemento del lenguaje universal al lenguaje
   de las MT que reconocen un lenguaje finito.

   Dado un $(M,w)$, construimos $M'$ que para cada entrada $n$
   leída como un número natural, ejecuta $n$ pasos de $M$ sobre
   $w$ y acepta si no ha parado o ha rechazado y rechaza si $M$ para.
   Si $M'$ reconoce un lenguaje finito, entonces existe algún $n_0$
   para el que rechaza, y $(M,w)$ para en $n_0$ pasos. Si $M'$
   reconoce un lenguaje no finito, entonces no puede darse el
   caso de que $M$ pare sobre entrada $w$.

   Así, el lenguaje de las MT que reconocen un lenguaje finito no
   es r.e.

   Ahora reduciremos el complemento del lenguaje universal al
   lenguaje de las MT que reconocen un lenguaje infinito.

   Dado un $(M,w)$, construimos una $M'$ que para cada entrada $n$
   la lee como un número natural y ejecuta $n$ pasos de $M$ sobre
   $w$, aceptando si ha aceptado ya. Si $M'$ reconoce un lenguaje
   infinito, es porque eventualmente $M$ para. Si $M'$ no reconoce
   un lenguaje infinito, es porque $M$ no para nunca.

   Así, el lenguaje de las MT que reconocen un lenguaje infinito
   no es r.e.

3. Reduciremos el complemento del lenguaje universal al lenguaje
   de las MT que reconocen un lenguaje independiente del contexto.
   Dado $(M,w)$ construimos $M'$ que para cada entrada $a^nb^nc^n$, 
   ejecuta $n$ pasos de $M$ sobre $w$ y acepta si no ha parado o ha
   rechazado. Rechaza si ha parado o si el input no es de la
   forma de la entrada.

   Si $M'$ reconoce un lenguaje libre de contexto, es porque
   reconoce un lenguaje finito y por tanto la máquina para en
   algún punto. Si $M'$ reconoce un lenguaje que no es libre de
   contexto, debe ser infinito, luego debe ser porque $M$ no
   para sobre $w$ o lo rechaza.

   Existe una máquina de Turing que acepta un lenguaje libre de
   contexto y otra que acepta un lenguaje no libre de contexto.
   Por ejemplo, existen máquinas de Turing que aceptan $\left\{ a^nb^nc^n \right\}$,
   que no es libre de contexto. Por Teorema de Rice, saber si
   una máquina de Turing acepta un lenguaje libre de contexto es
   indecidible. No es decidible.

***** Ejercicio 14
#+begin_statement
Sea $L$ el lenguaje formado por pares de códigos de MT más un entero
$(M_1,M_2,k)$ tales que $L(M_1) \cap L(M_2)$ contiene, al menos, $k$ palabras.
Demostrar que $L$ es r.e. pero no recursivo.
#+end_statement

Probaremos que el lenguaje es recursivamente enumerable.
Dada una entrada $(M_1,M_2,k)$, de forma no determinista probaremos
tuplas de la forma $(w_1,\dots,w_k)$; cada una de ellas pudiendo estar
codificada por un solo natural, $n = 2^{w_1}\dots p_k^{w_k}$. Aceptaremos si todas
las $(w_1,\dots,w_k)$ sean aceptadas por $M_1$ y por $M_2$. Así, el lenguaje
es recursivamente enumerable.

Para probar que no es recursivo, vamos a reducir el problema de
determinar si una máquina acepta alguna palabra (que no es recursivo)
a este problema. Lo que hacemos es tomar $M_2$ como una máquina que
simplemente acepta siempre y $k=1$. Comprobamos si $L(M_1) \cap L(M_2) = L(M_1)$
contiene alguna palabra. Por tanto, $L$ tampoco es recursivo.

****** Nota
Explícitamente, lo que queremos es una biyección computable
$\mathbb{N} \to \mathbb{N}^2$.
***** Ejercicio 20
****** Apartado b
Decidible, sólo consultando las cinco primeras letras.
Simulamos sólo los 6 primeros pasos.
***** TODO Ejercicio 21 (Interesante para practicar reducción)
**** Relación 3
***** Ejercicio 7
#+begin_statement
Construir un programa con variables que dada una cadena $u \in \left\{ 0,1 \right\}^{\ast}$
calcule la cadena $w$ formada por los símbolos que ocupan las posiciones
impares de $u$ y en el mismo orden que aparecen en $u$.
#+end_statement

#+BEGIN_SRC text
[A]   IF X ENDS 0 GOTO I₀
      IF X ENDS 1 GOTO I₁
      HALT
[I₀]  X ← X-
      Y ← 0Y
      GOTO B
[I₁]  X ← X-
      Y ← 1Y
      GOTO B
[B]   IF X ≠ ε GOTO P
      HALT
[P]   X ← X-
      GOTO A
#+END_SRC

***** Ejercicio 8
#+begin_statement
Construir un programa con variables sobre $\left\{ a,b \right\}$ que dadas dos cadenas
$u_1,u_2 \in \left\{ a,b \right\}^{\ast}$ calcule la cadena $u$ cuyo número verifica $Z(u) = Z(u_1) + Z(u_2)$
(es decir, hacer la suma de números representados por cadenas de
caracteres sobre $\left\{ a,b \right\}$).
#+end_statement

Suponemos que tenemos dos variables de entrada X1 y X2 y que la salida
se produce en la variable Y.

#+BEGIN_SRC text
$macro RESTAUNO{X}
  [B]   IF X ENDS a GOTO Aa
        IF X ENDS b GOTO Ab
        HALT
  [Aa]  X ← X-
        IF X ≠ ε GOTO Ra
        HALT
  [Ra]  Y ← bY
        GOTO B
  [Ab]  X ← X-
        Y ← aY
        GOTO C
  [C]   IF X ENDS a GOTO Da
        IF X ENDS b GOTO Db
        HALT
  [Da]  X ← X-
        Y ← aY
        GOTO C
  [Db]  X ← X-
        Y ← bY
$endmacro
$macro SUMAUNO{X}
  [B]   IF X ENDS a GOTO Aa
        IF X ENDS b GOTO Ab
        Y ← aY
        HALT
  [Aa]  X ← X-
        Y ← bY
        GOTO C
  [Ab]  X ← X-
        Y ← aY
        GOTO B
  [C]   IF X ENDS a GOTO Da
        IF X ENDS b GOTO Db
        HALT
  [Da]  X ← X-
        Y ← aY
        GOTO C
  [Db]  X ← X-
        Y ← bY
$endmacro

[A]   IF X1 ≠ ε GOTO B1
      IF X2 ≠ ε GOTO B2
      HALT
[B1]  RESTAUNO{X1}
      SUMAUNO{Y}
      GOTO A
[B2]  RESTAUNO{X2}
      SUMAUNO{Y}
      GOTO A
#+END_SRC

***** Ejercicio 9
#+begin_statement
Considerar un lenguaje Post Turing para programas con varias cintas. Hay un
número finito de cintas y en cada momento una de ellas está activa, inicialmente
la primera. Hay dos instrucciones UP y DOWN que se mueven a la cinta superior
e inferior respectivamente. Demostrar que todo cálculo realizado por un programa
Post Turing con varias cintas puede realizarse con un programa Post Turing con
una sola cinta.
#+end_statement

Supongamos un programa $P$ para $n$ cintas y un alfabeto $A$. Consideramos
el lenguaje Post Turing con alfabeto $A^n$ y construimos un programa
que será equivalente.

Empezamos terminando $P$ con la instrucción =HALT=, lo que no cambia
su significado (si un programa Post Turing lee una instrucción vacía
para de todas formas). Por otro lado, además de las etiquetas que ya
existieran, añadimos una etiqueta nueva en cada instrucción posterior
a una ocurrencia de =UP= o =DOWN=; esto, de nuevo, no altera el
comportamiento del programa.

Ahora concatenamos $n$ veces el mismo programa $P$ usando un subíndice
$i = 1,\dots,n$ para identificar cada una de las $n$ instancias de
cada etiqueta. Cada =UP= en la instancia $i$ del programa se
sustituirá por un =GOTO= a la etiqueta después del =UP= correspondiente
en la instancia $i+1$ del programa. Cada =DOWN= en la instancia $i$
del programa se sustituirá por un =GOTO= a la etiqueta después del =DOWN=
correspondiente en la instancia $i-1$ del programa. Podemos convenir
que si se ejecuta =DOWN= en la cinta inferior o =UP= en la cinta superior,
simplemente se salta a la siguiente instrucción. De esta forma,
la instancia del programa en la que estamos en cada momento marcará
la cinta en la que estamos trabajando.

Las instrucciones =PRINT a= en la instancia $i$ serán sustituidas por la
siguiente macro, que lo que hace es considerar todas las letras posibles
de $A^n$ y cambiar el elemento en el índice $i$ en ellas por una =a=.

#+BEGIN_SRC text
                 IF (....,x,...) GOTO L(....,x,...)
                 IF (....,x,...) GOTO L(....,x,...)
                 ...
                 IF (....,y,...) GOTO L(....,y,...)
                 IF (....,y,...) GOTO L(....,y,...)
                 ...
[L(....,x,...)]  PRINT (....,a,...)
[L(....,x,...)]  PRINT (....,a,...)
...              ...
[L(....,y,...)]  PRINT (....,a,...)
[L(....,y,...)]  PRINT (....,a,...)
...              ...
#+END_SRC

Las instrucciones =IF a GOTO A= en la instancia $i$ serán sustituidas por
la siguiente macro, donde diferenciamos en el caso de que la tupla tenga en
el índice $i$ una =a=. Llamamos =A(i)= a la etiqueta =A= en la instancia $i$.

#+BEGIN_SRC text
# Para cada tupla que contenga una a en la posición i
      IF (....,a,...) GOTO A(i)
      IF (....,a,...) GOTO A(i)
      ...
#+END_SRC

De esta forma, estamos siempre leyendo y escribiendo sobre una de las
componentes de las tuplas que forman el alfabeto. Sólo las instrucciones
=UP= y =DOWN= cambian la instancia del programa en la que estamos trabajando
y, con ella, la componente del $A^n$ en la que estamos trabajando. El programa
es por tanto equivalente al programa con cinta múltiple.

**** Relación 5
***** Ejercicio 1
#+begin_statement
a) Un grafo dirigido se dice que es acíclico si no tiene ciclos.
   Demostrar que todo grafo dirigido acíclico tiene una fuente
   (un nodo al que no llegan arcos).

b) Demostrar que un grafo dirigido con n nodos es acíclico si
   y sólo si se pueden numerar los nodos del 1 al n de manera 
   que siempre los arcos van desde números más pequeños a
   números más grandes.

c) Describir un algoritmo polinómico para determinar cuándo
   un grafo es acíclico.
#+end_statement

Asumimendo un grafo finito no vacío.

a) Tomamos un vértice del grafo $v_0 \in G$; si no fuera una fuente,
   existiría otro $v_1$ con un arco hacia él $v_1 \to v_0$. Iterando este
   proceso llegamos bien a una fuente o a una cadena infinita
   \[
   \dots \to v_n \to v_{n-1} \to \dots \to v_1 \to v_0;
   \]
   donde si tuviéramos dos vértices iguales $v_i = v_j$ para $i \neq j$,
   tendríamos un ciclo, por lo que deberían ser todos distintos,
   contradiciendo la finitud del grafo. Debe ser por tanto una
   cadena finita con una fuente al principio.

b) Usaremos inducción. Sabemos que se puede hacer para un grafo de
   un solo elemento, asignándole un $0$. Dado un grafo de $n$ elementos
   acíclico, sabemos que tiene una fuente, a la que podemos asignar
   un $0$, numerar el resto del grafo usando la hipótesis de inducción
   y añadiendo uno a cada uno de los números obtenidos. Sabemos que
   la numeración así conseguida hace que todos los arcos entre nodos
   en el resto del grafo vayan de un número más pequeño a uno más
   grande por hipótesis de inducción y porque el añadir uno es una
   función monótona creciente. Sabemos que todos los arcos entre
   la fuente y un nodo del resto del grafo, que deben empezar en la
   fuente por definición, van de un nodo numerado con el $0$ a un nodo
   numerado como el sucesor de un natural, que forzosamente debe ser
   mayor que $0$.

c) Asumimos que el grafo está representado por una matriz de adyacencia,
   nótese que podría transformarse desde otras representaciones usuales
   por un algoritmo polinómico, por lo que no afectará a la demostración.
   Demostraremos que es polinómico en el número de vértices, nótese que
   el tamaño de la entrada está acotado polinómicamente por el número de
   vértices, por lo que no afectará a la demostración.

   Para cada vértice recorremos la columna de aristas que llegan hacia
   él para consultar si llega alguna arista a él. Si es una fuente, no
   puede pertenecer a ningún ciclo; y así, al retirarla del grafo, no
   estaríamos perdiendo ningún ciclo. Podemos mantener una lista de
   vértices retirados y marcar sus entradas en la matriz a cero.

   Si el grafo no tiene fuentes, tendrá por tanto un ciclo. Si por el
   contrario acabamos retirando todos los vértices del grafo, llegaremos
   a un grafo vacío, que trivialmente no tiene ciclos.

   Acceder a una posición aleatoria de la matriz representada en la
   cinta se podría hacer en ${\cal O}(v^4)$, calculando a qué posición queremos
   acceder dada fila y columna $(f,c)$ como $fv + c$ en ${\cal O}(v^2)$ supuesta la
   multiplicación en ese tiempo y acceder a ella en ${\cal O}(v^2)$ para recorrer
   todas las casillas; leer la fila y columna
   asociada a un vértice se podría hacer
   entonces en ${\cal O}(v^5)$. Hacer esto para todos los vértices se haría en
   ${\cal O}(v^6)$ y como lo haremos a lo sumo $v$ veces (retirando un vértice cada
   vez), tenemos una cota en tiempo polinómica ${\cal O}(v^7)$.

***** Ejercicio 2
#+begin_statement
a) Demostrar que un grafo es /bipartito/ (se puede dividir
   en dos partes, que no son necesariamente iguales, de manera
   que todas las aristas van de una parte a otra) si y sólo si
   todos sus ciclos son de longitud par.

b) Describir un algoritmo polinómico para comprobar si un 
   grafo es bipartito.
#+end_statement

Asumimos un grafo no dirigido.

a) Si tiene un ciclo de longitud impar, sería imposible
   dividir los vértices del ciclo en dos partes de forma
   que ninguno estuviera conectado con vértices de la otra
   porque si fijamos la parte en la que está un vértice,
   el resto de partes quedarían determinadas por la paridad
   de pasos desde ese vértice y en particular, el último
   vértice empezando desde él, estaría a un número par de
   pasos en el ciclo pero conectado al inicial.

   Si no es bipartito, alguna de sus componentes conexas
   debe no ser bipartita (si todas lo fueran, podríamos
   partir cada una en dos partes y por conexión sabríamos que
   no hay aristas de una parte a otra). Tomamos una
   componente conexa no bipartita y fijamos un vértice $v$. Para
   cualquier otro vértice, existirá por conexión un camino de
   aristas (en cualquier dirección) entre ellos, y la paridad
   de este camino determinará su parte. Como el grafo no es
   bipartito, deben existir $w_1,w_2$ conectados a los que hemos
   asignado la misma paridad, luego el ciclo
   \[
   v \dots w_1w_2 \dots v
   \]
   es de longitud impar.

b) Asumimos de nuevo representación por matriz de adyacencia y
   demostraremos que es polinómico en $v$. Para ello, mantendremos una
   lista con el "color" que hemos asignado a cada vértice y también
   una lista que indica uno de los siguientes tres estados para cada
   vértice

    * /no estudiado/, si todavía no hemos estudiado sus vecinos,
    * /a estudiar/, si hemos estudiado ya uno de sus vecinos, le
      hemos asignado un color y deberíamos seguir estudiando sus
      vecinos, o
    * /estudiado/, si ya lo hemos estudiado.

   A cada iteración, podemos tener vértices /a estudiar/ con un
   color ya asignado, en cuyo caso deberíamos empezar por ellos,
   asignando colores a sus vecinos y añadiéndolos a la lista de
   vértices a estudiar;
   o no tener vértices /a estudiar/, en cuyo caso ningún vértice
   está determinando el color de ningún vértice nuevo y podemos
   tomar cualquiera para continuar.

   Si existe una bicoloración, este algoritmo debe encontrarla porque
   siempre que asume un color nuevo lo hace en un vértice que no
   estaba conectado con ninguno anterior y por tanto está en una
   componente conexa nueva, donde, si existe una bicoloración,
   existirán dos que quedan fijadas al fijar el color de cualquier
   vértice. Si no existe, se llegará en algún momento a encontrar
   dos vértices vecinos con el mismo color; ya que si no fuera así,
   acabaríamos habiendo asignado un vértice a cada color y habiendo
   estudiado que todos sus vecinos tienen un color distinto.

   Acceder a la matriz se hace en tiempo polinómico ${\cal O}(v^4)$, como hemos visto
   en el ejercicio anterior. Buscar el próximo vértice a estudiar o
   comprobar que no hay ninguno para estudiar se puede hacer en tiempo
   lineal. Recolectar todos los vecinos del vértice en la matriz (que
   será simétrica) y marcarlos, se puede hacer en tiempo ${\cal O}(v^2v^{4})$.
   Este proceso tendremos que repetirlo en el peor de los casos para
   cada vértice, teniendo una cota ${\cal O}(v^7)$.

***** Ejercicio 3
#+begin_statement
Demostrar que P es cerrada para la unión y la intersección.
#+end_statement

Si tenemos dos algoritmos que reconocen una palabra del lenguaje en
tiempo polinómico, el tiempo de ejecución de ambos secuencialmente
está acotado también por una suma de polinomios, que vuelve a ser
un polinomio. Ejecutando ambos secuencialmente y aceptando si ambos
aceptan (para la intersección) o si al menos uno de ellos acepta
(para la unión), tenemos lo pedido.
***** TODO Ejercicio 4
#+begin_statement
Demostrar que $NP \neq ESPACIO(n)$.
#+end_statement

Hay una reducción polinómica $\pi_1 \propto \pi_2$ teniendo
que $\pi_1 \notin ESPACIO(n)$ y $\pi_2 \in ESPACIO(n)$.

***** Ejercicio 5
#+begin_statement
Determinar cuáles de las siguientes clases de funciones son cerradas
para la composición polinómica por la derecha y cuáles lo son por la
izquierda.

  1. $\left\{ n^k \mid k > 0 \right\}$
  2. $\left\{ nk \mid k > 0 \right\}$
  3. $\left\{ k^n \mid k > 0 \right\}$
  4. $\left\{ 2^{n^{k}} \mid k > 0 \right\}$
  5. $\left\{ \log^k(n) \mid k > 0 \right\}$
#+end_statement

1. Lo es por la izquierda porque $p(n^k)$ con $p$ de grado $q$ vuelve a ser
   un polinomio de grado $kq$. Lo es por la derecha porque $p(n)^k$ también
   es un polinomio de grado $kq$.

2. Con $p(x) = x^2$ se tiene $p(nk) = n^2k^2$, que no está en la clase. De
   la misma forma se tiene $p(n)k= n^2k^2$, que tampoco lo está. No es
   cerrada ni a izquierda ni a derecha.

3. Usando que $(k^n)^{q} = (k^q)^n$, podemos escribir la composición con cualquier
   polinomio por la derecha como suma de funciones de la clase. Es cerrada
   a derecha.

   Sabemos sin embargo que $k^{n^2}$ no está en la misma clase de complejidad que
   ningún $l^n$ porque $\lim_{n \to \infty} log(k^{n^2}/l^n) = \infty$. No es cerrada a izquierda.

4. Para $p$ polinomio de grado $q$ tenemos que $2^{p(n)^k} = {\cal O}(2^{n^{qk}})$, luego la clase
   es cerrada a derecha. Además $p(2^{n^k}) = {\cal O}(2^q2^{n^k}) = {\cal O}(2^{n^{k}})$, luego es cerrada
   a izquierda.

5. Tenemos $(\log(n^q))^k = q^k\log(n)^k$, luego es cerrada a derecha. Además,
   $((\log(n))^{k})^{q} = (\log(n))^{kq}$, luego es cerrada a izqueirda.

6. Para $q > 1$ tenemos $\lim_{n \to \infty} \log(n)^q / \log(n) = \infty$, luego no es cerrada
   a izquierda. Por otro lado, $\log(n^q) = q\log(n)$, luego es cerrada a
   derecha.
**** Práctica 4
***** Ejercicio 1.g
#+begin_statement
Demostrar que el siguiente problema es NP-completo.

*Cubrimiento exacto por conjuntos de 4 elementos*. Dado un conjunto finito $X$
con $|X| = 4q$, siendo $q$ entero y una familia $C$ de subconjuntos de 4 elementos
de $X$, ¿existe una subfamilia $C' \subseteq C$ tal que todo elemento de $X$ pertenece a
uno y sólo uno de los subconjuntos de $C$?
#+end_statement

Podemos resolverlo de forma no determinista eligiendo una subfamilia
$C'$ de forma no determinista y comprobando si es partición, si cumple
las propiedades del enunciado. Esto puede hacerse en tiempo polinómico
sobre el tamaño de la entrada porque elegir la subfamilia es
polinómico, comprobar si un elemento pertenece a un subconjunto es
polinómico, y tendremos que comprobar para cada elemento si pertenece
a sólo un conjunto; que se hace en tiempo polinómico sobre el máximo
entre el número de conjuntos y elementos. Es por tanto NP.

Reduciremos ACTRI a este problema. Dados $W,X,Y$ de tamaño $q$ y un
subconjunto $M$ de compatibilidades, creamos $U = W_1 \cup W_2 \cup X \cup Y$,
una unión disjunta de conjuntos donde $W_1$, $W_{2}$ son copias de $W$, y
tomamos $C$ como $\left\{(w,w,x,y) \mid (w,x,y) \in M \right\}$, es decir,
extendemos cada tupla del conjunto de compatibilidades copiando
su primera componente. Este es un proceso que puede hacerse en
espacio logarítmico simplemente duplicando en la salida parte
de la entrada.

Ahora, $|U| = 4q$ y $C$ es una familia de subconjuntos de 4 elementos de $X$.
Vemos que si existe una subfamilia que es partición, entonces, esa misma
subfamilia sin considerar el elemento repetido (nótese que por construcción
todos los elementos de $C$ tienen un elemento repetido) es una partición
solución de ACTRI. Si tuviéramos solución al ACTRI inicial, nótese que la
misma partición, duplicando el último elemento de cada compatibilidad
vuelve a ser solución de este problema, donde el ser disjuntos se mantiene
por ser disjuntos los iniciales (no pueden coincidir en la componente duplicada
porque no coinciden en la componente $W$; y cubren todos los elementos porque
la solución original cubría todos los de $W$). Así, hay solución a este problema
si y sólo si la hay al ACTRI inicial.

***** Ejercicio 1.h
#+begin_statement
Demostrar que el siguiente problema es NP-completo.

*Conjunto dominante*. Dado un grafo $G=(V,E)$ y un entero positivo $K \leq |V|$,
¿existe un subconjunto $V' \subseteq V$ tal que $|V'| \leq K$ y tal que todo vértice
$v \in V\setminus V'$ está conectado con al menos un vértice de $V$?
#+end_statement

Será NP porque podemos elegir de forma no determinista un subconjunto
de vértices y para cada vértice, comprobar en tiempo polinómico si
está unido a alguno de los vértices del subconjunto.

Para compbrobar que es NP-completo vamos a reducir ACTRI a él. Dado un
conjunto de compatibilidades $M$ y un $q$, lo que hacemos es tomar un
grafo que contenga un vértice por cada uno de los elementos de $M$
(vértices *de compatibilidad*), y por cada uno de los elementos de
$W,X,Y$ (vértices *de elemento*). Cada vértice de compatibilidad
estará unido a todos los demás y además a los tres vértices de
elemento que representen a los elementos que cubra. Este proceso
puede hacerse en espacio logarítmico porque puede irse escribiendo
el grafo conforme leemos las compatibilidades.

Si hubiera una solución a ACTRI, el tomar los $q$ vértices
representando las compatibilidades elegidas es claramente una solución
al problema porque cubrirían todos los vértices de elemento por
definición y además cubrirían todos los vértices de compatibilidad
porque los hemos unido entre sí.

Si hubiera una solución del conjunto dominante de tamaño $q$,
entonces, como cada vértice de compatibilidad cubre como máximo a tres
vértices de elemento y un vértice de elemento solo cubre a uno, todos
los vértices del conjunto dominante deberían ser de compatibilidad
(para poder cubrir los $3q$ vértices de elemento).  Además, los
vértices de compatibilidad deberían cubrir a elementos distintos
porque si repitieran, cubrirían menos de $3q$ vértices en total.
Así, el conjunto dominante debe estar dándonos una elección de
compatibilidades disjuntas que resuelve el problema del ACTRI.

***** Ejercicio 1.k
#+begin_statement
Demostrar que el siguiente problema es NP-completo.

*Partición de conjuntos*. Dada una familia $C$ de subconjuntos de un conjunto
finito $S$ ¿existe una partición de $S$ en dos partes $S_1$ y $S_2$ tales que no hay un
elemento $A \in C$ que esté contenido en $S_1$ o esté contenido en $S_2$ (o equivalentemente
todo $A \in C$ debe de tener intersección no vacía con $S_1$ y con $S_2$?
#+end_statement

Será un problema NP porque podemos elegir la partición en dos subconjuntos
de forma no determinista (marcando cada elemento de $S$ con un bit, por ejemplo),
y luego comprobar en tiempo polinómico que cada elemento $A \in C$ tiene intersección
no vacía con $S_1$ y con $S_2$ (tiene un elemento marcado $0$ y otro marcado $1$).

Para demostrar que es NP-completo, reduciremos NAESAT a este problema. Dado
un conjunto de cláusulas de longitud $3$ sobre un alfabeto, tomamos $S$ como
el conjunto de todos los literales del alfabeto y sus negaciones,
\[
S = \left\{ a,b,c,\dots,\neg a,\neg b,\neg c, \dots \right\},
\]
y tomamos la familia $C$ dada por las parejas de cada literal con su negación,
$\left\{ a,\neg a \right\}$, y por los tres literales que forman cada cláusula: por ejemplo,
$a \vee b \vee \neg c$ nos daría el conjunto $\left\{ a,b,\neg c \right\}$. Una solución a este problema
nos daría dos conjuntos $S_1$ y $S_2$ representando los dos valores de verdad,
y asegurándonos que cada elemento tiene un valor distinto del de su negación,
y que cada cláusula tiene algún literal cierto y otro falso. De nuevo, la
reescritura de la entrada puede hacerse en espacio logarítmico, ya que sólo
tendrá que determinar el conjunto y reescribir el formato de las cláusulas.

***** Ejercicio 2
#+begin_statement
Una Máquina de Turing no-determinística fuerte es una máquina que tiene tres
posibles respuestas 'Sí', 'No' y 'Duda'. Una de estas máquinas decide $L$ si y
solo si, para todo $x \in L$, todos los cálculos posibles terminan en 'Sí' o 'Duda'
y al menos uno en 'Sí' y para todo $x \not\in L$, todos los cálculos posibles terminan en 
'No' o 'Duda' y al menos uno en 'No'. Demostrar que $L$ es decidido por una Máquina
de Turing no-determinística fuerte polinómica si y solo si $L$ está en $\mathrm{NP}\cap \mathrm{coNP}$.
#+end_statement

Supongamos $L$ aceptado por una máquina de Turing no-determinística
fuerte.  El lenguaje estaría en $\mathrm{NP}$, porque podríamos construir una máquina
no-determinística que funcionara igual que la no-determinística fuerte, pero
devolviendo 'No' en los casos de 'Duda'; esta máquina aceptaría $L$, ya que
para todo $x \in L$ existe algún cálculo devolviendo 'Sí' y para todo $x \notin L$
no existe ninguno.  El lenguaje estaría en $\mathrm{coNP}$, porque podríamos construir
una máquna no-determinística que funcionara igual que la no-determinística
fuerte, pero devolviendo 'Sí' en los casos de 'No' y 'No' en el resto de
casos; esta máquina aceptaría el complemento de $L$, ya que para todo
$x \notin L$ existe algún cálculo devolviendo 'Sí' y para todo $x \in L$ no
existiría ninguno.

Supongamos ahora $L$ en $\mathrm{NP} \cap \mathrm{coNP}$, existirían máquinas no-determinísticas
aceptando $L$ y aceptando su complemento. Construimos una máquina no-determinística
fuerte que usaría ambas secuencialmente sobre la entrada tomando elecciones de
forma no-determinista en ambas. Si la primera aceptara, devolveríamos 'Sí';
si la segunda aceptara, devolveríamos 'No'; y si ninguna lo hiciera, devolveríamos
'Duda'. Nótese que si $x \in L$, habrá algún caso en el que la primera aceptará, y
la segunda no lo hará nunca; por el contrario, si $x \notin L$, habrá algún caso en el que
la segunda aceptará, y la primera no lo hará nunca.

**** Relación 6
***** Ejercicio 1

 b. Reducir 3-SET a este problema.
 c. Detectar hamiltonianos se reduce directamente.
 d. Detectar hamiltonianos se reduce poniendo un ciclo en el primer argumento.
 e. Reducimos el problema de la partición a él.
**** Práctica 5
***** Ejercicio 2
#+begin_statement
Demostrar que el umbral de aproximación del problema del mínimo de
colores es mayor o igual que 4/3 (recordar que saber si un grafo se
puede colorear con 3 o 4 colores es NP-completo).
#+end_statement

Suponiendo que $P \neq NP$, veremos que si existiera un algoritmo
polinómico con una razón de eficacia $\delta < 4/3$, entonces
podríamos resolver el problema de determinar si un grafo se puede
colorear con 3 colores en tiempo polinómico y habremos llegado a
contradicción.

En efecto, si tenemos un algoritmo polinómico para el problema del
mínimo de colores con $\delta < 4/3$, dado un grafo, podremos
aplicarlo sobre él; si obtenemos un resultado menor que $4$, eso
querría decir que debe poder colorearse con $3$ colores, y si
obtenemos un resultado igual o mayor que $4$, eso querría decir que

\[
\mathrm{opt}(x) \geq \frac{C(m(x))}{\delta} > 3\frac{C(m(x))}{4} \geq 3,
\]

luego el óptimo debería ser mayor estricto que $3$ y no podría
colorearse con $3$ colores.  Tendríamos así un algoritmo polinómico
capaz de resolver un problema NP-completo.

***** Ejercicio 3
#+begin_statement
Un problema de la clase NPO es simple si para cada entero positivo $k$
fijo, el problema de decidir si para un ejemplo $x$ el óptimo es menor
o igual que $k$ está en P. Demostrar que el problema del clique máximo es
simple, pero no el del número mínimo de colores (excepto $\mathrm{NP}= \mathrm{P}$).
#+end_statement

Fijado $k$, podemos crear un algoritmo polinómico que toma todas las
posibles elecciones de $k+1$ vértices del grafo y comprueba si forman
un clique. Hay ${v \choose k+1} = {\cal O}(v^{k+1})$ posibles elecciones y hay que comprobar
en cada una de ellas ${k+1 \choose 2}$ aristas, dándonos un algoritmo polinómico.
Ahora, si este algoritmo encuentra un clique, sabemos que el óptimo no
es menor o igual que $k$, ya que en particular tenemos un ejemplo con $k+1$.
Si este algoritmo no encuentra un clique, no puede existir ningún clique
de tamaño $k+1$ o mayor, porque esto implicaría la existencia de un
clique de tamaño $k+1$; así, el óptimo debe ser menor o igual que $k$.

En problema del número mínimo de colores no puede ser simple porque ya
sabemos que saber si un grafo se puede colorear con 3 colores (o
menos, que implicaría que se puede con 3) es un problema NP-completo.

***** Ejercicio 4
#+begin_statement
Demostrar que si un problema tiene un esquema de aproximación polinómico,
entonces es simple.
#+end_statement

Supongamos que es un problema de minimización. Fijado un $k$, tomamos
$1 < \delta < (k+1)/k$ y usamos el esquema de aproximación polinómico
para obtener un algoritmo $m$ que nos da una aproximación de grado $\delta$
del óptimo de cada ejemplo. Ahora, como

\[
\mathrm{opt}(x) \geq \frac{C(m(x))}{\delta} > \frac{k}{k+1}C(m(x)),
\]

sabemos que si $C(m(x)) \geq k+1$, entonces $\mathrm{opt}(x) > k$; y que si
$C(m(x)) < k+1$, entonces $C(m(x)) \leq k$ y en particular $\mathrm{opt}(x) \leq k$.
Hemos conseguido un algoritmo que determina si el óptimo es menor o
igual que $k$ en tiempo polinómico.

 \\

Supongamos ahora que fuera un problema de maximización. Fijado un $k$,
tomamos $1 < \delta < (k+1)/k$ y usamos el esquema de aproximación polinómico
para obtener un algoritmo $m$ que nos da una aproximación de grado
$\delta$ del óptimo de cada ejemplo. Ahora, como

\[
\mathrm{opt}(x) \leq \delta C(m(x)) < \frac{k+1}{k}C(m(x)),
\]

sabemos que si $C(m(x)) > k$, entonces, en particular,
$\mathrm{opt}(x) > k$; y que si $C(m(x)) \leq k$, entonces $\mathrm{opt}(x) < k+1$ y por
tanto $\mathrm{opt}(x) \leq k$. Hemos conseguido un algoritmo que determina si el
óptimo es menor o igual que $k$ en tiempo polinómico.

**** Práctica 5 (pistas)
***** Ejercicio 2
Si existiera la aproximación, se resuelve un NP en tiempo polinómico.

Asumimos P ≠ NP.

***** Ejercicio 3
El clique es simple porque saber si existe un clique de tamaño 3 es
polinómico.

Para cada k fijo, encontrar un clique de tamaño k es polinómico.

***** Ejercicio 4
Podemos usar el esquema de aproximación calculando el problema

** Metaheurísticas
*** Detalles de la asignatura y examen
Transparencias en la página de la asignatura
http://sci2s.ugr.es/graduateCourses/Metaheuristicas

 * Práctica 1: búsqueda local (2 pts).
 * Práctica 2: búsqueda en poblaciones (2.5 pts).
 * Práctica 3: búsqueda basada en trayectorias (3.5 pts).
 * Práctica opcional: sustituye examen de teoría.
   * Estudiar metaheurísticas de reciente creación.
   * Seleccionar un problema a resolver y analizarlo con metaheurísticas.
   * Documento explicando la técnica.
   * Exposición en clase.

Mínima puntuación de 1 en ambas partes (teoría y prácticas) de la
asignatura.

**** Examen

 - Problema (2pt)
 - Cuestiones (3pt)
   - Dar una esquema de una parte del curso. (1pt)

*** Tema 1. Introducción a las metaheurísticas
Conjunto de técnicas para resolver problemas de optimización.  Una
*heurística* es un algoritmo aproximado que depende del problema
concreto; una *metaheurística* es un algoritmo aproximado general.

**** 1.1. Resolución aproximada, esquemas de representación
Un problema se debe resolver con metaheurísticas cuando:

 * Tiene gran complejidad computacional.
 * No se requiere solución exacta.
 * No hay algoritmos eficientes exactos o aproximados específicos.

/Ejemplo: viajante de comercio./

Para diseñar una metaheurística se necesita:

 * Una *función objetivo* a minimizar.
 * Un *esquema de representación* de soluciones. Debe facilitar el uso
   de operadores.
 * Un *conjunto de restricciones* sobre el espacio de búsqueda.

Podemos elegir entre varios esquemas de representación.

 - *Codificación binaria*: Representa pertenencia a un conjunto de una
   lista de elementos o satisfacibilidades booleanas.

 - *Representación de orden*: Representa la solución como una
   permutación del conjunto $\left\{ 1,\dots,n \right\}$.

 - *Vector de valores discretos*: Representa una asignación como
   un vector de valores discretos.
 - *Vector de valores reales*: Representa una solución en optimización
   continua global.

**** 1.2. Algoritmos aproximados, elementos de búsqueda
Los *algoritmos aproximados* dan soluciones cercanas a la óptima
cuando esta no se necesita o sería ineficiente.  Elementos de un
algoritmo de búsqueda son:

 * *Solución*, representación de valor de salida posible.

 * *Entorno*, soluciones cercanas una vez fijada una estructura
   de espacio métrico en el espacio de soluciones.

 * *Movimiento*, transformación de solución a una solución en
   algún entorno cercano.

 * *Evaluación*, factibilidad de la solución, dada por la función
   objetivo.

**** 1.3. Metaheurísticas, clasificación
Las *metaheurísticas* son una familia de algoritmos aproximados de
propósito general.

 * Son de propósito general.
 * Fácilmente implementables.
 * Fácilmente paralelizables.

 * No son exactos, son aproximados.
 * No son deterministas.
 * No siempre tienen base teórica.

Se clasifican en tres grandes grupos.

 1. *Métodos constructivos*. Como GRASP o colonias de hormigas.

 2. *Basadas en trayectorias*. Búsqueda local, Enfriamiento simulado,
    Búsqueda tabú, Búsqueda local iterativa.

 3. *Basadas en poblaciones*. Genéticos, Meméticos, Evolución diferencial.

**** 1.4. Paralelización
Tiene tres objetivos

 1. Preservar la calidad y reducir el tiempo de ejecución.
 2. Incrementar la calidad sin aumentar el tiempo de cálculo.
 3. Mejorar calidad por el efecto sinérgico de espaciar la búsqueda.
 
**** 1.5. Aplicaciones
Optimización, diseño de circuitos, planificación, trayectorias, control
de procesos químicos, flotas logísticas.

*** Tema 2. Modelos de búsqueda. Entornos, trayectorias y poblaciones
**** 2.1. Búsqueda local
Decimos que una búsqueda es *local* cuando usamos estructuras de 
entorno derivadas de un espacio métrico. Una *búsqueda local* es
aquella que dada una solución actual, selecciona iterativamente
una de su entorno para seguir la búsqueda.  Tiene elementos:

 * Elección de solución inicial.
 * Operador de vecino, determina estructura de entornos.
 * Proceso de aceptación de soluciones.

La búsqueda basada en poblaciones regenera la solución a cada
paso.

**** 2.2. Búsqueda aleatoria
La *búsqueda aleatoria pura* es muy ineficiente.  Puede considerarse
una búsqueda aleatoria por recorrido al azar, escogiendo el primer
vecino que se encuentre.

**** 2.3. Métodos de búsqueda local básicos

 * *Ascent Hill Climbing*, búsqueda local del mejor; genera todos los
   vecinos y escoge el mejor. Si no hay mejor que lo actual, termina.

 * *Simple Hill Climbing*, búsqueda local del primer mejor; va
   generando vecinos hasta que encuentra alguno mejor que el actual,
   cambia en ese punto.

Es iteresante evitar óptimos locales, una idea puede ser permitir
empeoramientos, modificar la estructura de entornos o usar búsquedas
multiarranque.

*** Tema 3. Metaheurísticas basadas en poblaciones I
**** 3.1. Computación evolutiva
Nos basamos en poblaciones que se reproducen, se seleccionan y mutan.
Una *población* selecciona unos *padres*, que se combinan y mutan para
generar *descendientes* que reemplazan a otros en la población.

Los paradigmas básicos son:

 1. Algoritmos genéticos, a nivel de cromosomas.
 2. Estrategias de evolución, a nivel de individuos.
 3. Programación evolutiva, a nivel de especies.
 4. Programación genética, evolución de expresiones sintáticas.

Las ventajas son:

 1. Funcionan aceptablemente en amplia variedad de problemas.
 2. Paralelismo intrínseco.
 3. Superioridad en problemas muy complejos.
 4. Fáciles de desarrollar e hibridar.

**** 3.2. Algoritmos genéticos
Los *algoritmos genéticos* se inspiran en la evolución natural y la
evolución genética. Requieren de reproducción, selección, cruce y
mutación.
 
***** Diseño del genético
Se construyen:

 1. Decidiendo representación, población inicial, cómo se expresa el
    genotipo en un fenotipo.
 2. Decidiendo operadores mutación, cruce, selección y reemplazamiento.
    La representación debe ser buena para los operadores.
 3. Decidiendo condición de parada.

***** Modelos de evolución
Hay dos *modelos de evolución*.

 * *Modelo generacional*, donde la nueva población reemplaza a la
   anterior completamente.

 * *Modelo estacionario*, donde en cada iteración se toman dos padres
   y se aplican operadores genéticos para reemplazar a algún elemento
   de la población anterior.  Es un modelo elitista con una
   convergencia rápida.

***** Estrategia de selección
La *estrategia de selección* puede ser.

 * *Torneo*, el mejor entre varios aleatorios.
 * *Orden lineal*, probabilidad ordenada según fitness.
 * *Selección aleatoria*.
 * *Emparejamiento variado inverso*. Busca un padre lejano al otro,
   introduce diversidad.
 * *Ruleta*. Proporcional al fitness.

***** Operador de cruce
Pueden ser varios, debe tomar características de cada padre (si no, es
mutación); debe producir cromosomas válidos (!) en la representación.

 - Cruce binario.
 - Cruce aritmético.
 - Cruce BLX.
 - Cruce de orden OX.
 
***** Operador de mutación
Debe producir soluciones válidas, intentar alcanzar todo el espacio de
búsqueda y producir un cambio controlado no demasiado grande.

 - Mutación binaria.
 - Mutación real.
 - Mutación de orden (intercambio).

***** Estrategia de reemplazamiento
Para modelos estacionarios.

 - Reemplazar al peor, genera mucha presión.
 - Torneo restringido, reemplazando al más parecido.
 - Peor entre semejantes, reemplaza al peor entre los parecidos.
 - Crowding determinístico, reemplaza al padre más parecido.

*Elitismo* es no reemplazar al mejor de la población. 

**** 3.3. Exploración y explotación
**** 3.4. Conclusiones
*** Tema 3. Metaheurísticas basadas en poblaciones II
**** 3.1. Optimización continua
Nos centramos en optimizar una función de variables reales.  Los algoritmos
más populares son Evolución diferencial, PSO y Meméticos.

 - Los genéticos toman ideas de la estructura de espacio vectorial de
   las soluciones (Cruce lineal). Hay operadores de cruce

   - discretos,
   - basados en agregación,
   - basados en vecindario.

   Los primeros usaban operadores componente a componente que no
   capturan interacciones no lineales.

 - CMA-ES. Soluciona un problema de autovalores.

**** 3.2. Evolución diferencial
La *Evolución diferencial* usa un operador de cruce a posteriori de la
mutación y enfatiza ésta.  A partir de cada vector se genera un vector
mutado con un vector diferencia aleatorio escalado.

 - Recombinación discreta.  Cruza el objetivo respecto al mutado con
   ratio predefinido de cruce. Hay otras variantes de recombinación,
   aritméticas, exponenciales y binomiales.

**** 3.3. Estrategias de evolución
**** 3.4. PSO (Particle Swarm Optimization)
De las parvadas. Sistema multiagente de soluciones comunicándose
fitness, posición, mejor solución hasta el momento y velocidad; siguen
a la mejor partícula. Hay dos componentes para ajustar velocidad.

 - *Cognitivo*, peso de la mejor encontrada por la partícula.
 - *Social*, peso del mejor individuo en la población. Puede ser
   *local*, si es el mejor del entorno, o *global* en otro caso.

Modelos.

 - Completo, si sigue ambos.
 - Sólo cognitivo.
 - Sólo social. 
 - Social exclusivo. La partícula no se sigue a sí misma aunque sea la
   mejor.

Parámetros a ajustar.

 - Tamaño de la nube.
 - Velocidad máxima.
 - Ratio de aprendizaje.
 - PSO Global o Local: sigue al mejor local o al mejor global.
 - Topología de la nube: entornos geográficos (cercanas en el espacio)
   o entornos sociales (fijadas de antemano). La topología social de
   anillo es común.
 - Introducir inercia.

**** 3.5. Optimización continua II
La evolución diferencial da buenos resultados en CEC.

***** SHADE
*JADE* es evolución diferencial que tiene parámetros CR y F
específicos para cada individuo, elegidos según distribución normal y
Cauchy. Se van actualizando en una memoria histórica. Se usa una media
ponderada para actualizarla. Se necesita un parámetro para fijar la
greediness de current-to-best.

En *SHADE* el parámetro $p$ está asociado en cada individuo. *L-SHADE*
utiliza reducción lineal de la población. Muy robustos.

**** 3.6. Modelos bioinspirados
Numerosas propuestas bioinspiradas de optimización real. Es necesario
un análisis crítico.

*** Tema 4. Algoritmos meméticos
**** 4.1. Hibridar, límites de los genéticos
Los evolutivos son buenos exploradores pero malos explotadores, las
búsquedas locales al revés.  El comportamiento de cualquiera está
limitado por el NoFreeLunch Theorem.  Necesitamos usar conocimiento
específico del problema para mejorar. Los meméticos balancean
evolutivos y búsquedas para ser más robustos.

**** 4.2. Diseño de meméticos
Evolución de poblaciones, usa conocimiento en términos de búsquedas
locales. Un *algoritmo memético* está dado por una población de agentes
alternando periodos de /mejora/ (búsqueda local), /cooperación/ (recombinación)
y /competición/ (selección).

 - ¿Cuándo aplicar búsqueda?

   - En inicialización.
   - Cada cierto número de generaciones.
   - Al final del ciclo reproductivo.

 - ¿Sobre qué individuos aplicar búsqueda?

   - A toda la población.
   - A los mejores.
   - Representantes tras una agrupación.
   - Probabilísticamente

 - ¿Cómo se usa el optimizado?

   - Lamarkiano. Reemplaza a su versión no optimizada.
   - Baldwiniano. Se toma el fitness del optimizado pero genotipo no
     optimizado.

 - ¿Cómo se regula?

   - Anchura. Frecuencia de aplicación de la búsqueda.
   - Profundidad. Intensidad de la búsqueda.

**** 4.3. Conclusiones
Explotan el conocimiento disponible, pero no son puristas, teniendo
muchos parámetros; suelen ser más eficaces que los genéticos. El
proceso de diseño es importante.

*** Tema 5. Metaheurísticas basadas en trayectorias
**** 5.1. Enfriamiento simulado
Criterio de aceptación de soluciones peores, basado en
termodinámica. Variable de temperatura que regula el criterio de
aceptación, que también depende de la diferencia de fitness.

Mecanismos de enfriamiento.

 - Temperaturas descendientes.
 - Descenso constante.
 - Descenso geométrico.
 - Criterio de Boltzmann.
 - Esquema de Cauchy.

Condición de parada con número de iteraciones fijo.

**** 5.2. Búsqueda tabú (Glover)
Se introduce la posibilidad de introducir movimientos peores. Se
introducen /prohibiciones/ que evitan que se vuelva a buscar en el
mismo sitio. Hay una estructura de memoria adaptativa llamada *lista
tabú* que mantiene las zonas buscadas para no volver a ellas,
restringiendo el entorno de búsqueda.

Es costoso mantener todos los visitados.

 - Corto plazo o lista tabú, memoria recientemente considerada. Los
   así marcados son *tabú-activos*. No permanencen siempre en la lista
   hay un intervalo de tiempo de *tenencia tabú*. Puede haber niveles
   de aspiración.

   - Lista se soluciones tabú. Ya visitadas.
   - Lista de movimientos tabú. Vecinos que se eliminan del entorno.
   - Lista de valores tabú. Se eliminan los que tienen una característica.

 - Largo plazo, diversificación a zonas nuevas. Guía a posteriori,
   después de varias ejecuciones con memoria a corto plazo. Se usa
   para intensificar en zonas usadas o para diversificar la búsqueda 
   a zonas nuevas.  Estrategias de reinicialización cuando la búsqueda
   se estanca.

**** 5.3. Modelos multiarranque
 
**** 5.4. GRASP
Construye soluciones greedy aleatorizadas y aplica búsqueda local
sobre ellas. La construcción de la solución inicial ya lleva información
del problema eligiendo de una lista de candidatos greedy.

**** 5.5. ILS
Búsqueda local reiterada. Hay una mutación fuerte que aplica un cambio
brusco para poder seguir buscando.

 - Criterios de aceptación [TODO]

**** 5.6. Búsqueda de entorno variable. VNS

 - VND. Búsqueda descendente en entornos variables. Se amplía el
   entorno si no hay nadie mejor.
 - VNS. Es un ILS donde la mutación cambia si la solución mutada
   tras la búsqueda local no es mejor que la actual.

Otros modelos de entornos variables.

***** Diferencia VNS/ILS
La VNS quiere cambiar de entorno a lo largo de la búsqueda. La ILS
quiere construir un camino de soluciones óptimas locales.

*** Tema 6. Metaheurísticas basadas en adaptación social
**** Basados en adaptación social: particle swarm optimization
¿Cómo se mueven las partículas por el espacio de búsqueda?

**** Colonias de hormigas
Es bueno al meterlo:

 - Local search.
 - Multiarranque.
 - La reinicialización viene muy bien.

Colonias de hormigas sin local search se estancan y no son
competitivos.

**** Similitudes y diferencias PSO y Colonia de hormigas

 - Uno resuelve problemas reales, colonia de hormigas resuelve
   problemas en grafos.

 - Hormigas basado en estimergia, PSO está basado en trayectorias
   múltiples y en paralelo donde cada elemento es una solución y
   donde uno guía la búsqueda.

**** PSO pierde frente a Differential Evolution
Differential evolution es la más consistente para variables reales,
después de muchos años de desarrollo.

*** Tema 7. Aspectos avanzados en metaheurísticas
**** 7.1. Intensificación y diversificación

 * Intensificación (explotación), búsqueda local.
 * Diversifiación (exploración), búsqueda global.

Pueden presentarse en componentes *intrínsecas* (del algoritmo)
o *estratégicas* (añadidas al algoritmo). Suelen aplicarse de forma
oscilatoria.

|----------------+-----------------+-----------------------------|
| Metaheurística | Intensificación | Diversificación             |
|----------------+-----------------+-----------------------------|
| ES             | Búsqueda local  | Modificación de temperatura |
| BT             | Búsqueda local  | Lista tabú                  |
| GRASP          | Búsqueda local  | Lista candidatos            |
| ILS            | Búsqueda local  | Perturbación                |
| AGs            | Selección       | Operadores genéticos        |
|----------------+-----------------+-----------------------------|

***** Equilibrio
 * ES: hay una primera fase de diverisficación y una segunda de
   intensificación, es dinámico.
 * BT: es estático, el cuanto más tamaño más diversidad y menos
   intensificación.
 * ILS: hay intensificación si hay aceptación del mejor y más
   diversificación si se acepta el último local.
 * VNS: balance osiclatorio.
 * AGs: Modelo dinámico con diversidad.

***** Componentes estratégicas
Operadores genéticos especializados. Búsquedas locales especializadas
en el espacio métrico. Los genéticos necesitan componentes específicas
estratégicas.

***** Equilibrio oscilatorio
 * Algoritmo genético: modelo CHC.
 * Búsqueda tabú: memoria de frecuencias.

**** 7.2. Algoritmos genéticos. Exploración y explotación
 * Convergencia: presión selectiva, competición padres e hijos.
 * Diversidad: mutación fuerte, dispersión de soluciones.

***** Algoritmo CHC
Usa un operador de cruce que crea hijos muy diferentes a los padres.
Componentes estratégicas

 * *selección elitista*, introduce convergencia al seleccionar sólo
   las soluciones buenas;

 * *cruce uniforme (HUX)*, intercambia exactamente la mitad de alelos entre
   padres e hijos, garantizando que los hijos tengan distancia Hamming
   máxima a los padres; esto puede ralentizar convergencia;

 * *prevención de incesto*, solo cruza parejas que se diferencian en más
   de un número determinado de bits; previene la convergencia rápida.
   Normalmente se toma un umbral de diferencia a $l/4$ genes y se baja
   en cada generación en la que no se han generado nuevos.
   
 * *reinicialización*, cuando el umbral de cruce baja suficiente, se
   reinicializa; esto da muchísima diversidad;

   * modificando parcialmente la mejor solución,
   * generando aleatoriamente laa mayoría de la población.

Además, no usa mutación.

***** Propuesta del TSP
Introducir diversidad cuando no la haya.

 * Selección aleatoria adyacente que potencia diversidad.
 * Probabilidad de cruce 1.
 * Sin mutación.
 * Competición padres-hijos para tener más presión en población.
 * Diversificación voraz de la población en cada iteración.

Esto mantiene la diversidad constante y alta en la población
frente a la implementación normal. Las soluciones repetidas se
eliminan.

**** 7.3. Múltiples soluciones. Problemas multimodales
**** 7.4. Comentarios finales
*** Tema 8. Metaheurísticas paralelas
*** Prácticas
**** Elephant Search Algorithm (ESA)

*** Práctica alternativa
El usar focos de luz es un ejemplo de Estimergia.

** Ecuaciones diferenciales I
*** 1. Métodos de integración
**** 1.1. Método de variables separadas
**** 1.2. Ecuaciones homogéneas
\[
x' = f\left(\frac{x}{t}\right)
\]
**** 1.3. Ecuaciones reducibles a homogéneas
\[
x' = f \left( \frac{a+bt+cx}{\alpha + \beta t + \gamma x} \right)
\]

según la posición de las rectas

**** 1.4. Ecuaciones exactas
\[
M + Nx' = 0
\]

tal que existe $F \in {\cal C}^1(D)$ con $\frac{\partial F}{\partial t} = M$ y  $\frac{\partial F}{\partial x} = N$. Tienen
solución trivial $F(t,x) = k$ para $k$ constante.

** Álgebra conmutativa y computacional
# Exportaba con config.setup

*** 1. Anillos e ideales
**** La categoría CRing
***** Categoría
Consideramos la categoría de los *anillos conmutativos*, que consta de
los anillos conmutativos como objetos y de los homomorfismos de
anillos; respetando suma, producto y unidad; como morfismos.

***** Z es objeto inicial
El anillo $\mathbb{Z}$ es inicial en =CRing=. El homomorfismo único
queda unívocamente definido con $f(1) = 1$ y $f(n) = nf(1)$.

***** Subanillos
*Subanillo*. Subconjunto cerrado para la suma y el producto
conteniendo a 1.

***** Monomorfismos y epimorfismos
En =CRing= coinciden la inyectividad con ser monomorfismo y la
sobreyectividad con ser epimorfismo.

**** Ideales
***** Definición
Un *ideal* es un subconjunto cerrado para la suma y el producto de cualquier 
elemento desde $R$.

***** Retículo de ideales
Los ideales forman un retículo con la suma y la intersección.
Dos ideales son *primos relativos* cuando suman el anillo.

***** Generación de ideales
Llamamos $(X)$ al *ideal generado* por $X$; el menor ideal que 
contiene a $X$:

\[ (X) = \bigcap_{X \subset \alpha \text{, ideal}} \alpha\]

Lo llamamos *ideal finitamente generado* cuando $X$ es finito,
cumpliéndose:

\[ (X) = \left\{ \sum^{finita} r_ix_i \mid r_i \in R, x_i \in X\right\}\]

E *ideal principal* cuando $X$ tiene un sólo elemento.

***** Producto de ideales
Se define para $\alpha, \beta$ ideales como:

\[ \alpha\beta = \left\{ xy \mid x\in\alpha, y\in\beta \right\}\]

***** Ideales primos relativos
Dos ideales son *primos relativos* cuando $\alpha+\beta = R$. Cuando son 
primos relativos se cumple que $\alpha\beta = \alpha \cap \beta$.

**** Anillo cociente
***** Definición
Sea $R$ anillo y $\alpha \subset R$ ideal, tomamos la relación de equivalencia
$x \sim y \Leftrightarrow x-y \in \alpha$, para obtener:

\[ R/\alpha = \{x+\alpha \mid x\in R\}\]

***** Ideales del anillo cociente
Los ideales del anillo cociente sobre $\alpha$ están en correspondencia biyectiva
con los ideales que lo contienen, $\beta \supset \alpha$. Son siempre de la forma $\beta/\alpha$.

***** Primer Teorema de Isomorfía
Para cualquier homomorfismo de anillos $f$:

\[ R/\ker(f) \cong \mathrm{img}(f)\]

Y además, los ideales están en correspondencia biyectiva por $f_\ast$ y $f^{-1}$:

\[ \{ \alpha \mid \ker(f)\subset\alpha \} 
\longleftrightarrow 
\{ \beta \mid \beta \subset \mathrm{img}(f)\}\]

****** Demostración
Trivial desde la descomposición de morfismos en una categoría arbitraria.
Además, se comprueba que $f^{-1}$ preserva ideales y que $f_\ast$ preserva ideales en su 
imagen.

**** Ideales primos y maximales
***** Definición
$P$ es ideal *primo* si no es el total y $xy\in P \Rightarrow x \in P \vee y \in P$.
$P$ es ideal *maximal* si $M \neq R$ y es maximal en el retículo de ideales 
sin $R$.

***** Caracterización de ideales primos y maximales
En relación a su cociente en el anillo:

 - $P$ es primo ssi $R/P$ es un dominio de integridad no trivial.
 - $M$ es maximal ssi $M/P$ es un cuerpo no trivial.

****** Demostración trivial
***** Preservación de ideales primos y maximales
Dado un homomorfismo $f$,

 1. Si $\Pi$ es ideal primo, entonces $f^{-1}(\Pi)$ es ideal primo.
 2. La imagen y preimagen de ideales preserva primos y maximales 
    entre el núcleo y sobre la imagen del anillo.

Como consecuencia los ideales primos (resp. maximales) de un
anillo $R/\alpha$, son los ideales de la forma $\Pi/\alpha$ con $\alpha\subset\Pi$ primo (resp.
maximal).

****** Demostración
*1* es trivial. *2* tenemos que demostrarlo en cuatro pasos:

 - Si $M$ es maximal en $\mathrm{img} f$, entonces $f^{-1}(M)$ es maximal entre los 
   ideales que contienen a $\ker f$.
 - Si $M$ es maximal, entonces $f(M)$ es maximal en $\mathrm{img} f$.
 - Si $\Pi$ es primo en $\mathrm{img} f$, entonces $f^{-1}(\Pi)$ es primo, ya demostrado.
 - Si $\ker f \subset \Pi$ es primo, entonces $f(\Pi)$ es primo en $\mathrm{img} f$.

***** Teorema de Krull
Dados $\alpha \subseteq R$ ideal y $S$ multiplicativamente cerrado con $\alpha\cap S = \varnothing$, 
existe un ideal $M$ tal que:

  - $\alpha \subset M$ 
  - $M \cap S = \varnothing$
  - $M$ es maximal respecto a estas condiciones.

Además, $M$ es un ideal primo.

****** Subconjunto multiplicativamente cerrado
Es un subconjunto $S$ con:

 - $1 \in S$
 - $x,y\in S \implies xy \in S$

****** Demostración
Dada una cadena de ideales cumpliendo la condición su unión también 
la cumple y es cota de la cadena. Aplicando lema de Zorn obtenemos 
un maximal.

Supongamos $xy \in M$, pero $x,y \notin M$. Entonces $M+(x) \cap S \neq \varnothing$ y
$M + (y) \cap S \neq \varnothing$ por maximalidad, y deben existir $xz,yt \in S$; luego
se tendría $xzyt \in M \cap S$, contradicción.

***** Corolario al teorema de Krull
Tomando $S=\{1\}$ tenemos que; dado un ideal, existe un ideal maximal que 
lo contiene. En particular, todo elemento no unidad está contenido en un 
ideal maximal, tomando $S = (x)$.

**** Anillos locales
***** Inclusión en ideales primos
Sean ideales $\alpha_1,\dots,\alpha_n$ y $\pi$ un ideal primo. Si $\bigcap \alpha_i \subset \pi$, entonces,

$\exists i: \alpha_i \subset \pi$.

****** Demostración
Supongamos que $\forall i: \alpha_i \nsubseteq \Pi$; entonces tenemos $x_i \in \alpha_i - \Pi$ tales que ninguno
está en $\Pi$, pero su producto debe estar, contraviniendo que sea primo.

***** Inclusión de ideales primos
Sean ideales primos $\pi_1,\dots,\pi_n$, (salvo quizá 2) y $\alpha$ un ideal. Si $\alpha \subset \bigcup \pi_i$, 
entonces,

$\exists i: \alpha \subset \pi_i$.

****** Demostración
En el caso $n=2$, supongamos $\alpha \subset \pi_1 \cup \pi_2$; y tomemos $x \in \alpha, x\in\pi_1$, $y\in\alpha, y\in\pi_2$.
Entonces tendría $x+y \in \alpha$, pero no estaría en $\pi_1 \cup \pi_2$. Nótese que no usamos
todavía que sean primos.

En el caso inductivo, aplico la hipótesis de inducción para obtener, para cada $k$:

\[\exists x_k \in \alpha : x_k \notin \bigcup_{i\neq k} \pi_i\]

Luego debe tenerse $x_k \in \alpha_k$; sea ahora $x = x_1x_2\dots x_{n-1}+x_n \in \alpha$; 
luego $\exists r: x\in\alpha_r$. Si $r=n$, tendríamos $x_1x_2\dots x_{n-1} \in \alpha_r$, y por primalidad debería
estar alguno; si no, tendríamos $x_n \in \alpha_r$.

***** Definición de anillo local
Un *anillo local* es aquel con un único ideal maximal. A $R/M$ se le llama 
*cuerpo residual*.

***** Caracterización de anillos locales
Un anillo $R$ es local ssi $\{x\in R \mid x \text{ no unidad}\}$ es un ideal.

Sea $M$ ideal propio:

 - $R$ es local con maximal $M$ ssi $R-M \subset {\cal U}(R)$.
 - Si $M$ es maximal y $\{1+x \mid x\in M\}\subset {\cal U}(R)$ entonces es $R$ local y $M$ su maximal.

****** Demostración
1. Una no unidad debe estar contenida en el único maximal que hay, que no contiene
   a las unidades y además es ideal.
   Por otro lado, por Krull, el ideal de las no unidades debería estar contenido
   en un ideal maximal que tampoco tuviera unidades, luego debe ser él mismo.
2. Por la caracterización anterior tenemos una implicación. Sea $R-M \subset {\cal U}(R)$,
   si tenemos $M \not\subset \beta$, entonces tendríamos un $x \in \beta,x \notin M$, luego $x \in {\cal U}(R)$
   y entonces $\beta = R$. Si tenemos otro $M'$ maximal, entonces $\exists x\in M': x \notin M$,
   pero eso me vuelve a dar $M' = R$. Luego $M$ es el único ideal y maximal.
3. Por la caracterización anterior tenemos una implicación. Sea $x \notin R-M$,
   tenemos por maximalidad: $rx+m = 1$, luego $rx = 1-m \in {\cal U}(R)$.
   En conclusión, $R-M \subset {\cal U}(R)$ y es local.

**** Radicales
***** Nilradical
Sus elementos se llaman *nilpotentes*:

\[\operatorname{Nil}(R) = \{x \in R \mid \exists n: x^n = 0\}\]

El nilradical es un ideal.

***** Anillo reducido
Un anillo es *reducido* si $\operatorname{Nil}(R) = 0$. Los dominios de integridad son 
reducidos. Además, podemos reducir un anillo dividiendo por su 
nilradical $R/\operatorname{Nil}(R)$.

***** Espectro
El *espectro* de un anillo R es el conjunto de sus ideales primos:

\[\spec(R) = \{\pi\subset R \mid \pi \text{ es un ideal primo}\}\]

***** Caracterización del nilradical
El nilradical de $R$ es la intersección de los ideales del espectro:

\[ \operatorname{Nil}(R) = \bigcap_{\pi \in \operatorname{Spec}(R)} \pi\]

****** Demostración
Sea $x^n = 0$, entonces $x^n \in \pi, \forall \pi \in \operatorname{Spec}(R)$; y, por primalidad, $x \in \pi$.
Sea $x \notin \operatorname{Nil}(R)$, entonces $S = \{1,x,x^2,\dots\}$ es multiplicativamente cerrado 
con $S \cap \operatorname{Nil}(R) = \varnothing$. Por Krull, tenemos un $\pi$ tal que $\pi \cap S = \varnothing$.

***** Radical de un ideal
Se define como:

\[\sqrt{\alpha} = \{x \in R \mid \exists n \geq 1 : x^n \in \alpha\}\]

Tenemos que $\operatorname{Nil}(R/\alpha) = \sqrt{\alpha}/\alpha$. Cuando $\alpha = \sqrt{\alpha}$ decimos que es *ideal radical*.
Se caracteriza como:

\[\sqrt{\alpha} = \bigcap_{\alpha \subset \pi \in Spec(R)} \pi\]

****** Demostración
Tenemos claramente $\pi^{-1}(\operatorname{Nil}(R/\alpha)) = \sqrt{\alpha}$, pero entonces:

\[\sqrt{\alpha} = 
\pi^{-1}(\operatorname{Nil}(R/\alpha))=
\pi^{-1} \left( 
\bigcap_{\alpha \subset \pi \in \operatorname{Spec}(R/\alpha)} \pi/\alpha 
\right) = \bigcap_{\alpha \subset \pi \in \operatorname{Spec}(R)} \pi\]

***** Radical de Jacobson
Se define el *radical de Jacobson* como:

\[{\cal J}(R) = \bigcap_{{\cal M} \text{ maximal}} {\cal M}\]

****** Caracterización del radical de Jacobson
Tenemos que $x \in {\cal J}(R)$ ssi $1-xy \in U(R)$ para cualquier $y$.

******* Demostración
Un elemento $1-xy$ para $x \in {\cal J}(R)$ no puede estar en ningún ideal maximal, 
porque estaría entonces el $1$. Por corolario de Krull, debe ser unidad.

Supongamos $x \notin M$, entonces $(x) + M = R$, y por tanto $1-xy \in M$. Pero 
un maximal no puede contener una unidad.

**** Ideales residuales y anulador
***** Ideales residuales
Definimos el *ideal residual* (a veces llamado *cociente*) de dos 
ideales como:

\[ (\alpha : \beta) = \{x\in R\mid x\beta \subset\alpha\}\]

***** Anulador
\[\operatorname{Ann}(\beta) = \{x \in R \mid x\beta = 0\} = (0 : \beta)\]

**** Ideales contraídos y extendidos
***** Ideal extendido
Dado un homomorfismo $f : R \longrightarrow S$ llamamos *ideal extendido* de $\alpha$ al ideal:

\[ \alpha^e = (f(\alpha)) = \left\{ \sum s_i f(x_i) \mid s_i \in S, x_i \in \alpha\right\}\]

***** Ideal contraído
Dado un homomorfismo $f$ llamamos *ideal contraído* de $\beta$ al ideal:

\[ \beta^c = f(\beta) \]

***** Biyección entre ideales
Para $f : S \longrightarrow R$ homomorfismo y $\alpha,\beta$ ideales:

  1. $\alpha \subset \alpha^e^c$, y $\beta \supset \beta^c^e$.
  2. $\alpha^e = \alpha^e^c^e$, y $\beta^c = \beta^c^e^c$.
  3. Hay una biyección con $(-)^e,(-)^c$ entre ideales contraídos y extendidos, 
     que además pueden escribirse como $\{\alpha \subset R \mid \alpha = \alpha^e^c\}$ y $\{\beta \subset S \mid \beta = \beta^c^e\}$.

****** Demostración
Pueden escribirse así porque si tengo $\beta = \alpha^e$, entonces $\beta^c^e = \alpha^e^c^e = \alpha^e = \beta$. 
La biyección es trivial desde la definición y las proposiciones anteriores.

**** Producto directo de anillos
***** Producto directo
Para $R_1,R_2,\dots,R_n$ tomamos como su producto directo a:

\[R_1\times \dots \times R_n = \prod_{i=1}^n R_i\]

con las operaciones definidas componente a componente.

***** Proyecciones e inclusiones
Las *proyecciones*, $p_k$, a cualquier factor son homomorfismos.
Las *inclusiones*, $u_k$, *no* son homomorfismos, ya que no respetan
el uno del anillo, que en este caso es $(1,\dots,1)$. Cumplen además:

 - $p_k \circ u_k = \delta_{kj}id$
 - $\sum u_i \circ p_i = id$
 - $\ker(p_j) = \sum \mathrm{img}(u_j)$

***** Propiedad universal
El producto con las proyecciones es el *producto categórico* de la
categoría de los anillos:

\[ \begin{tikzcd}
& & S \dar[dashed]{\exists!} \arrow[bend right]{ddll} \arrow[bend right]{ddl} \arrow[bend left]{ddr} \arrow[bend left]{ddrr} & &\\
& & \prod R \arrow{dll}[swap]{\pi_1} \arrow{dl}{\pi_2} \arrow{dr}[swap]{\pi_3} \arrow{drr} & & \\
R_1 & R_2 &  & R_3 & \dots
\end{tikzcd} \]

***** Teorema Chino del Resto
En la situación de la propiedad universal sobre el cociente por unos
ideales $\alpha_1,\dots,\alpha_n$:

\[ \begin{tikzcd}
\prod_{i=1}^n R/\alpha_i \rar{\pi_i} &  R/\alpha_i \\
R \uar{\exists! f} \urar{p_i}
\end{tikzcd} \]

Tenemos que:

  1. Si los $\alpha_i$ son primos entre sí, $\prod \alpha_i = \bigcap \alpha_i$.
  2. La $f$ es sobreyectiva ssi los $\alpha_i$ son primos entre sí.
  3. La $f$ es inyectiva ssi $\bigcap \alpha_i = 0$. De hecho, $\ker(f) = \bigcap \alpha_i$.

****** Demostración
1. El caso $n=2$ es conocido. En el caso $n>2$, aplicamos la hipótesis
   de inducción a $\alpha_1\alpha_2\dots\alpha_{n-1}$ y a $\alpha_n$, que se demuestran primos relativos.
2. Doble implicación:
   - Si $f$ es sobreyectiva, existe $f(x) = (1,0,0,\dots)$, que me da $x \in \alpha_i$
     para cualquier $i$, y además, $x-1 \in \alpha_1$; luego $1 \in \alpha_i+\alpha_1$.
   - Si son primos relativos, existen $x_i + y_i = 1$ con $x_i \in \alpha_1$, $y_i \in \alpha_i$.
     $y = y_2y_3\dots y_n = 1 + x$, con $x \in \alpha_1$; luego $y \equiv_{\alpha_1} 1$ pero $y \equiv_{\alpha_i} 0$; luego
     puedo crear una base del anillo.
3. Trivial.

*** 2. Bases de Gröbner
**** R-álgebras
***** R-módulo
Dado $R$ anillo. Un *R-módulo* (izquierdo) es un grupo abeliano $M$ junto
a una operación $\cdot : (R,M) \longrightarrow M$ verificando:

  - $r(x+y) = rx+ry$
  - $(r+s)x = rx+sx$
  - $r(sx) = (rs)x$
  - $1x = x$

***** R-álgebras
Una *R-álgebra* $S$ es un anillo con estructura de R-módulo, tal que:

\[\forall r\in R, x,y\in S:\; (rx)y = r(xy) = x(ry)\]

***** Homomorfismo de estructura
Equivalentemente, una R-álgebra es un anillo $S$ junto a un 
*homomorfismo de estructura* $\lambda : R \longrightarrow S$.

****** Equivalencia
Nótese que puedo pasar de una a otra definición tomando $\lambda(r) = r1$.

***** Homomorfismos de R-álgebras
Un homormorfismo de R-álgebras $f : S_1 \longrightarrow S_2$ es un homomorfismo de 
anillos que sea también homomorfismo de R-módulos.

\[ f(rs) = rf(s) \]

***** Anillo de polinomios
Definimos el anillo de polinomios en varias variables recursivamente:

\[ R[X_1,X_2,\dots,X_n] = R[X_1,X_2,\dots,X_{n-1}][X_n] \]

Y forma una R-álgebra con la inclusión desde $R$.

***** Propiedad universal del anillo de polinomios
Sea $S$ anillo y $f : R \longrightarrow S$ homomorfismo de anillos. Sean $s_1,\dots,s_n \in S$
elementos arbitrarios; entonces existe un único homomorfismo de 
R-álgebras $f_{s_1,\dots,s_n} : R[X_1,\dots,X_n] \longrightarrow S$ tal que:

\[ \begin{tikzcd}
R \rar[hook]{i} \drar[swap]{f} & R[X_1,X_2,\dots,X_n] \dar[dashed]{f_{s_1,\dots,s_n}} \\
  & S
\end{tikzcd} \]

Llevando $f(X_i) = s_i$.

****** TODO Demostración

***** R-álgebras finitamente generadas
Una R-álgebra $S$ es finitamente generada si existe un epimorfismo de
R-álgebras $f : R[X_1,\dots,X_n] \longrightarrow S$.

**** Órdenes monomiales
***** Representación recursiva de un polinomio
Llamamos representación recursiva a la siguiente:

\[
F = \sum_{j=0}^t F_j X^j_n
\]

donde $F_j \in K[X_1,\dots,X_{n-1}]$. Nótese que es la representación natural una
vez asumimos la definición recursiva del anillo de polinomios.

***** Representación distributiva de un polinomio
Llamamos representación distributiva a la siguiente:

\[ p = \sum a_{(\alpha_1,\dots,\alpha_n)} 
X_1^{\alpha_1} X_2^{\alpha_2} \dots X_n^{\alpha_n} \]

Si escribimos los monomios como $X^{\alpha}$ para cada $\alpha \in \mathbb{N}^n$, nos
queda:

\[p = \sum_{\alpha \in \mathbb{N}^n} a_\alpha X^\alpha\]

***** Base de los polinomios
Los monomios forman una K-base vectorial del espacio de polinomios:

\[\{ X^\alpha \mid \alpha \in \mathbb{N}^n \}\]

****** Demostración
Son claramente sistema de generadores y, por definición, un polinomio
con algún coeficiente no nulo no puede ser nunca nulo. Nótese que puede
haber cuerpos donde los polinomios evalúen a cero en cualquier punto
del cuerpo, como $X(X-1)$ en $\mathbb{F}_2$, pero ese polinomio no se considera 
nulo.

***** Grado de un monomio
El grado de un monomio $X^\alpha$ con $\alpha \in \mathbb{N}^n$ es la suma:

\[gr(X^\alpha) = \sum^n_{i=1} \alpha_i\]

***** Órdenes compatibles
Un orden $\leq$ en $\mathbb{N}^n$ es compatible si:

\[\alpha \leq \beta \Longrightarrow \alpha + \gamma \geq \beta + \gamma\]

***** Órdenes monótonos
Un orden $\leq$ es monótono si:

\[ 0 \leq \alpha \]

***** Órdenes monomiales
Un orden monomial es compatible, monótono y total.

***** Orden lexicográfico
Definimos $\alpha \geq_{lex} \beta$ cuando para el primer $\alpha_i \neq \beta_i$, se tiene $\alpha_i \geq \beta_i$.

***** Orden lexicográfico graduado
Definimos $\alpha \geq_{grlex} \beta$ cuando $\sum \alpha > \sum \beta$ ó se da la igualdad
y se tiene $\alpha \geq_{lex} \beta$.

***** Orden lexicográfico graduado inverso
Definimos $\alpha \geq_{invgrlex} \beta$ cuando $\sum \alpha > \sum \beta$ ó se da la igualdad
y para el primer $\alpha_i \neq \beta_i$ a la derecha, se tiene $\alpha_i < \beta_i$.

***** Preórdenes
Un preorden es una relación binaria transitiva y reflexiva.
Equivalentemente, es un orden sin la antisimetría.

***** Relación de equivalencia en preódenes
Dado un preorden $\sqsubseteq$, se define la relación de equivalencia $x \equiv y$,
que se tiene cuando $x \sqsubseteq y \wedge y \sqsubseteq x$.

***** Producto lexicográfico de preórdenes
Definimos el producto lexicográfico de dos preórdenes $\sqsubseteq_1,\sqsubseteq_2$
como:

\[x \sqsubseteq_{12} y = \left\{
\begin{array}{l} 
x \sqsubseteq_1 y \wedge y \not\sqsubseteq_1 x \\ 
\text{  ó} \\
x \equiv_1 y \wedge x \sqsubseteq_2 y
\end{array}\right.\]

***** Propiedades del producto
El producto de preórdenes cumple:

  1. $\sqsubseteq_{12}$ es un preorden.
  2. $\sqsubseteq_2$ orden $\Rightarrow$ $\sqsubseteq_{12}$ orden
  3. $\sqsubseteq_1,\sqsubseteq_2$ totales $\Rightarrow$ $\sqsubseteq_{12}$ total
  4. $\sqsubseteq_1,\sqsubseteq_2$ compatible $\Rightarrow$ $\sqsubseteq_{12}$ compatible
  5. $\sqsubseteq_1,\sqsubseteq_2$ monótono $\Rightarrow$ $\sqsubseteq_{12}$ monótono

****** Demostración
******* Punto 1
Es reflexivo trivialmente. La transitividad se obtiene analizando 
por casos.

******* Punto 2
Cuando $x \equiv_{12} y$, se tiene $x \equiv_1 y$ y por tanto $x \equiv_2 y$; lo que llevaría
a $x = y$.

******* Punto 3
Si ambos son totales, suponemos s.p.g. que $x \sqsubseteq_1 y$. Si no tuviéramos
que $y \sqsubseteq_1 x$, entonces $x \equiv_1 y$ y como son totales, podemos suponer s.p.g
que $x \sqsubseteq_2 y$, llgando a $x \sqsubseteq_{12} y$.

******* Punto 4
# No parece obvio si no son órdenes. Además, tenemos definido lo que
# es ser compatible o monótono sólo para órdenes.

******* Punto 5
Tenemos $0 \sqsubseteq_1 x$; si tuviéramos $x \sqsubseteq_1 0$, entonces $x \equiv_1 0$; pero como
sabemos que $0 \sqsubseteq_2 x$, tenemos finalmente $0 \sqsubseteq_{12} x$.

***** Los órdenes son monomiales
Los órdenes $\leq_{lex},\leq_{grlex},\leq_{invgrlex}$ son monomiales.

****** Demostración
******* El orden lexicográfico es monomial
Una forma de definir el orden lexicográfico es con el signo del primer
elemento de la resta. Sabemos que es total. La monotonía y la 
compatibilidad se tienen por:

\[(\alpha+\gamma)-(\beta+\gamma) = (\alpha-\beta)\]

Tenemos que $\alpha - 0 = \alpha$, positivo.

******* El resto de órdenes son monomiales
Simplemente notando que el grado es un preorden y que son [[*Propiedades del producto][producto]]
de preorden con el lexicográfico o con un lexicográfico inverso.

**** Lema de Dickson
***** Lema de Dickson
Para $S \subseteq \mathbb{N}^n$ no vacío, existe $G \subseteq S$ finito tal que $S \subseteq G + \mathbb{N}^n$.

****** Demostración
******* Caso base
Cuando $n=1$, como los naturales están bien ordenados, podemos tomar
el mínimo

******* Caso inductivo
Tomamos un $y \in S$, y tenemos dos casos, o bien $x \in \{y\} + \mathbb{N}^n$, o bien
se tiene $x \in S_{i|j}$ para $j < y_i$. Donde definimos:

\[
S_{i|j} 
= 
\{ x \in S \mid x_i = j\}
\]

Y una familia de conjuntos:

\[
S_{i|j}'
=
\{ 
x \in \mathbb{N}^n
\mid
x_i=0, (x_1,\dots,j,\dots,x_n) \in S
\}
\]

Que por hipótesis de inducción dejando nula a cada paso una de las
coordenadas, dan lugar a $G_{i|j}' \subseteq S_{i|j}'$ finito con $S'_{i|j} = G_{i|j}'+\mathbb{N}^{n-1}$.

\[
G_{i|j} = 
\{x \in S_{i|j} \mid (x_1,\dots,0,\dots,x_n) \in G'_{ij} \}
\]

Sea ahora $x \in S_{i|j}$. Si hacemos un cero en $i$, se tiene 
$(x_1,\dots,0,\dots,x_n) \in S'_{i|j} \subseteq G_{i|j}'+ \mathbb{N}^{n-1}$. Luego

\[\begin{aligned}
(x_1,\dots,0,\dots,x_n) &= z + \alpha \\
(x_1,\dots,j,\dots,x_n) &= (z_1,\dots,j,\dots,z_n) + (\alpha_1,\dots,0,\dots,\alpha_n)
\end{aligned}\]

Por lo tanto, $S_{i|j} \subseteq G_{i|j} + \mathbb{N}^{n}$; y tenemos finalmente $S \subseteq G + \mathbb{N}^n$ si
definimos:

\[G = \{y\} \cup \bigcup_{i,j<y_i} G_{i|j}\]

Tenemos que cada uno de ellos es finito.

***** Orden monomial es buen orden
Todo orden monomial en $\mathbb{N}^n$ es buen orden.

****** Demostración
Por Dickson, cualquier subconjunto tiene un $G$ finito con $S \subseteq G + \mathbb{N}^n$.
El mínimo de $G$ existe por finitud y ser orden total. Es el mínimo de
$S$ porque cualquier otro $s \in S$ cumple $s = g + \gamma$ para $g \in G$, lo que lleva
por monotonía y compatibilidad, a $s \geq g$.

***** Monoideales
Un subconjunto $E \subseteq \mathbb{N}^n$ es monoideal cuando $E = E + \mathbb{N}^n$.

***** Sistemas de generadores
Si $E$ es monoideal, existe $G \subset E$ finito con $E = G + \mathbb{N}^n$.
Llamamos a $G$ sistema de generadores de $E$.

****** Demostración
Por Dickson tenemos $E \subset G + \mathbb{N}^n$, luego $E = E + \mathbb{N}^n = G + \mathbb{N}^n$. 

***** Sistema de generadores minimal
Un sistema de generadores es minimal si ningún subconjunto
suyo es sistema de generadores.

***** Unicidad del sistema de generadores minimal
El sistema de generadores minimal de un monoideal es único.

****** Demostración
Supongamos que hubiera dos $G,G'$, con $\beta \in G' \setminus G$. Entonces tendría una
representación con $g \in G, g' \in G', \gamma \neq 0$ como:

\[
\beta = g + \gamma = g' + \delta + \gamma
\]

Con lo cual, $\beta \in G'\setminus \{\beta\} + \mathbb{N}^n$, contraviniendo minimalidad.

**** División de polinomios
***** Diagrama de Newton
El conjunto de exponentes para un polinomio $p = \sum a_\alpha x^\alpha$:

\[N(p) = \{\alpha\in\mathbb{N}^n \mid a_\alpha \neq 0\}\]

***** Exponente
El exponente de un polinomio, fijado un orden monomial, es el máximo
exponente de su diagrama:

\[exp(p) = \max \{\alpha\in\mathbb{N}^n \mid a_\alpha \neq 0\} \]

***** Grado total
Definimos el grado total, fijado un orden monomial, como el máximo
grado de los exponentes:

\[Grtot(p) = \max \{gr(\alpha) \mid a_\alpha \neq 0\} \]

***** Término líder
Llamamos término líder al que aporta el exponente, $a_{Exp(p)}X^{Exp(p)}$.
Su coeficiente líder es $a_{Exp(p)}$ y su monomio líder, $X^{Exp(p)}$.

***** Propiedades del exponente
Dados $F,G \in K[X_1,\dots,X_n]$ no nulos: 

  1. $exp(FG) = exp(F) + exp(G)$.
  2. $exp(F+G) \leq \max\{exp(F),exp(G)\}$.
  3. Si $exp(F) < exp(G)$; entonces $exp(F+G) = exp(G)$.

****** Demostración
En el fondo, parte sólo de la observación de que son K-espacios 
vectoriales y tienen de base a los distintos monomios.

******* Punto 1
Primero notamos que si estamos en un cuerpo, el producto de dos
polinomios tendrá en su diagrama de Newton a la suma de cualesquiera
exponentes de ambos polinomios. Supongamos la suma máxima $\gamma + \delta$, y
la suma de los máximos $\alpha+\beta$. Usamos que son máximos y orden monomial
para tener:

\[\alpha + \beta \geq \gamma + \delta\]

******* Punto 2
Si un exponente no aparece en $F$ ni en $G$, tendrá coeficiente nulo
también en $F+G$.

******* Punto 3
La suma tendrá como mucho los exponentes de $F$ y de $G$. Pero además,
conserva los exponentes que sólo estuvieran en uno de los dos con los
coeficientes intactos.

***** Partición de generadores
Dada una lista de elementos $a_1,\dots,a_k$, tenemos una partición que
definimos inductivamente como:

  1. Los elementos que genera el primer generador: 

     \[\Delta^1 = a_1 + \mathbb{N}^n\]

  2. Los elementos nuevos que aporta cada nuevo generador:

     \[\Delta^i = (a_i + \mathbb{N}^n) \setminus \bigcup_{j < i} \Delta^j \]

  3. Todos los demás elementos:

     \[ \overline{\Delta} = \mathbb{N}^n \setminus \bigcup_{j \leq k} \Delta^j\]

***** Teorema de la división
Dado un orden monomial y una lista de polinomios $G_i$; consideramos la
partición $\Delta_1,\dots,\overline{\Delta}$ dada por los exponentes $exp(G_i)$. Tenemos que para
cada $F \in K[X_1,\dots,X_n]$, existen $Q_1,\dots,Q_t,R$ únicos tales:

  1. $F = Q_1G_1 + \dots + Q_tG_t + R$.
  2. $R = 0$ ó $N(R) \subseteq \overline\Delta$.
  3. $exp(G_i) + N(Q_i) \subseteq \Delta^i$.

****** Demostración
******* Caso base
Aplicamos inducción a $exp(F)$ aprovechando el [[*Orden monomial es buen orden][buen orden]]. Sea 
$exp(F) = (0,\dots,0)$.

******** Aparece en algún elemento de la partición
Si $exp(F) \in \Delta^i$, entonces forzosamente $exp(G_i)=0$. Entonces tomamos
$Q_i = {F}/{G_i}$, y $Q_j=0$ para $j \neq i$.

******** Sólo aparece en el resto de la partición
Simplemente tomamos $R = F$.

******* Caso inductivo
Sabiendo que se tiene el resultado para todo $G$ con $exp(G) < exp(F)$,
tenemos de nuevo dos casos.

******** Aparece en algún elemento de la partición
Si $exp(F) \in \Delta^i$, entonces $exp(F) = exp(G) + \gamma$. Tomando $H=X^\gamma G$,
aplicamos inducción sobre:

\[F - \frac{cl(F)}{cl(H)} H 
=
F'
= 
\sum Q'_iG_i + R'
\]

Pero si tomamos $Q_i = Q_i' + \frac{cl(F)}{cl(H)} X^\gamma$ y $Q_j = Q_j'$ para todos los demás:

\[F = \sum Q_i G_i + R\]

******** Sólo aparece en el resto de la partición
Aplicamos hipótesis de inducción sobre:

\[F-tl(F) = F' = \sum Q_i'G_i + R'\]

Entonces tomamos $R = R' + tl(F)$ y se tiene:

\[F = \sum Q_i'G_i + R\]

***** Ejemplo de división
Dividimos $F = X^4Y^2+X^2Y^3Z-2XY^2Z^3-3X^2YZ^4$ entre los polinomios:

  - $G_1 = X^3Y-2X^2Z^2$
  - $G_2 = X^2Y^3+XZ^3$
  - $G_3 = XY^2Z - X^2YZ - 3XYZ^2$

Usando el orden lexicográfico.

****** Exponentes
Con el orden dado, tenemos exponentes:

  - $exp(G_1) = (3,1,0)$
  - $exp(G_2) = (2,3,0)$
  - $exp(G_3) = (2,1,1)$

Con ellos creamos las particiones $\Delta_i$.

****** Desarrollo
A cada paso tomamos el exponente mayor, lo encuadramos en un subconjunto
de la partición y dividimos para el siguiente elemento.

\[F = X^4Y^2+X^2Y^3Z-2XY^2Z^3-3X^2YZ^4\]

Tenemos $(4,2,0) \in \Delta_1$, así que restamos $XYG_1$:

\[F = 2X^3YZ^2+X^2Y^3Z-2XY^2Z^3-3X^2YZ^4\]

Tenemos $(3,1,2) \in \Delta_1$, así que restamos $2Z^2G_1$:

\[F = 4X^2Z^4+X^2Y^3Z-2XY^2Z^3-3X^2YZ^4\]

Tenemos $(2,3,1) \in \Delta_2$, así que restamos $ZG_2$:

\[F = 4X^2Z^4 - 2XY^2Z^3 - 3X^2YZ^4 - XZ^4\]

Tenemos $(2,1,4) \in \Delta_3$, así que restamos $3Z^3G_3$:

\[F = 4X^2Z^4 - 2XY^2Z^3 - XZ^4 - 3XY^2Z^4 + 9XYZ^5\]

Tenemos $(2,0,4) \in \overline\Delta$, así que tomamos lo demás como resto. Nos acabará
quedando que:

\[R = 4X^2Z^4 - 2XY^2Z^3 - XZ^4 - 3XY^2Z^4 + 9XYZ^5\]

Por lo tanto:

\[F = (XY+2Z^2)G_1 + ZG_2 + 3Z^3G_3 + R\]

****** Cálculo en Sage
Calculamos el resto de la división en sage. Nótese cómo se ve afectado
por el orden de los polinomios que escojamos para la división.

#+BEGIN_SRC sage
  R.<x,y,z> = PolynomialRing(QQ, 3, 'xyz', order='lex')
  f = x^4*y^2 + x^2*y^3*z - 2*x*y^2*z^3 - 3*x^2*y*z^4
  g1 = x^3*y - 2*x^2*z^2
  g2 = x^2*y^3 + x*z^3
  g3 = x*y^2*z - x^2*y*z - 3*x*y*z^2
  f.reduce(Ideal([g1])).reduce(Ideal([g2])).reduce(Ideal([g3]))
  f.reduce(Ideal([g3])).reduce(Ideal([g2])).reduce(Ideal([g1]))
#+END_SRC

#+RESULTS:
: 4*x^2*z^4 - 3*x*y^2*z^4 - 2*x*y^2*z^3 + 9*x*y*z^5 - x*z^4
: x^2*y^3*z - 3*x^2*y*z^4 + 4*x^2*z^4 - 2*x*y^2*z^3

**** Ideales monomiales
***** Ideales monomiales
Un ideal es monomial si está generado por monomios. Es decir, si es de la 
forma:

\[ I = (X^\alpha \mid \alpha\in A)\]

Para algún $A \subset \mathbb{N}^n$.

***** Pertenencia a ideal monomial
Si $X^\beta \in (X^\alpha \mid \alpha\in A)$ es de la forma: $X^\beta = FX^\alpha$.

****** Demostración
Los monomios forman una K-base del espacio. Como:

\[X^\beta = \sum F_iX^\alpha\]

Todo monomio de la expresión de la derecha es divisible por algún $X^\alpha$,
y en particular, $X^\beta$ debe serlo.

***** Monomios en ideal monomial
Sea $I = (X^\alpha \mid \alpha\in A)$ monomial, equivalen:

  1. $F \in I$.
  2. Todo monomio de $F$ está en $I$.
  3. $F$ es combinación lineal de monomios de $I$.

Y además, si para cualquier polinomio todos sus monomios están en
el ideal, es monomial.

****** Demostración
Los monomios forman una K-base del espacio. Como:

\[F = \sum F_iX^\alpha\]

Todo monomio de $F$ debe ser múltiplo de algún $X^\alpha$.

El resto de implicaciones son triviales. Nótese que podemos escribir
el ideal como $(X^\alpha \mid \alpha \in Exp(I))$.

***** Exponente de un ideal
Dado un ideal $I$ no nulo, definimos su exponente como el subconjunto:

\[Exp(I) = \{Exp(F) \mid 0\neq F \in I\} \subseteq \mathbb{N}^n\]

***** El exponente es monoideal
$Exp(I)$ es un monoideal de $\mathbb{N}^n$.

****** Demostración
Sea $F \in I$, tenemos $X^\alpha F \in I$ para cualquier $\alpha$ y:

\[exp(X^\alpha F) = \alpha + exp(F)\]

Gracias a que los órdenes son compatibles.

***** Lema de Dickson para ideales monomiales
Todo ideal monomial tiene un sistema de generadores finito y formado
por monomios.

****** Demostración
Como $Exp(I)$ es [[*Monoideales][monoideal]], tiene [[*Sistemas de generadores][sistema de generadores]] $Exp(I) = G + \mathbb{N}^n$.
Dado un exponente $\alpha \in Exp(I)$, [[*Monomios en ideal monomial][tenemos]] $X^\alpha \in I$, luego tomamos como sistema
de generadores:

\[ (X^\alpha \mid \alpha \in G) \]

Dado cualquier $F \in I$, sus monomios estarán en $I$ y serán múltiplo
de ellos.

***** Corolario de generación de ideales
Sean $I,J \subseteq K[X_1,\dots,X_n]$ ideales monomiales:

\[I=J \iff Exp(I)=Exp(J)\]

****** Demostración
Si tienen el mismo exponente, tienen el mismo generador.

***** Unicidad del sistema de generadores minimal
Sea $I$ monomial no nulo. Existe un único sistema de generadores minimal
formado por monomios, es decir, ningún subconjunto suyo es generador.

****** Demostración
Dado $G$ el [[*Unicidad del sistema de generadores minimal][único]] sistema generador minimal de $Exp(I)$. Entonces, sus
monomios generan al ideal y si:

\[H \subseteq (X^\alpha\mid \alpha \in G)\]

genera al ideal, en particular se tendría $Exp(I) = H + \mathbb{N}^n$, contraviniendo
minimalidad.

***** Otros sistemas de generadores
Sea $G = \{\alpha_1,\dots,\alpha_n\}$ sistema de generadores de $Exp(I)$. Si $exp(F_i)=\alpha_i$,
entonces $\{F_1,\dots,F_n\}$ es sistema de generadores de $I$.

****** Demostración
Para $F\in I$, por [[*Teorema de la división][división]] tenemos:

\[F = \sum Q_iF_i + R\]

Como $R\in I$, $exp(R) \in Exp(I)$ y debe tenerse $R = 0$.

**** Bases de Gröbner
***** Bases de Gröbner
Sea $I \subseteq K[X_1,\dots,X_n]$ un ideal no nulo. Una base de Gröbner es un conjunto
$\mathbb{G} = \{G_1,\dots,G_n\} \subseteq I$ cumpliendo $Exp(I) = \{exp(G_1),\dots,exp(G_n)\} + \mathbb{N}^n$.

***** Propiedades de bases de Gröbner
Las bases de Gröbner en $K[X_1,\dots,X_n]$ cumplen:

  1. Todo ideal no nulo tiene una base de Gröbner.
  2. Toda base de Gröbner de un ideal es base de generadores del ideal.
  3. *Teorema de la base de Hilbert*: todo ideal es finitamente generado.

****** Demostración 
******* Punto 1
Sabemos que $Exp(I)$ es [[*El exponente es monoideal][monoideal]] y por tanto tiene un sistema de
[[*Sistemas de generadores][generadores]]. Existen entonces polinomios cumpliendo:

\[Exp(I) = \{exp(G_1),\dots,exp(G_n)\} + \mathbb{N}^n\]

Que forman una base de Gröbner

******* Punto 2
Por el algoritmo de la [[*Teorema de la división][división]], tenemos que todo polinomio del ideal
se divide entre ellos dando un resto tal que $exp(R) \in \overline{\Delta} \cap Exp(I) = \varnothing$.
Por tanto, $R=0$.

******* Punto 3
Todo ideal está generado por su base de Gröbner, que es finita.

***** Resto en bases de Gröbner
Sea $I$ ideal con bases de Gröbner $\mathbb{G},\mathbb{G}'$. Para $F \in K[X_1,\dots,X_n]$:

\[R(F;\mathbb{G}) = R(F;\mathbb{G}')\]

****** Demostración
Tenemos que, al coincidir los exponentes:

\[Exp(I) = \bigcup_{i=1}^t \Delta^i\]

Por lo tanto, $\overline{\Delta} = \overline{\Delta}'$, y tenemos ${\cal N}(R-R') \subseteq {\cal N}(R) \cup {\cal N}(R') \subseteq \overline{\Delta}$.
Pero como $R-R' \in I$, y tenemos $exp(R-R') \in Exp(I)$, debe ser nulo.

***** Caracterización de bases de Gröbner
Sea $I$ ideal no nulo, equivalen:

  1. $\mathbb{G}$ es base de Gröbner de $I$.
  2. $R(F,\mathbb{G}) = 0$, para todo $F \in I$.

****** Demostración
******* Primer punto al segundo
Tenemos $exp(R) \in Exp(I) \cap \overline{\Delta}$, luego debe ser $exp(R) = 0$.

******* Segundo punto al primero
Por la división, cualquier $F \in I$ es de la forma:

\[ F = \sum_{i=0}^n Q_iG_i\]

Donde $exp(Q_iG_i) \in \Delta^i$, y como forman una partición disjunta, se tiene 
que el $exp(F) = max\{exp(Q_iG_i)\} \notin \overline{\Delta}$. Por tanto $Exp(I) \cap \overline{\Delta} = \varnothing$.

***** Semizigia
Sean $F,G \in K[X_1,\dots,X_n]$ no nulos. Definimos el S-polinomial o *semizigia*
como el siguiente polinomio:

\[{\cal S}(F,G) 
= \frac{1}{cl(F)}X^{\gamma-\alpha}F - \frac{1}{cl(G)}X^{\gamma-\beta}G\]

donde $\alpha = exp(F)$, $\beta = exp(G)$, y $\gamma_i = \max\{\alpha_i,\beta_i\}$, para $\gamma = (\gamma_1,\dots,\gamma_n)$.

***** Teorema de Buchberger
Sea $I$ ideal no nulo de $K[X_1,\dots,X_n]$ y $\mathbb{G} = \{G_1,\dots,G_n\}$ un sistema de
generadores. Equivalen:

  1. $\mathbb{G}$ es base de Gröbner.
  2. Para cualquier ordenación de $\mathbb{G}$, se tiene $R({\cal S}(G_i,G_j); \mathbb{G}) = 0$
     para cualesquiera $i \neq j$.
  3. Para alguna ordenación de $\mathbb{G}$, se tiene $R(S(G_i,G_j); \mathbb{G}) = 0$.

****** Demostración
******* Primera implicación
Trivialmente por la [[*Caracterización de bases de Gröbner][caracterización]] una vez que vemos que las 
semizigias son combinaciones lineales.

******* Tercera implicación
No es trivial. Puede consultarse [[http://people.math.aau.dk/~diego/Libro.pdf][aquí]].

***** Algoritmo de Buchberger
Sea $I$ ideal no nulo y $\mathbb{G} = (G_1,\dots,G_n)$ sistema de generadores. Es posible 
construir una base de Gröbner con los siguientes pasos:

  1. $\mathbb{G}_0 = \{G_1,\dots,G_n\}$
  2. $\mathbb{G}_{n+1} = \mathbb{G}_n \cup \{R(S(F,G);\mathbb{G}_n) \neq 0 \mid F,G \in \mathbb{G}_n, F \neq G\}$

Entonces cuando $\mathbb{G}_i = \mathbb{G}_{i+1}$, podemos asegurar que $\mathbb{G}_i$ es base de Gröbner del
ideal $I$.

****** Demostración
Cuando el algoritmo termina, la base que tenemos es claramente de 
Gröbner debido a la caracterización que nos da [[*Teorema de Buchberger][Buchberger]].

Hay que demostrar que el algoritmo termina en algún punto. Esto se
deduce de el hecho de que, dado un monoideal, el conjunto de monoideales
que lo contienen es finito. Pero si un elemento es resto de una división
por $\mathbb{G}$ no nulo, no puede estar en el monoideal generado por los exponentes.
Así, al añadirlo tendremos un monoideal generado mayor, y esto sólo puede
hacerse un número finito de pasos.

***** Retirando un polinomio de una base de Gröbner
Sea $\mathbb{G}$ una base de Gröbner de un ideal no nulo $I \subseteq K[X_1,\dots,X_n]$ y sea
$F \in \mathbb{G}$ tal que $exp(F) \in \{exp(G) \mid G \in \mathbb{G}, F \neq G \}+\mathbb{N}^n$. Entonces, $\mathbb{G}\setminus\{F\}$
es también una base de Gröbner de $I$.

****** Demostración
# Esto no parece necesario. Es trivial desde la definición.
Si $R(F;\mathbb{G}\setminus \{F\})$ está en $\overline\Delta$, que es el mismo que generarían
con $F$. Pero como está en el ideal, debería ser $0$.

Por lo tanto $F$ está generado por $\mathbb{G}$, que es generadora y por tanto,
base de Gröbner.

***** Base de Gröbner minimal
Una base de Gröbner de un ideal no nulo $I \subseteq K[X_1,\dots,X_n]$ se dice minimal
si:

  1. $cl(F) = 1,\quad\forall F\in\mathbb{G}$.
  2. $exp(F) \notin \{exp(G) \mid G \in \mathbb{G}, G \neq F\} + \mathbb{N}^n$.

Es claro que todo ideal tiene una base de Gröbner minimal, simplemente
[[*Retirando un polinomio de una base de Gröbner][retirando]] polinomios.

***** Caracterización de bases minimales
Sea $\mathbb{G}$ un sistema de generadores de $I$. Equivalen:

  1. $\mathbb{G}$ es una base de Gröbner minimal de $I$.
  2. $\{exp(G_1),\dots,exp(G_t)\}$ es sistema minimal de generadores de $Exp(I)$
     y se tiene $cl(G_i) = 1$.

Los términos líderes de los polinomios de una base de
Gröbner minimal están determinados de forma única y, además, dos bases
de Gröbner minimales tienen el mismo número de elementos.

****** Demostración
******* Primera implicación
Si no fuera sistema minimal, un subconjunto suyo lo sería y generaría
también $Exp(I)$. Pero entonces, podemos quitar elementos de la base
de Gröbner y seguirían generando lo mismo; contraviniendo minimalidad.

******* Segunda implicación
Si no fuera minimal, algún $exp(F)$ sería generado por los demás,
y por tanto los exponentes no formarían un sistema mnimal.

Nótese que hay que considerar los coeficientes líderes para que sean
$1$.

******* Unicidad
Como el sistema minimal de generadores de $Exp(I)$ es único, los
términos líderes de los polinomios de una base de Gröbner minimal
deben ser únicos.

******* Cardinalidad invariante
Dos bases minimales darían lugar a dos sistemas minimales de 
generadores, que deben ser iguales y tener la misma cardinalidad.

***** Base de Gröbner reducida
Una base de Gröbner $\mathbb{G}$ de $I$ es reducida si para cualquier $\forall F \in \mathbb{G}$:

  1. $cl(F) = 1$.
  2. ${\cal N}(F) \cap \{exp(G) \mid G \in \mathbb{G}, G \neq F\} + \mathbb{N}^n = \varnothing$.

***** Una base de Gröbner reducida es minimal
Toda base de Gröbner reducida es minimal.

****** Demostración
Trivialmente, si todo el diagrama de Newton está fuera de lo que
generan los demás; el exponente está fuera de lo que generan los demás.

***** Existencia y unicidad de la base reducida
Todo ideal no nulo $I$ tiene una única base de Gröbner reducida.

****** Demostración
******* Existencia
Dada una base de Gröbner minimal, $F \in \mathbb{G}$, veremos que podemos tomar
otra base minimal en la que ${\cal N}(F)$ no esté en los exponentes que 
generan los demás. Si dividimos $F$ entre los demás polinomios
de la base de Gröbner:

\[
F = \sum Q_iG_i + F'
\]

Como $exp(F) = \max(\max\{Q_iG_i\},exp(F'))$ y sabemos que por ser minimal
tiene que ser distinto del exponente de los $Q_iG_i$; luego
$exp(F) = exp(F')$.

Entonces sustituyendo $F$ por $F'$ tenemos otra base de Gröbner minimal
en la que $F$ está reducido. Podemos repetir esto para todos los 
elementos obteniendo una base reducida.

******* Unicidad
Sean bases de Gröbner reducidas $\mathbb{G}$ y $\mathbb{G}'$. Sea $F \in \mathbb{G}$ y sea $F' \in \mathbb{G}'$ el
que tiene el mismo exponente. Tenemos que si intentamos dividir
por $\mathbb{G}$, por ser ambas reducidas:

\[{\cal N}(F-F') \subseteq \overline{\Delta}\]

Entonces $R(F-F';\mathbb{G}) = F-F'$, pero como $F - F' \in I$, debe 
ser $F - F' = 0$.

**** Teoría de eliminación
***** Ideal de eliminación
Sea $I$ ideal no nulo. Definimos el j-ésimo ideal de eliminación como:

\[ I_j = I \cap K[X_{j+1},\dots,X_n]\]

***** Base del ideal de eliminación
Sea $I$ ideal no nulo y $\mathbb{G}$ base de Gröbner del orden lexicográfico
dado por $X_1 > X_2 > \dots > X_n$. Entonces:

\[\mathbb{G}_j = \mathbb{G} \cap I_j\]

es base de Gröbner de $I_j$.

****** Demostración
Sea $F \in I_j$, veremos que $exp(F) = exp(G) + \gamma$ para algún $G \in \mathbb{G}_j$.
Tenemos ya $exp(F) = exp(G) + \gamma$ para $G \in \mathbb{G}$. Como el exponente de $F$ es
nulo en las $j$ primeras variables, entonces $exp(G)$ también lo hace.
Como estamos usando orden lexicográfico ${\cal N}(G)$ entero se anula en las
$j$ primeras variables. Luego $G \in \mathbb{G}$.

***** Extensión de un ideal
Sea $I$ ideal de $K[X_1,\dots,X_n]$. Un sistema de generadores suyo es
también sistema de generadores de:

\[
I^e = \left\{
\sum_{i=1}^k Q_iF_i \;\middle|\; Q_i \in K[T,X_1,\dots,X_n], F_i \in I
\right\}
\]

en el espacio $K[T,X_1,\dots,X_n]$.

****** Demostración
Trivialmente por ser generador de $I$.

***** Cálculo de la intersección
Sean $I,J$ dos ideales no nulos de $K[X_1,\dots,X_n]$. Sea:

\[ H = TI^e + (1-T)J^e \subseteq K[T,X_1,\dots,X_n]\]

Entonces $I\cap J = H \cap K[X_1,\dots,X_n]$, primer ideal de eliminación de $H$.
Esto nos permite calcular la intersección usando bases de Gröbner.

****** TODO Demostración
Si está en $I\cap J$ tenemos $TF + (1-T)F = F \in H$. Si está en 
$H \cap K[X_1,\dots,X_n]$, entonces es de la forma:

\[TF+(1-T)G = G + (F-G)T\]

Y por tanto debe tenerse $F = G \in I \cap J$.

***** Cociente de ideales
Dados $I,J$ ideales no nulos, definimos el ideal cociente como:

\[(I : J) 
= 
\{F \in K[X_1,\dots,X_n] \mid FJ \subset I\}
=
\bigcap_{i=1}^n (I : G_i)\]

Siendo $J = (G_1,\dots,G_n)$.

****** Demostración
Trivialmente, si incluye al ideal $J$ incluye a todos sus generadores.
Si está en la intersección incluye a todos los generadores por tanto
a todo el ideal.

***** Caracterización del cociente
Para $G \in K[X_1,\dots,X_n]$ se verifica que $G(I:G) = I \cap (G)$. Luego:

\[(I:G) = \frac{1}{G}(I \cap (G))\]

***** Máximo común divisor y mínimo común múltiplo
Sean $F,G \in K[X_1,\dots,X_n]$ con $D = \operatorname{mcd}(F,G)$ y $M = \text{mcm}(F,G)$. Entonces:

  1. $(F) \cap (G) = (M)$
  2. $D = \frac{FG}{M}$

Nótese que la intersección puede calcularse como el primer ideal de
eliminación de:

\[
H = T(F)^e + (1-T)(G)^e = (TF,(1-T)G)
\]

*** 3. Variedades afines
**** Funciones polinómicas
***** Espacio afín de un álgebra
Llamamos $\mathbb{A}^n(K)$ al espacio afín sobre $K^n$ con la función afín
$\varphi : K^n \times K^n \longrightarrow K^n$ dada por $\varphi(u,v) = v-u$.

***** Funciones polinómicas
A partir de cada polinomio $F \in K[X_1,\dots,X_n]$, tenemos definida una función
polinómica $F^\ast : \mathbb{A}^n(K) \longrightarrow K$.

****** Álgebra de funciones polinómicas
Al conjunto de funciones polinómicas lo denotamos por $P(\mathbb{A}^n(K))$.
Forma una K-álgebra con las operaciones usuales:

\[\begin{aligned}
(F^\ast+G^\ast)(a_1,\dots,a_n) 
&= 
F^\ast(a_1,\dots,a_n)+G^\ast(a_1,\dots,a_n)
\\
(F^\ast G^\ast)(a_1,\dots,a_n) 
&= 
F^\ast(a_1,\dots,a_n)G^\ast(a_1,\dots,a_n)
\\
(\alpha F^\ast)(a_1,\dots,a_n) 
&= 
\alpha F^\ast(a_1,\dots,a_n)
\end{aligned}\]

***** Epimorfismo de los polinomios a las funciones polinómicas
Por definición se tiene un epimorfismo $\Delta : K[X_1,\dots,X_n] \longrightarrow P(\mathbb{A}^n(K))$ 
dado por:

\[\Delta(F) = F^\ast\]

****** No es inyectivo en general
La función dada por un polinomio no nulo puede ser nula. Por ejemplo:

\[F = X(X+1)\]
\[G = 0\]

Dan lugar a la misma función en $\mathbb{F}_2$, pero son polinomios distintos.

***** Isomorfismo de los polinomios en cuerpos infinitos
Sea $K$ cuerpo infinito. Sus polinomios verifican:

  1. $F^\ast = 0 \iff F = 0$.
  2. $F^\ast=G^\ast \iff F = G$.

****** Demostración
Un polinomio que de la función constante $0$ en un cuerpo infinito 
debería tener infinitas raíces. Eso sólo puede darlo el polinomio
constantemente $0$.

**** Variedades afines
***** Variedad de un polinomio
Dado $F \in K[X_1,\dots,X_n]$, denotamos por $\mathbb{V}(F)$ al conjunto de sus ceros:

\[\mathbb{V}(F) = \Big\{(a_1,\dots,a_n) \in \mathbb{A}^n(K) \;\Big|\; F(a)=0 \Big\}\]

Dado un ideal ${\cal F}$, denotamos por $\mathbb{V}({\cal F})$ al conjunto de sus ceros:

\[\mathbb{V}({\cal F})
=
\Big\{(a_1,\dots,a_n) \in \mathbb{A}^n(K) \;\Big|\; F(a)=0\; \forall F \in {\cal F} \Big\}\]

***** Variedad algebraica afín
Un conjunto es una *variedad algebraica afín* cuando existe
${\cal F} \subseteq K[X_1,\dots,X_n]$ tal que es de la forma $\mathbb{V}({\cal F})$.

***** Variedad de un ideal
Sea ${\cal F} \subseteq K[X_1,\dots,X_n]$ y sea ${\cal I} = ({\cal F})$ el ideal generado. Se tiene:

  1. $\mathbb{V}({\cal F}) = \mathbb{V}({\cal I})$
  2. $\exists F_1,\dots,F_t : \mathbb{V}({\cal F}) = \mathbb{V}(F_1,\dots,F_t)$

****** Demostración
******* Punto 1
Si los generadores se anulan en un punto, sus combinaciones lineales
también.

******* Punto 2
Todo ideal en el anillo de polinomios es finitamente [[*Propiedades de bases de Gröbner][generado]]
gracias a las bases de Gröbner.

***** Propiedades de las variedades
Las variedades dadas por ideales cumplen:

  1. \[\bigcap_{\lambda \in \Lambda} \mathbb{V}(J_\lambda)
     = \mathbb{V}\left(
     \sum_{\lambda \in \Lambda} J_\lambda
     \right)\]

  2. $\mathbb{V}(J_1) \cup \mathbb{V}(J_2) = \mathbb{V}(J_1J_2) = \mathbb{V}(J_1 \cap J_2)$

  3. $\mathbb{V}(0) = \mathbb{A}^n(K)$

  4. $\mathbb{V}(K[X_1,\dots,X_n]) = \varnothing$

****** Demostración
******* Punto 1
Si un punto se anula para todos los polinomios de cada $J_\lambda$, en
particular está en cada $\mathbb{V}(J_\lambda)$. Si está en cada $\mathbb{V}(J_\lambda)$, se anula
para todos sus polinomios y por tanto para sus combinaciones
lineales.

******* Punto 2
Si $x \notin \mathbb{V}(J_1) \cup \mathbb{V}(J_2)$, entonces existirían polinomios en cada ideal
para los que no sería cero, y no sería cero de su producto, luego
$x \notin \mathbb{V}(J_1J_2)$.

El resto de los contenidos son triviales, viendo:

\[\mathbb{V}(J_1) \cup \mathbb{V}(J_2) \subseteq
\mathbb{V}(J_1\cap J_2) \subseteq
\mathbb{V}(J_1J_2)\]

******* Punto 3
Todos los puntos son raíces del constante $0$.

******* Punto 4
Ningún punto es raíz de todos los polinomios, porque existen los
polinomios constantes no nulos en cualquier cuerpo.

***** Topología de Zariski
Las variedades son los cerrados de una topología sobre $\mathbb{A}^n(K)$.

\[\{
V \subseteq \mathbb{A}^n(K) 
\mid
V \text{ es variedad algebraica afín}
\}\]

****** Demostración
Desde las propiedades de una [[*Variedad de un ideal][variedad]] tenemos que la 
intersección arbitraria y la unión finita de variedades son variedad.
Además, lo son el vacío y el total.

***** Ejemplos
****** Puntos discretos
Dado un conjunto discreto de puntos:

\[\{(a_1,\dots,a_n)\} = \mathbb{V}(X_1-a_1,\dots,X_n-a_n)\]

****** Hipersuperficies
Toda variedad generada por un polinomio no constante:

\[
\mathbb{V}(F) = \Big\{ 
\alpha \in \mathbb{A}^n(K) \mid F(\alpha) = 0
\Big\}
\]

Toda variedad afín es una intersección finita de hipersuperficies.

****** Hiperplano
La variedad de un polinomio de grado total 1 es un hiperplano.
Para $F = a_0 + a_1X_1 +a_2X_2 + \dots + a_nX_n$, tenemos:

\[
\mathbb{V}(F) = \Big\{
\alpha \in \mathbb{A}^n(K) 
\mid 
a_0 + a_1\alpha_1 + a_2\alpha_2 + \dots + a_n\alpha_n = 0
\Big\}
\]

La intersección finita de hiperplanos es una variedad afín lineal.

**** Teorema de los ceros de Hilbert
***** Representaciones paramétricas
Una *representación paramétrica racional* de $\mathbb{V}(F_1,\dots,F_t)$ es un conjunto
de funciones $G_i,H_i \in K[X_1,\dots,X_n]$ cumpliendo:

\[\left\{ 
\frac{G_1}{H_1}(t_1,\dots,t_n),
\frac{G_2}{H_2}(t_1,\dots,t_n),
\dots,
\frac{G_n}{H_n}(t_1,\dots,t_n)
\;\middle|\;
t_1,\dots,t_n \in \mathbb{K}
\right\}
\subseteq
V\]

Cuando $H_i = 1$, la llamamos *representación polinomial*.

****** Ejemplos
******* Representación no racional del círculo
El círculo es una variedad de la que puede darse una representación
no paramétrica.

\[V = \{(sen(t), cos(t)) \midt \in \mathbb{R}\}\]

Sabemos que es variedad porque puede expresarse como:

\[ V = \mathbb{V}(X^2+Y^2-1) \]

Y podemos darle además una representación paramétrica racional
no trivial:

***** Ideal de un conjunto
Sea $S \subseteq \mathbb{A}^n(K)$. Definimos el ideal asociado a $S$ como:

\[
\mathbb{I}(S)
=
\Big\{F \in K[X_1,\dots,X_n] \mid \forall a \in S: F(a) = 0\Big\}
\]

****** Es ideal
Trivialmente sabiendo que se conservan los ceros por suma y producto
externo.

***** Propiedades de variedades e ideales
Los ideales y sus variedades cumplen:

  1. $S_1 \subseteq S_2 \implies \mathbb{I}(S_1) \supseteq \mathbb{I}(S_2)$.
  2. $\mathbb{I}(\varnothing) = K[X_1,\dots,X_n]$.
  3. $S \subseteq \mathbb{V}\mathbb{I}(S)$ y $J \subseteq \mathbb{I}\mathbb{V}(J)$.
  4. $\mathbb{I}(S) = \mathbb{I}\mathbb{V}\mathbb{I}(S)$ y $\mathbb{V}(J) = \mathbb{V}\mathbb{I}\mathbb{V}(J)$.
  5. $\mathbb{I}(S)$ es ideal radical.
  6. Cuando $V \subseteq \mathbb{A}^n(K)$ es variedad afín, $V = \mathbb{V}\mathbb{I}(V)$.
  7. $V_1 \subseteq V_2 \iff \mathbb{I}(V_1) \supseteq \mathbb{I}(V_2)$.
  8. $\mathbb{I}(S_1 \cup S_2) = \mathbb{I}(S_1) \cap \mathbb{I}(S_2)$.
  9. $V_1 \cup V_2 = \mathbb{V}(\mathbb{I}(V_1)\mathbb{I}(V_2)) = \mathbb{V}(\mathbb{I}(V_1) \cap \mathbb{I}(V_2))$.
  10. \[\bigcap_{\lambda \in \Lambda} V_\lambda = \mathbb{V}\left(\sum_{\lambda\in\Lambda} \mathbb{I}(V_\lambda)\right)\].

****** Demostración
******* Punto 1, 2 y 3
Triviales desde la definición. Nótese que las inclusiones vienen
dadas directamente.

******* Punto 4
Uniendo las dos inclusiones anteriores.

******* Punto 5
Si $f^n \in \mathbb{I}(S)$ entonces para cualquier punto en $S$ se cumple $f^n(s) = 0$, 
lo que lleva a $f(s) = 0$.

******* Punto 6
Al igual que el punto 4 uniendo las dos inclusiones anteriores.

******* Punto 7
Usando la igualdad y por definición se tiene.

******* Punto 8
Trivial por definición.

******* Punto 9
La unión de variedades es variedad y se tiene por la igualdad y por 
el punto anterior.

******* Punto 10
Por propiedades de las variedades y la igualdad.

***** No todo ideal radical es de esa forma
La función $\mathbb{{I}}$ considerada como:

\[ \mathbb{I} : \left\{ V \in \mathbb{A}^n(K) \mid V \text{ es v.a.}\right\}
\longrightarrow
\left\{ J \subseteq K[X_1,\dots,X_n] \mid J = \sqrt{J}\right\}\]

Es inyectiva, se tiene $\mathbb{V}\mathbb{I} = 1$ y en general no se tiene $\mathbb{I}\mathbb{V} = 1$.

***** Teorema de los ceros de Hilbert
Cuando $K$ es algebraicamente cerrado, para cualquier ideal
$J \subseteq K[X_1,\dots,X_n]$, se verifica que:

\[\mathbb{I}\mathbb{V}(J) = \sqrt{J}\]

Y por tanto hay una biyección entre ideales radicales y variedades.

\[ \{ V \in \mathbb{A}^n(K) \mid V \text{ es v.a.}\}
\cong
\{ J \subseteq K[X_1,\dots,X_n] \mid J = \sqrt{J}\}\]

****** TODO Demostración                                                                                   :extra:
**** Anillos de coordenadas
***** Aplicaciones polinómicas
Un *morfismo entre variedades* de $\mathbb{A}^n$ y $\mathbb{A}^m$ es una aplicación $f : V \longrightarrow W$
tal que existen polinomios $F_1,\dots,F_n$ tales que:

\[f(a) = (F_1(a),F_2(a),\dots,F_n(a)) \quad \forall a \in V\]

Los llamamos también *aplicaciones polinómicas*.

****** Isomorfismos de variedades afines
Un isomorfismo entre variedades afines es un morfismo entre variedades
cuya inversa es un morfismo entre variedades.

***** Anillo de coordenadas
Sea $V \subset \mathbb{A}^n(K)$ una variedad algebraica afín. Definimos el anillo de 
coordenadas de $V$ como:

\[
K[V] = \frac{K[X_1,\dots,X_n]}{\mathbb{I}(V)}
\]

Estos anillos son K-álgebras.

****** Ejemplos de anillo de coordenadas
Sea $V = \mathbb{V}(X^3-Y^2) \subseteq \mathbb{A}^2(K)$. 

******* En característica 0
Si $car(K)=0$, entonces $\mathbb{I}(V) = (X^3-Y^2)$. Entonces:

\[K[V] = \frac{K[X_1,\dots,X_n]}{(X^3-Y^2)\]

******* En característica 2
En característica 2 tenemos $V = \{(0,0),(1,1)\}$, luego
$\mathbb{I}(V) = \mathbb{I}(\{(0,0\} \cup \{(1,1)\}) = (X,Y) \cap (X-1,Y-1)$, y en este caso:

\[\mathbb{F}_2[V]
= 
\frac{\mathbb{F}_2[X,Y]}{(X,Y) \cap (X-1,Y-1)}
= 
\frac{\mathbb{F}_2[X,Y]}{(X,Y)} +
\frac{\mathbb{F}_2[X,Y]}{(X-1,Y-1)}
=
\mathbb{F}_2 \times \mathbb{F}_2
\]

***** Funtor entre anillos de coordenadas y aplicaciones polinómicas
Sea $V \subseteq \mathbb{A}^n(K)$ y $W \subseteq \mathbb{A}^m(K)$ variedades algebraicas afines.

  1. Toda aplicación polinómica $f : V \longrightarrow W$ define un homomorfismo de
     K-álgebras $\tilde{f} : K[W] \longrightarrow K[V]$.
  2. Para cada homomorfismo de K-álgebras $h : K[W] \longrightarrow K[V]$ existe una
     única aplicación polinómica $f : V \longrightarrow W$ única tal que $\tilde{f} = h$.
  3. Si $V_1 \overset{f}\longrightarrow V_2 \overset{g}\longrightarrow V_3$ son aplicaciones polinómicas, $\widetilde{f} \circ \widetilde{g} = \widetilde{g \circ f}$.
  4. $f$ es isomorfismo ssi $\widetilde{f}$ es isomorfismo.

Es decir, hay un funtor contravariante entre ambas categorías.

****** Demostración
******* Punto 1
Sea $f(a) = (F_1(a),\dots,F_m(a))$. Por propiedad universal del anillo de
polinomios tenemos un $f'$ cumpliendo $f'(Y_j) = F_j$:

\[\begin{tikzcd}
K \rar[hook]\drar[hook]& K[Y_1,\dots,Y_n] \dar{\exists! f'} \\
& K[X_1,\dots,X_n]
\end{tikzcd}\]

Comprobamos que baja al cociente. Para $G \in \mathbb{I}(W)$, veamos que $f'(G) \in \mathbb{I}(V)$.
Sea $a \in V$, entonces $f(a) \in W$ y por tanto:

\[ f'(G)(a) = G(F_1(a),\dots,F_n(a)) = G(f(a)) = 0\]

Acabamos de ver que está bien definida una función:

\[\widetilde{f}(G + \mathbb{I}(W)) = G(F_1,\dots,F_n)+\mathbb{I}(V)\]

******* Punto 2
******** Existencia
Dada $h$, calculamos:

\[h(Y_i + \mathbb{I}(W)) = F_i + \mathbb{I}(V)\]

Y definimos $f : V \longrightarrow \mathbb{A}^m(K)$ como:

\[f(a) = (F_1(a),\dots,F_m(a))\]

********* Bien definida
Si $a \in V$, veremos que $f(a) \in W = \mathbb{VI}(W)$. Para $G \in \mathbb{I}(W)$:

\[h(0) = h(G+\mathbb{I}(W)) = G(F_1,\dots,F_n) + \mathbb{I}(V)\]

Luego $G(f(a)) = G(F_1,\dots,F_n)(a) + 0 = 0$, tenemos una función
polinómica $f : V \longrightarrow W$.

********* Cumple el requisito
Si $h(Y_j + \mathbb{I}(W) = F_j'+\mathbb{I}(V)$, entonces $F_j + \mathbb{I}(V) = F_j' + \mathbb{I}(V)$.
Y $F_j(a) = F_j'(a)$ para cualquier $a$. Es claro por tanto que $\widetilde{f} = h$.

******** Unicidad
Supongamos una $g : V \longrightarrow W$ tal que $\widetilde{g} = h$ con $g(a) = (G_1(a),\dots,G_m(a))$.
Entonces $\widetilde{g} : K[W] \longrightarrow K[V]$:

\[\tilde{g}(Y_j + \mathbb{I}(W)) = G_j + \mathbb{I}(V)\]
\[h(Y_j + \mathbb{I}(W)) = F_j + \mathbb{I}(V)\]

Por lo tanto $G_j - F_j \in \mathbb{I}(V)$ para cualquier $j$.

******* Punto 3
Por construcción.

******* Punto 4
Por el punto anterior, comprobando que el funtor respeta la identidad.

****** Ejemplo de polinómica biyectiva no isomorfismo
Sea $V = \mathbb{A}^1(\mathbb{R})$ y $W = \mathbb{V}(X^3-Y^2) \subseteq \mathbb{A}^2(\mathbb{R})$. Tenemos una aplicación
del tipo $f : \mathbb{A}^1(\mathbb{R}) \longrightarrow W$:

\[ f(a) = (a^2,a^3)
\]

Que es claro que es polinómica. Tenemos $f$ biyectiva. Pero vemos que no
es isomorfismo de variedades con $\widetilde f(X) = T^2$, $\widetilde f(X) = T^3$:

\[\widetilde{f} : \frac{K[X,Y]}{(X^3-Y^2)} \longrightarrow K[T]\]

Ya que $\tilde{f}$ no es sobreyectiva porque $T \notin \mathrm{img}(\tilde{f})$.

***** Núcleos e imágenes de morfismos de anillos de coordenadas
Sea $h : K[W] \longrightarrow K[V]$ un morfismo de K-álgebras dado por
$h(Y_j + \mathbb{I}(W)) = F_j+\mathbb{I}(V)$.

  1. Sea el ideal de $K[X_1,\dots,X_n,Y_1,\dots,Y_n]$ dado por
     $C = (Y_1-F_1,\dots,Y_m-F_m) + \mathbb{I}(V)$, entonces:

     \[\ker(h) = 
     ((C \cap K[Y_1,\dots,Y_m]) + \mathbb{I}(W)) / \mathbb{I}(W)\]

  2. Sea $\mathbb{G}$ una base de Gröbner reducida de $C$ con orden lexicográfico:

     \[F + \mathbb{I}(V) \in \mathrm{img}(h) 
   \iff
   R(F;\mathbb{G}) \in K[Y_1,\dots,Y_n]
   \]

     Además, en tal caso, $F+\mathbb{I}(V) = h(R(F;G) + \mathbb{I}(W))$.

***** Corolario: caracterización de inyectividad y sobreyectividad
Se cumple:

  1. $h$ inyectiva $\iff$ $C \cap K[Y_1,\dots,Y_m] \subseteq \mathbb{I}(W)$.
  2. $h$ sobreyectiva $\iff$ existen $M_i \in K[Y_1,\dots,Y_m]$ tal que $X_i-M_i \in \mathbb{G}$.

****** TODO Demostración
***** Clausura de Zariski
Dada una variedad $V$ y una representación paramétrica polinomial suya:

\[
U = \left\{
(F_1(t_1,\dots,t_k),F_2(t_1,\dots,t_k), \dots, F_n(t_1,\dots,t_k))
\mid
t_1,t_2,\dots,t_k \in K
\right\}
\subseteq V
\]

su clausura en la topología de Zariski es:

\[
\overline{U} =
\mathbb{V}(J \cap K[X_1,\dots,X_n])
\]

donde $J = (X_1-F_1,\dots,X_m-F_m) \subseteq K[X_1,\dots,X_n,T_1,\dots,T_n]$.

*** Temas de teoría
**** 1. Ideales maximales y primos. Teorema de Krull.
***** Ideales                                                                                               :extra:
Un ideal de $R$ es un subconjunto cerrado para la suma y
el producto por elementos $R$.

****** Anillo cociente
Para un $R$ anillo con $\alpha$ ideal, se define el *anillo cociente*:

\[
R/\alpha = \{x+\alpha\mid x \in R\}
\]

Obtenido por la relación $x \sim y \iff x-y\in\alpha$, con la suma y el
producto proyectados.
***** Retículo de ideales                                                                                   :extra:
Los ideales forman un retículo con la suma y la intersección.
Se tiene:

  - $I,J \subseteq I + J$
  - $I \cap J \subseteq I,J$

****** Son ideales
Claramente son cerrados para la suma y el producto externo por serlo
ambos.

***** Anillo cociente                                                                                       :extra:
Dado $R$ anillo con $\alpha$ ideal, tomamos la relación de equivalencia 
$x \sim y \iff x-y\in\alpha$, para obtener el ideal:

\[
R/\alpha = \{x+\alpha \mid x \in R\}
\]

***** Ideales primos y maximales
Un ideal propio $P$ es:

  - Primo, si $xy \in P \implies x \in P \vee y \in P$.
  - Maximal, si es maximal en el retículo de ideales.
 
****** Caracterización de ideales primos y maximales
Un ideal $P$ propio es:

  - Primo ssi $R/P$ es dominio de integridad.
  - Maximal ssi $R/P$ es un cuerpo.
 
Así, tenemos que primo implica maximal.

******* Demostración: primos
Véase que es equivalente a pedir que a $(x+P)(y+P) \neq 0$ equivalga
$x+P = 0$ ó $y+P = 0$.

******* Demostración: maximales
Ser maximal equivale a que no podamos añadir ningún elemento sin
llegar al ideal total. Esto es, si intentamos añadir $y$, tendremos
algún $z$ tal que $(y+P)(z+P) = 1+P$, que es equivalente a la
condición de cuerpo.

***** Teorema de Krull
Dados $\alpha \subset R$ ideal y $S$ multiplicativamente cerrado con $\alpha\cap S=\varnothing$,
existe un ideal $M$ tal que:

  - $\alpha \subset M$
  - $M \cap S = \varnothing$
  - $M$ es maximal respecto a esta condición.

Además, $M$ es un ideal primo.

****** Multiplicativamente cerrado
Un subconjunto $S$ es multiplicativamente cerrado si:

  - $1 \in S$
  - $a,b \in S \implies ab \in S$

****** Demostración
Dada una cadena de ideales que cumple $\alpha \subset I$ y $I \cap S = \varnothing$, su unión
también lo cumple y es cota de la cadena. Aplicando lema de Zorn,
sabemos que debe haber un ideal maximal $M$ respecto a las condiciones.

Supongamos $xy \in M$ pero $x,y \notin M$. Por maximalidad, $(M+(x)) \cap S$ y
$(M+(y)) \cap S$ son no vacíos y existen $xz,yt \in S$. Entonces tenemos 
que $xzyt \in M \cap S$, contradicción.

****** Corolario al teorema de Krull
Todo ideal tiene un ideal maximal que lo contiene. Además, todo elemento
no unidad tiene un ideal maximal que lo contiene.

******* Demostración
Tomando $S = \{1\}$.

***** Inclusión en ideales primos                                                                           :extra:
Sean ideales $\alpha_1,\dots,\alpha_n$ y $\pi$ un ideal primo. Si $\bigcap \alpha_i \subseteq \pi$, entonces,

\[
\exists \alpha_i \subseteq \pi
\]

**** 2. Nilradical y radical de Jacobson.
***** Nilradical
El *nilradical* es el ideal dado por los elementos nilpotentes:

\[
\operatorname{Nil}(R) = \{x \in R \mid \exists n : x^n = 0\}
\]

****** Es un ideal
Trivial usando el binomio de Newton.

****** Anillo reducido
Un anillo se dice reducido si $\operatorname{Nil}(R) = 0$. Los dominios de integridad son
trivialmente reducidos. Además, podemos reducir un anillo dividiéndolo
por su nilradical, $R/\operatorname{Nil}(R)$.

***** Caracterización del Nilradical
El nilradical es la intersección de ideales del espectro, los ideales
primos del anillo.

\[
\operatorname{Nil}(R) = \bigcap_{{\cal \pi}\text{ primo}} \pi
\]

****** Demostración
******* Nilpotente en la intersección
Si $x^n = 0 \in \pi$, por primalidad, $x \in \pi$ para cualquier ideal primo.

******* En la intersección es nilpotente
Si $x \notin \operatorname{Nil}(R)$, $S=\{1,x,x^2,\dots\}$ es multiplicativamente cerrado con
$S \cap \operatorname{Nil}(R) = \varnothing$, y por Krull, existe un primo con $\pi \cap S = \varnothing$.

***** Radical de un ideal                                                                                   :extra:
El *radical de un ideal* se define como:

\[
\sqrt{\alpha} = \{x \in R \mid x^n \in \alpha\}
\]

Cuando $\alpha = \sqrt{\alpha}$, lo llamamos *ideal radical*.

****** Caracterización
Tenemos que $\operatorname{Nil}(R/\alpha) = \sqrt{\alpha}/\alpha$ por construcción. De esa forma además 
llegamos a caracterizar al radical como:

\[
\sqrt{\alpha} = \bigcap_{\alpha \subset \pi \in \operatorname{Spec}(R)} \pi
\]

***** Radical de Jacobson
El *radical de Jacobson* es el dado por:

\[
{\cal J}(R) = \bigcap_{{\cal M} \text{ maximal}} {\cal M}
\]

***** Caracterización del radical de Jacobson
Tenemos que $x \in {\cal J}(R)$ ssi $1-xy \in U(R)$ para cualquier $y$.

****** Demostración
******* Primera implicación
Si $x \in {\cal J}(R)$, entonces $1-xy$ no puede estar en ningún ideal maximal,
porque estaría también el $1$. Pero todo elemento no unidad está en un
ideal maximal por teorema de Krull.

******* Segunda implicación
Si $x\notin M$ maximal, $(x)+M = R$. Luego $1-xy \in M$, y un maximal
no puede contener una unidad.

**** 3. Algoritmo de la división en K[X1,…,Xn].
***** Órdenes monomiales                                                                                    :extra:
Un orden monomial $\leq$ en $\mathbb{N}^n$ es un orden compatible, monótono y total.

  1. *Compatible:* si $x\leq y$, entonces $\gamma+x \leq \gamma+y$.
  2. *Monótono:* $0 \leq x$.
  3. *Total:* o bien $x \leq y$, o bien $y \leq x$.

El orden lexicográfico, el orden lexicográfico graduado y el orden 
lexicográfico graduado inverso son órdenes monomiales.

***** Componentes de la división                                                                            :extra:
Definimos los siguientes componentes para un polinomio
expresado como $p = \sum a_\alpha X^\alpha$:

  - ${\cal N}(p) = \{\alpha \in \mathbb{N}^n \mid a_\alpha \neq 0\}$, diagrama de Newton.
  - $exp(p) = \max\{\alpha \in \mathbb{N}^n \mid a_\alpha \neq 0\}$, exponente.
  - $tl(p) = a_{exp(p)}X^{exp(p)}$, término líder.

****** Propiedades del exponente
Dados $F,G \in K[X_1,\dots,X_n]$ no nulos, se cumple:

  1. $exp(FG) = exp(F)+exp(G)$
  2. $exp(F+G) \leq \max\{exp(F),exp(G)\}$
  3. Si $exp(F) < exp(G)$, entonces $exp(F+G) = exp(G)$.

******* Demostración
Se demuestran usando que los polinomios forman un K-espacio vectorial
teniendo de base a los monomios.

***** Partición de generadores
Dada una lista de elementos $a_1,\dots,a_k$, tenemos una partición que
definimos inductivamente como:

  1. Los elementos que genera el primer generador:

     \[\Delta^1 = a_1 + \mathbb{N}^n\]

  2. Los elementos que aporta cada nuevo generador:

     \[
     \Delta^i = (a_i+\mathbb{N}^n) \setminus \bigcup_{j<i} \Delta^j
     \]

  3. Todos los demás elementos:

     \[
     \overline{\Delta} = \mathbb{N}^n \setminus \bigcup_{j \leq k} \Delta^j
     \]

***** Teorema de la división
Dado un orden monomial y una lista de polinomios $\{G_1,\dots,G_t\}$; consideramos
la partición $\Delta_1,\dots,\Delta_t,\overline{\Delta}$ dada por los generadores $exp(G_i)$. Tenemos que,
para cada $F \in K[X_1,\dots,X_n]$, existen $Q_1,\dots,Q_t,R$ únicos tales que:

  1. $F = Q_1G_1+\dots+Q_tG_t+R$.
  2. $R=0$ ó $N(R) \subset \overline{\Delta}$.
  3. $exp(G_i)+N(Q_i) \subseteq \Delta^i$.

****** Demostración
Procedemos por inducción sobre $exp(F)$ con el orden monomial que
tenemos. Distinguimos siempre según si aparece en $\Delta_i$ o en $\overline{\Delta}$.
Nótese que en cada caso debemos comprobar que se cumplen trivialmente
las condiciones del teorema.

******* Caso base
******** Aparece en algún elemento de la partición
Si $exp(F) \in \Delta^i$, entonces forzosamente $exp(G_i)=0$. Entonces
tomamos $Q_i = F/G_i$ y $Q_j=0$ para $j \neq i$.

******** Aparece en el resto de la partición
Simplemente tomamos $R=F$.

******* Caso inductivo
Sabiendo ahora que podemos dividir todo $G$ con $exp(G) < exp(F)$.

******** Aparece en algún elemento de la partición
Si $exp(F) \in \Delta^i$ entonces $exp(F) = exp(G_i) + \gamma$. Tomando $H=X^\gamma G$,
aplicamos inducción sobre:

\[
F -\frac{cl(F)}{cl(H)}H = F' = \sum Q_i'G_i+R'
\]

Ahora tomamos $Q_i = Q_i'+\frac{cl(F)}{cl(H)}X^\gamma$ y $Q_j = Q_j'$, para llegar a:

\[
F = \sum Q_iG_i+R'
\]

******** Aparece en el resto de la partición
Aplicamos inducción sobre:

\[
F - tl(F) = \sum Q_i'G_i + R'
\]

Y tomamos entonces $R=R'+tl(F)$, que sigue cumpliendo las 
condiciones.

**** 4. Ideales monomiales.
***** Exponente de un ideal                                                                                 :extra:
El exponente de un ideal es el conjunto de exponentes de sus polinomios:

\[
Exp(I) = \{
exp(F) \mid 0\neq F \in I
\} \subseteq \mathbb{N}^n
\]

El exponente es un monoideal, es decir, $Exp(I) + \mathbb{N}^n = Exp(I)$.

****** Demostración
Nótese que tenemos $exp(X^\gamma F) = \gamma + exp(F)$.

***** Lema de Dickson y sistemas generadores                                                                :extra:
Para $S \subseteq \mathbb{N}^n$ no vacío, existe $G \subseteq S$ finito tal que $S \subseteq G + \mathbb{N}^n$.

****** Monoideal
Un subconjunto $E \subseteq \mathbb{N}^n$ es monoideal cuando $E = E+\mathbb{N}^n$.

****** Sistemas de generadores
Si $E$ es monoideal, existe un $G \subset E$ finito con $E = G + \mathbb{N}^n$. Llamamos
a $G$ sistema de generadores de $E$.

Esto es debido al lema de Dickson.

***** Ideales monomiales
Un *ideal monomial* está generado por monomios, es de la forma:

\[
I = (X^{\alpha}\mid \alpha \in A)
\]

para algún $A \subseteq \mathbb{N}$.

***** Monomios en un ideal monomial
Sea $I = (X^\alpha \mid \alpha \in A)$ monomial, equivalen:

  1. $F\in I$.
  2. Todo monomio de $F$ está en $I$.
  3. $F$ es combinación lineal de monomios de $I$.

Y además, si para cualquier polinomio de un ideal todos sus monomios 
están en el ideal, es monomial.

****** Demostración
******* Primera implicación
Si $F \in I$, será de la forma:

\[
F = \sum F_iX^\alpha
\]

Como los monomios son una K-base del espacio, todo monomio de la
suma será múltiplo de algún $X^\alpha$.

******* Segunda y tercera implicaciones
Triviales desde lo anterior.

******* Caracterización de ideales monomiales
Nótese que podemos tomar todos los polinomios del ideal y generarlo
como: $(X^\alpha \mid \alpha \in Exp(I))$.
***** Lema de Dickson para ideales monomiales
Todo ideal monomial tiene un sistema de generadores finito y 
formado por monomios.

****** Demostración
Como el exponente de un ideal es siempre monoideal, podemos aplicar
el lema de Dickson para darle un sistema de generadores $Exp(I)=G+\mathbb{N}^n$.
Dado un exponente $\alpha \in Exp(I)$, tenemos $X^\alpha\in I$, luego tomamos como
sistema de generadores:

\[
(X^\alpha \mid \alpha \in G)
\]

Dado cualquier $F\in I$, cada monomio suyo estará en $I$, luego será 
generado por este sistema.
**** 5. Bases de Gröbner. Aplicaciones.
***** Base de Gröbner
Una *base de Gröbner* de un ideal $I$ es un conjunto $\mathbb{G} = \{G_1,\dots,G_n\} \subseteq I$
cumpliendo $Exp(I) = \{exp(G_1),\dots,exp(G_n)\} + \mathbb{N}^n$.

***** Propiedades de bases de Gröbner
Las bases de Gröbner en $K[X_1,\dots,X_n]$ cumplen:

  1. Todo ideal no nulo tiene base de Gröbner.
  2. Toda base de Gröbner de un ideal genera al ideal.
  3. *Teorema de la base de Hilbert*: todo ideal es finitamente generado.

****** Demostración
******* Primer punto
Todo ideal tiene $Exp(I)$ monoideal, y por tanto tiene un sistema de
generadores. Tomamos polinomios que tengan como exponente estos
generadores y tenemos una base de Gröbner.

******* Segundo punto
Por algoritmo de la división, todo polinomio del ideal se divide
entre ellos dando un resto tal que $exp(R) \in \overline{\Delta} \cap Exp(I) = \varnothing$. Por
tanto, $R=0$.

******* Tercer punto
Todo ideal está generado por su base de Gröbner, que es finita.

***** Caracterización de las bases de Gröbner
Sea $I$ ideal no nulo, equivalen:

  1. $\mathbb{G}$ es base de Gröbner de $I$.
  2. $R(F,\mathbb{G}) = 0$, para todo $F\in I$.

****** Demostración
******* Primera implicación
Como $exp(R) \in Exp(I)\cap\overline{\Delta}$, tenemos $exp(R) = 0$.

******* Segunda implicación
Por teorema de la división, todo $F \in I$ es de la forma:

\[
F = \sum_{i=0}^n Q_iG_i
\]

Donde $exp(Q_iG_i) \in \Delta^i$, y como forman una partición disjunta, se
tiene que el $exp(F) = \max\{exp(Q_iG_i)\} \notin \overline{\Delta}$. Por tanto $Exp(I)\cap\overline{\Delta} = \varnothing$.

***** Cálculo de bases de Gröbner                                                                           :extra:
Las bases de Gröbner de un ideal pueden calcularse a partir de sus
generadores utilizando el Algoritmo de Buchberger, que añade a cada
paso los restos de las semizigias de los generadores a la base.

****** Teorema de Buchberger
Dado un sistema de generadores $\mathbb{G} = \{G_1,\dots,G_n\}$ de una base de Gröbner,
equivalen:

  1. $\mathbb{G}$ es base de Gröbner.
  2. Para alguna ordenación de $\mathbb{G}$, se tiene $R(S(G_i,G_j);\mathbb{G}) = 0$ para $i\neq j$.

****** Semizigia
Definimos la semizigia de dos polinomios como:

\[{\cal S}(F,G) 
= \frac{1}{cl(F)}X^{\gamma-\alpha}F - \frac{1}{cl(G)}X^{\gamma-\beta}G\]

***** Base de Gröbner minimal                                                                               :extra:
Una base de Gröbner de $I$ se dice minimal si, para cualquier $F \in \mathbb{G}$:

  1. $cl(F) = 1$
  2. $exp(F) \notin \{exp(G) \mid G\in\mathbb{G}, G\neq F\} + \mathbb{N}^n$

****** Retirar polinomios
Sea $\mathbb{G}$ base de Gröbner con un ideal no nulo y sea un $F \in \mathbb{G}$ que no
cumple la segunda condición de minimalidad. Tenemos que $\mathbb{G}\setminus\{F\}$ es
también base de Gröbner, ya sus exponentes siguen generando $Exp(I)$.
***** Base de Gröbner reducida                                                                              :extra:
Una base de Gröbner $\mathbb{G}$ de $I$ es reducida cuando para cualquier $\forall F\in\mathbb{G}$:

  1. $cl(F) = 1$
  2. ${\cal N}(F) \cap \{exp(G) \mid G \in \mathbb{G}, G \neq F\} + \mathbb{N}^n = \varnothing$

Toda base de Gröbner reducida es minimal y todo ideal no nulo $I$ tiene una
única base de Gröbner reducida.

****** Demostración: existencia
Dada una base de Gröbner, podemos llegar a una base de Gröbner minimal
retirando polinomios. Y dada una base minimal, podemos llegar a una base
reducida dividiendo cada polinomio por todos los demás y sustituyéndolo
por su resto, que tiene el mismo exponente por ser la anterior una base
minimal.

****** Demostración: unicidad
Si hubiera dos bases reducidas, tomaríamos los dos elementos con el mismo
exponente en cada una de ellas, y dividiríamos su resto $F-F' \in I$, que
debe dar resto $0$:

\[R(F-F';\mathbb{G}) = F-F'
\]

Ya que por ser una base reducida, ${\cal N}(F-F') \subseteq \overline{\Delta}$.

***** Aplicaciones: Problema de pertenencia
Sea $I$ ideal con un sistema de generadores. Podemos calcular si $F \in I$
calculando una base de Gröbner del ideal y usando:

\[F \in I \iff R(F,\mathbb{G}) = 0\]

***** Aplicaciones: Igualdad de ideales
Dados dos ideales $I,J$ con sus sistemas de generadores. Podemos comprobar
que serán iguales calculando sus bases de Gröbner reducidas, que por
unicidad, deben ser iguales.

***** Aplicaciones: Ideal de eliminación
Dado $I$ ideal no nulo. Definimos el j-ésimo ideal de eliminación como:

\[
I_j = I \cap K[X_{j+1},\dots,X_n]
\]

Si $\mathbb{G}$ era base de Gröbner con el orden lexicográfico de $I$, entonces:

\[
\mathbb{G}_j = \mathbb{G} \cap I_j
\]

es base de Gröbner de $I_j$.

****** Cálculo de la intersección
Sean $I,J$ ideales no nulos de $K[X_1,\dots,X_n]$ y sea:

\[
H = TI + (1-T)J \subseteq K[T,X_1,\dots,X_n]
\]

considerando los ideales extendidos. Entonces su intersección es el
primer ideal de eliminación de $H$:

\[
I \cap J = H \cap K[X_1,\dots,X_n]
\]

**** 6. Variedades algebraicas afines. Correspondencia ideal-variedad.
***** R-álgebras                                                                                            :extra:
Dado un anillo $R$, un R-módulo es un grupo abeliano $M$ junto a una
operación $\cdot : (R,M) \longrightarrow M$ verificando:

  - $r(x+y) = rx+ry$
  - $(r+s)x = rx + sx$
  - $r(sx) = (rs)x$
  - $1x = x$

Una *R-álgebra* $S$ es un anillo con estructura compatible de R-módulo,
tal que:

\[
\forall r \in R; x,y \in S: (rx)y = r(xy) = x(ry)
\]

***** Variedades algebraicas afines
Dado un ideal ${\cal F} \subseteq K[X_1,\dots,X_n]$, denotamos:

\[
\mathbb{V}({\cal F}) = \left\{ (a_1,\dots,a_n) \mid 
\forall F \in {\cal F}: F(a) = 0 \right\}
\]

Y llamamos *variedad algebraica afín* a los conjuntos de esta forma.

***** Topología de Zariski
Las variedades son los cerrados de una topología sobre $\mathbb{A}^n(K)$, ya
que cumplen:

  1. \[\bigcap_{\lambda\in\Lambda} \mathbb{V}(J_\lambda) =
     \mathbb{V}\left(\sum_{\lambda\in\Lambda} J_\lambda\right)}\]

  2. $\mathbb{V}(J_1) \cup \mathbb{V}(J_2) = \mathbb{V}(J_1J_2) = \mathbb{V}(J_1\cap J_2)$

  3. $\mathbb{V}(0) = \mathbb{A}^n(K)$

  4. $\mathbb{V}(K[X_1,\dots,X_n]) = \varnothing$

****** Demostración
******* Punto 1
Nótese que un punto se anula para un conjunto de ideales ssi
se anula para todas sus combinaciones lineales.

******* Punto 2
Si $x \notin \mathbb{V}(J_1) \cup \mathbb{V}(J_2)$, entonces existen polinomios en cada ideal
que no lo anulan, y su producto da $x \notin \mathbb{V}(J_1J_2)$ y $x \notin \mathbb{V}(J_1\cap J_2)$.

El resto de inclusiones son triviales.

******* Punto 3
El polinomio $0$ anula todos los puntos.

******* Punto 4
Ningún punto es raíz de todos los polinomios. Existen los 
polinomios constantes no nulos en particular.

***** Correspondencia ideal-variedad
Se define el *ideal de un conjunto* como:

\[
\mathbb{I}(S) = 
\left\{
F \in K[X_1,\dots,X_n]
\mid
\forall a \in S: F(a) = 0
\right\}
\]

Los ideales y variedades cumplen:

  1. $\mathbb{I}(\varnothing) = K[X_1,\dots,X_n]$.

  2. $\mathbb{I}(S_1\cup S_2) = \mathbb{I}(S_1) \cap \mathbb{I}(S_2)$.

  3. $S_1 \subseteq S_2 \implies \mathbb{I}(S_1) \supseteq \mathbb{I}(S_2)$.

  4. $\mathbb{I}(S)$ es ideal radical.

  5. $S \subseteq \mathbb{VI}(S)$ y $J \subseteq \mathbb{IV}(J)$.

  6. $\mathbb{I}(S) = \mathbb{IVI}(S)$ y $\mathbb{V}(J) = \mathbb{VIV}(J)$.

  7. Cuando $V \subseteq \mathbb{A}^n(K)$ es variedad afín, $V = \mathbb{VI}(V)$.

  8. $V_1 \subseteq V_2 \iff \mathbb{I}(V_1) \supseteq \mathbb{I}(V_2)$.

  9. $V_1\cup V_2 = \mathbb{V}(\mathbb{I}(V_1)\mathbb{I}(V_2)) = \mathbb{V}(\mathbb{I}(V_1) \cap \mathbb{I}(V_2))$.

  10. \[\bigcap_{\lambda\in\Lambda} V_\lambda = \mathbb{V}\left(\sum_{\lambda\in\Lambda} \mathbb{I}(V_\lambda)\right)\]

****** Demostración
******* Puntos 1, 2 y 3
Triviales por definición.

******* Punto 4
Notamos que $f^n(s)=0 \implies f(s) = 0$.

******* Puntos 5, 6 y 7
Desde la definición se tienen las desigualdades. Uniendo ambas nos
da la igualdad. El siguiente es un caso particular.

******* Punto 8
Trivial por definición y por la igualdad anterior.

******* Punto 9
La unión de variedades es variedad, aplicamos $\mathbb{VI}$ y las propiedades
anteriores.

******* Punto 10
La intersección es variedad y volvermos a aplicar $\mathbb{VI}$.

***** Teorema de los ceros de Hilbert
En general las funciones $\mathbb{I}, \mathbb{V}$ dan una correspondencia no biyectiva
entre ideales radicales y variedades, con $\mathbb{VI} = id$. Cuando $K$ es además
*algebraicamente cerrado*, se tiene $\mathbb{IV}(J) = \sqrt{J}$, y hay biyección:

\[
\left\{ V \in \mathbb{A}^n(K) \mid V \text{ es v.a.}\right\}
\cong
\left\{
J \subseteq K[X_1,\dots,X_n] \mid J = \sqrt{J}
\right\}
\]

**** 7. Anillo de coordenadas de una variedad. Aplicaciones polinómicas.
***** Espacio afín de un cuerpo                                                                             :extra:
Llamamos $\mathbb{A}^n(K)$ al espacio afín sobre $K^n$ con la función afín
$\varphi : K^n \times K^n \longrightarrow K^n$ dada por $\varphi(u,v) = v-u$.

***** Aplicaciones polinómicas
Una aplicación polinomial o morfismo entre variedades es una aplicación
$f : V \longrightarrow W$, variedades de $\mathbb{A}^n$ y $\mathbb{A}^m$, de la forma:

\[
f(a) = (F_1(a),F_2(a),\dots,F_m(a))
\]

donde los $F_1,\dots,F_m \subseteq K[X_1,\dots,X_n]$ son polinomios.

***** Anillo de coordenadas
El anillo de coordenadas de una variedad $V \subseteq \mathbb{A}^n(K)$ es la K-álgebra:

\[
K[V] = \frac{K[X_1,\dots,X_n]}{\mathbb{I}(V)}
\]

***** Relación entre aplicaciones polinómicas y anillos de coordenadas
Para $V \subseteq \mathbb{A}^n(K), W \subseteq \mathbb{A}^m(K)$ variedades,

  1. Toda aplicación polinómica $f : V \longrightarrow W$ induce un homomorfismo de
     K-álgebras $\widetilde f : K[W] \longrightarrow K[V]$ cumpliendo $\widetilde f(G+\mathbb{I}(W)) = G(f) + \mathbb{I}(V)$.

  2. Cada homomorfismo $h : K[W] \longrightarrow K[V]$ induce una única aplicación
     polinómica $h' : V \longrightarrow W$ tal que $\tilde{h}' = h$.

  3. Dadas aplicaciones polinómicas $V_1 \overset{f}\longrightarrow V_2 \overset{g}\longrightarrow V_3$, $\widetilde{f} \circ \widetilde{g} = \widetilde{g \circ f}$.

  4. $f$ es isomorfismo ssi $\widetilde f$ es isomorfismo.

Es decir, hay un funtor contravariante entre ambas categorías.

****** Demostración
******* Punto 1
Dado $f(a) = (F_1(a),\dots,F_m(a))$, por propiedad universal del anillo de
polinomios definimos $f'(Y_j) = F_j$. Para $G \in \mathbb{I}(W)$, si tomamos $a \in V$,
se tiene $f(a) \in W$, y por tanto:

\[
f'(G)(a) = G(F_1(a),\dots,F_n(a)) = G(f(a)) = 0
\]

Así, está bien definida la función:

\[
\widetilde f (G + \mathbb{I}(W)) = G(F_1,\dots,F_m) + \mathbb{I}(V)
\]

******* Punto 2
******** Existencia
Dada $h$, llamamos $h(Y_i+\mathbb{I}(W)) = F_i$, y definimos $f(a) = (F_1(a),\dots,F_m(a))$.
Está bien definida porque para $G \in \mathbb{I}(W)$,

\[
h(0) = h(G) = G(F_1,\dots,F_m) + \mathbb{I}(V)
\]

Luego $G(f(a)) = G(F_1,\dots,F_m)(a) + 0 = 0$, y $f(a) \in \mathbb{VI}(W) = W$. Es claro
además que $\widetilde f = h$, por estar definida como ella en una base de los
polinomios.

******** Unicidad
Supongamos $\widetilde g = h$ con $g(a) = (G_1(a),\dots,G_m(a))$, entonces:

\[\widetilde g(Y_j+\mathbb{I}(W)) = G_j + \mathbb{I}(V)\]
\[h(Y_j+\mathbb{I}(W)) = F_j + \mathbb{I}(V)\]

Por lo tanto, $G_j-F_j \in \mathbb{I}(V)$, para cualquier $j$.

******* Punto 3
Por construcción. Sean:

  - $f(a) = (F_1(a),\dots,F_m(a))$
  - $g(a) = (G_1(a),\dots,G_m(a))$
  - $g \circ f (a) = (G_1(F_1(a),\dots), \dots, G_m(F_1,\dots))$

Entonces comprobamos que: $\widetilde{g \circ f}(H) = \widetilde f  \circ \widetilde{g} (H)$.

******* Punto 4
Por el punto anterior y viendo simplemente que $\widetilde{id} = id$.

***** Caracterización de núcleos e imágenes                                                                 :extra:
Sea $h : K[W] \longrightarrow K[V]$ un morfismo de K-álgebras dado por $h(Y_j) = F_j$.

  1. Sea $C = (Y_1-F_1,\dots,Y_m-C_m) + \mathbb{I}(V)$ ideal de $K[X_1,\dots,X_n,Y_1,\dots,Y_m]$
     se tiene:

     \[
     \ker(h) = ((C\cap K[Y_1,\dots,Y_m]) + \mathbb{I}(W))/\mathbb{I}(W)
     \]
     
  2. Sea $\mathbb{G}$ Gröbner reducida de $C$ con orden lexicográfico:

     \[F + \mathbb{I}(V) \in \mathrm{img}(h) \iff
     R(F;\mathbb{G}) \in K[Y_1,\dots,Y_m]\]
     
     Además, en tal caso, $F + \mathbb{I}(V) = h(R(F;G)+\mathbb{I}(W))$.

****** Demostración
******* Primer punto
******** Primera implicación
Sea $G \in \ker(h)$, entonces $G(F_1,\dots,F_m) = h(G) = 0+\mathbb{I}(V) \in C$.
Dividimos ahora $H = G - G(F_1,\dots,F_m)$ entre $Y_1-Y_1,\dots,Y_m-C_m$
pero con orden lexicográfico $Y_1>\dots >Y_m>X_1> \dots>X_n$:

\[
H = \sum_{i=1}^m (Y_i-F_i) Q_i + R
\]

Como ${\cal N}(R) \subseteq \overline\Delta$, $R \in K[X_1,\dots,X_m]$, pero:

\[
H(F_1,\dots,F_m) = G(F_1,\dots,F_m) - G(F_1,\dots,F_m) = 0 = R
\]

Luego $H \in C$, y $G \in C \cap K[Y_1,\dots,Y_m]$.

******** Segunda implicación
Si escribimos $\mathbb{I}(V) = (H_1,\dots,H_s)$, tenemos entonces:

\[
G = \sum (Y_i-F_i)T_i + \sum H_jR_j
\]

luego:

\[
G(F_1,\dots,F_m) = \sum_{j=1}^s H_jR_j(X_1,\dots,X_n,F_1,\dots,F_m) 
\in \mathbb{I}(V)
\]

Y por tanto tenemos $G \in \ker(H)$:

\[
h(G) = G(F_1,\dots,F_m) + \mathbb{I}(V) = 0
\]

******* TODO Segundo punto
****** Inyectividad y sobreyectividad
Se tiene desde lo anterior que:

  1. $h$ inyectiva ssi $C \cap K[Y_1,\dots,Y_m] \subseteq \mathbb{I}(W)$.
  2. $h$ sobreyectiva ssi $\exists M_i \in K[Y_1,\dots,Y_m]$ tal que $X_i-M_i \in \mathbb{G}$.

*** Ejercicios
**** Relación 1
***** Ejercicio 1
#+begin_statement
Sea $R$ un anillo conmutativo. Demostrar:

 1. Los elementos $0$ y $1$ están determinados de forma única.
 2. Para cada elemento $x\in R$, el opuesto $-x$ y el inverso si existe $x^{-1}$, están
    determinados de forma única.
 3. El conjunto ${\cal U}(R)$ de las unidades de $R$ es un grupo abeliano.

$\quad$
#+end_statement
****** Punto 1
Supongamos que hubiera dos elementos neutros de cualquier tipo:

\[e = e \otimes e' = e'\]

****** Punto 2
Supongamos que hubiera dos inversos $x,y$ de cualquier tipo:

\[x = x \otimes (a \otimes y) = (x \otimes a) \otimes y = y\]

****** Punto 3
El anillo es conmutativo. Así que el grupo de las unidades con el producto será
abeliano.

***** TODO Ejercicio 2
#+begin_statement
Sea $R$ anillo conmutativo. Demostrar:

  1. $x0=0$ para todo $x\in R$.
  2. $R$ tiene más de un elemento ssi $0\neq 1$.
  3. $(-x)y = -(xy) = x(-y)$ para cualesquiera $x,y \in R$.
  4. $(nx)y = n(xy) = x(ny)$ para cualesquiera $x,y \in R$ y todo $n \in \mathbb{Z}$.
  5. $(nx)(my) = (nm)(xy)$ para cualesquiera $x,y \in R$ y $n,m \in \mathbb{Z}$.
  6. $\left(\sum_{i=1}^n x_i\right) \left(\sum^m_{j=1} y_j\right) = \left(\sum^{n,m}_{i=1,j=1} x_iy_j\right)$, para $x_i,y_j \in R$ y $n,m > 0$.
  7. $(x+y)^n = \sum_{i=0}^n {n \choose i} x y^{n-i}$, para cualesquiera $x,y \in R$ y $n,m \geq 0$.
  8. $(xy)^n = x^ny^n$ y $(x^n)^m = x^{nm}$, para cualesquiera $x,y\in R$ y $n,m \geq 0$.
$\quad$
#+end_statement
***** Ejercicio 3
#+begin_statement
Sea $X$ un conjunto, en ${\cal P}(X)$ se consideran las opearciones

\[A+B := (A\cup B) \setminus (A\cap B)\]
\[AB := A \cap B\]

para cualesquiera $A,B \in {\cal P}(X)$.

Prueba que ${\cal P}(X)$, con las operaciones anteriores y elemento uno igual a $X$, es un
anillo conmutativo. ¿Cuál es el elemento cero?. Observa que este anillo es un 
*anillo de Boole*, es decir $A^2=A$ para $A\in{\cal P}(X)$ y que por tanto $2A = 0$.
#+end_statement

Demostramos que ${\cal P}(X)$ con la suma forma un grupo abeliano. Cada conjunto es su
inverso, es conmutativo y tiene al conjunto vacío como neutro. La asociatividad
se comprueba viendo que pertenecer a $A+B+C$ es pertenecer a uno o a los tres.

Que es conmutativo se tiene por:

\[0 = (A+B)^2 - (A+B) = AB + BA\]
\[0 = A+A\]

***** Ejercicio 4
#+begin_statement
Dado un anillo $R = (R,+,\times,1)$, definir sobre $R$ dos operaciones $\oplus,\otimes$ de forma
que $(R,\oplus,\otimes,0)$ sea un anillo con elemento $1$ como cero.
#+end_statement
Nos sirve tomar:

\[a \oplus b = a+b-1\]
\[a \otimes b = a + b - ab\]

Debemos comprobar las propiedades.

***** TODO Ejercicio 7
***** Ejercicio 8
#+begin_statement
¿Se deduce la condición $f(1) = 1$ en la definición de homomorfismo de anillos de 
las dos condiciones $f(x+y) = f(x)+f(y)$ y $f(xy) = f(x)f(y)$?
#+end_statement
Una inclusión en la suma directa de dos anillos cumple lo pedido pero no cumple
que $i(1) = 1$.

\[i : R \longrightarrow R \oplus S,\quad i(r) = (r,0)\]

***** Ejercicio 9
#+begin_statement
Prueba que los elementos nilpotentes de un anillo forman un ideal.
#+end_statement
Sean $n^p = 0$ y $m^q = 0$, dos nilpotentes. Tenemos que $(n+m)^{p+q} = 0$, por binomio de 
Newton, y que $(rn)^p = 0$ por conmutatividad.
***** Ejercicio 10
#+begin_statement
Demuestra que todo dominio de integridad finito es un cuerpo.
#+end_statement
Dado $x \in R$, considero el endomorfismo $(\lambda a. xa)$. Por ser dominio de integridad, es
inyectivo, y siendo inyectivo y finito, es sobreyectivo. Luego $\exists a : xa = 1$.
***** Ejercicio 11
#+begin_statement
Demuestra que todo dominio de integridad con un número finito de ideales es un
cuerpo.
#+end_statement
Dado $x\in R$, considero una aplicación que lleva un ideal $I$ en $(x)I$. Tenemos que es
inyectiva por ser dominio de integridad. De hecho, sean $i \in I$ con $(x)I = (x)J$:

\[xi = rxj = xrj \Rightarrow i = rj\]

Luego $I\subset J$, simétricamente $I =J$. Por ser inyectiva y ser de número finito, es
biyectiva, luego $\exists I: (x)I = (1)$.
***** Ejercicio 12
Sea una cadena de ideales $\Pi \subset \beta\subset R$, con $x \in \beta$, $x \notin \Pi$.
Entonces $x(x^{n-1}-1) = 0 \in \Pi$, y debe tenerse $x^{n-1}-1 \in \Pi \subset \beta$.
Con eso, debe ser $\beta = R$.

***** Ejercicio 13
 Por definición de *radical*, tenemos que cuando es radical es intersección de 
 anillos primos.

 Sea $\alpha$ intersección de ideales primos, será en particular intersección de ideales
 primos más algunos que lo contienen.

***** Ejercicio 14
 Sea $x$ idempotente y sea $M$ el maximal de $R$. 

 - Sea $x \notin M$, entonces debe ser $x$ una
   unidad; por ser $R$ local. Siendo unidad $x^2 = x$ nos da $x=1$.

 - Sea $x \in M$. Sabemos ${\cal J}(R) = M$, luego $x$ está en el radical de Jacobson.
   Esto quiere decir que $1-xy \in U(R)$ para cualquier $y \in R$. En particular $1-x$
   está en las unidades del anillo. Como $x(1-x) = 0$, se tiene $x = 0$.

***** Ejercicio 15
 Aplicaremos Zorn, viendo que todo conjunto totalmente ordenado tiene cota inferior.

 Sea una cadena de ideales primos $\Pi_i$, entonces sea $ab \in \bigcap \Pi_i$, entonces, supongamos que
 $a$ no perteneciera a la intersección, entonces, por primalidad, si $b \notin \Pi_j$, tampoco
 pertenecería a ninguno por debajo de él; y $a$ debería pertenecer a todos ellos y
 por tanto a la intersección.

***** Ejercicio 16
****** Punto 1
 Tenemos que $0 = (2x)^2 - 2x = 4x - 2x= 2x$.

****** Punto 2
 Si $\pi$ es primo, entonces $R/\pi$ es dominio de integridad. Sea $m \in R/\pi$, tenemos que
 $m(m-1) = 0$, luego $m=0$ ó $m=1$. Así, sólo puede ser isomorfo a $\mathbb{Z}_2$
 y cuerpo. $\pi$ es maximal.

 Además, la primera parte se obtiene también por caso particular del ejercicio 12.

****** Punto 3
 Definimos la operación $a \oplus b = a+b+ab$ y comprobamos que $(a,b) = (a \oplus b)$, ya que
 $a (a\oplus b) =a$ y $b(a\oplus b) = b$. Por inducción, cada ideal generado por varios lo podemos
 generar por un elemento.

***** Ejercicio 17
Tenemos que los divisores de cero ya forman un ideal primo.
***** TODO Ejercicio 18
 Esto es equivalente a decir, ya que estamos en un anillo de ideales principales,
 que $X^3-Y^2$ es irreducible.

***** Ejercicio 19
 Vemos que $\alpha$ es ideal. Supongamos que fuera principal, debería estar generado
 por uno de mínimo grado. Si está generado por una constante, como contiene a $(2)$,
 debe estar generado por $(2)$, pero no es el caso porque no contendría a $x+2$.

***** TODO Ejercicio 21
***** Ejercicio 24
1. => 2. Sea $R$ con un ideal primo, y sea $a \in R$ no unidad. Tengo $a \in M$ para algún 
   maximal, que debe ser el único ideal primo que hay. Aplicando Krull a  
   $S = \{1,a,a^2\dots\}$ contra el ideal $(0)$ tendría un ideal no conteniendo 
   a $S$ pero primo, lo que es imposible, así que $S$ tiene intersección no vacía 
   con $(0)$.
2. => 3. Trivial.
3. => 1. Si $R/{\cal N}$ es un cuerpo, ${\cal N}$ es maximal. Si hubiera otro ideal primo, 
   lo meteríamosen su maximal ${\cal M}$ y; si hubiera $m \in {\cal M}-{\cal N}$, se 
   tendría $(m) \cup {\cal M} = R$. Entonces $km+n = 1$, luego $km$ es unidad y ${\cal M} = R$.

***** TODO Ejercicio 25
***** Ejercicio 26
 Nótese que si $x$ es nilpotente, también lo es $ux$ para $u$ unidad.
 Sea $x^n = 0$. Tenemos que:

 \[(1+x)(1-x+x^2-\dots+x^{n-1}) = 1 + (-x)^n = 1\]

 Luego es unidad. Dada suma de unidad y nilpotente, podemos escribirla como:

 \[(u+x) = u(1+u^{-1}x)\]

 Producto de unidades.

***** Ejercicio 27
****** Punto 1
 Por un lado, si todos los $a_i$ fueran nilpotentes se tendrían $a_iX^i$ nilpotentes.
 Y como la suma de unidad por nilpotente es unidad, la suma total es unidad.

 Sea $\sum b_iX^i$ el inverso de un polinomio $f(x) = \sum a_iX^i$. Es obvio que $a_0$ es unidad
 porque $a_0b_0 = 1$. Veamos por inducción que  $a^{r+1}_nb_{m-r} = 0$.

  - *Caso base:* $a_nb_m = 0$ por ser coeficiente del grado máximo.
  - *Caso de inducción*: El coeficiente de grado $n+m-1$ sería:
    $a_nb_{m-1} + a_{n-1}b_n = 0$, luego $a_n(a_nb_{m-1} + a_{n-1}b_m) = a_n^2b_{m-1} = 0$; y aplicaríamos
    inducción en los siguientes casos de forma similar.

 En particular, para $r=n$ tenemos que $a_n^{n+1}b_0 = 0$, luego $a_n$ es nilpotente.
 Ahora hacemos inducción sobre el grado. También es nilpotente $a_nX^n$, y 
 entonces tenemos que el polinomio siguiente también es unidad, pero de menor grado 
 que el original:

 \[f - a_nX^n = \sum^{n-1} a_iX^i \in {\cal U}(R[X])\]

****** Punto 2
 Tenemos que las $a_iX^i$ son nilpotentes; y la suma de nilpotentes es trivialmente
 nilpotente. 

 Hacia el otro lado, hacemos inducción sobre $grd(f)$:

  - Si $grd(f) = 0$, entonces $f = a_0$.
  - Sea $f = a_0 + \dots + a_nX^n$, tenemos que que si $f$ es nilpotente a la potencia $m$:
    \[ 0 = f^m = \sum_{j=0}^m {m \choose j}(a_0+\dots+a_n-1X^{n-1})^j(a_nX^n)^{m-j} = a_n^mX^{nm} + \dots\]
    Luego $a^m_n = 0$. El polinomio total es suma de esto y un polinomio de grado menor,
    que por inducción es nilpotente.

****** Punto 3. Teorema de MaCoy.
 Una implicación es trivial por definición.

 Sea $f$ divisor de cero. Tomamos un polinomio $g = \sum b_iX^i$ de grado mínimo con

 $fg = 0$. Entonces $a_nb_m = 0$, y por tanto $a_ng$ anularía también a $f$ pero tendría grado
 menor que $m$, luego debería ser $a_ng = 0$. Ahora procedemos por inducción, y se 
 volvería a tener $a_{n-r}g = 0$.

 Si $a_{n-r}g = 0$ para cualquier $r$, entonces:

 \[ 0 = \sum a_{n-r}b_i X^i\]

 Así que $a_{n-r}b_0 = 0$ y se concluye $fb_0 = 0$.

***** Ejercicio 30
#+begin_statement
Calcular el radical de cualquier ideal de $\mathbb{Z}$.
#+end_statement
Dado $(n\mathbb{Z})$ y escribiendo $n = p_1^{e_1}\dots p_n^{e_n}$, podemos ver que un número que perteneciera
a su radical debería ser tal que:

\[ p_1^{e_1}\dots p_n^{e_n} | (q_1^{f_1}\dots q_n^{f_n})^k\]

Para algún $k$, lo que equivale a que $e_i \leq kf_i$. Es decir, necesitamos sólo $f_i \neq 0$.
En conclusión, $\sqrt{n\mathbb{Z}} = (p_1p_2\dots p_n)\mathbb{Z}$, ideal del producto de sus factores primos.

***** Ejercicio 31
#+begin_statement
Demostrar los siguientes resultados para radicales de ideales de un anillo $R$:

  1. $\sqrt{\sqrt{\alpha}} = \sqrt{\alpha}$.
  2. $\sqrt{\alpha\beta} = \sqrt{\alpha \cap \beta} = \sqrt{\alpha} \cap \sqrt{\beta}$.
  3. $\sqrt{\alpha} = R \Leftrightarrow \alpha = R$.
  4. $\sqrt{\alpha+\beta} = \sqrt{\sqrt{\alpha}+\sqrt{\beta}}$.
  5. Si $\pi$ es un ideal primo, entonces $\sqrt{\pi} = \pi$.
  6. Si $\sqrt{\alpha} + \sqrt{\beta} = R$, entonces $\alpha+\beta = R$.

$\quad$
#+end_statement
****** Punto 1
Sea $y \in \sqrt{\sqrt{\alpha}}$, entonces $y^n \in \sqrt\alpha$, y entonces $(y^n)^m \in \alpha$, luego $y \in \sqrt{\alpha}$.
****** Punto 2
Sea $y \in \sqrt{\alpha \cap \beta}$, entonces $y^n \in \alpha \cap \beta$, y entonces $y^ny^n \in \alpha\beta$, luego 
$y \in \sqrt{\alpha\beta}$.
****** Punto 3
Sea $\sqrt{\alpha} = R$, entonces $1 = 1^n \in\alpha$.
****** Punto 4
Sea $x \in \sqrt{\sqrt\alpha+\sqrt\beta}$, entonces $x^n = u+v$, donde $u^p \in \alpha$, $v^q \in \beta$. Tengo entonces que
$(x^n)^{p+q} = (u+v)^{p+q} \in \alpha+\beta$, donde aplicamos Binomio de Newton.
****** Punto 5
Si fuera $x^n \in \pi$ para $n>1$, por primalidad, debería tenerse $x^{n-1} \in \pi$. Así que $x\in\pi$.
****** Punto 6
Si $1 = a+b$ con $a^n\in \alpha$, $b^m\in\beta$, entonces, por Binomio de Newton tenemos que 
$1^{n+m} = (a+b)^{n+m} \in \alpha+\beta$.

***** Ejercicio 32
#+begin_statement
Sean $\alpha,\beta$ ideales de un anillo $R$ tales que $\sqrt{\alpha},\sqrt{\beta}$ son primos entre sí. Demostrar que
entonces $\alpha,\beta$ también son primos entre sí.
#+end_statement
Trivial por el punto 6 del ejercicio 31.

***** Ejercicio 33
#+begin_statement
Sea $R$ un anillo y $\alpha,\beta$ ideales. Demostrar que si $(\alpha)^n\subseteq\beta$ para algún $n\geq 0$, entonces
$\sqrt\alpha \subseteq \sqrt\beta$.
#+end_statement
Tengo trivialmente que $\alpha \subseteq \sqrt\beta$, puedo tomar 
raíces para tener $\sqrt{\alpha} \subseteq \sqrt{\sqrt{\beta}}$.

***** Ejercicio 34
#+begin_statement
Sea $\alpha\subseteq R$ un ideal tal que $\sqrt\alpha$ es finitamente generado. Demostrar que existe
$n \in \mathbb{N}$ tal que $(\sqrt{\alpha})^n\subseteq\alpha$.
#+end_statement

Sea $(\sqrt{\alpha}) = (x_1,\dots,x_m)$ tales que $x_i^{e_i} \in \alpha$. Entonces se tiene por binomio de Newton:

\[(\sqrt\alpha)^{e_1+\dots+e_m} \subset \alpha\]

Ya que cada sumando tiene algún $x_i$ elevado a más que $e_i$.

***** Ejercicio 35
#+begin_statement
En el anillo de polinomios $\mathbb{F}_2[X,Y]$, con $\mathbb{F}_2$ cuerpo finito de dos elementos, sean
$\alpha_1 = (X,Y)$ y $\alpha_2 = (X-1,Y-1)$. Haciendo uso del ejercicio anterior, demuestra que el
ideal producto $\alpha = \alpha_1\alpha_2$ es un ideal radical.
#+end_statement
Primero vemos que $\alpha_1$ y $\alpha_2$ son radicales. $\alpha_1$ lo forman todos los polinomios con
término independiente $0$, y ningún polinomio con término independiente $1$ puede
elevarse hasta tener término $0$. $\alpha_2$ es la imagen de $\alpha_1$ por el homomorfismo de 
anillos que lleva la indeterminada $X$ en $X+1$, así que también lo es.

Sabemos que $\alpha_1$,$\alpha_2$ son primos entre sí. Luego $\alpha_1\alpha_2 = \alpha_1 \cap \alpha_2$. Ahora tenemos
que:

\[\sqrt{\alpha_1\alpha_2} = \sqrt\alpha_1 \cap \sqrt\alpha_2 = 
\alpha_1\cap\alpha_2 = \alpha_1\alpha_2\]

***** Ejercicio 36
Sea $x \in \sqrt{\alpha}$, entonces $x^n \in \alpha \subset \bigcap \pi_i$, pero $x^n \in \pi_i$ me da $x \in \pi_i$, luego $x \in \bigcap \pi_i$.

***** Ejercicio 37
***** Ejercicio 38
***** Ejercicio 39
***** Ejercicio 40
***** Ejercicio 41
****** Punto 1
 Veamos que la aplicación que va del producto de ideales a $R$ es un homomorfismo
 de grupos abelianos multiplicativo biyectivo.

 \[ f((x_1,\dots,x_n)) = x_1+\dots+x_n\]

 Por la definición de *conjunto independiente*, sabemos que dado $x\in R$ existen únicos
 $x_1 \in \alpha_1, x_2 \in \alpha_2,\dots, x_t \in \alpha_t$ tales que $x = x_1 + \dots + x_t$. Esto en el caso $2$ es trivial, y
 se puede ampliar por inducción.

****** Punto 2
 Por el apartado primero, sabemos que existen $e_1+e_2+\dots+e_t = 1$. Puedo tomar
 $\alpha_i$ como anillo sobre la suma y el producto, pero tomando $e_i$ como unidad.

 Sea $x_i \in \alpha_i$, tenemos que $x_i = x_i(e_1+e_2+\dots+e_t)$, así que por unicidad de la 
 descomposición, debe ser $x_i = e_ix_i$.

****** Punto 3
 Tenemos un conjunto de elementos que suman $1$, son idempotentes y ortogonales.

***** Ejercicio 43
****** Punto 1
 Tenemos $X \times \mathbb{Z}$ grupo abeliano con la suma por serlo $X$ y $\mathbb{Z}$. La asociatividad se 
 tiene por:

 \[(x_1,n_1)(x_2,n_2)(x_3,n_3) 
 = (x_1x_2x_3 + n_1x_2x_3+x_1n_2x_3+x_1x_2n_3+x_1n_2n_3+n_1x_2n_3+n_1n_2x_3, 
 n_1n_2n_3)\]

 Y la distributividad:

 \[\begin{aligned}
 (x,y)((a,b)+(c,d)) &= (x,y)(a+c,b+d) = (x(a+c)+y(a+c)+x(b+d)), y(b+d)) \\
 &= (xa+ya+xb,yb) + (xc+yc+xd,yd)
 \end{aligned}\]

****** Punto 2
 Vemos que es trivialmente cerrado para la suma y el producto. Cualquier
 elemento de $X\times \mathbb{Z}$ puede expresarse como $(x,0)+(0,n)$ así que tomamos el isomorfismo
 entre $X\times \mathbb{Z}/ X$ y $\mathbb{Z}$ siguiente:

 \[\phi(x,n) = n\]

 Bien definido porque tiene a $X$ como núcleo.

****** Punto 3
 El valor de $f'(x,0) = f(x)$ está fijado por la condición, y por ser homomorfismo
 de anillos debe tener $f'(0,1) = 1$; por tanto, para preservar suma, $f'(x,n) = f(x)+n$.

 Ahora, para comprobar que es homomorfismo vemos que respeta las sumas, la unidad
 y los productos:

 \[\begin{align*}
 f'((a,b)(c,d)) &= f(ac+bc+da) + bd = f(a)f(c)+bf(c)+df(a)+bd \\
		&= (f(a)+b)(f(c)+d) = f'(a,b)f'(c,d)
 \end{align*}\]

***** Ejercicio 44
 $S,T$ son R-Módulos, así que entendemos por $S\times T$ la suma directa como módulos.
 Tomamos como definición de $R \cong S \times T$ el que:

 \[\forall r \in R: \exists! s\in S, t\in T:\quad s + t = r\]

****** Descompone con un idempotente
 Primero vemos que $\forall r \in R: re + r(1-e) = r$, y es forma única, porque si existieran
 dos formas de expresar $r$:

 \[\begin{align*}
 r &= s + t \\
 r &= s' + t'
 \end{align*}\]

 Entonces $(s-s') + (t-t') = 0$, y no es posible salvo que
 sean iguales, porque $s + t = 0$, con $ea + (1-e)b = 0$ conduce a:

 \[\begin{align*}
 0 &= eea + e(1-e)b &=& ea \\
 0 &= (1-e)ea + (1-e)(1-e)b &=& (1-e)b
 \end{align*}\]


****** Toda descomposición es por idempotente
 Supongamos $R \cong S \times T$. Tenemos la única descomposición de $1$ como $u+v = 1$.
 Hacemos otra descomposición de $1$ como:

 \[1 = (u+v)(u+v) = u^2+v^2+2uv\]

 Aquí tenemos que $uv \in S$ y $uv \in T$, así que $uv = 0$ (si no, tendría dos 
 descomposiciones); por tanto $1 = u^2 + v^2$, y por unicidad $u=u^2$ y $v=v^2$.

 Ahora veamos $S = (u)$, si tengo $s \in S$, entonces $su+sv = s$, y como $sv \in S$ y
 además $sv \in T$, debe ser nulo y tenerse $s = su$.
***** Ejercicio 45
****** Punto 1
 El producto directo de ideales es trivialmente ideal.

 Sea $\alpha$ un ideal del producto directo, tomamos los siguientes ideales
 \[\beta_i = \{ e_ix \med| x \in \alpha\}\]. Siendo $\pi_i$ la proyección canónica, tomamos:

 \[ \alpha_i = \pi_i(\beta_i) \]

 Por ser sobreyectivo $\pi$, se tiene que es ideal. Queda probar:

 \[\alpha = \prod \alpha_i\]

****** Punto 2
 Vemos que los ideales primos son de la forma $R_1 \times \dots \times P_i \times \dots R_n$, para algún
 $P_i$ primo en $R_i$.

 Sea un ideal primo del producto, será producto de ideales 
 \[P = \alpha_1\times\alpha_2\dots\times\alpha_n\]. Veremos que son todos el total salvo uno. Supongamos que 
 tuviéramos dos ideales propios $\alpha_i,\alpha_j$, con $x_i \in \alpha_i$ y $x_j \in \alpha_j$. Tengo:

 \[x = (0,\dots,x_i,0,\dots,1,0,\dots,0) \notin \Pi\]
 \[y = (0,\dots,1,0,\dots,x_j,0,\dots,0) \notin \Pi\]

 Y sin embargo, $xy \in \pi$.

 Para maximales, la demostración es análoga.

****** Punto 3
 Por el apartado primero, tiene $2^n$ ideales.

***** Ejercicio propuesto
 Veamos que si $x \in J(R)$, entonces $1-xy$ es unidad. Tenemos que $yx \in J(R)$. Si 
 $1-xy$ no fuera unidad, habría un maximal conteniéndolo, luego ese maximal contendría
 a la vez a $1-xy$ y a $xy$.

 Ahora, sea $1-xy$ unidad para cualquier $y$. Si un maximal no contuviera a $x$, entonces
 contendría a $1-xy$. Tendría que necesariamente al añadir $x$ a ese maximal obtendría
 todo el anillo. Luego $m + xy = 1$ y entonces $m = 1-xy$ sería unidad y pertenecería
 al ideal maximal, lo que es imposible.

**** Relación 2
***** DONE Ejercicio 8
***** Ejercicio 16
#+begin_statement
Sea $\leq$  un orden en $\mathbb{N}^n$ que es total y compatible. Haciendo uso de la teoría
de ideales monomiales, probad que $\leq$ es un buen orden si, y sólo si, es
monótono.
#+end_statement

Si es monótono, entonces es monomial, y los monomiales son buenos [[*Sistemas de generadores][órdenes]].

Si es buen orden, todo $\mathbb{N}^n$ tiene un mínimo. Si fuera $a$, se tendría
que $a \leq 0$ y por tanto $2a \leq a$, llegando a $a = 2a$, lo que da $a = 0$.

***** Ejercicio 17
#+begin_statement
Sean $I,J \subset K[X_1,\dots,X_n]$ ideales monomiales generados por $\{A_1,\dots,A_s\}$ y
$\{B_1,\dots,B_n\}$, respectivamente:

  1. Demuestra que $I \cap J$ es un ideal monomial.
  2. Demuestra que $\{M_{i,j} \mid i=1,\dots,s;\;j=1,\dots,t\}$, $M_{i,j}$ es un m.c.m. de
     $A_i$ y $B_j$, es un sistema de generadores de $I \cap J$.
  3. Calcula la intersección de los ideales $I = (X,Y^2Z,YZ^2)$ y
     $J = (X^3YZ, X^2Y, Y^2Z^3)$ en el anillo $K[X,Y,Z]$.
#+end_statement

****** Punto 1 y punto 2
Un monomio $X^\mu \in I \cap J$ debe cumplir $A_i \mid X^\mu$, $B_j\mid X^\mu$ y por tanto
$M_{ij}\mid X^\mu$ para algunos $i,j$. Todo monomio del ideal es generado por 
los $M_{ij}$.

Pero dado un $F \in I \cap J$, sus monomios deben estar en $I \cap J$ también,
así que todo polinomio del ideal es generado por los $M_{i,j}$, y es monomial.

****** TODO Punto 3
Como ambos son ideales monomiales, tenemos que calcular sólo sus
$M_{ij}$.
 
***** Ejercicio 19
#+begin_statement
Demuestra que si $\{J_i \mid i \in I\}$ es una cadena de ideales monomiales, entonces
la unión $\bigcup_{i} J_i$ es un ideal monomial.
#+end_statement

Sea un polinomio que está en la unión. Sus monomios están en algún $J_i$,
así que el ideal es monomial.

***** Ejercicio 20
#+begin_statement
Demostrad que la intersección de ideales monomiales es un ideal monomial.
#+end_statement

Si un polinomio pertenece a la intersección, todos sus monomios pertenecen
a cada ideal y a la intersección. Por lo tanto, la intersección es monomial.

***** Ejercicio 22
#+begin_statement
Demuestra que:

  1. Un ideal monomial es primo ssi está generado por un subconjunto 
     de $\{X_1,\dots,X_n\}$.
  2. El número de ideales monomiales primos es finito, y cada uno de ellos
     es finitamente generado.
  3. $(X_1,\dots,X_n)$ es el único ideal maximal que es monomial.
#+end_statement

****** Punto 1
Si está generado de esa forma, debe ser primo, ya que es imposible que
el producto de dos polinomios que no contienen a una incógnita contenga
a la incógnita o sea nulo.

Si tengo un ideal monomial primo:

\[ I = (X^\alpha \mid \alpha \in A \subseteq \mathbb{N}^n)\]

Tengo que si $gr(\alpha) > 1$, entonces podría escribirse como $\alpha = \beta + \gamma$
y debería tenerse a $X^\beta$ o $X^\gamma$ en el ideal, generando a $X^\alpha$. Por
descenso infinito tengo todos los generadores de grado $1$.

****** Punto 2
Como son de la forma dada, debe tenerse.

****** Punto 3
Tenemos que es un cuerpo su cociente, luego debe ser un ideal
maximal:

\[ \frac{K[X_1,\dots,X_n]}{(X_1,\dots,X_n)} \cong K\]

Ahora bien, todo ideal maximal es primo, y por tanto de la forma
anterior, y por tanto está contenido en este, que debe ser el único
maximal.

***** Ejercicio 26
#+begin_statement
Da un ejemplo de dos polinomios $F,G \in K[X_1,\dots,X_n]$ tales que
$Exp((F,G)) \not\subseteq \{exp(F), exp(G)\} + \mathbb{N}^n$. Observar que la inclusión contraria
es siempre cierta.
#+end_statement

Incluso en una variable podemos tener $F = X^2+X$ y $G = X^2-X$, que
cumplen:

\[Exp((F,G)) = \{1\}+\mathbb{N}^n\]
$\{exp(F),exp(G)\} + \mathbb{N}^n = \{2\} + \mathbb{N}^n$

La inclusión contraria es cierta porque podemos multiplicar por monomios
como $X^\gamma$ para cualquier $\gamma$.

***** Ejercicio 32
Vemos que en el primer caso queda invariante en el algoritmo de Buchberger
y en el segundo no. Es decir, las semizigias dan un resto distinto de cero
sólo en el segundo caso.

*** Prácticas
**** Práctica 1: Anillos e ideales
***** Anillos básicos
#+BEGIN_SRC sage
  ZZ in Fields
  ZZ in EuclideanDomains
#+END_SRC

#+RESULTS:
: False
: True

****** Extensiones algebraicas
 #+BEGIN_SRC sage
 K = NumberField(x^2+1, 's')
 OK = K.ring_of_integers()
 OK
 SS = NumberField(x^2-5,'s').ring_of_integers()
 SS.0
 SS
 #+END_SRC

 #+RESULTS:
 : Gaussian Integers in Number Field in s with defining polynomial x^2 + 1
 : 1/2*s + 1/2
 : Maximal Order in Number Field in s with defining polynomial x^2 - 5

****** Anillos de enteros módulo n
 #+BEGIN_SRC sage
 Z7 = Integers(7)
 Z7.is_field()
 Z8 = Integers(8)
 Z8.cardinality()
 #+END_SRC

 #+RESULTS:
 : True
 : 8

****** Anillos de polinomios
 #+BEGIN_SRC sage
 P = QQ['x']
 P
 P2 = QQ['x','y','z']
 P2
 #+END_SRC

 #+RESULTS:
 : Univariate Polynomial Ring in x over Rational Field
 : Multivariate Polynomial Ring in x, y, z over Rational Field

***** Cuerpos finitos
#+BEGIN_SRC sage
K = GF(5)
a = K.0
a+a+a+a
K.characteristic()
#+END_SRC

#+RESULTS:
: 4
: 5

****** Cuerpos de fracciones
 #+BEGIN_SRC sage
 P.<x> = QQ[]
 K = P.fraction_field()
 1/x in K
 #+END_SRC

 #+RESULTS:
 : True

***** Producto de anillos
#+BEGIN_SRC sage
CZQ = ZZ.cartesian_product(QQ)
CZQ
CZQ.one()
#+END_SRC

#+RESULTS:
: The Cartesian product of (Integer Ring, Rational Field)
: (1, 1)

***** Ideales
#+BEGIN_SRC sage
P.<x,y> = QQ[]
I = Ideal(P,[x+y,x^2+1])
I
ZZ8 = ZZ.quotient(ZZ.ideal(8))
ZZ8 == Integers(8)
#+END_SRC

#+RESULTS:
: Ideal (x + y, x^2 + 1) of Multivariate Polynomial Ring in x, y over Rational Field
: True

****** Inclusión de ideales
 Definimos la inclusión de ideales y sobrecargamos el método de 
 orden para expresarla.
 #+BEGIN_SRC sage
   I = 2*ZZ
   J = 4*ZZ
   def contenido(I,J):
       return I+J == J

   contenido(I,J)
   contenido(J,I)
   sage.rings.ideal.Ideal_pid.__lt__=contenido
   I < J
   J > I
 #+END_SRC

 #+RESULTS:
 : False
 : True
 : False
 : True

****** Operaciones con ideales
 #+BEGIN_SRC sage
   # Suma de ideales
   4*ZZ + 6*ZZ

   # Producto de ideales
   (4*ZZ)*(6*ZZ)

   # Intersección de ideales
   def intersection(I,J):
       a = I.gen()
       b = J.gen()
       q = (a*b).quo_rem(gcd(a,b))
       return Ideal(q[0])
   sage.rings.ideal.Ideal_pid.__and__=intersection

   (4*ZZ)&(6*ZZ)

   # Cociente de ideales
   def cocienteideales(I,J):
       if not (J<I):
           raise "El cociente necesita de inclusión"
       return I.gens()*I.ring().quo(J)
   sage.rings.ideal.Ideal_pid.__div__=cocienteideales

   (2*ZZ)/(4*ZZ)

   # Operaciones con ideales
   6*ZZ/((6*ZZ)&(4*ZZ))
 #+END_SRC

 #+RESULTS:
 : Principal ideal (2) of Integer Ring
 : Principal ideal (24) of Integer Ring
 : Principal ideal (12) of Integer Ring
 : Principal ideal (2) of Ring of integers modulo 4
 : Principal ideal (6) of Ring of integers modulo 12

****** Ideales primos y maximales
 #+BEGIN_SRC sage :file images/idealpoly.png :output both
 P.<x,y> = QQ[]
 I = (x^3-y^2)*P
 I.is_prime()
 implicit_plot(x^3-y^2, (x,-1,2), (y,-1,1))
 #+END_SRC

 #+RESULTS:
 [[file:images/idealpoly.png]]

****** Ideales radicales
 #+BEGIN_SRC sage
 R.<x,y> = GF(2)[]
 I = (x,y)*R
 J = (x-1,y-1)*R
 K = I*J
 K.radical() == K
 #+END_SRC

 #+RESULTS:
 : True

***** Homomorfismos de anillos
#+BEGIN_SRC sage
# Inclusión 
H = Hom(ZZ,QQ)
inc = H([1])
inc(1)

# Homomorfismo al cociente
f = ZZ.hom([1],ZZ.quo(4*ZZ))
f(1) == f(5)
f(6)

# Composición de homomorfismos
R.<x,y,z> = QQ[]
S.<t> = QQ[]
f = R.hom([t^3,t^5,t^7],S)
g = S.hom([t^2],S)
g*f
#+END_SRC

#+RESULTS:
#+begin_example
1
True
2

Ring morphism:
  From: Multivariate Polynomial Ring in x, y, z over Rational Field
  To:   Univariate Polynomial Ring in t over Rational Field
  Defn: x |--> t^6
        y |--> t^10
        z |--> t^14
#+end_example

**** Práctica 2: Anillos de polinomios
***** Anillos de polinomios
    Para poder usar las variables del anillo de polinomios en 
    sage debemos insertarlas

#+BEGIN_SRC sage
P = PolynomialRing(QQ,['x','y','z','t'])
P.inject_variables()
x in P
#+END_SRC
#+RESULTS:
: Defining x, y, z, t
: True

***** Factorización
#+BEGIN_SRC sage
P.<x,y> = QQ[]
c = x^3-y^2
c.factor()

f = x*y-1
g = x^2+y^2-4
#+END_SRC
#+RESULTS:
: (-1) * (-x^3 + y^2)

***** Polinomios en una variable
#+BEGIN_SRC sage
R = Zmod(2)['x']
R.inject_variables()
filter(is_prime,list(R.monics(of_degree=5)))
#+END_SRC
#+RESULTS:
: Defining x
: 
: [x^5 + x^2 + 1,
:  x^5 + x^3 + 1,
:  x^5 + x^3 + x^2 + x + 1,
:  x^5 + x^4 + x^2 + x + 1,
:  x^5 + x^4 + x^3 + x + 1,
:  x^5 + x^4 + x^3 + x^2 + 1]

***** Ejemplo: Cuerpo de 256 elementos
Vamos a tomar un cuerpo de 256 elementos y vamos a multiplicar en él usando 
logaritmos. Es decir, vamos a representar cada polinomio como un número binario
y vamos a sumarlos para multiplicar.

#+BEGIN_SRC sage
p = R.irreducible_element(8)
Q = R.quo(p*R,'a')
Q.is_field()
a = Q.0

# Potencias de a, son todo elementos de Q
l = [a^i for i in range(2**8-1)]
l.index(a^2+1)
#+END_SRC
#+RESULTS:
: True
: 50

***** TODO Ejercicio 1
    #+begin_statement
    Demuestra que la clase de $x+1$ genera $\mathbb{Z}_2[x]/(x^8+x^4+x^3+x+1)$.
    #+end_statement

***** Órdenes monomiales
    #+BEGIN_SRC sage
      P = PolynomialRing(QQ,x,3,order='lex')
      P.inject_variables()

      ds = list(WeightedIntegerVectors(2,[1,1,1]))+list(WeightedIntegerVectors(1,[1,1,1]))
      ms=[P({tuple(l):1}) for l in ds]
      sorted(ms)

      P=PolynomialRing(QQ,x,3,order='degrevlex')
      P.inject_variables()

      ds = list(WeightedIntegerVectors(2,[1,1,1]))+list(WeightedIntegerVectors(1,[1,1,1]))
      ms=[P({tuple(l):1}) for l in ds]
      sorted(ms)
    #+END_SRC

    #+RESULTS:
    : Defining x0, x1, x2
    : [x2, x2^2, x1, x1*x2, x1^2, x0, x0*x2, x0*x1, x0^2]
    : Defining x0, x1, x2
    : [x2, x1, x0, x2^2, x1*x2, x0*x2, x1^2, x0*x1, x0^2]

****** Ejercicio
     Ordena mediante el orden lexicográfico y lexicográfico graduado todos los 
     monomios en tres variables de grado 3.

     #+BEGIN_SRC sage
       P=PolynomialRing(QQ,x,3)
       P.inject_variables()

       ds = list(WeightedIntegerVectors(3,[1,1,1]))
       ms=[P({tuple(l):1}) for l in ds]
       sorted(ms)
     #+END_SRC

     #+RESULTS:
     #+begin_example
     Defining x0, x1, x2

     [x2^3,
      x1*x2^2,
      x0*x2^2,
      x1^2*x2,
      x0*x1*x2,
      x0^2*x2,
      x1^3,
      x0*x1^2,
      x0^2*x1,
      x0^3]
     #+end_example

***** Algoritmo de la división
**** Práctica 3: Bases de Gröbner
***** Bases de Gröbner
    #+BEGIN_SRC sage
      P = PolynomialRing(QQ, ['x','y','z'], order='lex')
      I = (x^4-y^4+z^3-1, x^3+y^2+z^2-1)*P
      len(I.groebner_basis())
    #+END_SRC

    #+RESULTS:
    : 5

***** Pertenencia de polinomios
    #+BEGIN_SRC sage
      P.<x,y>=QQ[]
      I = (x^2-y^3,x)*P
      I.groebner_basis()
      y**3 in I
    #+END_SRC

    #+RESULTS:
    : [y^3, x]
    : True

****** Ejercicio
     #+BEGIN_SRC sage
       P.<x,y,z>=QQ[]
       g1=x^2*y*z+y^2*z+1
       g2=x*y^2*z+y*z^2-2
       g3=x*y*z^2+z+3
       I = (g1,g2,g3)*P
       len(I.groebner_basis())
       P.quo(I).()
     #+END_SRC

     #+RESULTS:
     : 8
     : Rational Field

***** Cúpside
    #+BEGIN_SRC sage
      P = PolynomialRing(QQ,["t","x","y"],order="lex")
      P.inject_variables()
      I = (x-t^2,y-t^3)*P
      I.groebner_basis()
      I.elimination_ideal([t])
    #+END_SRC

    #+RESULTS:
    : Defining t, x, y
    : [t^2 - x, t*x - y, t*y - x^2, x^3 - y^2]
    : Ideal (x^3 - y^2) of Multivariate Polynomial Ring in t, x, y over Rational Field

    
****** Ejercicio
     #+BEGIN_SRC sage
       P = PolynomialRing(QQ,["t","x","y","z","u"],order="lex")
       P.inject_variables()
       I = (x-t-u, y-t^2-2*t*u, z-t^3-3*t^2*u)*P
       I.elimination_ideal([t,]u)
     #+END_SRC

     #+RESULTS:
     : Defining t, x, y, z, u
     : Ideal (4*x^3*z - 3*x^2*y^2 - 6*x*y*z + 4*y^3 + z^2) of Multivariate Polynomial Ring in t, x, y, z, u over Rational Field     
** Álgebra III
# Exportaba con config.setup

*** 1. Polinomios simétricos
**** Motivación: La cúbica
***** Polinomios cúbicos
Toda ecuación cúbica polinómica puede escribirse en la forma
\(Y^3 + pY + q\), tomando un cambio de variable desde la original
\(X \mapsto - \frac{1}{3} b\). Esto se llama una cúbica deprimida.

****** Método de Vieta
El método de Vieta toma \(t = w - \frac{p}{3w}\), y llega a la ecuación:

\[w^3 + q - \frac{p^3}{27w^3} = 0\]

Ahora podemos resolver esa cuadrática y resolver luego la ecuación
en $w^3$.

**** 1.1. Polinómios simétricos
***** Polinomios simétricos
Un *polinomio simétrico* es aquel invariante por $f_\sigma$ para cualquier $\sigma \in S_r$, 
donde $f_\sigma (X_i) = X_{\sigma i}$. Llamamos $Sim(A[X_1\dots X_n])$ al subanillo de polinomios 
simétricos.

***** Componentes homogéneas
Llamamos *componente homogénea* a cada sumando homogéneo maximal de un
polinomio. Un polinomio es simétrico si y sólo si cada una de sus
componentes lo es.

***** Polinomios simétricos elementales
Los polinomios simétricos elementales son aquellos de la forma:

\[e_i = \sum_{i_1 < \dots < i_i} X_{i1} X_{i2} \dots X_{ii}\]

***** Teorema fundamental de los polinomios simétricos
Los polinomios elementales generan cada polinomio $Sim(A[X_1\dots X_n])$ 
de forma única. En particular,

\[\omega : A[X_1,\dots,X_r] \longrightarrow Sim(A[X_1,\dots,X_r])\]

con $\omega(a) = a$ y $\omega(X_i) = e_i$ es un isomorfismo.

****** Demostración
Damos una relación de orden lexicográfica entre los monomios de un
polinomio simétrico homogéneo. Al mayor de ellos, llamado 
$X_1^{k_1} \dots X_r^{k_r}$ le restamos $e^{b1}_1 e^{b2}_2 \dots e^{br}_r$, donde
$b_i = k_i - k_{i+1}$. Nos quedará $0$ u otro polinomio simétrico de
igual grado pero menor en el orden lexicográfico. Este proceso debe
ser finito.

La unicidad se obtiene con $0 = h(e_1\dots e_r) - k(e_1\dots e_r) =
l(e_1 \dots e_r)$.

**** 1.2. Polinomios alternados
***** 1.2.1. Polinomio alternado
Un polinomio $f$ es alternado cuando para toda permutación se tiene
$\sigma(f) = sign(\sigma) f$.

**** 1.3. La resultante
***** 1.3.2. Resultante
Dados dos polinomios $f,g$ en un cuerpo $K$ en el que descomponen 
podemos escribirlos como:

\[ f = a_n(X-\alpha_1)\dots(X-\alpha_n) = a_n \prod^n_{i=1}(X-\alpha_i)\]
\[ g = b_n(X-\beta_1)\dots(X-\beta_n) = a_n \prod^n_{i=1}(X-\beta_i)\]

La *resultante* busca ser una expresión que se anula cuando tienen
raíz común, y se define como:

\[ R(f,g) = a_n^m b_m^n \prod^n_{i=1} \prod^m_{j=1} (\alpha_i - \beta_j)\]

***** TODO 1.3.3. Propiedades de la resultante
La resultante de dos polinomios $f,g$ cumple:

 1. $R(f,g) = 0$ ssi tienen una raíz común.
 2. $R(g,f) = (-1)^{nm}R(f,g)$, siendo $nm$ el producto del número de raíces.
 3. $R(f,g) = a^m_n \prod^n_{i=1} g(\alpha_i)$
 4. $R(fg,h) = R(f,h)R(g,h)$, $R(f,gh) = R(f,g)R(f,h)$
 5. Si $m=0$, entonces $R(f,k) = k^n$
 6. $R(X^k,f) = a_0^k$; con $R(f,X^k) = (-1)^{nk}a_0^k$

**** 1.4. Discriminante
***** 1.4.1. Raíces múltiples
Podemos usar la resultante para caracterizar los polinomios
con raíces múltiples, que son aquellos que comparten raíz con
su derivada.

\[ R(f,f') = a_n^{n-1} \prod f'(\alpha_j)\]

***** 1.4.1. El discriminante
El *discriminante* de un polinomio con raíces $\alpha_1, \dots, \alpha_n$ en una 
clausura algebraica es:

\[\text{Discr}(p) = a^{2n-2}_n \prod_{i<j}(\alpha_i-\alpha_j)^2\]

***** 1.4.1. Relación con la resultante
\[R(p,p') = (-1)^{\frac{n(n-1)}{2}}a_n \text{Discr}(p)\]

***** 1.4.2. Propiedades del discriminante
El determinante cumple:

  1. $f_1,f_2 \in F[X] \implies D(f_1f_2) = D(f_1)D(f_2)R(f_1,f_2)^2$.
  2. $f_1,\dots,f_r \in F[X] \implies D(f_1\dots f_r) = D(f_1)\dots D(f_r)R^2$ con $R \in F$.

**** 1.5. Métodos de cálculo
***** TODO 1.5.2. Método modular
***** TODO 1.5.3. Por el algoritmo de Euclides
***** 1.5.4. Resultante de Euler-Sylvester-Cayley
Definimos la resultante de Euler-Sylvester-Cayley:

\[
R(f,g) = \left| \begin{matrix}
a_n & a_{n-1} & \dots & a_0 & 0 & \dots &\\
0   & a_n & \dots & a_{1} & a_0 & 0 & \dots \\
0   &   0 & a_n & \dots & a_1 & a_0 & \dots \\
&      &     &\vdots & & & \\
b_m & b_{m-1} & \dots & b_0 & 0 & \dots &\\
0   & b_m & \dots & b_1 & b_0 & 0 & \dots \\
0   &   0 & b_m & \dots & b_1 & b_0 & \dots \\
\end{matrix} \right|
\]

****** Origen
La resultante se obtiene como la determinante de la
matriz del sistema de ecuaciones que dan:

\[ \begin{aligned}
X^{m-1} f &= 0 \\
X^{m-2} f &= 0 \\
& \vdots \\
1f &= 0 \\
X^{n-1}g &= 0 \\
X^{n-2}g &= 0 \\
& \vdots \\
1g &= 0 \\
\end{aligned}\]

Por Teorema de Rouché, este sistema tiene solución ssi 
el determinante de los coeficientes es cero.

***** 1.5.5. Resultante como determinante
La *resultante* de dos polinomios $p,q$ es el determinante solución de 
$pq' - qp' = 0$ dados $p$ y $q$.

\[R(p,q) = \left| \begin{matrix}
a_0 & a_1 & \dots & a_n & 0 & \dots &\\
0   & a_0 & \dots & a_{n-1} & a_n & 0 & \dots \\
0   &   0 & a_0 & \dots & a_{n-1} & a_n & \dots \\
&     &     &\dots & & & \\
b_0 & b_1 & \dots & b_m & 0 & \dots &\\
0   & b_0 & \dots & b_{m-1} & b_m & 0 & \dots \\
0   &   0 & b_0 & \dots & b_{m-1} & b_m & \dots \\
\end{matrix} \right|
\]

Y llamamos *matriz resultante* a la matriz de la que es determinante.

*** 2. Series de grupos y grupos solubles
**** 2.1. Series de composición
***** 2.1.1. Factor
Sea $G$ grupo, llamamos factor a cualquier $H/H'$ donde $G > H \trianglerighteq H'$.

***** 2.1.2. Proyección
Llamamos proyección de $H/H'$ sobre $K/K'$, ambos factores, a:

\[\frac
{K'(H\cap K)}
{K'(H'\cap K)}\]

***** 2.1.3. Serie
Llamamos serie a toda cadena finita:

\[ G > G_1 > G_2 > \dots > G_r = 1\]

Donde llamamos a $r$ la longitud del grupo.

***** 2.1.4. Refinamiento de una serie
Dadas dos series,

\[ G > G_1 > G_2 > \dots > G_r = 1\]
\[ G > G'_1 > G'_2 > \dots > G'_r = 1\]

llamamos a la segunda refinamiento si todo grupo suyo aparece en
la primera. Es refinamiento propio si además son distintas.

***** 2.1.5. Serie normal
Una serie es *normal* cuando se verfica $G_i \trianglerighteq G_{i+1}$. Llamamos a $G_{i-1}/G_i$
los *factores* de la serie.

***** 2.1.5. Serie propia
Una serie propia tiene sólo inclusiones propias $G_i \gneq G_{i+1}$.

***** 2.1.5. Isomorfismo de series
Dos series son isomorfas cuando existe una permutación que hace 
isomorfos sus factores:

\[\exists \sigma \in S_r : \quad 
G_{i-1}/G_i \cong H_{\sigma(i)-1}/H_{\sigma(i)}\]

***** 2.1.5. Serie de composición
Una *serie de composición* es una serie normal propia sin 
refinamientos normales. Llamamos *factores de composición* a sus
factores.

***** 2.1.6. Grupo simple
Un grupo simple es aquel que no admite subgrupos normales propios.

***** 2.1.7. Grupos abelianos finitos simples
Un grupo abeliano, finito y simple es isomorfo a $\mathbb{Z}_p$ para algún $p$ primo.

****** TODO Demostración

***** 2.1.8. Los factores de composición son simples
Los factores de cualquier serie de composición son simples.

****** TODO Demostración

***** 2.1.9. Existencia de la serie de composición
Todo grupo finito posee una serie de composición.

***** 2.1.10. Teorema de refinamiento de Schreier
Dos series normales de un grupo tienen refinamientos isomorfos.

***** 2.1.11. Teorema de Jordan-Holder
Si un grupo admite serie de composición, toda serie normal propia puede
refinarse a una serie de composición. Las series de composición son 
isomorfas.

**** 2.2. El programa de Holder
***** TODO 2.2.1. Teorema de clasificación de grupos simples finitos
***** 2.2.2. Teorema de Abel
El grupo $A_n$ es simple para $n \geq 5$.

****** TODO Demostración

***** 2.2.3. Teorema de Feit-Thompson
Si $G$ es simple de orden impar, entonces $G \cong \mathbb{Z}_p$ con $p$ primo.

****** TODO Demostración

**** 2.3. Grupos solubles
***** 2.3.1. Serie derivada
Dado $G$, definimos la serie derivada de $G$ como:

\[G = G^0 > G' > G'' > \dots \]

donde $G^{(i+1} = [G^{(i}, G^{(i}]$ es el grupo derivado. Nótese que no tiene por
qué ser finita.

***** 2.3.2. Caracterización de grupos solubles
Para $G$ grupo finito, equivalen:

 1. Los factores de composición son cíclicos de orden primo.
 2. $G$ tiene serie normal con factores cíclicos.
 3. $G$ tiene serie normal con factores abelianos.
 4. Se tiene $G^{(i} = 1$.

****** TODO Demostración

***** 2.3.3. Grupo soluble
Un grupo es soluble si tiene una serie normal con factores cíclicos.

***** 2.3.4. Subgrupos de solubles
Son solubles:

 1. Los subgrupos de un grupo soluble.
 2. Los cocientes de un grupo soluble.
 3. Si $N$ y $G/N$ son solubles, $G$ es soluble.

****** TODO Demostración

***** 2.3.5. Producto de solubles
Todo producto finito de grupos solubles es soluble.

****** TODO Demostración

***** 2.3.6. Teorema de Hall
Sea $G$ soluble de orden $mk$ cumpliendo $mcd(m,k) = 1$. Entonces:

 1. $G$ posee un grupo de orden $m$.
 2. Dos subgrupos cualesquiera de orden $m$ son conjugados.
 3. Todo subgrupo de orden $m' \mid m$ está contenido en uno de orden $m$.
 4. El número de subgrupos de orden $m$, $r_m$ es producto de factores
    congruentes a $1$ módulo algún factor primo de $m$. Es además potencia
    de primo y divide a alguno de los factores de $G$.

****** TODO Demostración

***** 2.3.7. Caracterización de grupo soluble
Dado $G$ grupo finito, es soluble ssi para cualquier descomposición $|G|=mk$
con $mcd(m,k) = 1$, existe un subgrupo de orden $m$.

*** 3. Extensiones de cuerpos
**** 3.1. Generalidades
***** 3.1.1. Extensiones de cuerpos
Una *extensión de cuerpos* es un subcuerpo $K$ de $F$, se nota por $F/K$. 

***** 3.1.2. Grado de la extensión
Llamamos *grado* a la dimensión de $F$ como espacio vectorial.
Notamos por $[F : K]$.

***** 3.1.3. Cuerpo intermedio
Un cuerpo intermedio entre $F$ y $K$ es cualquier subcuerpo de $F$ 
conteniendo a $K$.

***** 3.1.4. Torre de cuerpos
Una torre es una sucesión de subcuerpos:

\[F_0 \subset F_1 \subset \dots \subset F_n\]

***** 3.1.5. Extensiones finitas
Una extensión es finita ssi $[F:K]$ es finito.

***** 3.1.6. Base de una torre de inclusiones
Sea $K \supset F \supset E$ una torre de inclusiones. Sean $\{u_i\}_{i\in I}$ una base de $E$
sobre $F$ y $\{v_j\}_{j\in J}$ una base de $F$ sobre $K$. Entonces $\{u_iv_j\}$ es una base
de $E$ sobre $K$.

****** Demostración
******* Es sistema de generadores
Si tenemos ambos sistemas de generadores, podemos escribir cada
elemento de $E$ como:

\[ e 
= \sum u_i f_i 
= \sum u_i \left(\sum v_j k_{ij}\right) 
= \sum u_iv_ik_{ij}\]

******* Son linealmente independientes
Aplicando la independencia lineal de cada una de las bases:

\[ \sum u_iv_jk_{ij} 
= \sum u_i \left( \sum v_jk_{ij}\right) = 0\]

Tenemos que $\sum v_jk_{ij} = 0$, luego $k_{ij} = 0$.

***** 3.1.7. Teorema del grado
Sean $K \subset F \subset E$, extensiones de cuerpos, se tiene que:

\[ [E:K] = [E:F][F:K] \]

****** Demostración
Teniendo una base de cada uno de ellos, calculamos la base
de la [[*3.1.6. Base de una torre de inclusiones][torre de inclusiones]], que nos da la dimensión.

***** 3.1.8. Corolario al Teorema del grado: finitud
Sean $K \subset F \subset E$, la extensión $E/K$ es finita ssi las extensiones
$E/F$ y $F/K$ lo son.

****** Demostración
Si ambas son finitas, podemos aplicar el [[*3.1.7. Teorema del grado][teorema del grado]]. Cuando
$E/K$ es finita, tenemos que $E/F$ tiene como sistema generador a la
base y $F/K$ es un subespacio de $E/K$.

***** 3.1.9. Corolario al Teorema del grado: torres de cuerpos
Sea $F_0 \subset F_1 \subset \dots \subset F_n$ torre de longitud $n$, entonces:

\[ [F_n : F_0] =
[F_n:F_{n-1}] \dots [F_2:F_1][F_1 : F_0]
\]

****** Demostración
Por inducción sobre la longitud de la torre y aplicando el teorema
del grado a cada paso.

***** 3.1.10. Corolario al Teorema del grado: extensiones primas
Sea $F/K$ una extensión tal que $[F:K] = p$ es primo. Entonces no
existe ningún cuerpo intermedio propio.

****** Demostración
Usando el teorema del grado, tenemos que debería tener grado $p$, en
cuyo caso sería un subespacio de la misma dimensión que $F$, y por
tanto $F$. O debería tener grado $1$, en cuyo caso sería $K$.

**** 3.2. Elementos algebraicos y extensiones algebraicas
***** 3.2.1. Homomorfismo unital
Para todo anillo $A$ existe un único homomorfismo de anillos
$1_\mathbb{Z} : \mathbb{Z} \longrightarrow A$, llamado *homorfismo unital*.

***** 3.2.2. Característica del anillo
La característica de $A$ es el entero no negativo que genera
al ideal $ker(1_\mathbb{Z})$.

***** 3.2.3. Característica en dominios de integridad
Si $A$ es dominio de integridad, $car(A)$ es primo o $0$.

****** Demostración
Trivialmente desde el homomorfismo unital. Si no fuera así,
tendríamos $ab = 0$ enteros.

***** 3.2.4. Caracterización de la característica
$car(A)=n$ ssi $n$ es el menor entero positivo tal que $na = 0$ para
todo $a \in A$.

****** Demostración
Si hubiera otro menor, debería pertenecer al núcleo del homomorfismo
unital, y no podría ser generado por $n$. Si cumple la condición
y es el menor, todo el resto de elementos del núcleo deben ser 
múltiplos, porque si no lo fueran, podríamos crear un menor con 
Bezout.

***** 3.2.5. Intersección de anillos
Sea $A$ un anillo y sea $\{B_i\}_{i\in I}$ una familia de subanillos. Entonces
$\bigcap B_i$ es subanillo. Análogo para cuerpos y subcuerpos.

****** Demostración
Si dos elementos pertenecen a todos los $B_i$, tenemos que su suma
y su producto pertenece a cada uno de ellos.

***** 3.2.6. Anillo primo
Llamamos subanillo primo de $A$ a la intersección de todos los 
subanillos de $A$.

***** 3.2.7. Clasificación de anillos primos
El subanillo primo de un $A$ es isomorfo a $\mathbb{Z}$ si $car(A) = 0$ y
a $\mathbb{Z}/n\mathbb{Z}$ si $car(A) = n \neq 0$.

****** Demostración
En ambos casos, ellos son subanillos por ser imágenes del 
homomorfismo unital, como se comprueba por primer teorema de
isomorfía.

***** 3.2.8. Subcuerpo primo
Llamamos subcuerpo primo de $K$ a la intersección de todos los
subcuerpos de $K$.

***** 3.2.9. Clasificación de subcuerpos primos
El subcuerpo primo de un cuerpo $K$ es isomorfo a $\mathbb{Q}$ cuando
$car(K)=0$ y a $\mathbb{Z}/p\mathbb{Z}$ cuando $car(K) = p \neq 0$.

****** Demostración
De nuevo, vuelve a tenerse una inyección de ambos por el 
homomorfismo unital. Cualquier subanillo contendrá a $1$ y por
tanto a este subcuerpo.

***** 3.2.10. Subanillo generado
Sea $F/K$ extensión con $S\subseteq F$; llamamos *subanillo generado*
$K[S]$ a la intersección de todos los subanillos de $F$ conteniendo
a $K$ y a $S$.

***** 3.2.10. Subcuerpo generado
Sea $F/K$ extensión con $S \subseteq F$; llamamos *subcuerpo generado*
$K(S)$ a la intersección de todos los subcuerpos de $F$ conteniendo
a $K$ y a $S$.

***** 3.2.11. Propiedades de subanillos y subcuerpos generados
Para $S,T \subseteq F$ extensión de $K$, tenemos:

 - $K[S \cup T] = K[S][T] = K[T][S]$
 - $K(S \cup T) = K(S)(T) = K(T)(S)$

****** Demostración
En cualquiera de los dos casos la definición es la intersección
de todos los que contienen a $K$, $T$ y $S$.

***** 3.2.12. Subcuerpo compuesto
Dados $K \subset E,F \subset L$, definimos el subcuerpo compuesto
$EF = E(F) = F(E)$.

****** Demostración
Son iguales trivialmente desde la definición.

***** 3.2.13. Conjunto de generadores
Sea $F/K$ con $S \subseteq F$, es un subconjunto de generadores si
$F = K(S)$.

***** 3.2.14. Extensión finitamente generada
Una extensión $F/K$ es finitamente generada cuando tiene un
conjunto finito de generadores, $F = K(u_1,u_2,\dots,u_n)$.

***** 3.2.15. Extensiones simples y elementos primitivos
Una extensión $F/K$ se llama simple cuando $F = K(u)$. Al $u$
se le llama *elemento primitivo* para la extensión.

***** 3.2.16. Elementos algebraicos
$\alpha \in F$ es *algebraico* sobre $K$ si existe polinomio $f \in K[x]$ tal 
que $f(\alpha) = 0$. 

Un no algebraico es *trascendente* y una extensión es *algebraica* 
si lo son todos sus elementos.

***** 3.2.16. Polinomios irreducibles
Dado $F/K$ con $\alpha \in F$ algebraico. Existe un único polinomio 
irreducible del que $\alpha$ es raíz salvo asociados, llamado $Irr(\alpha)$.
   
****** Existencia y unicidad del polinomio irreducible
Tomo el núcleo del homomorfismo que evalúa un polinomio en $\alpha$. 
Por ser un ideal en PID, estará generado por algún polinomio $f$ 
no nulo y no constante.

Este será irreducible, porque si no lo fuera, con $f = g_1g_2$ se 
tendría:

\[0 = f(\alpha) = g_1(\alpha)g_2(\alpha)\]

Un polinomio de grado mínimo debería estar dentro del ideal, 
y por tanto ser asociado de $f$, que lo genera.

***** 3.2.16. Propiedades de los polinomios irreducibles
Sea $F/K$ extensión con $u \in F$ algebraico. Se cumple:

  1. $K(u) = K[u]$
  2. $K[u] \cong K[X]/(Irr(u,K))$
  3. $[K(u):K]$ es igual al grado de $Irr(u,K)$.
  4. $\{1,u,u^2,\dots,u^{n-1}\}$ es una base de $K[u]$ sobre $K$.
  5. $f(u)=0$ ssi $Irr(u,K) \mid f$.

Llamamos *grado* del elemento $u$ al grado de $Irr(u,K)$.

****** Demostración
******* Punto 1
Sabemos que el anillo generado está dentro del cuerpo generado,
y además, $u^{-1}$ está en el anillo generado porque, si su polinomio
irreducible nos da $\sum a_iu^i = 0$, tenemos:

\[ u \left(a_nu^{n-1} + a_{n-1}u^{n-2} + \dots a_1 \right)\frac{1}{a_0} = 1\]

******* Punto 2
Aplicando el primer teorema de isomorfía al morfismo evaluación,
tenemos el resultado.

******* Punto 3
Tenemos que $1,u,u^2,\dots,u^{n-1}$ son linealmente independientes porque
una relación lineal entre ellos daría un polinomio menor que el
mínimo. Además son base trivialmente porque $u^{-1}$ puede expresarse
linealmente como polinomio suyo como mostramos [[*Punto 1][antes]] y porque
cuaquier expresión polinómica de grado mayor a $n$ puede dividirse 
por el polinomio irreducible para obtener otra de grado menor.

******* Punto 4
La misma demostración [[*Punto 3][anterior]].

******* Punto 5
Un polinomio verificando $f(u)=0$ está dentro del núcleo del
homomorfismo evaluación.

***** 3.2.17. Algebraicos en una torre de cuerpos
Sea $K \subset F \subset E$ con $u \in E$ algebraico sobre $K$, entonces $u$ es
algebraico sobre $F$ y $Irr(u,F)$ divide a $Irr(u,K)$.

****** Demostración
Notamos que $Irr(u,K)$ es también un polinomio sobre $F$ que anula
a $u$, así que, por las propiedades de los polinomios irreducibles,
se debe tener $Irr(u,F) \mid Irr(u,K)$.

***** 3.2.18. Extensiones algebraicas
Una extensión se llama *algebraica* si todos sus elementos lo son.
Es *trascendente* en otro caso.

***** 3.2.19. Elementos algebraicamente independientes
Los elementos $\{u_i \mid i\in I\}$ son algebraicamente independientes si el
homomorfismo de evaluación sobre el cuerpo de polinomios en varias
variables $K[X_i \mid i\in I]$ es inyectivo.

***** 3.2.20. Extensiones puramente trascendentes
Una extensión $F/K$ se llama puramente trascendente si $F = K(S)$
donde $S$ un conjunto de algebraicamente independientes.

***** 3.2.21. Generación finita de elementos
Para $F/K$ extensión cualquiera $S \subseteq F$, se tiene:

 1. Para $u \in K[S]$ existe un subconjunto $\{u_1,\dots,u_n\} \subset S$ tal que
    $u \in K[u_1,\dots,u_n]$.
 2. Para $u \in K(S)$ existe un subconjunto $\{u_1,\dots,u_n\} \subset S$ tal que
    $u \in K(u_1,\dots,u_n)$.

****** Demostración
Tener $u \in K[S]$ nos da una expresión polinómica finita como elementos
de $S$. Los elementos involucrados en esa expresión crean una extensión
finita en la que está $u$. Análogo en el caso de cuerpos.

***** 3.2.22. Generación del compuesto
Sean $K \subset E,K(S) \subset L$, entonces $EK(S) = E(S)$.

****** Demostración
Por definición del cuerpo compuesto, será $EK(S) = K(E)(S) = E(S)$.

***** 3.2.23. Grado de una extensión compuesta
Sean $K \subset E,F \subset L$. Entonces:

\[ [EF:K] \leq [E:K][F:K]\]

****** Demostración
En el caso finito, el cuerpo generado por las bases de $E$ y
de $F$ multiplicadas contiene a todo elemento de $E$ y de $F$, por 
lo que es sistema de generadores de $EF$.

***** 3.2.24. Extensiones primas relativas
Sean $K \subset E,F \subset L$ con $n = [E:K]$ y $m = [F:K]$ primos relativos.
Entonces $[EF:K] = [E:K][F:K]$.

****** Demostración
Sea $\{f_i\}$ base de $F$ sobre $K$. Tenemos que es sistema de generadores
de $F$ sobre $E$, y por tanto, de $EF$ sobre $E$. Así $[EF:E] \leq [F:K]$
y análogamente $[EF:F] \leq [E:K]$.

Por otro lado, por teorema del grado tenemos:

\[[EF:K] = [EF:F][F:K] = [EF:F]m\]
\[[EF:K] = [EF:E][E:K] = [EF:E]n\] 

Así, por ser primos relativos, tenemos $n \mid [EF:E]$ y $m \mid [EF:F]$; 
teniéndose finalmente:

\[ [EF:F] = [E:K] \]
\[ [EF:E] = [F:K] \]

***** 3.2.25. Extensión finitamente generada por algebraicos es finita
Una extensión $F = K(u_1,\dots,u_n)$ finitamente generada por $u_i$ algebraicos
es finita.

****** Demostración
Todo elemento algebraico cumple una relación polinómica. Así,
todo elemento de grado igual o mayor a esta relación, puede
expresarse como elementos de grado menor.

Si tenemos $e_i$ como el exponente mayor al que puedo elevar $u_i$ sin
que pueda ser reescrito, tenemos un sistema de generadores de $F$ 
finito como:

\[\{ 1, u_1^1, u_1^2, \dots u_1^{e_i}, u_2^1, \dots, u_2^{e_j}, u_3^1,\dots\}\]

***** 3.2.26. Extensión generada por algebraicos es algebraica
Una extensión $K(S)/K$ es algebraica sobre $K$ ssi todo $u \in S$ es 
algebraico sobre $K$.

****** Demostración
Si es algebraica, en particular lo es cada elemento de $S$.
Si lo son los elementos de $S$, podemos ver que cualquier 

***** 3.2.27. Finita es algebraica y finitamente generada
Una extensión es finita ssi es algebraica y finitamente generada

****** Demostración
Tenemos que extensión finitamente generada por algebraicos es
[[*3.2.25. Extensión finitamente generada por algebraicos es finita][finita]]. Por otro lado, si es finita, tendrá una base finita que
la genera; y para cada elemento de la base, $\{1,u,\dots,u^n\}$ no
será linealmente independiente. Luego será finita.

***** 3.2.28. Caracterización de elementos algebraicos
Un elemento $u \in F$ es algebraico sobre $K$ ssi existe una extensión
finita intermedia $E/K$ donde $u \in E$.

****** Demostración
Si es algebraico de grado $n$, tenemos $K(u)$ algebraica y finitamente
generada, [[*3.2.27. Finita es algebraica y finitamente generada][luego finita]]. Si existe una extensión finita intermedia, 
será algebraica.

***** 3.2.29. Torre algebraica
Sean $K \subset F \subset E$, $E/K$ es algebraica ssi $E/F$ y $F/K$ son ambas 
algebraicas.

****** Demostración
******* Si es algebraica, lo son sus partes
Un elemento algebraico sobre $K$ lo será sobre $F$. Y todo elemento
de $F$ está en $E$, luego será algebraico sobre $K$.

******* Si las partes son algebraicas, es algebraica
Todo elemento $e \in E$ es algebraico sobre $F$, luego cumple algún
polinomio con elementos en $F$. Los elementos que generan el polinomio
en $F$ son todos algebraicos sobre $K$, luego $K$ extendido con esos
elementos es finito. Si lo extiendo con $e$, que es algebraico sobre
ellos, llego a otra extensión finita. Toda finita es [[*3.2.27. Finita es algebraica y finitamente generada][algebraica]].

***** 3.2.30. Clausura algebraica relativa
Dada $F/K$ extensión, el conjunto de elementos algebraicos forman un
subcuerpo de $F$. Llamado *clausura algebraica relativa* de $K$ en $F$.

****** Demostración
Sean $a,b \in F$ algebraicos; entonces $K(a,b)$ es finito, luego $a+b$ y
$ab$ son también algebraicos.

****** Demostración constructiva para la suma
Se puede [[http://mathoverflow.net/a/81640/45365][encontrar constructivamente]] un polinomio que tenga como
raíz a la suma de dos algebraicos.

***** DONE Existencia de clausura
*Teorema de Steinitz*. Todo cuerpo tiene una extensión algebraicamente 
cerrada.

***** DONE Homomorfismos sobre un cuerpo
     Un *homomorfismo sobre cuerpos* $K,K'$ es un homomorfismo $\phi$ sobre extensiones
     $F,F'$ con un isomorfismo $\omega : K \longrightarrow K'$ debe cumplir: $\phi|_K = \omega$. 
     Cuando no se especifica, se asume la identidad.

     \[ \phi : F/K \longrightarrow F'/K' \]

***** DONE Automorfismos entre extensiones
     Un automofismo de extensiones es un homomorfismo sobre el cuerpo $K$, 
     $\phi : F/K \longrightarrow F/K$ que es isomorfismo.

*** 4. Cuerpos de descomposición
**** 4.1. Cuerpo de descomposición
***** 4.1.1. Teorema de Kronecker
Sea $f$ de grado no nulo sobre $K$, entonces existe una extensión $F/K$ 
tal que existe $u \in F$ con $f(u) = 0$.

****** Demostración
Puedo descomponer en irreducibles $f = f_1f_2\dots f_m$; y tener una 
extensión cumpliendo lo pedido:

\[ F = \frac{K[X]}{(f_1)}\]

Para el elemento $u = x + (f_1)$.

***** 4.1.2. Extensión de un homomorfismo
Dadas extensiones $F_1/K_1, F_2/K_2$, decimos que $\tau : F_1 \longrightarrow F_2$ es una extensión
de $\sigma : K_1 \longrightarrow K_2$, ambos homomorfismos de cuerpos, cuando $\tau|_{K_1} = \sigma$.

***** 4.1.3. Isomorfismo extendido a polinomios
Sea $\sigma : K_1 \longrightarrow K_2$ isomorfismo de cuerpos. Existe una única extensión a
un isomorfismo $\sigma : K_1[X] \longrightarrow K_2[X]$ cumpliendo que $\sigma(X) = X$.

****** Demostración
Por la propiedad universal por el anillo de polinomios. Las imágenes
de todos los elementos están fijas excepto la de $X$ y sus múltiplos.

***** 4.1.4. Isomorfismos respetan irreducibilidad
Sea $f_1 \in K_1[X]$ irreducible sobre $K_1$, entonces $\sigma(f)$ es irreducible 
sobre $K_2$; donde $\sigma$ es la [[*4.1.3. Isomorfismo extendido a polinomios][extensión]] a polinomios de un isomorfismo.

****** Demostración
Si tuviéramos $f_1 = gh$ dos polinomios no triviales, su grado se 
conservaría al aplicar el isomorfismo y tendríamos
$\sigma(f)=\sigma(g)\sigma(h)$.

***** 4.1.5. Isomorfismo de raíces de polinomios
Sea $\sigma : K_1 \longrightarrow K_2$ isomorfismo de cuerpos y sean $F_1/K_1, F_2/K_2$ 
extensiones algebraicas. Dado un homomorfismo $\tau : F_1 \longrightarrow F_2$ sobre $\sigma$;
si $u$ es raíz de $p$ entonces $\tau(u)$ es raíz de $\sigma(p)$.

****** Demostración
Por simple cálculo tomando $p(x) = a_nx^n + \dots + a_1x + a_0$:

\[ \begin{aligned}
\sigma(p)(\tau(u)) &= \sigma(a_n)\tau(u)^n + \dots + \sigma(a_1)\tau(u) + \sigma(a_0) \\ 
                   &= \tau(a_n)\tau(u)^n + \dots + \tau(a_1)\tau(u) + \tau(a_0) \\
                   &= \tau(a_nu^n + \dots + a_1u + a_0) \\
                   &= \tau(0) = 0
\end{aligned} \]

***** 4.1.6. Los endomorfismos de extensiones algebraicas son automorfismos
Sea $F/K$ una extensión algebraica y $\tau : F/K \longrightarrow F/K$ un endomorfismo
sobre $K$. Entonces $\tau$ es un automorfismo.

****** Demostración
Tenemos que es una extensión de la identidad y que preserva [[*4.1.5. Isomorfismo de raíces de polinomios][raíces]].
Por eso, dado un elemento $u \in F$, tomamos su $f = Irr(u,K)$. Y tenemos
que $\{\tau^n(u)\}_{n\in \mathbb{N}}$ es una sucesión de raíces del polinomio que, por 
inyectividad, deberá repetir los elementos en algún momento.

Tendremos $\tau^m(u)=u$ y será sobreyectiva. Nótese que estamos usando
la inyectividad de todo homomorfismo de cuerpos.

***** 4.1.7. Isomorfismo intercambiando conjugadas
Sea $\sigma : K_1 \longrightarrow K_2$ isomorfismo de cuerpos. Sea $p$ irreducible
y $u_1,u_2$ raíces de $p$ y $\sigma(p)$ en extensiones $F_1,F_2$. Entonces existe un 
único isomorfismo $\tau : K_1(u_1) \longrightarrow K_2(u_2)$ sobre $\sigma$ tal que $\tau(u_1) = u_2$.

****** Demostración
El isomorfismo buscado sale como composición:

\[K_1(u_1) \cong 
  \frac{K_1[X]}{(f_1)} \cong 
  \frac{K_2[X]}{(f_2)} \cong
  K_2(u_2)\]

***** 4.1.8. Número de extensiones
El número de extensiones $\tau : K_1[u_1] \longrightarrow F_2$ sobre $\sigma$ es el número de
raíces distintas de $\sigma(p)$ en $F_2$.

****** Demostración
Por la [[*4.1.7. Isomorfismo intercambiando conjugadas][proposición anterior]], una para cada raíz de $\sigma(p)$. Nótese
que no puede haber más porque la imagen de $u_1$ determina completamente
el morfismo y porque la imagen de raíz [[*4.1.5. Isomorfismo de raíces de polinomios][debe ser]] una raíz.

***** 4.1.9. Cuerpo de descomposición
Un $E/K$ es un cuerpo de descomposición de $f$ ssi existen $u_1,\dots,u_n \in E$ 
tales que $f = (X-u_1)\dots(X-u_n)$ y $E = K(u_1,\dots,u_n)$.

****** Caracterización
Nótese que es el mínimo en el que factoriza linealmente. Cualquier
otro en el que factorice linealmente necesita contar con sus raíces.

***** 4.1.10. Cuerpo de descomposición en una torre
Sean $K \subset F \subset E$. Si $E$ es cuerpo de descomposición de $f$ sobre $K$, 
también lo es de $f$ sobre $F$.

****** Demostración
Se cumple trivialmente:

\[ E = K(u_1,\dots,u_n) \subset F(u_1,\dots,u_n) \subset E\]

***** 4.1.11. Existencia del cuerpo de descomposición
Cualquier $f \in K[X]$ de grado $n$ tiene un cuerpo de descomposición, 
que además verifica $[F:K] \leq n!$

****** Demostración
******* Inducción: caso base
Cuando $n=1$, tenemos una raíz en el cuerpo.

******* Inducción: caso inductivo
En otro caso, por [[*4.1.1. Teorema de Kronecker][Kronecker]], tenemos que existe una extensión
en la que hay una raíz del polinomio. Tomamos esa raíz para crear
$K(u)$. Por hipótesis de inducción, hay un cuerpo de descomposición
de $f/(X-u)$ sobre $K(u)$, llamado $F$. Por último, podemos construir 
un cuerpo de descomposición con sus raíces.

Tenemos además que la raíz tiene menos grado que el polinomio:

\[ [F:K] = [F:K(u)][K(u):K] \leq (n-1)!n = n! \]

***** 4.1.12. Isomorfismo entre cuerpos de descomposición
Sean $F_1/K_1, F_2/K_2$ cuerpos de descomposición de $f \in K_1[X]$ y 
$\sigma(f) \in K_2[X]$; para $\sigma : K_1 \longrightarrow K_2$ isomorfismo. Entonces son
isomorfos.

****** Demostración
******* Caso base
Si ambos son de grado $1$ tenemos extensiones triviales y 
hemos terminado.

******* Caso inductivo
Sea $u \in F_1$ raíz de $f$. Como $Irr(u,K) \mid f$, tenemos que 
$\sigma(Irr(u,K)) \mid \sigma(f)$. Si tomamos una raíz $v$ de $\sigma(Irr(u,K))$ y 
aplicamos el [[*4.1.7. Isomorfismo intercambiando conjugadas][isomorfismo intercambiando conjugadas]] anterior,
tenemos una extensión $\tau : K_1(u) \longrightarrow K_2(v)$ que lleva una en 
otra. Ahora tomamos $f=g(X-u)$ y por inducción tenemos
un isomorfismo extendiendo hasta el cuerpo de descomposición.

***** 4.1.13. Unicidad del cuerpo de descomposición
Dos cuerpos de descomposición de $f \in K[X]$ sobre $K$ son isomorfos.

****** Demostración
Trivial aplicando lo [[*4.1.12. Isomorfismo entre cuerpos de descomposición][anterior]] al isomorfismo igualdad.

***** 4.1.23. Cuerpo de descomposición de una familia
Sea ${\cal P} \subseteq K[X]$ una familia de polinomios no constantes. Una
extensión $E/K$ es cuerpo de descomposición suyo si todo polinomio
factoriza linealmente y es además se tiene $E = K(S)$ con:

\[ S = \{ u \in E \mid \exists f \in {\cal P}: f(u)=0\} \]

***** 4.1.24. Existencia del cuerpo de descomposición de una familia
Para toda familia de polinomios existe un cuerpo de descomposición.

****** Demostración
******* Caso finito
En el caso finito, multiplicamos toda la familia para aplicar
la [[*4.1.11. Existencia del cuerpo de descomposición][existencia del cuerpo de descomposición]] al producto.

******* Caso infinito
Cuando tenemos una familia $\{ f_\lambda \mid \lambda \in \Lambda\}$. Si tomamos $I \subset \Lambda$ finito, 
podemos asignarle un cuerpo de descomposición $F_I$ tal que $I\subset J$ 
implique $F_I \subset F_J$.

Tomamos:

\[F = \bigcup_{J\text{ finito}} F_J \]

Las operaciones entre dos elementos de $F$ se definen en el menor
cuerpo que contenga a los dos.

Esto es un cuerpo de descomposición porque todo polinomio ya
descompone linealmente en cualquier $F_J$ que lo contenga; y cada
$F_J$ era ya cuerpo de descomposición de los polinomios que contenía,
así que el cuerpo de descomposición debe al menos contener a todos
los $F_J$.

***** 4.1.25. Unicidad (esencial) del cuerpo de descomposición de una familia
El cuerpo de descomposición de una familia de polinomios es único
salvo isomorfismos.

****** Demostración
******* Caso finito
Aplicamos que los cuerpos de descomposición de un polinomio
[[*4.1.13. Unicidad del cuerpo de descomposición][son isomorfos]] al polinomio producto.

******* Caso infinito
Sean $F_1,F_2$ dos cuerpos de descomposición sobre $K$ de una familia
de polinomios.

Ordenamos el siguiente conjunto por inclusión y por extensión del
isomorfismo. 

\[ (E,\tau) \leq (F,\psi) \Leftrightarrow 
(E \subset F) \wedge (\psi|_E = \tau)\]

Es una ordenación inductiva porque la unión arbitraria da una 
cota maximal de cualquier cadena:

\[ {\cal E} = 
\left\{ (E,\tau) 
\mid F_1 \supset E \supset K;\;
\tau : E/K \longrightarrow F_2/K
\right\}\]

Que sabemos no vacío por el caso finito. Sea $(F,\sigma)$ maximal. Y 
supongamos que $F \subsetneq F_1$, entonces existe alguna raíz de alguno
de los polinomios que no está en $F$. Creando un [[*4.1.7. Isomorfismo intercambiando conjugadas][isomorfismo]]
sobre $F$ que la llevara a su conjugada, contravendríamos maximalidad.

Ahora, todo $f$ de la familia descompondría en $F$ y por $\sigma$, se las
llevarían a $F_2$.

**** 4.2. Clausura algebraica
***** 4.2.1. Algebraicamente cerrado
Un cuerpo tal que toda extensión algebraica suya sea trivial es un
cuerpo algebraicamente cerrado.

***** 4.2.2. Caracterización de los algebraicamente cerrados
Equivalen las siguientes propiedades:

 1. Todo polinomio no constante tiene raíz en $K$.
 2. Todo polinomio descompone linealmente en $K$.
 3. Un polinomio es irreducible en $K$ ssi es de grado $1$.
 4. Toda extensión algebraica de $K$ es trivial.

****** Demostración
******* Implicación 1 a 2
Como $f$ tiene raíz en $K$, podemos dividirlo por $(x-u)$, para
obtener un nuevo polinomio de grado menor.

******* Implicación 2 a 3
Trivialmente.

******* Implicación 3 a 4
Sea un elemento en la extensión algebraica, su irreducible
debe ser de grado $1$, luego debe estar en el cuerpo base.

******* Implicación 4 a 1
Si algún polinomio no constante no tuviera raíz, aplicamos
[[*4.1.1. Teorema de Kronecker][Teorema de Kronecker]] para crear una extensión algebraica
no trivial.

***** 4.2.3. Infinitud de algebraicamente cerrados
Todo cuerpo algebraicamente cerrado es infinito.

****** Demostración
Si tengo un cuerpo finito $K$ formo el polinomio irreducible
siguiente, que no tiene raíces en $K$:

\[ 
f(x) = \prod_{k \in K} (x-k) + 1
\]

***** 4.2.4. Cuerpo algebraicamente cerrado de elementos algebraicos
Sea $E/K$ con $E$ algebraicamente cerrado. Los elementos algebraicos
de $E$ forman un cuerpo algebraicamente cerrado.

****** Demostración
Sabemos que [[*3.2.30. Clausura algebraica relativa][forman un cuerpo]]. Para ver que es algebraicamente cerrado
vemos que todo polinomio sobre ellos tiene una raíz en $E$, por ser
este algebraicamente cerrado. Como una raíz es algebraica, tiene
una raíz en el subcuerpo de los algebraicos.

***** 4.2.5. Clausura algebraica absoluta
Una extensión algebraica $E/K$ es la clausura algebraica (absoluta) 
si es una extensión algebraica y $E$ es algebraicamente cerrado.

***** 4.2.6. Caracterización de la clausura algebraica
Equivalen:

 1. $E/K$ clausura algebraica.
 2. $E/K$ algebraica y todo polinomio no constante $f \in K[X]$ descompone
    en factores lineales en $E[X]$.
 3. $E$ es cuerpo de descomposición de todos los polinomios no 
    constantes de $K$.
 4. $E/K$ algebraica y todo no constante tiene una raíz en $E$.

****** Demostración
******* Implicación 1 a 2
Como $E$ es algebraicamente cerrado, [[*4.2.2. Caracterización de los algebraicamente cerrados][sabemos que]] todos sus polinomios
descomponen en factores lineales en $E[X]$.

******* Implicación 2 a 3
Todo polinomio descompone. Además, todo elemento de $E$ es algebraico;
así que $K(S) = E$.

******* Implicación 3 a 1
$E$ está generado por elementos algebraicos, luego es algebraico.
Además, todo polinomio no constante descompone en él, luego
es algebraicamente cerrado por la [[*4.2.2. Caracterización de los algebraicamente cerrados][caracterización]].

******* TODO Equivalencia con 4
***** 4.2.7. Transitividad de la clausura algebraica
Sean $K \subset F \subset E$ torre de cuerpos, con $F/K$ algebraica. 
Entonces $E$ es clausura algebraica de $F$ ssi lo es de $K$.

****** Demostración
Ser algebraicamente cerrado es independiente del cuerpo base de
la extensión. Ser algebraico [[*3.2.29. Torre algebraica][equivale]] a que lo sean las dos partes.

***** 4.2.8. Teorema de Steinitz
Para todo cuerpo existe una clausura algebraica.

****** Demostración
Sabemos que [[*4.1.24. Existencia del cuerpo de descomposición de una familia][existe]] el cuerpo de descomposición de todos los polinomios
no constantes. Por la caracterización de [[*4.2.6. Caracterización de la clausura algebraica][clausura algebraica]] sabemos
que lo es.

***** 4.2.9. Unicidad esencial de la clausura algebraica
Dos clausuras algebraicas $E_1,E_2$ del mismo cuerpo $K$ son isomorfas 
sobre $K$.

****** Demostración
Tenemos unicidad de esencial de los cuerpos de descomposición,
y estos son cuerpos de descomposición de todos los polinomios
no constantes.

***** 4.2.10. Extensión de homomorfismos a algebraicas
Sea $K \subset F \subset E$ con $E/K$ algebraica. Entonces todo $\sigma : F \longrightarrow \overline{K}$ tiene
una extensión $\tau : E \longrightarrow \overline{K}$.

****** Demostración
Aplicamos Zorn sobre el siguiente conjunto ordenado para la inclusión,
sabiendo que toda cadena de cuerpos está acotada por su unión y que cada
$\sigma_i$ es extensión del anterior:

\[{\cal S} = \{(E_i,\sigma_i) \mid 
F \subset E_i \subset E;\; \sigma_i : E_i \longrightarrow \overline{K};\;
\sigma_i|_F = \sigma\}\]

Esto nos da el maximal $E_1$. Si $E_1 \subsetneq E$, tomo $u \in E - E_1$; y busco un
[[*4.1.7. Isomorfismo intercambiando conjugadas][isomorfismo]] intercambiando $u$ por una conjugada también raíz de $Irr(u,K)$.
Esto me da $(E_1,\sigma_1) \leq (E_1(u),\tau)$.

***** 4.2.11. Cardinalidad de la clausura algebraica
Sea $K$ cuerpo y $\overline{K}$ su clausura.

 1. Si $K$ es finito, $\overline{K}$ es infinito numerable
 2. Si $K$ es infinito, $\#K = \#\overline{K}$.

****** Demostración
******* Caso finito
Cuando $K$ es finito, el número de polinomios irreducibles
sobre él es infinito numerable.
******* Caso infinito
En el caso infinito, como máximo se tendrá la acotación que
da el número de polinomios, que es una unión numerable:

\[ \#\overline{K} \leq \#\left(\bigcup K^n\right) = \#K \]

*** 5. Extensiones normales y separables
**** 5.1. Elementos conjugados y extensiones conjugadas
***** 5.1.1. Elementos conjugados
Sean $u,v \in \overline{K}$, clausura algebraica. Equivalen:

  1. $Irr(u,K) = Irr(v,K)$
  2. $\exists \tau : K(u) \longrightarrow K(v)$ *isomorfismo* con $\tau(u) = v$.
  3. $\exists\sigma : K(u) \longrightarrow \overline{K}$ *homomorfismo* con $\sigma(u) = v$.
  4. $\exists \sigma : \overline{K} \longrightarrow \overline{K}$ *automorfismo* con $\sigma(u) = v$.

Morfismos manteniendo $K$. Estos elementos se llaman 
*elementos conjugados*.

****** Demostración
******* Implicación 1 a 2
Supongamos que tienen el mismo polinomio irreducible $f(X)$, 
entonces podemos construir un isomorfismo que lleve $u,v$ a 
$X + (f(X))$ para tener:

\[K(u) \cong \frac{K[X]}{(f(X))}\cong K(v)\]

******* Implicación 2 a 3 y 4
Dado el isomorfismo, lo podemos prolongar a un homomorfismo.
Y dado un homomorfismo, lo podemos [[*4.2.10. Extensión de homomorfismos a algebraicas][prolongar]] a un automorfismo 
por ser una extensión algebraica.

******* Implicación 4 a 1
Supongamos que existe el automorfismo de $\overline{K}$. Sea $f(X) = Irr(u,K)$,
y tenemos $0 = \phi(f(u)) = f(\phi(u)) = f(v)$; luego $Irr(u,K) = Irr(v,K)$.

***** 5.1.3. Extensiones conjugadas
Sean $F_1/K$, $F_2/K$ extensiones algebraicas, equivalen:

 1. $\exists \sigma: F_1 \longrightarrow F_2$ *isomorfismo* sobre $K$.
 2. $\exists \sigma : F_1 \longrightarrow \overline{K}$, *homomorfismo* sobre $K$ con $\sigma(F_1) = F_2$.
 3. $\sigma : \overline{K} \longrightarrow \overline{K}$, *isomorfismo* tal que $\sigma(F_1) = F_2$.

Estas extensiones se llaman *extensiones conjugadas*.

****** Demostración
******* Implicación 1 a 2
Extendiendo el isomorfismo se pasa de 1 a 2.

******* Implicación 2 a 3
Dado el homomorfismo, lo podemos [[*4.2.10. Extensión de homomorfismos a algebraicas][prolongar]] a un homomorfismo
por ser $\overline{K}$ algebraica. Tenemos entonces un endomorfismo de un
cuerpo algebraico, que [[*4.1.6. Los endomorfismos de extensiones algebraicas son automorfismos][debe ser]] un automorfismo.

******* Implicación 3 a 1
La restricción a $F_1$ es isomorfismo.

**** 5.2. Extensiones normales
***** 5.2.1. Extensiones normales
Sea $F/K$ extensión algebraica, subcuerpo de $\overline{K}$, equivalen:

  - $\sigma : F \longrightarrow \overline{K}$ sobre $K$, me da $\sigma(F) = F$.
  - Todo irreducible de $K[X]$ con una raíz en $F$ descompone en 
    lineales en $F[X]$.
  - $F$ es cuerpo de descomposición de una familia de polinomios
    sobre $K[X]$.

 A una extensión de este tipo se le llama *extensión normal*.

****** Demostración
******* Implicación 1 a 2
Dos raíces del mismo irreducible son conjugadas, luego existe
un [[*5.1.1. Elementos conjugados][homomorfismo]] que lleva una en otra, como debe llevar $F$ en $F$,
la otra debe estar en $F$.

******* Implicación 2 a 3
Para cada elemento de $F$ puedo tomar su irreducible, como tiene
una raíz en $F$ tiene todas. $F$ es el cuerpo de descomposición de la
familia de todos los irreducibles de sus elementos.

******* Implicación 3 a 1
Tenemos que $F = K(\alpha_1,\alpha_2,\dots)$, raíces de los polinomios. La imagen
de la raíz de un polinomio sobre $K$ debe ser raíz de ese mismo 
polinomio porque este debe quedar invariante sobre $\sigma$. Así tenemos
que $\sigma(F) \subset F$, y por ser algebraico, todo [[*4.1.6. Los endomorfismos de extensiones algebraicas son automorfismos][endomorfismo es automorfismo]].

***** 5.2.3. Propiedades de las extensiones normales
Sea $E$ extensión normal. Cumple:

 1. Si $A/K$ es algebraica, $EA/A$ es normal.
 2. Si $K \subset F \subset E$, entonces $E/F$ es normal.
 3. Si $E_1/K, E_2/K$ son normales, $E_1E_2/K$ es normal.
 4. Sea $E_\lambda$, familia de extensiones normales; $F = \bigcap E_\lambda$ es normal.

****** Demostración de 1
Dado $\sigma : EA/A \longrightarrow \overline{K}/A$, tengo que $\sigma(EA) = \sigma(E)\sigma(A) = EA$.

****** Demostración de 2
Sea $\sigma : E/F \longrightarrow \overline{K}/F$, como deja fijo $K$, debe tenerse $\sigma(E)=E$.

****** Demostración de 3
Sea $\sigma: E_1E_2/K \longrightarrow \overline{K}/K$, las restricciones dejan fijos ambos cuerpos
y $\sigma(E_1E_2) = \sigma(E_1)\sigma(E_2) = E_1E_2$.

****** Demostración de 4
Si un homomorfismo de la intersección lo extiendo y lo restrinjo a
cada uno, debe dejar todos los cuerpos fijos. Por tanto, un elemento
en la intersección debe quedarse en la intersección.

****** Contraejemplo: subcuerpo de normal no es normal
El último es cuerpo de descomposición de $x^3-2$,
pero el primero no es normal, porque no están todas las
raíces del polinomio irreducible de $\sqrt[3]{2}$.

$\mathbb{Q} 
\subset \mathbb{Q}(\sqrt[3]{2}) 
\subset \mathbb{Q}(\sqrt[3]{2}, i)$

***** 5.2.4. Clausura normal
Llamamos clausura normal de $F/K$ a:

\[ E = \bigcap \{ H \mid H \supset F;\; H/K\text{ normal}\}\]

***** 5.2.5. Existencia de la clausura normal
Para toda extensión algebraica existe una clausura normal. 

****** Demostración
Trivial porque la clausura algebraica es normal.

***** 5.2.6. Unicidad de la clausura normal
La clausura normal es única salvo isomorfismos.

****** Demostración
Sean las dos clausuras sobre la clausura algebraica absoluta.
Como son intersección de normales y ambas lo son, deben ser
la misma.

***** 5.2.7. Extensión de homomorfismos a extensión normal
Sea $K \subset F \subset E$ con $E/K$ normal. Todo $\tau : F \longrightarrow E$ extiende a
un $\tau : E \longrightarrow E$. 

****** Demostración
Tenemos que extiende a $\tau : F \longrightarrow \overline{K}$ y de ahí, por ser $E$ algebraica,
se [[*4.2.10. Extensión de homomorfismos a algebraicas][prolonga]] a $\tau : E \longrightarrow \overline{K}$. Por ser normal, $\tau(E) = E$.

***** 5.2.8. Clausura de una extensión finita
Sea $F = K(u_1,u_2,\dots,u_n)$ y $f_i = Irr(u_i,K)$; entonces la clausura normal
es el cuerpo de descomposición de $f = f_1f_2\dots f_n$.

****** Demostración
Es normal por ser cuerpo de descomposición de un polinomio, es
la mínima porque debe contener las raíces de $f_i = Irr(u_i,K)$
para ser normal, y si las contiene, debe contener al cuerpo de
descomposición de $f$.

***** 5.2.9. La clausura normal de extensión finita es finita
Sea $F/K$ finita, su clausura normal es finita.

****** Demostración
El cuerpo de descomposición anterior es finito porque puedo
crearlo insertando las raíces de cada polinomio.

***** 5.2.10. Polinomio normal
Un polinomio irreducible es normal si en toda extensión
algebraica $F/K$ con una raíz de $f$, descompone en factores 
lineales.

***** 5.2.11. Caracterización de polinomios normales
Sea $f$ un polinomio en $K[X]$, equivalen:

 1. $f$ es normal sobre $K$.
 2. El cuerpo de descomposición de $f$ es $K(u)$, una raíz de $f$.
 3. Todas las raíces de $f$ es expresan como polinomios de una de ellas.

****** Demostración
******* Implicación 1 a 2
Tenemos que en $K(u)$, $f$ descompone en factores lineales,
luego es cuerpo de descomposición.

******* Implicación 2 a 3
Trivial.

******* Implicación 3 a 1
Una extensión con una raíz $u$ contendría a $K(u)$, y como todas
las raíces se expresan como polinomios de $u$, contendría a todas
las raíces y $f$ descompondría en polinomios lineales.

**** 5.3. Extensiones separables
***** 5.3.1. Elemento separable
Un elemento algebraico $u$ es separable en $K$ si $Irr(u,K)$ no tiene 
raíces múltiples.

***** 5.3.2. Extensiones separables
Una extensión algebraica $F/K$ es *separable* si todos sus elementos 
lo son.

****** Ejemplo de extensión normal no separable
Existen [[http://math.stackexchange.com/questions/982702/example-of-a-non-separable-normal-extension][ejemplos]] de extensiones normales no separables.

***** 5.3.3. Torres separables
Si $E \supset F \supset K$ es extensión separable, lo son $E/F$ y $F/K$.

****** Demostración
Que $F/K$ es separable es trivial. Y $E/F$ es separable porque
$Irr(u,F) \mid Irr(u,K)$, y si el segundo no tiene raíces múltiples,
no puede tenerlas el primero.

***** 5.3.4. Grado separable
El *grado separable* es cardinal del conjunto de homomorfismos
de $F/K \longrightarrow \overline{K}/K$.

\[ [F : K]_s = \#\{F/K \longrightarrow \overline{K}/K\}\]

***** 5.3.5. Grado separable en torres
Sea $K \subset F \subset E \subset \overline{K}$ entonces $[E:K]_s = [E:F]_s[F:K]_s$.

****** Demostración
******* Con dos homomorfismos construyo el mayor
Dados $\sigma : F/K \longrightarrow \overline{K}/K$ y $\psi : E/F \longrightarrow \overline{K}/F$, puedo extender $\sigma$ al
algebraico $E$ para tener $\sigma^\ast : \overline{K}/K \longrightarrow \overline{K}/K$. Ahora, la composición
$\sigma^\ast \circ \psi$, me da el homomorfismo buscado.

******* Y es único
Supongamos que $\sigma^\ast \circ \psi = \sigma'^\ast \circ \psi'$; como deben ser iguales para 
cualquier $f \in F$, se tiene $\sigma = \sigma'$. Ahora, si tomamos la misma extensión
para cada elemento, $\sigma^\ast = \sigma'^\ast$ y entoces por inyectividad $\psi = \psi'$.

Así tenemos ya:

\[ [E:K]_S \geq [E:F]_S[F:K]_S \]

******* Con el mayor construyo los dos menores
Dado un $\sigma : E/K \longrightarrow \overline{K}/K$, para cada $\sigma|_F$ construyo una extensión
a la clausura, $\tau : \overline{K}/K \longrightarrow \overline{K}/K$, que es isomorfismo. Como 
es isomorfismo podemos construirle inversa para tener 
$\tau^{-1} : \overline{K}/K \longrightarrow \overline{K}/K$. A la vez, podemos extender todos los $\sigma$ a
la clausura algebraica como $\sigma^\ast$.

Ahora bien, como $\tau|_F = \sigma|_F$, tenemos que $\sigma^\ast \circ \tau^{-1}$ deja fijo a $F$. 
Así, hemos partido $\sigma$ en $\sigma^\ast \circ \tau^{-1}|_E$ y $\sigma|_F$.

******* Y son únicas
Supongamos que tenemos $\sigma|_F = \sigma'|_F$, entonces las dos extensiones $\tau$
las hemos tomado iguales. Si tenemos $\sigma \circ \tau^{-1}|_E = \sigma' \circ \tau^{-1}|_E$, como $\tau^{-1}$
es sobreyectiva, tenemos $\sigma^\ast|_E = \sigma'^\ast|_E$, y por tanto $\sigma = \sigma'$.

Así tenemos que:

\[ [E:K]_S \leq [E:F]_S[F:K]_S \]

***** 5.3.6. Relación de grado y grado separable
Sea $F/K$ extensión finita, entonces $[F:K]_s \mid [F:K]$.

****** Demostración
******* Caso simple
Sea $K(u)$ la extensión, con polinomio $Irr(u,K)$ de grado $n$. 
Si la raíz $u$ tiene multiplicidad $m$ en el polinomio, todas las
raíces del polinomio tienen la misma multiplicidad y hay
$n/m$ raíces distintas.

Cada homormofismo quedará determinado por la imagen de $u$, y
tenemos $n/m$ imágenes distintas para $u$.

******* Caso compuesto
Ahora procedemos por inducción sobre el grado de la extensión. 
Tomamos un elemento de la base y hacemos:

\[ [F:K(u)]_S[K(u):K]_S  \mid  [F:K(u)][K(u):K] \]

Lo primero es divisible por el caso simple y lo segundo por
hipótesis de inducción.

***** 5.3.7. Igualdad de grados en torres
Sea $K \subset F \subset E$, con $E/K$. Entonces $[E:K]_s = [E:K]$ ssi 
$[E:F]_s = [E:F]$ y $[F:K]_s = [F:K]$.

****** Demostración
Tenemos que deben tenerse ambos casos de igualdad en:

\[
[E:K]_S = [E:F]_S[F:K]_S \leq [E:F][F:K] = [E:K]
\]

***** 5.3.8. Caracterización de extensión separable
La extensión finita $E/K$ es separable ssi $[E:K]_s = [E:K]$.

****** Demostración
Usamos la idea de la demostración de la relación con el grado.
En el caso simple tenemos $[K(u):K]_S = [K(u):K]$ solo cuando la
multiplicidad de cada raíz es uno. En el caso compuesto exigimos
eso a cada paso.

***** 5.3.9. Extensión por un conjunto separable
Para $K(S)/K$ algebraica es separable ssi todo elemento de $S$ es
separable sobre $K$.

****** Demostración
La suma o producto de elementos separables [[http://math.stackexchange.com/a/82837/85067][es separable]].

***** 5.3.10. Propiedades de extensiones separables
Las extensiones separables cumplen:

 1. Para $K \subset F \subset E$, se tiene $E/K$ separable ssi $E/F$ y $F/K$ 
    separables.
 2. Sea $E/K$ algebraica separable y $H/K$ extensión, entonces $EH/H$ 
    es separable.
 3. Sean $E/K$ y $F/K$ separables, entonces $EF/K$ es separable.

****** Demostración
******* Punto 1
Simplemente usar que la igualdad de grados de separabilidad
se da en [[*5.3.7. Igualdad de grados en torres][torres]] y que equivale a la [[*5.3.8. Caracterización de extensión separable][separabilidad]].

******* Punto 2
Tenemos $EH/H = H(E)/H$. Que sea separable [[*5.3.9. Extensión por un conjunto separable][equivale]] a que
cada elemento de $E$ lo sea. Pero $Irr(e,H) \mid Irr(e,K)$, y si uno
tiene sólo raíces simples, el otro las tendrá también.

******* Punto 3
Tenemos $K(E,F)/K$ separable por serlo todos los elementos en 
$E,F$.

***** 5.3.11. La clausura normal de una separable es separable
Sea $F/K$ separable y $E/K$ su clausura normal. Entonces $E/K$ es
separable.

****** Demostración
Si extiendo $F$ con todas las raíces de los irreducibles de sus
elementos, tengo la clausura normal; porque debe contenerlas
y es normal, así que es la mínima. Como cada una de ellas es
separable porque tiene como irreducible el mismo irreducible
de un elemento de $F$, la [[*5.3.9. Extensión por un conjunto separable][extensión entera]] es separable.

***** 5.3.12. Clausura separable
El conjunto de todos los elementos de $\overline{K}$ separables sobre $K$ forman
un subcuerpo $K^{sep}$ que se llama *clausura separable*.

****** Demostración
La suma o producto de elementos separables es separable, como
demostramos [[*5.3.9. Extensión por un conjunto separable][anteriormente]].

***** 5.3.13. Teorema del elemento primitivo
Sea $E/K$ una extensión finita. Es simple ssi el conjunto de
cuerpos intermedios $\{ F \mid K \subset F \subset E\}$ es finito.

****** Demostración
******* Primera implicación
Sea $K(\alpha)$ simple, como es finita es algebraica, y $Irr(a,K)$ tiene 
finitos divisores en la clausura. 

Para cada divisor del polinomio irreducible creo $K[|p|]$, el subcuerpo
generado por los coeficientes del polinomio. Todo cuerpo intermedio $E$,
en el que el irreducible de $\alpha$ sea $p$ contendrá a $K[|p|]$, pero como:

\[ [K(\alpha): E] = [K(\alpha) : K[|p|]] \]

Se tendrá forzosamente $E = K[|p|]$.

******* Segunda implicación
******** Cuerpo base finito
Como la extensión es finita, tenemos que hay finitos elementos.
El grupo multiplicativo de un cuerpo finito es [[http://mathoverflow.net/a/54741/45365][cíclico]], luego es 
simple.

******** Cuerpo base infinito
Siendo $E = K(a_1,a_2,\dots,a_n)$, nos limitamos a probar $K(a,b)$ simple.
Consideramos las $K(a+xb)$ para $x \in F$. Como los elementos de $F$ son 
infinitos y las extensiones intermedias finitas, se tienen $x \neq y$
tales que $K(a+xb) = K(a+yb)$, y por tanto:

\[
b = \frac{ a +bx - (a + by)}{x-y} \in K(a+bx)
\]

****** Contraejemplo:
Hay extensiones finitas de cuerpos que no son simples

***** 5.3.13. Finita y separable es simple
Una extensión finita y separable es simple.

****** Demostración
Si es finita y separable, podemos tomar su clausura normal.
La clausura normal de una extensión finita es [[*5.2.8. Clausura de una extensión finita][finita]], así que
tengo una extensión de Galois finita. Habrá finitas subextensiones
porque habrá finitos subgrupos de Galois.

****** Contraejemplo: cuerpo finito no simple
Tenemos [[https://en.wikipedia.org/wiki/Primitive_element_theorem#Counterexamples][contraejemplos]] en característica $p$ con cuerpos de
dimensión $p^2$.

***** 5.3.14. Endomorfismo de Frobenius
Sea $K$ de característica de $p$. Llamamos *endomorfismo de Frobenius* 
a $\phi(u) = u^p$.

***** 5.3.15. Cuerpos perfectos
Para $K$ cuerpo equivalen:

  1. Todo $f \in K[X]$ irreducible tiene raíces simples.
  2. Toda $E/K$ algebraica es separable.
  3. Toda $E/K$ finita es separable.
  4. $car(K)=0$ ó $car(K)=p$, y el endomorfismo de Frobenius es 
     sobreyectivo.

Y en ese caso, llamamos a $K$ *cuerpo perfecto*.

****** Demostración
******* Implicación 1 a 2
Todo elemento de la extensión cumple algún polinomio,
y son todos separables, luego es separable.

******* Implicación 2 a 3
Trivial

******* Implicación 3 a 4
Supongamos que no fuera sobreyectivo, existe $y \neq x^p$.
Si tomamos $(x^p-y)$, tenemos que es irreducible. Y si creamos
entonces $z^p = y$ tendríamos una extensión no finita no
separable.

# TODO: ¿Por qué es irreducible? Por Eisenstein en algún cuerpo 
# raro podría tenerse.

******* Implicación 4 a 1 en característica 0
En característica $0$, un polinomio no puede dividir a su derivada,
que será de grado menor, así que un irreducible no puede tener raíces
dobles.

******* Implicación 4 a 1 en característica p
Para que un irreducible divida a la derivada, que debe ser de grado
menor, se debe tener que sea $0$. El polinomio original debe ser
de la forma $f(x^p)$ para que al derivarlo se anule.

Cuando Frobenius es automorfismo, podemos escribir:

\[f(x^p) = \sum a_i x^{ip} = \left(\sum \sqrt[p]{a_i} x^i\right)^p\]

contraviniendo irreducibilidad. Todos los polinomios deben tener
raíces simples.

***** 5.3.17. Ejemplos de cuerpos perfectos
Son perfectos:

  1. Todo cuerpo de característica cero.
  2. Todo cuerpo finito.
  3. Todo cuerpo algebraicamente cerrado.
    
****** Demostración
******* Punto 1
Trivial desde la [[*5.3.15. Cuerpos perfectos][caracterización]].
******* Punto 2
En todo cuerpo finito, un endomorfismo es sobreyectivo.
******* Punto 3
En un algebraicamente cerrado, todo irreducible es lineal y
tiene raíces simples.

**** 5.4. Derivada y raíces múltiples
***** 5.4.1. Raíces
Sea $f\in F[X]$ y $u \in F$. Es raíz de multiplicidad $k$ cuando $f = (X-u)^kf_0$,
con $f_0(u) \neq 0$.

***** 5.4.2. Derivada
Se define la derivada de $f$ como:

\[ f' = \sum_{i=1}^n ia_iX^{i-1} = na_nX^{n-1} + \dots + a_1\]

***** 5.4.3. Propiedades de la derivada
La derivada verifica:

 1. $(f+g)' = f'+g'$
 2. $(f \cdot g)' = f' \cdot g'$
 3. $(f^m)' = mf^{m-1}\cdot f'$

***** 5.4.4. Condición de raíces simples
Las raíces de $f$ son simples ssi $mcd(f,f') = 1$.

***** 5.4.5. Condición de raíces simples en irreducibles
Sea $f$ irreducible con $f' \neq 0$, las raíces de $f$ son simples.

***** 5.4.6. Propiedades de las raíces simples
Se cumple:

 1. En característica $0$, todo irreducible tiene raíces simples.
 2. En característica $p$ prima, un irreducible tiene raíces múltiples
    ssi $f(x) = g(x^p)$.

****** TODO Demostración
***** 5.4.7. Polinomio separable
Un polinomio $f \in K[X]$ se llama separable $K$ si sus factores 
irreducibles tienen sólo raíces simples.

*** 6. Teoría de Galois Finita
**** 6.1. Grupos de automorfismos
***** 6.1.1. Espacio vectorial de las aplicaciones de un conjunto
Sea $S$ un conjunto. Las aplicaciones $Fun(S,F)$ con la suma y producto
de escalares elevados desde $F$ forman un espacio vectorial de dimensión
$|S|$.

****** Demostración
Simplemente comprobar que cumplen las propiedades de espacio 
vectorial.

***** 6.1.2. Proposición al lema de Dedekind
Sean $\sigma_1,\dots, \sigma_m : G \longrightarrow F^\times$ homomorfismos desde un grupo $G$. 
Son distintos ssi son linealmente independientes sobre $F$.

****** Demostración
******* Caso base
Procedemos por inducción. Cuando $n=1$, es trivial.

******* Caso inductivo
Tomemos un subconjunto mínimo de linealmente dependientes, 
$\sigma_1,\dots,\sigma_s$. Tendríamos $b_i \in F^\times$:

\[\sigma_s = b_1\sigma_1 + \dots + b_{s-1}\sigma_{s-1}\]

Si tomamos ahora $y$ tal que $\sigma_1(y) \neq \sigma_s(y)$, evaluamos en $xy$ y 
multiplicamos por $\sigma_s(y)$ obtenemos dos ecuaciones que restadas
dan:

\[0 = b_1(\sigma_1(y)-\sigma_s(y))\sigma_1 + \dots + b_{s-1}(\sigma_{s-1}(y) - \sigma_s(y)) \sigma_{s-1}\]

Relación de dependencia no nula menor que la anterior.

***** 6.1.3. Lema de Dedekind
Un conjunto de homomorfismos de cuerpos $F_1 \longrightarrow F_2$ distintos
son linealmente independientes sobre $F_2$.

****** Demostración
Desde el lema anterior, tenemos que son linealmente independientes 
una vez restringidos a $F_1^\times \longrightarrow F_2^\times$, el añadirles el $0$ no los vuelve 
dependientes.

***** 6.1.4. Acotación del número de homomorfismos sobre K
Existen como máximo $[F:K]$ morfismos distintos sobre $K$ 
hacia cualquier otro cuerpo:

\[|Hom(F/K,E/K)| \leq [F:K]\]

****** Demostración
Sea $\{u_1,\dots,u_n\}$ base de $F$, y supongamos $n+1$ homomorfismos
distintos. El siguiente sistema de ecuaciones tiene solución 
no trivial porque tiene $n+1$ incógnitas y tiene $n$ ecuaciones.
      
\[ X_1\sigma_1(u_j) + \dots + X_{n+1}\sigma_{n+1}(u_j) = 0 
\qquad j = 1,\dots,n\]
      
Pero una solución es una relación de dependencia sobre toda la
base de $F$. Si son dependientes, por Dedekind son [[*6.1.3. Lema de Dedekind][iguales]].

***** 6.1.5. Grupo de extensión
Para toda extensión finita $F/K$ llamamos *grupo de la extensión* a:

\[ G(F/K) = \{ \sigma \in  Aut(F) \mid \forall u \in K : \sigma(u) = u\}\]

***** 6.1.6. Acotación de elementos del grupo
Para toda extensión finita $F/K$ se verifica que $|G(F/K)| \leq [F : K]$.

****** Demostración
Caso particular de la [[*6.1.4. Acotación del número de homomorfismos sobre K][acotación]] del número de homomorfismos
sobre el cuerpo.

***** 6.1.7. Cuerpo fijo
Sea $G < Aut(E)$, llamamos *cuerpo fijo* por $G$ al conjunto al que 
dejan fijos todos los elementos de $G$:

\[ E^G = \{ u \in E \mid \forall\sigma\in G: \sigma(u) = u\}\]

Es un *subcuerpo* de $E$.

****** Demostración: es un subcuerpo
Trivialmente desde la definición de automorfismo de cuerpos.

***** 6.1.8. Teorema de Artin
Para $G < Aut(E)$ finito, $[E : E^G] = |G|$.

****** Demostración
Ya tenemos $n = |G| \leq [E : E^G]$. Supongamos la desigualdad estricta 
con $u_1,\dots,u_{n+1} \in E$ independientes sobre $E^G$. Y tenemos el sistema 
de $n+1$ incógnitas y $n$ ecuaciones, sobre los $\sigma_j$ de $G$:

\[ X_1\sigma_j(u_1) + \dots + X_{n+1}\sigma_j(u_{n+1}) = 0 \qquad
j = 1,\dots,n\]
      
Sea $a_1,\dots,a_{n+1}$ una solución no trivial con número mínimo de 
elementos no nulos. Suponemos s.p.g. que $a_1 \neq 0$ y despejamos para 
tener:

\[\sigma_j(u_1) = b_2\sigma_j(u_2) + \dots + b_n\sigma_j(u_{n+1}) 
\qquad j = 1,\dots,n\]
      
En particular, en el caso $\sigma_j = id$, tenemos:

\[u_1 = b_2u_2 + \dots + b_{n+1}u_{n+1}\]

que obliga a que uno de los coeficientes no esté en $E^G$. Supongamos 
s.p.g. que $b_2 \notin E^G$, y sea $\tau \in G$ tal que $\tau(b_2) \neq b_2$. Si aplicamos ahora
$\tau$ a cada una de las ecuaciones y restamos tenemos:

\[0 = (b_2-\tau(b_2))\sigma_j(u_2) + \dots + (b_n-\tau(b_n)\sigma_j(u_{n+1}))
\qquad j = 1,\dots,n\]

Esta solución es no trivial porque $(b_2-\tau(b_2)) \neq 0$, pero tiene más 
elementos nulos que la anterior.

***** 6.1.9. Extensión de Galois
Una extensión finita $E/K$ es *de Galois* cuando:
     
\[\exists Gal(E/K) < Aut(E): E^{Gal(E/K)} = K\]

Llamamos a $Gal(E/K)$ el *grupo de Galois* de la extensión.

***** 6.1.10. Caracterización de extensión de Galois
Una extensión finita es de Galois ssi es normal y separable.

****** Demostración
Sea $Gal(E/K) = G$, entonces cada automorfismo se extiende a un 
homomorfismo $\sigma' : E/K \longrightarrow \overline{K}/K$, luego $[E:K]_S \geq |G| = [E:K] \geq [E:K]_S$, 
y por tanto la extensión es separable. Como además el número total 
de homomorfismos es $[E:K]_S = |G|$, son todos automorfismos y la 
extesión es normal.

Sea $E/K$ normal y separable. Tenemos $n = [E:K]_S = [E:K]$ 
homomorfismos $\tau : E \longrightarrow \overline{K}$ sobre $K$, con $\tau(E) = E$. Entonces 
$G = G(E/K)$ tiene orden $n$. Por Teorema de Artin, 
$[E:E^G] = n = [E:K]$, luego $[E^G:K] = 1$.

***** 6.1.11. Caracterización para extensiones finitas
Sea $F/K$ una extensión separable finita y sea $E/K$ su clausura 
normal. Entonces $E/K$ es una extensión finita de Galois.

****** Demostración
La clausura normal de una extensión separable es [[*5.3.11. La clausura normal de una separable es separable][separable]].

**** 6.2. Correspondencia de Galois, caso finito
***** Correspondencia
Definimos una correspondencia entre los subgrupos de una 
extensión de Galois y los cuerpos intermedios como:

\[ H^\ast = E^H = \{u \in E \mid \forall\sigma\in H: \sigma(u)=u\}\]
\[F^\ast = Gal(E/F) = \{\sigma\in G \mid \forall u\in F: \sigma(u) = u\}\]

***** 6.2.1. Contenidos de cuerpos
Sean $F_i$ cuerpos intermedios de $E/K$ y $H_i$ subgrupos de $Gal(E/K)$.
Se cumple:

 1. Si $F_1 \subset F_2$, entonces $F_1^\ast \supset F_2^\ast$.
 2. Si $H_1 \subset H_2$, entonces $H_1^\ast \supset H_2^\ast$.
 3. $F \subset F^\ast^\ast$; $H < H^\ast^\ast$.
 4. $F^\ast = F^\ast^\ast^\ast$; $H^\ast = H^\ast^\ast^\ast$.

****** Demostración
1. Trivial.
2. Trivial.
3. Trivial.
4. Componiendo el apartado 3 con el 2 y el 1.

***** 6.2.2. Correspondencia de Galois
El par de aplicaciones $\ast$ se llama *correspondencia de Galois*.

***** 6.2.3. Teorema fundamental
Sea $E/K$ una extensión de Galois finita con $G = Gal(E/K)$:

  1. La correspondencia es biyección, ${\cal F}(E/K) \cong {\cal S}(G)$.
  2. $A \supset B$ ssi $B^\ast \subset A^\ast$.
  3. La correspondencia es un antiisomorfismo de retículos, 
     $(F_1 \cdot F_2)^\ast = F_1^\ast \cap F_2^\ast$ y $(F_1 \cap F_2)^\ast = F_1^\ast \vee F_2^\ast$.
  4. Las extensiones $F_1/K$ y $F_2/K$ son conjugadas ssi los subgrupos
     $F_1^\ast$ y $F_2^\ast$ son conjugados en $G$.
  5. La extensión $F/K$ es normal ssi $F^\ast$ es un subgrupo normal de $G$.
     En este caso $Gal(F/K) \cong G/F^\ast$.
  6. Para $H<G$ se verifica $|H| = [E:H^\ast]$ y $[G:H]=[H^\ast:K]$. 
     Para $F \in {\cal F}(E/K)$ se verifica $[E:F] = |F^\ast|$ y $[F:K] = [G:F^\ast]$.
 
****** Demostración de 6 para grupos
Por [[*6.1.8. Teorema de Artin][teorema de Artin]] tenemos $|G| = [E:K]$ y $|H| = [E : H^\ast]$.
Por teorema de Lagrange y teorema del grado tenemos:

\[ |G| = [G:H] |H| \]
\[ [E:K] = [E:H^\ast][H^\ast : K] \]

Simplificando obtenemos $[G:H] = [H^\ast : K]$.

****** Demostración de 6 para cuerpos intermedios
Como $E/F$ es de Galois, $|F^\ast| = [E:F]$ y sabemos $|G| = [E:K]$.
Volvemos a aplicar Lagrange y teorema del grado.

****** Demostración de 1
Tenemos la torre $G > H^\ast^\ast > H$ y:

\[ [G : H^\ast^\ast] = [H^\ast^\ast^\ast : K] = [H^\ast : K] = [G : H] \]

Tenemos la torre $E \supset F^\ast^\ast \supset F$ y:

\[ [E:F] = |F^\ast| = |F^\ast^\ast^\ast| = [E : F^\ast^\ast] \]

****** Demostración de 2 y 3
Se cumple por ser biyección y la proposición anterior. Trivial
desde esto el antiisomorfismo de retículos.

****** Demostración 4
Sean $F_2 = \sigma(F_1)$, para $\tau \in F_1^\ast$, tenemos $\sigma\tau\sigma^{-1} \in F_2^\ast$.
Luego $\sigma F_1^\ast \sigma^{-1} \subset F_2^\ast$. Aplicando lo mismo sobre $\sigma^{-1}$ llegamos
a la otra igualdad. Dando la vuelta al razonamiento, tenemos
que $\sigma F_1^\ast \sigma^{-1} = F_2^\ast$ nos da $F_2 = \sigma(F_1)$.

****** Demostración 5
Desde el cuarto apartado, se conserva normalidad.

Si aplicamos primer Teorema de Isomorfía a la restricción
$\Phi : Gal(E/K) \longrightarrow Gal(F/K)$:

\[ \frac{Gal(E/K)}{F^\ast} 
= \frac{Gal(E/K)}{\ker(\Phi)} 
\cong \im(\Phi) 
= Gal(F/K) \]

El que $\im(\Phi) = Gal(F/K)$ usa la normalidad de $F$.

**** 6.4. Propiedades de las extensiones de Galois
***** 6.4.1. Subgrupos en Galois
Sean $E \supset F \supset K$ con $E/K$ Galois finita. Entonces $E/F$ es Galois
finita y $Gal(E/F)$ es subgrupo de $Gal(E/K)$.

****** Demostración
La finitud se tiene trivialmente. La normalidad se tiene
sobre cuerpos [[*5.2.3. Propiedades de las extensiones normales][intermedios]] y la separabilidad [[*5.3.10. Propiedades de extensiones separables][también]]. Y sabemos
que normal y separable es de [[*6.1.10. Caracterización de extensión de Galois][Galois]].

Que uno es subgrupo de otro está claro por las propiedades de la
[[*6.2.3. Teorema fundamental][correspondencia]].

***** 6.4.2. Extensiones abelianas, cíclicas y solubles
Una extensión finita se dice *abeliana, cíclica o soluble* si es
de Galois y su grupo lo es.

***** 6.4.3. Subgrupos abelianos, cíclicos y solubles
Sea $E\supset F\supset K$ con $E/K$ finita y *abeliana, cíclica o soluble*,
entonces $E/F$ también es abeliana, cíclica o soluble, respectivamente.

****** Demostración
Tenemos que el subgrupo de un abeliano, cíclico o soluble
es también abeliano, cíclico o soluble.

***** 6.4.4. Subextensiones finitas abelianas y cíclicas
Sean $K \subset F \subset E$ torre de extensiones *finitas*:

 1. Si $E/K$ es Galois abeliana, $F/K$ es Galois abeliana.
 2. Si $E/K$ es Galois cíclica, $F/K$ es Galois cíclica.

****** TODO Demostración

***** 6.4.5. Galois para cuerpos compuestos
Sea $E/K$ Galois finita y $F/K$ extensión con $E,F \subset L$.
Entonces $EF/F$ y $E/(E\cap F)$ son extensiones finitas de Galois.
Además la aplicación restricción $\sigma \mapsto \sigma|_E$ define un isomorfismo:

\[ \bullet|_E : Gal(EF/F) \longrightarrow Gal(E/(E\cap F)) < Gal(E/K) \]

****** TODO Demostración

***** 6.4.6. Relación de Galois con el grado
Sea $E/K$ extensión finita de Galois y sea $F/K$ con $E,F \subset L$.
Entonces $[EF:F] \mid [F:K]$.

****** TODO Demostración

***** 6.4.8. Composición de extensiones de Galois
Sean $E_1/K$, $E_2/K$ extensiones Galois finitas con $E_1,E_2 \subset L$.
Entonces $E_1E_2/K$ es extensión finita de Galois y existe un
monomorfismo restricción:

\[
\lambda : Gal(E_1E_2/K) 
\longrightarrow 
Gal(E_1/K) \times Gal(E_2/K)
\]

Cuando además tenemos $E_1 \cap E_2 = K$, $\lambda$ es un isomorfismo.

****** TODO Demostración
***** 6.4.9. Extensión del producto
Sean $E_i/K$ extensiones contenidas en un $L$ con grupos de Galois
$G_1,G_2,\dots,G_n$. Si cumplendemás $E_i \cap (E_1E_2\dots E_{i-1}) = K$, entonces:

\[Gal(E_1E_2\dots E_n/K) \cong G_1 \times G_2 \times \dots \times G_n\]

****** TODO Demostración
***** 6.4.10. Cuerpos fijos del producto
Sea $E/K$ una extensión finita de Galois con grupo $G = G_1 \times \dots \times G_n$.
Sea $E_i$ el cuerpo fijo de $G_1 \times \dots \times \{1\} \times \dots \times G_n$. Entonces $E_i/K$ es
de Galois con grupo $Gal(E_i/K) = G_i$, $E_i \cap (E_1\dots E_{i-1})$ y $E=E_1\dots E_n$.

****** TODO Demostración

*** 7. Cuerpos finitos
**** 7.1. Estructura de los cuerpos finitos
***** 7.1.1. Propiedades de un cuerpo finito
Sea $F$ cuerpo finito con $|F| = q$,

  1. $car(F) = p$ es un primo.
  2. El cuerpo primo es $\mathbb{Z}/p\mathbb{Z}$.
  3. $F/\mathbb{Z}_p$ es extensión finita.
  4. $[ F : \mathbb{Z}_p] = n$, entonces $|F| = p^n$.
  5. $F^\times$ es cíclico de orden $|F|-1$.
 
****** Demostración
******* Punto 1
No puede tener característica nula por ser finito, luego debe
ser un primo.

******* Punto 2
Ya que tiene característica prima.

******* Punto 3
Ya que $F$ es finito.

******* Punto 4
Si tiene una base de $n$ elementos, debe tener $p^n$ combinaciones
de elementos básicos.

******* Punto 5
Todo subgrupo finito del grupo multiplicativo de un cuerpo es 
cíclico.

***** 7.1.2. Clasificación de cuerpos finitos
Dos cuerpos finitos del mismo cardinal son isomorfos. De hecho,
son el cuerpo de descomposición de $X^{|F|} - X$ sobre $\mathbb{F}_p$.

****** Demostración
Al ser [[*7.1.1. Propiedades de un cuerpo finito][cíclico]] $u^{q-1} = 1$ nos da $u^q-u = 0$ con todo el cuerpo
como raíces.

***** 7.1.3. Existencia de cuerpos finitos
Dado $p$ primo, existe cuerpo de $p^n$ elementos.

****** Demostración
Sea $f(x) = x^{p^n}-x$ polinomio en $\mathbb{Z}_p$. Su derivada, $-1$, no tiene raíces,
luego tiene sólo raíces simples. Veamos que con sólo añadir esas
raíces del polinomio, llega a ser cuerpo de descomposición.

Sean $u,v$ raíces:

 - $(u+v)^{p^n} - (u+v) = u^{p^n}-u+v^{p^n}-v = 0$
 - $(uv)^{p^n}-uv = u^{p^n}v^{p^n} - uv = 0$
 - $(-u)^{p^n} - (-u) = 0$
 - $(u^{-1})^{p^n} - u^{-1} = 0$

***** 7.1.4. Teorema de Moore
Para cada $p^n$ existe exactamente un cuerpo con $p^n$ elementos; 
que es el cuerpo de descomposición de $x^{p^n}-x$ sobre $\mathbb{Z}_p$. 
No existen otros cuerpos finitos.

****** Demostración
Sabemos los cuerpos [[*7.1.1. Propiedades de un cuerpo finito][deben]] tener cardinal $p^n$ y que dos cuerpos
con el mismo cardinal son [[*7.1.2. Clasificación de cuerpos finitos][isomorfos]]. Además, sabemos que
[[*7.1.3. Existencia de cuerpos finitos][existe]].

***** 7.1.5. Cuerpos de Galois
Notamos por $GF(p^n)$ o $\mathbb{F}_{p^n}$ al único cuerpo con esa cardinalidad,
lo llamamos cuerpo de Galois de orden $p^n$.

***** 7.1.6. Cuerpo extensión
Para $\mathbb{F}_q$ cuerpo finito, exíste un único cuerpo de extensión de grado $n$,
que es $\mathbb{F}_{q^n}$.

****** Demostración
Por el teorema de Moore, $q = p^m$, y sólo hay uno de $p^{nm}$ elementos.

***** 7.1.7. Grupo de automorfismos
El grupo $Aut(\mathbb{F}_{p^n}) \cong \mathbb{Z}_n$ es cíclico y está generado por el [[*5.3.14. Endomorfismo de Frobenius][Endomorfismo de 
Frobenius]].

****** Demostración
El cuerpo fijo bajo el endomorfismo de Frobenius son los $p$ 
elementos cumpliendo $a^p = a$, es decir, el cuerpo base $\mathbb{F}_p$.

El generado debe ser su grupo de Galois, ya que tiene orden $n$.

***** 7.1.8. Grupo de automorfismos relativo
Un $\mathbb{F}_{p^n}$ es subcuerpo de $\mathbb{F}_{p^m}$ ssi $n\;|\;m$. En este caso, $\mathbb{F}_{p^m}/\mathbb{F}_{p^n}$ es cíclica
con $Gal(\mathbb{F}_{p^m}/\mathbb{F}_{p^n}) = \langle \phi^n \rangle$.

****** Demostración
******* Si es subcuerpo, divide
Por Lagrange, $[\mathbb{F}_{p^n} : F] | [\mathbb{F}_{p^m} : F]$.

******* Si divide, es subcuerpo
El $Gal(\mathbb{F}_{p^m}/\mathbb{F}) \cong \mathbb{Z}_m$ tiene un único subgrupo de orden $n$. Y debe
ser el grupo de Galois de un cuerpo de orden $m/n$, que tiene por
Moore que ser $\mathbb{F}_{p^n}$.

**** 7.2. Factorización de polinomios
***** 7.2.1. Listado de polinomios irreducibles
Los factores irreducibles de $X^{p^n} - X$ son exactamente los polinomios
irreducibles de $\mathbb{F}_p[X]$ con grado divisor de $n$.

****** Demostración
******* Los factores irreducibles tienen grado n
Cuando $g(\alpha) = 0$, por ser factor tenemos $\alpha^{p^n} = \alpha$, luego $\alpha \in \mathbb{F}_{p^n}$.
Así, $\mathbb{F}_{p^n} \supseteq \mathbb{F}_p(\alpha) \supseteq \mathbb{F}_p$, y por teorema del grado, $gr(g) = [\mathbb{F}_p(\alpha) : \mathbb{F}_p]$
divide a $[\mathbb{F}_{p^n} : \mathbb{F}_p]$.

******* Los irreducibles de grado divisor de n son factores
Sea $g(\alpha) = 0$, tomamos $m = [\mathbb{F}_p(\alpha) : \mathbb{F}_p] = gr(g)$, y [[*7.1.8. Grupo de automorfismos relativo][sabemos]] que
debe tenerse $\mathbb{F}_{p^m} \supset \mathbb{F}_p(\alpha)$. Por Moore $f(\alpha) = 0$ y $g \mid f$.

***** 7.2.2. Número de mónicos irreducibles
Para $n$ primo, el número de mónicos irreducibles de $\mathbb{F}_p[X]$ de grado $n$
es $(p^n-p)/n \neq 0$.

****** TODO Demostración

***** 7.2.3. Raíces simples
Para $f \in \mathbb{F}_p[X]$, $f_1 = f / mcd(f,f')$ tiene todas las raíces simples y
$f(\alpha) = 0 \iff f_1(\alpha) = 0$.

****** Demostración
Calculando vemos que $f = \prod_i(X-\alpha_i)^{k_i}$ da $f_1 = \prod_{i} (X- \alpha_i)$.

***** 7.2.4. Producto de factores irreducibles de grado n
El producto de todos los factores irreducibles distintos de un $f$
y cuyo grado divida a $n$ es $mcd(f, X^{p^n} - X)$.

****** TODO Demostración

**** TODO 7.3. Ilustraciones
*** 8. Extensiones ciclotómicas
**** 8.1. Raíces de la unidad
***** 8.1.1. Subgrupos finitos del grupo multiplicativo
Todo subgrupo finito del grupo multiplicativo $K^\times$ es cíclico.

****** Demostración
Si $n = mcm\{ord(\alpha) \mid \alpha \in G\} = \max\{ord(\alpha) \mid \alpha \in G\}$, tenemos que
debe ser $n = |G|$. En caso contrario se tendría $X^n-1$ con más de
$n$ raíces.

***** 8.1.2. Raíces n-ésimas
Si llamamos $\mu_n(K) = \{ \zeta \in K \mid \zeta^n = 1 \}$, $\mu_n(K)$ es un grupo cíclico finito
con $|\mu_n(K)| \leq n$.

****** Demostración
Trivial por el orden del polinomio $\zeta^n-1$.

***** 8.1.3. Grupo de raíces n-ésimas
Llamamos *grupo de raíces n-ésimas* de la unidad al grupo siguiente. 
Cualquier generador del grupo se llama una *raíz primitiva* de la 
unidad.

\[ \mu_n(\overline{K}) = \{\zeta\in \overline{K} \mid \zeta^n = 1\} \]

***** 8.1.4. Lema de división
Tenemos $d\mid n$ ssi $\mu_d \subset \mu_n$.

****** TODO Demostración
**** 8.2. Polinomios ciclotómicos
***** 8.2.1. Polinomio ciclotómico
Se llama *polinomio ciclotómico* al polinomio:

\[\Phi_n = \prod_{\zeta \text{ primitiva}} (X -\zeta)\]

***** 8.2.2. Grado del polinomio ciclotómico
Se cumple que $\operatorname{grad}(\Phi_n) = \phi(n)$.

****** Demostración
El grupo de las raíces n-ésimas es cíclico y de orden $n$, y tendrá
exactamente $\phi(n)$ generadores.

***** 8.2.3. Lema al cálculo de polinomios ciclotómicos
Tenemos:

\[X^n-1 = \prod_{d \mid n} \Phi_d\]

****** TODO Demostración
***** 8.2.4. Cálculo de los polinomios ciclotómicos
 Tenemos:

 \[\Phi_n  = \frac{X^n-1}{\prod_{d|n, d\neq n} \Phi_d}\]

****** Demostración
Aplicando la fórmula [[*8.2.3. Lema al cálculo de polinomios ciclotómicos][anterior]].

***** 8.2.7. El polinomio ciclotómico es mónico
El polinomio ciclotómico es mónico $\Phi_n$ y tiene coeficientes en el
anillo primo.

****** TODO Demostración
***** 8.2.8. Función de Möbius
Se define la *función de Möbius*, $\mu : \mathbb{N} \longrightarrow \mathbb{Z}$, como:

\[\mu(n) = \threepartdef
{0}{\exists p: \text{ primo con } p^2|n}
{(-1)^r}{n = p_1p_2\dots p_n \text{ primos distintos}}
{1}{n=1}\]

***** 8.2.8. Función de Möbius en la unidad
La función de Möbius verifica que:

\[ \sum_{d \mid n} \mu(d) =
\left\{\begin{array}{ll} 
1 & \mbox{if } n=1  \\
0 & \mbox{if } n \neq 1 
\end{array}
\right.
\]

****** TODO Demostración

***** 8.2.10. Reglas de cálculo de polinomios ciclotómicos
1. Si $p$ es primo $\Phi_p(X) = X^{p-1} + X^{p-2} + \dots + X + 1$.
2. $\Phi_{p^e}(x) = \Phi_p(x^{p^{e-1}})$
3. $\Phi_{p_1^{e_1}p_2^{e_2}\dots p_r^{e_r}}(x) = \Phi_{p_1\dots p_r}(x^{p_1^{e_1-1}\dots p_r^{e_r-1}})$
4. $\Phi_n = \prod_{d\mid n} (x^{n/d}-1)^{\mu(d)}$

**** 8.3. Extensiones ciclotómicas
***** 8.3.1. Extensión ciclotómica
Llamamos n-ésima extensión ciclotómica de $K$ a $K(\zeta)/K$, donde
$\zeta$ es una raíz primitiva de la unidad en la clausura.

***** 8.3.2. Grado en los racionales
En los racionales, $[\mathbb{Q}(\zeta) : \mathbb{Q}] = \phi(n)$.

****** TODO Demostración

***** 8.3.3. Irreducibilidad racional del polinomio ciclotómico
$\Phi_n$ es irreducible en $\mathbb{Z}[X]$ (y en $\mathbb{Q}[X]$).

****** TODO Contraejemplo general
****** TODO Demostración
***** 8.3.4. Irreducibilidad en cuerpo base primo
El cuerpo $\mathbb{F}_p$ contiene una raíz n-ésima primitiva de la unidad
ssi $p \equiv_n 1$.

****** Demostración
Si contiene una raíz n-ésima primitiva, debe cumplir $\zeta^n = 1$, y a su
vez tener orden $p-1$, luego $n \mid p-1$. Si $n\mid p-1$, como $\mathbb{Z}_p^\times$ es
cíclico, tiene un elemento de orden $n$, que será raíz primitiva de la
unidad.

***** 8.3.5. Primos congruentes a 1
Para todo $n$ existen infinitos primos congruentes a $1$ módulo $n$.

****** TODO Demostración
***** 8.3.6. Torre de extensiones ciclotómicas
Sean $n \mid m$, entonces $\mathbb{Q}(\zeta_n) \subset \mathbb{Q}(\zeta_m)$.

****** TODO Demostración
***** 8.3.7. Producto de extensiones ciclotómicas
Sean $n,m$ y raíces primitivas distintas:

\[\mathbb{Q}(\zeta_n)\mathbb{Q}(\zeta_m) = \mathbb{Q}(\zeta_{mcm(n,m)})\]

****** TODO Demostración

***** 8.3.8. Intersección de extensiones ciclotómicas
Sean $n,m$ primos relativos, $\mathbb{Q}(\zeta_n) \cap \mathbb{Q}(\zeta_m) = \mathbb{Q}$.

****** TODO Demostración
**** 8.4. Grupos de Galois
***** 8.4.1. Extensión ciclotómica es de Galois
La extensión ciclotómica $K(\zeta)/K$ es una extensión de Galois.

****** Demostración
Es normal porque está generada por $X^n-1$, ya que la raíz primitiva
genera a todas sus raíces. Como trabajamos con la hipótesis de que
$car(K) \nmid n$, todas las raíces de la unidad son distintas y el polinomio
es separable.

***** 8.4.2. Grupo de galois de la extensión ciclotómica
El grupo de Galois de la extensión ciclotómica es un subgrupo
de un multiplicativo, $Gal(K(\zeta)/K) < \mathbb{Z}_n^\times$.

****** Demostración
Todo $\sigma \in Gal(K(\zeta)/K)$ está determinado por su efecto sobre $\sigma(\zeta) = \zeta^a$,
que debe llevar una raíz primitiva en otra. Comprobamos que $\Lambda(\sigma) = a$
es un homomorfismo inyectivo y aplicamos Primer teorema de Isomorfía:

\[\Lambda(\sigma) = a;\; \Lambda(\tau) = b; 
\qquad
\tau\sigma(\zeta) = \zeta^{ab}\]

Donde $a \in \mathbb{Z}^\times_n$ porque debe poder invertirse por otra función.

***** 8.4.3. Grupo abeliano de la extensión ciclotómica
En general $Gal(K(\zeta)/K)$ es abeliano.

****** Demostración
Es subgrupo de un abeliano.

***** 8.4.4. Grupo de la extensión ciclotómica en los racionales
Tenemos $Gal(\mathbb{Q}(\zeta)/\mathbb{Q}) \cong \mathbb{Z}_n^\times$.

****** TODO Demostración

***** 8.4.11. Teorema de Kronecker-Weber
Toda extensión abeliana de $\mathbb{Q}$ está contenida en una extensión 
ciclotómica.

***** 8.4.12. Existencia de extensiones
Sea $G$ un grupo abeliano finito arbitrario. Existe una extensión $K/\mathbb{Q}$
tal que $Gal(K/\mathbb{Q}) \cong G$.

*** 10. Extensiones cíclicas y radicales
**** 10.1. Extensiones cíclicas
***** 10.1.1. Extensión cíclica
Una extensión es cíclica si es de Galois con grupo cíclico.

***** 10.1.2. Teorema de Lagrange
Sea $K$ cuerpo y $n$ un primo relativo a $car(K)$. Supongamos que existe
una raíz n-ésima de la unidad en $K$:

  1. Dada $E/K$ extensión cíclica de grado $n$, existe $\alpha \in E$ tal que
     $E = K(\alpha)$ y $Irr(\alpha,K) = X^n-a$ para algún $a \in K$.
  2. Para $a \in K$, con $\alpha$ raíz de $X^n-a$, se tiene $K(\alpha)/K$ cíclica
     de grado $d \mid n$ y $\alpha^d \in K$.

****** Demostración
******* Primer punto
Sea $E = K(u)$, $Gal(E/K) = \langle\sigma\rangle$ y $\zeta$ raíz n-ésima primitiva de la 
unidad. Llamamos *resolvente de Lagrange* a:

\[
\alpha = 
u + \zeta\sigma(u) + \zeta^2\sigma^2(u) + \dots + \zeta^{n-1}\sigma^{n-1}(u)
\]

Y por independencia lineal de los homomorfismos, sabemos $\alpha \neq 0$.
Aplicando $\sigma$ obtenemos:

\[\begin{aligned}
\sigma(\alpha) &= 
\zeta^{n-1}\sigma^n(u) + \sigma(u) + 
\zeta\sigma^2(u) + \dots + \zeta^{n-2}\sigma^{n-1}(u)
\\&=
\zeta^{-1}\alpha
\end{aligned}\]

Luego $\sigma^{i}(\alpha) = \zeta^{-i}\alpha$ y $\alpha$ tiene $n$ conjugados. Como $[K(\alpha):K] \geq n$,
tenemos $E = K(\alpha)$. Además $\sigma(\alpha^n) = (\zeta\alpha)^n = \alpha^n$, luego $a = \alpha^n$ es
fijo bajo $\sigma$ y debe ser $a \in K$.

******* Segundo punto
******** Es de Galois
Todas las $\zeta^i\alpha$ son raíces disintas, luego $K(\alpha)$ es el cuerpo de
descomposición del polinomio $X^n-a$ y es normal y separable por
ser $n$ primo relativo a $car(K)$.

******** Es cíclica
Cada $\sigma \in Gal(K(\alpha)/K)$ se escribe como $\sigma(\alpha) = \omega_\sigma\alpha$ para alguna raíz
de la unidad, ya que debe llevar $\alpha$ en otra raíz y queda determinado
por ella. Así $\sigma \longrightarrow \omega_\sigma$ es un monomorfismo en el grupo de las raíces 
n-ésimas, que sólo tiene como subgrupos cíclicos de orden $d \mid n$. 

Si $Gal(K(\alpha)/K)$ es cíclico de orden $d$ generado por $\langle\sigma\rangle$, entonces $\omega_\sigma$ 
es raíz d-ésima primitiva de la unidad. Entonces:

\[\sigma(\alpha^d) = (\omega_\sigma\alpha)^d = \alpha^d\]

Quedando fijo sobre el grupo de Galois, $\alpha^d \in K$.

**** 10.2. Extensiones solubles y radicales
***** 10.2.1. Extensión soluble
Una extensión separable $F/K$ es soluble si hay una extensión $E/K$ de 
Galois con grupo soluble y $K < F < E$.

****** Definición equivalente
Una extensión separable es soluble si su clausura normal tiene grupo
de Galois soluble.

***** 10.2.2. Extensión soluble por radicales
Una extensión $F/K$ finita separable es soluble por radicales cuando
$mcd([F:K],car(K)) = 1$ y hay una torre:

\[K = E_0 < E_1 < \dots < E_m = E\]

cumpliendo $F < E$ y siendo cada $E_{i+1}/E_i$ de una de estas dos formas:

  1. $E_{i+1} = E_i(\zeta)$ raíz de la unidad.
  2. $E_{i+1} = E_i(\alpha)$ raíz de un polinomio $X^n-a \in E_i[X]$, con 
     $mcd(n,car(K)) = 1$.

***** 10.2.3. Propiedades de las solubles por radicales
Sea $F/K$ soluble por radicales:

  1. Dada $L > K$, $FL/L$ es soluble por radicales.
  2. Dada $L > F > K$, $L/K$ soluble por radicales ssi $F/K, L/F$ solubles
     por radicales.
  3. $F/K, L/K$ solubles por radicales da $FL/K$ soluble por radicales.

****** TODO Demostración

***** 10.2.4. Caracterización de solubilidad por radicales
Sea $F/K$ separable finita. Es soluble por radicales ssi existe:

\[L_0 < L_1 < \dots < L_m = L > F\]

Con cada paso soluble por radicales y $L/K$ Galois.

****** TODO Demostración

***** 10.2.5. Teorema de Galois
Sea $F/K$ separable finita. Es soluble por radicales ssi es soluble.

****** TODO Demostración

***** 10.2.6. Propiedades de las solubles
Cumplen:

  1. Dada $L > F > K$, $L/K$ soluble ssi $F/K,L/F$ solubles.
  2. Dada $F/K$ soluble $L/K$ arbitraria, $FL/L$ es soluble.
  3. Dadas $F/K,L/K$ solubles, $FL/K$ es soluble.

****** TODO Demostración
Aplicando el [[*10.2.5. Teorema de Galois][Teorema de Galois]] a las propiedades de [[*10.2.3. Propiedades de las solubles por radicales][solubles por 
radicales]].

*** 11. Polinomios de grado 3 y 4
**** 11.1. El grupo de un polinomio
***** 11.1.1. Grupo de un polinomio
Llamamos grupo del polinomio $f$ al grupo $Gal(f/K)$, dado por las 
permutaciones de raíces del polinomio que da el grupo de Galois sobre
su cuerpo de descomposición. Se tiene:

\[Gal(f/K) \lhook\joinrel\relbar\joinrel\rightarrow S_n\]

**** 11.2. Los teoremas clasificatorios
***** 11.2.1. Ceros bajo la misma órbita
Sea un polinomio con raíces simples factorizado $f = f_1f_2\dots f_r \in K[X]$.
Dos ceros $\alpha_i,\alpha_j$ son raíces del mismo $f_k$ ssi están en la misma órbita
bajo $Gal(f/K)$.

****** Demostración
Si están en la misma órbita, hay morfismo que lleva una en otra, luego
son conjugadas y tienen el mismo irreducible. Si son conjugadas existe
el morfismo que lleva una en otra y están bajo la misma órbita.

***** 11.2.2. Criterio de irreducibilidad de Galois
El polinomio $f$ es irreducible sobre $K$ ssi $Gal(f/K)$ es un subgrupo
transitivo de $S_n$.

****** Demostración
Serán todas sus raíces del mismo irreducible ssi sólo hay una órbita.

***** 11.2.3. Discriminante fijo bajo permutaciones pares
Supongamos que $f$ no tiene raíces múltiples y sea $car(K) \neq 2$. Sea:

\[\delta = \prod_{i < j} (\alpha_i - \alpha_j)\]

El cuerpo fijo bajo las permutaciones pares de $Gal(f/K)$ es $K(\delta)$.

****** Relación con el discriminante
Observamos que $(a_n^{n-1}\delta)^2 = Disc(f)$.

****** Demostración
Llamamos $F$ al cuerpo fijo bajo las permutaciones pares.
Para cualquier permutación impar $\rho(\delta) = -\delta$ y para cualquiera
par $\sigma(\delta) = \delta$, así que $K \subset K(\delta) \subset F$. Tenemos dos casos:

  - $K = F$, que daría el resultado.
  - $K \neq F$, donde por Galois, $G \neq G^+$ y debería tenerse $[G : G^+] = 2$,
    luego $[F : K] = 2$. Pero como una permutación impar cambia el signo
    del determinante, que no es nulo por definición, $\delta \notin K$, y por
    tanto $F = K(\delta)$.

Nótese que en $car(K)=2$, el cambio de signo no hubiera movido a $\delta$.

***** 11.2.4. Determinante marcando paridad
El grupo de un polinomio es sólo par $Gal(f/K) < A_n$ ssi $\sqrt{Disc(f)} \in K$.

****** Demostración
Es lo que marca la distinción de casos en la anterior demostración.

**** 11.3. Polinomios de grado pequeño
***** 11.3.1. Polinomios de grado 2
En un polinomio de grado 2 el discriminante vale $b^2 - 4ac$. Hay sólo
dos posibilidades:

  - $\sqrt{b^2-4ac} \in K$, entonces $Gal(f/K) = 1$, y tiene dos raíces en el 
    cuerpo. 
  - $\sqrt{b^2-4ac} \notin K$, entonces $Gal(f/K) = S_2$, y el polinomio es 
    irreducible.

El cuerpo de descomposición es $E = K\left(\sqrt{Disc(f)}\right)$.

****** Demostración
Nótese que en ambos casos el cuerpo que dejan fijo las permutaciones
pares es todo el cuerpo de descomposición del polinomio.

***** 11.3.2. Polinomios de grado 3
Un polinomio mónico $f = X^3+b_2X^2+b_1X +b_0$ puede:

  - Ser reducible, con algún factor lineal que nos lleva al caso de
    grado 2.
  - Ser irreducible.

En el caso irreducible:

  - $\sqrt{Disc(f)} \notin K$ ssi $Gal(f/K)=S_3$.
  - $\sqrt{Disc(f)} \in K$ ssi $Gal(f/K) = A_3$.

***** 11.3.3. Polinomios de grado 4
Tenemos un polinomio de grado 4 dado por:

\[
f = X^4 + a_3X^3+ a_2X^2 + a_1X + a_0 = \prod_{i=1}^4 (X - \alpha_i)
\]

****** Cuártica reducible
Pueden darse dos casos:

  1. Se descompone en polinomios de grado 3 y 1; y tenemos una cúbica
     como en el caso anterior.
  2. Se descompone en $f = f_1f_2$, por lo que debe ser subgrupo de
     $\langle (1\ 2),(3\ 4) \rangle$. Se distinguen dos casos usando discriminante:

     - $H = \langle (1\ 2)(3\ 4) \rangle$ cuando el discriminante está
       en el cuerpo $\sqrt{Disc(f_1)Disc(f_2)} \in K$.

     - $H = \langle (1\ 2),(3\ 4)\rangle$ cuando el discriminante no está
       en el cuerpo $\sqrt{Disc(f_1)Disc(f_2)} \notin K$.

****** Cuártica irreducible
El grupo es uno de los grupos transitivos de $S_4$:

\[\begin{tikzcd}
& S_4 \dlar[no head]\drar[no head] & & \\
A_4 \drar[no head] & & D_4 \dlar[no head]\drar[no head] & \\
& V & & C_4
\end{tikzcd}\]

Para ayudarnos a resolver el polinomio debemos creamos su 
*resolvente cúbica*, dados:

  - $\beta_1 = \alpha_2\alpha_3 + \alpha_1\alpha_4$
  - $\beta_2 = \alpha_1\alpha_3 + \alpha_2\alpha_4$
  - $\beta_3 = \alpha_1\alpha_2 + \alpha_3\alpha_4$

El polinomio que los tiene como raíces es de grado 3 y tiene
el mismo determinante. Puede calcularse con polinomios simétricos:

\[\begin{aligned}
g &= (X-\beta_1)(X-\beta_2)(X-\beta_3) \\
  &= X^3 - a_2X^2 + (a_1a_3 - 4a_0)X + (4a_2a_0 - a_3^2a_0 - a_1^2)
\end{aligned}\]

Nótese que $H < D_4$ o conjugado si $\beta_2 \in K$ o alguno de los otros.
Usando eso y que el discriminante nos da las permutaciones pares:

\[\begin{array}{ccc|c}
\sqrt{Disc(g)} & \beta_i & Gal(g/K) & Gal(f/K) \\
\hline
\notin K & \notin K & S_3 & S_4 \\
\in K & \notin K & A_3 & A_4 \\
\in K & \in K & 1 & V \\
\notin K & \in K & S_3 & D_4,C_4
\end{array}\]

******* Distinción de los últimos casos
Observamos que $D_4 \cap A_4 = V$ es transitivo pero $C_4 \cap A_4 = \langle (13)(24) \rangle$ 
no lo es. Así que $Gal(f/K) = D_4$ ssi $f$ es irreducible sobre
$K\left(\sqrt{Disc(f)}\right)$.

**** TODO 11.4. Cómo resolver una ecuación soluble

*** A. Norma y traza
**** Norma y traza
***** Norma
Se define la *norma* de $\alpha$ relativa a $F/K$ separable como:

\[N_{F/K} = \prod \{\sigma_i(\alpha) \mid 1\leq i\leq n\} \]

para los $n$ homomorfismos que da $[F:K]_S$.

***** Traza
Se define la *traza* de $\alpha$ relativa a $F/K$ separable como:

\[T_{F/K} = \sum \{\sigma_i(\alpha) \mid 1 \leq i \leq n\}\]

para los $n$ homormorfismos que da $[F : K]_S$.

***** Norma y traza están en el normal
Si $F/K$ es de Galois, $N_{F/K}(\alpha), T_{F/K}(\alpha) \in F$.

****** Demostración
Al ser de Galois, los homomorfismos tienen imágenes en $F$.

***** Propiedades de norma y traza
Sea $F/K$ finita y separable de grado $n$:

  1. $N(\alpha\beta) = N(\alpha)N(\beta)$
  2. $T(\alpha+\beta) = T(\alpha) + T(\beta)$
  3. $N(a\alpha) = a^nN(\alpha)$ para cada $a \in K$
  4. $T(a\alpha) = naT(\alpha)$ para cada $a \in K$
  5. $N(\alpha) \in K$ para cada $\alpha \in F$
  6. $T(\alpha) \in K$ para cada $\alpha \in F$

****** Demostración
******* Puntos 1 y 2
Simplemente por ser homomorfismos los que componen la suma y el
producto.

******* Puntos 3 y 4
Los homomorfismos dejan fijos los elementos del cuerpo.

******* TODO Puntos 5 y 6
Para $E$ una clausura normal $Gal(E/K)$ actúa sobre $\frac{Gal(E/K)}{Gal(F/K)}$.

***** Fórmulas de transitividad
Para una torre $K \subset F \subset E$ y $E/K$ finita y separable:

  1. $N_{F/K}(N_{E/F}(\alpha)) = N_{E/K}(\alpha)$
  2. $T_{F/K}(T_{E/F}(\alpha)) = T_{E/K}(\alpha)$

****** TODO Demostración
***** Elemento de traza no nula
Sea $F/K$ finita y separable, existe $\alpha \in F$ tal que $T_{F/K}(\alpha) \neq 0$.

****** TODO Demostración

***** Discriminante de una extensión
Sea $F/K$ extensión finita y separable. Dados $\alpha_1,\dots,\alpha_n \in F$ equivalen:

  1. $\{\alpha_1,\dots,\alpha_n\}$ base de $F$ como espacio vectorial sobre $K$.
  2. Son linealmente independientes sobre $F$ los elementos:

     \[\begin{aligned}
     \beta_1 &= (\sigma_1(\alpha_1), \dots, \sigma_1(\alpha_n)) \\
     \vdots &\\
     \beta_n &= (\sigma_n(\alpha_1), \dots, \sigma_n(\alpha_n)) \\
     \end{aligned}\]

  3. El determinante de la matriz $(T_{F/K}(\alpha_i\alpha_j))_{ij}$ es no nulo.

A este determinante lo llamamos *discriminante de la extensión* relativo
a la base $\alpha_1,\dots,\alpha_n$.

****** TODO Demostración

*** B. Lista de temas de teoría
**** 1. Galois es normal y separable
Si $E/K$ es una extensión finita, son equivalentes:

  1. $E/K$ extensión de Galois.
  2. $E/K$ extensión normal y separable.

***** Demostración
****** Primera implicación
Como cada $\sigma \in G = Gal(E/K)$ nos da un $\sigma : E/K \longrightarrow \overline{K}/K$, se tiene, por 
Teorema de Artin:

\[
[E:K]_S \geq |G| = [E:K] \geq [E:K]_S
\]

Por tanto, es separable. Además, cada homomorfismo de ese tipo está
en $G$ luego es un automorfismo y el cuerpo queda fijo, siendo una
extensión normal.

****** Segunda implicación
Sea $n = [E:K]_S = [E:K]$ por separabilidad. Cada uno de esos 
homomorfismos nos da $\sigma : E/K \longrightarrow E/K$, luego $Gal(E/K) = G$ tiene
orden $n$. Por Teorema de Artin:

\[ [E : E^G] = n = [E:K]\]

luego $[E^G : K] = 1$.

**** 2. Teorema del elemento primitivo de Steinitz
En $F/K$ extensión finita equivalen:

  1. $F/K$ tiene elemento primitivo.
  2. Existe un número finito de cuerpos intermedios.

***** Demostración
****** Primera implicación
Sea $F = K(\alpha)$. $Irr(\alpha,K)$, tiene un número finito de factores. Para 
cada uno de ellos, $p$, definimos el subcuerpo generado por sus 
coeficientes $K[|p|]$. Cualquier cuerpo intermedio $E$ en el que
$Irr(\alpha,E)=p$, contendrá a los coeficientes $E \supset K[|p|]$, pero además:

\[ [K(\alpha) : K[|p|] = [K(\alpha) : E]\]

Luego $E = K[|p|]$ y sólo hay finitos cuerpos intermedios.

****** Segunda implicación
******* Caso de cuerpo base finito
Como la extensión es finita, sólo habrá finitos elementos en ella. El
grupo multiplicativo de cualquier cuerpo es simple, así que tendrá un
elemento primitivo.

******* Caso de cuerpo base infinito
Nos limitamos a probar $K(a,b)$ simple. Si consideramos los subcuerpos
de la forma $K(a+bx)$ para cada $x\in F$, como sólo habrá finitos,
deberán coincidir algunos dos $K(a+bx) = K(a+by)$ con $x\neq y$. 

Entonces:

\[
b = \frac{(a+bx) - (a+by)}{x-y} \in K(a+bx) = K(a,b)
\]

**** 3. Caracterizaciones de extensiones normales
Para $E/K$ extensión finita equivalen:

  1. $E/K$ es una extensión normal. Es cuerpo de descomposición de un
     polinomio.
  2. Para cada $\sigma : E/K \longrightarrow \overline{K}/K$, donde $\overline{K}$ es una clausura algebraica,
     se tiene $\sigma(E) = E$.
  3. Todo polinomio irreducible $f \in K[X]$ con una raíz en $E$ descompone
     en $E$.

***** Demostración
****** Implicación 1 a 2
Como es una extensión finita será de la forma $E = K(\alpha_1,\dots,\alpha_n)$.
La imagen de la raíz de un polinomio deberá ser una conjugada suya,
luego $\sigma(E) \subseteq E$. Como además un endomorfismo entre extensiones
algebraicas es automorfismo, $\sigma(E) = E$.

****** Implicación 2 a 3
Si una raíz del polinomio está, existen homomorfismos que la llevan
en cada una de las conjugadas. Como cumplen $\sigma(E) = E$, se tiene que
todas las conjugadas están en $E$ y el polinomio descompone.

****** Implicación 3 a 1
La extensión finita es de la forma $E = K(\alpha_1,\dots,\alpha_n)$. Podemos tomar
los irreducibles de cada uno de los $\alpha_i$ y multiplicarlos. Como si una
raíz está en el cuerpo todas lo están, el cuerpo de descomposición
de ese producto está contenido en $E$. Como tiene a todos sus $\alpha_i$, es $E$.

**** 4. Caracterización de la separabilidad
Sea $F/K$ una extensión finita y $\overline{K}$ una clausura algebraica de $K$ conteniendo
a $F$, entonces son equivalentes:

  1. $F/K$ es separable.
  2. $|Hom(F/K,\overline{K}/K)| = [F:K]$.

***** Demostración
Llamamos $[F:K]_S = |Hom(F/K,\overline{K}/K)|$.

****** Caso simple
En un caso simple $K(\alpha) / K$ cada homomorfismo a la clausura queda
determinado por la imagen de $\alpha$, que debe ser a un elemento conjugado.
Tenemos que todas las raíces de $Irr(\alpha,K)$ tienen la misma multiplicidad
$m$, luego si es de grado $n$ habrá $n/m$ raíces distintas.

Se da la igualdad sólo si cada uno de los elementos es distinto,
esto es, si la extensión es separable.

****** Caso compuesto
Procedemos por inducción sobre el grado. Si tomamos un elemento en la
extesión $F \supseteq K(\alpha) \supseteq K$, sabemos:

\[
[F : K]_S = [F : K(\alpha)]_S [K(\alpha) : K]_S
\]

Sabemos que una extensión es separable si lo son sus subextensiones. 
Por hipótesis de inducción $[F : K(\alpha)]_S = [F : K(\alpha)]$ y por el caso base
$[K(\alpha) : K]_S = [K(\alpha) : K]$, por ser ambas separables.

**** 5. Teorema de Artin
Sea $E$ cuerpo y $G \subseteq Aut(E)$ un subgrupo finito, prueba que
$E^G = \{e \in E \mid \forall \sigma \in G: \sigma(e) = e\}$ es un subcuerpo y $[E : E^G] = |G|$.

***** Demostración
****** Es un subcuerpo
Por definición de morfismo de cuerpos.

****** Igualdad
Sabemos por Lema de Dedekind que $n = |G| \leq [E:E^G]$. Supongamos la
desigualdad estricta con $u_1,\dots,u_{n+1}$ independientes sobre $E^G$ y
creamos el siguiente sistema de $n+1$ incógnitas y $n$ ecuaciones:

\[
X_1\sigma_j(u_1) + \dots + X_{n+1}\sigma_j(u_{n+1}) = 0
\qquad
j = 1,\dots,n
\]

Sea $a_1,\dots,a_{n+1}$ solución no trivial con número mínimo de elementos
no nulos. Suponemos s.p.g. que $a_1 \neq 0$, despejamos:

\[\sigma_j(u_1) = b_2\sigma_j(u_2) + \dots + b_{n+1}\sigma_j(u_{n+1})\]

En particular, cuando $\sigma_j = id$:

\[
u_1 = b_2u_2 + \dots + b_{n+1}u_{n+1}
\]

Por lo que alguno de los coeficientes no está en $E^G$ si queremos
mantener la independencia lineal. Sea $b_2 \notin E^G$ y $\tau(b_2) \neq b_2$. Si aplicamos
$\tau$ a cada una de las ecuaciones y restamos nos queda, sabiendo
que $\tau G = G$:

\[
0 = (b_2-\tau(b_2))\sigma_j(u_2) + \dots + (b_n-\tau(b_n))\sigma_j(u_{n+1})
\qquad
j = 1,\dots,n
\]

Esta solución es no trivial pero tiene más elementos nulos que la
anterior, llevando a contradicción.

**** 6. Lema de independencia de Dedekind
Sea $F/K$ y $E/K$ extensiones de cuerpos, para cada familia no vacía ${\cal F}$ de
elementos de $Hom(F/K,E/K)$ prueba que son equivalentes:

  1. ${\cal F}$ es linealmente independiente en $Hom_K(F,E)$ sobre $E$.
  2. Todos los elementos de ${\cal F}$ son distintos.

***** Demostración
Demostraremos que, en general $\sigma_1,\dots,\sigma_m : G \longrightarrow F^\times$ homomorfismos desde un
grupo $G$ son distintos ssi son linealmente independientes sobre $F$. El caso
$m = 1$ es trivial, y, en otro caso, podemos tomar un subconjunto mínimo
de linealmente dependientes:

\[
\sigma_s = b_1\sigma_1 + b_2\sigma_2 + \dots + b_{s-1}\sigma_{s-1}
\]

Sea $y$ tal que $\sigma_1(y) \neq \sigma_s(y)$. Evaluamos en $xy$, multiplicamos por $\sigma_s(y)$
por otro lado y restamos para tener:

\[
0 = b_1(\sigma_1(y)-\sigma_s(y))\sigma_1 + 
\dots + 
b_{s-1}(\sigma_{s-1}(y)-\sigma_{s-1}(y))\sigma_{s-1}
\]

Contraviniendo minimalidad de los linealmente independientes. Nótese
que el añadirles $0$ para tener $\sigma_1,\dots,\sigma_m : F_1 \longrightarrow F_2$ no los vuelve
linealmente dependientes o iguales.

**** 7. Caracterización de cuerpo algebraicamente cerrado
Para $K$ cuerpo, equivalen:

  1. Todo polinomio no constante $f \in K[X]$ tiene al menos una raíz en $K$.
  2. Todo polinomio no constante $f \in K[X]$ descompone en $K$.
  3. Los polinomios no constantes irreducibles en $K[X]$ son de grado 1.
  4. $K$ no tiene extensiones algebraicas propias.

Los cuerpos que lo cumplen son *algebraicamente cerrados*.

***** Demostración
****** Primera implicación
Si el polinomio tiene una raíz, puede descomponerse como $f = (X-\alpha)f'$.
Si $f'$ es constante, tenemos una descomposición de $f$, si no lo es, podemos
descomponerlo a su vez.

****** Segunda implicación
Un polinomio de grado distinto de $1$ descompone linealmente y por tanto
no puede ser irreducible.

****** Tercera implicación
Sea $\alpha \in F/K$ algebraica. Como $Irr(\alpha,K)$ es de grado $1$, $\alpha \in K$. No puede
ser una extensión propia.

****** Cuarta implicación
Si algún polinomio no tuviera ninguna raíz en $K$, entonces él o un
divisor suyo serían irreducibles sin raíz en $K$. Con ellos se genera
una extensión algebraica propia.

**** 8. Teorema de Kronecker
Sea $f \in K[X]$ un polinomio no constante, entonces existe una extensión
$F/K$ en la que $f(X)$ tiene al menos una raíz.

***** Demostración
Podemos descomponer en polinomios irreducibles $f = f_1 f_2\dots f_{n}$ y crear
la extensión siguiente con la inclusión trivial de $K$, que es cuerpo
por ser $(f_1)$ un ideal maximal:

\[
F = \frac{K[X]}{(f_1)} \supset K
\]

Y donde $X + (f_1)$ es raíz del polinomio original por ser raíz de la
inclusión de $f_1$:

\[
f_1(X+(f_1)) = f_1 + (f_1) = 0
\]

**** 9. Extensiones ciclotómicas de Galois
Sea $n$ entero positivo, $K$ un cuerpo y $F/K$ una extensión ciclotómica, cuerpo
de descomposición del polinomio $X^n-1$, prueba que se verifica:

  1. $F/K$ es una extensión de Galois.
  2. $Gal(F/K)$ es isomorfo a un subgrupo del grupo multiplicativo de las
     unidades de $\mathbb{Z}_n$, por lo tanto su orden es un divisor de $\varphi(n)$.

***** Demostración
****** Primer punto
Es el cuerpo de descomposición de un polinomio, por lo tanto, es
normal. Además, trabajamos con la hipótesis de que $car(K) \nmid n$, por lo
que el polinomio debe tener todas sus raíces distintas y ser separable.

****** Segundo punto
Nótese que si tenemos una raíz primitiva, todas las raíces de la unidad
quedan generadas por ella, $F = K(\zeta)$, y cada elemento del grupo de Galois
queda determinado por a qué otra raíz primitiva envía la $\zeta$.

Sea $\sigma(\zeta) = \zeta^a$. Tenemos que $\sigma^{-1}(\zeta) = \zeta^b$ y que $\zeta^{ab} = \zeta$, luego debe ser $a \in \mathbb{Z}^\times_n$.
Creamos entonces la función inyectiva $\Lambda(\sigma) = a$, que trivialmente es
un homomorfismo inyectivo:

  - $\Lambda(\sigma) = a \wedge \Lambda(\tau) = b \implies \Lambda(\sigma\tau) = ab$.
  - $\Lambda(\sigma) = 1 \implies \sigma = id$.

Y por Primer Teorema de isomorfía tenemos lo pedido. Comprobar que
además divide a $\varphi(n)$ es trivial por ser el orden de $\mathbb{Z}_n^\times$.

**** 10. Teorema de Moore
Para cada $p^n$ potencia de primo, existe un cuerpo con $p^n$ elementos;
que es el cuerpo de descomposición de $x^{p^n}-x$ sobre $\mathbb{F}_p$. Además,
todo cuerpo finito de $p^n$ elementos es isomorfo a él.

***** Demostración
Dos cuerpos finitos con el mismo cardinal son isomorfos y que además
existe siempre un cuerpo de $p^n$ elementos.

****** Dos cuerpos finitos del mismo cardinal son isomorfos
Todo subgrupo finito del grupo multiplicativo de un cuerpo es cíclico,
luego $F^\times$ será cíclico de orden $p^n-1$, y sus elementos cumplen el 
polinomio:

\[x^{p^n-1} - 1 = 0\]

Así, $x^{p^n} - x$ tiene exactamente como raíces los $p^n$ elementos de $F$.

****** Existe un cuerpo con ese número de elementos
El polinomio $x^{p^n}-x$ tiene derivada $-1$, y por tanto, sólo raíces
simples. Añadiéndolas a $\mathbb{F}_p$, se tiene ya un cuerpo de descomposición.
Sean $u = u^{p^n}$ y $v = v^{p^n}$:

  - $(u+v)^{p^n} - (u+v) = 0$
  - $(uv)^{p^n} - uv = 0$
  - $(-u)^{p^n} - (-u) = 0$
  - $(u^{-1})^{p^n} - u^{-1} = 0$

**** 11. Teorema 90 de Hilbert
Sea $E/K$ extensión cíclica de grado $n$ con grupo $G = Gal(E/K) = \langle \sigma\rangle$, y
sea $\beta \in E$, prueba que son equivalentes:

  1. $N_{E/K}(\beta) = 1$
  2. Existe $0 \neq \alpha \in E$ tal que $\beta = \frac{\alpha}{\sigma(\alpha)}$.

***** Demostración
****** Primera implicación
Los automorfismos $1,\sigma,\dots,\sigma^n$ son distintos y por tanto linealmente
independientes, luego no es la aplicación cero:

\[
\tau 
= 
1 + \beta\sigma + (\beta \sigma(\beta))\sigma^2 + 
\dots +
(\beta \sigma(\beta)\dots \sigma^{n-2}\beta) \sigma^{n-1}
\]

Y existe $\tau(\theta) \neq 0$. Evaluando $\sigma(\tau(\theta))$ y multiplicando por $\beta$ nos queda
que $\beta \sigma(\tau(\theta)) = \tau(\theta)$.

****** Segunda implicación
Usando que la norma es homomorfismo:

\[
N_{E/K}(\beta) = \frac{N_{E/K}(\alpha)}{N_{E/K}(\sigma(\alpha))} = 1
\]

**** 12. Raíces simples y derivada
Sea $f \in K[X]$ no constante. Equivalen:

  1. Todas las raíces de $f$ son simples.
  2. $f$ y $Df$ son primos relativos.

***** Demostración
****** Primera implicación
En el cuerpo de descomposición de $f$ podemos escribir:

\[Df(X) = a \sum 
(X-\alpha_1)\dots(X-\alpha_{i-1})(X-\alpha_{i+1})\dots(X-\alpha_n)\]

Que claramente no comparte ningún factor primo $(X-\alpha_i)$ de $f$.

****** Segunda implicación
En el cuerpo de descomposición de $f$ podemos tomar una raíz de 
multiplicidad $m > 1$. Y entonces $f = (X-\alpha)^m g$ mientras:

\[ Df = (X-\alpha)^m Dg+ m(X-\alpha)^{m-1}g\]

Por lo que no serían primos relativos en el cuerpo de descomposición,
y por tanto, tampoco en $K$; ya que tenemos:

\[ Irr(\alpha,K) \mid f, Df\]

**** 13. Teorema de Lagrange
Sea $K$ un cuerpo, $n$ un entero positivo que es primo con la característica
de $K$ (o es nula) y existe una raíz n-ésima primitiva de la unidad
$\xi$ en $K$, prueba que se verifica:

  1. Si $E/K$ es una extensión cíclica de grado $n$, existe $\alpha \in E$ tal que
     $E = K(\alpha)$ e $Irr(\alpha,K) = X^n-a$ para algún $a \in K$.
  2. A la inversa, sea $a \in K$. Si $\alpha$ es una raíz de $X^n-a$, entonces $K(\alpha)/K$
     es una extensión cíclica de grado $d$, con $d\mid n$ y $a^d \in K$.

***** Demostración
****** Primer punto
Sea $E = K(u)$ con $Gal(E/K) = \langle \sigma \rangle$ y $\zeta$ la raíz n-ésima primitiva de la
unidad. Creamos el *resolvente de Lagrange*:

\[
\alpha 
= 
u + \zeta\sigma(u) + \zeta^2\sigma^2(u) + \dots + \zeta^{n-1}\sigma^{n-1}(u)
\]

Que sabemos que no es nula por independencia lineal de homomorfismos
distintos, y que cumple que: $\sigma(\alpha) = \zeta^{-1}\alpha$. Luego $\sigma^i(\alpha) = \zeta^{-i}\alpha$, que son
las $n$ raíces conjugadas de $\alpha$. Además $\sigma(\alpha^n) = \alpha^n$, por lo que $\alpha^n$ es un
punto fijo bajo $\sigma$ y debe ser $\alpha^n \in K$.

****** Segundo punto
******* Es extensión de Galois
Todas las $\zeta^i \alpha$ son raíces distintas, luego $K(\alpha)$ es el cuerpo de 
descomposición del polinomio $X^n-\alpha$ y es normal y separable por ser
$n$ un primo relativo de $car(K)$.

******* Es cíclica
Cualquier automorfismo debe llevar una raíz del polinomio en otra y
queda determinado por ella. Así, es de la forma $\sigma(\alpha) = \omega_\sigma \alpha$ para alguna 
raíz de la unidad.

**** 14. Automorfismo de Frobenius
Sea $K$ cuerpo de característica $p \neq 0$, prueba que son equivalentes:

  1. Todo polinomio irreducible no constante $f \in K[X]$ tiene todas sus 
     raíces simples.
  2. El endomorfismo de Frobenius es automorfismo.

***** Demostración
****** Primera implicación
Dado $a \in K$. Sea $X^p-a$, con una raíz $\alpha$ en un cuerpo de descomposición.
Tenemos $X^p-a = (X-\alpha)^p$. Como todos los irreducibles tienen raíces
simples, el único irreducible factor del polinomio puede ser $X-\alpha$.

Así $\alpha \in K$ y $a = \alpha^p$, siendo Frobenius sobreyectivo.

****** Segunda implicación
Para que un irreducible tenga raíz múltiple, debe dividir a su derivada,
que debe ser de grado menor, luego debe ser $0$. El polinomio debe ser
entonces de la forma $f(x^p)$ para que al derivarlo se anule.

Cuando Frobenius es automorfismo, podemos escribir:

\[f(x^p) = \sum a_i x^{ip} = \left( \sum \sqrt[p]{a_i} x^i \right)^{p}\]

Lo que contraviene irreducibilidad. Todos los polinomios deben tener
raíces simples.

**** 15. Galois es descomposición de separable
Sea $E/K$ una extensión finita, prueba que son equivalentes:

  1. $E/K$ extensión de Galois.
  2. $E$ cuerpo de descomposición de un polinomio separable sobre $K$.

***** Demostración
****** Primera implicación
Galois es normal y separable. Luego es cuerpo de descomposición de
algún polinomio y este debe ser separable. Si no fuera separable,
tendría algún factor con alguna raíz que no sería separable.

****** Segunda implicación
El cuerpo de descomposición de un polinomio separable debe ser normal
por cuerpo de descomposición y separable porque todos los elementos
que lo generan lo son y la suma y producto de separables es separable.

*** Ejercicios
**** Relación 1
***** Ejercicio 1.1
 Los polinomios simétricos en cuatro variables serán de la forma:

 \[\sum X_a = X_1+X_2+X_3+X_4\]
 \[\sum X_aX_b = X_1X_2+X_1X_3+X_1X_4+X_2X_3+X_2X_4+X_3X_4\]
 \[\sum X_aX_bX_c = X_1X_2X_3 + X_1X_2X_4 + X_1X_3X_4 + X_2X_3X_4\]
 \[\sum X_aX_bX_cX_d = X_1X_2X_3X_4\]

***** Ejercicio 1.2
 Usamos el polinomio recíproco relacionando $p(x)$ con $p(\frac{1}{x})$ y usamos
 la derivada $p(x)$ para raíces dobles. Sea:

 \[\hat p(x) = \frac{1}{x^n}(1+a_nx+\dots+a_0x^n)\]

 Usamos entonces $\hat{\hat{p}'}$ para relacionar las raíces.
   
***** Ejercicio 1.3
***** Ejercicio 1.5
 Vamos a usar una ecuación general que escribe una suma de potencias con
 otras variables en función de sumas de potencias de grado menor.

 \[\sum X_1^nX_2 \dots X_k = e_k\sum X_1^{n-1} - \sum X_1^{n-1}X_2 \dots X_kX_{k+1}\]

 para concluir que si la aplicamos repetidamente y llamamos 
 $s_n = \sum X^n$ obtendremos:

 \[ s_n = e_1s_{n-1} - e_2s_{n-2} + \dots + e_{n-1}s_1 - ne_n \]

 Por tanto, en los casos hasta $5$, tenemos:

 \[s_1 = e_1\]

 \[\begin{align*}
 s_2 &= e_1s_1 - 2e_2 \\
 &= e_1^2 - 2e_2
 \end{align*}
 \]

 \[\begin{align*}
 s_3 &= e_1s_2 - e_2s_1 + 3e_3 \\
 &= e_1^3 - 3e_1e_2 + 3e_3
 \end{align*}
 \]

 \[\begin{align*}
 s_4 &= e_1s_3 - e_2s_2 + e_3s_1 - 4e_4 \\
 &= e_1^4 - 3e_1^2e_2 + 3e_1e_3 - e_1^2e_2 + 2e_2^2 + e_1e_3 - 4e_4 \\
 &= e_1^4 - 4e_1^2e_2 + 4e_1e_3 - 4e_4 + 2e_2^2 
 \end{align*}
 \]

 \[\begin{align*}
 s_5 &= e_1s_4 - e_2s_3 + e_3s_2 - e_4s_1 + 5e_5 \\
 &= e_1^5 - 5e_1^3e_2 + 5e_1^2e_3 - 5e_1e_4 + 5e_1e^2_2 - 5e_3e_2 + 5e_5
 \end{align*}
 \]

 Nótese que aquí tomamos $e_m = 0$ en el caso de que haya menos de $m$ variables.

****** Solución por grados
 Cada polinomio simétrico de grado $n$ es combinación lineal de los que surgen
 como productos de elementales de grado $n$.

 \[x^3+y^3+z^3 = \alpha e_1^3 + \beta e_1e_2 + \gamma e_3\]

 Calculando se llega a $\alpha = 1$, $\beta = -3$, $\gamma = 3$.

***** Ejercicio 10
 Necesitamos uno que sea raíz de $p'$ y de $p$.
 Sacamos las raíces de $p'$, que son $1$ y $\frac{5}{3}$.

 Tenemos que $1$ es raíz doble cuando $k= -2$. Dividiendo por $(x-1)^2$ tenemos

 \[p(x) = (x-1)^2(x-2)\]

 Lo mismo se puede hacer con $\frac{5}{3}$, pero saldría $k \notin \mathbb{Z}$.

***** Ejercicio 11

**** Semana 1
***** Ejercicio 1.24
 Sea $M$ el conjunto de posibles /monomios/ en las variables y exponentes dados. 
 Podemos definir una función $S_n \longrightarrow M$ como sigue:

 \[\sigma(X_1^{e_1} X_2^{e_2} \dots X_n^{e_n}) = 
 X_{\sigma(1)}^{e_1} X_{\sigma(2)}^{e_2} \dots X_{\sigma(n)}^{e_n}
 \]

 Esto es una acción transitiva pero no fiel. El estabilizador para
 el monomio inicial, por ejemplo, son las permutaciones que mueven variables a
 variables del mismo exponente. Si hay $m_i$ variables de exponente $i$, podemos
 intercambiarlas de $m_i!$ formas distintas quedando un monomio igual. El estabilizador
 de ese monomio tiene por tanto orden $k = |Stab(x)| = m_1!m_2!\dots m_n!$. Aplicando ahora el
 Teorema de Lagrange para órbitas y estabilizadores obtenemos el número de
 monomios distintos:

 \[|M| = |S_n(M)| = \frac{|S_n|}{|Stab(x)|} = \frac{n!}{m_1!m_2!\dots m_n!}\]

***** Ejercicio 1.25
 Sea el polinomio $p(x) = x^3-5x-5$ con raíces $\alpha, \beta, \gamma$. Tenemos que el polinomio $p(x-1)$
 tendrá raíces $\alpha+1,\beta+1,\gamma+1$:

 \[p(x-1) = (x+1)^3-5(x+1)-5 = x^3 - 3x^2 - 2x - 1\]

 Y que el polinomio recíproco a él tendrá raíces  $\frac{1}{\alpha+1}, \frac{1}{\beta+1}, \frac{1}{\gamma+1}$:

 \[q(x) = 1 - 3x - 2x^2 - x^3\]

 Trabajando con $-q(x)$, que es mónico, y con los polinomios de Cardano-Vieta sobre
 sus raíces tenemos que si estas fueran $u,v,w$, tendríamos:

 \[(x-u)(x-v)(x-w) = x^3 - (u+v+w)x^2 +(uv+vw+wu)x - uvw\]

 Y desde aquí obtenemos el valor de los polinomios simétricos elementales sobre
 las raíces

 \[\begin{align*}
 e_1 &= u+v+w = -2 \\
 e_2 &= uv+vw+wu = 3 \\
 e_3 &= uvw = 1
 \end{align*}\]

 Ahora, expresamos el valor de $u^3+v^3+w^3$ como suma de polinomios elementales
 mediante el algoritmo de orden lexicográfico de la demostración:

 \[\begin{align*}
 \sum X_1^3 &= e_1^3 - (3\sum X_1^2X_2 + 6\sum X_1X_2X_3) \\
            &= e_1^3 - 3(e_1e_2 - 3\sum X_1X_2X_3 + 6\sum X_1X_2X_3) \\
            &= e_1^3 - 3e_1e_2 + 3e_1
 \end{align*}\]

 Y así, finalmente tenemos:

 \[u^3+v^3+w^3 = (-2)^3 - 3(-2)3 + 3 = 13\]

 # ¿Existen cuerpos infinitos de característica no nula?

**** Semana 2
***** Ejercicio 2.14
****** Punto 1
 Supongamos que se tiene $f(x) = ax+b$ con $a$ una unidad del anillo. Entonces podríamos
 tomar como inversa de $\phi$ el homomorfismo de anillos que cumple $g(x) = a^{-1}(x - b)$ y que
 sobre los elementos del anillo es la identidad. Sería un isomorfismo.

 Estudiamos el caso de que $f(x)$ fuera de otra forma pero fuera isomorfismo. 
 Trivialmente su grado no podría ser $0$ para ser inyectivo sobre los elementos del
 anillo. Si $f(x)$ tuviera monomio líder $b_kx^k$
 y el monomio líder de $p$ fuera $a_mx^m$. Su imagen sería:

 \[\phi(p(x)) = a_0 + a_1f(x) + a_2f(x)^2 + \dots + a_mf(x)^m\]

 tendría un único coeficiente líder de grado $km$ que sería 
 $a_mb_kx^{m+k} \neq 0$ por ser dominio de integridad.

 Así,tenemos que $f$ no puede tener grado mayor que $1$ y debe tener un coeficiente líder unidad
 si queremos que $a_mb_kx^{m+k} = x \in img(\phi)$.

****** Punto 2
 El coeficiente líder puede anularse y la condición ya no es suficiente.

 Sea $e$ en el nilradical de un anillo, con $e^n = 0$. Entonces se pueden tomar
 los dos homomorfismos cumpliendo:

 \[\phi(x) = x - e^{n-1}x^n\]
 \[\phi'(x) = x + e^{n-1}x^n\]

 Nótese ahora que $\phi\phi'(x) = \phi'\phi(x) = x$ y que para cualquier polinomio se comprobará
 que son dos automorfismos inversos entre sí. De hecho, usando que son
 homomorfismos:

 \[\phi\phi'(p(x)) = p(\phi\phi'(x)) = p(x)\]

***** Ejercicio 2.15
****** Punto 1
 Si $f$ es irreducible en $\mathbb{Z}$, es en particular primitivo.
 Supongamos que $f = gh$ en $\mathbb{Q}$, factorización no trivial. Puedo escribir $g$ y $h$ como
 polinomios primitivos por una unidad de $\mathbb{Q}$: $f = ug_0h_0$. Como el producto de primitivos
 es primitivo, $g_0h_0$ lo es. Supongamos que tuviéramos $u = \frac{a}{b}$, con:

 \[bf = ag_0h_0\]

 Llegamos a que $a|b$, $b|a$, ya que ninguno de los dos puede dividir a un 
 polinomio primitivo; y obtenemos $u$ unidad de $\mathbb{Z}$. Con lo cual, $f$ no sería
 irreducible en $\mathbb{Z}$.

****** Punto 2
 Como es irreducible sobre $\mathbb{Q}$, el ideal que genera es maximal y $F$ es
 por tanto un cuerpo. Las inclusiones son las triviales.

****** Punto 3
 Sea el polinomio $f(y) \in F[y]$. Tenemos que:

 \[f(X + (f(X))) = f(X) + (f(X)) = 0 + (f(X)) \]

 Por lo que es raíz.

 La primera igualdad se obtiene del hecho de que las potencias y el producto
 por elementos del cuerpo respetan las clases de equivalencia; y por tanto,
 la evaluación de un polinomio lo hace:

 \[(X + (f(X)))^n = X^n + X^{n-1}(f(X)) + \dots + (f(X)) = X^n + (f(X))\]
 \[a(X+(f(X))) = aX + (f(X))\]

***** Ejercicio 2.16
 Tenemos una extensión sobre $\mathbb{F}_2$ generada por un polinomio de grado 3. 
 Sus elementos son clases de equivalencia sobre polinomios de hasta 
 grado dos, habiendo 8 elementos. Abusando de la notación, los escribimos como
 los representantes de su clase de equivalencia:

 \[\{0,1,x,x+1,x^2,x^2+1,x^2+x,x^2+x+1\}\]

 Tenemos las siguientes tablas para la suma y el producto:

 #+BEGIN_SRC sage :exports none
 R.<t> = PolynomialRing(GF(2),'t')
 I = R.ideal(t^3+t+1)
 S.<x> = R.quotient_ring(I)
 #+END_SRC
 #+RESULTS:

 #+BEGIN_SRC sage :exports results
 S.addition_table(
     names=["0","1","x","x+1","x^2","x^2+1","x^2+x","x^2+x+1"],
     elements=[0,1,x,x+1,x^2,x^2+1,x^2+x,x^2+x+1]
 )
 #+END_SRC
 #+RESULTS:
 #+begin_example

       +        0       1       x     x+1     x^2   x^2+1   x^2+x x^2+x+1
	+----------------------------------------------------------------
       0|       0       1       x     x+1     x^2   x^2+1   x^2+x x^2+x+1
       1|       1       0     x+1       x   x^2+1     x^2 x^2+x+1   x^2+x
       x|       x     x+1       0       1   x^2+x x^2+x+1     x^2   x^2+1
     x+1|     x+1       x       1       0 x^2+x+1   x^2+x   x^2+1     x^2
     x^2|     x^2   x^2+1   x^2+x x^2+x+1       0       1       x     x+1
   x^2+1|   x^2+1     x^2 x^2+x+1   x^2+x       1       0     x+1       x
   x^2+x|   x^2+x x^2+x+1     x^2   x^2+1       x     x+1       0       1
 x^2+x+1| x^2+x+1   x^2+x   x^2+1     x^2     x+1       x       1       0
 #+end_example

 #+BEGIN_SRC sage :exports results
 S.multiplication_table(
     names=["0","1","x","x+1","x^2","x^2+1","x^2+x","x^2+x+1"],
     elements=[0,1,x,x+1,x^2,x^2+1,x^2+x,x^2+x+1]
 )
 #+END_SRC
 #+RESULTS:
 #+begin_example

       *        0       1       x     x+1     x^2   x^2+1   x^2+x x^2+x+1
	+----------------------------------------------------------------
       0|       0       0       0       0       0       0       0       0
       1|       0       1       x     x+1     x^2   x^2+1   x^2+x x^2+x+1
       x|       0       x     x^2   x^2+x     x+1       1 x^2+x+1   x^2+1
     x+1|       0     x+1   x^2+x   x^2+1 x^2+x+1     x^2       1       x
     x^2|       0     x^2     x+1 x^2+x+1   x^2+x       x   x^2+1       1
   x^2+1|       0   x^2+1       1     x^2       x x^2+x+1     x+1   x^2+x
   x^2+x|       0   x^2+x x^2+x+1       1   x^2+1     x+1       x     x^2
 x^2+x+1|       0 x^2+x+1   x^2+1       x       1   x^2+x     x^2     x+1
 #+end_example

**** Semana 3
***** Ejercicio 2.17
****** Punto 1
 Tenemos el siguiente diagrama con las extensiones

 \[ \begin{tikzcd}
  & \mathbb{Q}({\sqrt{2}},\sqrt{3},\sqrt{5}) \drar[dash] \dar[dash] \dlar[dash] & \\
 \mathbb{Q}(\sqrt{2}) & \mathbb{Q}(\sqrt{3}) & \mathbb{Q}(\sqrt{5}) \\
 & \mathbb{Q} \urar[dash,swap]{2} \uar[dash]{2} \ular[dash]{2} &
 \end{tikzcd} \]

 Donde $\sqrt{2},\sqrt{3},\sqrt{5}$ son irracionales y sus polinomios irreducibles
 en $\mathbb{Q}$ son $x^2-2 = 0$, $x^2-3=0$ y $x^2-5=0$; por lo que son extensiones
 de grado $2$.

 Ahora mostramos que $\sqrt{3} \notin \mathbb{Q}(\sqrt{2})$, ya que:

 \[\sqrt{3} = a + b \sqrt{2}\]

 Y sabiendo que no puede tenerse $\sqrt{3} = a$ o $\sqrt{3} = b\sqrt{2}$:

 \[\sqrt{2} = \frac{3-a^2-b^2}{2ab}\]

 Y entones $\sqrt{2}$ sería racional. Así, $\mathbb{Q}(\sqrt{2},\sqrt{3})$, sabiendo que además 
 $\sqrt{3}^2 \in \mathbb{Q}$, debe ser una extensión de grado $2$ sobre $\mathbb{Q}(\sqrt{2})$.

 Ahora mostramos que $\sqrt{5} \notin \mathbb{Q}(\sqrt{2})(\sqrt{3})$, ya que, siendo $a,b \in \mathbb{Q}(\sqrt{2})$:

 \[\sqrt{5} = a + b\sqrt{3}\]
 \[ 5 = a^2 + 2ab\sqrt{3} + 3b^2\]

 Ahora, $ab = 0$, ya que, si no fuera así, $\sqrt{3} \in \mathbb{Q}(\sqrt{2})$; además, $a=0$ o $b=0$, llegando
 a uno de los siguientes casos:

 \[ 5 = a^2 = x^2+y^2+2xy\sqrt{2}\]
 \[ 5 = 3b^2 = 3(x^2+y^2+2xy\sqrt{2})\]

 Donde, análogamente, llegaríamos a contradicción con $\frac{5}{3} \notin \mathbb{Q}$.
 Como además $\sqrt{5}^2 \in \mathbb{Q}$, es una extensión de grado $2$.

 Resumiendo, tenemos:

 \[ \begin{tikzcd}
  & \mathbb{Q}({\sqrt{2}},\sqrt{3},\sqrt{5}) & \\
  \mathbb{Q}(\sqrt{2},\sqrt{3}) \urar[dash]{2} & & \\
 \mathbb{Q}(\sqrt{2}) \uar[dash]{2} & \mathbb{Q}(\sqrt{3}) \ular[dash]{2} & \mathbb{Q}(\sqrt{5}) \arrow[uul,dash] \\
 & \mathbb{Q} \urar[,dash,swap]{2} \uar[dash]{2} \ular[dash]{2} &
 \end{tikzcd} \]

 Y aplicando la fórmula de grado de las extensiones llegamos
 a que $[\mathbb{Q}(\sqrt{2},\sqrt{3},\sqrt{5}) : \mathbb{Q}] = 8$.

****** Punto 2
 Tenemos a $1,\sqrt{2},\sqrt{3},\sqrt{5},\sqrt{6},\sqrt{10},\sqrt{15},\sqrt{30}$ sistema de generadores del espacio,
 y por ser de dimensión $8$, sabemos que forman una base. Veamos que $1,\alpha,\alpha^2,\dots,\alpha^7$ es una base 
 del mismo espacio comprobando independencia lineal sobre la base inicial.

 #+BEGIN_SRC sage :exports none
   A = FreeAlgebra(QQ,3,'i')
   F = A.monoid()
   a,b,c = F.gens()
   mons = [ F(1), a,b,c,a*b,a*c,b*c,a*b*c ]
   M = MatrixSpace(QQ,len(mons))
   mats = [
       M([0,1,0,0,0,0,0,0,
          2,0,0,0,0,0,0,0,
          0,0,0,0,1,0,0,0,
          0,0,0,0,0,1,0,0,
          0,0,2,0,0,0,0,0,
          0,0,0,2,0,0,0,0,
          0,0,0,0,0,0,0,1,
          0,0,0,0,0,0,2,0
       ]),
       M([0,0,1,0,0,0,0,0,
          0,0,0,0,1,0,0,0,
          3,0,0,0,0,0,0,0,
          0,0,0,0,0,0,1,0,
          0,3,0,0,0,0,0,0,
          0,0,0,0,0,0,0,1,
          0,0,0,3,0,0,0,0,
          0,0,0,0,0,3,0,0
       ]),
       M([0,0,0,1,0,0,0,0,
          0,0,0,0,0,1,0,0,
          0,0,0,0,0,0,1,0,
          5,0,0,0,0,0,0,0,
          0,0,0,0,0,0,0,1,
          0,5,0,0,0,0,0,0,
          0,0,5,0,0,0,0,0,
          0,0,0,0,5,0,0,0
       ])
   ]
   P3.<a,b,c> = A.quotient(mons,mats)
 #+END_SRC

 #+RESULTS:

 Para ello escribo los coeficientes de cada $\alpha^n$ en la
 base inicial formando la siguiente matriz y compruebo que son linealmente independientes.

 #+BEGIN_SRC sage :exports results
 M = matrix([ ((a+b+c)^n).vector() for n in range(0,8) ]).transpose()
 M
 #+END_SRC

 #+RESULTS:
 : 
 : [    1     0    10     0   224     0  6160     0]
 : [    0     1     0    26     0   784     0 23024]
 : [    0     1     0    24     0   664     0 18976]
 : [    0     1     0    20     0   520     0 14720]
 : [    0     0     2     0    80     0  2448     0]
 : [    0     0     2     0    64     0  1904     0]
 : [    0     0     2     0    56     0  1584     0]
 : [    0     0     0     6     0   200     0  5936]

 Si calculamos el rango de esta matriz, obtenemos que es invertible.

 #+BEGIN_SRC sage :exports both
 M.rank()
 #+END_SRC

 #+RESULTS:
 : 8

****** Punto 3
 Usando la matriz anterior, obtengo un polinomio que tiene por raíz
 a $\sqrt{2}+\sqrt{3}+\sqrt{5}$. Para ello escribo los coeficientes de $\alpha^8$ en
 función de la base anterior de la matriz.

 #+BEGIN_SRC sage :exports both
 M.solve_right(vector(QQ,((a+b+c)^8).vector()))
 #+END_SRC

 #+RESULTS:
 : (-576, 0, 960, 0, -352, 0, 40, 0)

 Así que tengo el polinomio siguiente del que $\alpha$ es raíz:

 \[t^8-40*t^6+352*t^4-960*t^2+576\]

 # Checking the answer
 #+BEGIN_SRC sage :exports none
 t = sqrt(2)+sqrt(3)+sqrt(5)
 (-40*t^6+352*t^4-960*t^2+576+t^8).expand()
 #+END_SRC

 #+RESULTS:
 : 0

****** Punto 4
 Por el diagrama de extensiones del ejercicio $1$ sabemos que $\mathbb{Q}(\sqrt{2},\sqrt{3})$ es una extensión
 de grado 4. Como ya sabemos que $\mathbb{Q}(\sqrt{2}+\sqrt{3}) = \mathbb{Q}(\sqrt{2},\sqrt{3})$, tenemos que $\sqrt{2}+\sqrt{3}$ es 
 un elemento de grado 4 sobre $\mathbb{Q}$.
**** Semana 4
***** Ejercicio 3.11
****** Punto 1
 Sea el polinomio $f\in \mathbb{F}_2[X]$ con una raíz $\lambda$; comprobamos que también
 es raíz $\lambda^2$:

 \[\begin{aligned}
 f(\lambda^2) 
 &= a_n\lambda^{2n} + a_{n-1}\lambda^{2(n-1)} + \dots + a_1\lambda^2 + a_0 \\
 &= (a_n\lambda^n + a_{n-1}\lambda^{n-1} + \dots + a_1\lambda + a_0)^2 \\
 &= f(\lambda)^2
 \end{aligned}
 \]

 Donde usamos que:

 \[a_p\lambda^{2p} + a_q\lambda^{2q} = 
 a^2_p\lambda^{2p} + 2a_pa_q\lambda^p\lambda^q + a^2_q\lambda^{2q} =
 (a_p\lambda^p + a_q\lambda^q)^2\]

 Aplicando esto varias veces llegamos a que $\lambda,\lambda^2,\lambda^4,\dots$ son raíces.

****** Punto 2
 Sea el polinomio $f(x) = x(x^2+x+1) = x^3+x^2+x$, que tiene como raíz en 
 $K \cong \frac{\mathbb{F}_2[X]}{(x^2+x+1)}$ a $\lambda = x + (x^2+x+1)$; nótese que tiene como raíz también a $0$, que no es
 potencia de $\lambda$.

****** Punto 3
 Siendo $\beta$ una raíz primitiva, genera el cuerpo y una base de $K$ sobre su cuerpo
 base debe estar generada por $\beta$ y formada por  
 $\{1,\beta,\beta^2,\dots,\beta^{n-1}\}$; supongamos que el grado de $f$ fuera
 menor que $n$, entonces tendría una relación de dependencia lineal entre la base:

 \[ 0 = f(\beta) = a_0 +a_1\beta + \dots + a_{n-1}\beta^{n-1} \]

 Lo que nos daría una contradicción.

**** Semana 5
***** Ejercicio 4.17
#+begin_statement
Sea $K \subseteq E \subseteq F$ una torre de cuerpos y supongamos que $\alpha_1,\dots,\alpha_r$ son algunas de las 
raíces de $f(X) \in K[X]$ y $E = K(\alpha_1,\dots,\alpha_r)$. Demuestra que $F$ es el cuerpo de 
descomposición de $f(X)$ sobre $K$ si, y sólo si, $F$ es el cuerpo de descomposición de
$f(X)$ sobre $E$.
#+end_statement

Antes que nada, podemos descomponer $f$ en la clausura algebraica $\overline{K}$ como factores
lineales con raíces $\alpha_1,\dots,\alpha_n$. Vamos a fijarnos en el hecho de que el cuerpo de 
descomposición de un polinomio sobre un cuerpo es el cuerpo resultante de añadirle
sus raíces en la clausura; esto es debido que cumple trivialmente la propiedad del 
cuerpo de descomposición, y además es minimal porque cualquier otro debe contener a 
sus raíces y, por tanto, contenerlo él.

Ahora veamos que ambos cuerpos de descomposición que se plantean en el ejercicio 
son iguales. Por un lado, el cuerpo de descomposción de $f$ sobre $K$ debe ser
$K(\alpha_1,\dots,\alpha_n)$; y por otro, el cuerpo de descomposición de $f$ sobre
$E$, que también tiene como clausura algebraica a $K$, debe ser: 

\[\begin{aligned}
E(\alpha_1,\dots,\alpha_n) &= K(\alpha_1,\dots,\alpha_r)(\alpha_1,\dots,\alpha_n) \\
&= K(\alpha_1,\dots,\alpha_r)(\alpha_{r+1},\dots,\alpha_n) \\
&= K(\alpha_1,\dots,\alpha_n) 
\end{aligned}\]

***** Ejercicio 4.18
#+begin_statement
Sea $a \in \mathbb{Q}$ y $n$ un número entero positivo impar tal que
$\sqrt[n]{a} \in \mathbb{R}/\mathbb{Q}$. Demuestra que la extensión $\mathbb{Q}(\sqrt[n]{a})/\mathbb{Q}$ no es normal.
#+end_statement

Tengo que $\sqrt[n]{a}$ es raíz de $x^n-a$. Eso quiere decir que será múltiplo de 
$\operatorname{Irr}(\sqrt[n]{a},K)$, y que por tanto, toda raíz de su polinomio irreducible será raíz 
de $x^n-a$. En $\mathbb{C}$, las raíces de ese polinomio son de la forma $\{\zeta^i_n\sqrt[n]{a}\}$,
con los $\zeta$ raíces de la unidad; y, siendo $n$ impar, sólo una será real.

Por otro lado, si queremos que sea una extensión normal, el polinomio irreducible
debería tener todas sus raíces en la extensión y factorizar linealmente en ellas;
pero como sólo hay una real y la extensión está contenida en los reales, sólo
podría tener una raíz, el polinomio sería lineal y entonces se tendría $\sqrt[n]{a} \in \mathbb{Q}$.

***** Ejercicio 4.19
#+begin_statement
Sea $E/K$ una extensión normal y $f(X) \in K[x]$ un polinomio (mónico) irreducible. Si
$f(X)$ se factoriza en $E$ como producto de dos polinomios (mónicos) irreducibles 
$f_1(x)$ y $f_2(x)$. Demuestra que existe un homomorfismo $\sigma : E/K \longrightarrow E/K$ tal que
$f^\sigma_1(x) = f_2(x)$.
#+end_statement

Sea $\alpha$ raíz de $f_1$ y $\beta$ raíz de $f_2$. Ambos son los polinomios irreducibles de sus raíces
en $E$. Como ambas además son raíces de $f$, son conjugadas sobre $K$
y existe un automorfismo sobre $K$ que lleva $\sigma(\alpha) = \beta$. Ese isomorfismo cumple 
que $\sigma(E) = E$ por normalidad. Ahora, por irreducibilidad:

\[f_2 | f_1^\sigma\]

Y tenemos que:

\[ f_1f_2 = f = f^\sigma = f_1^\sigma f_2^\sigma\]

Esto quiere decir que $f_1 = f_2^\sigma$ y que $f_2 = f_1^\sigma$; ya que estamos en un dominio de 
factorización única y ambos son mónicos.
**** Semana 6
***** Ejercicio 5.10
#+begin_statement
Sea $K$ cuerpo de característica $p \neq 0$ y $t$ una indeterminada sobre $K$. Prueba que el
polinomio $X^p-t^p \in K(t^p)[X]$ es irreducible.
#+end_statement

Por binomio de Newton, en $K(t)[X]$ tenemos $x^p-t^p = (x-t)^p$. Sus divisores son de la
forma $(x-t)^q$ para $q<p$; y ninguno puede estar en $K(t^p)[X]$ porque implicaría que
estuviera su último coeficiente $(-t)^q \in K(t^p)[X]$, con lo que ya no sería una 
indeterminada porque se podría escribir $t^q$ relacionado con $t^p$.

***** Ejercicio 5.11
#+begin_statement
Estudiar si son o no ciertas las siguientes afirmaciones:

 - $\sqrt[3]{-1}$ es separable sobre $\mathbb{F}_9$.
 - $\sqrt[3]{-1}$ es separable sobre $\mathbb{F}_{49}$.
 - $\sqrt[7]{5}$ es separable sobre $\mathbb{F}_{7^7}$.
 - $t$ es separable sobre $\mathbb{F}_{p^2}(t^p)$, siendo $p$ un número entero primo positivo y $t$ una
   indeterminada sobre $\mathbb{F}_{p^2}$.

$\quad$
#+end_statement

Las tres primeras son extensiones finitas sobre cuerpos perfectos (por ser finitos),
luego todas son separables. Para el último caso, $x^p-t^p = 0$ es irreducible y por 
tanto polinomio mínimo de $t$, pero tiene raíces múltiples, luego $t$ es un elemento 
no separable.

***** Ejercicio 5.12
#+begin_statement
Sea $E$ un cuerpo y $\{\varphi_1,\dots,\varphi_n\}$ un conjunto de $n$ automorfismos distintos de $E$.
Llamamos $K = \{e \in E \mid \varphi_i(e) = e, 1 \leq i \leq n\}$. Demuestra que $[E:K]\geq n$.
#+end_statement

Dada la extensión $E/K$. Tenemos dos casos:

 - $E$ es infinita sobre $K$, luego $[E:K] \geq n$.
 - $E$ es finita sobre $K$, por el corolario al lema de Dedekind, tenemos:
   \[ [E:K] \geq |Hom(E/K,E/K)| \geq n\]

**** Semana 7
***** Ejercicio 7.25
#+begin_statement
Sea $f \in K[X]$ un polinomio sin raíces múltiples; y
$G = \operatorname{Gal}(f/K)$. Prueba que son equivalentes:

 1. $f(X)$ es irreducible.
 2. $G$ actúa transitivamente sobre las raíces de $f$.

$\quad$
#+end_statement

Sea $f$ irreducible. Cualesquiera dos de sus raíces tienen a $f$ como polinomio 
irreducible; luego son conjugadas y existe un automorfismo de la clausura que
lleva una en otra, $\sigma : \overline{K} \longrightarrow \overline{K}$. Como la extensión $f/K$ es normal ser la extensión
de descomposición de un polinomio irreducible $f$, tenemos que $\sigma|_{f/K} \in G$.

Sea $G$ actuando transitivamente sobre las raíces de $f = gh$, descomposición
en $K[X]$. Una raíz no puede estar
repetida en $g$ y en $h$, porque conllevaría raíces múltiples. Sea $a$ raíz de $g$, y
sea un $\sigma : f/K \longrightarrow f/K$ que la lleve en $b$ raíz de $h$. Entonces

\[ h(a) = h(\sigma(b)) = \sigma(h(b)) = 0\]

contraviniendo que no existan raíces múltiples.
**** Semana 8
***** Ejercicio 7.26
    #+begin_statement
    Se considera el producto semidirecto $G = \mathbb{Z}_8\rtimes_\theta\mathbb{Z}_2$, siendo $\theta(1)(1)=3$.
    Observa que $G$ es un grupo de orden 16. Supongamos que $G$ es el grupo de Galois
    de una extensión $E/K$.

    1. ¿Cuántos cuerpos intermedios $F/K$, con $K\subset F\subset E$, existen de grado $8$?
       ¿Cuántos con un grupo de Galois $Gal(F/K)$ isomorfo a $\mathbb{Z}_8$?
    2. ¿Cuántos cuerpos intermedios $F/K$, con $K\subset F\subset E$, existen de grado $4$?
       ¿Cuántos con un grupo de Galois $Gal(F/K)$ isomorfo a $\mathbb{Z}_4$? y
       ¿cuántos con grupo de Galois isomorfo al grupo de Klein?
    3. ¿Cuántos cuerpos intermedios $F/K$, con $K\subset F\subset E$, existen de grado $2$?
       ¿Cuántos con grupo de Galois $Gal(E/F)$ isomorfo a $\mathbb{Z}_8$?
    4. Determina el retículo de subgrupos de $\mathbb{Z}_8 \rtimes_\theta\mathbb{Z}_2$.
    #+end_statement
    
    Lo que estamos buscando en cada uno de esos casos, gracias a la correspondencia
    de Galois, son subgrupos. Si calculamos el orden de los elementos en este
    producto semidirecto, tenemos:

    | Elemento | Orden |
    |----------+-------|
    | (0,0)    |     0 |
    | (1,0)    |     8 |
    | (2,0)    |     4 |
    | (3,0)    |     8 |
    | (4,0)    |     2 |
    | (5,0)    |     8 |
    | (6,0)    |     4 |
    | (7,0)    |     8 |
    | (0,1)    |     2 |
    | (1,1)    |     4 |
    | (2,1)    |     2 |
    | (3,1)    |     4 |
    | (4,1)    |     2 |
    | (5,1)    |     4 |
    | (6,1)    |     2 |
    | (7,1)    |     4 |

****** Punto 1
     Isomorfo a $\mathbb{Z}_8}$ es:

     \[<(1,0)>\]

     Que como contiene a todos los demás elementos de orden $8$, nos asegura que no 
     hay más isomorfos a $\mathbb{Z}_8$.

     Tenemos además uno isomorfo a $\mathbb{Z}_2\times\mathbb{Z}_4$, que es:

     \[<(2,0),(0,1)>\]
     
     Y otro isomorfo al grupo de los cuaternios, que es:

     \[<(4,0),(2,0),(1,1),(7,1)>\]

     No encontramos ninguno isomorfo a $\mathbb{Z}_2\times\mathbb{Z}_2\times\mathbb{Z}_2$, que necesitaría de $7$ elementos
     de orden $2$.

****** Punto 2
     Isomorfos al grupo de Klein:

     \[\{(0,0),(2,1),(4,0),(6,1)\}\]
     \[\{(0,0),(0,1),(4,1),(4,0)\}\]

     Cíclicos de grado $4$:

     \[<(2,0)>\]
     \[<(1,1)>\]
     \[<(3,1)>\]

****** Punto 3
     Subgrupos de grado $2$ son los que genera cada elemento de grado $2$. Hay
     cinco elementos de grado $2$.

***** Ejercicio 7.26 (Usando sage)
    Usamos Galois para tener correspondencia con un problema de grupos

    #+BEGIN_SRC sage
sage: C8 = CyclicPermutationGroup(8)
sage: alpha = PermutationGroupMorphism(C8,C8,[C8.gen()**3])
sage: phi = [[(1,2)],[alpha]]
sage: G = CyclicPermutationGroup(2).semidirect_product(C8,phi)
sage: G
Permutation Group with generators [(3,4,5,6,7,8,9,10), (1,2)(4,6)(5,9)(8,10)]
sage: G.order()
16
sage: G.subgroups()

[Subgroup of (Permutation Group with generators 
[(3,4,5,6,7,8,9,10), (1,2)(4,6)(5,9)(8,10)]) generated by [()],
 Subgroup of (Permutation Group with generators 
[(3,4,5,6,7,8,9,10), (1,2)(4,6)(5,9)(8,10)]) generated by [(3,7)(4,8)(5,9)(6,10)],
 Subgroup of (Permutation Group with generators 
[(3,4,5,6,7,8,9,10), (1,2)(4,6)(5,9)(8,10)]) generated by [(1,2)(4,6)(5,9)(8,10)],
 Subgroup of (Permutation Group with generators 
[(3,4,5,6,7,8,9,10), (1,2)(4,6)(5,9)(8,10)]) generated by [(1,2)(3,5)(4,8)(7,9)],
 Subgroup of (Permutation Group with generators 
[(3,4,5,6,7,8,9,10), (1,2)(4,6)(5,9)(8,10)]) generated by [(1,2)(3,7)(4,10)(6,8)],
 Subgroup of (Permutation Group with generators 
[(3,4,5,6,7,8,9,10), (1,2)(4,6)(5,9)(8,10)]) generated by [(1,2)(3,9)(5,7)(6,10)],
 Subgroup of (Permutation Group with generators 
[(3,4,5,6,7,8,9,10), (1,2)(4,6)(5,9)(8,10)]) generated by [(3,5,7,9)(4,6,8,10), (3,7)(4,8)(5,9)(6,10)],
 Subgroup of (Permutation Group with generators 
[(3,4,5,6,7,8,9,10), (1,2)(4,6)(5,9)(8,10)]) generated by [(3,7)(4,8)(5,9)(6,10), (1,2)(4,6)(5,9)(8,10)],
 Subgroup of (Permutation Group with generators 
[(3,4,5,6,7,8,9,10), (1,2)(4,6)(5,9)(8,10)]) generated by [(3,7)(4,8)(5,9)(6,10), (1,2)(3,9)(5,7)(6,10)],
 Subgroup of (Permutation Group with generators 
[(3,4,5,6,7,8,9,10), (1,2)(4,6)(5,9)(8,10)]) generated by [(3,7)(4,8)(5,9)(6,10), (1,2)(3,4,7,8)(5,10,9,6)],
 Subgroup of (Permutation Group with generators 
[(3,4,5,6,7,8,9,10), (1,2)(4,6)(5,9)(8,10)]) generated by [(3,7)(4,8)(5,9)(6,10), (1,2)(3,10,7,6)(4,5,8,9)],
 Subgroup of (Permutation Group with generators 
[(3,4,5,6,7,8,9,10), (1,2)(4,6)(5,9)(8,10)]) generated by [(3,5,7,9)(4,6,8,10), (3,7)(4,8)(5,9)(6,10), (1,2)(4,6)(5,9)(8,10)],
 Subgroup of (Permutation Group with generators 
[(3,4,5,6,7,8,9,10), (1,2)(4,6)(5,9)(8,10)]) generated by [(3,4,5,6,7,8,9,10), (3,5,7,9)(4,6,8,10), (3,7)(4,8)(5,9)(6,10)],
 Subgroup of (Permutation Group with generators 
[(3,4,5,6,7,8,9,10), (1,2)(4,6)(5,9)(8,10)]) generated by [(3,5,7,9)(4,6,8,10), (3,7)(4,8)(5,9)(6,10), (1,2)(3,4,7,8)(5,10,9,6)],
 Subgroup of (Permutation Group with generators 
[(3,4,5,6,7,8,9,10), (1,2)(4,6)(5,9)(8,10)]) generated by [(3,4,5,6,7,8,9,10), (3,5,7,9)(4,6,8,10), (3,7)(4,8)(5,9)(6,10), (1,2)(4,6)(5,9)(8,10)]]
    #+END_SRC

**** Semana 9
***** Ejercicio 7.27
    #+begin_statement
    Prueba que los subgrupos transitivos de $S_4$ son los subgrupos siguientes:
    
      1. $S_4$, que es normal.
      2. $A_4$, que es normal.
      3. $D_4 = \langle(1234),(13) \rangle$, y todos sus conjugados.
      4. $C_4 = \langle (1234) \rangle$, y todos sus conjugados.
      5. $V = \{1,(12)(34),(13)(24),(14)(24)\}$, que es normal.
    
    El retículo de subgrupos transitivos de $S_4$ es:

    \[ \begin{tikzcd}
    & & S_4 & \\
    & A_4 \urar & & D_4 \ular \\
    V \urar & & C_4 \ular \urar &
    \end{tikzcd} \]

    Como consecuencia, si $f(X)\in \mathbb{Q}[X]$ es un polinomio irreducible de grado cuatro,
    el grupo de Galois de $\mathbb{Q}(f)/\mathbb{Q}$ es isomorfo a uno de éstos.
    #+end_statement

    El grupo de Galois de un polinomio *irreducible* de grado cuatro debe poder
    permutar entre las $4$ raíces del polinomio, por lo que debe ser un subgrupo
    transitivo de $S_4$. Para que un subgrupo sea transitivo, su orden debe ser mayor
    que $4$.

    Comprobamos que:

      - De orden 24, el único es $S_4$.
      - De orden 12, el único es $A_4$.
      - De orden 8, el único es $D_4$, con tres conjugados.
      - De orden 6, el único es isomorfo a $S_3$, con cuatro conjugados.
      - De orden 4, los únicos son $C_4$ y $V$, con seis conjugados.
	
    De esta lista retiramos a $\langle (12),(23),(13) \rangle$ y sus cuatro conjugados por no ser
    transitivos. El resto se comprueban transitivos.

***** Ejercicio 7.28
    #+begin_statement
    Sea $f(X)\in K[X]$ un polinomio separable y $g$ un factor irreducible de $f$. ¿Actúa
    transitivamente $G = \operatorname{Gal}(f/K)$ sobre las raíces de $g$?
    #+end_statement
    
    Como $g$ es el polinomio irreducible de cualesquiera dos raíces suyas, estas son
    conjugadas y existe un isomorfismo $\sigma : \overline{K} \longrightarrow \overline{K}$. Como $f/K$ entendemos que es
    normal, ese isomorfismo se restringe a $f/K$.
**** Semana 10
***** Ejercicio 7.29
****** Punto 1
Si es irreducible, teníamos por el ejercicio de Semana 9 que
su grupo sería un subgrupo transitivo de $S_4$.

Como si $\alpha$ es raíz lo es $-\alpha$, tenemos que como mucho habrá $8$ automorfismos.
Fijada la imagen de $\alpha$ entre las cuatro posibles, queda fijada la imagen
de $-\alpha$, así, sólo quedan dos posibles imágenes para $\beta$. No puede ser
isomorfo por tanto a $S_4$ o a $A_4$.

****** Punto 2
Estamos en el caso del punto anterior por el polinomio $(x^2-n)(x^2-m)$.
El grupo no es trivial porque $\sqrt{n},\sqrt{m}$ no son racionales. No puede
tener automorfismos que lleven $\sqrt{n}$ en $\sqrt{m}$ porque $\sqrt{nm}$ no es un
cuadrado y entonces se tiene $n \neq m$.

Fijada la imagen de $\sqrt{n}$ entre dos posibles, sólo queda la imagen de 
$\sqrt{m}$ entre dos posibles. No puede ser por tanto $D_4$, y no puede ser
un grupo cíclico porque tiene elementos de orden $2$. Debe ser $V$.

****** Punto 3
Como $\mathbb{Q}(\sqrt{n}+\sqrt{m})$ genera una extensión de grado 4, será de grado 4
su polinomio irreducible, ya que hemos dicho que $\sqrt{nm}$ no es racional
y tenemos que:

\[ \frac{\sqrt{nm}}{\sqrt{n}+\sqrt{m}} = \frac{1}{\sqrt{1/n}+\sqrt{1/m}}\]

Ambos irreducibles por serlo $\sqrt{n}+\sqrt{m}$.

Por último, comprobamos que es un polinomio que lo tiene como raíz:

\[ x^4 - 2(n+m) x^2 + n^2 -2nm + m^2\]

A este polinomio llegamos simplemente manipulando algebraicamente
las representaciones de $(\sqrt{n}+\sqrt{m})^2$ y $(\sqrt{n}+\sqrt{m})^4$.

****** Punto 4
Si tomamos un elemento en $u \in F-\mathbb{Q}$, tenemos que $[F:\mathbb{Q}(u)]$ podría
ser $2$ o $1$. Si fuera $1$, entonces $\{1,u,u^2,u^3\}$ es base y $[F : Q(u^2)]$ sería
de grado $2$. Tendríamos un cíclico. Si fuera $2$, tenemos $u^2 \in \mathbb{Q}$,
como buscamos.

****** Punto 5
Tomamos $f_1(x) = (x^2-2)(x^2-3)$, que hemos demostrado en el punto
2 que funciona. $f_2(x) = x^4+3$ tiene grupo isomorfo a $D_3$.
En el punto 7 tenemos un ejemplo para $f_3$ en $x^4+5x^2+5$, que es
irreducible por Eisenstein en módulo 2.

****** Punto 6
Si tengo raíces $u,-u,v,-v$, tengo $\sqrt{c} = \pm uv$ racional. Cualquier
automorfismo de grado cuatro de los posibles llevaría $u \mapsto v$
$v \mapsto -u$, por lo que cambiaría el signo de un racional.

****** Punto 7
Si resolvemos la ecuación de grado $4$ tenemos:

\[ \sqrt{c} = uv \]
\[ \sqrt{b^2-4c} = (u^2-v^2)\]

El producto de ambas es racional, pero uno de los automorfismos de
grado dos que está en $V$ y en $D_4$, que lleva $u \mapsto v$, $v \mapsto u$, cambiaría
el signo de un real.
** Topología II
*** 1. El grupo fundamental
**** 1. Espacios conexos por arcos
***** Arcoconexión
*Arcoconexión*. Las curvas definen relación de equivalencia cuando
unen dos puntos.

 \[\exists f\ \text{arco}: f(0) = x, f(1) = y \Rightarrow x \sim y\]

Cada componente de esta partición es una *componente arcoconexa*. Un
espacio es *arcoconexo* cuando tiene una sola componente.

***** Operaciones en arcos y arcoconexión como equivalencia
Las propiedades de la relación de equivalencia se cumplen por:

 - 1. *Reflexividad*. Arco constante, $f(t) = x$, lleva a $x \sim x$.
 - 2. *Simetría*. Arco inverso, $\widetilde f(t) = f(1-t)$, lleva a $x\sim y \Rightarrow y \sim x$.
 - 3. *Transitividad*. Composición de arcos $f \ast g$.

La composición de arcos se define como:

\[f \ast g = \twopartdef{f(2t)}{t \leq \frac{1}{2}}{g(2t-1)}{t \geq \frac{1}{2}}\]

***** Arcoconexión y conexión
Un espacio *arcoconexo es conexo*. Un espacio *conexo localmente arcoconexo 
es arcoconexo*, que es conexo y donde todo punto posee un entorno arcoconexo.

****** Demostración
Dado un punto en un espacio arcoconexo, los caminos a los demás serán conexos y
compartirán un punto, luego su unión será conexa. Por otro lado, en un localmente
arcoconexo, todo punto está dentro de un abierto (tiene un entorno arcoconexo),
luego cada componente arcoconexa será abierta y si hubiera varias, contravendría
la conexión.

****** Contraejemplo del recíproco
Hay un contraejemplo de espacio conexo no arcoconexo en el
[[https://es.wikipedia.org/wiki/Seno_del_top%25C3%25B3logo][seno del topólogo]].

**** 2. Grupo fundamental
***** Homotopía de lazos
Un arco con $f(0) = f(1) = x$ es un *lazo* alrededor de $x$. Dos lazos son *homotópicos*
y escribimos $f \sim g$ cuando $\exists H: [0,1] \times [0,1] \longrightarrow X$, cumpliendo:

  - $H$ continua.
  - $H(t,0) = f(t)$
  - $H(t,1) = g(t)$
  - $H(0,s) = H(1,s) = x$

lo escribimos como $H : f \simeq g$.

***** Clases de homotopía
La homotopía es una relación de equivalencia entre lazos:

 - *Reflexividad*. Definiendo $H(t,s) = f(t)$, tenemos $H : f \simeq f$.
 - *Simetría*. Dada $G : g \simeq f$, definimos $H(t,s) = G(t,1-s)$, tenemos $H : f \simeq g$.
 - *Transitividad*. Dadas $F : f \simeq g$, $G : g \simeq h$, definimos
    \[H(t,s) = \twopartdef{F(t,2s)}{0\leq s \leq 1/2}{G(t,2s-1)}{1/2 \leq s \leq 1}\]
    Y tenemos $H : f \simeq h$.

Llamamos *clase de homotopía* $[f]$ a la clase de equivalencia de un lazo $f$.

***** Producto de clases de homotopía
El producto de lazos está bien definido entre las clases de homotopía. Sean 
$H : f_1 \simeq f_2$ y $G: g_1 \simeq g_2$; entonces definimos $F: f_1 \ast g_1 \simeq f_2 \ast g_2$ como:

\[ F(t,s) = \twopartdef{H(2t,s)}{0\leq t \leq 1/2}{G(2t-1,s)}{1/2 \leq t \leq 1}\]

***** El grupo fundamental
Comprobamos que las clases de homotopía sobre un $x$ forman un grupo con el producto:

\[\Pi(X,x) = \{[f] \mid f \text{ lazo alrededor de } x\}\]

****** Asociatividad
Para la *asociatividad*, definimos $H : (f \ast g) \ast h \simeq f \ast (g \ast h)$:

\[H(t,s) = \threepartdef
{f\left(t \frac{4}{1+s}\right)}{0\leq t\leq \frac{1+s}{4}}
{g\left(4t-1-s\right)}{\frac{1+s}{4}\leq t \leq \frac{2+s}{4}}
{h\left(t\frac{4}{2-s}-1\right)}{\frac{2+s}{4}\leq t\leq 1}\]

****** Elemento neutro
Como *elemento neutro* tomaremos el lazo constante $f_x(t)=x$. Y definimos  
$H : f_x \ast f \simeq f$:

\[ H(t,s) = \twopartdef
{f(t\frac{2t}{1+s})}{0\leq t\leq \frac{1+s}{2}}
{x}{\frac{1+s}{2}\leq t \leq 1}\]

****** Elemento inverso
Como *elemento inverso* tendremos el lazo $\hat{f}(t) = f(1-t)$. Y definimos 
$H : f \ast \hat{f} \simeq f$:

\[H(t,s) = \threepartdef
{f(2t)}{0\leq t\leq\frac{1-s}{2}}
{f(1-s)}{\frac{1-s}{2}\leq t\leq \frac{1+s}{2}}
{\hat{f}(2t-1)}{\frac{1+s}{2}\leq t\leq 1}\]

***** El grupo fundamental como funtor
Sea $\Phi : (X,x) \longrightarrow (Y,y)$ /continua/, entonces tenemos una aplicación bien definida 
por:

\[\Phi_\ast ([f]) = [\Phi \circ f] \]

Que es un homomorfismo de grupos. Podemos comprobar fácilmente que $Id_\ast = Id$ y que
$(\Psi\circ\Phi)_\ast = \Psi_\ast\circ\Phi_\ast$. Es decir, el grupo fundamental es un funtor de la categoría de 
los espacios topológicos punteados a la de los grupos.

****** Demostración
Sean $H: f \simeq g$, veamos que $\Phi\circ H: \Phi f \simeq \Phi g$. Tenemos que:

  - $\Phi\circ H$ continua
  - $\Phi\circ H(t,0) = \Phi\circ f(t)$
  - $\Phi\circ H(t,1) = \Phi\circ g(t)$
  - $\Phi \circ H(0,s) = \Phi \circ H(1,s) = y$

El que respeta el producto se tiene por $\Phi\circ (f \ast g) = \Phi\circ f \ast \Phi\circ g$.

***** Homotopía de arcos
Decimos que dos arcos cumpliendo $f(0)=g(0)$, $f(1)=g(1)$ son homotópicos cuando 
existe una función continua con características similares a la dada para lazos.

****** Propiedades
De demostración similar al caso de lazos:

  - Hay un arco simétrico $\tilde{f}$ tal que $f\ast \tilde{f} \simeq f_x$.
  - El producto es asociativo por homotopía $f \ast (g \ast h)\simeq (f\ast g)\ast h$-
    
***** Isomorfismo entre grupos fundamentales en distintos puntos
Sea un arco $\gamma : [0,1] \longrightarrow X$ cumpliendo $\gamma(0) = x$, $\gamma(1)=y$. Entonces se tiene un 
isomorfismo entre $\Pi(X,x)$ y $\Pi(X,y)$:

\[ F_\gamma([f]) = [\tilde\gamma\ast f\ast\gamma]\]

Por tanto, el grupo fundamental es el mismo en cualquier punto de la componente
arcoconexa.

****** Demostración
Para ver que está bien definido basta notar:

\[f \simeq g \Rightarrow 
\gamma\ast f\ast\tilde\gamma\simeq \gamma\ast g\ast\tilde\gamma\]

Que es homomorfismo se tiene viendo $F([f]\ast [g]) = F([f]) \ast F([g])$, y que es biyectivo
porque tiene inversa $G_\gamma([f]) = [\gamma\ast f\ast \tilde\gamma]$.

***** El grupo fundamental del producto
Dado el producto de dos espacios topológicos $X\times Y$ con proyecciones $\pi_1,\pi_2$. Tenemos
un isomorfismo entre grupos fundamentales:

\[F: \Pi(X\times Y, (x,y)) \longrightarrow \Pi(X,x)\times\Pi(Y,y)\]

Dado por:

\[F([f]) = (\pi_1([f]), \pi_2([f]))\]

**** 3. El grupo fundamental del círculo
***** Cálculo del grupo fundamental del círculo
Usaremos la teoría de recubridores que se probará luego.

Probamos que $\pi : \mathbb{R} \longrightarrow \mathbb{S}$ es un recubridor con $\pi(t) = e^{it}$; podemos tomar como entorno
fundamental de $p$ a $\mathbb{S}-\{p\}$, que tiene en la preimagen componentes arcoconexas 
homeomorfas a él. Siendo $t_0 \in \pi^{-1}(p)$:

\[V_m = (t_0 + 2\pi m, t_0 + 2\pi(m+1))\]

Definimos ahora el grado de un lazo en el círculo como:

\[\operatorname{deg}(f) = \frac{\hat{f}(1) - \hat{f}(0)}{2\pi} \]

Y comprobamos que está bien definido entre las clases de homotopía levantando
las homotopías y viendo que debe ser constante el punto final para que se proyecte
en un punto constante. Es decir $f \simeq g \Rightarrow \hat{f}(0) = \hat{g}(0)
\Rightarrow \hat{f}(1) = \hat{g}(1)$.

Como el levantamiento de la composición es la composición de levantamientos
y levantando de forma que $\hat{g}(0) = \hat{f}(1)$:

\[ \operatorname{deg}(f \ast g) =
   \frac{\widehat{f\ast g}(1) - \widehat{f\ast g}(0)}{2\pi} = 
   \frac{\hat{f}(1) - \hat{g}(0) + \hat{g}(1) - \hat{f}(0)}{2\pi} =
   \operatorname{deg}(f) + \operatorname{deg}(g) \]

Siendo un homomorfismo del grupo fundamental del círculo con $\mathbb{Z}$.

***** Teorema fundamental del álgebra
*Teorema fundamental del álgebra*. Todo polinomio con coeficientes
en $\mathbb{C}$ de grado $n$ tiene $n$ raíces en $\mathbb{C}$.

****** Demostración
Supongamos un $P$ que no tuviera raíz en $\mathbb{C}$.

Fijado un $r$, restringimos el polinomio desde la circunferencia de
radio $r$ a la circunferencia unidad, girándolo
además para que en $0$ valga $1$.

\[f_r(t) = \frac{|P(r)|}{P(r)} \frac{P(re^{2\pi it})}{|P(re^{2\pi it})|}\]

Tenemos una homotopía de este lazo al constante, definida como:

\[H(t,s) = f_{(1-s)r}(t)\]

Y por tanto, $deg(f_r) = 0$.

Por otro lado, sea ahora $R > 1, \sum |a_i|$, y tomemos $|z| = R$, tenemos
por un lado:

\[|z^n| 
 = R^n > R^{n-1}\left(\sum |a_i|\right) 
 \geq |a_1z^{n-1} + \dots + a_n|\]

Y por otro lado, si tomo un $t \in [0,1]$, puedo definir una familia
de polinomios $P_s(z) = z^n + t(a_1z^{n-1} + \dots + a_n) = 0$, que no tienen raíces
porque, por otro lado:

\[|z^n| = |t||a_1z^{n-1} + \dots + a_n| \leq |a_1z^{n-1} + \dots + a_n|\]

Luego esta familia de polinomios no tiene raíces en el círculo 
de radio $R$. Podemos ahora definir otra homotopía:

\[H(t,s) = \frac{P_s(Re^{2\pi it})}{|P_s(Re^{2\pi it})|}  \frac{|P_s(R)|}{P_s(R)}\]

Que es homotopía entre $e^{2\pi int}$ y $f_R(t)$. Luego $deg(f_R) = n$.

***** Lema al punto fijo de Brower
No existe aplicación continua $f : D^2\longrightarrow \mathbb{S}$ tal que $f|_\mathbb{S} = id$.

****** Demostración
Estamos buscando una aplicación cumpliendo:

\[ \begin{tikzcd}
\mathbb{S} \rar[hook]{i} & D^2 \rar{f} & \mathbb{S}
\end{tikzcd} \]

Aplicando el funtor obtendríamos:

\[ \begin{tikzcd}
\mathbb{Z} \rar[hook] & 0 \rar & \mathbb{Z}
\end{tikzcd} \]

Pero así es imposible obtener la identidad como composición.

***** Teorema del punto fijo de Brower
Toda función continua $f : D^2 \longrightarrow D^2$ tiene un punto fijo.

****** Demostración
Si no lo hubiera, para cada $x$ tomo $f(x)$ y la intersección de la recta que los une
con el círculo más cercana a $x$. Tengo una aplicación cuya restricción es la 
identidad.

***** Grupos topológicos
Un grupo topológico es un grupo en la categoría de espacios punteados. Esto es,
tal que la función producto y la función inverso son continuas.
***** Grupos topológicos y grupo fundamental
El producto en un grupo topológico respeta clases de homotopía:

\[ [f]\cdot [g] = [f\cdot g]\]

Y además, actúa sobre ellas igual que la composición:

\[ [f]\ast [g] = [f] \cdot [g]\]

**** 4. Tipo de homotopía. Equivalencias homotópicas
***** Aplicaciones homotópicas
Sean $F,G : X \longrightarrow Y$ continuas. Las decimos *homotópicas* si existe 
$H : X \times [0,1] \longrightarrow Y$ tal que $H(x,0) = F(x)$ y $H(x,1) = G(x)$. Lo notamos
por $H: F\simeq G$.

***** Grupo fundamental entre dos puntos
Entre cualesquiera puntos de dos funciones homotópicas $F(x_0)$, $G(x_0)$; tenemos un 
arco $\gamma = H(x_0,t)$. Se cumple que:

\[ \begin{tikzcd}
& \Pi(Y,F(x_0)) \arrow[leftrightarrow]{dd}{F_\gamma}\\
\Pi(X,x_0) \urar{F_\ast}\drar{G_\ast} \\
& \Pi(Y,G(x_0))
\end{tikzcd} \]

****** Demostración
Sea $f \in \Pi(X,x_0)$. Si defino la función $\hat{H}(t,s) = H(f(t),s)$ tengo una homotopía como
la siguiente:

\begin{tikzpicture}
\draw (A) -- node [above] {$G f$} ++ (-1, 0)
-- node [left]  {$\gamma$} ++ (0, -1)
-- node [below] {$F f$} ++ (1, 0)
-- node [right] {$\gamma$} ++ (0, 1);
\end{tikzpicture}

Rotándola obtengo:

\begin{tikzpicture}
\draw (A) -- node [above] {$G f \circ \gamma$} ++ (-1, 0)
-- node [left]  {$F(x_0)$} ++ (0, -1)
-- node [below] {$\gamma \circ F f$} ++ (1, 0)
-- node [right] {$G(x_0)$} ++ (0, 1);
\end{tikzpicture}

Lo que me da $[Gf \circ \gamma] = [\gamma \circ Ff]$, y por tanto $[Gf] = [\gamma \circ Ff \circ \tilde{\gamma}]$.

***** Equivalencia homotópica
Una *equivalencia homotópica* es una aplicación continua $F$, para la que
existe $G$ cumpliendo $F \circ G \simeq G \circ F \simeq Id$.

***** Propiedades de la equivalencia homotópica
Cumple:

1. Los homeomorfismos son equivalencias homotópicas.
2. La inversa de una equivalencia homotópica es equivalencia homotópica.
3. La composición de equivalencias homotópicas es equivalencia homotópica.

***** Conservación del grupo fundamental por equivalencia homotópica
Sea $F: X\longrightarrow Y$ equivalencia homotópica:

\[\forall x\in X : F_\ast : \Pi(X,x) \longrightarrow \Pi(Y,F(x))\]

Es un isomorfismo

****** Demostración
Por ser equivalencia homotópica tengo que $F \circ G \simeq Id$, luego se cumple:

\[ \begin{tikzcd}
& \Pi(X,F\circ G(x_0)) \arrow[leftrightarrow]{dd}{\cong}\\
\Pi(X,x_0) \urar{(F\circ G)_\ast}\drar{Id} \\
& \Pi(X,x_0)
\end{tikzcd} \]

Así, $(F\circ G)_\ast$, y de la misma forma $(G\circ F)_\ast$ son isomorfismos. Tenemos por tanto:

\[ \begin{tikzcd}
\Pi(X,x) \rar{F_\ast} \arrow[bend left=20]{rr}{\cong}
& \Pi(Y,F(x)) \rar{G_\ast} \dlar{\cong}
& \Pi(X,(G\circ F)(x)) \dlar{\cong}
\\
\Pi(Y,F(x)) \rar{F_\ast} \arrow[bend right=20]{rr}{\cong}
& \Pi(X,(G\circ F)(x)) \rar{F_\ast}
& \Pi(X,(G\circ F)(x))
\end{tikzcd} \]

Demostrando ambas filas que $F_\ast$ y $G_\ast$ son isomorfismos.

***** Lema a Borsuk-Ulam
No existe $F: \mathbb{S}^2 \longrightarrow \mathbb{S}^1$ continua respetando antípodas.

\[F(-x) = -F(x)\]

****** TODO Demostración
***** Teorema de Borsuk-Ulam
Sea $F:\mathbb{S}^2 \longrightarrow \mathbb{R}^2$ continua, entonces:

\[\exists x\in\mathbb{S}^2 : F(-x) = F(x)\]

****** Demostración
Supongamos que no se cumpliera, definimos:

\[G(x) = \frac{F(x)-F(-x)}{|F(x)-F(-x)|}\]

Y entonces $G$ sería continua respetando antípodas.

***** Teorema del sandwich de jamón
Sean $A,B\subset \mathbb{R}^2$ compactos y conexos. Existe una recta dividiendo a ambos en dos
trozos de igual área.

****** TODO Demostración
***** Espacio proyectivo
En $\mathbb{S}^n$ defino la ralación de equivalencia $p \sim q$ ssi $p = \pm q$. Definimos el 
espacio proyectivo como el cociente bajo esta relación:

\[\mathbb{RP}^n = \mathbb{S}^n}/\sim\]

**** 5. Teorema de Seifert-Van Kampen
***** Producto libre de grupos
Si definimos el *producto libre* de grupos en términos de palabras; podemos 
llamar *grupo libre sobre un conjunto de generadores* al producto libre del 
grupo libre generado por cada uno de ellos.

***** Subgrupo normal generado
El *subgrupo normal generado* por un subgrupo $B$ o por un conjunto de 
generadores es:

\[ \{g \cdot b \cdot g^{-1} \mid g\in G, b\in B\}\]

***** Producto libre amalgamado
Sean tres grupos $A$, $G_1$, $G_2$ y dos proyecciones de $A$ en ellos, llamadas 
$\Phi_1,\Phi_2$. Definimos el *producto libre amalgamado* como:

\[G_1 \ast_{A} G_2 =
\frac{G_1 \cdot G_2}{N} = \frac{G_1 \cdot G_2}{\{\Phi_1(a)=\Phi_2(a)\}}\]

Donde estamos dividiendo por $N$, el subgrupo normal generado por 
$\{\Phi_1(a)\Phi_2(a)^{-1} \mid a \in A\}$. Es decir, imponemos la relación $\Phi_1(a) = \Phi_2(a)$.

***** Teorema de Seifert-Van Kampen
Sea $X$ espacio topológico con $U,V$ abiertos arcoconexos no vacíos de $X$ tales 
que $X = U \cup V$ y $U\cap V$ son arcoconexos. Existe un isomorfismo:

\[\Theta : \Pi(U,x) \ast_{\Pi(U\cap V,x)} \Pi(V,x) \longrightarrow \Pi(X,x)\]

donde se amalgama usando $i_\ast$, $j_\ast$, homomorfismos dados por las inclusiones.

***** Seifert-Van Kampen para intersección simplemente conexa
En las condiciones del teorema, con $U\cap V$ simplemente conexo, se tiene:

\[\Pi(X,x) \cong \Pi(U,x)\ast\Pi(V,x)\]

***** Seifert-Van Kampen para abierto simplemente conexo
En las condiciones del teorema, con $V$ simplemente conexo, se tiene:

\[\Pi(X,x) \cong \Pi(U,x)/N\]

Con $N$ es el subgrupo normal generado por $i_\ast(\Pi(U\cap V,x))$.

**** Extra: Teoría de categorías
***** El grupo fundamental como funtor
El grupo fundamental $\Pi$ es un funtor entre las categorías:

- =Top.= de los espacios topológicos con un punto base, usando como morfismos
  las funciones continuas respetando punto base.
- =Grp= de los grupos con los homomorfismos de grupos.

Estamos llamando $f_\ast$ a los morfismos creados por el funtor, $\Pi(f)$.

***** Producto categórico
El producto de dos espacios con un punto base es, usando la topología producto:

\[(X,x) \times (Y,y) \cong (X\times Y, (x,y))\]

El funtor lo lleva al producto de grupos.

***** Coproducto categórico
El coproducto de dos espacios con un punto es la suma directa de los espacios
identificando el punto. Intuitivamente, consiste pegar los dos espacios por ese
punto.

\[ X \wedge Y \cong (X \amalg Y)/(x\sim y)\]

Cuando además tenemos espacios localmente contractibles, el coproducto se lleva
al coproducto de grupos, esto es, al producto libre:

\[\Pi(X \wedge Y) \cong \Pi(X) \ast \Pi(Y)\]

Nótese que esto es un caso particular de Seifert-Van Kampen.

***** TODO Seifert-Van Kampen
*** 2. Recubridores
**** 1. Introducción
***** Localmente arcoconexo
Un espacio es *localmente arcoconexo* si todo punto posee una base de 
entornos arcoconexos.

/Durante este tema tomamos los espacios como arcoconexos y localmente 
arcoconexos/.

***** Recubridores
Un *recubridor* de $X$ es un par $(Y,p)$ donde $p : Y \longrightarrow X$ es continua; 
cumpliendo que todo $x\in X$ tiene un entorno abierto $U$, llamado *entorno 
fundamental* tal que toda componente arcoconexa de $p^{-1}(U)$ se aplica 
homeomórficamente por $p$ sobre $U$.

***** Ejemplos de recubridores
Ejemplos básicos de recubridores son:

- Cualquier homeomorfismo $p : Y \longrightarrow X$
- $p : \mathbb{S}^1\longrightarrow\mathbb{S}^1$, con $p(z) = z^n$

***** Homeomorfismos locales
Un *homeomorfismo local* es una aplicación continua $f : Y \longrightarrow X$ tal que para 
todo $y\in Y$ existe $y \in V\in\tau_Y$ tal que $f|_V$ es homeomorfismo.

***** Propiedades de un recubridores
Sea $(Y,p)$ recubridores de $X$. Entonces:

1. $p$ es sobreyectiva.
2. $p$ es una aplicación abierta.
3. $p$ es un homeomorfismo local.

****** Demostración
La sobreyectividad es trivial por la definición. Dado un abierto $y\in O$; 
tengo $y \in V_y \cong U_x$ su entorno abierto, luego $p(O\cap V_y)$ es abierto. De esta 
forma,

\[p(O) = \bigcup_{y\in O} p(O \cap V_y)\]

es abierto.

**** 2. Grupo fundamental y levantamiento de aplicaciones al recubridor
***** Levantamiento de arcos
Sea $(Y,p)$ recubridor con $x_0\in X$ y $y_0 \in p^{-1}(x_0)$. Sea $f : [0,1]\longrightarrow X$ arco 
continuo con $f(0) = x_0$, entonces existe un único arco continuo $\check{f}$ cumpliendo:

  - $\check{f}(0) = y_0$
  - $p \circ \check{f} = f$

    Llamado el *levantamiento* de $f$.

****** Existencia
Tomo $\{f^{-1}(U^x) \mid x\in X\}$, que recubre por abiertos a $[0,1]$. Sabemos que 
existirá una partición del intervalo cumpliendo:

\[\exists 0 < t_1 <\dots < t_n < 1: f([t_i,t_{i+1}]) \subseteq U^{x_i}\]

La correspondiente $y_i \in V^{y_i}$ nos da un isomorfismo $p_i$ que nos 
deja definir $\check{f} : [t_i,t_{i+1}] \longrightarrow V^{y_i}$ mediante $\check{f} = (p|_{V^{y_i}})^{-1} \circ f$. Nótese que para 
tomar cada $y_i$ necesitamos usar la componente arcoconexa de la última $\check{f}(t_{i-1})$.

****** Unicidad
Sean dos levantamientos $g_1,g_2$. Su conjunto ecualizador es cerrado:

\[ A = \{ t \mid g_1(t) = g_2(t)\} \neq \varnothing\]

Pero también es abierto porque dado un punto donde coincidan, puedo tomar la 
componente arcoconexa que es isomorfa por $p$ a un entorno abierto; y las 
curvas deben coincidir en él.

***** Levantamiento de homotopías
Sea $(Y,p)$ recubridor con $x_0\in X$ y $y \in p^{-1}(x_0)$. Sea $H : [0,1]\times[0,1] \longrightarrow X$ 
continua con $H(0,0) = x_0$, entonces existe una única aplicación
continua $\check{H} : [0,1]\times [0,1] \longrightarrow Y$ cumpliendo:

  - $p \circ \check{H} = H$
  - $\check{H}(0,0) = y_0$

    Llamada el *levantamiento* de $H$.

****** Existencia
Tomamos las $\{ H^{-1}(U^x) \mid x \in X \}$ y tenemos recubrimiento por abiertos de $[0,1]^2$. 
Tendremos alguna partición cumpliendo:

\[\exists 0 < t_1 < \dots < t_n < 1 : 
H([t_i,t_{i+1}]\times[s_i,s_{i+1}]) \subset U^{x_i}\]

En la correspondiente $y_i \in V^{y_i}$ podemos definir 
$\check{H} = (p|_{V^{y_i}}^{-1})\circ H$. Nótese que tenemos que usar en cada paso la componente arcoconexa
del último lado unido a nuestro cuadrado, que no puede salirse de esa componente
por ser arcoconexa.

****** TODO Unicidad
***** Hojas del recubridor
Sea $p : Y\longrightarrow X$ recubridor. Los cardinales de los $p^{-1}(x)$ son un invariante 
llamado el *cardinal de hojas del recubridor*.

****** Demostración
Puedo definir una biyección entre $p^{-1}(x_1)$ y $p^{-1}(x_2)$ tomando un arco entre 
ellas $\gamma$, y levantándolo en cada componente. Los arcos arriba me relacionan 
los dos conjuntos. La biyección se obtiene levantando $\tilde\gamma$, que sé que es $\tilde{g}$ 
porque ella ya es un levantamiento y es único.

***** Los recubridores crean monomorfismos
Sea $p: Y \longrightarrow X$ recubridor, entonces $p_\ast : \Pi(Y,y) \longrightarrow \Pi(X,x)$ es monomorfismo.

****** Demostración
Supongamos $p_\ast[h] = 0$; tengo una homotopía $H : p \circ h \simeq f_x$ que puedo levantar tomando
$\check{H}(0,0)=y$ y sabiendo $p \circ \check{H} = H$. Tengo:

\[ p \circ \check{H} (t,0) = H(t,0) = (p\circ h)(t)\]
\[ p \circ \check{H} (t,1) = H(t,1) = f_x(t) = x\]

Luego $\check{H}(t,0) = h(t)$ porque son levantamientos de lo mismo y $\check{H}(t,1) = y$ para poder
ser levantamiento. Esto me da $\check{H} : h \simeq f_y$.

***** Conjugación y recubridores
Si $p : Y \longrightarrow X$ es recubridor y $x\in X$, entonces la familia de subgrupos:

\[ \left\{p_\ast(\Pi(Y,y)) \mid y\in p^{-1}(x)\right\}\]

forma exactamente una clase de conjugación de subgrupos de $\Pi(X,x)$.

****** Demostración
Sea $\gamma$ camino entre $y_1,y_2 \in p^{-1}(x)$ con el isomorfismo $F_\gamma([f]) = [\tilde\gamma \ast f \ast \gamma]$, construimos 
el diagrama:

\[ \begin{tikzcd}
\Pi(Y,y_1) \rar{F_\gamma} \dar{p_\ast} & \Pi(Y,y_2) \dar{p_\ast} \\
\Pi(X,x) \rar{F_{p \circ \gamma}}& \Pi(X,x)
\end{tikzcd} \]

Que es conmutativo:

\[ \begin{tikzcd}
\math{[f]} \rar{F_\gamma} \dar{p_\ast} & 
\math{[\tilde\gamma \ast f \ast\gamma]} \dar{p_\ast} \\
\math{[p\circ f]} \rar{F_{p \circ \gamma}} & 
\math{[p(\tilde\gamma) \ast p(f) \ast p(\gamma)]}
\end{tikzcd} \]

Y que nos da por tanto:

\[ p_\ast(\Pi(Y,y_2)) = 
F_{p\circ\gamma}(\Pi(Y,y_1)) =
[p(\tilde\gamma)] \ast \Pi(Y,y_1) \ast [p(\gamma)]
\]

Ahora, sea una clase de conjugación de la proyección de un grupo fundamental
$H = [g]^{-1} \ast p_\ast(\Pi(Y,y)) \ast [g]$. El levantamiento $\check{g}$ da un camino entre dos puntos de 
$p^{-1}(x)$, y vemos que:

\[ \begin{aligned}
H &= \{[g]^{-1} \ast [p\circ h] \ast g \mid [h] \in \Pi(Y,y)\} \\
&= \{[p\circ \tilde{\check{g}} \ast p\circ h \ast p \circ \check{g}] \mid [h] \in \Pi(Y,y)\} \\
&= p_\ast(F_{\check{g}}(\Pi(Y,y))) = p_\ast(\Pi(Y,y'))
\end{aligned} \]

***** Levntamiento de aplicaciones
Sea $\Phi : Z \longrightarrow X$ continua con $x_0 = \Phi(z_0)$, $y_0 \in p^{-1}(x_0)$. Tenemos que
$\exists! \Psi : Z \longrightarrow Y$ continua cumpliendo:

- $\Psi(z_0) = y_0$
- $p \circ \Psi = \Phi$

ssi $\Phi_\ast(\Pi(Z,z_0)) \subset p_\ast(\Pi(Y,y_0))$.

****** Demostración
Definimos:

\[\check\Phi(z) = \widehat{\Phi \circ f}(1)\]

Siendo el levantamiento de la imagen de una curva que tenía $f(1)=z$, $f(0)=z_0$.
Esta es una función que lo cumple; debemos demostrar que está *bien definida* y
que es continua. Esto es, $\widehat{\phi \circ g}(1) = \widehat{\phi\circ f}(1)$, para otro $g$ cumpliendo lo mismo que $f$.

Como tenemos por la condición que $\phi_\ast[f \ast\tilde{g}] = p_\ast(\alpha)$, tenemos que ambas
$H : \phi(f \ast \tilde{g}) \simeq p\circ \alpha$. Tomamos $[f \circ \tilde{g}]$ para ver:

\[ p(\widehat{\phi\circ f} \ast \widehat{\phi\circ g}) = 
\phi\circ f \ast \widetilde{\phi\circ g}\]

Y usando eso, levantamos la homotopía, para tener 
$\check{H} : \widehat{\phi\circ f} \ast \widehat{\phi \circ \tilde{g}} 
\simeq \alpha$. Pero como $\alpha$ es lazo, tengo que es lazo lo primero.

Para ver que es *continua*, sea $\check{\Phi}(z) \in O$, abierto. Tenemos $p(O)$ abierto y tomamos
$W$ como la arcocomponente de la preimagen de $U^{\Phi(z)}$ en la que está $\check{\Phi}(z)$. Ahora
sea $\Phi(z) \in p(W \cap O)$, abierto por homeomorfismo; y sea

$\Phi(\hat{O}) \subset p(W \cap O)$, que existe por continuidad de $\Phi$ y es abierto arcoconexo. 

Veamos que $\Phi(\hat{O}) \subset \check{\Phi}^{-1}(O)$. Si $\hat{z} \in \hat{O}$, entonces hay un arco $g$ que une $z$ y $\hat{z}$; y tenemos
$\Phi(g) \subset p(W\cap O)$; como hay homeomorfismo, su levantamiento está en $W \cap O$, y
se tiene:

\[\check{\Phi}(z) = \widehat{\Phi(g)}(1) \in O\]

***** Estructura de grupo topológico
Sea $G$ un grupo topológico con neutro $e$. Sea $(\check{G},p)$ un recubridor y 
$\check{e} \in p^{-1}(e)$. Entonces $\check{G}$ admite una estructura de grupo topológico que tiene
a $\check{e}$ como elemento neutro y a $p$ como homomorfismo de grupos.

**** 3.1. Isomorfismos de recubridores
***** Homomorfismos
Sean $(Y_1,p_1)$, $(Y_2,p_2)$ recubridores. Un *homomorfismo de recubridores* es
$\Phi : (Y_1,p_1) \longrightarrow (Y_2,p_2)$ continua con $p_2 \circ \Phi = p_1$.

\[ \begin{tikzcd}
Y_1 \drar[swap]{p_1} \arrow{rr}{\Phi} & & Y_2 \dlar{p_2} \\
& X &
\end{tikzcd} \]

***** Propiedades de los homomorfismos de recubridores
Los homomorfismos de recubridores cumplen:

   1. La composición de homomorfismos es homomorfismo.
   2. La identidad $Id : Y \longrightarrow Y$ es homomorfismo.
   3. El inverso de isomorfismo es isomorfismo.

      Llamamos $Aut(Y,p)$ al *grupo de automorfismos* de un recubridor.
      # ¡Forman una categoría! Debe ser algo como una "slice category".

***** Puntos fijos de los automorfismos de recubridores
Sean dos homomorfismos de recubridores $\Phi,\Psi$ con $\Phi(y) = \Psi(y)$ en algún punto; 
entonces $\Phi = \Psi$. Por tanto, todo automorfismo distinto de la identidad actúa 
sin puntos fijos.

***** Existencia de homomorfismos
Existe un homomorfismo de recubridores $\Phi : (Y_1,p_1) \longrightarrow (Y_2,p_2)$ con $\Phi(y_1) = y_2$ ssi
$p_1_\ast(\Pi(Y_1,y_1)) \subseteq p_2_\ast(\Pi(Y_2,y_2))$. Es isomorfismo en el caso de igualdad.

***** Existencia de isomorfismos
Dos recubridores son isomorfos ssi las clases de conjugación asociadas a sus 
proyecciones al grupo fundamental son iguales:

\[\{ p_1_\ast(\Pi(Y_1,y)) \mid y\in p_1^{-1}(x)\}
= \{ p_2_\ast(\Pi(Y_2,y)) \mid y\in p_2^{-1}(x)\}\]

***** Ejemplos de recubridores
****** Espacios simplemente conexos
Sólo se admiten a sí mismos como recubridores.
****** Circunferencia unidad
Grupo fundamental isomorfo a $\mathbb{Z}$ y abeliano. Sus subgrupos son de la forma $m\mathbb{Z}$,
así que, salvo isomorfismos, sus recubridores son de la forma:

\[ p_0 : \mathbb{R} \longrightarrow \mathbb{S}^1,\ p(t) = e^{it} \]
\[p_m : \mathbb{S}^1 \longrightarrow \mathbb{S}^1,\ p_m(z) = z^m\]

****** Espacio proyectivo
Como $\mathbb{R}\mathbb{P}^n$ tiene grupo fundamental $\mathbb{Z}_2$, tiene sólo a $(\mathbb{RP}^n,Id)$ y a $(\mathbb{S}^n,p)$ 
como recubridores.

***** Recubridores de recubridores
Sean $(Y_1,p_1)$, $(Y_2,p_2)$ dos recubridores, y sea $\Phi : Y_1 \longrightarrow Y_2$ un homomorfismo de 
recubridores. Entonces $(Y_1,\Phi)$ es un recubridor de $Y_2$.

***** Recubridores universales
Un recubridor $(\check{X},p)$ de $X$ es *universal* si $\check{X}$ es simplemente conexo.

**** 3.2. Automorfismos de recubridores
***** Acción del grupo fundamental
Sea $(Y,p)$ un recubridor y $x$ punto de $X$ definimos la acción

\[ (\cdot) : p^{-1}(x) \times \Pi(X,x) \longrightarrow p^{-1}(x) \]

construyendo $y \cdot \alpha$ como sigue: sea $\alpha = [f]$, tomamos $\check{f}(0) = y$ y llamamos 
$y \cdot \alpha = \check{f}(1)$.

****** TODO Está bien definida
****** TODO Es una acción transitiva
****** TODO Espacios homogéneos.
***** Índice y hojas del recubridor
Sea $(Y,p)$ recubridor; su número de hojas es el índice del subgrupo  $p_\ast(\Pi(Y,y))$ 
en $\Pi(X,x)$; donde $y \in p^{-1}(x)$.

***** Automorfismos del espacio homogéneo
Un *automorfismo del espacio homogéneo* $p^{-1}(x)$ es una biyección
$\varphi : p^{-1}(x) \longrightarrow p^{-1}(x)$ tal que:

\[ \varphi(y \cdot \alpha) = \varphi(y) \cdot \alpha\]

***** Automorfismos del espacio homogéneo y automorfismos de recubridores
Como dado un automorfismo de recubridores $\Phi\in Aut(Y,p)$, tenemos que 
$\Phi(y\cdot \alpha) = \Phi(y)\cdot\alpha$, tenemos $\Phi|_{p^{-1}(x)}$ un automorfismo del espacio homogéneo.
De hecho, es isomorfismo de grupos:

\[ ( \bullet |_{p^{-1}(x)}) : Aut(Y,p) \longrightarrow Aut(p^{-1}(x))\]

****** Demostración
******* La restricción es automorfismo en el espacio homogéneo
Sea $y\in p^{-1}(x)$, tenemos $p(\Phi(y)) = p(y) = x$, luego $\Phi(y) \in p^{-1}(x)$.

******* Los automorfismos de recubridor respetan la acción de grupos
Sea $[f]=\alpha$, y sea $\check{f}$ su levantamiento en $y$; si considero $\Phi(\check{f})$ puedo 
comprobar que $\Phi(\check{f})(0) = \Phi(y)$ y que $p \circ \Phi (\check{f}) = f$, luego es el levantamiento
de $f$ en $\Phi(y)$. Así:

\[\Phi(y)\cdot\alpha = \Phi(\check{f})(1) = \Phi(y \cdot \alpha)\]

******* Es inyectiva
Llamamos $F = (\bullet |_{p^{-1}(x)})$. Sea $\Phi\in\ker(F)$, entonces $\Phi|_{p^{-1}(x)} = Id$; pero dos
homomorfismos de recubridores coindiciendo en un punto son iguales.

******* Es sobreyectiva
Sea $\varphi\in Aut(p^{-1}(x))$. Por el lema de existencia:
       
\[\exists \phi\in Aut(Y,p): \phi(y) = \varphi(y) \Leftrightarrow
p_\ast(\Pi(Y,y)) = p_\ast(\Pi(Y,\varphi(y))\]
       
Pero tenemos la igualdad de estos dos grupos de isotropía por:
       
\[\begin{aligned}
H_{\varphi(y)} 
&= \{\alpha\in\Pi(X,x) \mid \varphi(y)\cdot\alpha = \varphi(y)\} \\
&= \{\alpha\in\Pi(X,x) \mid \varphi(y\cdot\alpha) = \varphi(y)\} \\
&= \{\alpha\in\Pi(X,x) \mid y\cdot\alpha = y\} = H_y\\
\end{aligned}\]
       
***** Identificación de automorfismos de un espacio homogéneo
Dado $E$ espacio homogéneo sobre $G$, existe el isomorfismo:

\[ Aut(E) \cong N(H)/H \]

donde $H = \operatorname{Stab}(y)$ y $N(H)$ es su normalizador, el mayor 
grupo en el que es normal.

***** Identificación de automorfismos del recubridor
Aplicando las dos identificaciones anteriores:

\[Aut(Y,p) \cong N(p_\ast(\Pi(Y,y))) / p_\ast(\Pi(Y,y))\]

***** Recubridores regulares
Un recubridor es *regular* cuando $p_\ast(\Pi(Y,y))$ es subgrupo normal de 
$\Pi(X,x)$ siendo $y \in p^{-1}(x)$. Equivalen, por conjugación:

- $\exists x\in X, y \in Y: p_\ast(\Pi(Y,y))$ subgrupo normal en $\Pi(X,x)$.
- $\forall x\in X, y \in Y: p_\ast(\Pi(Y,y))$ subgrupo normal en $\Pi(X,x)$.

***** Propiedades de recubridores regulares
Sea $(Y,p)$ un recubridor regular:

1. $Aut(Y,p) \cong \Pi(X,x)/p_\ast(\Pi(Y,y))$
2. Si es el universal, $Aut(Y,p) \cong \Pi(X,x)$. Y el número de hojas es 
   el orden de $\Pi(X,x)$.

***** Ejemplos de recubridores
****** Circunferencia, recubridor universal
Tenemos el recubridor $(\mathbb{R},p)$ de $\mathbb{S}$, que tiene como automorfismos:

\[Aut(\mathbb{R},p) = \{\Phi_n(t) = t + 2\pi n \mid n \in \mathbb{N}\}\]

****** Espacio proyectivo
Siendo $(\mathbb{S}^n,p)$ un recubridor de dos hojas de $\mathbb{RP}^n$, sus automorfismos 
vienen dados por:

\[Aut(\mathbb{RP}^n,p) = \{Id, -Id\}\]

****** Circunferencia, otros recubridores
Sean los recubridores $(\mathbb{S}^1,p_n)$ de $\mathbb{S}^1$. Sus grupos de automorfismos son:

\[Aut(\mathbb{S}^1,p_n) = \left\{\Phi_k(z) = e^{\frac{2\pi k}{n}i}z 
\mid k = 0,1,\dots,n-1 \right\}\]

***** Teorema de Borsuk-Ulam
No existe una aplicación continua $F : \mathbb{S}^2 \longrightarrow \mathbb{S}^1$ respetando antípodas, es decir,
$F(-x) = -F(x)$.

**** 4. Recubridores regulares y espacios cocientes
***** Acción transitiva de automorfismos de recubridores regulares
$Aut(Y,p)$ actúa transitivamente sobre $p^{-1}(x)$ ssi $(Y,p)$ es regular.

***** Acciones discontinuas
Un $G \subset Homeo(Y)$ *actúa discontinuamente* si:
 
\[\forall y\in Y: \exists V_y\text{ entorno}: \forall \Phi \in G:\quad
\Phi \neq Id \Rightarrow \Phi(V) \cap V = \varnothing\]

***** Recubrimiento de cocientes
Sea $G \subset Homeo(Y)$ actuando propia y discontinuamente sobre $Y$. Si
$p : Y \longrightarrow Y/G$ es proyección al cociente, $(Y,p)$ es recubridor regular de $Y/G$, 
con $Aut(Y,p) = G$.

***** Espacios lente
Sean las aplicaciones $\Phi_k : \mathbb{S}^{2n+1} \longrightarrow \mathbb{S}^{2n+1}$ definidas por:

\[\Phi_k(z) = e^{\frac{2\pi ik}{p}}z\]

Entonces $G_p = \{\Phi_0,\Phi_1,\dots,\Phi_{p-1}\}$ actúa discontinuamente. Llamamos *espacio 
lente* al cociente:

\[ L_p^{2n+1} = \mathbb{S}^{2n+1}/G_p\]

**** 5. Existencia de espacios recubridores
***** Caso del recubridor universal
Si $X$ admite recubridor universal, toda clase de conjugación de subgrupos de
$\Pi(X,x)$ está asociada a un recubridor.

***** Espacios semilocalmente simplemente conexos
Todo $x$ posee un entorno abierto y arcoconexo $U_x$ tal que el homomorfismo 
inducido por la inclusión $\Pi(U_x,x) \longrightarrow \Pi(X,x)$ es trivial.

****** Contraejemplo
El espacio formado por infinitos círculos de radio cada vez menor y unidos 
en un punto:

\[ X = \bigcup_{n>0} \left\{(x,y) \in \mathbb{R}^2 \mid 
\left(x-\frac{1}{n}\right)^2 + y^2 = \frac{1}{n^2} \right\}\]

cumple que cualquier entorno del $(0,0)$ contiene un lazo no trivial.

***** Existencia del recubridor universal
Un espacio semilocalmente simplemente conexo tiene recubridor universal.

***** Teorema de existencia de recubridores
Sea $X$ semilocalmente simplemente conexo. Para toda clase de conjugación de 
subgrupos de $\Pi(X,x)$, existe un recubridor que la tiene asociada.

****** Demostración
Sea $C$ clase de conjugación de algún $H < \Pi(X,x)$. Sea $Y$ recubridor universal 
de $X$, que existe por ser semilocalmente simplemente conexo, cumpliendo 
$Aut(Y,p) \cong \Pi(X,x)$; puedo tomar $G < Aut(Y,p)$ cumpliendo $G \cong H$.

Los automorfismos del recubridor actúan discontinuamente, así que $Y/G$ es un 
espacio del que es $Y$ recubridor. Induciendo la siguiente aplicación:

\[ \begin{tikzcd}
Y \rar{p} \dar{q} & X \\
Y/G \urar{\hat{p}} &
\end{tikzcd} \]

Que está bien definida por respetar la relación y es continua. Veamos que es 
un recubridor. Sea $U^x$ entorno fundamental, las arcocomponentes de su 
preimagen cumplen:

\[ p^{-1}(U) = \bigcup_{\phi\in Aut(Y,p)} \phi(V) \]

Si tenemos en cuenta que $\forall \phi \in G: q(\phi(V)) = q(V)$, tendremos:

\[\hat{p}^{-1}(U)
= \bigcup_{\phi \in Aut(Y,p)/G} q(\phi(V)) \]

Donde hay $[G:H]$ componentes. Ahora intentamos ver que $\hat{p}_\ast(\Pi(Y/G,-))$ genera
la clase de conjugación de $C$. Recordando cómo actuaban los caminos en el 
espacio base sobre los puntos del recubridor, buscamos los $\alpha\in\Pi(X,x)$ que 
cumplan $q(y)\cdot\alpha = q(y)$, es decir $\exists \phi\in G: y\cdot\alpha = \phi(y)$; luego tenemos $\alpha\in H$. Si 
tengo otro $\beta \in H$, debe cumplir $\phi(y) = y\cdot\beta$ para algún $\phi\in G$, y entonces
$q(y)\cdot\alpha = q(y)$, siendo de los buscados. Tenemos:

\[\hat{p}(\Pi(Y/G, q(y)) = \operatorname{Stab}(q(y)) = H\]

***** Clasificación de recubridores del círculo
El círculo $\mathbb{S}^1$ tiene como grupo fundamental a $\mathbb{Z}$, que es abeliano y tiene como 
subgrupos a $n\mathbb{Z}$.

- $0$ tiene a la *recta* como recubridor universal $\mathbb{R}$ con $p(t) = e^{2\pi it}$.
- $n\mathbb{Z}$ tiene al *círculo* como recubridor $\mathbb{S}^1$ de $n$ hojas con $p(z) = z^n$.
- $\mathbb{Z}$ tiene al recubridor *identidad*.

***** Clasificación de recubridores del toro
El toro $\mathbb{S}^1\times\mathbb{S}^1$ tiene como grupo fundamental a $\mathbb{Z}\times\mathbb{Z}$, que tiene como subgrupos 
a los generados por un generador $<(a,b)>$ o a los generados por dos, de la 
forma $<(a,b),(0,d)>$.

- $0$ tiene al *plano* como recubridor universal $\mathbb{R}^2$ con $p(x,y) = (e^{2\pi ix},e^{2\pi iy})$.
- $<(a,b)>$ tiene al *cilindro* como recubridor $\mathbb{S}\times\mathbb{R}$ con $p(z,y) = (az, bze^{2\pi iy})$.
- $<(a,b),(0,d)>$ tienen al *toro* como recubridor $\mathbb{S}\times\mathbb{S}$ con
  $p(z,w) = (z^a,z^bw^d)$.

***** Clasificación de recubridores del cilindro
El cilindro $\mathbb{S}\times\mathbb{R}$ tiene como grupo fundamental a $\mathbb{Z}$, que es abeliano y tiene 
como subgrupos a $n\mathbb{Z}$.

- $0$ tiene al *plano* como recubridor universal $\mathbb{R}^2$ con $p(x,y) = (e^{2\pi ix},y)$.
- $n\mathbb{Z}$ tiene al *cilindro* como recubridor universal con $p(z,y) = (e^{2\pi inz},y)$.
- $\mathbb{Z}$ tiene al recubridor *identidad*.

***** Clasificación de recubridores de la cinta de Möbius.
La cinta de Möbius tiene tipo de homotopía del círculo y por tanto grupo 
fundamental $\mathbb{Z}$. 

- $0$ tiene al *plano* como recubridor universal $\mathbb{R}^2$ sobre el que actúa el grupo
  $\phi_n(x,y) = (x+n, (-1)^ny)$ discontinuamente.
- $n\mathbb{Z}$ con $n = 2m$ par tiene al *cilindro* recubriéndose a sí mismo $m$ veces y 
  un recubrimiento de dos hojas del *cilindro* a la banda de Möbius.
- $n\mathbb{Z}$ con $n$ impar tiene a la *banda de Möbius* como recubridor.
- $\mathbb{Z}$ tiene al recubridor *identidad*.
*** 3. Superficies compactas
**** 3.0. Clasificación de variedades 1-dimensionales
***** Variedad 1-dimensional
Una variedad topológica 1-dimensional es un espacio topológico que
sea:

  - Conexo.
  - $T_2$, [[https://en.wikipedia.org/wiki/Hausdorff_space][Hausdorff]].
  - 2AN, [[https://en.wikipedia.org/wiki/Second-countable_space][segundo axioma de numerabilidad]].

y tal que:

\[\forall x \in X : \exists x \in U_x \in \tau:\quad
U_x \cong\: ]a,b[\]

***** Ejemplos
****** Los reales y el círculo
$\mathbb{R}$ es variedad trivialmente. El círculo $\mathbb{S}^1$ es también una variedad.

****** Contraejemplo: lemniscata
Un espacio que se cruza consigo mismo formando una lemniscata
es un contraejemplo. No hay abierto homeomorfo a un entorno del cruce.

[[file:./images/lemniscata.svg]]

****** Contraejemplo: folium
Una curva inyectiva y continua que se aproxima a un punto sin contenerlo.
Ninguno de los entornos del punto crítico tiene un entorno abierto
homeomorfo a un intervalo.

#+begin_center
#+attr_latex: :width 50px
[[./images//folium.png]]
#+end_center

****** Contraejemplo de 2AN
No existe una base numerable para el punto $(0,0)$ si usamos la
topología que une la recta izquierda con cada una de las rectas
derechas de forma separada, no podemos encontrar una base
numerable.

\[
X
=
\{(x,0) \mid x<0\}
\cup
\left(
\bigcup_{y \in \mathbb{R}\setminus\{0\}}
\{(x,y) \mid x \geq 0\}
\right)\]

#+begin_center
#+attr_latex: :width 50px
[[./images//2an.png]]
#+end_center

***** Clasificación de variedades topológicas en dimensión 1
Toda variedad topológica 1-dimensional es homeomorfa a $\mathbb{R}$ o a $\mathbb{S}^1$.

**** 3.1. Variedades topológicas
***** Espacio localmente euclídeo
Un espacio $X$ es *localmente euclídeo* cuando cada punto admite un
entorno abierto homeomorfo a un abierto de $\mathbb{R}^n$.

****** Definición equivalente
Cada punto admite un entorno abierto homeomorfo a una bola 
abierta de $\mathbb{R}^n$.

****** Carta
Cada entorno con su homeomorfismo forma una *carta local* $(U_x,\phi)$.

****** Bola euclídea
Carta homeomorfa a la bola unidad euclídea.

***** Variedad topológica
Una variedad topológica es un espacio topológico cumpliendo:

  1. Localmente euclídeo.
  2. Hausdorff $T_2$.
  3. Segundo axioma de numerabilidad 2AN.

A una variedad de dimensión 2 la llamamos *superficie*.

****** Axioma de Hausdorff
Todo par de puntos distintos tienen entornos que los separan. Es decir,
para $x \neq y$, existen $U_x \cap V_y = \varnothing$.

****** Segundo axioma de numerabilidad
Un espacio es 2AN si tiene una base numerable. Es decir, existe un
conjunto $\{U_n\}_{n \in \mathbb{N}}$ tal que todo abierto es unión de ellos.

***** Ejemplos de variedades topológicas
****** Los espacios euclídeos
****** Las esferas n-dimensionales
****** Recubridores de espacios localmente euclídeos
****** Recubiertos por espacios localmente euclídeos
***** Teorema de la invarianza de la dimensión
Si $U \subseteq \mathbb{R}^n$ y $V \subseteq \mathbb{R}^m$ son abiertos homeomorfos, $n=m$.
Por tanto cada variedad tiene una dimensión asignada.

****** Demostración
Puede demostrarse comprobando grupos de homología distintos para una
bola a la que retiramos un punto.

***** Base de las cartas
Los dominios de las cartas forman una base de la topología.

****** Demostración
Usamos simplemente que la intersección de un abierto con
una carta es una carta con el homeomorfismo restricción.

Dado un abierto, cada punto suyo tiene un entorno que es
una carta. Al intersecarlo con el abierto da otra carta,
y finalmente el abierto inicial es unión de todas las
cartas en cada punto.

***** Bola regular euclídea
Sea $B \subseteq X$ una bola euclídea, es regular cuando:

  1. Existe $B' \subseteq X$ bola euclídea con $\overline{B} \subseteq B'$.
  2. Existe $r > 0$ y una carta $\phi : B' \longrightarrow \mathbb{D}(0,2)$ tal que $\phi(\overline{B}) = \overline{\mathbb{D}(0,1)}$.

****** Contraejemplos
Una esfera sin un punto es una bola euclídea pero no una bola
regular euclídea.

***** Base de las bolas regulares euclídeas
Las bolas regulares euclídeas forman una base de la topología de una
variedad topológica.

****** Existencia de bola regular euclídea
En una variedad topológica sea $p \in S$ y $U \subseteq S$ entorno de $p$ abierto.
Existe una bola regular euclídea con $p \in B \subseteq U$.

******* Demostración
Es localmente euclídeo, luego localmente habrá una bola centrada
en la imagen de $p$ y otra de mitad de radio. Su preimagen será
regular euclídea.

****** Demostración
En cualquier entorno existe una bola regular euclídea entre
el punto y el entorno.

***** Autohomeomorfismo de superficies conexas
Sea $S$ superficie conexa con $p,q \in S$. Entonces existe $f : S \overset{\cong}\longrightarrow S$
con $f(p) = q$.

****** Lema al endomorfismo
Existe una constante $\varepsilon \in ]0,1]$ tal que dado $x \in B(0,\varepsilon)$, existe
un $F : \mathbb{R}^2 \overset{\cong}\longrightarrow \mathbb{R}^2$ con:

  1. $F(0) = x$.
  2. $F|_{\mathbb{R}^2\setminus D(0,2)}$ es la identidad.

******* Demostración
Tenemos funciones infinitamente diferenciables y no nulas que nos
permiten crear funciones que muevan un punto en otro dejando todo
el resto del plano igual.

******** TODO Construcción explícita
****** Demostración
Consideremos la relación de equivalencia $pRq$ cuando $\exists f : S \cong S$
con $f(p) = q$. Veamos que $[p]$ es abierta por $p$ arbitrario y por
tanto, $[p] = S$.

******* La clase de equivalencia es abierta
Dado $p$, tenemos $O$ disco [[*Base de las bolas regulares euclídeas][regular]] centrado en él y $O'$ disco 
euclídeo cubriendo su clausura y cumpliendo:

\[
\exists \phi : O' \overset{\cong}\longrightarrow D(0,\varepsilon)
\]

con $\phi(O) = \overline{D(0,\varepsilon/2)}$. El lema nos da una $F_x(0) = x$.

Definimos $D_0 = \phi^{-1}(D(0,\varepsilon)) \subset D'$, abierto cubriendo a $p$. Y para
cualquier $y \in D_0$, definimos la función $G_y : S \cong S$ como:

\[
G_y(z) = \left\{\begin{array}{ll} 
z & \mbox{if } z \notin O'  \\
\phi^{-1} \circ F_{\phi(y)} \circ \phi& \mbox{if } z \in O'
\end{array} 
\right.
\]

Lo que nos da $D_0 \subseteq [p]$, haciéndolo abierto.

***** Recubridor de una superficie
Sea $\pi : \widetilde{X} \longrightarrow X$ recubridor:

  1. Si $\widetilde X$ es una superficie y $A_\pi = \{(x,y) \in \widetilde{X} \times \widetilde{X} \mid \pi(x) = \pi(y) \}$
     es cerrado, entonces $X$ es superficie.
  2. Si $X$ es superficie, $\widetilde{X}$ es superficie.

****** Demostración
******* Localmente euclídea
La aplicación recubridora es localmente homeomorfismo, por lo
que lleva en ambas direcciones el ser localmente euclídeo.

******* TODO Hausdorff

******* TODO Axioma de numerabilidad

**** 3.2. Complejos simpliciales
***** P-símplice
Sean $v_1,\dots,v_p \in \mathbb{R}^n$ afínmente independientes. Se define el *p-símplice*
generado como:

\[
\langle v_0,\dots,v_p \rangle
=
\left\{\;
\sum_{j=0}^p \lambda_jv_j 
\;\middle|\;
0 \leq \lambda_j \leq 1, \sum_{j=0}^p \lambda_j = 1
\;\right\}
\]

Llamamos a los $v_i$ *vértices* del p-símplice y al entero $p$ se le llama
*dimensión* del p-símplice.

****** P-símplice abierto
Se define el *p-símplice abierto* como:

\[
{\cal O}(\langle v_0,\dots,v_p \rangle)
=
\left\{
\sum_{j=0}^p \lambda_jv_j 
\;\middle|\;
0 < \lambda_j \leq 1, \sum_{j=0}^p \lambda_j = 1
\right\}
\]

Observemos que en general no es igual al interior de un p-símplice,
que puede ser vacío en una dimensión alta.

****** Caras de un p-símplice
Las *caras* de un p-símplice $\sigma$ son los k-símplices generados por $k+1$ 
de sus vértices. Se notan por $\tau < \sigma$.

Llamamos *aristas* a las caras de dimensión 1 y *triángulos* a las 
caras de dimensión 2.

***** Complejo simplicial
Colección de símplices $K$ en algún $\mathbb{R}^n$ cumpliendo:

  1. $\tau < \sigma, \sigma \in K \implies \tau \in K$.
  2. $\sigma,\tau \in K,\; \sigma \cap \tau \neq \varnothing$ $\implies$ $\sigma \cap \tau < \sigma$ y $\sigma \cap \tau < \tau$.
  3. Todo punto en el símplice tiene un entorno abierto que corta a
     una cantidad finita de símplices en $\bigcup_{\tau \in K}\tau \subseteq \mathbb{R}^n$.

Llamamos *dimensión* de $K$ a la dimensión del mayor símplice que 
contiene.

****** Subcomplejo simplicial
Llamamos subcomplejo simplicial a $K' \subseteq K$ complejo simplicial.

***** Poliedro
Dado $K$ complejo simplicial, llamamos *poliedro* de $K$ al espacio
topológico formado por la unión de todos los símplices de $K$ con 
la topología inducida:

\[|K| = \bigcup_{\tau \in K} \tau \subseteq \mathbb{R}^n\]

***** Un compacto corta una cantidad finita de símplices
Sea $G \subseteq |K|$ compacto, entonces $G$ corta a una cantidad finita de
símplices de $K$. En particular $|K|$ compacto tiene una cantidad 
finita de símplices.

****** Demostración
Supongamos $\{\tau_n\}$, tomamos $\{p_n\} \in G \cap \tau_n$. Por compacidad habría 
una parcial convergente $\{p_n\} \longrightarrow p_\infty \in G \subseteq |K|$.

Pero por definición de complejo simplicial, este $p_\infty$ tiene un
entorno que corta sólo a una cantidad finita de símplices y por
tanto, de los $p_n$.

***** Aplicaciones simpliciales
Una $f : |K|\longrightarrow |L|$ entre complejos simpliciales es *aplicación simplicial* 
si:

  1. $f$ lleva símplices de $K$ en símplices de $L$.
  2. La restricción de $f$ a cada símplice es afín $Ax+b$.

****** Homeomorfismos simpliciales
Una aplicación simplicial homeomorfismo la llamamos 
*homeomorfismo simplicial*.

****** Categoría de las aplicaciones simpliciales
La inversa de un homeomorfismo simplicial es homeomorfismo simplicial;
así como la identidad y la composición de funciones. Las aplicaciones
simpliciales forman una categoría.

******* TODO Demostración

***** Superficies triangulables
Una superficie topológica $S$ se dice *triangulable* si existe algún
complejo simplicial de dimensión $2$ con $S \cong |K|$.

***** Teorema de Radó
Toda superficie admite una triangulación por un complejo simplicial
euclídeo de dimensión 2 donde cada 1-símplice es cara de exactamente
dos símplices.

****** Recíproco falso
No todo complejo simplicial es triangulación de una superficie.

***** Caracterización de triangulaciones
Un complejo simplicial $K$ de dimensión 2 es triangulación de una
superficie ssi:

  1. Todo símplice es cara de un 2-símplice.
  2. Todo 1-símplice es cara de exactamente dos 2-símplices.
  3. Si $\forall v \in K^{(0)}$ definimos $st(v) = \{ \tau \in K \mid v < \tau \}$ y

     \[ L(v) = \{ \tau \in K \mid \exists \sigma \in K : v < \sigma, \tau < \sigma, v \not< \tau
     \}
     \]

     y tenemos que $|st(v)| \cong \overline{D}$ y $|L(v)|$ es conexo.

****** Demostración
No se explica en la asignatura.

**** 3.3. Suma convexa
***** Curva de Jordan
Una curva de Jordan en $\mathbb{R}^n$ es una curva cerrada y simple.

****** Definición equivalente
Una curva de Jordan es la imagen de $f : \mathbb{S}^1 \longrightarrow \mathbb{R}^n$ que sea
homeomorfismo sobre su imagen.

***** Homeomorfismo que preserva la orientación
Sean $C_1,C_2 \subseteq \mathbb{R}^2$ dos curvas de Jordan y $f : C_1 \overset{\cong}\longrightarrow C_2$ un homeomorfismo.
Decimos que $f$ *preserva la orientación* si $\exists \alpha : [0,1] \longrightarrow C_1$ parametrización
tal que $\alpha$ recorre $C_1$ en el sentido de las agujas del reloj y $f \circ \alpha$
recorre $C_2$ en el sentido de las agujas del reloj.

***** Teorema de Jordan-Schönflies
Sean $C_1,C_2$ curvas de Jordan con $f : C_1 \cong C_2$. Entonces existe una
$F : \mathbb{R}^2 \cong \mathbb{R}^2$ con $F|_{C_1} = f$. Además, 

  1. Si $f$ preserva la orientación y $U \subseteq \mathbb{R}$ es un subconjunto 
     homeomorfo a $\mathbb{D}$ disco, con $U \supseteq C_1 \cup C_2$, entonces existe
     un $F : \mathbb{R}^2 \cong \mathbb{R}^2$ con $F|_{C_1} = f$ y $F|_{\mathbb{R}^2\setminus U} = Id$.
  2. Si $f$ revierte la orientación y $U \subseteq \mathbb{R}^2$ con $U \supseteq C_1 \cup C_2$
     con $U \cong \mathbb{D}$ disco, puedo tener $F$ con: $F|_{\mathbb{R}^2\setminus U}(x,y) = (x,-y)$.

****** Demostración
No trivial

******* Segundo punto desde el primero
Si tengo $f : C_1 \cong C_2$, revirtiendo la orientación, puedo tomar
la curva reflejada en el eje Y:

\[\widetilde{C_2} = \{(x,y) \mid (x,-y) \in C_2 \}\]

Y definir una $\widetilde{f} : C_1 \cong \widetilde{C_2}$ como $\widetilde{f} = (f_1,-f_2)$, que preserva la 
orientación. El teorema nos da entonces una $\widetilde{F}$ desde la que podemos
definir $F = (\tilde F_1, \tilde F_2)$, la buscada.

***** Teorema de la curva de Jordan
Sea $C$ curva de Jordan en $\mathbb{R}^2$. Entonces, $\mathbb{R}^2\setminus C$ tiene exactamente
dos componentes conexas, una de ellas acotada (*interior* de $C$) y
la otra es no acotada (*exterior* de $C$).

****** Demostración
Dado un $f : C \cong \mathbb{S}^1$ homeomorfismo, por Jordan-Schönflies, tenemos
una $F : \mathbb{R}^2 \cong \mathbb{R}^2$ extendiéndola, lo que nos da $\mathbb{R}^2\setminus C_1 \cong \mathbb{R}^2 \setminus \mathbb{S}^1$.

****** Contraejemplo en dimensiones superiores: esfera de Alexander
La [[https://es.wikipedia.org/wiki/Esfera_cornuda_de_Alexander][esfera cornuda de Alexander]] es una 2-esfera embebida en $\mathbb{R}^3$
cuyo exterior no es homeomorfo al exterior de la 2-esfera en $\mathbb{R}^3$.

***** Teorema de Jordan-Schonflies para la esfera
Sean $C_1,C_2$ dos curvas de Jordan en $\mathbb{S}^2 \subseteq \mathbb{R}^3$ y $f : C_1 \overset{\cong}\longrightarrow C_2$.
Entonces $\exists F : \mathbb{S}^2 \cong \mathbb{S}^2$ con $F|_{C_1} = f$.

****** Demostración
Si tomamos $p \in \mathbb{S}^2 \setminus \{C_1 \cup C_2\}$, tenemos $\mathbb{S}^2 \setminus \{p\} \cong \mathbb{R}^2$ por la proyección
estereográfica. Tomamos el $F$ que da el teorema de Jordan-Schönflies
y lo componemos con la inversa de la proyección para tener el $F$.

Dividimos en los dos casos para ver que el $F$ es continuo en el
punto impropio.

***** Suma conexa
Sean $S_1,S_2$ dos superficies convexas. Sean $D_1 \subseteq S_1$, $D_2 \subseteq S_2$ discos
regulares euclídeos y sea $\varphi : \partial D_1 \longrightarrow \partial D_2$ homeomorfismo. 

Denotemos $S'_i = S_i \setminus D_i$. En $S'_1 \sqcup S_2'$ definimos $R_{\varphi}$ relación de equivalencia 
entre el borde y su imagen:

\[ x\; R_\varphi \; \varphi(x)\quad \forall x \in \partial D_1\]

Tenemos una superficie topológica conexa que es independiente de los
discos y el homeomorfismo elegidos. La llamamos *suma conexa*:

\[
S_1 \# S_2
=
S_1' \sqcup S_2' / R_\varphi
\]

***** La suma es independiente de los discos
Para $D_1,D_3 \subseteq S'$ discos regulares euclídeos centrados en $p_1$, tenemos
que:

\[S_1 \setminus D_1 \cong S_1 \setminus D_3\]

****** Demostración
Sin pérdida de generalidad, $\overline{D_1} \subset D_3$. Sea $\psi$ el que hace bola [[*Bola regular euclídea][regular]]
a $D_3$. Definimos:

\[ C_3 = \psi(\partial D_3)\]
\[C_1 = \psi(\partial D_1)\]

Tomamos un $f : C_1 \cong C_3$ y Jordan-Schönflies nos da un $F$.

Definimos ahora por partes $\widetilde F$ como:

\[\widetilde{F}|_{D_3'} = \psi^{-1} \circ F \circ \psi\]
\[\widetilde{F}|_{S_1 \setminus D_3'} = Id\]

Comprobamos que está bien definida y es homeomorfismo, por lo que
tenemos $\widetilde F : S_1\setminus D_1 \cong S_3 \setminus D_3$.

***** La suma es independiente de los centros
Los puntos en los que centramos la suma conexa. Tomando $p_1 \neq p_3 \in S_1$,
con $D_1,D_3$ discos regulares euclídeos centrados en ellos:

\[S_1 \setminus D_1 \cong S_3 \setminus D_3\]

****** Demostración
Ya tenemos que hay un [[*Autohomeomorfismo de superficies conexas][automorfismo]] que centra un punto en otro.
Como los discos regulares son base de la topología, existirá un
$\overline{D_3''} \subseteq D_3$ y suficientemente pequeño para que $F(D_3'') \subseteq D_1$.

Como $F(D_3'')$ es disco regular euclídeo:

\[
S_1/D_3 \cong 
S_1/D_3'' \cong
S_1/F(D_3'') \cong
S_1/D_1
\]

***** La suma es independiente del homeomorfismo
El homeomorfismo no influye. Dados $\varphi, \xi : bD_1 \longrightarrow bD_2$ homeomorfismos,
queremos ver:

\[
S_1 \sqcup S_2 / R_\varphi \cong S_1 \sqcup S_2 / R_\xi
\]

****** Demostración
Suponemos s.p.g. que $\xi \circ \varphi^{-1}$ preserva la orientación. Como $D_2$ es disco
regular euclídeo, hay un $D_2' \subset S_2$ euclídeo con $\psi_2 : D_2' \longrightarrow \mathbb{D}(0,2)$:

\[
\psi_2(D_2') = \overline{\mathbb{D}(0,1)}
\]

Llamamos:

  1. $C = \psi_2(bD_2) = \mathbb{S}^1$, curva de Jordan.
  2. $f = \psi_2 \circ \xi \circ \varphi^{-1} \circ \psi_2^{-1} : C \cong C$.
  3. $U = \mathbb{D}(0,3/2)$.

Por [[*Teorema de Jordan-Schönflies][Jordan-Schönflies]], tenemos un $F : \mathbb{R}^2 \cong \mathbb{R}^2$ con $F|_G = f$, $F|_{\mathbb{R}^2-U} = Id$.

Definimos ahora $\widetilde F : S_2 \cong S_2$ cumpliendo $\widetilde F|_{D_2'} = \psi_2^{-1} \circ F \circ \psi$ y teniendo
también $\widetilde F|_{S_2-D_2'} = Id$.

Finalmente definimos $\widehat F : S_1 \sqcup S_2 \cong S_1' \sqcup S_2'$ con $\widehat F|_{S_1'} = Id, \widehat F|_{S_2'} = \widetilde F$.
El siguiente diagrama nos da el homeomorfismo:

\[\begin{tikzcd}
S_1' \sqcup S_2'           \rar{\widehat F}\dar{p_\xi}& 
S_1' \sqcup S_2'           \dar{p_\varphi} \\
S_1' \sqcup S_2'/R_\varphi \rar[dashed] & 
S_1' \sqcup S_2'/R_\xi
\end{tikzcd}\]

Ya que dados dos puntos $x,y$, si están fuera del borde su relación es
trivial, y si están en el borde cumplen $y = \varphi(x)$:

  - $\widehat F(x) = x \in bD_1 \subseteq S_1'$
  - $\widehat F(y) = \widetilde F(y) \in bD_2 \subseteq S_2'$

Luego basta comprobar que:

\[\widetilde F(y) = 
\widetilde F(\varphi(x)) =
\psi_2^{-1} (F(\psi_2(\varphi(x)))) =
\psi_2^{-1} (f(\psi_2(\varphi(x)))) =
\xi (x)
\]

***** La suma conexa de superficies conexas es superficie conexa
La suma conexa de dos superficies topológicas conexas es una
superficie topológica conexa.

****** Demostración
Sean $S_1,S_2,D_1,D_2,\varphi$ las superficies y los discos que definen
la suma conexa:

\[
S_1 \# S_2 =
S_1' \sqcup S_2' / R_\varphi
\]

******* Es localmente euclídea
******** Fuera de los discos
En los puntos fuera de los discos, es trivial por ser $S_1,S_2$
localmente euclídeas. Sea $p : S_1' \sqcup S_2' \longrightarrow S_1 \# S_2$, como es un 
homeomorfismo fuera del borde, llamamos:

\[
V_i = p(S_i' - bD_i') \subseteq S_1 \# S_2
\]

Y como tenemos por otro lado:

\[
p^{-1}(V_i) = S_i'-bD_i = (S_i-\overline{D_i})\cap S_i'
\]

Llegamos a que $p^{-1}(V_i)$ es abierto en $S_i'$ y por tanto $V_i$ es abierto
en $S_1 \# S_2$. Tenemos $V_i \cong S_i' - bD_i$ localmente euclídeo.

******** TODO En los discos
Sea $q \in p(bD_1) = p(bD_2)$. Como son discos regulares euclídeos, se
tienen $D_1',D_2'$ con cartas $\psi_i(D_1') = \mathbb{D}(0,2)$, $\psi(D_1) = \overline{\mathbb{D}(0,1)}$.

Pegamos ambos discos y comprobamos que son homeomorfos a un abierto
del plano.

******* Cumple Hausdorff
El único caso no trivial es el de $x \in V_0$, $y \in V_1 - V_0$. Como podemos tomar
$V_0$ abitrariamente pequeño, tenemos s.p.g. $y \notin \overline{V_0}$. Así, hay un abierto de $y$
que no corta a $\overline{V_0}$, y como $V_0$ era un abierto, hay otro abierto de $x$ que
queda dentro de él.

******* Cumple axioma de numerabilidad
El que exista una proyección abierta, continua y sobreyectiva desde un
espacio 2AN hace al espacio 2AN.

**** 3.4. Presentación poligonal de superficies
***** Polígono homeomorfo
Toda superficie topológica compacta es homeomorfa a un polígono con lados
identificados 2 a 2.

****** Idea de demostración
Dada $S$ compacta, por un teorema que no demostramos, $S \cong |K|$.
Por [[*Teorema de Radó][Radó]], podemos triangularlo y por compacidad, tiene un número
finito de caras. Ese polígono puede desplegarse.

***** Región poligonal
Un $P \subseteq \mathbb{R}^2$ es región poligonal si:

  1. Es compacta.
  2. Tiene por borde una curva poligonal (complejo de dimensión 1).
  3. Cada $v \in \operatorname{b}(P)$ vértice admite entorno $U \subseteq \mathbb{R}^2$ tal que:

     \[U \cap P = U \cap H_1 \cap H_2\]

     donde $H_1,H_2$ son semiplanos cerrados con $H_1 = H_2$ o $\operatorname{b}H_1 \cap \operatorname{b}H_2 = \{v\}$.

****** Ejemplos
******* Polígonos regulares
Toda región compacta, convexa y bordeada por una curva poligonal
es una región poligonal.

******* Contraejemplo: polígono no convexo
Un polígono no convexo no cumple la propiedad 3 en cualquier
vértice que no esté en la envolvente.

***** Superficie de una región poligonal
Sea $P \subseteq \mathbb{R}^2$ región poligonal con un número par de aristas. Si $R$ es relación 
de equivalencia, identificando cada arista con exactamente otra arista
mediante homeomorfismo simplicial, $P/R$ es una superficie topológica 
compacta.

****** Demostración
******* Compacta
Sabemos que $P$ es compacta, como $p$ es continua y sobreyectiva,
tenemos $P/R$ compacto.

******* Localmente euclídea
Consideramos tres casos:

******** Interior del polígono
Tenemos que la proyección es homeomorfismo local.

******** Interior de las aristas
Tenemos $q_i \in a_i$ identificadas por un homeomorfismo simplicial.
Podemos crear un disco centrado en $\mathbb{R}^2$ uniendo dos discos y que
la relación que define esa proyección sea la misma que la que
define la equivalencia de aristas.

******** Vértices
Trabajamos dependiendo de con cuántos puntos esté identificado
$p^{-1}(x) = \{v_1,\dots,v_k\}$. Sean $D_i$ discos abiertos en $\mathbb{R}^2$ para cada 
vértice cumpliendo $\overline{D_i} \cap \overline{D_j} = \varnothing$ y llamamos $U_i = D_i$.

Creamos un disco uniendo todos las partes de disco y comprobamos
que la relación que defina sea la misma que la de la proyección.

******* TODO Segundo axioma de numerabilidad

******* TODO Espacio de Hausdorff

***** Presentación poligonal
Llamamos presentación a una expresión de la forma:

\[\langle A;\; W_1,\dots,W_n \rangle\]

donde $W_i$ son palabras con todos los símbolos $\langle A \rangle$ de longitud mayor 
que 3. Permitimos además los casos especiales:

  - $\langle \{a\}, aa \rangle$
  - $\langle \{a\}, aa^{-1} \rangle$
  - $\langle \{a\}, a^{-1}a^{-1} \rangle$
  - $\langle \{a\}, a^{-1}a \rangle$

***** Presentación de un complejo simplicial
Dado un complejo simplicial $K$ donde cada símplice es cara de un
2-símplice, tenemos una presentación poligonal asignando a cada
2-símplice una palabra de longitud 3.

***** Realización geométrica de una presentación
Cada $P = \langle A; W_1,\dots,W_n \rangle$ determina $|P|$, una topología de la forma:

  1. Para cada $W_i$ tomamos un polígono $P_i$ de n-lados.
  2. Biyección entre lados y aristas de $P_i$ en sentido antihorario.
  3. Identificamos cada arista con la que tiene el mismo nombre en
     el sentido marcado por la inversa.

Tomamos la unión por esta relación $|P| = \bigsqcup P_i / R$.

***** Extensión a homeomorfismo
Para $P_1,P_2$ polígonos convexos con el mismo número de aristas.
El $f : \operatorname{b}P_1 \longrightarrow \operatorname{b}P_2$ homeomorfismo simplicial se extiende a un 
homeomorfismo $F : P_1 \longrightarrow P_2$.

****** TODO Demostración

***** Presentación de superficie
Una presentación $\langle A; W_1,\dots,W_n \rangle$ es de superficie si 
cada símbolo de $A$ aparece exactamente dos veces en los $W_i$.

***** Presentación asociada a una superficie
Si $S$ es superficie compacta y $|P| \cong S$, llamamos a $P$ una
*presentación* de $S$.

***** Presentaciones topológicamente equivalentes
Dos presentaciones $P_1,P_2$ son topológicamente equivalentes si:

\[ |P_1| \cong |P_2|\]

***** Transformaciones elementales de presentaciones poligonales
Dado $\langle A; W_1,\dots,W_n \rangle$, podemos definir las siguientes transformaciones
elementales.

****** 1. Renombrar
Cambiar un símbolo $a \in A$ por $e \notin A$ para cada palabra.

****** 2. Subdividir
Sustituir $a \mapsto ae$ y $a^{-1} \mapsto e^{-1}a^{-1}$.

****** 3. Consolidar
Inversa de subdividir.

****** 4. Reflejar
Cambiar orden de una palabra $a_1\dots a_m \mapsto a_m^{-1}\dots a_1^{-1}$.

****** 5. Rotar
Empezar una palabra en otro vértice $a_1\dots a_m \mapsto a_2\dots a_ma_1$.

****** 6. Cortar
Partir dos palabras $W_1W_2 \mapsto W_1e,e^{-1}W_2$.

****** 7. Pegar
Inversa de cortar.

****** 8. Doblar
Anular dos lados adyacentes $W_1ee^{-1} \mapsto W_1$.

****** 9. Desdoblar
Inversa de doblar.

***** Transformaciones elementales preservan la realización
Las transformaciones elementales de una presentación poligonal
producen una presentación poligonal equivalente.

****** Demostración
******* Renombrar
Trivialmente.

******* TODO Subdividir/Consolidar
******* Reflejar
Una aplicación que lleve cada arista en la inversa del mismo nombre
respetará vértices.

******* Cortar/Pegar
Probaremos que $\langle A; W_1W_2 \rangle \cong \langle A\cup \{e\} ; W_1e,e^{-1}W_2 \rangle$. Llamamos $P'$ al 
símplice generado por la primera y $P_1,P_2$ a los generados por las
segundas. Sea $f$ una aplicación simplicial que une la arista de corte:

\[\begin{tikzcd}
P_1 \sqcup P_2 \dar{p} \rar{f} & 
P' \dar{p'}
\\
\lvert P\rvert \rar{\widetilde f} &
\lvert P' \rvert
\end{tikzcd}\]

Sabemos que $f$ baja al cociente de manera continua y $\widetilde f$ es cerrada
por ir de un compacto a un cerrado. Además es biyectiva y por
tanto homeomorfismo.

En caso de que hubiera más de dos palabras podríamos extenderla
por la identidad y seguir el mismo razonamiento.

******* Doblar/Desdoblar
******** Caso triangular
Definimos una aplicación simplicial respetando el nombre de las
aristas:

#+begin_center
#+attr_latex: :width 50px
[[./images//doblartransformacion.png]]
#+end_center

Esa aplicación simplicial baja de forma continua y genera una
aplicación biyectiva entre compacto y cerrado.

******** Caso general
Podemos cortar o subdividir para llegar al caso triangular.

***** Presentación poligonal de la suma
Dadas $S_1,S_2$ con presentaciones $P_1 = \langle A_1; W_1 \rangle$ y $P_2 = \langle A_2;W_2 \rangle$ con
$A_1 \cap A_2 = \varnothing$. Entonces una presentación de $S_1 \# S_2$ es:

\[
\langle A_1 \cup A_2 ; W_1 W_2 \rangle
\]

****** Demostración
Desdoblamos y cortamos para llegar a la presentación:

\[
\langle W_1c^{-1}b^{-1}a^{-1}, abc \rangle
\]

De donde salen dos complejos simpliciales $P$ y $Q$. El segundo de
ellos se proyecta a un disco regular euclídeo.

\[ D_1 = p'(\mathring Q) \subseteq |P'| \]

Mientras que el primero se proyecta al polígono sin un disco cuyo
borde es $bD_1 = p(c^{-1}b^{-1}a^{-1})$.

\[
p'(P) \cong S_1 \setminus D_1
\]

Aplicando el mismo argumento a $W_2$, llegamos a una presentación de
$S_2\setminus D_2$, que al identificar ambos bordes permite unirlos pegando
y doblando:

\[
\langle W_1c^{-1}b^{-1}a^{-1}, abc W_2 \rangle \cong
\langle W_1W_2 \rangle
\]

***** Presentaciones modelo
****** Esfera
La presentación de la esfera $\mathbb{S}^2$ es:

\[P_0 = \langle a \mid aa^{-1} \rangle\]

****** Suma de toros
La presentación de la suma de toros $\mathbb{T}^{\#n} = \mathbb{T} \# \overset{n}\dots \#\mathbb{T}$ es:

\[
P_n = \langle
a_1,b_1,\dots,a_n,b_n 
\mid 
a_1b_1a_1^{-1}b_1^{-1}\dots a_nb_na_n^{-1}b_n^{-1} 
\rangle
\]

****** Suma de planos proyectivos
La presentación de la suma de planos proyectivos $\mathbb{RP}^{2\#n}$ es:

\[ Q_n =
\langle a_1,\dots,a_n \mid a_1a_1\dots a_na_n \rangle
\]
**** 3.5. Clasificación de superficies compactas I
***** Aristas retorcidas y complementarias
Un par de aristas en una presentación se dicen retorcidas si
aparecen como $a$ y $a$; y complementarias si aparecen como $a$ y $a^{-1}$.

***** Lema: botella de Klein
La botella de Klein $K$ es homeomorfa a la suma conexa de dos planos
proyectivos:

\[
K \cong \mathbb{RP}^2 \# \mathbb{RP}^2
\]

****** Demostración
Simplemente comprobando que sus presentaciones son equivalentes:

\[
\langle abab^{-1} \rangle \cong \langle ccbb \rangle
\]

***** Lema: suma de toro y plano proyectivo
La suma conexa de un toro y un plano proyectivo es homeomorfa a la 
suma conexa de 3 planos proyectivos:

\[
\mathbb{T} \cong \mathbb{RP}^2 \# \mathbb{RP}^2 \# \mathbb{RP}^2
\]

****** Demostración
Comprobando que sus presentaciones son equivalentes:

\[
\langle aba^{-1}b^{-1}cc \rangle \cong \langle aabbcc \rangle
\]

Podemos usar el [[*Lema: botella de Klein][lema]] anterior y ver que:

\[\begin{aligned}
\langle abab^{-1}cc \rangle 
&=
\langle cabd^{-1},dab^{-1}c \rangle 
\\&=
\langle abd^{-1}ba^{-1}d^{-1} \rangle
\\&=
\langle a^{-1}d^{-1}abe,e^{-1}d^{-1}b \rangle
\\&=
\langle a^{-1}d^{-1}abe,e^{-1}d^{-1}b \rangle
\\&=
\langle a^{-1}d^{-1}abe,b^{-1}de \rangle
\\&=
\langle ea^{-1}d^{-1}ade \rangle
\end{aligned}\]

***** Teorema de clasificación de presentaciones de superficies compactas
Cualquier presentación poligonal de una superficie compacta y conexa
es equivalente a una de las siguientes:

  1. $P_0$, presentación de $\mathbb{S}^2$.
  2. $P_n$, presentación de $\mathbb{T}^{\#n}$.
  3. $Q_n$, presentación de $\mathbb{RP}^{2\#n}$.

****** Demostración
Sea $S$ superficie con presentación $P$.

******* Paso 1: Reducir a una cara
Como el cociente es arcoconexo, si hay más de una palabra, comparten
entre sí alguna letra. Rotamos, reflejamos si es necesario y pegamos
para tener una sola cara.

******* Paso 2: Retirar complementarias adyacentes
Dos lados adyacentes pueden retirarse.

******* Paso 3: Colocar aristas retorcidas adyacentes
Dada una palabra de la forma $WaVa$:

  1. Cortamos: $Wab^{-1},bVa$.
  2. Reflejamos y rotamos: $b^{-1}Wa, a^{-1}V^{-1}b^{-1}$.
  3. Pegamos y rotamos: $b^{-1}b^{-1}WV^{-1}$.

******* Paso 4: Identificar todos los vértices
Fijado un vértice, puedo cortar un triángulo que lo contenga y
volver a pegar por uno de sus lados para identificar otro vértice
con él.

******* Paso 5: Las complementarias tienen complementarias intercaladas
Para un par de complementarias $a,a^{-1}$, hay otro par de complementarias
intercalado como: $a \dots b \dots a^{-1} \dots b^{-1}$.

Si no fuera así, tendríamos $aXa^{-1}Y$ sin forma de relacionar ningún
vértice de $X$ con un vértice de $Y$.

******* Paso 6: Las intercaladas pueden presentarse en bloques
Si tenemos una palabra de la forma $WaXbYa^{-1}Zb^{-1}$:

  1. Cortando antes de $b$ y pegando por $a$: $XcWZb^{-1}c^{-1}bY$.
  2. Cortando antes de $c$ y pegando por $b$: $d^{-1}WZYXcdc^{-1}$.

Luego tenemos: $WaXbYa^{-1}Zb^{-1} \longrightarrow WZYXcdc^{-1}d^{-1}$.

******* Paso 7: Nos queda suma de planos proyectivos y toros
Nos acaba quedando una palabra de la forma: 

\[aabb\dots cdc^{-1}d^{-1}\dots\]

Suma conexa de toros y planos proyectivos. Por el [[*Lema: suma de toro y plano proyectivo][lema]],
sabemos que será suma de toros o suma de planos proyectivos.

***** Preclasificación de superficies compactas
Toda superficie compacta y conexa es homeomorfa a al menos una de las 
siguientes:

  1. $\mathbb{S}^2$
  2. $\mathbb{T}^{\#n}$
  3. $\mathbb{RP}^{2\#n}$

****** Demostración
Cada superficie compacta es triangulable por [[*Teorema de Radó][Radó]], con cada 1-símplice
siendo cara de dos 2-símplices. Todo complejo simplicial tiene después
una [[*Presentación de un complejo simplicial][presentación poligonal]]. La compacidad da la finitud.

Podemos reducir su [[*Teorema de clasificación de presentaciones de superficies compactas][presentación]] a una de las de estas superficies
mediante transformaciones equivalentes. 
**** 3.6. Clasificación de superficies compactas II
***** Grupo fundamental de la presentación
Sea $S$ compacta y convexa determinada por la presentación $P$, entonces
su grupo fundamental tiene la misma presentación de $P$.

Es decir cociente del libre por la clausura normal de las $W$:

\[\Pi(S) = \frac{F(A)}{N_W}\]

****** Demostración
Aplicando Seifert-Van Kampen sobre una cara tenemos las aristas
como generadores y las palabras como relaciones entre ellas.

***** Conmutador
Dado $G$ se define su conmutador $[G,G]$ como el subgrupo normal de $G$ que
contiene las clases de conjugación, de la forma:

\[
[G,G] 
= 
\langle aba^{-1}b^{-1} \mid a,b \in G \rangle\]

***** Abelianizado
El conmutador cumple:

  1. $[G,G] \cong \{e\}$ $\iff$ $G$ abeliano.
  2. $Ab(G) = G/[G,G]$ es abeliano, llamado el *abelianizado* de $G$.

****** Demostración
Primer punto trivial. Para el segundo, comprobamos $ab[G,G] = ba[G,G]$.

***** Abelianizados de los grupos fundamentales de los modelos
Los abelianizados de los grupos de los modelos son:

  1. $Ab(\pi_1(\mathbb{S}^2)) = \{1\}$.
  2. $Ab(\pi_1(\mathbb{T}^{\#n}) \cong \mathbb{Z}^{2n}$.
  3. $Ab(\pi_1(\mathbb{RP}^{2\#n})) \cong \mathbb{Z}^{n-1} \times \mathbb{Z}_2$.

Distintos entre sí.

****** Demostración
******* Grupo abelianizado del toro
Podemos definir una función sobre el grupo libre:

  - \[\varphi(a_i) = (0,\dots,\overset{i}1,\dots,0)\]
  - \[\varphi(b_i) = (0,\dots,\overset{n-i}1,\dots,0)\]

Y comprobar que respeta las relaciones de abelianidad y de la
palabra. Además de dar un homomorfismo invertible.

******* Grupo abelianizado del plano proyectivo
Volvemos a definir sobre el grupo libre:

  - \[\varphi(a_i) = (0,\dots,\overset{i}1,\dots,0,0)\]
  - \[\varphi(a_n) = (-1,\dots,-1,1)\]

Volvemos a comprobar que tiene una inversa después de bajarla al
cociente.

****** Los productos de enteros son distintos
Trivial. Puede comprobarse dividiendo y por inducción.

****** El producto por el cíclico de orden 2 los hace distintos
Claramente, el producto por el cíclico de orden 2 añade un elemento de
orden 2 al grupo que antes no estaba.

***** Clasificación de superficies compactas
Una superficie topológica compacta $S$ es homeomorfa a una sola
de las siguientes:

  1. $\mathbb{S}^2$.
  2. $\mathbb{T}^{\#n}$.
  3. $\mathbb{RP}^{2\#n}$.

Dos superficies compactas son homeomorfas ssi sus grupos 
fundamentales son isomorfos.

**** 3.7. Característica de Euler y orientabilidad
***** Género
Se define el género de $S$ superficie compacta conexa:

\[ g(S) =
\left\{\begin{array}{ll} 
0 & \mbox{if } S \cong \mathbb{S}^2 \\
n & \mbox{if } S \cong \mathbb{T}^{\#n} \mbox{ ó } S \cong \mathbb{RP}^{2\#n}
\end{array} 
\right.
\]

***** Característica de Euler
Se define la característica de Euler de $S$ superficie compacta conexa:

\[\chi(P) = C-A+V\]

donde $C,A,V$ son los números de caras, aristas y vértices.

***** La característica de Euler es invariante a transformaciones
La característica de Euler es invariante a transformaciones
elementales.

****** Demostración
Podemos comprobar que cada transformación elemental preserva la
característica aunque añada caras, aristas o vértices.

***** Orientabilidad
Una superficie es orientable si admite una presentación orientada.

****** Presentación orientable
Una presentación poligonal es orientable si no tiene ningún par
de aristas retorcidas.

***** La orientabilidad de superficies compactas es un invariante
Una superficie compacta conexa es orientable ssi es homeomorfa a
la esfera o a la suma de planos proyectivos.

***** Bicolorabilidad                                                                                       :extra:
Una presentación es *bicoloreable* si podemos colorear sus palabras
con dos colores de forma que las dos ocurrencias de una arista:

  - tengan distinto color y mismo signo
  - o tengan el mismo color y distinto signo

***** Bicolorabilidad invariante a transformaciones elementales                                             :extra:
La bicolorabilidad es invariante a transformaciones elementales.

****** Demostración
******* Renombrar
Trivialmente manteniendo la coloración.

******* Subdividir
Trivial por la misma coloración por cumplirlo la subdividida.

******* Consolidar
Trivial por cumplirlo ambas aristas involucradas.

******* Reflejar
Cambiando la coloración de la palabra.

******* Rotar
Trivial, mantiene coloración.

******* Cortar
Manteniendo el mismo color en las dos palabras.

******* Pegar
Ambas palabras deben tener el mismo color.

******* Doblar
Anular dos lados adyacentes no cambia nada.

******* Desdoblar
Las dos partes están en la misma palabra y tienen el mismo color.

***** Bicolorabilidad coincide con orientabilidad                                                           :extra:
La bicolorabilidad coincide con la orientabilidad.

****** Demostración
Coincide en los modelos y por ende en todas las demás superficies.

***** Algoritmo de bicolorabilidad                                                                          :extra:
Podemos calcular la bicolorabilidad de una presentación simplemente
eligiendo un color para la primera cara y coloreando a partir de
ella.

****** Demostración
Asignado el color de la primera cara, queda determinado el color
de todas las caras que contengan una arista de ella. Como toda
cara está conectada a la inicial por conexión, toda cara queda
determinada.

Si esta coloración cumple las condiciones de bicolorabilidad,
hemos encontrado una forma de bicolorear. Si no lo cumple, ninguna
bicoloración es posible.

***** Clasificación por invariantes                                                                         :extra:
Tabla de clasificación de superficies compactas por invariantes:

|------------+--------+----------+----------------|
| Superficie | Género | C. Euler | Orientabilidad |
|------------+--------+----------+----------------|
| S          | 0      | 2        | Orientable     |
| T^n        | n      | 2-2n     | Orientable     |
| RP^n       | n      | 2-n      | No orientable  |
|------------+--------+----------+----------------|

Y podemos calcular el género desde la orientabilidad y la característica:

  - $S$ orientable: $g(S) = \frac{1}{2}(2-\chi(S))$
  - $S$ no orientable: $g(S) = 2-\chi(S)$

*** Ejercicios
**** Relación de problemas 1
***** Ejercicio 1
Trabajando en el grupo fundamental $\Pi(X,x)$.

***** Ejercicio 2
****** Punto 1
Trivial trabajando en el grupo fundamental.
****** Punto 2
La condición es $\gamma\beta \in {\cal Z}(\Pi(X,x))$.

***** Ejercicio 3
Calculamos usando Seifert-Van Kampen.

***** Ejercicio 6
Por Seifert-Van Kampen haciendo tres grupos, uno con equivalencia homotópica al
círculo y otro trivial. Sale $\mathbb{Z}$.

***** Ejercicio 7
Equivalencia homotópica a un círculo en el que se identifican antípodas, que es
homeomorfo a un círculo. Sale $\mathbb{Z}$.

***** Ejercicio 8
Por Van Kampen, teniendo un trozo con equivalencia homotópica a la esfera y otro
que es un simple disco abierto. Grupo fundamental trivial.

***** Ejercicio 9
Por el Van Kampen que aplicamos en estos casos, es $\mathbb{Z}_3$.

***** Ejercicio 10
Homeomorfo al anterior.
**** Relación de problemas 2
***** Ejercicio 1
****** Punto 1
     Trivial
****** Punto 2
     Subiendo la intersección del entorno abierto que es isomorfo a $\mathbb{R}^n$ con el 
     entorno abierto que nos da el recubridor.
****** Punto 3
     Probamos la caracterización, que es ser semilocalmente simplemente conexo. Cada
     punto tiene un entorno homeomorfo a un abierto de $\mathbb{R}^n$, así que puedo tomar una bola
     abierta en el punto y que sea homeomorfa a un abierto en el punto en el que el
     grupo fundamental sea trivial.
****** Punto 4
     Las esferas.

***** Ejercicio 2
    #+begin_statement
    Sea $\{a,b\}$ una base de $\mathbb{R}^2$ y $R$ la relación de equivalencia en $\mathbb{R}^2$ dada por:

    \[ qRq' \text{ si }\ q'-q = ma+nb,\quad m,n\in\mathbb{Z}\]

    Sea $T_{a,b}$ el espacio topológico cociente.
    #+end_statement

****** Punto 1
Usamos el recubrimiento de cocientes que surgen de acciones discontinuas para
el grupo de acciones de los $\phi_{n,m}(z) = z + (n,0) + (0,m)$ con $n,m\in\mathbb{Z}$.

**** Ejercicios de clase
***** Cálculo del espacio proyectivo con Van-Kampen
Para calcular el grupo de $\mathbb{R}\mathbb{P}^2$, lo definimos como una proyección desde la bola 
cerrada $C$ y tomamos abiertos en él.

 #+begin_center
 #+attr_latex: :width 50px
 [[./img/rpvankampen.png]]
 #+end_center

Aplicaremos Van Kampen sobre los siguientes abiertos:

 \[ U = \pi(C-\{p\})\]
 \[ V = \pi(B(p,\epsilon))\]
 \[ U \cap V = \pi((C-\{p\}) \cap B(p,\epsilon)) = \pi (B(p,\epsilon)) - \{p\}\]

Y tenemos que el grupo de $V$ es trivial. Para calcular el grupo de $U$ usaré que
tiene el mismo tipo de homotopía que su borde, que es isomorfo a un círculo y
por tanto tiene grupo fundamental $\mathbb{Z}$.

De la intersección tomaremos un generador $f$ y lo llevaremos al borde para tener:

 \[ f \simeq \alpha \ast c \ast a \ast \tilde\alpha\]

Que proyectando mientras sabemos que el generador de $U$ es 
$g = [\pi(\alpha \ast c \ast \tilde\alpha)]$ nos da finalmente que:

\[ [\pi(f)] \simeq 
 [\pi(\alpha\ast c \ast\tilde\alpha \ast \alpha \ast a \ast \tilde\alpha)] \simeq
 [g] \ast [g] \simeq 2[g]\]

Y el cálculo del grupo nos da:

\[\frac{<g>}{<2g>} \cong \mathbb{Z}_2\]

**** Examen 13 enero 2016
****** Ejercicio 3
******* Punto 1     
      Sabemos que todos los $\Phi_n$ son homeomorfismos. Dado un punto $(a,b)$ tomamos un
      disco abierto de radio $1/4$ alrededor de él, y comprobamos que $(a+n,(-1)^nb)$
      está siempre a distancia mayor a $n$ y mayor a $1/2$. Llamando a la bola $V$, 
      tenemos:
      
      \[\phi(V) \cap V = \varnothing\]

******* Punto 2
      Como $G$ actúa propia y discontinuamente sobre $\mathbb{R}^2$, tenemos que es un 
      recubridor regular.

******* Punto 3
      Como $G$ es ahora el grupo de automorfismos de un recubridor regular sobre $M$,
      tenemos que:
      
      \[ G \cong \Pi(M,x)\]

      Con lo que su grupo fundamental es $\mathbb{Z}$.

******* Punto 4
      Trivial desde lo anterior.

******* Punto 5
      Podemos definir una función de $C$ a $M$ desde las representaciones en $\mathbb{R}^2$,
      vemos luego que es identificación y que por tanto hay homeomorfismo entre
      la imagen y el cociente por la relación que define. Comprobamos que ese
      cociente es igual al que define el grupo.

******* Punto 6
      Tengo ya al cilindro como recubridor y al plano. Faltan las cintas de Möbius
      en el caso impar que se realizarán como en el ejercicio 5.
      
**** Relación de problemas 3
***** Ejercicio 1
#+begin_statement
Prueba que un espacio topológico conexo es arco-conexo si y sólo si
cada punto tiene un entorno arco-conexo. Demuestra que todo espacio
topológico localmente euclídeo es conexo si y sólo si es arco-conexo.
#+end_statement

Si es arcoconexo, claramente se tiene localmente arcoconexo.  Si es
localmente arcoconexo, una componente arcoconexa debe ser abierta y
cerrada, porque cada punto al que se pueda llegar tiene un entorno al
que se puede llegar. Y cada punto al que no se pueda llegar tiene un
entorno al que no se pueda llegar.

***** Ejercicio 3
#+begin_statement
Estudia si el subespacio topológico de $\mathbb{R}^3$ dado por:

\[ X = \{(x,y,z) \in \mathbb{R}^3 \mid z^2 = x^2+y^2\}\]

es una superficie topológica.
#+end_statement

Si $z=0$ se tiene $x,y = 0$, así, el único punto en ese plano es 
el $0$. Cualquier entorno suyo, si quitamos ese punto, tiene dos
componentes conexas y no puede ser homeomorfo a un disco.

El espacio no es localmente euclídeo.

***** Ejercicio 4
Ambos son localmente euclídeos.

***** Ejercicio 5
#+begin_statement
Prueba que el p-símplex generado por $\{a_1,\dots,a_n\}$ es la envolvente
convexa del conjunto $\{a_1,\dots,a_n\}$.
#+end_statement

La envolvente convexa debe contener a todos los puntos y a sus
combinaciones convexas, luego debe contener a todo el simplex.

El simplex es convexo trivialmente:

\[
t \sum \lambda_i v_i + (1-t) \sum \lambda_i' v_i =
\sum t \lambda_i v_i + \sum (1-t) \lambda_i' v_i
\]

Y entonces la suma de los coeficientes suma la unidad, usando
que lo cumplen ambos elementos del símplice:

\[
\sum t\lambda_i + \sum (1-t)\lambda_i' = t + (1-t) = 1
\]

***** Ejercicio 6
#+begin_statement
Dado un vértice de un complejo simplicial $K$ se define la estrella 
abierta de $v$ como $ost(v) = \{o(\sigma) \mid \sigma \in st(v)\}$. Prueba que $ost(v)$ es un
entorno abierto de $v$ en $|K|$ y la colección de todas las estrellas 
abiertas es un recubrimiento abierto de $|K|$.
#+end_statement

Todo punto aquí pertenece a algún $x \in o(\sigma), \sigma \in st(v)$. Una bola cerrada
alrededor suya es compacta y sólo contiene a una cantidad finita de
símplices. Un símplice $\tau$ que contenga a $x$ se corta con $\sigma$, nos da
$\sigma \cap \tau < \sigma$. Tenemos dos casos:

  - $\sigma \cap \tau = \sigma$, entonces $v \in \tau$.
  - $\sigma \cap \tau < \sigma$, que daría que $x$ esté en una cara de $\sigma$ y no pueda estar
    en $o(\sigma)$.

Así, no hay ningún vértice que no contenga a $v$ tocando a $x$. Todos están
a distancia mayor que $0$, y puedo tomar el mínimo de las distancias (que
son un conjunto finito) y tener una bola cerrada que sólo corta símplices
de la estrella. La bola abierta sólo cortará a los símplices abiertos.

[[./images/starcomplex.png]]

Imagen de [[http://math.stackexchange.com/questions/633307/definition-of-star-in-a-simplicial-complex][Math.SE: Definition of star in a simplicial complex]].

***** Ejercicio 7
#+begin_statement
Describe una triangulación del toro, el plano proyectivo y la botella
de Klein.
#+end_statement

Nótese que la triangulación debe cumplir los requisitos de los complejos
simpliciales, especialmente, que cada intersección debe ser vacía o cara
de ambos factores.

***** Ejercicio 8
#+begin_statement
Describe una triangulación del espacio topológico cociente que se
obtiene cuando en un toro identificamos un meridiano a un punto.
#+end_statement

Nótese primero que esto no es una superficie compacta porque el punto
en el que hemos identificado el meridiano no es localmente euclídeo.

***** Ejercicio 9
#+begin_statement
Demuestra que la suma conexa de uno o más planos proyectivos contiene un
subespacio que es homeomorfo a una banda de Möbius.
#+end_statement

Podemos obtener en la presentación poligonal, uniendo con una banda
dos aristas identificadas, una banda de Möbius.

***** Ejercicio 10
#+begin_statement
Para cada una de las siguientes presentaciones de superficies calcula
la característica de Euler y determina a cuál de las superficies modelo
es homeomorfa:

  1. $\langle a,b,c \mid abacb^{-1}c^{-1} \rangle$.
  2. $\langle a,b,c \mid abca^{-1}b^{-1}c^{-1} \rangle$.
  3. $\langle a,b,c,d,e,f \mid abc,bde,c^{-1}df,e^{-1}fa \rangle$.
#+end_statement

****** Superficie 1
Calculamos Euler:

\[\chi(S) = 1 - 3 + 1\]

Y vemos que no es orientable. Es $\mathbb{RP}^{2\#3}$.

****** Superficie 2
Es un toro.

****** Superficie 3
Calculamos Euler:

\[\chi(S) = 4 - 5 + 3 = 2\]

Y a la vez que sacamos los vértices comprobamos que es orientable.

***** Ejercicio 12
#+begin_statement
Prueba que la característica de Euler de la suma conexa de dos
superficies compactas es igual a la suma de sus características de
Euler menos dos.
#+end_statement

Si unimos las dos mediante cualquier triangulación razonable:

****** Triangulación 1
Se pierden 2 caras para cortar, se pegan con 3 caras, y 3 aristas.

#+begin_center
#+attr_latex: :width 50px
[[./images//sumatriangulacion1.png]]
#+end_center

****** Triangulación 2
Perdemos dos caras e identificamos 3 aristas y 3 vértices.

#+begin_center
#+attr_latex: :width 50px
[[./images//sumatriangulacion2.png]]
#+end_center
**** Clasificación de superficies compactas
***** Calcular la orientabilidad
Un algoritmo que usa la caracterización de bicolorabilidad para
determinar si una superficie es orientable o no:

#+BEGIN_SRC haskell
  import Text.ParserCombinators.Parsec
  type Letra = (Char,Bool)
  type Palabra = [Letra]
  type Color = Bool
  type Presentacion = [Palabra]
  type Coloracion = [(Palabra,Color)]

  orientable :: Presentacion -> Bool
  orientable presentacion = any esBuenaColoracion (posiblesColoraciones presentacion)

  posiblesColoraciones :: Presentacion -> [Coloracion]
  posiblesColoraciones [] = [[]]
  posiblesColoraciones (w:presentacion) =
    map ([(w,False)] ++) (posiblesColoraciones presentacion) ++
    map ([(w,True)] ++) (posiblesColoraciones presentacion)
  
  esBuenaColoracion :: Coloracion -> Bool
  esBuenaColoracion c = compruebaColores $ concat $ map (\(w,l) -> map (\x -> (x,l)) w) c

  compruebaColores :: [(Letra,Color)] -> Bool
  compruebaColores [] = True
  compruebaColores (vt : xs) = (all (\ut -> buenaArista ut vt) xs) && compruebaColores xs

  buenaArista :: (Letra,Color) -> (Letra,Color) -> Bool
  buenaArista ((x,u),v) ((y,w),z) = (x /= y) || (u == w && v /= z) || (u /= w && v == z)

  main :: IO ()
  main = return ()


  esOrientable :: String -> Bool
  esOrientable s = either undefined orientable (parse pres "" s) 

  pres :: Parser Presentacion
  pres = word `sepBy` (char ',')

  word :: Parser Palabra
  word = many letra

  letra :: Parser Letra
  letra = try letrainvertida <|> do
    l <- letter
    return (l,True)
  
  letrainvertida :: Parser Letra
  letrainvertida = do
    l <- letter
    _ <- char '*'
    return (l,False)
#+END_SRC
** Álgebra moderna
*** 1. Construcción de anillos
**** 1.1. Anillos
***** Anillos
Un *anillo* es $(R,+,\times,1)$ siendo:

 1) $(R,+)$ un grupo aditivo abeliano.
 2) $(R,\times,1)$ monoide multiplicativo.
 3) $\times$ distributivo con $+$.

Llamamos $0$ al elemento neutro de la suma.

****** Anillos conmutativos
Llamamos *anillo conmutativo* a un anillo con $\times$ conmutativo.

****** Propiedades en anillos
Sea $r_1,r_2 \in R$ anillo:

 - $0r=0=r0$
 - $r_1(-r_2) = -r_1r_2 = (-r_1)r_2$
 - $r(r_1-r_2) = rr_1-rr_2$
 - $r_1+r_2=r_2+r_1$

******* Demostración
Usando distributividad se prueban trivialmente.

***** Morfismos de anillos
Un $f : R \to S$ es homomorfismo de anillos cuando:

  - $f(r_1+r_2) = f(r_1)+f(r_2)$
  - $f(r_1r_2) = f(r_1)f(r_2)$
  - $f(1) = 1$

****** Categoría de los anillos
La composición de dos morfismos de anillos es morfismo de anillos y
la identidad es morfismo de anillos. Los anillos unitales forman así
una categoría $\mathtt{Ring}$.

****** Isomorfismos de anillos
***** Subanillos
***** Retículo de subanillos
***** Ideales
***** Ideales extendidos y contraidos
***** Retículo de ideales
***** Ejemplo: Matrices infinitas
***** Ejemplo: Álgebra de Weyl
Se llama *álgebra de Weyl* al anillo de operadores en los polinomios
generado por $X$ (multiplicación por la indeterminada) y $\frac{\partial}{\partial x}$ (diferenciación);
con la composición como producto.

****** Caracterización
El álgebra de Weyl es isomorfa a:

\[
\frac{K[X,Y]}{(YX-XY-1)}ñ
\]

***** Ejemplo: Anillo de un monoide
Dado un monoide multiplicativo $M$, definimos $R[M]$ como los polinomios que
usan como exponentes los elementos de $M$. Es decir,

\[
\sum_i r_i[m_i]
\]

Y forma un álgebra definiendo:

  - Suma: $\sum_i r_i[m_i] + \sum_i r_i'[m_i] = \sum_i (r_i+r_i')[m_i]$
  - Producto: $\left(\sum_i r_i[m_i]\right)\left(\sum_i r_i'[m_i]\right) = \sum_k \left(\sum_{m_im_j=m_k} (r_ir_j')[m_k]\right)$

****** Generaliza al anillo de polinomios
Nótese que generaliza al anillo de polinomios en una variable cuando 
el monoide es $\mathbb{N}$, y que generaliza al anillo de polinomios en varias 
variables cuando el monoide es $\mathbb{N}^n$.

***** TODO Monoide libre
**** 1.2. Construcción de anillos
***** Anillo cociente
****** Proyección
***** Propiedad universal del anillo cociente
***** Primer teorema de isomorfía
***** Segundo teorema de isomorfía
***** Tercer teorema de isomorfía
***** Producto directo
***** Caracterización del producto por ortogonales centrales idempotentes
***** Anillo opuesto
***** Centro
***** Propiedad universal del anillo de un monoide
***** Anillo de polinomios
***** Propiedad universal del anillo de polinomios
**** 1.3. Módulos
***** R-módulos
****** Caracterización por anillo opuesto
***** Morfismo de R-módulos
***** Submódulos
****** Ideales como submódulos 
***** Módulo cociente
***** Propiedad universal del módulo cociente
***** Retículo de submódulos
****** Intersección de submódulos
****** Suma de submódulos
***** Submódulos maximales
**** TODO 1.4. Categorías y funtores
**** 1.5. La categoría Mod-R
***** Caracterización de monomorfismos y epimorfismos
***** Primer teorema de isomorfía
***** Segundo teorema de isomorfía
***** Tercer teorema de isomorfía
***** Producto directo
***** Suma directa
***** Límites
***** Colímites
***** Ejemplos de límite
***** Cambios de anillo
https://en.wikipedia.org/wiki/Change_of_rings
*** 2. Construcción de módulos
**** 2.1. Producto tensor
***** Aplicaciones bilineales
Sean $M$ un R-módulo derecho y $N$ un R-módulo izquierdo. Un homomorfismo de
grupos es R-bilineal si:

  - $\varphi(m_1+m_2,n) = \varphi(m_1,n) + \varphi(m_2,n)$
  - $\varphi(m,n_1+n_2) = \varphi(m,n_1) + \varphi(m,n_2)$
  - $\varphi(mr,n) = \varphi(m,rn)$

***** Producto tensor
Construimos el grupo producto tensor como el grupo libre generado por
los elementos del producto cartesiano, dividido por el grupo generado 
por las relaciones de bilinealidad:

\[
M \otimes_R N = \frac{\langle
(m,n) \mid m \in M, n \in N
\rangle}{B}
\]

Donde $B$ está generado por:

  - $(m_1+m_2,n) - (m_1,n) - (m_2,n)$
  - $(m,n_1+n_2) - (m,n_1) - (m,n_2)$
  - $(mr,n)-(m,rn)$

Nótese que además tenemos la proyección $b : M \times N \to M \otimes N$.

***** Propiedad universal del producto tensor
Sean $M_R, _RN$ módulos con $f : M \times N \to X$ bilineal, existe un
único homomorfismo de grupos $\overline{f} : M \oplus_R N \to X$ tal que conmuta:

\[\begin{tikzcd}
M \times N \rar{b}\drar[swap]{f} & 
M \otimes_R N \dar[dashed]{\exists! \overline{f}} \\
& X
\end{tikzcd}\]

****** TODO Demostración

***** Neutro del producto tensor
Se cumple $M \otimes R \cong M$ y $R \otimes N \cong N$.

***** TODO Producto tensor en anillos conmutativos
***** Producto tensor de álgebras
Si $R,S$ son dos A-álgebras, su producto tensor lo es con el producto
dado por:

\[
(r_1 \otimes s_1)(r_2 \otimes s_2) = (r_1r_2)\otimes(s_1s_2)
\]

****** TODO Inclusiones en el producto tensor de álgebras

***** TODO Producto tensor de álgebras como coproducto
**** 2.2. Módulos a dos lados
***** Módulos a dos lados
Un $M$ R-módulo izquierda y S-módulo derecha se llama *(R;S)-módulo a dos lados*
si cumple:

\[
r(ms)=(rm)s
\]

***** TODO Caracterización de módulos a dos lados
***** TODO Módulos a dos lados balanceados y fieles
***** TODO Propiedad universal del producto tensor como módulo a dos lados
**** 2.3. El retículo de submódulos
***** Categoría de los conjuntos parcialmente ordenados
Tomamos la *categoría de los conjuntos parcialmente ordenados* ${\cal P}$, siendo 
sus morfismos las aplicaciones crecientes:

\[
x \leq y \implies f(x) \leq f(y)
\]

****** Submódulos como conjuntos parcialmente ordenados
Existe el funtor covariante retículo ${\cal L} : \mathtt{Mod-}R \to {\cal P}$ que lleva cada módulo 
en su retículo de submódulos y cada homomorfismo de módulos lo aplica sobre
cada submódulo del retículo:

\[
{\cal L}(f)(N) = f(N)
\]

Y existe el funtor contravariante retículo ${\cal L} : \mathtt{Mod-}R \to {\cal P}$ que lleva cada
módulo en su retículo y cada homomorfismo de módulos lo aplica de manera
inversa sobre cada submódulo del retículo:

\[
{\cal L}(f)(N) = f^{-1}(N)
\]

***** Retículos
Un *retículo* es un conjunto parcialmente ordenado donde todo par de
elementos tiene supremo e ínfimo, llamados $a \vee b$ y $a \wedge b$.

***** Propiedades del retículo
En todo retículo $({\cal L}, \leq)$ se verifican:

 1) Idempotencia, $a \vee a = a$
 2) Conmutatividad, $a \vee b = b \vee a$
 3) Asociatividad, $a \vee (b \vee c) = (a \vee b) \vee c$
 4) Absorción, $a \vee (a \wedge c) = a$

Y sus duales:

 1) Idempotencia, $a \wedge a = a$
 2) Conmutatividad, $a \wedge b = b \wedge a$
 3) Asociatividad, $a \wedge (b \wedge c) = (a \wedge b) \wedge c$
 4) Absorción, $a \wedge (a \vee c) = a$

***** Retículo abstracto
Llamamos *retículo abstracto* a un conjunto $L$ con operaciones $\vee,\wedge$ que
cumplen las propiedades de retículo.

****** Orden en un retículo abstracto
Un retículo abstracto determina una relación de orden, y además
se cumple en él:

\[
a \vee b = b \iff a \wedge b = a
\]

******* TODO Demostración
******** Relación de orden
******** Propiedad
****** Homomorfismo de retículos abstractos
Un homomorfismo de retículos abstractos es una aplicación preservando
supremos e ínfimos.

\[
f(a\wedge b) = f(a) \wedge f(b) \qquad f(a\vee b) = f(a) \vee f(b)
\]

****** Categoría de retículos abstractos
La categoría de retículos abstractos contiene a los retículos y los
homomorfismos de retículos entre ellos. Es una categoría isomorfa
a la categoría de conjuntos parcialmente ordenados.

***** Retículo de submódulos de un módulo
Los submódulos forman un retículo con:

  - $N \vee N' = N + N'$
  - $N \wedge N' = N \cap N'$

***** Retículos acotados
Un retículo con cero y uno se llama acotado, donde:

  - El elemento cero cumple: $a \wedge 0 = 0$
  - El elemento uno cumple:  $a \vee 1 = 1$

***** Retículos modulares
Llamamos retículo modular al que cumple la *ley modular*:

\[
N_1 \vee (N_2 \wedge N_3) = (N_1 \vee N_2) \wedge N_3
\]

****** El retículo de submódulos es modular
Los submódulos forman retículos modulares.

******* TODO Demostración

***** Retículos completos
Un retículo en el que existe el supremo e ínfimo de cualquier familia de
submódulos se dice *completo*.

****** El retículo de submódulos es completo
El retículo de submódulos es completo, siendo el supremo e ínfimo de
cada familia $\{ N_i \mid i \in I\}$:

  - $\bigvee N_i = \sum N_i$

  - $\bigwedge N_i = \bigcap N_i$

***** TODO Retículos superiormente continuos y compactamente generados
**** 2.5. Módulos finitamente generados
***** TODO Módulos finitamente generados
***** TODO Construcción de finitamente generados
***** TODO Submódulo maximal
***** TODO Caracterización de finitamente generados
***** TODO Homomorfismos a la suma directa
***** TODO Conmutación con sumas directas
***** TODO Compacidad
***** TODO Módulos noetherianos
***** TODO Módulos noetherianos: propiedades
**** TODO 2.6. Módulos noetherianos
*** 3. Sumas directas y productos directos de módulos
**** 3.1. Biproducto de módulos
***** Biproducto de módulos
Se llama *biproducto de módulos* a la terna $(M_1\oplus M_2, \{p_1,p_2\}, \{q_1,q_2\})$,
con las proyecciones e inclusiones de producto y coproducto.

****** Propiedades del biproducto
Las composiciones de proyecciones e inyecciones cumplen:

 - $p_1q_1 = id_1$
 - $p_2q_2 = id_2$
 - $p_1q_2 = 0$
 - $p_2q_1 = 0$
 - $q_1p_1 + q_2p_2 = id$

**** TODO 3.2. Independencia y sumas directas
**** TODO 3.3. Módulos libres
**** TODO 3.4. Descomposición de anillos
*** Ejercicios
**** Semana 1
#+begin_statement
Prueba que los ideales (biláteros) del anillo $M_n(R)$ son de la forma
$M_R(\mathfrak{a})$, para un ideal (bilátero) $\mathfrak{a} \subseteq R$.
#+end_statement

Llamamos $E_{ij}$ a la matriz que tiene todas sus entradas nulas excepto
la entrada $i,j$. Dada $N$, una matriz con elementos $N = (n_{ij})_{i,j}$, el
producto de matrices es:

\[
E_{ia}NE_{bj} = n_{ab}E_{ij}
\]

Es decir, si una matriz $N$ está en un ideal bilátero $J$, todas las 
matrices de la forma $n_{ab}E_{ij}$ estarán también en el ideal.

Esto nos da por un lado que los elementos que aparecen en matrices 
del ideal forman un ideal $I$, si $a,b$ están en el ideal, $(a+\alpha b)E_{ij}$ 
estará en el ideal. Y además, cualquier matriz de la forma $xE_{ij}$ para
$x \in I$ está en el ideal. Así, el ideal es de la forma:

\[
J = M_R(\mathfrak{a})
\]

**** Semana 2
#+begin_statement
Prueba que $A[|X|]$, el anillo de las series formales de potencias en una
indeterminada $X$, es isomorfo al límite inverso del sistema de anillos
dirigido inferiormente $(\{\frac{A[X]}{(X^n)}\}, \{f_{n,m}\}_{n \geq m})$, donde $f_{n,m} : \frac{A[X]}{(X^n)} \to \frac{A[X]}{(X^m)}$ es
el homomorfismo de anillos definido por $f_{n,m}(\overline{X}) = \overline{X}$, si $n \geq m$.
#+end_statement

***** Subanillo isomorfo
Empezamos definiendo un subanillo del producto de los anillos $\frac{A[X]}{(X^n)}$.
Nótese que es subanillo por ser las funciones $f_{i,j}$ morfismos de anillos:

\[
H = \left\{
(p_i)_i \in \prod_i \frac{A[X]}{(X^i)}
\;\middle|\;
f_{i,j}(m_i) = m_j
\right\}
\]

Comprobaremos que es isomorfo a $A[|X|]$; para ello definimos la función
siguiente:

\[
g(a_0+a_1X+a_2X^2+\dots) = (a_0,a_0+a_1X,a_0+a_1X+a_2X^2,\dots)
\]

Es trivialmente inyectiva porque si $p \neq q$, se diferenciarán en el primer
polinomio en el que tengan un coeficiente distinto. Es trivialmente
sobreyectiva porque si tengo un elemento de la forma $(u_0,u_1,\dots) \in H$,
se debe tener $u_n = u_{n-1} + a_n X_n$, para $u_{n-1}$ de grado $n-1$. Esto asegura
que el elemento será de la forma:

\[
(a_0,a_0+a_1X, a_0+a_1X+a_2X^2,\dots) = g(a_0+a_1X+a_2X^2+\dots)
\]

***** Límite inverso
Para probar que es límite inverso, probaremos que si existiera un $Z$ con
morfismos $\phi_n : Z \to \frac{A[X]}{(X^n)}$ cumpliendo $\phi_m = f_{n,m} \circ \phi_n$, existiría un único 
morfismo $Z \to H$ haciendo conmutar el diagrama:

\[\begin{tikzcd}
\frac{A[X]}{(X^0)} \rar &
\frac{A[X]}{(X^1)} \arrow{rr} &&
\frac{A[X]}{(X^2)} \rar &
\dots \\
&&
H \arrow{ull} \ular \urar \arrow{urr}
& & \\
& &
Z
\arrow[bend left]{uull} \arrow[bend left]{uul}
\arrow[bend right]{uurr} \arrow[bend right]{uur}
\uar[dashed]{!\exists}
&&
\end{tikzcd}\]

Ahora bien, dado $Z$ y los morfismos $\phi_n$, por propiedad universal del
producto directo, tenemos que existe un único morfismo $h: Z \to \prod_i \frac{A[X]}{(X^i)}$,
cumpliendo además que $\phi_n = \pi_n \circ h$. Aplicando $f_{n,m}$ tenemos:

\[
f_{n,m} \circ \pi_n \circ h = f_{n,m} \circ \phi_n =
\phi_m = \pi_m\circ h
\]

Lo que nos da que $im(h) \subseteq H$ y por tanto el morfismo buscado, que hereda
la unicidad.

**** Semana 3
***** Ejercicio 1.5.
#+begin_statement
Sea $R$ un anillo y $0 \neq e \in R$ un elemento idempotente; llamamos $f = 1-e$.

 1. Prueba que $eRe$ y $fRf$ son anillos.
 2. Prueba que $eRf$ es un $(eRe;fRf)$ módulo, y $fRe$ es un $(fRf,eRe)$ módulo.
 3. Prueba que existe un homomorfismo inyectivo de anillos

    $\lambda : R \longrightarrow 
    \begin{pmatrix}
    eRe & eRf \\
    fRe & fRf 
    \end{pmatrix}$, definido: $\lambda(r) = \begin{pmatrix} ere&erf\\fre&frf \end{pmatrix}$ para cada $r \in R$.

 4. Prueba que existe un isomorfismo de grupos abelianos
    $Hom_R(eR_R,fR_R) \cong fRe$, y un isomorfismo de anillos $End_R(eR_R) \cong eRe$.
 5. Prueba que:

    \[
    R \overset{\beta}\cong End_R(R_R) = 
    End_R((eR\oplus fR)_R) \cong \begin{pmatrix} eRe&eRf\\fRe&fRf \end{pmatrix}
    \]

    siendo $\beta(r)(x) = rx$. Como consecuencia $\lambda$ es un isomorfismo de anillos.

$\quad$
#+end_statement

****** Punto 1
Por propiedad distributiva, son cerrados con la misma suma que $R$. Son
trivialmente cerrados con el producto y nos falta comprobar que contiene
un elemento unidad, que es $e$ y es neutro gracias a ser idempotente:

\[
e(ere) = ere = (ere)e
\]

Nótese que $f$ es también idempotente y se repite el razonamiento.

****** Punto 2
Comprobamos que $eRf$ es cerrado para la suma, y además:

 - $(ese)(erf) = e(ser)f$
 - $(erf)(ftf) = e(rft)f$

Por lo que es un módulo a izquierda para $eRe$ y a derecha para $fRf$.

Nótese que el caso de $fRe$ es simétrico.

****** Punto 3
Nótese que $\lambda$ preserva sumas trivialmente. Debemos comprobar que respeta
la unidad y el producto. Notamos primero gracias a que $ef=0$ tenemos:

\[
\lambda(1) = \begin{pmatrix}e&0\\0&f\end{pmatrix}
\]

Que se comprueba trivialmente que es el uno de su anillo, ya que es neutro
respecto al producto:

\[\begin{pmatrix}e&0\\0&f\end{pmatrix}\begin{pmatrix}er_1e&er_2f\\fr_3e&fr_4f\end{pmatrix} =\begin{pmatrix}er_1e&er_2f\\fr_3e&fr_4f\end{pmatrix}\]

Por último comprobamos que el producto se preserva:

\[\begin{pmatrix}ere&erf\\fre&frf\end{pmatrix}\begin{pmatrix} ese & esf \\ fse & fsf \end{pmatrix}
= \begin{pmatrix}erse&ersf\\frse&frsf\end{pmatrix}\]

Donde usamos crucialmente que $erese+erfse=er(e+f)se=erse$.

****** Punto 4
******* Isomorfismo de grupos abelianos
Suponiendo que se consideran los homomorfismos como módulos a derecha
de $R$, podemos llevar cada homormofismo $\lambda$ a $\lambda(e)e$ y cada elemento $fre$
al homomorfismo $\psi(x) = (fre)x$.

Comprobamos que esto da una biyección para elemento cualquiera $fre \in fRe$
y $\lambda \in Hom(eR,fR)$ comprobando que la composición es la identidad:

\[
fre \mapsto \psi_{fre} \mapsto \psi_{fre}(e)e = freee = fre
\]
\[
\lambda(ex) \mapsto \lambda(e)e \mapsto \lambda(e)e(ex) = \lambda(ex)
\]

Donde hemos usado en el último paso que $\lambda$ es homomorfismo de R-módulos
a derecha. Que esto preserva la suma es trivial.

******* Isomorfismo de anillos
En este caso tenemos un isomorfismo de grupos abelianos dado por el
caso anterior. Además, es operación multiplicativa al tenerse:

\[
(\psi\circ\varphi)(e)e = \psi(e)\varphi(e)e
\]

Por ser homomorfismos de módulos a derecha. Y es unital por tenerse:

\[
id(e)e = e
\]

****** Punto 5
******* Primer isomorfismo
Trivialmente $\beta$ es inyectivo porque $\beta(r)$ aplica la unidad en $r$.
Que es sobreyectivo es trivial porque cada función está determinada
por dónde lleva la unidad. Por ser homomorfismo de R-módulos:

\[
\varphi(r) = \varphi(1)r
\]

******* Segundo isomorfismo
Nótese que dada una $\varphi \in End_R(eR\oplus fR)$, podemos descomponer su aplicación
a cualquier elemento como:

\[
\varphi(er+fr) = \varphi(er)+\varphi(fr) = e\varphi(er)+f\varphi(er)+
e\varphi(fr)+f\varphi(fr)
\]

Por lo que queda determinada por dos endomorfismos entre $eR$ y $fR$ y
dos homomorfismos de $eR$ a $fR$ y de $fR$ a $eR$; y se puede escribir como:

\[
\varphi(ex+fy) = \begin{pmatrix}f_1&f_2\\f_3&f_4\end{pmatrix}\begin{pmatrix}ex\\fy\end{pmatrix}
\]

Con los isomorfismos anteriores tenemos lo buscado.

******* Isomorfismo de anillos
Notamos trivialmente que el isomorfismo así determinado es $\lambda$.
Dado $r$, podemos ver que se divide como:

\[
rx = erex + erfx + frex + frfx
\]

Donde cada elemento pertenece al buscado.

***** Ejercicio 1.6.
#+begin_statement
Sea $R$ un anillo, $0\neq e \in R$ un elemento idempotente, y $f = 1 - e$. Para cada
R-módulo derecha $M$ se define $Me = \{me \mid m \in M\}$, y $Mf = \{mf \mid m \in M\}$.

 1. Prueba que $Me$ es un $eRe$ módulo derecha y $Mf$ un $fRf$ módulo derecha.
 2. Prueba que $Me \times Mf$ es un $\begin{pmatrix}eRe&eRf\\fRe&fRf\end{pmatrix}$ módulo derecha con estructura
    dada por,

    \[
    (m_1e, m_2f)
    \begin{pmatrix}em_{11}e&em_{12}f\\fm_{21}e&fm_{22}ff\end{pmatrix} =
    (m_1em_{11}e + m_2fm_{21}e, m_1em_{12}f + m_2fm_{22}f)
    \]

 3. Prueba que $h : M \longrightarrow Me \times Mf$, definido $h(m) = (me,mf)$, es un isomorfismo
    de R-módulos derecha, donde la estructura de $Me \times Mf$ está dada vía $\lambda$.
    Observa que $Me$ y $Mf$ son subgrupos de $M$, pero no necesariamente submódulos.

$\quad$
#+end_statement

****** Punto 1
Siendo $me \in Me$, tenemos que $me(ere) = (mer)e \in Me$, donde usamos que
$M$ es módulo a derecha. De la misma forma se cumple para $f$, que es
idempotente.

****** Punto 2
Simplemente tenemos que comprobar que la aplicación de multiplicar por
la matriz es lineal en $(m_1,m_2)$, y además, que los elementos vuelven
a estar en $Me \times Mf$ por escribirse como:

 - $(m_1em_{11})e + (m_2fm_{21})e$
 - $(m_1em_{12})f + (m_2fm_{22})f$

Usando de nuevo que $M$ es módulo a derecha.

****** Punto 3
Tenemos que cada elemento se escribe de forma única como $m = me+mf$.
Si tuviéramos otra suma $m = ae + bf$, se tendría $me=ae$ y $mf=bf$ al
multiplicar por cada uno de los idempotentes.

Tenemos por tanto una biyección, que además es lineal y preserva la
multiplicación por la derecha:

\[
(mre,mrf) = (me,mf)\begin{pmatrix}ere&erf\\fre&frf\end{pmatrix}
\]

Observamos que $Me$ y $Mf$ son cerrados para la suma. Pero no tienen por
qué ser cerrados como módulo. Nótese que puede darse el caso de que
$mer \notin Me$, como ocurre en las matrices, donde hay idempotentes no
centrales:

\[ e\begin{pmatrix}
a & b \\ c & d
\end{pmatrix} = \begin{pmatrix}
1 & 0 \\ 0 & 0
\end{pmatrix} \begin{pmatrix}
a & b \\ c & d
\end{pmatrix} = \begin{pmatrix}
a & b \\ 0 & 0
\end{pmatrix}\]

Que no puede pertenecer al $Me$ porque cambia al multiplicarla a la derecha
por $e$.
**** Semana 4
***** Ejercicio 1.7.
#+begin_statement
Si $K$ es un cuerpo, se considera el anillo:

\[
R = \begin{pmatrix}
K & K \\ 0 & K
\end{pmatrix}
\]

 1) Estudia los ideales derecha de $R$.
 2) Estudia los ideales izquierda de $R$.
 3) Estudia los ideales biláteros de $R$.

Ver también ejercicios anteriores.
#+end_statement

****** Ideales derecha
La multiplicación por un elemento del ideal sería:

\[\begin{pmatrix}
a & b \\ 0 & d
\end{pmatrix}\begin{pmatrix}
k_1 & k_2 \\ 0 & k_3
\end{pmatrix}  = \begin{pmatrix}
k_1a & k_2a+k_3b \\ 0 & k_3d
\end{pmatrix}\]

Estudiando cada combinación de $a,b,d$ nulos o no nulos, se obtienen
los ideales siguientes:

 - El ideal total, $\begin{pmatrix}K & K \\ 0 & K\end{pmatrix}$.

 - Suponiendo $a=0$, $\langle\begin{pmatrix}0 & k \\ 0 & 1\end{pmatrix}\rangle$.

 - Suponiendo $a=0,d=0$, $\begin{pmatrix}0 & K \\ 0 & 0\end{pmatrix}$.

 - Suponiendo $a=0,b=0$, $\begin{pmatrix}0 & 0 \\ 0 & K\end{pmatrix}$.

 - Suponiendo $d=0$, $\begin{pmatrix}K & K \\ 0 & 0\end{pmatrix}$.

 - El ideal trivial, $\begin{pmatrix}0 & 0 \\ 0 & 0\end{pmatrix}$.

****** Ideales izquierda
La multiplicación por un elemento del ideal es:

\[\begin{pmatrix}
k_1 & k_2 \\ 0 & k_3
\end{pmatrix} \begin{pmatrix}
a & b \\ 0 & d
\end{pmatrix} = \begin{pmatrix}
k_1a & k_1b+k_2d \\ 0 & k_3d
\end{pmatrix}\]

Estudiando cada combinación de $a,b,d$ nulos o no nulos, se obtienen
los ideales siguientes:

 - El ideal total, $\begin{pmatrix}K & K \\ 0 & K\end{pmatrix}$.

 - Suponiendo $d=0$, $\begin{pmatrix}K & K \\ 0 & 0\end{pmatrix}$.

 - Suponiendo $a=0$, $\begin{pmatrix}0 & K \\ 0 & K\end{pmatrix}$.

 - Suponiendo $a=0,d=0$, $\begin{pmatrix}0 & K \\ 0 & 0\end{pmatrix}$.

 - Suponiendo $a=0,b=0$ $\begin{pmatrix}K & 0 \\ 0 & 0\end{pmatrix}$.

 - El ideal trivial, $\begin{pmatrix}0 & 0 \\ 0 & 0\end{pmatrix}$.

****** Ideales biláteros
Buscamos los ideales que lo son a izquierda y derecha:

$\begin{pmatrix}K & K \\ 0 & K\end{pmatrix}$ $\begin{pmatrix}K & K \\ 0 & 0\end{pmatrix}$ $\begin{pmatrix}0 & K \\ 0 & K\end{pmatrix}$ $\begin{pmatrix}0 & K \\ 0 & 0\end{pmatrix}$ $\begin{pmatrix}0 & 0 \\ 0 & 0\end{pmatrix}$

***** Ejercicio 1.8.
#+begin_statement
Estudia los ideales derecha e izquierda del anillo:

\[
R = \begin{pmatrix}\mathbb{Q}&\mathbb{R}\\0&\mathbb{R}\end{pmatrix}
\]

 1) Prueba que $R$ es un anillo artiniano derecha y noetheriano derecha.
 2) Prueba que $R$ no es un anillo artiniano izqierda ni noetheriano izquierda.

$\quad$
#+end_statement

****** Ideales derecha
Los ideales no triviales a la derecha son los siguientes:

- $\begin{pmatrix} 0 & 0 \\ 0 & \mathbb{R} \end{pmatrix}$

- $\langle\begin{pmatrix} 0 & k \\ 0 & 1 \end{pmatrix}\rangle$

- $\begin{pmatrix} \mathbb{Q} & \mathbb{R} \\ 0 & 0 \end{pmatrix}$

- $\begin{pmatrix} \mathbb{Q} & \mathbb{R} \\ 0 & \mathbb{R} \end{pmatrix}$

Habiendo sólo una cantidad finita de ideales, el anillo será artiniano
y noetheriano.

****** Ideales izquierda
Considerando de nuevo los casos y teniendo esta vez en cuenta que el
primer coeficiente está en $\mathbb{Q}$.

- $\begin{pmatrix} \mathbb{Q} & \mathbb{K} \\ 0 & 0 \end{pmatrix}$, para cualquier $\mathbb{K}$ extensión de cuerpos $\mathbb{Q}\subset \mathbb{K}\subset\mathbb{R}$.

- $\begin{pmatrix} 0 & \mathbb{R} \\ 0 & \mathbb{R} \end{pmatrix}$

- $\begin{pmatrix} \mathbb{Q} & \mathbb{R} \\ 0 & \mathbb{R} \end{pmatrix}$

Comprobamos que no es artiniano ni noetheriano porque podemos crear
cadenas que rompen la condición de cadena ascendente y descendente.
Sabiendo que los reales tienen dimensión infinita sobre los racionales
como espacio vectorial, creamos ambas cadenas añadiendo y retirando
progresivamente vectores de la base.

**** Semana 6
#+begin_statement
Sea $M$ un grupo abeliano finitamente generado y libre de torsión.
Prueba que $M$ es un grupo libre.
#+end_statement

Si no fuera libre, cada conjunto de generadores
$\left\{ m_1,\dots,m_{n} \right\}$ debería cumplir ecuaciones de la forma

\[n_1m_1+ \dots + n_tm_t = 0,\]

y entre todos los posibles conjuntos de generadores de cardinalidad
mínima y combinaciones, podemos elegir una que minimice $|n_1|+\dots + |n_t|$.
Ahora, si hay una combinación en la que $|n_i|<|n_j|$ para dos $i\neq j$,
podemos usar que

\[
n_im_i + n_jm_j = (n_i-n_j)m_i + n_{j}(m_j-m_i)
\]

para reescribir la relación, teniendo otro sistema de generadores
equivalente $\left\langle m_1,\dots,m_i,m_j,\dots,m_{t} \right\rangle = \left\langle m_1,\dots,m_i,m_j-m_i,\dots,m_t \right\rangle$ que
tiene un $|n_1|+\dots + |n_t|$ menor. Así, en el mínimo, $|n_i| = d$ para cualquier
índice. Pero este $d$ no puede ser mayor que $1$ porque si no se tendría un
elemento de torsión

\[
d \left( \frac{n_1}{d}m_1 + \dots + \frac{n_t}{d}m_t \right) = 0.
\]

Así, hemos llegado a una relación en la que un generador puede ponerse
como suma y diferencia de los otros, 

\[
m_1 = \pm m_2 \pm m_3 \pm \dots \pm m_{t},
\]

contraviniendo la minimalidad del
sistema de generadores

**** Semana 7
#+begin_statement
Sea $R$ un anillo con un único ideal izquierda maximal $\mathfrak{a}$.

 1) Prueba que $\mathfrak{a}$ es un ideal bilátero.
 2) Prueba que $\mathfrak{a}$ es el único ideal derecha maximal.
 3) Prueba que $R/\mathfrak{a} = {\cal U}(R) = R^{\times}$, el conjunto de los elementos 
    invertibles de $R$.

Un anillo con un único ideal derecha maximal se llama *anillo local*.
#+end_statement

Nótese que por Teorema de Krull, todo ideal propio (izquierda,
derecha, bilátero) está contenido en un ideal maximal (izquierda,
derecha, bilátero). Todo elemento no unidad está contenido en un
ideal maximal (izquierda, derecha, bilátero).

***** Primer punto
Si $x \in \mathfrak{a}$, sabemos que no puede ser unidad; así, $xy$ tampoco puede serlo 
para ningún $y \in R$, y como no puede serlo, debe estar contenido en algún
ideal maximal izquierda, que debe ser $\mathfrak{a}$.

***** Segundo punto
Usando el tercer punto, cualquier elemento que estuviera en un ideal
derecha maximal que no estuviera en el único ideal bilátero que existe
debería ser una unidad.

***** Tercer punto
Si hubiera algún $x + \mathfrak{a}$ no invertible, se tendría que $\left\langle x \right\rangle$ generaría un
ideal propio que debería estar contenido en un maximal. Este maximal
debería ser $\mathfrak{a}$, y por tanto $x = 0$.

**** Semana 8
#+begin_statement
Sea $R$ un anillo y $e \in R$ un elemento idempotente

 1) para cada ideal derecha $\mathfrak{a} \subseteq R$ prueba que $\mathfrak{a} \cap Re = \mathfrak{a}e$.
 2) para cada ideal $\mathfrak{A} \subseteq R$ prueba que $\mathfrak{A} \cap Re = \mathfrak{A}e$.
 3) $eRe$ es un anillo y $\mathfrak{A} \mapsto e\mathfrak{A}e$ define una aplicación sobreyectiva que respeta
    el orden del retículo de los ideales de $R$ en el retículo de los ideales de
    $eRe$.
 4) prueba que tenemos un funtor $\text{Mod-}R \to \text{Mod-}eRe$, definido $M \mapsto Me$.
 5) si $M$ es un $R\text{-módulo}$ derecha simple, prueba que $Me = 0$ ó $Me$ es un
    $eRe\text{-módulo}$ derecha simple.
 6) ¿se conservan los $R\text{-módulos}$ derecha proyectivos?
 7) ¿se conservan los $R\text{-módulos}$ izquierda inyectivos?
#+end_statement

***** Punto 1
Sea $x \in \mathfrak{a} \cap Re$, entonces $x = xe \in \mathfrak{a}e$. Sea $ae \in \mathfrak{a}e$, es trivial que $ae \in \mathfrak{a} \cap Re$.

***** Punto 2
Un ideal es un ideal derecha.

***** Punto 3
Se comprueba que $eRe$ es anillo con unidad $e$. El producto de dos elementos
sigue siendo bilineal con $ere \cdot ese = erese$. Si $S \subseteq R$, es claro que $eSe \subseteq eRe$.
Es sobreyectiva porque si $I$ es $eRe\text{-ideal}$, podemos comprobar que $RIR$ es un
$R\text{-ideal}$ y que $eRIRe = eReIeRe = I$.

***** Punto 4
El funtor llevará $f \colon M \to N$ a $\widetilde f \colon Me \to Ne$ definida como

\[\widetilde f(me) = f(m)e.\]

Es funtor por cumplir $\widetilde g \circ \widetilde f (me) = (g \circ f(m))e$.

***** Punto 5
$Me$ sería un submódulo, así que podría ser $Me = 0$ o $Me = M$.
En el segundo caso sería un $eRe\text{-módulo}$ por ser un $R\text{-módulo}$,
y en ese caso, como $M = Me$, se tendría que si hubiera un
submódulo $A$ de $M$ como $eRe\text{-módulo}$, sería de $M$ como $R\text{-módulo}$
por tenerse $AR = ((Ae)R)e = A(eRe) = A$.

***** Punto 6
Si tenemos $P \oplus H \cong R^{(I)}$, multiplicando, $Pe \oplus He \cong (Re)^{(I)}$. Pero
sabemos que $Re \cong eRe$ como $eRe\text{-módulo}$.

***** Punto 7
Si $Q$ es un submódulo izquierda inyectivo, para cualquier $R\text{-módulo}$ $M$
con $Q \leq M$ existe un $Q \leq K$ tal que $K \oplus Q = M$, como producto directo
interno.

Sea ahora un $eRe\text{-módulo}$ $N$ tal que $Qe \leq N$. Tenemos que $Ne = N$ por
ser $e$ unidad del anillo. Como $Q$ es inyectivo, existe un $K$ tal que
$Q \cap K = \left\{ 0 \right\}$ y $Q + K = Q + N$. Si multiplicamos por $e$ tenemos

\[
Qe + Ke = Qe + N = N.
\]

De aquí se tiene que $Ke \cap N = Ke$. Entonces, $Ke \subset K \cap N$ y dado $l \in K \cap N$,
se tiene que como $l \in N$, $le=l$, luego $l \in Ke$. Así, $Ke = K \cap N$, tenemos

\[
Qe + K \cap N = N,
\]

y como $Q \cap K = \left\{ 0 \right\}$, se tiene $Qe \cap K = \left\{ 0 \right\}$ y por tanto $Qe \cap (K\cap N) = \left\{ 0 \right\}$.

**** Semana 9
#+begin_statement
Sea $R$ un anillo y $M$ un $R\text{-módulo}$ derecha. Se considera el anillo $S=M_n(R)$ y
el grupo abeliano $M^n$.

 1) Prueba que $M^n$ es un $S\text{-módulo}$ derecha con acción dada por
    $(m_i)_i(a_{ij})_{ij} = \left( \sum_i m_ia_{ij} \right)_j$.
 2) Prueba que $M \mapsto M^n$, extendiendo para homomorfismos en la forma obvia,
    define un functor $F \colon \text{Mod-}R \to \text{Mod-}S$.
 3) Se considera el idempotente $e_{11} \in M_n(R)$, la matriz que tiene $1$ en el
    lugar $(1,1)$, y $0$ en el resto. Observa que $e_{11}Se_{11} \cong R$. Tenemos entonces un
    funtor $G \colon \text{Mod-}S \to \text{Mod-}e_{11}Se_{11} = \text{Mod-}R$.
 4) Prueba que para cada $R\text{-módulo}$ derecha $M$ se tiene un isomorfismo
    $\theta_M\colon M \cong GF(M)$, y que si $f\colon M_1\to M_2$ es un homomorfismo de $R\text{-módulos}$,
    entonces tenemos un cuadrado conmutativo de homomorfismos de $R\text{-módulos}$.

    \[\begin{tikzcd}
    M_1 \rar{f} \dar[swap]{\theta_{M_1}} & M_2 \dar{\theta_{M_2}} \\
    GF(M_1) \rar{GF(f)} & GF(M_2) 
     \end{tikzcd}\]

 5) Prueba que para cada $S\text{-módulo}$ derecha $N$ se tiene un isomorfismo
    $\nu_N\colon N \cong FG(N)$, y que si $g\colon N_1 \to N_2$ es un homomorfismo de $S\text{-módulos}$,
    entonces tenemos un cuadrado conmutativo de homomorfismos de $S\text{-módulos}$.

    \[\begin{tikzcd}
    N_{1} \rar{g} \dar[swap]{\nu_{N_1}} & N_{2} \dar{\nu_{N_2}} \\
    FG(N_{1}) \rar{FG(g)} & FG(N_{2})
    \end{tikzcd}\]

 6) Prueba que si $M$ es un $R\text{-módulo}$ derecha simple (resp. proyectivo,
    inyectivo), también $F(M)$ lo es.
#+end_statement

***** Punto 1
Comprobaremos que cumple la definición de módulo, es decir,

 * hay una *identidad* dada por $(m_i)_i(\delta_{ij})_{ij} = (m_{j})_{j}$.
 * el *producto* es bilineal
   $(m_i+n_i)_i(a_{ij})_{ij} = (\sum_i (m_i+n_i)a_{ij})_j = (\sum m_ia_{ij} + \sum n_ia_{ij})_j$ y
   $(m_i)_i(a_{ij}+b_{ij})_{ij} = (\sum m_i(a_{ij}+b_{ij}))_j = \sum m_ia_{ij} + \sum m_ib_{ij}$.
 * y es *asociativa* con el producto de matrices usual
   $((m_i)_ia_{ij})(b_{ij}) = (\sum_j (\sum_i m_ia_{ij})b_{jk})_{k} = (\sum_i m_i\sum_{j}a_{ij}b_{jk})_k$.

***** Punto 2
Si los extendemos de forma obvia aplicando el homomorfismo a cada una de las
entradas de la matriz, es obvio que se conserva la composición de funciones
como

\[
g(f((m_{i})_i)) = (gf(m_i))_i,
\]

y que la indentidad se preserva por la extensión.

***** Punto 3
Notamos que podemos llevar cada matriz a su única entrada $e_{11}(r_{ij})e_{11} \mapsto r_{11}$.
La suma es por componentes y por tanto se respeta por la aplicación; el
producto de matrices de una entrada coincide con el producto del anillo.

***** Punto 4
Nótese que $F(M) = M^n$ y que $GF(M) = (M\ 0\ 0\ \dots )$, donde además hay un
isomorfismo $e_{ii}Se_{11} \cong R$. El isomorfismo de módulos lleva $m$ en $(m\ 0\ 0\ \dots)$,
y se comprueba trivialmente que la multiplicación funciona de la misma
manera.

Dado un homomorfismo de módulos, tenemos que $GF(f)$ aplicará el homomorfismo
sobre el único elemento llevando $GF(f)(m\ 0\ 0\ \dots) = (f(m)\ 0\ 0\ \dots)$.

***** Punto 5
Tenemos por ser idempotente que $G(Ne_{11}) = G(N)$, pero 

\[FG(N) \cong FG(Ne_{11}) \cong Ne_{11} \oplus Ne_{22} \oplus \dots \cong N\]

por ser $Ne_{11}\cong Ne_{22}$ como $R\text{-módulos}$ y ser $\left\{ e_{1},\dots,e_{n} \right\}$ un conjunto de
idempotentes centrales.

Una función $g\colon N_1 \to N_2$ está unívocamente determinada por cómo actúa
sobre cada sumando directo, por lo que conmuta su actuación antes y
después de aplicarla explícitamente sobre cada sumando directo.

***** Punto 6
Los dos puntos anteriores han definido dos isomorfismos naturales
que constituyen una equivalencia de categorías.

**** Semana 10
#+begin_statement
Se considera la categoría de grupos abelianos; en este caso $R = \mathbb{Z}$.

 1) Prueba que $\mathbb{Z}$ es un grupo abeliano uniforme. Determina todos los grupos
    cíclicos uniformes.
 2) Prueba que el grupo $\mathbb{Z}_{p^{\infty}}$ es un grupo uniforme y no es un grupo cíclico.
    Se consideran $\mathbb{Q}$ y $\mathbb{R}$; ¿es alguno uniforme?
 3) Determina todos los grupos abelianos inyectivos indescomponibles.
 4) Si $M$ es un grupo abeliano finitamente generado sabemos que 
    $M \cong \left( \bigoplus^t_{i=1} \mathbb{Z}_{p^{n_i}} \right) \oplus \mathbb{Z}^n$, para $n,n_1,\dots,n_t \in \mathbb{N}$. ¿Cuál es la descomposición
    de $E(M)$ como suma de inyectivos indescomponibles?
#+end_statement

***** Punto 1
Dados dos submódulos de $\mathbb{Z}$, que estarán generados por dos enteros, podemos
comprobar que se intersecarán en su mínimo común múltiplo.

***** Punto 2
Para comprobar que el grupo $\mathbb{Z}_{p^{\infty}}$ es uniforme tomamos un módulo no 
nulo que tenga al menos un elemento $a/p^n$ y otro con $b/p^m$; 
para $a,b$ coprimos con $p$.  Existirán $x,y,p$ tales que
$xp a/p^n = 1/p^{n+p} = y b/p^{m}$, por lo que será uniforme.

Comprobamos que $\mathbb{R}$ no es uniforme porque tiene, por ejemplo $(\pi) \cap (1) = 0$.
Sin embargo $\mathbb{Q}$ sí lo es porque si tenemos dos módulos y cada uno contiene
al menos un elemento no nulo $a/b$ y $c/d$; tenemos que $cb \cdot a/b = ad \cdot c/d$.

***** Punto 3
Los inyectivos indescomponibles están en correspondencia con los ideales
primos. Tenemos para $p$ primo que $E(\mathbb{Z}_p) = \mathbb{Z}_{p^{\infty}}$, ya que es extensión esencial
y es inyectivo. Para el ideal primo $\{0\}$ tenemos a su vez que $E(\mathbb{Z}) = \mathbb{Q}$, ya
que es inyectivo y uniforme.

***** Punto 4
Como $\mathbb{Z}$ es noetheriano, tenemos $\bigoplus E(M_i) = E \left( \bigoplus M_i \right)$, así que la suma
debe ser

\[
E(M) = \left( \bigoplus_{i=1}^t \mathbb{Z}_{p^{\infty}} \right) \oplus \mathbb{Q}^n
\]

considerando los sumandos con exponente no nulo.

*** Trabajos
**** Funtores adjuntos
***** Transformaciones naturales
#+begin_definition
Dados dos funtores $S,T : A \to B$, una *transformación natural* $\tau : S \Longrightarrow T$ 
es una función asignando a cada objeto $a \in A$ un morfismo $Sa \to Ta$ y 
cumpliendo el siguiente diagrama conmutativo:

\[\begin{tikzcd}
a \dar{f} & & Sa \rar{\tau_a}\dar{Sf} & Ta \dar{Tf} \\
a' & & Sa' \rar{\tau_{a'}} & Ta'
\end{tikzcd}\]

En este caso, decimos que $\tau_a$ es /natural en/ $a$.
#+end_definition

#+begin_definition
Llamamos *isomorfismo natural* a la transformación natural en la que
cada componente $\tau_a$ tiene una inversa. Podemos definir una transformación
natural inversa $\tau^{-1}$ que tiene por componentes a cada una de las inversas.
#+end_definition

****** Composición vertical de transformaciones naturales
#+begin_definition
Dados funtores $R,S,T : {\cal A} \to {\cal B}$ y transformaciones naturales $\tau : S \Longrightarrow T$
y $\sigma : R \Longrightarrow S$, podemos componerlas componente a componente para formar
una *transformación naturalcomposición vertical* $\tau \circ \sigma$.

\[\begin{tikzcd}
Rc \rar{Rf}\dar{\sigma_c}\arrow[dd,bend right=90] &
Rc' \dar{\sigma_{c'}} \arrow[dd,bend left=90] \\
Sc \rar{Sf} \dar{\tau_c} & Sc' \dar{\tau_{c'}} \\
Tc \rar{Tf} & Tc' 
\end{tikzcd}
\]

#+end_definition

Nótese que la naturalidad se preserva, ya que si los dos cuadrados
pequeños son conmutativos, conmuta todo el diagrama.

****** Composición horizontal de transformaciones naturales
#+begin_definition
Dados funtores $S,T : {\cal A} \longrightarrow {\cal B}$ y $S',T' : {\cal B} \longrightarrow {\cal C}$ y dadas transformaciones
naturales $\tau : S \Longrightarrow T$ y $\tau' : S' \Longrightarrow T'$, podemos crear una transformación
natural entre los funtores compuestos, $\tau' \ast \tau$:

\[\begin{tikzcd}
S'Sx \arrow{rr}{(\tau' \ast \tau)_x} \dar &&
T'Tx \dar \\
S'Sy \arrow{rr}{(\tau' \ast \tau)_y} &&
T'Ty
\end{tikzcd}\]

Cada componente se crea aprovechando la siguiente igualdad:

\[
(\tau' \ast \tau) = T'\tau \circ \tau' = \tau' \circ S'\tau
\]
#+end_definition

Y puede comprobarse que constituye una transformación natural.

****** Categoría de los funtores
#+begin_definition
Dadas ${\cal A},{\cal B}$ categorías, los funtores entre ellas forman una *categoría de funtores* 
que llamaremos $Funct({\cal A},{\cal B})$ y que tiene como morfismos a las transformaciones 
naturales con la composición vertical:

\[
Nat(S,T) = \{ \tau \mid \tau : S \Longrightarrow T \}
\]
#+end_definition

Nótese que la composición es asociativa y que consta de una identidad
en la transformación natural de cada funtor consigo mismo que tiene
como componentes identidades en cada objeto.

***** Definición de funtores adjuntos por naturalidad
#+begin_definition
Una *adjunción* entre categorías ${\cal A}$ y ${\cal B}$ es un par de funtores $F:{\cal A} \to {\cal B}$ y
$G: {\cal B} \to {\cal A}$ con una familia de isomorfismos $\varphi_{a,b} : Hom(Fa,b) \cong Hom(a,Gb)$
que determinan transformaciones naturales en ambas componentes.
#+end_definition

Notamos al par de funtores adjuntos como $F \dashv G$. Llamamos a $F$ adjunto
izquierdo y a $G$ adjunto derecho.

****** Condiciones de naturalidad
Las condiciones de naturalidad de esa familia de isomorfismos equivalen
a que los siguientes diagramas conmuten:

\[\begin{tabular}{cc} \begin{tikzcd}
Hom(Fa,b) \rar{\varphi_{a,b}} \dar[swap]{f_\ast} & 
Hom(a,Gb) \dar{(Gf)_\ast} \\
Hom(Fa,b') \rar{\varphi_{a,b'}} &
Hom(a,Gb')
\end{tikzcd} &
\begin{tikzcd}
Hom(Fa,b) \rar{\varphi_{a,b}} \dar[swap]{(Fg)^\ast} & 
Hom(a,Gb) \dar{g^\ast} \\
Hom(Fa',b) \rar{\varphi_{a,b'}} &
Hom(a',Gb)
\end{tikzcd} \end{tabular}\]

Nótese que cada uno de ellos expresa la naturalidad entre los dos bifuntores
cuando se fija un argumento. Es decir, hay dos isomorfismos naturales

 1) $Hom(F-,b) \Longrightarrow Hom(-,Gb)$.
 2) $Hom(Fa,-) \Longrightarrow Hom(a,G-)$.

***** Definición por unidad y counidad
#+begin_definition 
Una *adjunción* entre categorías ${\cal A}$ y ${\cal B}$ es un par de funtores $F:{\cal A} \to {\cal B}$ y
$G: {\cal B} \to {\cal A}$ con dos transformaciones naturales:

  - La *unidad*:   $\eta : 1_{\cal A} \Longrightarrow GF$
  - La *counidad*: $\epsilon: FG \Longrightarrow 1_{\cal B}$

Cumpliendo que las composiciones siguientes dan la identidad:

 - $F \overset{F \eta} \Longrightarrow FGF \overset{\varepsilon F}\Longrightarrow F$
 - $G \overset{\eta G} \Longrightarrow GFG \overset{G \varepsilon}\Longrightarrow G$
#+end_definition

Demostraremos que esta definición es equivalente a la anterior.

****** Equivalencia de definiciones: desde familia de isomorfismos a unidades
#+begin_theorem
Dada una adjunción en términos de una familia de isomorfismos, podemos
construir una adjunción en términos de unidad y counidad.
#+end_theorem

#+begin_proof
/Paso 1: Construcción de la unidad y la counidad./

Supongamos que tenemos la familia de transformaciones naturales
$\varphi_{a,b} : Hom(Fa,b) \to Hom(a,Gb)$. Particularizaremos los cuadrados de
naturalidad en los dos casos $b = Fa$ y $a = Gb$ para crear la unidad y
la counidad.

\[\begin{tikzcd}
Hom(Fa,Fa) \arrow{d}[swap]{(Ff)^\ast} \arrow{r}{\varphi} & 
Hom(a,GFa) \arrow{d}{(f)^\ast} \\
Hom(Fa', Fa) \arrow{r}{\varphi} &
Hom(a',GFa)
\end{tikzcd}\]

Si tomamos la identidad $1_{Fa}$ y llamamos $\eta_a = \varphi(1_{Fa})$, tenemos que
$\eta \circ f = \varphi(Ff)$ por conmutatividad.

Si damos la vuelta al isomorfismo $\varphi$ para tomar $\varphi^{-1}$, llamarlo de la
misma forma y repetir el mismo proceso:

\[\begin{tikzcd}
Hom(FGb,b) \arrow{d}[swap]{(Ff)^\ast} & 
Hom(Gb,Gb) \arrow{d}{(f)^\ast} \lar[swap]{\varphi} \\
Hom(FGb', b) &
Hom(Gb',Gb) \lar{\varphi}
\end{tikzcd}\]

Nótese que aquí usamos $\varphi$ para notar un isomorfismo y su inversa;
dependerá sólo del contexto determinar cuál estamos usando.
Si tomamos la identidad $1_{Gb}$ y llamamos $\varepsilon_b = \varphi(1_{Gb})$, tenemos que
$\varepsilon \circ Ff = \varphi(f)$.

Aplicamos el mismo proceso al segundo cuadrado natural.

\[\begin{tikzcd}
Hom(Fa,Fa) \arrow{d}[swap]{g_\ast} \arrow{r}{\varphi} & 
Hom(a,GFa) \arrow{d}{(Gg)_\ast} \\
Hom(Fa, Fa') \arrow{r}{\varphi} &
Hom(a,GFa')
\end{tikzcd}\]

Y volvemos a tomar la identidad para tener $\varphi(g) = Gg \circ \eta$. Volviendo a
dar la vuelta a los isomorfismos llegamos a:

\[\begin{tikzcd}
Hom(FGb,b) \arrow{d}[swap]{(g)_\ast} & 
Hom(Gb,Gb) \arrow{d}{(Gg)_\ast} \lar[swap]{\varphi} \\
Hom(FGb,b') &
Hom(Gb,Gb') \lar{\varphi}
\end{tikzcd}\]

Que nos da, tomando la identidad, $\varphi(Gg) = g \circ \varepsilon$.

/Paso 2: Naturalidad de la unidad y la counidad./

Una vez tenemos definidas la unidad y la counidad, podemos comprobar
su naturalidad desde las ecuaciones que hemos obtenido:

\[\begin{aligned}
\eta     \circ f        &= \varphi(Ff) \\
g        \circ \epsilon &= \varphi(Gg) \\
\epsilon \circ Ff       &= \varphi(f) \\
Gg       \circ \eta     &= \varphi(g) \\
\end{aligned}\]

Y la naturalidad de $\eta$ y $\varepsilon$ se deduce desde ahí por la conmutatividad de los
siguientes diagramas, con $\eta \circ f = GFf \circ \eta$ y $g \circ\varepsilon = \varepsilon\circ FGg$:

\[\begin{tabular}{cc}\begin{tikzcd}
GFa  \arrow{r}{GFf} & 
GFb \\
a \arrow{u}[swap]{\eta_X} \arrow{r}[swap]{f} & 
b \arrow{u}{\eta_Y}
\end{tikzcd} & \begin{tikzcd}
FGX \arrow{d}[swap]{\epsilon_X} \arrow{r}{FGg} & FGY \arrow{d}{\epsilon_Y}\\
X \arrow{r}[swap]{g} & Y
\end{tikzcd}\end{tabular}\]

/Paso 3: Comprobar la condición de composición./

Por último tenemos los dos triángulos siguientes, cuya conmutatividad
equivale a la condición de que la composición debía ser la identidad.

\[\begin{tabular}{cc} \begin{tikzcd}
F \arrow{r}{F \eta_X} \arrow{dr}{id} & FGF \arrow{d}{\epsilon_{FX}} \\
 & F
\end{tikzcd} & \begin{tikzcd}
G \arrow{r}{\eta_{GX}} \arrow{dr}{id} & GFG \arrow{d}{G\epsilon_X} \\
 & G
\end{tikzcd}\end{tabular}
\]

Para ello usamos las identidades anteriores comprobando que:

\[\begin{aligned}
\epsilon \circ F\eta &= \varphi(\eta) = 1 \\
G\epsilon \circ \eta &= \varphi(\epsilon) = 1
\end{aligned}\]

$\quad$
#+end_proof

****** Equivalencia de definiciones: desde unidades a familia de isomorfismos
#+begin_theorem
Dada una adjunción en términos de unidad y counidad, podemos construir
una adjunción en términos de familia de isomorfismos.
#+end_theorem

#+begin_proof
/Paso 1: Definición de los isomorfismos./

Por las condiciones sobre la composición de unidad y counidad,
tenemos:

\[\begin{aligned}
\varepsilon \circ F\eta &= 1 \\
G\varepsilon \circ \eta &= 1
\end{aligned}\]

Y por las condiciones de naturalidad de ambas transformaciones, se
tiene:

\[\begin{aligned}
\eta \circ f &= GFf \circ \eta \\
g \circ \varepsilon &= \varepsilon \circ FGg
\end{aligned}\]

Definimos el isomorfismo y su inversa, que seguimos notando igual,
como:

\[\begin{aligned}
\varphi(f) &= \varepsilon \circ Ff \\
\varphi(g) &= Gg \circ \eta
\end{aligned}\]

Se comprueba trivialmente que es isomorfismo por las condiciones
anteriores. Tenemos así las igualdades:

\[\begin{aligned}
\eta     \circ f        &= \varphi(Ff) \\
g        \circ \epsilon &= \varphi(Gg) \\
\epsilon \circ Ff       &= \varphi(f) \\
Gg       \circ \eta     &= \varphi(g) \\
\end{aligned}\]

/Paso 2: Naturalidad de los isomorfismos./

Demostraremos que el isomorfismo es natural en cada una de sus
componentes. La naturalidad aquí se deduce de que la definición
de $\varphi$ nos da las siguientes ecuaciones para cualesquiera $f,g,h$:

\[\begin{aligned}
\varphi(f \circ h)   &= Gf \circ \varphi(h) \\
\varphi(h \circ Fg) &= g \circ \varphi(h)
\end{aligned}\]

Que nos dan la naturalidad de $\varphi$ en ambas componentes.
#+end_proof

***** Unicidad del adjunto
#+begin_theorem
El adjunto es esencialmente único, es decir,
si tenemos funtores $F : {\cal A} \to {\cal B}$ y $G,G' : {\cal B} \to {\cal A}$ y son ambos adjuntos por la
derecha al primero, $F \dashv G, F \dashv G'$; entonces existe un isomorfismo natural
$\tau : G \cong G'$.
#+end_theorem

#+begin_proof
/Paso 1: Definiendo el isomorfismo natural./

Por ser ambas adjunciones, tenemos un isomorfismo natural en ambas
variables $X,Y$ dado por $\varphi : Hom(X,GY) \cong Hom(X,G'Y)$, ya que
ambos eran isomorfos a $Hom(FX,Y)$.

Tomamos para cada $A$, la componente de nuestro isomorfismo natural
en $A$ como $\tau_A = \varphi_A(id_{GA})$.

/Paso 2: Probando la naturalidad./

Aplicamos dos veces la naturalidad de $\varphi$ para tener, dado un
$f : A \to B$:

\[\begin{tabular}{cc}
\begin{tikzcd}
Hom(GA,GA)\rar{\varphi} \dar[swap]{f^\ast} & Hom(GA,G'A) \dar{(Gf)^\ast} \\
Hom(GA,GB)\rar{\varphi} & Hom(GA,G'B)
\end{tikzcd} & \begin{tikzcd}
Hom(GB,GB)\rar{\varphi} \dar[swap]{(Gf)_\ast} & Hom(GB,GB') \dar{(Gf)_\ast} \\
Hom(GA,GB)\rar{\varphi} & Hom(GA,G'B)
\end{tikzcd}\end{tabular}\]

Obtenemos, tomando de la identidad en ambos diagramas, que $\tau \circ Gf = \varphi(Gf)$
y que $G'f \circ \tau = \varphi(Gf)$. Y uniendo ambas igualdades tenemos la condición de
naturalidad de la transformación $\tau$. Por ser la imagen por un isomorfismo 
natural del isomorfismo identidad, todas sus componentes son isomorfismos.
#+end_proof
***** Continuidad
#+begin_theorem
Todo funtor que es un adjunto derecho (equivalentemente, que tiene un
adjunto izquierdo) es *continuo*; es decir, preserva límites
categóricos. Por otro lado, todo functor que es un adjunto izquierdo
es *cocontinuo* y preserva colímites categóricos.
#+end_theorem

#+begin_proof
Sea $a$ el límite de un funtor en la categoría $A$ y sea $G : A \to B$ un
funtor con adjunto a la izquierda $F \dashv G$. Comprobaremos que si existiera
otro cono desde $x$, descompondría de forma única por $Ga$, haciéndolo límite.

\[\begin{tabular}{ccc}\begin{tikzcd}
a \dar[d]\dar[d,shift left=1, bend left]\dar[d,shift right=1, bend right] \\
\dots
\end{tikzcd} &
$\Longrightarrow$
&
\begin{tikzcd}
x
\arrow[in=70, out=290]{dd}
\arrow[bend left, shift left=1]{dd}
\arrow[bend right, shift right=1]{dd} \\
Ga 
\dar[d]\dar[d,shift left=1, bend left]
\dar[d,shift right=1, bend right] \\
G\dots
\end{tikzcd}\end{tabular}\]

Pero entonces, por la adjunción, por cada $x \to Gi$ tenemos un $Fx \to i$, y estas
aplicaciones generan un cono que conmuta con el diagrama por tenerse

\[\begin{tabular}{ccc}\begin{tikzcd}[column sep=0.5em]
& x \dlar[swap]{\alpha}\drar{\beta} & \\
Gi \arrow{rr}{Gf} & & Gj
\end{tikzcd} &
$\Longrightarrow$
&
\begin{tikzcd}[column sep=0.5em]
& Fx \dlar[swap]{\overline{\alpha}}\drar{\overline{\beta}} & \\
i \arrow{rr}{f} & & j
\end{tikzcd}\end{tabular}\]

y por las condiciones de naturalidad de la transformación
$Hom(F-,-) \cong Hom(-,G-)$ tenemos que

\[
\beta = Gf \circ \varphi(\overline{\alpha}) = 
\varphi(f \circ \overline{\alpha}) = \varphi(\overline{\beta})
.\]

Así, como $a$ es límite, tenemos un único $Hom(Fx,a)$ que hace conmutar a los
diagramas. Como sólo existe uno, sólo existe un $Hom(x,Ga)$, lo que conlleva
que sea $Ga$ efectivamente el límite.

El caso de cocontinuidad se obtiene aplicándolo a la categoría dual.
cite:lane78categories
#+end_proof

***** Ejemplos
****** Módulos libres
Un *funtor de olvido* es aquel que proyecta estructuras en una
categoría de estructuras más generales, "olvidando" en el proceso
parte de su estructura. En nuestro caso particular de R-módulos,
tenemos el funtor de olvido que lleva cada módulo a su conjunto
subyacente y cada homomorfismo a su aplicación de conjuntos:

\[
U : R\mathtt{-Mod} \longrightarrow \mathtt{Set}
\]

Sobre cada conjunto puede generarse un R-módulo libre, y cada
aplicación de conjuntos puede extenderse directamente por linealidad
a todo el módulo libre. Esto nos da el *funtor de módulo libre*:

\[
F : \mathtt{Set} \longrightarrow R\mathtt{-mod}
\]

Definido como, 

\[F(S) = <S> \qquad F(f)\left(\sum rx\right) = \sum rf(x)\]

Hay una *adjunción* entre el funtor libre y el funtor de olvido
$F \dashv U$, ya que tenemos la correspondencia natural entre homomorfismos
dada por, para un conjunto $X$ y un R-módulo $M$:

\[
Hom(FX,M) \cong Hom(X,UM)
\]

Que hace corresponder a cada aplicación entre conjuntos su extensión
lineal, que está biunívocamente determinada.

La naturalidad se tiene por tenerse para cada $x \in X$:

\[\begin{aligned}
\varphi(g\circ f)(x) = g(f(x)) =& Ug \circ f(x) \\
\varphi(Ff \circ g)(x) = Ff(g(x)) =& f(\varphi(g)(x))
\end{aligned}\]

****** Otros funtores libres y de olvido
De la misma forma que funciona el funtor de olvido entre
módulos y conjuntos, funciona con otras estructuras algebraicas,
como por ejemplo:

 - Grupos a conjuntos.
 - Grupos abelianos a grupos.
 - K-álgebras a K-módulos.

****** Funtor diagonal
******* Categoría producto
#+begin_definition
Dada una categoría ${\cal C}$ con productos y coproductos ($\mathtt{Set}$, por ejemplo) 
definimos ${\cal C}\times{\cal C}$ como la categoría que tiene como objetos a pares de 
objetos de ${\cal C}$ y morfismos a pares de morfismos que se componen componente
a componente:

\[
(f,g)\circ(h,i) = (f\circ h, g\circ i)
\]
#+end_definition

En la categoría producto, tenemos un *funtor diagonal* $\Delta : {\cal C} \to {\cal C}\times{\cal C}$, que 
lleva cada objeto $A$ a $A\times A$ y cada morfismo $f$ a $(f,f)$.

******* Producto como adjunto derecho
Si definimos el *funtor producto*, $\times : {\cal C}\times{\cal C} \to {\cal C}$, lleva $(A,B)$ en $A\times B$
y cada par de morfismos $f : A \to C$ y $g : B \to D$, en el morfismo producto
x$f \times g : A\times B \to C \times D$, dado por el único que hace conmutar:

\[\begin{tikzcd}
& A\times B \dlar[swap]{\pi}\drar{\pi}\dar[dashed] & \\
A\dar[swap]{f} & C \times D \dlar[swap]{\pi}\drar{\pi} & B\dar{g} \\
C & & D \\
\end{tikzcd}\]

Este funtor es adjunto derecho al funtor diagonal. Nótese que se
tiene:

\[
Hom(\Delta A, (B,C)) \cong Hom(A, B \times C)
\]

Y utilizamos la propiedad universal del producto para llevar dos
morfismos $A \to B$ y $A \to C$ a un morfismo al producto $A \to B \times C$.
Y puede comprobarse la naturalidad.

******* Coproducto como adjunto izquierdo
Si definimos el *funtor coproducto* $\coprod : {\cal C}\times{\cal C} \to {\cal C}$, lleva $(A,B)$ en
$A \coprod B$ y cada par de morfismos $f : A \to C$ y $g : B \to D$, en el morfismo
coproducto, dado por el único que hace conmutar:

\[\begin{tikzcd}
A\dar{f}\drar{i} & & B\dar{g}\dlar[swap]{i} \\
C\drar{i} & A \coprod B \dar[dashed] &D\dlar[swap]{i} \\
& C \coprod D &
\end{tikzcd}\]

Y este funtor es adjunto izquierdo al funtor diagonal. Teniéndose
el isomorfismo siguiente y la naturalidad por la propiedad universal
del coproducto:

\[
Hom\left(A \coprod B, C\right) \cong Hom((A, B), \Delta C)
\]

****** Tensor-Hom
Existe una adjunción entre los funtores *tensor y Hom*. cite:kan58adjoint
Si $R,S$ son dos anillos y fijamos un (R;S)-módulo $X$, tenemos los dos funtores

\[\begin{aligned}
F : \mathtt{Mod-}R \longrightarrow \mathtt{Mod-}S
&\qquad&
F(Y) = Y \otimes_R X\\
G : \mathtt{Mod-}S \longrightarrow \mathtt{Mod-}R
&\qquad&
G(Z) = \mathrm{Hom}(X,Z)
\end{aligned}\]

y tenemos el isomorfismo natural

\[
\mathrm{Hom}_{S}(Y \otimes_{R} X, Z) \cong
\mathrm{Hom}_{R}(Y, \mathrm{Hom}_{S}(X,Z))
\]

dado por $\widehat{f}(y)(x) = f(y \otimes x)$.

bibliographystyle:unsrt
bibliography:math.bib
**** Retículos
**** Módulos libres
# Págs 167 Aluffi -> Definición de módulos libres
# Págs 349 Aluffi -> Clasificación de módulos libres sobre PIDs
# Págs 359 Aluffi -> Endomorfismos de módulos libres

***** Definición de módulo libre
#+begin_definition 
Definimos el *R-módulo libre* cite:aluffi09_rings sobre $A$ como un módulo $F^R(A)$ 
con una inclusión $j : A \to F^R(A)$ como aquel que cumple que para cualquier 
aplicación $f : A \to M$ a un R-módulo, existe un único homomorfismo de 
R-módulos $\varphi:F^R(A) \to M$ que hace conmutar el diagrama

\[\begin{tikzcd}
F^R(A) \rar[dashed]{\exists!\varphi} & M \\
A \uar{j}\urar[swap]{f} &
\end{tikzcd}\]
#+end_definition

Sabemos por ser una propiedad universal que si existe, será único salvo
isomorfías y que $j\colon A \to F^R(A)$ será inyectivo.

****** Construcción
#+begin_definition
Dado un conjunto $A$, definimos la *suma directa indexada* sobre él como
las aplicaciones de soporte finito

\[
N^{\oplus A}
=
\left\{ \alpha\colon A \to N 
\mid 
\alpha(a) \neq 0 \text{ sólo para un número finito de elementos} \right\}
\]

a las que les damos estructura de R-módulo con $(r\alpha)a = r\alpha(a)$.
#+end_definition

Además, existe una inclusión $j\colon A \to R^{\oplus A}$ definida como

\[
j(a)(x) = \left\{\begin{array}{ll} 
1 & \mbox{if } x = a  \\
0 & \mbox{if } x \neq a 
\end{array} 
\right. .
\]

#+begin_theorem
El así definido es el módulo libre sobre $A$. Es decir, $F^R(A) \cong R^{\oplus A}$.
#+end_theorem

#+begin_proof
Nótese que podemos escribir realmente los elementos de esta suma directa
indexada como

\[
\sum_{a \in A} r_aa,
\]

además de forma única y en un número finito de sumandos, uno para cada
elemento en el que la aplicación sea no nula. Esto que nos lleva a que,
una vez definida la imagen de cada elemento $a$, queda definida la imagen
que debe tener $\varphi$ sobre toda el anillo de forma única.
#+end_proof

***** Independencia lineal y bases
#+begin_definition
Decimos que un conjunto indexado $i \colon I \to M$ es *linealmente independiente*
(respectivamente *sistema generador*) si el homomorfismo natural desde su
módulo libre, $\varphi\colon F^{R}(I) \to M$, haciendo conmutar

\[\begin{tikzcd}
F^{R}(I) \rar{\varphi} & M \\
I \uar{j}\urar[swap]{i} &
\end{tikzcd}\]

es inyectivo (respectivamente sobreyectivo). cite:aluffi09_linear
#+end_definition

#+begin_definition
Un conjunto indexado $I \to M$ es una base cuando es linealmente
independiente y genera $M$.
#+end_definition

#+begin_lemma
Un conjunto indexado $B \to M$ es una base si y sólo si el homomorfismo
natural desde su módulo libre es un isomorfismo $R^{\oplus B} \cong M$. Así, un
$R\text{-módulo}$ es libre si y sólo si admite una base.
#+end_lemma

#+begin_proof
Trivial si combinamos las definiciones de linealmente independiente y
sistema generador.
#+end_proof

***** Caso de los espacios vectoriales
#+begin_theorem
Los módulos sobre un cuerpo son necesariamente libres. Podemos
probarlo usando la caracterización anterior por bases. De hecho, dado un
subconjunto de vectores linealmente independientes en un espacio
vectorial, existe una base del espacio conteniéndolos.
#+end_theorem

La noción de dimensión de un espacio vectorial nos permite recuperar
la cardinalidad de la base sobre la que es módulo libre.

***** Clasificación de módulos libres en dominios de integridad
#+begin_theorem
Sea $M$ un $R\text{-módulo}$ libre para $R$ dominio de integridad con
$B$ un conjunto linealmente independiente maximal. Para cualquier $S$
linealmente independiente,

\[ \# S \leq \# B.
\]

En particular, cualesquiera dos conjuntos linealmente independientes
maximales tienen la misma cardinalidad.
#+end_theorem

# Completar la parte de cuerpos de fracciones.
#+begin_proof
Empezamos tomando cuerpos de fracciones y pasamos a considrear el caso
de $R$ un cuerpo y $M$ un espacio vectorial.

Comprobaremos que podemos ir reemplazando elementos de $B$ por
elementos de $S$ sucesivamente para ir creando sucesivos $B'$ y
seguir manteniendo independencia lineal y la maximalidad. Si tomamos
$B' \cup \{v\}$ para algún $v \in S$, por maximalidad tenemos una
dependencia lineal

\[
c_0v + c_1b_1 + \dots + c_tb_t = 0
\]

con $c_0 \neq 0$ para no contravenir la independencia de $B$; además, no sólo
pueden existir elementos no nulos de $S$, porque contravendría su independencia.
Debe existir un $c_1 \neq 0$ con $b_1 \in B' \setminus S$ y podemos intercambiar $b_1$ por $v$
teniendo de nuevo un conjunto linealmente independiente maximal, ya que

\[
v = -c_0^{-1}c_1b_1 - \dots - c_0^{-1}c_tb_t.
\]

Si aplicamos inducción transfinita bajo una buena ordenación de $S$, podemos
asegurar que se llega a un conjunto de cardinalidad $\#B$ que contiene a
los elementos de $S$.
#+end_proof

#+begin_corollary
Para $R$ un dominio de integridad y dos conjuntos $A,B$,

\[
F^R(A) \cong F^R(B) \iff A \cong B.
\]
#+end_corollary

#+begin_corollary
Para $R$ un dominio de integridad se satisface la propiedad IBN

\[
R^m \cong R^n \iff m = n.
\]
#+end_corollary

***** Clasificación de módulos libres en dominios de ideales principales
#+begin_lemma
Sea $R$ un dominio de ideales principales y $F$ un módulo libre finitamente
generado sobre él. Entonces existen $a\in R, x\in F, y\in M$ con $y = ax$ y
$M' \subseteq M,F' \subset F$ con $M' = F' \cap M$ submódulos cumpliendo

\[
F = \left\langle x \right\rangle \oplus F',
\qquad
M = \left\langle y \right\rangle \oplus M'.
\]
#+end_lemma

#+begin_proof
La familia de ideales $\left\{ \varphi \in \mathrm{Hom}(F,R) \mid \varphi(M) \right\}$ es no vacía. Como los PID son
noetherianos, tiene un elemento maximal $\alpha(M) = (a)$, para algún $\alpha(y) = a$.

Dado cualquier $\varphi(y)$, si tomamos el generador $(b) = (a,\varphi(y))$ tenemos que

\[
b = ra + s\varphi(y)
\]

y que si definimos $\psi = r\alpha + s\varphi$, tenemos $b = \psi(y) \in \psi(M)$, luego
$(a) \subseteq (b) \subseteq \psi(M)$, y por maximalidad, $a \mid \varphi(y)$.

Si vemos $y = \left( s_1,\dots,s_n \right)$ como elemento de $F\cong R^{\oplus n}$, tenemos $a \mid \pi_i(y) = s_i$,
así que sabemos $s_i = ar_i$, y definimos

\[
x = \left( r_1,\dots,r_n \right).
\]

Ahora tomamos $F' = \mathrm{ker}(\alpha)$ y comprobamos las sumas directas.
#+end_proof

#+begin_proposition
Sea $R$ un dominio de ideales principales y $F$ un módulo libre finitamente
generado sobre él. Todo submódulo $M \subset F$ será libre.
#+end_proposition

#+begin_proof
Aplicamos el lema anterior a los sucesivos $M^{(i)}$ que genere. Tendremos
que eventualmente $M^{(i)} = 0$, ya que los $y^{(i)}$ son independientes y $F$ es
finitamente generado.
#+end_proof

****** Resoluciones en PIDs
#+begin_proposition
Sea $R$ dominio de integridad. Será dominio de ideales principales si y sólo
si para cualquier epimorfismo a un módulo finitamente generado

\[
R^{m_0} \overset{\pi_0} \longrightarrow M \longrightarrow 0,
\]

existe un módulo libre haciendo exacta la secuencia

\[
0 \longrightarrow 
R^{m_1} \overset{\pi_1} \longrightarrow
R^{m_0} \overset{\pi_0} \longrightarrow
M \longrightarrow
0.\]
#+end_proposition

***** Anillo de endomorfismos
#+begin_proposition
Los endomorfismos de un $R\text{-módulo}$ $F$, $\mathrm{End}(F)$ forman un álgebra con la
composición.
#+end_proposition

****** Semejanza
#+begin_definition
Dos matrices $A,B \in {\cal M}_n(R)$ son *semejantes* si representan el mismo
endomorfismo $F \to F$, diferenciándose en la elección de la base.
#+end_definition

#+begin_proposition
Dos matrices $A,B$ son semejantes si y sólo si

\[
B = PAP^{-1}.
\]
#+end_proposition
# Sacar demostración de página 360.

#+begin_definition
Dos endomorfismos $\alpha,\beta \colon F \to F$ son *semejantes* si existe un
automorfismo $\pi \colon F \to F$ cumpliendo

\[
\beta = \pi \circ \alpha \circ \pi^{-1}.
\] cite:aluffi09_linear
#+end_definition

****** Semejanza y acciones de anillos de polinomios
#+begin_proposition
Una transformación lineal de $F$ es exactamente lo mismo que una estructura
como $R[X]\text{-módulo}$ compatible con la estructura de $R\text{-módulo}$.
#+end_proposition

Si tenemos una transformación lineal $\alpha$, podemos definir la acción de
un polinomio como

\[
\left( r_mt^m + \dots + r_1t + r_0 \right)(v) =
r_{m}\alpha^m(v) + \dots r_1\alpha(v) + r_0v.
\]

Y por la propiedad universal del anillo de polinomios, toda estructura
de $R[t]\text{-módulo}$ quedará determinada por el endomorfismo que asignemos a $t$.

#+begin_lemma
Dadas transformaciones lineales $\alpha,\beta$ de $F$; las estructuras como $R[t]\text{-módulo}$
son isomorfas si y sólo si $\alpha$ y $\beta$ son semejantes.
#+end_lemma
#+begin_proof
Si llamamos $F_{\alpha}$, $F_{\beta}$ a las dos estructuras como $R[t]\text{-módulo}$, tendremos que
un isomorfismo $\pi\colon F_{\alpha}\to F_{\beta}$ será lo mismo que una transformación invertible
$\pi\colon F \to F$ cumpliendo $\beta = \pi\circ\alpha\circ\pi^{-1}$.

Nótese de hecho que un isomorfismo entre módulos debe comportarse como

\[
\pi\circ\alpha (v) = \pi(tv) = t\pi(v) = \beta\circ\pi(v),
\]

por lo que $\pi\circ\alpha = \beta\circ\pi$ es la condición que lo distingue de cualquier
otra transformación lineal.
#+end_proof

#+begin_corollary
Hay una correspondencia biyectiva entre clases de semejanza de transformaciones
lineales de un $R\text{-módulo}$ libre $F$ y clases de isomorfía de estructuras de
$R[t]\text{-módulo}$ en $F$.
#+end_corollary

Nótese que esto se expande a las matrices en el caso finito-dimensional.

***** Proyectividad
#+begin_theorem
Todo módulo libre es proyectivo.
#+end_theorem
#+begin_proof
Supongamos que tenemos un módulo libre $F$ sobre el conjunto $A$. Dado
un epimorfismo $\varphi\colon M \to N$, tendremos la situación siguiente, donde
podemos definir una aplicación de $A$ a $M$ por ser $\varphi$ epimorfismo.
Dado cualquier $\alpha\colon F \to N$ se tiene

\[\begin{tikzcd}
& A\dar{i}\ar{ddl} \\
& F\dar{\alpha}\dlar[dashed] \\
M\rar{\varphi} & N \\
\end{tikzcd}\]

tales que conmutan el triángulo exterior y el superior. Así tenemos
que ambas funciones coinciden sobre la base y por tanto coinciden
para todo el módulo libre.
#+end_proof
***** Referencias
bibliographystyle:unsrt
bibliography:math.bib
**** Categorías abelianas
***** Objeto nulo
#+begin_definition
En una categoría, un *objeto nulo* es aquel que es a la vez inicial y final.
#+end_definition

Nótese que no todas las categorías tienen por qué tener un objeto nulo.
La categoría $\mathtt{Set}$, por ejemplo, tiene objetos inicial y final no isomorfos.

#+begin_definition
En una categoría con objeto nulo llamamos *morfismo cero* entre dos
objetos, $0_{a,b}\colon a \to b$, al que resulta de componer el único morfismo $a \to 0$ con 
el único morfismo $0 \to b$.
#+end_definition

***** Núcleos y conúcleos
#+begin_definition
En una categoría con objeto nulo, el *núcleo* de un morfismo
$f \colon a \to b$ es un morfismo $k \colon \mathrm{ker}(f) \to a$ tal que $f\circ k = 0$ y que es universal 
respecto a esa propiedad; es decir, para cualquier otro $h$ cumpliendo 
que $f \circ h = 0$, se tiene el diagrama

\[\begin{tikzcd}
c \dar[dashed]{\exists! h'}\ar[bend right=90,swap]{dd}{h}\arrow[bend left=45]{ddr}{0} &   \\
\mathrm{ker}(f) \dar{k}\drar{0} &   \\
a\rar{f} & b & .\\
\end{tikzcd}\]
#+end_definition

De otra forma, podríamos definirlo como el *ecualizador* del morfismo $f$ con
el morfismo cero, es decir, como el universal respecto al diagrama

\[\begin{tikzcd} \mathrm{ker}(f) \rar{k} & 
a \rar[bend left]{f}\rar[bend right,swap]{0} & b
\end{tikzcd},\]

y por tanto, es un límite finito y es único salvo isomorfismo. cite:aluffi09_linear

#+begin_definition
En una categoría con objeto nulo, se define el *conúcleo*, $c \colon b \to \mathrm{coker}(f)$
de manera dual al núcleo, como universal según el siguiente diagrama 
conmutativo

\[\begin{tikzcd}
c  &   \\
\mathrm{coker}(f)  \uar[dashed]{\exists! h'} &   \\
a \ar[bend left=90]{uu}{0}\uar{0} \rar{f} & b \ular[swap]{c} \arrow[bend right=45,swap]{uul}{h} \\
\end{tikzcd}\]
#+end_definition

****** Propiedades del núcleo
#+begin_proposition
Cualquier núcleo es un monomorfismo. Dualmente, cualquier conúcleo es
un epimorfismo.
#+end_proposition
#+begin_proof
Si se tienen dos $m,n\colon d \to \mathrm{coker}(f)$, entonces sabemos que $m \circ k$ y $n \circ k$,
por propiedad universal, hacen que exista un único $h \circ k = m\circ k=n\circ k$.
Debe tenerse por tanto $h=m=n$.
#+end_proof

Nótese que el converso no tiene por qué ser cierto. En general, no todo
monomorfismo es núcleo ni todo epimorfismo es conúcleo.

****** Ejemplo: grupos
En la categoría $\mathtt{Grp}$, el objeto cero es el grupo trivial. El núcleo de
cualquier morfismo es lo que llamamos usualmente núcleo, como se puede
comprobar trivialmente. Nótese que todos los núcleos son normales en un 
grupo pero que no todas las inclusiones lo son como subgrupo normal, por 
lo que no todos los monomorfismos serán aquí núcleos.

***** Categorías preaditivas
#+begin_definition
Una *categoría preaditiva* es aquella en la que cada conjunto de morfismos
$\mathrm{hom}(a,b)$ es un grupo abeliano y la composición es bilinear respecto a la
operación de grupo.
#+end_definition

#+begin_proposition
Para un objeto en una categoría preaditiva, $z \in {\cal A}$, equivalen:

  1) $z$ es inicial.
  2) $z$ es final.
  3) $\mathrm{id}_z$ es el elemento neutro de $\mathrm{hom}(z,z)$.
  4) $\mathrm{hom}(z,z)$ es el grupo trivial.
#+end_proposition
#+begin_proof
Si $z$ es inicial o final, se tiene un único $\mathrm{id}_z = 0$, que da el grupo trivial.
Si se tiene $\mathrm{id}_z=0$, entonces para cualquier morfismo $f\colon a \to z$, se tendrá

\[
f = \mathrm{id}_z \circ f = 0\circ f = 0
\]

por la bilinealidad de la composición. Dualmente se verá que es inicial.
#+end_proof

****** Biproductos
#+begin_definition
Un *biproducto* para dos objetos en una categoría preaditiva $a,b \in A$ es un
$c$ con morfismos

\[\begin{tikzcd}
a \rar[bend right,swap]{i_{1}} &
c \rar[bend left]{p_2} \lar[bend right,swap]{p_1} &
b \lar[bend left]{i_2}
\end{tikzcd}\]

cumpliendo las identidades $p_1i_1 = \mathrm{id}_a$, $p_2i_2 = \mathrm{id}_b$, y $i_1p_1 + i_2p_2 = \mathrm{id}_{c}$.
#+end_definition

#+begin_theorem
Dos objetos en una categoría preaditiva $a,b \in A$ tienen producto (o coproducto) 
si y sólo si tienen un biproducto, que será a su vez producto y coproducto.
#+end_theorem

***** Categorías abelianas
#+begin_definition
Una *categoría abeliana* es una categoría preaditiva cumpliendo que

 1) tiene un objeto nulo.
 2) tiene biproductos finitos.
 3) todo morfismo tiene núcleo y conúcleo.
 4) todo monomorfismo es núcleo y todo epimorfismo es conúcleo.
#+end_definition

****** Factorización de un morfismo
#+begin_proposition
En una categoría abeliana, cada morfismo se factoriza como $f = m\circ e$,
donde $m = \mathrm{ker}(\mathrm{coker}(f))$ y $e = \mathrm{coker}(\mathrm{ker}(f))$. 
Además, esta factorización cumple que, dada cualquier otra factorización
de la forma $f' = m'e'$ con $m'$ monomorfismo, $e'$ epimorfismo y con morfismos
de la forma

\[\begin{tikzcd}
\cdot \rar{f}\dar[swap]{g} & \cdot \dar{h} \\
\cdot \rar[swap]{f'} & \cdot &,
\end{tikzcd}\]

existe un único $k$ cumpliendo

\[\begin{tikzcd}
\cdot \arrow[bend left]{rr}{f}\dar[swap]{g} \rar{e}& 
\cdot\rar{m}\dar{k} & \cdot \dar{h} \\
\cdot \arrow[bend right,swap]{rr}{f'} \rar{e'} & \cdot\rar{m'} & \cdot
\end{tikzcd}\]
#+end_proposition
#+begin_proof
Tomamos $m = \ker(\operatorname{coker} f)$. Como $(\operatorname{coker} f)\circ f = 0$, por propiedad universal
del núcleo sabemos que $f$ se escribe como $f = me$ para algún $e$. Como puede
demostrarse que $e$ será epimorfismo, luego $e = \operatorname{coker}(\ker f)$.

Dadas $f=me$ y $f'=m'e'$ con $g,h$ del diagrama, consideramos
$u = \ker f = \ker e$ y entonces tenemos que $0 = hfu = m'e'gu$, luego $e'gu = 0$.
Por ser $u$ núcleo, $e'g$ factoriza en $e = \operatorname{coker}(u)$ como $e'g = ke$ para algún
$k$ que además debe ser único. Así, $m'ke = hme$ y $m'k = hm$, dando la
conmutatividad del diagrama.
#+end_proof

#+begin_definition
La *imagen* y *coimagen* de un morfismo $f = me \colon a \to b$ se definen como

 * $\operatorname{im} f = m$
 * $\operatorname{coim} f = e$
#+end_definition

La proposición anterior se usa para comprobar que son únicas salvo
isomorfismo.

***** Secuencias exactas
****** Exactitud
#+begin_definition
Un par de morfismos componibles es *exacto* en el objeto que comparten
cuando $\operatorname{im} f = \operatorname{ker} g$. Equivalentemente, cuando $\operatorname{coker} f = \operatorname{coim} g$.
#+end_definition

****** Complejos de cadenas
#+begin_definition
En una categoría abeliana, un *complejo de cadenas* es una secuencia

\[\begin{tikzcd}
\dots \rar &
c_{n+1} \rar{\partial_{n+1}} &
c_n \rar{\partial_n} &
c_{n-1} \rar &
\dots
\end{tikzcd}\]

cumpliendo que $\partial_n\partial_{n+1} = 0$.
#+end_definition

****** Secuencias exactas cortas
#+begin_definition
Una *secuencia exacta corta* es un diagrama

\[
0 \longrightarrow
a \overset{f}\longrightarrow
b \overset{g}\longrightarrow
c \longrightarrow
0
\]

que es exacto en $a$,$b$ y $c$.
#+end_definition

#+begin_definition
Un *morfismo de secuencias exactas cortas* está formado por tres morfismos
$f,g,h$ que hacen conmutar el diagrama

\[\begin{tikzcd}
0 \rar& 
\cdot \rar{m}\dar{f}& 
\cdot \rar{e}\dar{g}& 
\cdot \rar\dar{h}& 
0 \\
0 \rar& 
\cdot \rar{m'}& 
\cdot \rar{e'}& 
\cdot \rar& 
0 & .\\
\end{tikzcd}\]

Las secuencias exactas cortas de una categoría abeliana $A$ con estos 
morfismos forman la categoría $\mathtt{Ses}(A)$, que se hace preaditiva sumando
las tres componentes de cada morfismo.
#+end_definition

***** Resultados en categorías abelianas
****** Manipulación elemental en categorías abelianas
#+begin_proposition
Si dados dos morfismos $f,g$ hacia $c$ calculamos su producto fibrado
(/pullback/) tendremos que $f$ epimorfismo nos da $f'$ epimorfismo en

\[\begin{tikzcd}
s\rar{f'} \dar[swap]{g'} & d \dar{g} \\
b\rar{f} & c
\end{tikzcd}\]

donde además, el núcleo de $f$ factoriza como $\mathrm{ker}(f) = g'\circ \mathrm{ker}(f')$.
#+end_proposition
#+begin_proof
El producto fibrado se construye formando la secuencia exacta

\[\begin{tikzcd}
0\rar&s\rar{m}&b\oplus d\rar{fp_1-gp_2}& c
\end{tikzcd}\]

y tomando $g' = p_1m$ y $f'=p_2m$. Probaremos que $fp_1-gp_2$ es un
epimorfismo, para lo que basta comprobar que si $h(fp_1-gp_2) = 0$
entonces

\[
0 = h(fp_1-gp_2)i_1 = hfp_1i_1 = hf,
\]

y por ser epimorfismo $f$, $h = 0$. Ahora probaremos que $f'$ es
epimorfismo; si $uf'=up_2m=0$, por exactitud, es de la forma
$up_2 = u'(fp_1-gp_2)$. Ahora tenemos

\[
0 = up_2i_1 = u'f
\]

llegándose a $u'=0$ por ser $f$ epimorfismo.
#+end_proof

#+begin_definition
Definimos un *miembro* de $a$ como un morfismo con codominio $a$. Existe
una equivalencia $x \equiv y$ entre dos miembros cuando existen epimorfismos
$u,v$ tales que $xu=yv$.
#+end_definition
#+begin_proof
Para demostrar la transitividad de esta relación de equivalencia,
debemos aplicar la proposición anterior al diagrama siguiente,

\[\begin{tikzcd}
\cdot \rar\dar & 
\cdot \rar\dar& 
\cdot \dar{x}\\
\cdot \rar\dar& 
\cdot \rar{y}\dar{y}&
a \\
\cdot \rar{z} &
a &&,\\
\end{tikzcd}\]

donde probamos que si $x \equiv y$ y $y \equiv z$, entonces $x \equiv z$.
#+end_proof

Dado un morfismo $f \colon a \to b$, cada $x \in a$ da lugar a $f \circ x \in b$; y además,
$x \equiv y$ implica $f x \equiv f y$. Gracias a esto, podemos tratar a los miembros
de un objeto en una categoría abeliana de la misma manera de la que
tratamos a los elementos de un conjunto. La aplicación de funciones
se comporta de la misma manera y preserva la relación de equivalencia
de los miembros.

#+begin_proposition
En cualquier categoría abeliana cite:lane78categories

 1) $f \colon a \to b$ es /monomorfismo/ ssi para $x \in a$, $f(x) \equiv 0 \implies x \equiv 0$.
 2) $f \colon a \to b$ es /monomorfismo/ ssi para $x,y \in a$, $f(x) \equiv f(y) \implies x\equiv y$.
 3) $g\colon b \to c$ es /epimorfismo/ ssi para $z\in c$, existe $y \in b$ con $g(y) \equiv z$.
 4) $h\colon r \to s$ es /nulo/ ssi para $x \in r$, $hx \equiv 0$.
 5) $a \overset{f}\to b\overset{g}\to c$ es /exacta/ ssi $gf = 0$ y para cada $g(y)\equiv 0$ existe un
    $x \in a$ tal que $f(x) \equiv v$.
 6) Si existen $g(x) = g(y)$, existe $g(z) = 0$; además cualquier $f(x) \equiv 0$
    implica $f(y) \equiv f(z)$ y cualquier $h(y)\equiv 0$ implica $h(x) \equiv -h(z)$.
#+end_proposition
#+begin_proof
Se tienen (1) y (2) por definición de monomorfismo. Se tiene además
(3) por construcción del producto fibrado y (4) por definición.

Si factorizamos $f = me$, por exactitud se tendrá $\operatorname{ker} g = m$. Si $g y \equiv 0$,
$y \equiv my'$, y si construimos el producto fibrado

\[\begin{tikzcd}
\cdot\dar[dashed]{y''}\rar[dashed]{e'} & \cdot\dar{y'}\drar[bend left=45]{y} \\
\cdot\rar{e} & \cdot\rar{m} & \cdot &,
\end{tikzcd}\]

como $e'$ es epimorfismo, $y \equiv fy''$.

A la inversa, si para $y \in b$ existe $k = \ker g$, entonces $k \in b$ y $gk \equiv 0$.
Existe entonces $x \in a$ con $fx \equiv k$, es decir, $ku \equiv mexv$. Esto lleva
a $\operatorname{im} f \geq \ker g$ y a $gf = 0$, la exactitud.
#+end_proof

****** Lema de los cinco
#+begin_theorem
En un diagrama conmutativo con filas exactas

\[\begin{tikzcd}
a_1 \rar{g_1} \dar{f_1} & 
a_2 \rar{g_2} \dar{f_2} &
a_3 \rar{g_3} \dar{f_3} & 
a_4 \rar{g_4} \dar{f_4} & 
a_5 \dar{f_5} \\
b_1 \rar{h_1} &
b_2 \rar{h_2} &
b_3 \rar{h_3} &
b_4 \rar{h_4} &
b_5 & ,
\end{tikzcd}\]

si $f_2,f_4$ son isomorfismos, $f_1$ es epimorfismo y $f_5$ es monomorfismo, $f_3$ es isomorfismo.
#+end_theorem
#+begin_proof
Usando la manipulación de diagramas cuyas reglas hemos escrito en
la proposición anterior, demostraremos que $f_3$ es monomorfismo.
La dualidad servirá para demostrar a su vez que es epimorfismo.

Explícitamente, si hubiera un elemento en $a_3$ que diera un cero en
$b_3$, habría un cero en $b_4$, por ser isomorfismo, habría un cero en
$a_4$, y entonces existiría, por exactitud, un elemento en $a_2$ cuya
imagen sería el elemento original en $a_3$. Por isomorfismo, este
debería dar un elemento en $b_2$ cuya imagen sería cero, así que
por exactitud existiría un elemento en $b_1$ del que sería imagen.
Como $f_1$ es epimorfismo, existiría un elemento en $a_1$ del que
sería imagen, y entonces el elemento original sería la imagen
por la composición de dos morfismos en secuencia exacta del
primer elemento. Debería ser cero, quedando probado $f_3$ como
monomorfismo.
#+end_proof

****** Lema de la serpiente
#+begin_theorem
Dado un morfismo de secuencias exactas cortas $f,g,h$; existe un morfismo
$\delta \colon \operatorname{ker} h \to \operatorname{coker} f$ tal que la secuencia siguiente es exacta

\[\begin{tikzcd}
0 \rar &
\mathrm{ker}(f) \rar{m} &
\mathrm{ker}(g) \rar{e} &
\mathrm{ker}(h) \arrow[out = 0,in =180,swap]{dll}{\delta} \\&
\mathrm{coker}(f) \rar{m'} &
\mathrm{coker}(g) \rar{e'} &
\mathrm{coker}(h) \rar &
0
\end{tikzcd}\]
#+end_theorem
#+begin_proof
El diagrama extendido que tenemos es

 \[ \begin{tikzcd}
	& 0 \dar              & 0 \dar            & 0 \dar           &   \\
 0 \rar & ker(f) \rar \dar  & ker(g) \rar \dar    & ker(h) \dar \ar[out=355, in=175,looseness=1, overlay, swap]{dddll}{\delta}       &   \\
 0 \rar & a \rar{m} \dar{f}  & b \rar{e} \dar{g} & c \rar \dar{h}        & 0 \\
 0 \rar & a' \rar{m'} \dar & b' \rar{e'} \dar & c' \rar \dar        & 0 \\
	& coker(f) \rar \dar & coker(g) \rar \dar  & coker(h) \rar \dar & 0 \\
	& 0                   & 0                 & 0                &
 \end{tikzcd} \]

y desde él, manipulando de nuevo el diagrama podemos construir primero
el morfismo $\delta$ y demostrar después que efectivamente es exacto.

Explícitamente, lo que haríamos sería tomar un elemento en $\mathrm{ker}(h)$.
Este elemento pasaría a $c$ y luego, como un cero a $c'$. Como $e$ es
sobreyectiva, existiría un elemento en $b$, y luego uno en $b'$ que
haría conmutar el diagrama. Pero como este elemento iría hacia
un cero al aplicar $e'$, debería estar en la imagen de $m'$, así sólo
deberíamos pasar de $a$ a $\mathrm{coker}(f)$ para terminar la construcción de
$\delta$.

Nótese que si el elemento procede de $\mathrm{ker}(g)$, entonces sería nulo en $b'$,
y de ahí sería nulo en $a'$ y en $\mathrm{coker(f)}$; y que la imagen de un
elemento que hubiera llegado desde $\delta$, al pasar a $\mathrm{coker}(g)$ debería ser
$0$ por provenir desde $b$. Esto demuestra la exactitud del diagrama.
#+end_proof

***** Referencias
bibliographystyle:unsrt
bibliography:math.bib

** Análisis funcional
# Exportaba con config.setup

*** 1. Espacios normados
**** Espacios normados
***** Norma y seminorma
*Norma*. Función $\|\cdot\| : X \longrightarrow \mathbb{R}$ verficando:

  - $\|x\| = 0 \Leftrightarrow x = 0$
  - $\|ax\| = |a| \|x\|$
  - $\|x+y\| \leq \|x\|+\|y\|$

****** Seminorma
Cuando $\|x\| = 0$ no implica $x = 0$, se llama *seminorma*. Define
una norma en un espacio cociente.

  - $\|ax\| = |a| \|x\|$
  - $\|x+y\| \leq \|x\|+\|y\|$

****** Sublineal
Cuando además $\|\alpha x\| = \alpha\|x\|$ sólo se cumple para reales positivos, 
se llama funcional *sublineal*.

  - $\|ax\| =  a \|x\|$ para $a \in \mathbb{R}^+$
  - $\|x+y\| \leq \|x\|+\|y\|$

****** Distancia de la norma
Desde la norma se puede definir una *distancia* asociada 
$d(x,y) = \|x-y\|$, que hace a $X$ un *espacio métrico*. La distancia 
cumple:

  - $d(x+a,y+a) = d(x,y)$
  - $d(\lambda a) = |\lambda| d(a)$

****** Topología de la norma
La distancia hace a un espacio normado un *espacio topológico*
con abiertos:

\[\tau = \{G \subset X \;|\; \forall a \in G: \exists r > : B(a,r) \subset G\}\]

Dos normas que generan el mismo espacio topológico son 
*equivalentes*.

****** Equivalencia proporcional
Dos normas $\|.\|$ y $\|.\|_\ast$ generan topologías equivalentes cuando:

\[\exists m,M \in \mathbb{R^+}:\; m \|x\| \leq \|x\|_\ast \leq M \|x\|\]

******* Demostración
Se demuestra por mutua inclusión de bolas.

***** Espacios vectoriales topológicos
Cualquier espacio vectorial sobre $\mathbb{R}$ o $\mathbb{C}$ es normado.

****** Demostración
Dada una base \(\{e_i\}\) del espacio, podemos escribir $x = \sum \alpha_i e_i$ 
y definirla como:

\[ \|x\| = \sum |\alpha_i|\]

La suma es finita por definición de base.

***** Continuidad de la norma, suma y producto
La norma es continua en su espacio por ser lipschitziana:

\[ |\|x\| -  \|y\|| \leq \|x-y\| \]

****** Continuidad de suma y producto
La suma y el producto por escalares son continuos, usando que la
convergencia en el producto equivale a la convergencia por
coordenadas.

****** Continuidad de homotecias y translaciones
Como corolario, lo son las *homotecias* y *translaciones*, todas las
bolas cerradas son homeomorfas a la bola unidad.

***** Operaciones sobre conjuntos
Para $X$ espacio normado:

  1. $A$ abierto $\Rightarrow$ $A+B$ abierto.
  2. $A$ cerrrado, $B$ compacto $\Rightarrow$ $A+B$ cerrado.
  3. $A,B$ compactos $\Rightarrow$ $A+B$ compacto.
  4. $M$ subespacio $\Rightarrow$ $\overline{M}$ subespacio.

****** Demostración de 1
Es la unión de abiertos, $A + B = \bigcup_{b \in B} (b + A)$.

****** Demostración de 2
Sea $x \in \overline{A+B}$, $\exists \{a_n,b_n\} : \{a_n,b_n\} \longrightarrow x$, por compacidad
tenemos $\{b_{\sigma_n}\} \longrightarrow b \in B$ y por tanto $\{a_{\sigma_n}\} \longrightarrow x-b \in A$.

****** Demostración de 3
Se tiene $A\times B$ compacto, y la suma es continua, luego
$A+B$ es compacto.

****** Demostración de 4
Usando la continuidad de la suma y del producto por 
escalares:

\[(+)(\overline{M}\times\overline{M}) 
= (+)\overline{(M\times M)}
\subset \overline{(+)(M \times M)}\]
\[(*)(\mathbb{K}\times\overline{M})
= (*)\overline{(\mathbb{K}\times M)}
\subset \overline{(*)(\mathbb{K} \times M)}\]
      
****** Contraejemplo de suma de cerrados
La suma de dos cerrados puede no ser cerrado:

\[\left\{n + \frac{1}{n} \mid n \in \mathbb{N}\right\} + 
\left\{-n \mid n \in \mathbb{N}\right\} = 
\left\{\frac{1}{n} \mid n \in \mathbb{N}\right\}\]

***** Conexión de espacios normados
Todo espacio normado es *conexo* y *localmente arcoconexo*;
por tanto *arcoconexo*. De hecho, la bola unidad es *convexa*.

***** Espacios de Banach
Un *espacio de Banach* es un espacio normado completo.

**** Desigualdades básicas
***** Desigualdad de Young
Para $a,b\in\mathbb{R}^+$ y $p>1$ con $\frac{1}{p}+\frac{1}{q} = 1$ se tiene:

\[ab \leq \frac{a^p}{p}+\frac{b^q}{q}\]

****** Demostración
Se demuestra aplicando desigualdad de Taylor al logaritmo con 
pesos $1/p$ y $1/q$.

\[\log(ab) = \frac{1}{p}\log(a^p) + \frac{1}{q}\log(b^q) \leq 
\log\left(\frac{a^p}{p} + \frac{b^q}{q}\right)\]

***** Desigualdad de Hölder
Para $a_1\dots a_nb_1\dots b_n \in \mathbb{R}^+_0$ con $\frac{1}{p} +\frac{1}{q} = 1$ se verifica:

\[\sum a_kb_k \leq \left(\sum a_k^p\right)^{1/p}\left(\sum b_k^q\right)^{1/q}\]

****** Demostración
Se demuestra aplicando Young a la división de ambos lados y
cuidando el caso $0$. Llamamos $\alpha = \left(\sum_k a^p_k\right)^{1/p}$, $\beta = \left(\sum_k \beta^q_k\right)^{1/q}$:

\[\frac{a_kb_k}{\alpha\beta}
\leq \frac{a_k^p}{p\alpha^p} + \frac{b_k^q}{q\beta^q}\]

Sumando cada desigualdad tenemos:

\[\frac{1}{\alpha\beta} \sum a_kb_k \leq 
\frac{1}{p\alpha^p}\sum a_k^p +
\frac{1}{q\beta^q}\sum b_k^q = 1\]

***** Desigualdad de Minkowski
Para $a_1\dots a_nb_1\dots b_n \in \mathbb{R}^+_0$, $p>1$, se verifica:

\[\left(\sum_{k=1}^n (a_k+b_k)^p \right)^{1/p} \leq 
\left(\sum_{k=1}^n a_k^p \right)^{1/p} + 
\left(\sum_{k=1}^n b_k^p \right)^{1/p} \]

Dicho de otra forma:

\[\|a+b\|_p \leq \|a\|_p + \|b\|_p\]

****** Demostración
Aplicando Hölder con $p$, $1 - 1/p$ para tener:

\[\begin{aligned}
\left( \sum_{k=1}^n (a_k+b_k)^p \right)^{1/p} 
&=
\left( \sum_{k=1}^n (a_k+b_k)(a_k+b_k)^{p-1} \right)^{1/p}
\\&=
\left( \left( \sum_{k=1}^n a_k^p \right)^{1/p} + \left( \sum_{k=1}^n b_k^p \right)^{1/p} \right)
\left( \sum_{k=1}^n (a_k+b_k)^{\frac{p(p-1)}{p-1}} \right)^{1-1/p}
\end{aligned}\]

**** Ejemplos de espacios normados
***** Espacios de dimensión finita
Solemos notar por ${l}_p^n = (\mathbb{K}^n,\|.\|_p)$ al espacio de Banach sobre $\mathbb{R}^n$ o $\mathbb{C}^n$ 
que da la norma:

\[\|x\|_p = \left(\sum |x_{(k)}|^p \right)^{1/p}\]

Nótese el caso especial $l^n_\infty$ que da la norma del máximo.

****** Normas
Todas estas normas lo son gracias a la [[*Desigualdad de Minkowski][desigualdad de Minkowski]].

****** Equivalencia
Todas las normas son equivalentes y generan el mismo espacio de
Banach:

\[ \|x\|_\infty \leq \|x\|_p \leq \|x\|_1 \leq N \|x\|_\infty\]

******* Demostración
Aplicamos la desigualdad de las medias.

***** Espacios de sucesiones
Las *sucesiones* tales que su p-suma es convergente,
con las normas $\|.\|_p$, dan los siguientes espacios de Banach:

\[\ell_p = \left\{ x : \mathbb{N} \longrightarrow \mathbb{K} \,\middle|\,
\sum_{n=1}^\infty |x(n)|^p < \infty \right\}\]

siendo un caso particular el de la norma del supremo
sobre *sucesiones acotadas*:

\[{\cal \ell}_\infty = \left\{ x : \mathbb{N} \longrightarrow \mathbb{K}\ \left|\ x(n) \text{ acotada} \right\}\]

****** Forman un subespacio vectorial
Pasando la desigualdad de Minkowski al límite, tenemos:

\[\left(\sum^\infty_{k=1} (a_k+b_k)^p \right)^{1/p} \leq 
\left(\sum^\infty_{k=1} a_k^p \right)^{1/p} + 
\left(\sum^\infty_{k=1} b_k^p \right)^{1/p} \]

Por tanto, es un subespacio vectorial y se obtiene una norma
como:

\[\|x\|_p = \left(\sum_{n=1}^\infty |x(n)|^p \right)^{1/p}\]

****** Son espacios de Banach
Como tenemos $|x_n(k)-x_m(k)| \leq \|x_n-x_m\|$, cuando $\{x_n\}$ es 
Cauchy en $\ell_p$, también es Cauchy $\{x_n(k)\}$. Y por tanto, es
convergente por componentes $x(k) = \lim_{n\to\infty}x_n(k)$.

Usamos $\{x_n\}$ de Cauchy para tener:

\[\exists n_0 : \forall m,n\geq n_0 :
\|x_n-x_m\| < \varepsilon\]

Es decir,

\[\sum_{k=1}^N |x_n(k)-x_m(k)|^p \leq (\|x_n-x_m\|_p)^p < \varepsilon^p\]

Tomando $m \to \infty$, y luego tomando $N \to \infty$:

\[\sum_{k=1}^\infty |x_n(k)-x(k)|^p \leq \varepsilon^p\]

Así, tenemos que $x = x_n - (x_n-x) \in \ell_p$, y como $\|x_n-x\|_p \leq \varepsilon$,
tenemos $\{x_n\} \to x$.

***** Subespacios del espacio de sucesiones
El espacio de sucesiones cuenta con subespacios usando la misma 
norma:

****** Sucesiones convergentes
Es un subespacio de $\ell_\infty$ cerrado, y por tanto, de Banach.

\[c = \left\{ x : \mathbb{N} \longrightarrow \mathbb{K}\ 
\left|\ \{x(n)\} \text{ convergente } \right\}\]
 
****** Sucesiones nulas
Otro subespacio de $\ell_\infty$, también cerrado y por tanto, de Banach.

\[c_0 = \left\{ x : \mathbb{N} \longrightarrow \mathbb{K}\ 
\left|\ \{x(n)\} \longrightarrow 0 \right\}\]

****** Sucesiones casi-nulas o de soporte finito
Es un subespacio para todo $\ell_p$.

\[c_{00} = \left\{ x : \mathbb{N} \longrightarrow \mathbb{K}\ 
\left|\ \exists m: \forall n \geq m:\  x(n) = 0 \right\}\]

Este es un subespacio denso ya que toda sucesión es límite de
sucesiones de soporte finito. Pero no es el total, así que no
será completo.

***** Espacios de funciones continuas acotadas
Dado $T$ espacio topológico, tomamos el espacio de funciones
continuas y acotadas:

\[{\cal C}_b(T) = \left\{f : T \longrightarrow \mathbb{K} \mid
f \text{ continua, acotada}\right\}\]

Y lo dotamos de la *norma del supremo*:

\[ \|f\|_\infty = \sup\{ |f(t)| \mid t \in T\}\]

Que da la *convergencia uniforme*.

****** Es espacio de Banach
Si tenemos $\{f_n\}$ de Cauchy, $\{f_n(x)\}$ es de Cauchy y converge a $f(x)$.
Como tenemos algún $n$ para el que $\forall p\geq n: \|f_n-f_p\|_\infty \leq \varepsilon$, entonces:

\[|f_n(x)-f_p(x)| \leq \|f_n-f_p\|_\infty \leq \varepsilon\]

Y tomando límite en $p$ se tiene $|f_n(x) - f(x)| \leq \varepsilon$, luego
$\|f_n-f\|_{\infty} \leq \varepsilon$.

****** Anuladas en infinito
Sea $L$ compacto y separado. Una función se *anula en el infinito*
cuando:

\[\forall \varepsilon: 
\{t\in L \mid |f(t)|\geq\varepsilon\} 
\text{ es compacto}\]

Las funciones continuas que se anulan en el infinito forman 
${\cal C}_0(L)$, subespacio de ${\cal C}_b(L)$. Es espacio cerrado 
y por tanto de Banach.

****** Funciones de soporte compacto
El soporte de $f : L \longrightarrow \mathbb{K}$ para $L$ localmente compacto 
separado es:

\[sop(f) = 
\overline{\{t \in L \mid f(t) \neq 0\}} \subset
L \]

Las funciones con soporte compacto forman ${\cal C}_{00}(L)$, subespacio
vectorial de ${\cal C}_0(L)$.

****** Relación entre ambas
Tenemos que ${\cal C}_{00}(L)$ no es completo en general y que:

\[\overline{{\cal C}_{00}(L)} = {\cal C}_0(L)\]

***** Espacios de funciones derivables
Consideraremos el espacio de funciones sobre un intervalo que sean $d$
veces derivables con derivadas continuas, ${\cal C}^n([a,b],\mathbb{K}^d)$. Escritas:

\[f^{k)} = \left(f^{k)}_1,f^{k)}_2,\dots,f^{k)}_d\right)\]

Sobre él defimos una norma del supremo sobre cada derivada
$\|f^{k)}\| = max \{\|f^{k)}_i\|_\infty\}$. La norma del espacio es la suma de la de 
cada una de las derivadas.

\[ \|f\|_\infty = \sum \|f^{k)}\|_\infty\]

****** Es espacio de Banach
Esto, por el *teorema de la convergencia uniforme* nos lleva a que una
sucesión de Cauchy converja de manera que respete la derivada. Este
será un espacio de Banach.

***** Espacios de funciones integrables
Consideramos el *espacio de funciones p-integrables* como:

\[ L_p(\Omega) =
\left\{ f \in L(\Omega) \;\middle|\; \int_\Omega |f(t)|^p dt < \infty \right\}
\]

Normándolas con:

\[ \|f\|_p =
\left( \int_\Omega |f(t)|^p dt \right)^{1/p}\]

Debemos /identificar funciones que coinciden c.p.d./ para
deducir $\|f\|_p = 0 \Rightarrow f = 0$. Estos espacios son siempre completos.

****** Desigualdades integrales de Hölder y Minkowski
A partir de la desigualdad de Young llegamos
a la *desigualdad integral de Hölder* para funciones
tales que $|f|^p, |g|^p$ son Lebesgue-integrables:

\[\int_\Omega |f(t)g(t)| dt \leq
\left( \int_\Omega |f(t)|^p dt \right)^{1/p}
\left( \int_\Omega |g(t)|^q dt \right)^{1/q}\]

Y desde ella, la *desigualdad integral de Minkowski*:

\[\left( \int_\Omega |f(t) + g(t)|^p dt \right)^{1/p} \leq
\left( \int_\Omega |f(t)|^p dt \right)^{1/p} +
\left( \int_\Omega |g(t)|^p dt \right)^{1/p}\]

Esto nos da la naturaleza de norma.

****** Complitud en el caso real
Usando el Teorema de Riesz-Fisher.

***** Espacios de funciones esencialmente acotadas
Una función es *esencialmente acotada* cuando es $f : [0,1] \longrightarrow \mathbb{K}$:

\[\exists M: |f| \leq M \text{ c.p.d.}\]

Al espacio de funciones esencialmente acotadas lo llamamos ${\cal L}_\infty[0,1]$ y 
le damos una seminorma:

\[\phi_\infty(f) = \inf\{ M
 \mid |f|\leq M \text{ c.p.d.}\}\]

****** Naturaleza de seminorma
Se cumple por un lado que:

\[\phi_\infty(\alpha f) = |\alpha|\phi_\infty(f)\]

Y por otro lado que:

\[ \phi_\infty(f+g) \leq \phi_\infty(f) + \phi_\infty(g) \]

****** Estructura de espacio normado
Podemos convertirlo en espacio normado si tomamos cociente sobre:

\[ N = \{ f \in {\cal L}_\infty[0,1] \mid
\phi_\infty(f)=0 \} \]

Esto es espacio de Banach con la norma $\phi_\infty$.

**** Categoría de espacios normados
***** Homomorfismos topológicos
Los morfismos de la categoría de espacios normados son los
*homomorfismos topológicos*, operadores lineales y continuos que
además son abiertos en su imagen. Hablamos igualmente de
*monomorfismos topológicos*, *epimorfismos topológicos* o de
*isomorfismos topológicos*.

***** Producto de espacios normados
Dados $X_1,\dots,X_n$ espacios normados, podemos definir normas 
sobre su producto cartesiano $\prod X_i$:

 - *Norma del máximo*: $\|x\|_\infty = \max\{\|x_i\|\}$
 - *Norma p*: $\|x\|_p = (\sum \|x_i\|^p)^{1/p}$

****** Topología del producto
La convergencia es trivialmente coordenada a coordenada, y
las topologías asociadas son equivalentes a la topología
producto. El espacio es *Banach* ssi lo son las componentes.

***** Cociente de un espacio normado
Sea $M$ subespacio vectorial cerrado de $X$. Podemos hacer a $X/M$ 
normado con:

\[ \|x+M\| 
= \inf\left\{ \|x - m\| \mid m \in M \right\} 
= d(x,M)\]

****** Topología del cociente
Este espacio es de Banach ssi $X$ es de Banach y $M$ completo. 
La topología coincidirá con la topología cociente.

****** Proyecciones
La proyección $Q: X \longrightarrow X/M$ es lineal, sobreyectiva, abierta
y continua.

**** Operadores y funcionales lineales
***** Operadores lineales continuos
Para $T : X \longrightarrow Y$ lineal entre espacios normados, equivalen:

- $T$ lipschitziana
- $T$ uniformemente continua
- $T$ continua
- $T$ continua en $0$
- $\exists M: \|Tx\| \leq M\|x\|$
- $T$ preserva acotación, $A$ acotado da $TA$ acotado
- $TB_X$ acotado
- $TS_X$ acotado

Y lo llamamos *operador lineal continuo*, $T \in L(X,Y)$.

****** Demostración
******* Lipschitzianidad
La lipschitzianidad implica hasta la continuidad en $0$.

******* Continuidad en 0 implica acotación
Si hay continuidad en $0$ existe $\|x\| < \delta \implies \|Tx\| \leq 1$. Tenemos
entonces:

\[ \left\|\frac{\delta}{\|x\|}x\right\| = \delta \implies
T\left( \frac{\delta}{\|x\|}x \right) \leq 1\]

Luego $\|Tx\| \leq \|x\|/\delta$.

******* Acotación
La acotación implica todo lo demás excepto lipschitzianidad.

******* Acotación de la esfera implica lipschitzianidad.
Como tenemos $\frac{x-y}{\|x-y\|} \in S_X$, lo tenemos acotado por algún $\alpha$ y:

\[T(x-y) \leq \alpha\|x-y\|\]

Por lo tanto, es lispchiztiano.
****** Norma de operadores
Se define la *norma de operadores* como:

\[\begin{aligned}
\|T\| =& \sup_{x \in B_X}\left\{\|Tx\|\right\} \\
=& \sup_{x \in S_X}\left\{\|Tx\|\right\} \\
=& \min\{k \mid \|Tx\| \leq k\|x\| \}
\end{aligned}\]

Y cumple que $\|Tx\| \leq \|T\|\|x\|$.

******* TODO Está bien definida
***** Cuatro teoremas sobre la norma de operadores
Dados $X,Y$ espacios normados:

 1. $(L(X,Y),\|.\|)$ es espacio normado.
 2. $\{T_n\}\longrightarrow T$ ssi $\{T_n\}\longrightarrow T$ uniformemente en $B_X$.
 3. Si $Y$ es de Banach, $L(X,Y)$ es de Banach.
 4. Para $X \overset{T}\longrightarrow Y \overset{S}\longrightarrow Z$, se tiene $\|S \circ T\| \leq \|S\|\|T\|$.

****** Demostración
******* Primer punto
La norma de operadores es norma porque hereda la desigualdad
triangular y la linealidad de la norma del espacio. Nótese
que si $\sup_{x \in B_X} \|Tx\|=0$, es porque $T = 0$.

******* Segundo punto
Nótese que la norma de operadores mide el supremo en la bola
unidad y por homotecias se extiende al espacio.

\[\begin{aligned}
\{T_n\} \longrightarrow T 
&\iff \{\|T_n-T\|\} \longrightarrow 0 
\\&\iff 
\sup_{x \in B_X}\{\|T_n(x) - T(x)\|\} \longrightarrow 0 
\\&\iff 
\sup_{x \in X}\left\{ \left\|T_n\left(\frac{x}{\|x\|}\right) - T\left(\frac{x}{\|x\|}\right) \right\|\right\}
\longrightarrow 0
\end{aligned}\]

******* Tercer punto
Sea $\{T_n\}$ Cauchy. Tenemos $\|T_p(x) - T_q(x)\| \leq \|T_p - T_q\|\|x\|$, por lo que
sabemos $\{T_n(x)\}$ Cauchy; por complitud  $\{T_n(x)\} \longrightarrow T(x)$. Es lineal:

\[T(\alpha x + \beta y) = 
\lim \left( \alpha T_n(x) + \beta T_n(y) \right)
\longrightarrow
\alpha T(x) + \beta T(y)
\]

Tomando límites en la condición de Cauchy, vemos que es acotada
la función $T_p - T$:

\[\|T_p(x) - T(x)\| \leq \varepsilon\]

Luego $T$ es lineal y continua. Y además, $\{T_n\} \longrightarrow T$.

******* Cuarto punto
$\|S \circ T (x)\| \leq \|S\|\|T\|\|x\|$

***** Espacio dual topológico
Sea $X$ normado, su *dual topológico* es el espacio de funciones al
cuerpo con la norma de operadores:

\[ X^\ast = 
L(X,\mathbb{K}) 
= \left\{ f : X \longrightarrow \mathbb{K} \mid
f \text{ lineal y continua} \right\}
\]

***** Extensión desde un subespacio denso
Sea $M$ subespacio denso en $X$, para cada $T \in L(M,Y)$ existe
un $S \in L(X,Y)$ tal que $S|_M = T$ y $\|S\| = \|T\|$

****** Demostración
Podemos extenderla por continuidad, y comprobamos que es lineal:

\[\begin{aligned}
S(\alpha x_n + \beta y_n) = 
T(\alpha x_n + \beta y_n) = 
\alpha Tx_n + \beta Ty_n 
\longrightarrow \alpha Sx_n + \beta Ty_n
\end{aligned}\]

Como la norma es continua y el supremo invariante a clausuras,
hay igualdad entre las normas.

***** Caracterización de operadores abiertos
Sea $T : X\longrightarrow Y$ lineal. Equivalen:

 - $T$ es abierta.
 - $T(B_X)$ es entorno de $0$.

****** Sobreyectividad
Una función lineal y abierta debe ser sobreyectiva ya que la imagen
es subespacio vectorial abierto, y por tanto el total.

****** Demostración
Si es abierta, trivialmente $T(B_X)$ es abierto.

Sea $O \subseteq X$ abierto. Sea $x \in O$, con $B(x,r) \subseteq O$. Como $T(B_X)$ es entorno 
de $0$, tenemos $T(x) + T(B_X)r = T(B(x,r)) \subseteq T(O)$ entorno de $x$, por ser
la translación y homotecia [[*Continuidad de homotecias y translaciones][homeomorfismos]].

***** Caracterización de operadores abiertos sobre la imagen
Sea $T : X \longrightarrow Y$ lineal. Equivalen:

 - $T$ abierta sobre $TX$.
 - $\exists r>0:\quad TX \cap rB_Y \subset TB_X$.
 - $\exists\alpha>0: \forall y\in TX: \exists x\in X: 
  \quad \|x\| \leq \alpha\|y\|$, cumpliendo $Tx = y$.

****** Demostración
Aplicando la caracterización anterior a $TX$ tenemos que
equivalen el primer y segundo apartado.

Por el apartado 2, tengo que dado un $y$, $y\frac{\delta}{\|y\|} \in \delta B_Y$.
Por tanto, $\exists x: Tx = y \frac{\delta}{\|y\|}$. Tomamos $x' = x \frac{\|y\|}{\delta}$, y tenemos
que $T(x') = y$, y además que $\|x'\| = \|x\|\frac{\|y\|}{\delta} \leq \frac{\|y\|}{\delta}$.

***** Descomposición canónica: proyección al cociente
Sea $X$ un espacio normado, $M$ subespacio cerrado y $\pi$ la proyección.
Entonces $\pi \in L(X,X/M)$ es sobreyectiva y abierta, con $\|\pi\| = 1$ cuando
$M \neq X$.

****** Demostración
******* Es continua
Por caracterización de [[*Operadores lineales continuos][operadores lineales continuos]]:

\[ \|\pi(x)\| = \|x+M\| \leq \|x\|\]

******* Tiene norma unidad
Para ver que tiene norma 1, tomamos $x_0 \notin M$.

\[\forall m \in M: \|x+M\| = \|\pi(x+m)\| \leq \|\pi\|\|x+m\|\]

En particular,

\[ \|x+M\| \leq \|\pi\| \inf\{\|x+m\|\} = \|\pi\|\|x+M\| \]

******* Sobreyectiva y abierta
Trivialmente es sobreyectiva. Usamos la caracterización de 
[[*Caracterización de operadores abiertos][operadores abiertos]], comprobando que:

\[\pi^{-1}(B(r,0)) = \{x \in X \mid \|x+m\| < r\} = \bigcup_{m \in M} B(r,m)\]

Por tanto, $B(r,0) \subseteq \pi(B(1,0))$ es un entorno de $0$ por contener un 
abierto.

***** Descomposición canónica: isomorfismo
Sea $T: X\longrightarrow Y$ lineal con $\ker(T)$ cerrado. Se define:

\[\begin{tikzcd}
X \rar[two heads]{\pi} & X/\ker T \rar{\widehat T}[swap]{\cong} & \im T \rar[hook]{i} & Y
\end{tikzcd}\]

Y se tiene:

  - $\hat{T}$ continua ssi $T$ continua. En cuyo caso $\|T\| = \|\hat{T}\|$.
  - $T$ abierta en $TX$ ssi $\hat{T}$ abierta en $TX$.

****** TODO Demostración
**** Teorema de Tychonoff. Dimensión finita
***** Lema a Tychonoff
Toda aplicación lineal desde $\ell_2^n$ es continua.

****** Demostración
Comprobamos que está acotada. Dada una base finita y las coordenadas
sobre ella:

\[
\|Tx\|
=
\left\|\sum_{k=1}^n T(e_k)x_k \right\| 
\leq 
\sum_{k=1}^n |x_k| \|T(e_k)\|
\leq
\|x\| \sum_{k=1}^n \|T(e_k)\|
\]

***** Teorema de Tychonoff
Sea $X$ espacio normado. Toda biyección lineal de $\ell^n_2$ sobre $X$ es 
isomorfismo topológico.

****** Demostración
Por el lema es continua. La esfera de $\ell^n_2$ es compacta; y podemos 
aplicar la caracterización de aplicaciones abiertas anterior.

***** Corolarios al teorema de Tychonoff
Se cumple que:

  1. $T:X\longrightarrow Y$ lineal con $dim(X) < \infty$ nos da $T$ lipschiztiana.
  2. Dos espacios de dimensión finita son isomorfos ssi tienen igual
     dimensión.
  3. En un espacio de dimensión finita, todas las normas son
     equivalentes.
  4. Todo espacio de dimensión finita es Banach.
  5. Todo subespacio de dimensión finita de espacio normado es cerrado.
  6. Un subconjunto de un espacio normado de dimensión finita es
     compacto ssi es cerrado y acotado.

****** Demostración
******* Punto 1
Tenemos $X \cong \ell^n_2 \longrightarrow Y$, [[*Lema a Tychonoff][continua]].

******* TODO Punto 2

***** Dual topológico en dimensión finita
Sea $X$ normado de dimensión finita, su *dual topológico* es:

\[X^\ast =
\left\{ f:X \longrightarrow \mathbb{K} \mid
f \text{ lineal } \right\}\]

****** Demostración
Toda lineal es continua si sale de dimensión finita.

***** Compacidad relativa y precompacidad
Llamamos $A$ *relativamente compacto* cuando $\overline{A}$ es compacto.
Llamamos $A$ *precompacto* cuando, dado un $\varepsilon$, existen $x_1,\dots,x_n$:

\[ A \subset \bigcup_{k=1}^n B(x_n,\varepsilon) \]

****** Cadena de implicaciones
Compacidad implica compacidad relativa, que a su vez implica
precompacidad, que implica acotación.

****** Corolario de Tychonoff de compacidad
En un espacio normado de dimensión finita, un subconjuto es
relativamente compacto ssi es acotado y ssi es precompacto.

***** Corolario de caracterización de continuas
Sea $T : X \longrightarrow Y$ lineal con $TX$ de dimensión finita.
Equivalen:

  1. $T$ es continua.
  2. $\ker T$ cerrado en $X$.

****** Demostración
Cuando $\ker T$ es [[*Descomposición canónica: isomorfismo][cerrado]], $X/\ker T \cong TX$ dimensión finita. $\widehat T$ será
continua.

***** Corolario de caracterización de abiertas
Sea $T : X \longrightarrow Y$ lineal con $X$ de dimensión finita.
Equivalen:

  1. $T$ es abierta.
  2. $T$ es sobreyectiva.

****** Demostración
******* Primera implicación
$TX$ sería abierto y [[*Corolarios al teorema de Tychonoff][cerrado]] a la vez.

******* Segunda implicación
$T$ es continua, luego $\ker T$ [[*Corolario de caracterización de continuas][cerrado]]. $\widehat T : X/\ker T \cong Y$ biyección lineal,
que es por tanto isomorfismo topológico y abierta.

***** Corolario de caracterización de la dimensión finita.
Equivalen:

  1. Todo cerrado y acotado es compacto.
  2. Bola unidad compacta.

**** Teorema de Riesz
***** Lema al teorema de Riesz
Sea $X$ espacio normado con $M$ subespacio propio cerrado. Si
$\varepsilon \in (0,1)$, existe $x \in \mathbb{S}_X$ tal que:

\[ \|x+M\| = d(x,M) > 1-\varepsilon \]

****** Demostración
Sea $x_0 \notin X-M$. Por ser $M$ cerrado $d(x_0,M)>0$. Por ser
el ínfimo, tengo que existe $m_0$ tal que:

\[\frac{1}{1-\varepsilon}\| x_0 - M\| > \| x_0-m_0 \| \]

Por tanto, tomando $x = \frac{x_0-m_0}{\|x_0-m_0\|} \in \mathbb{S}_X$, tenemos:

\[ \| x + M \| 
=  \left\| \frac{x_0-m_0}{\|x_0-m_0\|} + M \right\|
= \frac{\|x_0-M\|}{\|x_0-m_0\|} > 0\]

***** Teorema de Riesz
Son equivalentes:

1. $X$ de dimensión finita.
2. $X$ es localmente compacto.
3. $B_X$ es compacta.
4. $B_X$ es [[*Compacidad relativa y precompacidad][precompacta]].

****** Demostración
1. Cuando la dimensión es finita, $X \cong \mathbb{K}^n$, que es localmente
   compacto.
2. Sea $U$ entorno compacto de $0$, $\exists r>0: \overline{B}(0,r) \subset U$. Por ser un cerrado
   en compacto, es compacto. Por homeomorfismo, lo es $B_X$.
3. Compacidad implica precompacidad.
4. Por ser $B_X$ precompacta,

   \[B_X \subseteq \bigcup B\left(x_i,\frac{1}{2}\right)\]
   
   Como $M = \langle x_1,x_2,\dots,x_k \rangle$ es de dimensión finita, es un subespacio 
   cerrado y propio en $X$. Por el lema de Riesz, existe $x_0 \in \mathbb{S}_X$ 
   tal que:

   \[ \|x_0 - x_i\| \leq d(x_0,M) > \frac{1}{2} \]
   
   Teniendo entonces $x \notin \bigcup B(x_i,\frac{1}{2})$, que nos lleva a 
   contradicción.

*** 2. Principios fundamentales del análisis funcional
**** Teorema de Hahn-Banach
***** Versión analítica de Hahn-Banach
Sea $M \subseteq X$ subespacio con $p$ sublineal y $g : M \longrightarrow \mathbb{K}$ lineal 
verificando:

\[Re(g(m)) \leq p(m)\]

Entonces existe $f : X \longrightarrow \mathbb{K}$ lineal extendiéndolo y verificando:

\[Re(f(x)) \leq p(x)\]

Cuando $p$ es [[*Seminorma][seminorma]], se tiene además que $|f(x)|\leq p(x)$.

****** Demostración
******* Primera extensión en los reales
En un primer caso, sea $\mathbb{K} = \mathbb{R}$. Podemos tomar $x_0 \notin X-M$, 
crear $Y = M\oplus x_0\mathbb{R}$ y extender como:

\[ f(m + \lambda x_0) = g(m) + \lambda\alpha\]

******* Elegir el coeficiente de la extensión
Nos falta elegir el $\alpha$. Sabemos que debe cumplir:

\[\alpha \leq \frac{1}{\lambda}\left( p(m+\lambda x_0) - g(m) \right)\]

Tomando un $\lambda$ positivo y negativo llegamos a dos 
condiciones:

\[ g(v) - p(v-x_0) 
\leq \alpha 
\leq p(u+x_0) - g(u)\]

Y tenemos un $\alpha$ cumpliendo esta condición por ser 
equivalente a:

\[ g(u+v) \leq p(u+v) \leq p(u+x_0) + p(v-x_0)\]

Y lo sacamos partiendo la desigualdad, minimizando
y maximizando cada lado de la desigualdad, y dando
la vuelta a todas las desigualdades:

\[ g(u) - p(v-x_0) \leq \alpha \leq p(u+x_0) - g(u)\]

******* Lema de Zorn
Puedo ordenar las extensiones por inclusión, teniendo
además que una cadena de extensiones tiene por maximal a
la unión de todos los espacios, con la función definida
por el primer conjunto en el que aparece el primer elemento.

Si $Y \neq X$ fuera el maximal, podría añadir $x_0 \in X-Y$ y
contravenir la maximalidad de $Y$ extendiendo una dimensión.

******* Caso complejo
Como todo espacio sobre los complejos lo es sobre los reales,
aplicamos el caso real a $g_0 = Re(g)$, y obtenemos $f_0$ cumpliéndolo
y siendo lineal en los reales.

Creo $f$ siendo lineal en los complejos como:

\[f(x) = f_0(x) - if_0(xi)\]

Que cumple las condiciones

******* Caso de la seminorma
Cuando $p$ es seminorma tengo, para $|\alpha|=1$ dando el giro
apropiado:

\[f(\alpha x) = |f(x)| = Re(f(\alpha x)) \leq p(\alpha x) = p(x)\]

***** Extensión equinórmica de Hahn-Banach
Sea $M \subseteq X$ subespacio vectorial, con $g \in M^\ast$. 
Existe $f\in X^\ast$ tal que $f|_M = g$ y $\|f\| = \|g\|$.

****** Demostración
Sea $p(x) = \|g\|\|x\|$, es una seminorma y cumple $Re(g(m)) \leq p(x)$.
Por *Hahn-Banach*, tenemos una extensión $f$, cumpliendo $\|f\| \geq \|g\|$
por ser extensión y:

\[ \|f\| 
= \sup\left\{ \frac{|f(x)|}{\|x\|} \mid x\in X-\{0\}\right\} 
\leq \|g\|\]

***** Separación en el dual topológico
Sea $x_0 \in X$, entonces existe $f \in \mathbb{S}_{X^\ast}$, tal que $f(x_0) = \|x_0\|$.
En consecuencia:

 1. Si $x \neq y$, existe $f \in X^\ast: f(x) \neq f(y)$.
 2. $\forall x \in X: \|x\| = max_{f \in B_{X^\ast}} \{ |f(x)| \}$

****** Demostración
Podemos aplicar Hahn-Banach a $g : x_0\mathbb{K} \longrightarrow \mathbb{K}$ con $g(\lambda x_0) = \lambda \|x_0\|$,
para obtener una extensión de norma $1$.

****** Corolario 1
Aplicamos el resultado para $f(x-y) = \|x-y\| = 0$.

****** Corolario 2
Tenemos $|f(x)| \leq \|x\|$. El mínimo se alcanza en un $f$ dado por
la proposición.

***** Corolario para subespacios finitos
Sea $X$ un espacio normado $\{x_1,\dots,x_n\} \subseteq X$ linealmente independientes
y $\alpha_1,\dots,\alpha_n \in \mathbb{K}$, entonces existe $f \in X^\ast$ tal que $f(x_i) = \alpha_i$.

****** Demostración
Puedo crear una función lineal, sobre $\langle x_1,\dots,x_n \rangle$ que lo cumpla.
Por venir de dimensión finita será continua, así que podemos
aplicar Hahn-Banach para obtener una extensión.

***** Corolario: L(X,Y) es Banach ssi Y es Banach
El espacio $L(X,Y)$ con la norma de operadores es Banach ssi
el espacio $Y$ es Banach.

****** Demostración
******* Primera implicación
[[*Cuatro teoremas sobre la norma de operadores][Cuatro teoremas sobre la norma de operadores]]

******* Segunda implicación
[[http://math.stackexchange.com/questions/1023681/y-is-a-banach-space-if-bx-y-is-a-banach-space][Y is a Banach space if B(X,Y) is a Banach spacea]]

**** Inyección canónica e isometrías
***** Inyección canónica
Se define $J_X(x_0) : X^\ast \longrightarrow \mathbb{K}$ como:

\[J_X(x_0)(f) = f(x_0)\]

****** La inyección es isométrica
Se verifica:

  1. $\forall x \in S_X: J_X(x)$ es lineal y de módulo $1$.
  2. $J_X : X \longrightarrow X^{\ast\ast}$ es isométrica y lineal.

******* TODO Demostración
***** Completación de un espacio
$X^\ast$ es completo para cualquier espacio normado $X$. Cuando $X$ no es 
completo, $J_X$ no es sobreyectivo y podemos completarlo como:

\[ X \subset \overline{J_X(X)} \]

Que lo será por ser cerrado en $X^{\ast\ast}$, que sí es completo.

***** Polar de un subespacio
Dado $M \subset X$, el *polar* de $M$ se define como:

\[M^0 = \left\{ f\in X^\ast \mid f(M) = \{0\} \right\}\]

****** Definición equivalente
Para la restricción $S : X^\ast \longrightarrow M^\ast$, $M^0 = \ker S$.

***** Primer teorema de isometría
Sea $M \subseteq X$ subespacio, \[\cdot|_M : {X^\ast}/{M^0} \longrightarrow M^\ast \] es biyección lineal 
isométrica.

****** Demostración
Tenemos $\|f|_M\| \leq \|f+M^0\|$, y hay igualdad por extensión 
equinórmica.

***** Segundo teorema de isometría
Sea $M\subseteq X$ subespacio vectorial cerrado. Para $\pi_{X/M}$ proyección, 
$\_ \circ \pi : (X/M)^\ast \longrightarrow M^0$ es una biyección lineal isométrica.

****** Demostración
Claramente es lineal. Tenemos que es lipschitziana por:

\[ \|T(f)\| = \| f \circ \pi \| \leq \|f\|\|\pi\| = \|f\| \]

Y por otro lado,

\[ \|T(f)\|\|x+m\| \geq 
\|T(f)(x+m)\| = 
\|f(x+M)\|\]

Por tanto, $\|T(f)\| \geq \|f\|$.

***** Función de aproximación
Sea $M \subseteq X$ subespacio con $x_0 \in X-\overline{M}$. Existe $f\in X^\ast$ con $\|f\|=1$,
tal que $f \in M^0$ y $f(x_0) = d(x_0,\overline{M}) = d(x_0,M)$.

****** Demostración
Como $\overline{M}$ es subespacio cerrado, tenemos $g \in (X/M)^\ast$ con $\|g\|=1$ y
$g(x_0+\overline{M}) = \|x_0+\overline{M}\|$. Entonces $T(g) \in \overline{M}^0$ y $T(g)(x) = g(x+\overline{M})$.
Tenemos $\|T(g)\|= \|g\|=1$ y $f(x_0) = g(x_0+\overline{M}) = \|x_0+\overline{M}\|$.

***** Clausura desde el polar
Sea $M \subseteq X$ subespacio. Entonces:

\[ \overline{M} = \bigcap_{f \in M^0} \ker(f)\]

***** Distancia a un kernel
Sea $X$ espacio normado, $f \in X^\ast - \{0\}$ y $x_0 \in X$. Entonces,

\[d(x_0,\ker(f)) = \frac{|f(x_0)|}{\|f\|}\]

****** Demostración
Por el [[*Función de aproximación][teorema de aproximación]] con $M = \ker(f)$, tenemos una $g$ con
$\|g\| = 1$ tal que $g(x_0) = d(x_0,M)$; tenemos $\ker(f) \subseteq \ker(g)$.

\[\exists u\in X: f(u)=1\]. Para $x\in X$, tenemos $x -f(x)u \in \ker(f)$ y entonces:

\[ 0 = g(x-f(x)u) = g(x) - f(x)g(u)\]

Aplicando esto en $x_0$ tenemos $g(x_0) = g(u)f(x_0)$, que tomando módulos,
nos da $\|g\| = \|f\| |g(u)|$.

**** Funcional de Minkowski
***** Funcional de Minkowski
Se define $p_U : X \longrightarrow \mathbb{R}^+$ para $U$ entorno de $0$ como:

\[ p_U(x) = \inf\{ \lambda \in \mathbb{R}^+_0 \mid x \in \lambda U\} \]

****** Sublinealidad
Para $U$ convexo, $p_U$ es sublineal.

***** Separación de un punto
Sea $U$ entorno de $0$ convexo con $x_0 \notin U$, existe $f \in X^\ast$ tal que 
$Re(f(x)) \leq 1$ para todo $x \in U$; mientras $Re(f(x_0)) \geq 1$.

Se cumple además:

\[ \{x \in X \mid p_U(x)<1\} \subset
U \subset
\{ x \in X \mid p_U(x) \leq 1\}\]

****** Demostración
Tomamos $g : x_0\mathbb{R} \longrightarrow \mathbb{R}$ definido por $g(\alpha x_0) = \alpha p_U(x_0)$.
Aplicamos [[*Versión analítica de Hahn-Banach][Hahn-Banach]] sobre $x_0\mathbb{R}$ y tenemos un $f$ extensión de $g$
verificando que $f(x_0) = p_U(x_0) \geq 1$, y que para $x \in U$ se tiene 
$f(x) \leq p_U(x) \leq 1$.

Ahora para el caso complejo, tenemos $f_0$ lineal y continuo
cumpliendo que $f_0(x_0)\geq 1$, pero $f_0(x) \leq 1$ para todo $x \in U$.
Definimos $f(x) = f_0(x) - if_0(ix)$, y entonces es lineal en los
complejos cumpliendo lo pedido.

***** Separación de convexos (para un abierto)
Sean $A,B \subset X$ convexos con $A \cap B = \varnothing$ con $A$ abierto. Existe $f \in X^\ast$ 
con $\alpha \in \mathbb{R}$ tal que:

\[ Re(f(a)) < \alpha \leq Re(f(b)) \quad \forall a \in A, b \in B\]

***** Existencia de funcionales de soporte
Sea $X$ normado, $A \subset X$ convexo cerrado con $\mathring{A} \neq \varnothing$. Para cada 
$x_0 \in Fr(A)$; existe $f \in X^\ast$ tal que:

  - $\|f\| = 1$
  - $Re(f(x_0)) = \max\{Re(f(x)) \mid x \in A\}$

****** TODO Demostración

***** Separación de convexos (para un compacto)
Sean $A,B \subset X$ convexos con $A \cap B = \varnothing$ con $A$ compacto y 
$B$ cerrado. Existe $f \in X^\ast$ con $\alpha \in \mathbb{R}$ tal que:

\[ Re(f(a)) < \alpha < Re(f(b)) \quad \forall a \in A, b \in B\]

****** TODO Demostración

**** Lema de categoría de Baire
***** Teorema de Baire
Sea $E$ espacio métrico completo y $G_n \subset E$ abiertos densos.
$\bigcap_{n \in \mathbb{N}} G_n$ es denso.

****** Demostración
Empezando con un abierto $G$ y con $G_1$, puedo a cada paso tomar el 
abierto anterior, tomar un abierto dentro de él como 
$\overline{B}(a_i,r_i) \subset G_i \cap B(a_{i-1},r_{i-1})$, y construir una sucesión $\overline{B}(a_n,r_n)$.

Esta sucesión podemos tomarla para que cumpla $\{r_n\} \to 0$. Desde
aquí tenemos que converge $\{a_n\} \to a \in \bigcap \overline{B}(a_n,r_n) \cap G$ por ser de 
Cauchy.

***** Corolario al teorema de Baire
Sea $E$ espacio métrico completo y $F_n \subset E$ cerrados con:

\[E = \bigcup_{n \in \mathbb{N}} F_n\]

Entonces, $\exists n \in \mathbb{N}$ tal que $\mathring{F}_N \neq \varnothing$.

****** Demostración
Aplicando el teorema de Baire en sus complementos.

***** Dimensión en espacios de Banach
Todo espacio de Banach tiene dimensión finita o no numerable.

****** Demostración
Si fuera $X$ espacio de Banach con base numerable, cualquier
subespacio de dimensión finita sería cerrado, pero entonces,
tomando $F_n = \langle e_1,\dots,e_n \rangle$:

\[ X = \bigcup F_n \]

Luego para algún $n$, se tiene $\mathring{F_n} \neq \varnothing$; así que debe ser 
$X=F_n$.

**** Teorema de la aplicación abierta
***** Teorema de la aplicación abierta
Sean $X,Y$ Banach con $T \in L(X,Y)$ sobreyectiva. 
Entonces $T$ epimorfismo topológico (abierta).

****** Demostración
******* La imagen de bola tiene interior no vacío
Como $X = \bigcup_{n \in \mathbb{N}} n B_X$, tenemos que:

\[ Y 
= T\left(\bigcup_{n \in \mathbb{N}} n B_X \right)
= \bigcup_{n \in \mathbb{N}} n T(B_X) 
\subseteq \bigcup_{n \in \mathbb{N}} \overline{n T(B_X)}
= Y
\]

Aplicando corolario a Baire, $\exists N: \mathring{\overline{NT(B_X)}} \neq \varnothing$, luego
$\mathring{\overline{T(B_X)}} \neq \varnothing$. 

******* La imagen de la bola es entorno de 0
Sea ahora, $y_0 \in \mathring{\overline{T(B_X)}}$, se tendrá que:

\[ 0 \in \mathring{\overline{T(B_X)}} - y_0
\subset \overline{T(B_X)} - \overline{T(B_X)}
\subset 2\overline{T(B_X)}\]

Siendo por tanto $\overline{T(B_X)}$ un entorno de 0.

******* Acotación de la bola
Tenemos $\exists\delta > 0: \delta B_Y \subset \overline{T(B_X)}$, y en general:

\[ \forall n \in \mathbb{N}: \frac{\delta}{2^n}B_Y \subseteq \overline{T\left(\frac{1}{2^n}B_X\right)}\]

******* Sucesión
Tomamos $x_0 = 0$, $y \in \overline{T(\frac{1}{2}B_X)}$, y construimos sabiendo:

\[ y - T(x_i) \in
\frac{\delta}{2^i} B_Y \subseteq
T\left(\frac{1}{2^i} B_X\right)\]

Luego existe un $x_{i+1}$ verificando $\|x_{i+1}\|\leq \frac{1}{2^{i+1}}$ y que:

\[ \left\| y - \sum_{k=1}^{i+1} T(x_k) \right\| < \frac{\delta}{2^{i+2}} \]

******* La suma converge
Definimos la suma de la sucesión:

\[ S_n = \sum_{k=1}^n x_k \in X\]

Es de Cauchy por ser convergente $\sum_{n=1}^\infty \frac{1}{2^n}$. Por complitud,
converge, $S_n \to x$, con:

\[ \|S_n\| \leq \sum \|x_k\| \leq \sum \frac{1}{2^n} = 1 \]

Luego $\|x\| \leq 1$, $x \in B_X$. Como además se tiene:

\[\| y - T(S_n) \| \leq  
\|y - \sum T(x_k) \| < 
\frac{\delta}{2^{n+1}} \]

Tenemos $\lim\{T(S_n)\} = T(x)$ y concluimos $y \in T(B_X)$.

******* Conclusión
Hemos probado $\overline{T(\frac{1}{2} B_X)} \subseteq T(B_X)$, y finalmente,

\[ \frac{\delta}{2} B_Y \subset \overline{T\left(\frac{1}{2} B_X\right)} \subset T(B_X)\]

Así que $T(B_X)$ es un entorno de $0$ y $T$ es abierta.

***** Teorema de los isomorfismos de Banach
Sean $X,Y$ Banach con $T \in L(X,Y)$ biyectiva.
Entonces $T$ es isomorfismo topológico.

****** Demostración
Por [[*Teorema de la aplicación abierta][teorema de la aplicación abierta]] $T$ y $T^{-1}$ son abiertas;
luego $T^{-1}$ y $T$ son continuas.

***** Teorema del homomorfismo de Banach
Sean $X,Y$ espacios de Banach con $T \in L(X,Y)$. Será homomorfismo 
topológico ssi $TX$ es cerrado en $Y$.

****** TODO Demostración
***** Equivalencia de normas en espacios de Banach
Sean $\|\cdot\|_1, \|\cdot\|_2$ dos normas en un espacio de Banach. Si cumplen que:

\[\exists M>0 : \|x\|_1 \leq M \|x\|_2\]

Entonces son equivalentes.

****** Demostración
Sea $T(x)=x$ biyección lineal entre las dos normas. Es lipschitziana
por la condición. Por el [[*Teorema de los isomorfismos de Banach][teorema de los isomorfismos de Banach]], es 
isomorfismo topológico.

**** Teorema de la gráfica cerrada
***** Gráfica de una función
La *gráfica* de una función $f$ se define como:

\[ Graf(f) = 
\{(x,f(x)) \mid x \in A\} \subseteq
A \times B\]

Una $T$ es lineal ssi $Graf(T)$ es subespacio vectorial, y
cuando $f$ es continua en Hausdorff, $Graf(f)$ es cerrada.

***** Teorema de la gráfica cerrada
Sean $X,Y$ Banach con $T : X \longrightarrow Y$ lineal. Si la gráfica 
de $T$ es cerrada, $T$ es continua.

****** Demostración
Si tomamos $\|x+y\| = \|x\|+\|y\|$, que genera la topología
producto en $X \times Y$, tenemos un Banach. Como $T$ es lineal,
$G(T)$ es subespacio lineal de $X \times Y$, y como $G(T)$ es cerrado,
es de Banach con la norma inducida.

Sea $\Phi : GT \longrightarrow X$ definida por:

\[ \Phi(x,Tx) = x\]

Como $\Phi$ es lineal, su restricción es continua, lineal y biyectiva.
Por [[*Teorema de los isomorfismos de Banach][teorema de isomorfismo de Banach]], $\Phi^{-1}$ es continua; y entonces
$T = \pi_2 \circ \Phi^{-1}$ es continua.

***** Caracterización de la gráfica cerrada en espacios normados
Sean $X,Y$ normados con $T: X \longrightarrow Y$ lineal. Equivalen:

- $T$ con gráfica cerrada.
- Si $\{x_n\} \longrightarrow 0$ y $\{Tx_n\}\longrightarrow y$; entonces $y=0$. Cuasicontinuidad en 0.

****** TODO Demostración

**** Teorema de Banach-Steinhaus
***** Teorema de Banach-Steinhaus para funcionales
Sea ${\cal A} \subset L(X,Y)$ para $X$ de Banach e $Y$ normado; una familia de 
operadores acotada puntualmente:

\[ \forall x : \exists M(x): \forall T \in A: \quad \|T(x)\| \leq M(x)\]

Entonces está acotada:

\[\exists M : \forall T \in A: \quad \|T\| \leq M \]

****** Demostración
Tomamos $F_n$ como intersección de conjuntos que son cerrados
por la continuidad de $T$:

\[F_n = \bigcap_{T \in {\cal A}} \{ x \in X \mid \|Tx\| \leq n\}\]

Como está acotada puntualmente, $\bigcup F_n = X$; así que aplicamos
el [[*Corolario al teorema de Baire][corolario a Baire]] para tener un $\mathring{F_N} \neq \varnothing$. Eso quiere decir
que $\exists a: \exists r: a + rB_X \subseteq F_n$. Para $T \in {\cal A}$ se tiene:

\[\begin{aligned}
\|Tx\| =& \frac{1}{r} \| T(a+rx) - Ta\| \\
\leq& \frac{1}{r} (\| T(a+rx) \| + \|Ta\|) \\
\leq& \frac{N}{r} + \|Ta\|\frac{1}{r} \\ 
\leq& \frac{N}{r} + M(a)\frac{1}{r}
\end{aligned}\]

Acotación independiente de $X$.

***** Teorema del cierre de Steinhaus
Sea $X$ de Banach, $Y$ normado, y una sucesión $\{T_n\} \in L(X,Y)$ 
convergiendo puntualmente. La convergencia puntual da un operador 
lineal y continuo:

\[ T(x) = \lim_{n \longrightarrow \infty} T_n(x) \in L(X,Y)\]

****** Demostración
La linealidad se tiene trivialmente:

\[ T(\alpha x_1 + \beta x_2) 
= \lim T_n (\alpha x_1 + \beta x_2)
= \alpha T(x_1) + \beta T(x_2) \]

Como $\{T_n\}$ es una familia acotada puntualmente por converger
puntualmente, se tiene por [[*Teorema de Banach-Steinhaus para funcionales][Banach-Steinhaus]] que está acotada.

Entonces para $x \in B_X$, tenemos $\|T_n(x)\| \leq M$, así que:

\[ \|\lim T_n(x)\| =
\lim \|T_n(x)\| \leq M\]

Luego $\|T(x)\| \leq M$, y por estar acotada en la bola unidad
y ser lineal, $T$ es continua.

***** Corolario a Banach-Steinhaus para el dual
Sea $X$ espacio de Banach y $A \subseteq X^\ast$, equivalen:

1. $A$ acotado, $\exists M>0: \forall f \in A: \|f\| \leq M$
2. $A$ puntualmente acotado, $\forall x\in X: \{f(x) \mid f \in A\}$ acotado.

****** Demostración
Por [[*Teorema de Banach-Steinhaus para funcionales][teorema Banach-Steinhaus]] con $X^\ast = L(X,\mathbb{K})$ se tiene
la segunda implicación. La primera se tiene simplemente por
tenerse:

\[ \|f(x)\| \leq \|f\|\|x\| \leq M \|x\| \]

***** Corolario a Banach-Steinhaus para el doble dual
Sea $X$ espacio normado con $A \subseteq X$. Equivalen:

1. $A$ acotado.
2. $\{ f(x) \mid x \in A\}$ acotado para cualquier $f \in X^\ast$.

****** Demostración
Sabemos $J_X$ isometría, luego $J_X(A)$ está acotado. Como 
la acotación equivale a la acotación puntual, para cualquier
punto del espacio $f \in X^\ast$ se tiene acotado:

\[ \{J_X(x)(f) \mid x \in A \} \]

*** 3. Espacios de Hilbert I
**** Espacios prehilbertianos
***** Producto escalar
Sea $H$ un K-espacio vectorial. Un producto escalar es: $\langle \cdot,\cdot\rangle : H \times H \longrightarrow \mathbb{K}$
cumpliendo:

  1. $\langle \alpha u + \beta v, w\rangle = \alpha\langle u,w \rangle + \beta\langle v,w \rangle$, lineal en la primera variable.
  2. $\langle u,\alpha v + \beta w\rangle = \overline{\alpha}\langle u,v\rangle + \overline{\beta}\langle u,w\rangle$, conjugadalineal en la segunda variable.
  3. $\langle u,v \rangle = \overline{\langle v,u \rangle}$, hermítica.
  4. $\langle u,u \rangle \geq 0$, definida positiva.
  5. $\langle u,u \rangle = 0$ ssi $u=0$, no nula.

****** Observaciones
Cuando $\mathbb{K}=\mathbb{R}$, 3 es conmutatividad; cuando $\mathbb{K}=\mathbb{C}$, implica que 4 está 
bien definido por ser $\langle u,u \rangle$ real.

***** Espacio prehilbertiano
Llamamos espacio prehilbertiano a un espacio vectorial dotado de un 
producto escalar.

***** Ejemplos de espacios prehilbertianos
****** Espacio euclídeo complejo
Para el espacio $\mathbb{C}^n$:

\[\langle (x_1,\dots,x_n), (y_1,\dots,y_n) \rangle =
\sum_{i=0}^n x_i\overline{y_i} \]

****** Espacio de sucesiones
Para el espacio $\ell^2$, de sucesiones de cuadrado sumable:

\[\langle \{x_i\},\{y_i\} \rangle = \sum^\infty_{n=0} x_n\overline{y_n}\]

Nótese que es sumable por tenerse $2|x_n||y_n| \leq |x_n|^2+|y_n|^2$.

****** Espacio de funciones continuas
Para ${\cal C}([0,1],\mathbb{K})$ funciones continuas:

\[
\langle f,g \rangle = \int_{[0,1]} f\overline{g}
\]

****** Espacio de funciones de cuadrado integrable
Para funciones de cuadrado integrable $L^2(\mu)$, tenemos:

\[\langle f,g \rangle = \int_\Omega f\overline{g} \;d\mu\]

Donde por Hölder tenemos la integrabilidad:

\[
\int_\Omega |f\overline{g}| \;d\mu \leq
\sqrt{
\int_\Omega |f|^2 d\mu
}
\sqrt{
\int_\Omega |g|^2 d\mu
}
\]

***** Desigualdad de Cauchy-Schwarz
Para $H$ prehilbertiano, si notamos $\|u\| = \sqrt{\langle u,u \rangle}$,

\[ |\langle u,v \rangle| \leq \|u\|\|v\|
\]

Con caso de igualdad $u = v$.

****** Demostración
Elevando al cuadrado los dos números positivos:

\[\begin{aligned}
0 
&\leq 
\|u\|^2\|v\|^2 - 2|\langle u,v \rangle|^2  + |\langle u,v \rangle|^2
\\ 0 &\leq
\|v\|^2 - \frac{2|\langle u,v \rangle|^2}{\|u\|^2}  + \frac{|\langle u,v \rangle|^2}{\|u\|^2}
\\ 0 &\leq
\left\langle 
\frac{\overline{\langle u,v \rangle}}{\|u\|^2}u + v,
\frac{\overline{\langle u,v \rangle}}{\|u\|^2}u + v
\right\rangle
\end{aligned}\]

***** Desigualdad de Minkowski
Para $H$ prehilbertiano, si notamos $\|u\| = \sqrt{\langle u,u \rangle}$,

\[
\| u + v \| \leq \|u\| + \|v\|
\]

****** Demostración
Desarrollando llegamos a $\langle u,v \rangle + \langle v,u \rangle \leq 2\|u\|\|v\|$, que es cierto por:

\[
\langle u,v \rangle + \langle v,u \rangle \leq
2Re(\langle u,v \rangle) \leq 
2|\langle u,v \rangle| \leq
2 \|u\|\|v\|
\]

Aplicando Cauchy-Schwarz en la última desigualdad.

***** Espacio prehilbertiano es normado
Todo espacio prehilbertiano es normado con norma:

\[
\| u \| = \sqrt{\langle u,u \rangle}
\]

****** Cumple propiedades de la norma
Tenemos trivialmente:

  1. $\|u\| = 0 \iff u =0$
  2. $\|\alpha u\| = |\alpha| \|u\|$
  3. $\|u+v\| \leq \|u\|+\|v\|$

Donde la última se deduce de la desigualdad de Minkowski.

***** El producto escalar es continuo
En un espacio prehilbertiano:

\[\{u_n\} \longrightarrow u, \{v_n\} \longrightarrow v 
\implies
\{ \langle u_n, v_n \rangle\} \longrightarrow \langle u,v \rangle\]

****** Demostración
Se tiene:

\[\begin{aligned} |\langle u_n,v_n \rangle - \langle u,v \rangle| 
&\leq |\langle u_n-u,v \rangle| + |\langle u,v_n-v \rangle| \\
&\leq \|u_n-u\|\|v\| + \|u\|\|v_n-v\| \longrightarrow 0
\end{aligned}\]

**** Identidades de polarización
***** Identidades de polarización
Sea $H$ prehilbertiano:

  1. $\langle u,v \rangle = \frac{1}{4}\left( \|u+v\|^2 - \|u-v\|^2 \right)$, cuando $\mathbb{K} = \mathbb{R}$.
  2. $\langle u,v \rangle = \frac{1}{4}\left( \|u+v\|^2 - \|u-v\|^2 \right) + \frac{i}{4}\left( \|u+iv\|^2 - \|u-iv\|^2 \right)$, cuando $\mathbb{K} = \mathbb{C}$.

****** Demostración
La segunda es trivial calculando y la primera es un caso particular.

***** Identidad del paralelogramo
Sea $H$ normado, es prehilbertiano ssi se verifica:

\[
\|u+v\|^2 + \|u-v\|^2 = 2\left( \|u\|^2 + \|v\|^2\right)
\]

Con el producto escalar dado por la [[*Identidades de polarización][identidad de polarización]]:

\[ \langle u,v\rangle = 
\frac{1}{4}\left(\|u+v\|^2-\|u-v\|^2 \right) +
\frac{i}{4}\left(\|u+iv\|^2-\|u-iv\|^2 \right)
\]

****** Demostración
Cuando es prehilbertiano, se verifica la ecuación trivialmente.
Cuando se verifica la ecuación, podemos ver que la identidad de 
polarización nos da un producto escalar que es conjugadolineal,
hermítico, definido positivo y no nulo.

# ¿En cuál de estas comprobaciones se usa paralelogramo?
# Parecen largas de comprobar.

***** Ejemplos de normados prehilbertianos
****** Contraejemplo: funciones continuas con el máximo
El espacio ${\cal C}[0,1]$ con la norma del máximo no es prehilbertiano.
Hay un contraejemplo a la identidad del paralelogramo en $f(t) = 1$ y
$g(t) = t$.

****** Espacio de sucesiones de cuadrado sumable
El espacio $\ell_p$ es prehilbertiano ssi $p=2$, con:

\[\|x\| = \left(\sum_{i=1}^\infty |x_n|^2 \right)^{1/2}\]

******* Demostración
Se cumple que:

\[
\sum_{n=1}^k |a_n + b_n|^2 + \sum_{n=1}^k |a_n-b_n|^2
= 2\left(\sum_{n=1}^k |a_n|^2+|b_n|^2\right)
\]

Y tomando límites tenemos lo pedido.

**** Espacios de Hilbert
***** Espacios de Hilbert
Un espacio prehibertiano completo es un espacio de Hilbert.
Equivalentemente, un espacio de Banach con norma asociada a un producto
escalar.

***** Hilbert de dimensión finita
Todo prehilbertiano de dimensión finita es Hilbert.

****** Demostración
Todo espacio normado de dimensión finita es de Banach.

***** Compleción de prehilbertianos
La completación de un espacio prehilbertiano es espacio de Hilbert.

****** Demostración
La [[*Completación de un espacio][completación]] restringida al espacio orginal tiene su norma. Y la
norma es [[*Continuidad de la norma, suma y producto][continua]]. Por tanto, será prehilbertiano al cumplir la
[[*Identidad del paralelogramo][identidad del paralelogramo]]:

\[
\lim_{n \to \infty} \|u_n+v_n\|^2 + \|u_n-v_n\|^2
=
2\left(\|\lim_{n \to \infty} u_n\|^2+\|\lim_{n \to \infty} v_n\|^2\right)
\]

**** Ortogonalidad
***** Ley de los cosenos
La ley de los cosenos puede reinterpretarse como una definición del
ángulo para espacios distintos de $\mathbb{R}^2$.

\[
cos(\theta) = \frac{\langle u,v \rangle}{\|u\|\|v\|}
\]

***** Ortogonalidad
Dos vectores se dicen *ortogonales* $u \perp v$ cuando su producto escalar 
es nulo:

\[\langle u,v \rangle = 0\]

***** Espacio ortogonal
Para $H$ hilbertiano, $S \subseteq H$; definimos el ortogonal de $S$ como:

\[
S^\perp = \left\{
u \in H \mid \forall s \in S: u \perp s
\right\}
\]

***** Propiedades del espacio ortogonal
Para $0 \subset S \subset H$, tenemos:

  1. $0 \in S^\perp$.
  2. $S \cap S^\perp \subseteq \{0\}$.
  3. $\{0\}^\perp = H$, $H^\perp = \{0\}$.
  4. $S_1 \subseteq S_2 \implies S_1^\perp \supseteq S_2^\perp$.
  5. $S^\perp$ es subespacio vectorial cerrado.
  6. $S \subseteq S^{\perp\perp}$.
 
****** Demostración
Triviales. La quinta se tiene por núcleo de una función lineal y
continua.

***** Suma directa
Sea $X$ normado con $M,N$ subespacios. Se dice que hay suma directa
$X = M \oplus N$, cuando:

  1. $X = M + N$
  2. $M \cap N = \{0\}$

***** Suma directa topológica
Se dice que hay suma directa topológica cuando $M \oplus N$ cumplen que
$x_n = m_n + n_n$ respeta la convergencia $x = m + n$ con $m \in M, n \in N$.

****** Suma directa topológica en Banach
En un espacio de Banach, la suma directa es topológica cuando
ambos espacios $M,N$ son cerrados.

***** Lema de aproximación óptima
Sea $S$ un cerrado y convexo de $H$ prehilbertiano. Hay un sólo elemento
en el conjunto que realiza la mínima norma.

\[\exists! s_0 \in S:\quad \|s_0\| = \min\{\|s\| \mid s\in S\}\]

****** Demostración
******* Existencia
Sea $t$ el ínfimo. Por convexidad tenemos: $\|\frac{1}{2}(u+v)\| \geq t$. Dada una
sucesión $\{\|s_n\|\} \longrightarrow t$; vemos que es de Cauchy:

\[\begin{aligned}
\|s_n-s_m\|^2 &\leq \|s_n+s_m\|^2 + \|s_n-s_m\|^2 - 4t^2 \\&=
2(\|s_n\|^2 -t^2) + 2(\|s_m\|^2 - t^2) \longrightarrow 0
\]

Luego converge en el cerrado.

******* Unicidad
Si hubiese dos mínimos, se tendría:

\[
\|s+s'\|^2 + \|s-s'\|^2 = 2\left(\|s\|^2 + \|s'\|^2 \right) 
= 4t^2 \leq \|s+s'\|^2
\]

Por lo que $\|s-s'\| = 0$.

***** Teorema de la aproximación óptima
Sea $H$ Hilbert, $M \subseteq H$ subespacio cerrado y $u \in H$. Entonces, existe 
una única mejor aproximación a $M$, esto es:

\[\exists! \pi_M(u) \in M:\quad d(u, \pi_M(u)) = d(u,M) \]

****** Demostración
Aplicaremos el [[*Lema de aproximación óptima][lema de aproximación óptima]] a $u+M$. Tenemos que probar
que es convexo, y para ello:

\[\lambda (u+m) + (1-\lambda)(u+m') = u + m\lambda + m'(1-\lambda) \in u+M\]

Sea $s_0 \in u+M$ la mínima norma en $u+M$:

\[ \|s_0\| = \min\{\| u + m \| \mid m \in M\}\]

Tomamos $\pi_M(u) = u - s$, y tenemos:

\[ \| u - \pi_M(u)\| = \|s \| \leq \|u + m\|\]

La unicidad la da la unicidad en el lema de aproximación óptima.

**** Proyecciones y proyección ortogonal
***** Proyecciones
Sea $H$ Hilbert y $p : H \longrightarrow H$ lineal. Se llama proyección cuando $p \circ p = p$.

***** Suma directa de una proyección
Sea $p:H \longrightarrow H$ proyección, entonces $H = \ker(p) \oplus \im(p)$.

****** Demostración
Para $h \in H$ tenemos la descomposición $p(h) + (h-p(h))$. Dado $p(g) \in \ker(p)$,
se tiene $p(g) = p(p(g)) = 0$.

***** Proyecciones ortogonales
Se dice proyección ortogonal a una proyección $p$ en la que $\ker(p) \perp \im(p)$.

***** Lemas al teorema de la proyección ortogonal
Sea $H$ Hilbert y $M$ subespacio cerrado. Entonces:

  1. $u-\pi_M(u) \in M^\perp$.
  2. $\pi_M(\alpha u) = \alpha \pi_M(u)$.
  3. $\pi_M(u + v) = \pi_M(u)+\pi_M(v)$.
  4. $\pi_M(\pi_M(u)) = \pi_M(u)$.

****** Demostración
******* Punto 1
Para cualquier $t \in \mathbb{R}$ y $m \in M$ tenemos:

\[
0 \leq 
\| u - \pi u + tm \| - \| u - \pi u \| \leq
2t\; Re \langle u-\pi u, m\rangle + t^2 \|m\|^2
\]

Pero para que esto sea cierto, debe ser $Re \langle u-\pi u, m \rangle = 0$.
Tomando $im$ se tiene la parte imaginaria también nula, luego
debe ser $\langle u-\pi u, m \rangle = 0$.

******* Punto 2
Tenemos:

\[
\| \alpha u - m \| 
= |\alpha| \left\|u - \frac{m}{\alpha}\right\| \geq |\alpha| \|u- \pi u\|
\]

Dándose la igualdad con $m = \alpha \pi u$.

******* Punto 3
La ortogonalidad del primer punto:

\[
\|u + v - m\| = 
\|(u -\pi u) + (v - \pi v) - \widetilde m\| =
\|u - \pi u+  v - \pi v \| + \|\widetilde m\|
\]

Para el mínimo debe tenerse $\widetilde m = 0$.

******* Punto 4
Usando de nuevo la ortogonalidad del primer punto:

\[
\pi_M(u) - \pi_M\pi_M(u) \in M^\perp \cap M = \{0\}
\]

***** Teorema de la proyección ortogonal
Para $H$ Hilbert y $M$ subespacio cerrado:

  1. $H = M \oplus M^\perp$.
  2. La proyección a $M$ es la aproximación óptima.
  3. $\|u\|^2 = \|\pi_M(u)\|^2 + \| u - \pi_M(u) \|^2$.

Análogamente, $\pi_{M^\perp}$ da la aproximación óptima a $M^\perp$.

****** Demostración
Por el [[*Lemas al teorema de la proyección ortogonal][lema]] sabemos que $\pi_M$ es una proyección. Como además tiene 
$\ker(\pi_M) = M^\perp$ e $\im(\pi_M) = M$, se tiene que es la buscada.

Por ser ortogonales:

\[
\|u\|^2 = 
\|u - \pi_M(u) + \pi_M(u)\|^2 =
\|u-\pi_M(u)\|^2 + \|\pi_M(u)\|^2
\]

***** Nota: Unicidad de la descomposición ortogonal
Sea $H = M \oplus N$ con $\langle m, n \rangle = 0$ para $m \in M,\; n \in N$. Se tiene que $N = M^\perp$.

****** Demostración
Tenemos $N \subseteq M^\perp$ y además, para $m+n \in M^\perp$, se tiene 
$0 = \langle m, m+n \rangle = \|m\|^2$, luego $m = 0$.

***** Corolario: clausura del doble ortogonal
Para $H$ Hilbert, $M$ subespacio, $M^{\perp\perp} = \overline{M}$.

****** Demostración
El espacio puede partirse de dos formas distintas como suma ortogonal 
de cerrados:

\[ H = \overline{M} \oplus \overline{M}^\perp \]
\[ H = M^{\perp\perp} \oplus M^{\perp}\]

Como $M^\perp = \overline{M}^\perp$, debe ser $\overline{M} = M^{\perp\perp}$.

***** Corolario: caracterización de la densidad
Para $H$ Hilbert, $M$ subespacio, $M$ es denso ssi $M^\perp = \{0\}$.

****** Demostración
Si es denso, $M^\perp = \overline{M}^\perp = \{0\}$. 
Si $M^\perp = \{0\}$, tenemos $H = \overline{M} \oplus \{0\}$.

***** Teorema de Lindestrauss-Tzafriri
Un espacio de Banach es Hilbert ssi todo subespacio cerrado suyo admite
un complemento topológico. Es decir, para cada $M$ cerrado hay un $N$ cerrado
tal que:

\[
X = M \overset{t}{\oplus} N
\]

****** TODO Demostración

**** Teorema de Riesz-Frechet
***** Recordatorio: por Teorema de Hahn-Banach
Sea $X$ espacio normado sobre $\mathbb{K}$. Entonces $\exists f: X \longrightarrow \mathbb{K}$ lineal y continua
no nula. Además, dado $x \in X\setminus\{0\}$, tenemos $\exists f \in X^\ast: f(x) \neq 0$. De hecho,

\[
\|x\| = \sup\{ |f(x)| \mid f \in X^\ast \}
\]

****** Demostración
Hemos reenunciado la [[*Separación en el dual topológico][separación en el dual topológico]], que era 
consecuencia de la [[*Versión analítica de Hahn-Banach][versión analítica de Hahn-Banach]].

****** Relación en el caso prehilbertiano
Cada vector tiene asociada una función lineal y continua en el dual
dada por su producto escalar: $v \mapsto \langle \cdot,v \rangle$.

***** Teorema de Riesz-Fréchet
Sea $H$ Hilbert y $f : H \longrightarrow \mathbb{K}$ lineal y continuo. Existe un único $v \in H$ 
tal que:

\[f(u) = \langle u,v \rangle\]

De otra forma, $v \mapsto \langle \cdot,v \rangle$ es una biyección conjugada-lineal de $H$ en $H^\ast$.

****** Demostración
******* Existencia: caso nulo
En el caso $f=0$, simplemente tomamos $v=0$.

******* Existencia: caso general
Dado $f$, $\ker(f)$ será propio, luego necesitamos $\ker(f)^\perp$ espacio propio
para que la suma directa sea el total. Sea $w \in \ker(f)^\perp$ no nulo, tenemos:

\[
0 = \langle f(u)w - f(w)u , w \rangle = \|w\|^2f(u) - f(w)\langle u,w \rangle
\]

Por lo que tenemos:

\[
f(u) = \left\langle u, \frac{f(w)}{\|w\|^2} w \right\rangle
\]

******* Unicidad: caso nulo
Debe ser un vector en $H^\perp = \{0\}$.

******* Unicidad: caso general
Simplemente notando que $f(u) = \langle u,v \rangle = \langle u,w \rangle$ nos daría $\langle u,v-w \rangle = 0$.
Un vector perpendicular a todo el espacio es nulo.

***** Corolario: el dual es de Hilbert
Si $H$ es Hilbert, $H^\ast$ con la norma de operadores es de Hilbert.

****** Demostración
Tomamos como producto escalar:

\[
\langle f_v,f_w \rangle = \langle w,v \rangle
\]

Y comprobamos que cumple los axiomas. Nótese que es necesario invertir
el orden para que sea hermítico. Por otro lado, la norma es la misma
que la norma de operadores:

\[ \sqrt{\langle f_v,f_v \rangle} = \|v\|
\]

mientras que si $\|u\| = 1$, por Cauchy-Schwarz hay caso de igualdad en:

\[ |f_v(u)| = |\langle u,v \rangle| \leq \|v\|\]

***** Corolario: el doble dual es Hilbert
Si $H$ es Hilbert, $H^{\ast\ast}$ es Hilbert.

****** Demostración
Componemos dos veces lo que hemos hecho con el dual. Tenemos una
biyección lineal en este caso.

***** Corolario: completación de prehilbertianos
Si $H$ es prehilbertiano, $H^{\ast\ast}$ es su completación.

****** Demostración
Veremos que si $\widehat H$ es su completación, $H^\ast \cong \widehat{H}^\ast$, por lo que tendrá que
tenerse $H^{\ast\ast} \cong \widehat{H}^{\ast\ast} \cong \widehat{H}$.

Pero $H^\ast \cong \widehat{H}^\ast$ es cierto simplemente porque la única extensión continua y
la restricción serán inversas.

***** Corolario: extensión única
Sea $H$ Hilbert con $M \subset H$ subespacio y $f \in M^\ast$. Existe una única extensión
lineal y continua cumpliendo:

\[ \|f_H\| = \|f\| \]

****** Demostración
******* Existencia
Podemos extender la función de $M$ a $\overline{M}$ por continuidad. Como es cerrado
y subespacio de Hilbert, será Hilbert. Entonces aplicamos Riesz-Frechet
para tener que la función será de la forma $f(x) = \langle x,m \rangle$ para algún
$m \in M$. Ahora, $f_m = \langle \cdot,m \rangle$ es extensión y cumple:

\[
\|f_m\| = \|m\| = \|f\|
\]

******* Unicidad
Si hubiera otra extensión $\langle \cdot,u \rangle$, se tendría $\langle \cdot,m \rangle - \langle \cdot,u \rangle = 0$ en $M$. 
Y entonces, $m - u \in M^\perp$, lo que implicaría:

\[ \|u\|^2 = \|m\|^2 + \|m-u\|^2 \geq \|m\|^2\]

Con caso de igualdad sólo si $\|m-u\| = 0$.

 - [[http://math.stackexchange.com/questions/332350/hilbert-spaces-and-unique-extensions-of-linear-functions][functional analysis - Hilbert spaces and unique extensions of
   linear functions. - Mathematics Stack Exchange]]

*** 4. Espacios de Hilbert II
**** Convergencia débil
***** Convergencia débil
En $H$ Hilbert, se dice que $\{u_n\}$ converge débilmente a $u$ cuando:

\[\{u_n\} \overset{w}\longrightarrow u 
\iff \forall v \in H: \{\langle u_n,v \rangle\} \longrightarrow \langle u,v \rangle \]

De otra forma, $\forall f \in H^\ast: \{f(u_n)\} \longrightarrow f(u)$.

****** Unicidad del límite débil
La unicidad se tiene porque si $\forall v: \langle u,v \rangle = \langle u',v \rangle$, entonces $f_u = f_{u'}$,
que por [[*Teorema de Riesz-Frechet][Riesz-Frechet]] nos da $u = u'$.

***** Convergencia implica convergencia débil
En $H$ Hilbert, la convergencia implica la convergencia débil: 

\[\{u_n\} \longrightarrow u \implies \{u_n\} \overset{w}\longrightarrow u\]

****** Demostración
Trivial por continuidad del producto escalar.

****** Contraejemplo del recíproco
En el espacio de sucesiones cuadrado sumables $\ell_2$, sabemos que los
términos de toda sucesión tienden a $0$, por eso:

\[ \{e_n\} \overset{w}\longrightarrow 0\]

Pero no se tiene $\{e_n\} \longrightarrow 0$.

***** Compacidad débil
Un conjunto es débilmente compacto si toda sucesión suya tiene una
parcial débilmente convergente.

***** Compacidad de la bola unidad
Sea $H$ Hilbert, entonces la bola $\overline{B(0,1)}$ es débilmente compacta.

****** TODO Demostración

***** Espacio vectorial topológico
Un espacio vectorial topológico es un espacio vectorial con una topología
que hace continuos a la norma y el producto por escalares.

**** Ortonormalidad
***** Ortogonalidad y ortonormalidad
Sea dice $S \subset H$ ortogonal cuando $\forall u,v \in S: \; u \perp v$. Se dice que es además
ortonormal cuando $\forall u \in S : \|u\| = 1$.

***** Independencia de ortogonales
Si hay un conjunto ortogonal $S$, es linealmente independiente.

****** Demostración
Supongamos que tenemos $e_1,\dots,e_n \in S$ y una combinación lineal suya.
Entonces para cada $e_k$:

\[
0 = \left\langle \sum \alpha_i e_i, e_k \right\rangle
= \alpha_k \|e_k\| = \alpha_k
\]

***** Gram-Schmidt
Sea $H$ prehilbertiano de dimensión $n$, finita:

  1. $\{e_1,\dots,e_n\}$ ortogonal $\implies$ $\{e_1,\dots,e_n\}$ base
  2. Existe una base ortonormal.

****** Demostración
******* Punto 1
Son linealmente independientes y generan un espacio de dimensión $n$,
que debe ser el total.

******* Punto 2
Sabemos que existe una base $u_1,\dots,u_n$, podemos generar una base
ortonormal tomando a cada paso:

\[ e_i = u_i - \sum_{j < i} \langle u_i,e_j \rangle e_j\]

Para tener una base ortogonal. Dividiendo por la norma para tener una
base ortonormal.

***** Base ortonormal finita
Sea $e_1,\dots,e_n$ una base ortonormal de un Hilbert. Cada elemento puede
escribirse en coordenadas de sus productos escalares:

\[
u = \sum_{i=1}^n \langle u,e_i \rangle e_i
\]

Y su norma será:

\[
\|u\| = \sqrt{\sum^n_{i=1} |\langle u,e_i \rangle|^2}
\]

****** Demostración
Si escribimos las coordenadas $u = \sum \alpha_ie_i$ tenemos que $\alpha_i = \langle u,e_i \rangle$.
La norma se obtiene desde la descripción de coordenadas por 
ortonormalidad.

**** Familias sumables
***** Familia sumable
Sea $X$ normado y $\{x_i\}_{i\in I}$ familia; se dice sumable si:

\[\exists x \in X: 
\forall \varepsilon > 0:
\exists J_\varepsilon:
\forall J \text{ finito} \supseteq J_\varepsilon: 
\quad
\left\|\; \sum_{i \in J} x_i - x \;\right\| < \varepsilon
\]

Llamamos suma de la familia a $\sum_{i \in I} x_i = x$.

****** Redes
Nótese que esto es una generalización del concepto de sucesión.
Las [[https://es.wikipedia.org/wiki/Red_(matem%25C3%25A1tica)][redes]] son una generalización de las secuencias para una
cantidad no numerable de elementos.

# Quizá podríamos ver que toda red es Cauchy ssi es convergente.
# Eso nos ahorraría las demostraciones posteriores de familias sumables.

***** Unicidad de la suma
La suma de una familia sumable es única.

****** Demostración
Si tuviera dos sumas $x$ y $x'$, tomaríamos los $J_\varepsilon, J_\varepsilon'$ para tener:

\[
\| x - x' \| \leq
\left\| x - \sum_{x_i \in J_\varepsilon \cup J_\varepsilon'} x_i \right\| +
\left\| \sum_{x_i \in J_\varepsilon \cup J_\varepsilon'} x_i - x' \right\|
\leq 2\varepsilon
\]

***** Propiedades de las familias sumables
Sea $X$ normado con $\{x_i\}_{i \in I}$ familia con suma $x$:

  1. $\sum_{i \in I} x_{\sigma(i)} = x$, para cualquier permutación $\sigma$.
  2. $\sum_{i \in I} \alpha x_i + \beta y_i = \alpha x + \beta y$, siendo la suma lineal.
  3. $\sum_{i \in I} Tx_i = Tx$, para $T$ lineal continua.

****** Demostración
Nótese que cuando coinciden en subsumas finitas, deben coincidir
en la suma total, por definición.

******* Punto 1
Trivial por la definición.

******* Punto 2
Tomando el conjunto $J_{\frac{\varepsilon}{2\alpha}}^x \cup J_{\frac{\varepsilon}{2\beta}}^y = K$, tenemos que:

\[ \left\| \alpha x + \beta y - \left(\sum_{i \in K} \alpha x_i + \beta y_i \right)\right\| 
\leq |\alpha| \left\| x - \sum_{i \in K} x_i \right\| + |\beta| \left\|y - \sum_{i \in K} y_i \right\| 
\leq \varepsilon\]

******* Punto 3
Si tomo unos $\varepsilon \longrightarrow 0$ tendré:

\[
\left\| Tx - \sum_{i \in J_\varepsilon} Tx_i \right\| = 
\left\| T\left( x - \sum_{i \in J_\varepsilon} x_i \right) \right\| \leq
\|T\|\varepsilon \longrightarrow 0
\]

***** Caracterización de familia sumable real
En los reales positivos, una familia $\{r_i\}_{i \in I} \in \mathbb{R}^+$ es sumable ssi:

\[\sup\left\{\;
\sum_{i \in J} r_i \;\middle|\; J \;\mtext{ finito } \subset I
\;\right\} < \infty\]

donde además, $\sum_{i \in I} r_i$ es el supremo.

****** Demostración
Por la definición de supremo, dado cualquier $\varepsilon$ podemos encontrar:

\[s \geq \sum_{J} r_i \geq \sum_{J_\varepsilon} r_i\]

Cumpliendo por tanto para $J_\varepsilon \subset J$:

\[ 
\left|s - \sum_J r_i\right| \leq 
\left|s - \sum_{J_\varepsilon} r_i \right| \leq
\varepsilon\]

***** Condición de Cauchy en familias sumables
Una familia $\{x_i\}_{i \in I}$ verifica la condición de Cauchy cuando:

\[\forall \varepsilon > 0:
\exists J_\varepsilon \text{ finito}:
\forall J \text{ finito}: J \cap J_\varepsilon = \varnothing \implies
\left\|\; \sum_{i \in J} x_i \;\right\| < \varepsilon\]

***** Toda sumable es Cauchy
Si $\{x_i\}_{i \in I}$ es sumable, verifica la condición de suma de Cauchy.

****** Demostración
Suponiendo que suman $s$, podemos tomar $J_\varepsilon$ cumpliendo que, dado $J \cap J_\varepsilon = \varnothing$:

\[
\left\|\; s - \sum_{J_\varepsilon \cup J} x_i \;\right\| < \varepsilon
\]

Y por tanto, aplicando Minkowski:

\[
\left\|\; \sum_{J} x_i \;\right\|
\leq
\left\|\; \left(s - \sum_{J_\varepsilon} x_i \right) - \sum_J x_i \;\right\| +
\left\|\; s - \sum_{J_\varepsilon} x_i \; \right\|
\leq
2\varepsilon
\]

***** Toda Cauchy en un Hilbert es sumable
Si $\{x_i\}_{i \in I} \in H$ Hilbert verifica la condición de suma de Cauchy, 
es sumable.

****** Demostración
Primero tomamos la sucesión de Cauchy siguiente, que por complitud
del espacio es convergente:

\[
\left\{
\sum_{i \in J_{\frac{1}{n}}} x_i
\right\}
\longrightarrow
s
\]

Tenemos, para $J \supseteq J_{\frac{1}{n}}$, para $n$ suficientemente grande, que:

\[
\left\|\sum_{i \in J} x_i - s \right\| \leq
\left\|\sum_{i \in J} x_i - \sum_{i \in J_{\frac{1}{n}}} x_i \right\| +
\left\|\sum_{i \in J_{\frac{1}{n}}} x_i - s \right\| \leq 
\frac{1}{n} + \varepsilon
\]

Siendo por tanto sumable.

***** Numerabilidad de familias de Cauchy
Toda familia de Cauchy tiene $\{ i \in I \mid x_i \neq 0\}$ numerable.

****** Demostración
Si verifica Cauchy, para cada $n$ podemos tomar, $J_n$ tal que 
para $J \cap J_n =\varnothing$:

\[\left\| \sum_{J} x_i \right\| \leq \frac{1}{n}\]

Si tenemos un $x \notin J_n$ para todo $n$, debe cumplir $\|x\| < \frac{1}{n}$, luego $x = 0$.
Como $\bigcup_{n \in \mathbb{N}} J_n$ es numerable. El conjunto de elementos no nulos es 
numerable.

***** Sumable es esencialmente numerable
En un espacio normado cualquiera equivalen:

  1. $\{x_i\}_{i \in I}$ sumable.
  2. $I_0 = \{ i \in I \mid x_i \neq 0\}$ numerable y para toda biyección $G : \mathbb{N} \longrightarrow I_0$:

     \[\sum_{i \in I_0} x_i = \sum_{n \in \mathbb{N}} x_{G(n)}\]

****** Demostración
******* Primera implicación
Si es sumable cumple la condición de Cauchy y por tanto,
su conjunto de elementos no nulos es numerable.

Además, si suma $s$, fijado $\varepsilon$, tengo un conjunto finito $J$.
Como $\{0,1,\dots,\max_{j \in J}\{G(j)\},\dots,m\} \supseteq G(J)$, se tiene:

\[
\left\| s - \sum_{i=0}^m x_{G(i)} \right\| \leq \varepsilon
\]

Por lo que la suma converge a $s$ para cualquier biyección.

******* TODO Segunda implicación
# Me gustaría probar que la convergencia incondicional da la convergencia
# absoluta, y entonces usar directamente la convergencia absoluta para
# probar que es sumable.

***** Corolario: convergencia conmutativa
Cuando $I = \mathbb{N}$, ser sumable equivale a converger conmutativamente,
esto es:

\[
\sum_{k \in \mathbb{N}} x_k = \sum_{k \in \mathbb{N}} x_{\sigma k}
\]

****** Demostración
Por el [[*Sumable es esencialmente numerable][teorema]] anterior.

***** Corolario: suma de particiones
En $X$ Banach, $I = \bigcup_{\lambda \in \Lambda} I_\lambda$ partición arbitraria nos da que si $\{x_i\}_{i \in I}$
es sumable, $\{x_i\}_{i \in I_\lambda}$ es sumable; además:

\[ \sum_{i\in I} x_i = \sum_{\lambda \in \Lambda} \left(\sum_{i \in I_\lambda} x_i \right)\]

****** TODO Demostración

**** Familias absolutamente sumables
***** Familia absolutamente sumable
Una familia $\{x_i\}_{i \in I}$ es absolutamente sumable cuando $\{\|x_i\|\}_{i \in I}$ es sumable
en $\mathbb{R}^+$:

\[
\sup_{J \subseteq I} 
\left\{ 
\sum_J \|x_i\| \;\middle|\; J \text{ finito}
\right\} < \infty
\]

***** Criterio de Abel
Sea $X$ Banach, $\{x_i\}_{i \in I} \in X$ y $\|x_i\| < |\alpha_i|$ cumpliendo $\sum |\alpha_i| < \infty$. Entonces
$\{x_i\}$ es sumable con:

\[
\left\|\sum_{i \in I} x_i\right\| \leq \sum_{i \in I} |\alpha_i|
\]

****** TODO Demostración
***** Absolutamente sumable implica sumable
En particular, absolutamente sumable implica sumabilidad en Banach, con:

\[
\left\|\sum x_i\right\| \leq \sum \|x_i\|
\]

****** Demostración
Trivialmente desde el [[*Criterio de Abel][criterio de Abel]].

**** Familias ortonormales
***** Suma ortogonal
Sea $\{e_i\}_{i\in I}$ familia ortogonal en un espacio de Hilbert $H$. Entonces
$\{e_i\}_{i \in I}$ es sumable ssi $\{\|e_i\|^2\}_{i \in I}$ es sumable en $\mathbb{R}^+$, en cuyo caso:

\[
\left\| \sum_{i \in I} e_i \right\| = \sqrt{\sum_{i \in I} \|e_i\|^2}
\]

****** Demostración
Coinciden en cualquier suma finita:

\[
\left\|\; \sum_{i \in I} e_i \;\right\|^2 = \sum_{i \in I} \|e_i\|^2
\]

Por lo tanto, coinciden sobre la condición de Cauchy.

***** Corolario: suma ortogonal con coeficientes
Sea $\{e_i\}_{i \in I}$ familia ortonormal con $f : H \longrightarrow \mathbb{K}$ aplicación. Entonces
$\{f(e_i)e_i\}$ es sumable ssi $\{|f(e_i)|^2\}$ es sumable en $\mathbb{R}^+$; en cuyo caso:

\[
\left\| \sum_{i \in I} f(e_i) e_i \right\| =
\sqrt{\sum_{i \in I} |f(e_i)|^2}
\]

****** Demostración
Trivial desde lo anterior viendo $\{f(e_i)e_i\}$ como familia ortogonal.

***** Corolario: suma ortogonal con productos escalares
Sea $H$ Hilbert, $\{e_i\}_{i \in I}$ familia ortonormal. Para $u \in H$ se tiene que
$\{\langle u,e_i \rangle e_i\}$ es sumable ssi $\{|\langle u,e_i \rangle|^2\}$ es sumable en $\mathbb{R}^+$.

****** Demostración
Caso particular de lo [[*Suma ortogonal][anterior]] con $f(x) = \langle u,x \rangle$.

***** Desigualdad de Bessel
Sea $\{e_i\}_{i \in I}$ ortonormal en $H$ Hilbert, entonces existe la suma siguiente
y está acotada:

\[
\sum_{i \in I} |\langle u,e_i \rangle|^2 \leq
\|u\|^2
\]

****** Demostración
En el caso finito:

\[
0 \leq
\left\| u - \sum_{J} \langle u,e_i \rangle e_i \right\|^2 =
\|u\|^2 - \sum_J \langle u,e_i \rangle^2 - \sum_J |\langle u,e_i \rangle|^2  + \sum_{J} \langle u,e_i \rangle^2
\]

Por tanto:

\[\sum_J |\langle u,e_i \rangle|^2 \leq \|u\|^2\]

Pero como estamos estudiando sumabilidad en los reales, basta haber
encontrado una cota sobre el [[*Caracterización de familia sumable real][supremo]] para acotar la suma.

***** Corolario de Bessel
Sea $\{e_i\}_{i \in I}$ ortonormal en $H$ Hilbert, y sea $M$ el subespacio cerrado 
generado: $M = \overline{lin\{e_i \mid i \in I\}}$. Dado $u \in H$, la mejor aproximación de $u$ a $M$ 
es:

\[ \pi_M(u) = \sum_{i \in I} \langle u,e_i \rangle e_i
\]

En consecuencia se tiene:

\[
\|u\| 
= 
\sqrt{\;\sum_{i \in I} |\langle u,e_i \rangle|^2 + 
\left\|u - \sum_{i \in I} \langle u,e_i \rangle e_i\right\|^2\;}
\]

Y además, equivalen:

  1. \[u \in M\]
     
  2. \[u = \sum \langle u,e_i \rangle e_i\]
     
  3. \[\|u\|^2 = \sum_{i \in I} |\langle u,e_i \rangle|^2\]

****** Demostración
******* Existe la suma
Por desigualdad de Bessel, comprobando la igualdad de ambas sumas
en los casos finitos, tenemos que existe la suma:

\[
\left\|\; \sum_{i \in I} \langle u,e_i \rangle e_i \;\right\|= 
\sqrt{\sum_{i \in I} |\langle u,e_i \rangle|^2} \leq \|u\|
\]

Ya que es una suma de positivos acotada. Ambas sumas cumplen
la misma condición de [[*Corolario: suma ortogonal con productos escalares][Cauchy]].

******* Hay ortogonalidad
Tomamos $m = \sum_{i \in I} \langle u,e_i \rangle e_i$, y comprobamos que $u - m \in M^\perp$. Como la
familia ortonormal genera el espacio, basta comprobar que es 
ortonormal a ella:

\[
\langle u-m,e_k \rangle = 0
\]

Por tanto, tenemos una descomposición $u = m + (u-m)$ y por teorema
de la [[*Teorema de la proyección ortogonal][proyección ortogonal]], $m$ es la mejor aproximación, y se tiene
la igualdad dada.

******* Equivalencias
Cuando $u \in M$, él mismo es su mejor aproximación y su norma puede
calcularse directamente. La igualdad de normas implica que la
norma de $u-m$ sea $0$, haciendo $u \in M$.
***** Existencia de familias ortonormales maximales
Existen sistemas ortonormales maximales.

****** Demostración
Lema de Zorn.

***** Caracterización de bases ortonormales
En $H$ Hilbert equivalen:

  1. $u = \sum \langle u,e_i \rangle e_i$ para cualquier $u$.
  2. $\langle u,v \rangle = \sum \langle u,e_i \rangle \langle e_i,v \rangle$, identidad de Parseval.
  3. $\|u\|^2 = \sum_{i \in I} |\langle u,e_i \rangle|^2$.
  4. $\{e_i\}$ sistema ortonormal maximal.
  5. $\forall e_i : v \perp e_i \implies v =0$.
  6. $H = \overline{lin\{e_i\}}$

****** Demostración
Directamente desde el corolario de Bessel en el caso de $M$ denso,
donde no hay ningún ortonormal a él. Podemos comprobar la implicación
en cada uno de los puntos.

**** Bases de Hilbert
***** Base de Hilbert
Se llama base de Hilbert a una familia ortonormal maximal.

****** Desarrollo en serie de Fourier
Una familia ortonormal maximal debe tener un subespacio cerrado
generado que sea [[*Corolario: caracterización de la densidad][denso]], ya que si no fuera así, tendría un $M^\perp$ no 
nulo. Por tanto cumple el corolario a Bessel y se tiene:

\[ u = \sum_{i \in I} \langle u,e_i \rangle e_i\]

llamada *Serie de Fourier*.

***** Dimensión Hilbertiana
El cardinal de las bases de Hilbert de un espacio es inveriante y
se llama *dimensión Hilbertiana*.

****** Demostración
[[http://math.stackexchange.com/questions/232166/showing-the-basis-of-a-hilbert-space-have-the-same-cardinality][Showing the basis of a Hilbert Space have the same cardinality]].

***** Isomorfía entre espacios de igual dimensión
Dos espacios de Hilbert con la misma dimensión Hilbertiana son
topológicamente isomorfos.

****** Demostración
Dado un isomorfismo entre las bases, definimos la aplicación lineal
que extiende el isomorfismo. Por el desarrollo en serie de Fourier,
sabemos que es equinórmica y por tanto continua.

Por el Teorema de los [[*Teorema de los isomorfismos de Banach][isomorfismos de Banach]], son isomorfos 
topológicamente.

**** Operadores adjuntos
***** Operadores adjuntos
Dado $T \in L(H_1,H_2)$ entre espacios de Hilbert, existe:

\[\exists! T^\ast \in L(H_2,H_1):  \langle Tx,y \rangle = \langle x,T^\ast y\rangle\]

Llamado el *operador adjunto*.

****** Demostración
Por Riesz-Fréchet, tenemos una aplicación $T^\ast y$ única cumpliendo:

\[\langle T \cdot, y \rangle = \langle \cdot , T^\ast y \rangle\]

******* Es lineal
La función es lineal ya que, aplicando unicidad de Riesz-Fréchet:

\[
\langle \cdot, T^\ast( \alpha y + y') \rangle =
\langle T \cdot, \alpha y + y' \rangle =
\overline{\alpha} \langle T \cdot, y \rangle + \langle T \cdot, y' \rangle =
\langle \cdot, \alpha T^\ast y + T^\ast y' \rangle
\]

******* Es continuo
La continuidad se tiene por acotación en la bola unidad:

\[
\| T^\ast y \|^2 \leq \|y\| \|TT^\ast y\| \leq \|T\| \|T^\ast y\|
\]

***** Propiedades de operadores adjuntos
Los adjuntos cumplen:

  1. $T^{\ast\ast} = T$.
  2. $\|T\| = \|T^\ast\| = \|TT^\ast\|^{1/2} = \|T^\ast T\|^{1/2}$.
  3. $(T_1+T_2)^\ast = T_1^\ast+T_2^\ast$
  4. $(\alpha T)^\ast = \overline{\alpha}T^\ast$.
  5. $(RT)^\ast = T^\ast R^\ast$.

****** Demostración
******* Punto 1
Aplicando unicidad de Riesz-Frechet a:

\[\overline{\langle y, T\cdot \rangle} = \overline{\langle y, T^{\ast\ast} \cdot \rangle}\]

******* Punto 2
Tenemos $\|T\| = \|T^{\ast\ast}\| \leq \|T^\ast\| \leq \|T\|$, como acotamos anteriormente.

Además, tenemos doble acotación para los dos operadores:

\[\|TT^\ast\| \leq \|T\|\|T^\ast\| = \|T\|^2\]
\[\|Tx\|^2 \leq \|x\|^2 \|TT^\ast\|\]

******* Puntos 3, 4 y 5
Trivialmente por linealidad, usando la unicidad de Riesz-Frechet.

***** Relación con el adjunto
Sea $T \in L(H,H)$; se cumple:

  1. $\ker T^\ast = T(H)^\perp$.
  2. $\ker T = T^\ast(H)^\perp$.
  3. $T^\ast$ inyectivo $\iff$ $T(H)$ denso.

****** Demostración
******* Punto 1 y 2
Trivial por doble inclusión y por reflexividad del adjunto.

******* Punto 3
Uniendo las condiciones de densidad y ortogonalidad con la 
caracterización de inyectividad por núcleo nulo.

***** Operador autoadjunto
Un operador $T \in L(H,H)$ es autoadjunto si $T^\ast = T$.

***** Propiedades de los autoadjuntos
Para $T \in L(H)$:

  1. $TT^\ast,T^\ast T, T+T^\ast$ son autoadjuntos.
  2. $T$ autoadjunto da $\alpha T$ autoadjunto.
  3. $\{ T = T^\ast\}$ es cerrado.
  4. Todo operador se divide en dos partes real e imaginaria:

     \[R = \frac{T+T^\ast}{2}\qquad S = \frac{T-T^\ast}{2}\]

**** Espectro y operadores compactos
***** Espectro
El espectro de un operador es el conjunto de valores propios,
llamamos:

****** Espectro

\[G(T) = \{\lambda \in \mathbb{C} \mid T - \lambda I \mbox{ invertible}\}\]

****** Espectro puntual

\[
G_p(T) =
\{
\lambda \in \mathbb{C} 
\mid
T - \lambda I \text{ no inyectivo}
\}
\]

****** Espectro comprimido

\[G_{com}(T) 
= 
\{\lambda \in \mathbb{C} \mid T - \lambda I \mbox{ con imagen no densa}\}
\]

****** Espectro aproximado

\[G_{ap}(T) =
\{\lambda \in \mathbb{C} \mid T-\lambda I \mbox{ no acotado por debajo}\}
\]

****** Relación
Equivalen ser invertible a tener imagen densa y estar acotado por 
debajo. Así,

\[G(T) = G_{com}(T) \cup G_{ap}(T)\]

Además, en *dimensión finita* y en compactos, equivalen inyectividad, 
sobreyectividad y biyectividad, luego:

\[G(T) = G_p(T)\]

******* TODO Demostración

***** Rango de un operador
El rango de $T$ es $n$ cuando puede escribirse con $u_i,w_i \in H$:

\[T = \sum u_i \otimes w_i\]

Es decir, como una matriz finita de ese rango.

****** Operadores de rango finito son compactos
Los operadores de rango finito son compactos.

******* Demostración
En dimensión finita las bolas son compactas. Al ser continuo,
la sucesión imagen es siempre acotada y con parcial convergente.

***** Operador compacto
Si $T \in L(H)$ es compacto si para cualquier acotada, la $\{T(u_n)\}$ tiene
una parcial convergente.

****** Caracterización de compactos
Un $T$ es compacto ssi $T(\overline{B(0,1)})$ es compacto.

****** Compactos como límite de los de rango finito
Los operadores de rango finito son compactos. De hecho, son su clausura.
Si tenemos:

 - \[KL(H) = \{T: H\longrightarrow H \mid \mbox{ compacto}\}\]
 - \[FL(H) = \{T : H\longrightarrow H \mid \mbox{ rango finito}\}\]

Se cumple $\overline{FL(H)} = KL(H)$.

******* TODO Demostración

****** El adjunto de un compacto es compacto
Si tenemos $T = \lim T_n$, con $T_n = \sum u_i \otimes w_i$. Podemos comprobar que
el adjunto es límite de $T_n^\ast = \overline{\sum w_i \otimes u_i}$, de rango finito.

***** Teorema de la aplicación espectral
Para $H$ Hilbert, un polinomio no constante puede aplicarse a operadores
para tener:

\[G(p(T)) = \{p(\lambda) \mid \lambda \in G(T)\}\]

***** Teorema del núcleo
Si $T \in L(H)$ compacto, $\ker(T - \lambda I)$ tiene dimensión finita.

****** TODO Demostración
***** Teorema del rango
Si $T \in L(H)$ compacto, $\im(T-\lambda I)$ es cerrado.

****** TODO Demostración
***** Biyectividad en compactos
Si $T \in L(H)$ compacto, para $\lambda \neq 0$, $T-\lambda I$ es inyectivo ssi es 
sobreyectivo ssi es biyectivo.

\[G(T) \setminus \{0\} 
=
G_p(T) \setminus \{0\}
= 
G_{ap}(T) \setminus \{0\}
\]

***** Alternativa de Fredholm
Sea $T \in L(H)$ compacto y $\lambda \neq 0$. Consideramos las ecuaciones:

  1. $(T - \lambda I)x = 0$.
  2. $(T^\ast - \overline{\lambda} I)z = 0$.
  3. $(T-\lambda I)x = y$.
  4. $(T^\ast - \overline{\lambda} I)z = w$.

Y sabemos que se cumple una de estas dos alternativas:

  - O bien $x=0,z=0$ son las únicas soluciones de 1 y 2; en
    cuyo caso 3 y 4 tienen solución única, que además depende 
    continuamente.
  - O bien hay soluciones no nulas de 1 y 2 y entonces 3 tiene
    solución si $y \perp \ker(T^\ast - \overline{\lambda} I)$ y 4 tiene solución si $w \perp \ker(T-\lambda I)$.

****** Alternativamente
En resumen, para $T$ compacto:

  - $img(T - \lambda I) = \ker(T^\ast - \lambda I)^\perp$.
  - $img(T^\ast - \lambda I) = \ker(T-\lambda I)^\perp$.

Y si uno es nulo ambos lo son.

****** Demostración
******* Caso sin valor propio
Si $\lambda \notin G(T)$, entonces es invertible, así como su adjunta.

******* Caso con valor propio
Si $\lambda \in G(T)$, entonces $\ker(T-\lambda I) \neq 0$ y $\ker(T^\ast-\lambda I) \neq 0$, porque
para compactos coinciden los espectros. Se tiene además:

  - $y \in img(T - \lambda I) = (\ker(T^\ast-\lambda I)^\perp)$
  - $w \in img(T^\ast - \lambda I) = (\ker(T-\lambda I)^\perp)$

***** Diagonalización de autoadjuntos compactos
Sea $T \in L(H)$, compacto y autoadjunto, entonces es *diagonalizable*.
Hay una base ortonormal con \[\lambda_n \longrightarrow 0\] de vectores propios, teniendo
convergencia uniforme sobre los compactos:

\[Tu = \sum \lambda_i \langle u,e_i \rangle e_i\]

Teniendo $G_p(T) \setminus \{0\} = \{\lambda_1,\dots,\lambda_n\}$, y coincide la dimensión del 
espacio propio y el número de veces que aparece $\lambda_i$.

**** Extra
***** Extra: El espectro de un autoadjunto es real
***** Extra: El espectro del adjunto es el conjugado en caso finito
****** Contraejemplo caso infinito
Pero en el caso general no. Un ejemplo es el siguiente:

\[
T(a_1,a_2,\dots) = (a_2,a_3,\dots)
\]

Que tiene cualquier valor en el espectro mientras su adjunto
no tiene ningún valor propio.

***** Extra: En el caso finito, el adjunto es la conjugada de la traspuesta
***** Extra: [[https://en.wikipedia.org/wiki/Spectral_theorem][Teorema espectral]]
*** Ejercicios
**** 1. Espacios normados
***** Ejercicio 3
La sucesión no puede tener ninguna parcial convergente a $0$, porque si no, 
al ser de Cauchy, convergería a $0$. Por tanto, a partir de un cierto $n$, 
todos los términos deben alejarse de $0$ más de un determinado $\alpha$.

Sean ahora $\|x - y\| \leq \epsilon$, por desigualdad triangular inversa tenemos:

\[ \bigg|\|x\|-\|y\|\bigg| \leq \|x-y\| \leq \epsilon\]

Y por tanto:

\[1 - \frac{\epsilon}{\|x\|} \leq \frac{\|x\|}{\|y\|} \leq 1 + \frac{\epsilon}{\|x\|}\]

Ahora, por otro lado, comprobaremos que podemos demostrar a la función 
$f(x) = \frac{x}{\|x\|}$ uniformemente continua:

\[ 
\bigg| \frac{x}{\|x\|} - \frac{y}{\|y\|} \bigg| =
\frac{1}{\|x\|} \|(x-y) + \left(1 - \frac{\|x\|}{\|y\|}y\right) \leq
\frac{\epsilon}{\|x\|} + \frac{\|y\|}{\|x\|} \left|1-\frac{\|x\|}{\|y\|}\right|
\]

Pero como tenemos acotaciones uniformes de $\|x\|^{-1}$ y de $\frac{\|y\|}{\|x\|}$, hemos 
terminado.
***** Ejercicio 4
#+begin_statement
Sea $X$ espacio normado. Probar que equivalen:

  1. $X$ completo.
  2. $B_X$ completo.
  3. $S_X$ completo.
#+end_statement

****** Primera y segunda implicaciones
Cerrados dentro de un completo.

****** Tercera implicación
Sea $\{x_n\}$ una sucesión de Cauchy. Descartamos el caso $\{\|x_n\|\} \longrightarrow 0$, 
que lleva a la convergencia a $0$. Podemos asumir $\|x_n\| \geq 0$ para
alguna cola de la sucesión.

La sucesión $\left\{\frac{x_n}{\|x_n\|}\right\}$ es de Cauchy (puede comprobarse acotando en el
caso en el que hemos descartado el $0$). Por tanto converge. Nótese
que las normas también son de Cauchy y también convergen. Así,
podemos escribir un $x/\|x\|$ al que converja la sucesión sobre $S_X$.

La distancia de cada elemento queda acotada por la distancia sobre
la bola unidad y la distancia en norma:

\[
\|x_n-x\| \leq
\|x_n\| 
\left( 
\left\| \frac{x_n}{\|x_n\|} - \frac{x}{\|x\|} \right\| +
\left\| \frac{x}{\|x\|} - \frac{x}{\|x_n\|} \right\|
\right)
\leq
\varepsilon
\]

El teorema es que si algo converge en la bola unidad y converge en
norma a distinto de $0$, converge a eso.

***** Ejercicio 7
#+begin_statement
Probar que, en un espacio normado, el interior de un subespacio
vectorial propio es vacío.
#+end_statement

Simplemente notando que si $B(m,r) \subseteq M$, entonces $B(0,1) \subseteq M$, y eso
lleva a $X = M$.

***** Ejercicio 16
****** Punto a
     Es de hecho una isometría por tenerse: 

     \[\|Tx\| = \left(\sum_{n=0} |Tx_n|^p\right)^{1/p} = 
     0 + \left(\sum_{n=1} |x_n|^p\right)^{1/p} =
     \|x\|\]

     Así que es continua y su norma es $1$.

****** Punto b
     Vemos que es lipschitziana trivialmente con $\|Tx\| \leq \|x\|$. Como además realiza la cota
     sobre la bola unidad al tener: $\|T(0,1,0,\dots)\| = \|(1,0,\dots)\| = 1$.

****** Punto c
     Vemos que es isometría $\|Tx\| = \|x\|$, por lo que es continua y de norma $1$.
**** 2. Hahn-Banach
***** Ejercicio 1
#+begin_statement
Sea $X$ espacio vectorial sobre $\mathbb{K}$, y sean $p_1,p_2 : X \longrightarrow \mathbb{R}$ seminormas.
Probar que si $f : X \longrightarrow \mathbb{K}$ es un funcional lineal verificando que 
$|f(x)|\leq p_1(x)+p_2(x)$ para todo $x\in X$, entonces existen $f_1,f_2 : X\longrightarrow\mathbb{K}$
funcionales lineales tales que $f = f_1+f_2$, y $|f_1(x)|\leq p_1(x)$, $|f_2(x)|\leq p_2(x)$
para todo $x\in X$.
#+end_statement

Sobre el espacio $X \times X$ definimos una seminorma desde las
dos seminormas anteriores:

\[ p(x,y) = p_1(x) + p_2(x)\]

Por otro lado, consideramos el subespacio diagonal:

\[ \Delta = \{(x,x) \mid x \in X\} \]

Y definimos sobre él un funcional lineal:

\[ h(x,x) = f(x) \leq p(x,y)\]


Ahora, podemos aplicar Hahn-Banach para obtener una extensión
de $h$ definida para todo el espacio cumpliendo:

\[ |h(x,y)| \leq p(x,y)\]

Ahora, si definimos $f_1(x) = h(x,0)$ y $f_2(x) = h(0,x)$, las 
desigualdades se obtienen trivialmente desde la anterior.

***** Ejercicio 2
#+begin_statement
Sean $X$ un espacio normado, $M$ un subespacio vectorial de $X$, y
$u \in X$. Probar que existe $f \in X^\ast$ tal que $|f(x)| \leq dist(x,M)$ para todo
$x \in X$ y $f(u) = dist(u,M)$.
#+end_statement

Sobre el espacio $\langle u \rangle$ definimos el funcional $g(x) = dist(x,M)$, que es
lineal y continuo. Y por otro lado, definimos la seminorma $p(x) = dist(x,M)$
en todo el espacio. Por Hahn-Banach, existe un funcional que extiende
a $g$ y que cumple además:

\[ |f(x)| \leq dist(x,M) \]

***** Ejercicio 3
#+begin_statement
Para cada $n \in \mathbb{N}$, sea $T_n : \ell_\infty \longrightarrow \mathbb{K}$ definido por $T_n(x) = \frac{1}{n}(x_1+\dots+x_n)$.
Sea $M = \{x \in \ell_\infty : \{T_n(x)\}\text{ converge} \}$ y definamos $T(x) = \lim\{T_n(x)\}$ sobre él.

 1. Probar que $T_n \in (l_\infty)^\ast$ y que $\|T_n\| = 1$ para todo $n \in \mathbb{N}$.
 2. Probar que $M$ es un subespacio vectorial de $\ell_\infty$ que contiene al espacio
    $c$ de las sucesiones convergentes.
 3. Probar que $T \in M^\ast$ con $\|T\| = 1$ y que $T(x) = \lim\{x_n\}$ para todo $x \in c$.
 4. Sea $\tau(x) = (x_2,x_3,\dots)$ para todo $x \in l_\infty$. Probar que 
    $x - \tau(x) \in \ker(T) \subseteq M$ para todo $x \in l_\infty$.
 5. Deducir que existe $S \in (l_\infty)^\ast$, extensión de $T$ tal que $\|S\| = 1$ y
    $S(x) = S(\tau^n(x))$ para todo $x \in l_\infty$ y para todo $n \in \mathbb{N}$.
 6. Probar que $S(0,\frac{1}{2},0,\frac{1}{2},\dots) = \frac{1}{4}$.
#+end_statement

****** Punto 1
Tenemos que demostrar que es lineal y continua. Pero sabemos
que es suma y multiplicación por escalar de las proyecciones, que
lo son. Por otro lado, por desigualdad de las medias sabemos:

\[ \frac{1}{n}(x_1+\dots+x_n)
\leq \max\{x_1,\dots,x_n\}
\leq \|x_n\|_\infty\]

Por tanto $x \in B_{\ell_\infty}$ implica $T(x) \leq 1$. Y la desigualdad se realiza
en el caso $(1,1,1,\dots)$.

****** Punto 2
Tenemos que es subespacio vectorial porque si $T_n(x)$ y $T_n(y)$ convergen,
también lo hace $T_n(x+\alpha y) = T_n(x) + \alpha T_n(y)$ por ser lineal.

****** Punto 3
El $T$ es el límite puntual de los $T_n$. Por teorema del cierre de
Steinhaus, $T$ es lineal y continuo. Veamos que tiene norma unidad.
Por desigualdad de las medias la norma no puede ser mayor que $1$.
Tenemos para $x \in S_M$:

\[ T_n(x) \leq 1 \Rightarrow T(x) \leq 1\]

Y además, para $u = (1,1,1,\dots)$ se tiene que $T_n(u) \to 1 = T(u)$.

****** Punto 4
Se ve que está en el núcleo.

****** Punto 5
Por extensión equinórmica de Hahn-Banach.

****** Punto 6
Sale desde la $T$.

***** Ejercicio 4
#+begin_statement
Fijado $n \in \mathbb{N}$, probar que existe un funcional lineal y continuo $f$ en
${\cal C}[0,1]$ tal que $f(p) = p'(0)$ para todo polinomio $p$ de grado menor o igual
que $n$. Probar que no existe un funcional lineal y continuo $f$ en ${\cal C}[0,1]$
tal que $f(p) = p'(0)$ para todo polinomio $p$.
#+end_statement

Fijado $n \in \mathbb{N}$ podemos crear una base del subespacio de polinomios
de grado menor o igual que $n$ y definir un $f$ sobre ella que cumple
lo pedido. Por Hahn-Banach, lo extenderemos a todo ${\cal C}[0,1]$. Es decir,

\[ \{1,x,x+x^2,x+x^3,\dots,x+x^n\} \overset{f}\longrightarrow \{0,1,1,\dots,1\}\]

Supongamos que existiera el funcional que lo cumple para todo polinomio.
Comprobamos que no es continuo, ya que si lo fuera debería dejar acotada
la bola unidad. Sin embargo tenemos,

\[ \frac{d}{dx}(x-1)^n|_{x=0} = n\]

Mientras que $(x-1)^n \leq 1$ para $x \in [0,1]$; lo que nos da $\|(x-1)^n\| \leq 1$.

***** Ejercicio 5
#+begin_statement
Sean $X$ un espacio normado y $M$ un subespacio vectorial de $X$. Probar que 
para cada $T \in L(M,l_\infty)$, existe $S \in L(M,l_\infty)$ tal que $S|_M = T$ y $\|S\| = \|T\|$.
#+end_statement

Si aplico la extensión equinórmica a cada una de las $\pi_i \circ T$, obtenemos
funciones $S_i \in X^\ast$ que extienden $T$ y tienen su misma norma. Ahora, la
función $S(x_1,x_2,\dots) = (S_1(x_1),S_2(x_2),\dots)$ es continua y lineal por serlo por
componentes; su restricción a $M$ es trivialmente $T$, y además, su
norma debe ser:

\[ \|S\| = \max\{ (S_1(x_1),S_2(x_2),\dots) \mid x \in B_X\} 
         = \max\{ \|S_1\|, \|S_2\|, \dots\} = \|T\| \]

***** Ejercicio 6
#+begin_statement
Sean $A$ y $B$ subconjuntos no vacíos, abiertos, convexos y disjuntos de un 
espacio normado $X$. Probar que existen $f \in X^\ast$ con $\|f\| = 1$ y $\alpha \in \mathbb{R}$ tales
que $Re(f(a)) < \alpha < Re(f(b))$ para todo $a \in A$ y $b \in B$. Mostrar con un ejemplo
que, en general, no es posible encontrar $f$ tal que 
$\sup Re(f(A)) < \inf Re(f(B))$.
#+end_statement

Por el lema de separación de convexos tenemos que existen con
$\|f\|$ no necesariamente $1$. Dividiendo por la norma obtenemos el $f$
buscado.

Podemos tomar $A$ y $B$ como los dos semiplanos de $\mathbb{R}^2$ dados por
$\{x > 0\}$ y por $\{x < 0\}$. Por continuidad de $f$ se tendría que:

$\sup Re(f(A)) \geq f(0) \leq \inf Re(f(B))$

Por lo que se tendría la igualdad.
**** 3. Teoremas fundamentales
***** Ejercicio 2
#+begin_statement

#+end_statement
***** Ejercicio 3
#+begin_statement
Sean $X$ e $Y$ espacios de Banach y $T : X\longrightarrow Y$ una aplicación lineal y 
continua. Probar que $T$ es inyectiva y $T(X)$ es cerrado en $Y$ si y sólo
si, existe $m > 0$ tal que $\|T(x)\| \geq m \|x\|$ para todo $x \in X$.
#+end_statement

****** TODO Primera implicación
Si $T$ es inyectiva y además $TX$ es cerrado en $Y$, entonces tenemos
que es un monomorfismo topológico.

Si tomamos $\| x \|_2 = \|T x\|$, podemos observar que es norma porque cumple
la desigualdad triangular y la inyectividad nos da la condición en
$0$.

****** Segunda implicación 
Si tenemos que se cumple lo segundo, el núcleo es trivial porque
para todo $x \neq 0$, se tiene $\|T(x)\| \geq m \|x\| > 0$. Es inyectiva.

Ahora, como $T$ es inyectiva la aplicación $T : X \longrightarrow TX$ es
biyectiva, luego es isomorfismo topológico por el teorema de los
isomorfismos de Banach. Por el teorema del homomorfismo de
Banach, $TX$ es cerrado.

***** Ejercicio 4
#+begin_statement
Sea $M$ un subespacio cerrado de $l_p$ y de $l_q$. Probar que las normas inducidas
en $M$ por $l_p$ y $l_q$ son equivalentes.
#+end_statement

Tenemos $M$ un espacio normado y cerrado dentro de Banach, luego Banach.
Dentro de este espacio podemos usar equivalencia de normas en espacios
de Banach para tener que ambas son equivalentes a la norma inducida por
la norma del máximo.

\[ \| x\|_p 
= \sqrt[p]{\sum^\infty x_i^p} 
\geq \sqrt[p]{\max\{x_i\}^p}
= \| x\|_\infty \]

***** Ejercicio 5
#+begin_statement
Sean $X,Y$ espacios de Banach, y $A \subset Y^\ast$ tal que $A$ separa los puntos de $Y$.
Probar que si $T : X \longrightarrow Y$ es una aplicación lineal tal que $f \circ T \in X^\ast$ para
todo $f \in A$, entonces $T$ es continua.
#+end_statement

Comprobaremos que la gráfica de $T$ es cerrada, y por teorema de la gráfica
cerrada, tendremos que es continua. Sean $(x_i,Tx_i) \to (x,y)$; si fueran
distintos tendríamos que existe alguna función en $A$ que separe $f(y) \neq f(Tx)$.

Pero como $f \circ T$ es continua y $f$ es continua, tenemos:

\[ f(T(x_i)) \longrightarrow f(T(x))\]
\[f(Tx_i) \to f(y)\]

Por lo que deben ser iguales, contraviniendo separación.

***** Ejercicio 6
#+begin_theorem
Sea $X$ un espacio de Banach real. Dada una aplicación lineal 
$T: X \longrightarrow L_1([0,1])$ se considera, para cada $A \subset [0,1]$ medible, el funcional
lineal $T_A : X \longrightarrow \mathbb{R}$ definido por:

\[ T_A(x) = \int_A T(x)\]

Probar que si $T_A \in X^\ast$ para todo $A \subset [0,1]$ medible, entonces $T$ es continua.
#+end_theorem

****** Familia de funcionales que separan
Definimos $i_A \in L_1[0,1]^\ast$ para cualquier $A \subset [0,1]$ medible como:

\[ i_A(f) = \int_A f \]

Y comprobamos que separa las funciones de $L_1[0,1]$, ya que si dos funciones
integran igual en cualquier conjunto medible, su diferencia integra $0$ en
todo conjunto medible. Cuando esto ocurre, si fuera distinta de $0$ en un
conjunto de medida no nula, sería mayor que algún $\varepsilon$ en un conjunto de medida
no nula, luego su integral no sería nula.

****** Desarrollo
Ahora aplicamos el ejercicio anterior, siendo $i_A$ la familia que separa
los puntos de $L_1[0,1]$. Como $i_A \circ T$ son todas lineales continuas, entonces
$T$ es continua.

***** Ejercicio 7
#+begin_statement
Sean $X$ un espacio de Banach sobre $\mathbb{K}$ e $I$ un conjunto no vacío. Dada una
aplicación lineal $T: X \longrightarrow l_\infty(I)$ se considera, para cada $i \in I$, el funcional
lineal $T_i : X \longrightarrow \mathbb{K}$ definido por:

\[ T_i(x) = T(x)(i)\]

Probar que si $T_i \in X^\ast$ para todo $i \in I$, entonces $T$ es continua.
#+end_statement

****** Familia de funcionales que separan
Llamamos $e_i \in l_\infty(I)^\ast$ a los funcionales lineales continuos siguientes,
definidos para cada $i \in I$:

\[ e_i(x) = x(i) \]

Trivialmente, si $x \neq y$, deben ser distintas en algún $x(i) \neq y(i)$.

****** Aplicación del ejercicio anterior
Aplicamos el [[*Ejercicio 5][ejercicio anterior]] sabiendo $l_\infty(I)$ de Banach. Como
$e_i \circ T$ es siempre continua, se tiene $T$ continua.

***** Ejercicio 8
#+begin_statement
Sean $X$ un espacio de Banach real y $T : X \longrightarrow C([0,1],\mathbb{R})$ una aplicación
lineal. Se considera, para cada $n \in \mathbb{N} \cup \{0\}$, el funcional lineal 
$T_n : X \longrightarrow \mathbb{R}$ definido por:

\[ T_n(x) = \int_0^1 t^n T(x)(t) dt\]

Probar que si $T_n \in X^\ast$ para todo $n \in \mathbb{N} \cup \{0\}$, entonces $T$ es continua.
#+end_statement

****** Separación
Definimos los $e_n$ para cada natural como:

\[ e_n(f) = \int_0^1 t^n f(t) dt\]

Si una función fuera nula bajo todos los $e_n$ debería ser ortogonal
a todos los polinomios, que son densos en $C([0,1],\mathbb{R})$; por lo que
debería ser $0$ casi por doquier.

***** Ejercicio 9
#+begin_statement
Sean $X$ un espacio de Banach, $A \subset X$ tal que $X = \overline{Lin(A)}$, y $\{f_n\}$ una
sucesión de elementos de $X^\ast$. Probar que equivalen:

 1. $\{f_n(x)\} \longrightarrow 0$ para todo $x \in X$
 2. $\sup \{ \|f_n\| \mid n \in \mathbb{N} \} < \infty$ y $\{f_n(a)\} \longrightarrow 0$ para todo $a\in A$.
#+end_statement

****** Primera implicación
Los $f_n$ forman una familia de operadores acotada puntualmente. Aplicando
el Teorema de Banach-Steinhaus a $X$ Banach, sabemos que debe estar 
acotada. Particulariza para los elementos de $a \in A$.

****** Segunda implicación
La convergencia a cero se mantiene por combinaciones lineales finitas,
así que se tiene para cualquier $a \in Lin(A)$. Ahora, para $b \in \overline{Lin(A)}$, 
sea $a_n \longrightarrow b$; tenemos:

\[ \|f_n(b)\| 
\leq \|f_n(b - a_m)\| + \|f_n(a_m)\|
\leq M \|b - a_m\| + \|f_n(a_m)\| \to 0
\]

Puedo tomar un $m$ que haga suficientemente pequeño el primer sumando
y luego tomar un $n$ que haga suficientemente pequeño el segundo.

***** Ejercicio 10
#+begin_statement
Sea $\{x_n\}$ una sucesión de escalares tal que la serie $\sum x_n y_n$ es convergente
para toda sucesión $\{y_n\} \in c_0$. Probar que $\{ x_n \} \in l_1$.
#+end_statement

Definimos los funcionales $f_n \in c_0^\ast$ tales que:

\[ f_n(\{y_i\}) = \sum^n_{k=0} |x_k|y_k \leq \sum^\infty_{k=0} x_k \left(y_k \frac{x_k}{|x_k|} \right)\]

Donde usamos que si $y_k$ es convergente a $0$ también lo será si la 
multiplicamos por escalares de valor absoluto $1$.

Como están acotados puntualmente, se tiene por Banach-Steinhaus que están
acotados. Esto es:

\[ \sup\left\{ \sum^n_{k=0} |x_k|y_k \middle| \|\{y_i\}\|_\infty = 1 \right\} 
= M < \infty\]

Y ahora, tenemos que las sucesiones con los $n$ primeros términos iguales
a $1$ y el resto nulos, están en la bola unidad y hacen que:

\[ \sum^n_{k=1} |x_k| \leq M < \infty\]

Dando así,

\[ \sum^\infty_{k=1} |x_k| < \infty\]

***** Ejercicio 11
#+begin_statement
Sea $\{x_n\}$ una sucesión de escalares tal que la serie $\sum x_ny_n$ es convergente 
para toda sucesión $\{y_n\} \in l_1$. Probar que $\{x_n\} \in l_\infty$.
#+end_statement

Tenemos funcionales $f_n \in l_1^\infty$ definidos como:

\[ f_n(\{ y_n \}) = \sum_{k=0}^n x_ky_k \leq \sum_{k=0}^\infty x_ky_k < \infty \]

Que por estar acotados puntualmente y ser $l_1$ un espacio de Banach, se
tiene por Banach-Steinhaus que están acotados. Esto es:

\[ \sup\left\{ \sum^n_{k=0} x_ky_k \middle| \|\{y_i\}\|_\infty = 1 \right\}
= M < \infty\]

En particular, si tomamos $g_i$ sucesiones con todos los elementos
nulos pero $g_{ii} = \frac{\overline{x_i}}{|x_i|}$, como $g_i \in \mathbb{S}_{l_\infty}$ tenemos que:

\[ |x_i| < \| f_n(g_n) \| \leq M \]

Teniéndose así que $|x_i|$ está acotada.

***** Ejercicio 12
#+begin_statement
Sea $\{x_n\}$ una sucesión de escalares tal que la serie $\sum x_ny_n$ es
convergente para toda sucesión $\{y_n\} \in l_p$ $(1<p<+\infty)$. Probar
que $\{x_n\} \in l_q$, siendo $\frac{1}{p} + \frac{1}{q} = 1$.
#+end_statement

Tomamos los funcionales $f_n \in l_p^\ast$ definidos por:

\[f_n(\{y_k\}) = \sum_{k=0}^n x_ky_k < \sum_{k=0}^\infty x_ky_k \]

Que están acotados y vienen de espacio de Banach, por lo que, por
Banach-Steinhaus, se tiene que:

\[ \sup\left\{ \|f_n\|_p \right\}
= M < \infty\]

Por desigualdad de Hölder, tenemos una cota para la norma de los
operadores, sea $\{y_i\} \in S_{l_p}$:

\[ \|f_n\| \leq \sum^{n}_{k=0} |x_k||y_i| \leq \left(\sum^n_{k=0} |x_k|^q\right)^{1/q} \| \{y_i\}\|_p
 = \left(\sum^n_{k=0} |x_k|^q\right)^{1/q} \]

Y comprobamos que se realiza tomando el vector siguiente:

\[
\frac{1}{\left( \sum^n_{k=0} |x_k|^q \right)^{1/p}}
( |x_1|^{q-1}, |x_2|^{q-1}, \dots, |x_n|^{q-1}, 0,0,\dots )
\]

Que tiene imagen de norma:

\[ \left( \sum_{k=0}^n |x_k|^q  \right)^{1/q}\]

Mientras que él tiene norma $1$.

**** 4. Espacios de Hilbert I
***** Ejercicio 2
#+begin_statement
Demuéstrese que si $H$ es un espacio prehiilbertiano respecto de dos productos
escalares $\langle \cdot,\cdot\rangle_1$ y $\langle \cdot,\cdot\rangle_2$ entonces ambos productos coinciden salvo conjugación
ssi sus normas asociadas coinciden.
#+end_statement

****** Si coinciden, coinciden las normas
Si llamamos a las normas $\|\cdot\|_1$ y $\|\cdot\|_2$, tenemos:

\[\|u\|_1 = \sqrt{\langle u,u \rangle_1} 
= \sqrt{\overline{\langle u,u \rangle_2}} = \|u\|_2\]

Donde usamos que el producto escalar es hermítico.

****** Si coinciden las normas, coinciden
# ¿Por qué salvo conjugación?
Por la identidad de polarización, tenemos:

\[
\langle u,v \rangle_1 = 
\frac{1}{4}\left( \|u+v\|^2-\|u-v\|^2+i\|u+iv\|^2-i\|u-iv\|^2 \right) =
\langle u,v \rangle_2
\]

***** Ejercicio 3
#+begin_statement
Sea $H$ un espacio prehilbertiano real. Probar que si $\|u+v\|^2 = \|u\|^2+\|v\|^2$,
entonces $u$ y $v$ son ortogonales. ¿Se verifica esta propiedad en todo espacio
prehilbertiano complejo?
#+end_statement

En un espacio real, esto implica $2\langle u,v \rangle = 0$. En un espacio complejo,
sólo tenemos $\langle u,v \rangle + \langle v,u \rangle = 0$, así que podemos buscar un ejemplo en el que
no se cumpla:

\[2 = \|1+i\|^2 = \|1\|^2 + \|i\|^2 \]

Pero $\langle 1,i \rangle = -i \neq 0$.

***** Ejercicio 4
#+begin_statement
Sea $H$ un espacio prehilbertiano sobre $\mathbb{{K}}$. Sean $u,v \in H$ y $\alpha \in \mathbb{K}$. Probar que
$u$ y $v$ son ortogonales ssi, $\|u+\alpha v\| = \|u-\alpha v\|$.
#+end_statement

Sea $\alpha \neq 0$, tenemos que $u \perp v \iff u \perp \alpha v$. Así, podemos demostrar que son
ortogonales ssi $\|u+v\| = \|u-v\|$. Pero esto sólo ocurre en $\mathbb{R}$, donde el ser
hermítico da simetría al producto escalar, en $\mathbb{C}$ tenemos un contraejemplo
trivial en $u=1,v=i$, que no son ortogonales.

***** Ejercicio 15
#+begin_statement
Demostrar que el espacio ${\cal C}[-1,1]$ es suma directa del espacio de las funciones
pares y del espacio de las funciones impares. ¿Son ortogonales dichos 
subespacios? Encontrar los complementos ortogonales de los siguientes 
conjuntos:

  - las funciones que se anulan en $[-1,0]$.
  - las funciones que se anulan en $x = 0$.
#+end_statement

****** Es suma directa
Sea $f \in {\cal C}[-1,1]$. Podemos escribirla como:

\[
f(x) = \frac{f(x) + f(-x)}{2} + \frac{f(x) - f(-x)}{2}
\]

Siendo cada sumando par e impar. Supongamos un $f$ par e impar, entonces se
tiene $f(x) = f(-x) = -f(-x) = 0$.

****** Es ortogonal
Usando que el producto de par e impar es impar:

\[
\int_{-1}^1 f(x)g(x) dx = \int_0^1 fg - \int_0^1 fg = 0x
\]

****** Complemento de las anuladas en [-1,0]
******* Sólo son ortogonales si se anulan en [0,1]
Para cada intervalo definimos las funciones:

\[
u_{[a,b]}(x) = \left\{\begin{array}{ll} 
(x-a)\frac{2}{b-a}& \mbox{if } a \leq x \leq \frac{a+b}{2} \\
(b-x)\frac{2}{b-a}& \mbox{if } \frac{a+b}{2} \leq x \leq b \\
0 & \mbox{otherwise}
\end{array} 
\right.
\]

Una $f$ ortogonal a las que se anulan en $[-1,0]$ debe ser nula en $(0,1)$. Si
no lo fuera en $x \in (0,1)$, existiría un intervalo $[a,b] \subset (0,1)$ donde la función
preservaría el signo. Y entonces,

\[
\int f(x)u_{[a,b]}(x) \;dx \neq 0
\]

contraviniendo ortogonalidad.

******* Si se anulan en [0,1] son ortogonales
Por otro lado, una función que se anulara en $(0,1)$ sería ortogonal a
cualquiera que se anulara en $[-1,0]$.
****** Complemento de las anuladas en 0
Cualquier función ortogonal a las anuladas en $0$ debe anularse en todo $x \neq 0$.
Se tiene que si no se anulara en algún punto distinto de $0$, existiría
un intervalo $[a,b]$ en el que preservaría el signo:

\[
\int^1_{-1} f(x)u_{[a,b]}(x) \;dx \neq 0
\]

contraviniendo ortogonalidad. Debe anularse en todo punto distinto de $0$,
y, por continuidad, también en $0$.
**** 5. Espacios de Hilbert II
***** Ejercicio 1
#+begin_statement
Demostrar que un funcional lineal sobre un espacio de Hilbert es continuo si
y sólo si su núcleo es cerrado. ¿Es cierto esto para espacios de Banach en
general?
#+end_statement
****** Si es continua, tiene núcleo cerrado
Un funcional lineal continuo debe tener siempre un núcleo cerrado 
trivialmente.

****** TODO Si tiene núcleo cerrado, es continua
En el caso de tener el núcleo cerrado, [[*Descomposición canónica: isomorfismo][se tiene]] $\widehat{T} : H/\ker(T) \cong Im(T)$. 
Entonces $H/\ker(T)$ es de dimensión finita y un isomorfismo entre espacios 
de dimensión finita es continuo.

Por último $T = \widehat{T} \circ \pi$.

****** Otra solución
Viendo que hay suma topológica $H = \ker(f) \oplus \mathbb{K}x_0$, ya que podemos escribir:

\[ u = (u - f(u)x_0) + f(u)x_0\]

exigiendo sólo $f(x_0) = 1$.

***** Ejercicio 2
#+begin_statement
Sean $f,g \in l_2 \longrightarrow \mathbb{K}$ los funcionales dados por $f(x) = \alpha_3+\alpha_4$ y $g(x) = 4\alpha_5$,
para cada $x = \{\alpha_n\}_{n \in \mathbb{N}} \in l_2$. Demostrar que son lineales y continuos. 
¿Son inyectivos? Calcular $\|f\|$ y $\|g\|$. Determinar $v,w \in l_2$ tales que
$f = \langle \cdot,g \rangle$ y $g = \langle \cdot,w \rangle$. Dado $n \in \mathbb{N}$, ¿define $h_n(x) = \sum_{k=1}^n \alpha_k$ un funcional
lineal de $l_2$?; ¿y $h(x) = \sum^\infty_{k=1} \alpha_k$?
#+end_statement

****** Continuas
Son trivialmente lineales. Son continuos porque están acotados ambos
en la bola unidad. Sabemos que debe tenerse $|\alpha_i| \leq 1$ para que esté en la
bola unidad, porque en caso contrario, la suma de cuadrados sería mayor
que $1$:

\[ |f(x)| = |\alpha_3+\alpha_4| \leq 2\]
\[ |g(x)| = 4|\alpha_5| \leq 4\]

Son trivialmente no inyectivas.

De otra forma, las proyecciones, producto y suma son continuas.

****** Calcular la norma
******* Primer caso
Tenemos por desigualdad cuadrática-aritmética que $|\alpha_3| + |\alpha_4| \leq 2\sqrt{\frac{1}{2}}$. 
Y se alcanza la cota con la sucesión $f(0,0,0,\sqrt{1/2},\sqrt{1/2},0,\dots)$.

Podemos ver además que $f = \langle \cdot,(0,0,0,1,1,0,\dots)\rangle$.

******* Segundo caso
Tenemos por $g(0,0,0,0,1,0,\dots) = 4$ que la cota anterior era correcta.
Es además el vector por el que multiplicar para tener $g = \langle \cdot,w \rangle$.

****** Otros funcionales
******* Caso finito
Tenemos un funcional que es lineal trivialmente y que es continuo por
acotarse en la bola unidad por la desigualdad aritmético-cuadrática:

\[
\left| \sum^n_{k=1} \alpha_k \right| \leq
\sum_{k=1}^n |\alpha_k| \leq
n \sqrt{\frac{1}{n}\sum^n_{k=1} |\alpha_n|^2} \leq \frac{n}{\sqrt{n}}
\]

******* Caso infinito
No tiene ni por qué estar definido, la sucesión $\{1/n\}$ es cuadrado 
sumable pero no es sumable.

***** Ejercicio 3
#+begin_statement
Sea $f : \mathbb{C}^3 \longrightarrow \mathbb{C}$ el funcional $f(\alpha_1,\alpha_2,\alpha_3) = 3i\alpha_1 + 2\alpha_2 - \alpha_3$. Demostrar que $f$
está en el dual topológico de $\mathbb{C}^3$. Calcular $v \in \mathbb{C}^3$ tal que $f = \langle \cdot,v \rangle$ y
determinar $\|f\|$.
#+end_statement

Es suma y producto por escalares de las proyecciones, así que es continua
y lineal. Comprobamos $f = \langle \cdot,(-3i,2,-1) \rangle$, y por Cauchy-Swarchz sabemos
la norma será:

\[\|f\| = \|(3i,2,-1)\| = \sqrt{9+4+1} = \sqrt{14}\]

***** Ejercicio 4
#+begin_statement
#+end_statement

***** Ejercicio 5
#+begin_statement
Sea ${\cal P}(x)$ el espacio vectorial de los polinomios $p(x) :\mathbb{R} \longrightarrow \mathbb{R}$ con el 
producto interno dado por:

\[
\langle p,q \rangle = \int_0^1 p(t)q(t)\;dt
\]

Dar un ejemplo de un funcional lineal y continuo $\varphi : {\cal P}(x) \longrightarrow \mathbb{R}$ para el que
no exista $v(x) \in {\cal P}(x)$ tal que $\varphi = \langle \cdot,v \rangle$. ¿Contradice este hecho el teorema
de Riesz-Fréchet?
#+end_statement

Un ejemplo es:

\[
\varphi(p) = \int^1_0 e^tp(t) \;dx
\]

Es trivialmente lineal, está acotado en la bola unidad y por tanto es
continuo, de hecho, se tiene:

\[
\left| \int^1_0 e^tp(t) \;dx \right| \leq
\int^1_0 |e^tp(t)| \;dx \leq
e\int^1_0 |p(t)| \;dx = e \langle p,1 \rangle \leq e\|p\| \]

Sin embargo, no puede tenerse $\varphi = \langle \cdot,v \rangle$, porque si se tuviera, se tendría
en el espacio de las funciones un polinomio que contravendría Riesz-Fréchet:

\[\int_0^1(e^t-v(t)) p(t) \;dt = 0
\]

Implicando que $e^t-v(t)$ es ortogonal a todos los polinomios. Como los
polinomios son densos en las continuas, esto implica que es ortogonal
a todas las funciones y por tanto $0$. $e^t = v(t)$, y no tenemos un polinomio
que cumpla eso.

No contradice Riesz-Fréchet por no ser el espacio de los polinomios 
completo.

***** Ejercicio 6
#+begin_statement
Considérese el espacio complejo $C[0,1]$ dotado con la norma del máximo.
Sean $\varphi_1,\varphi_2,\varphi_3$ los funcionales dados por:

\[\varphi_1(f) = \int_0^1 x|f(x)|\;dx \]

\[\varphi_2(f) = \int^1_0 f(x)\;dx\]

\[ \varphi_3(f) = f\left(\frac{1}{2}\right)
\]

respectivamente, para $f \in C[0,1]$. ¿Cuáles de ellos son funcionales lineales
y continuos? Cuando lo sean, determinar su norma. Repetir el ejercicio
considerando la norma dada por $\|f\| = \int_0^1 |f(x)|^2\;dx$. ¿En qué casos existe
$g \in C[0,1]$ tal que el funcional dado es de la forma $\langle \cdot,g \rangle$?
#+end_statement

****** Con la norma del máximo
El primero no es lineal porque no cumple $\varphi_1(if) = i\varphi_1(f)$. El segundo y
el tercero son trivialmente lineales. Se comprueban continuos acotándolos
por la norma en la bola unidad. Calculamos su norma viendo que cumplen
esa acotación en la constante:

\[\varphi_2(1) = 1;\quad \varphi_3(1) =1;\]

****** Con la norma euclídea
Por Hölder tenemos un funcional acotado en la bola unidad:

\[
\left| \int^1_0 f(x)\;dx\right| \leq
\int^1_0 |f(x)|\;dx \leq
\sqrt{\int^1_0 |f(x)|^2\;dx}
\]

Pero el otro no está acotado; podemos tomar una familia $\psi_n$ de funciones
que sean nulas excepto en $[\frac{1}{2} - \frac{1}{2n^2}, \frac{1}{2} + \frac{1}{2n^2}]$, donde crecen hasta llegar
a $\psi_n\left(\frac{1}{2}\right) = n$ y decrecen. Las podemos construir con líneas considerando
su parte imaginaria nula. Tenemos a $\varphi_3(\psi_n) = n$, arbitrariamente grande, 
mientras:

\[
\int_0^1 |\psi_n(t)|^2 \;dt \leq \frac{1}{n^2}n^2 = 1
\]

****** Aplicamos Fréchet en el resto de casos
Para tener que $\varphi_2 = \langle \cdot,1 \rangle$.

***** Ejercicio 7
#+begin_statement
Sea $\varphi : L^2(\mathbb{R}) \longrightarrow \mathbb{R}$ el funcional dado por $\varphi(g) = \int_0^1 3xg(x)\;dx$. Demostrar
que $\varphi$ es un funcional lineal y acotado. Determinar $f \in L^2(\mathbb{R})$ tal que
$\varphi = \langle \cdot,f \rangle$ y calcular $\|f\|$.
#+end_statement

Es lineal trivialmente. Podemos acotarlo en la bola unidad como:

\[
\left|
\int^1_0 3xg(x)\;dx
\right| \leq 
3 \int^1_0 |x||g(x)|\;dx \leq 
3\sqrt{\int_0^1 |g(x)|^2\;dx} \leq
3\sqrt{\int_{-\infty}^\infty |g(x)|^2\;dx} \leq 3
\]

Por otro lado, tenemos que $\varphi = \langle \cdot,\psi \rangle$, siendo:

\[\psi = \left\{\begin{array}{ll} 
3x& \mbox{if } 0 \leq x \leq 1  \\
0 & \mbox{otherwise }  
\end{array} 
\right.\]

La norma de $f$ será la de $\psi$, donde:

\[\|f\| = \int_{-\infty}^\infty \psi(x)\;dx = \frac{3}{2}\]

***** Ejercicio 10
#+begin_statement
Demostrar que los siguientes conjuntos forman una base ortonormal del 
espacio de Hilbert real $L^2[0,\pi]$.

  1. $B := \{ e_n \mid n \in \mathbb{N}_0\}$, donde $e_0 = \frac{1}{\sqrt{\pi}}$ y $e_n = \frac{\sqrt{2}}{\sqrt{\pi}} cos (nx)$.
  2. $B := \{ e_n \mid n \in \mathbb{N}\}$ donde $e_n = \frac{\sqrt{2}}{\sqrt{\pi}} sin(nx)$.

Obtener una base ortonormal del espacio de Hilbert complejo $L^2[0,\pi]$.
#+end_statement

****** Primer punto
******* Generan el espacio
Sabemos que los polinomios son densos en el espacio de funciones
continuas en $[0,1]$, y que la función arcocoseno es una biyección en
ese intervalo. Dado un $f$, tenemos un polinomio $p$ que aproxima a
la función $f \circ arccos$:

\[ 
\left\| f(x) - p(cos(x)) \right\|_2 \leq
\left\| f(x) - p(cos(x)) \right\|_\infty =
\left\| f(arccos(x)) - p(x) \right\|_\infty
\]

Ahora, un polinomio sobre $cos(x)$ puede reescribirse como una 
combinación lineal de los vectores de la base:

\[ cos(nx)cos(mx) = 
\frac{1}{2}\Big( cos((n+m)x) + cos((n-m)x)
\Big)\]

De esta forma, la clausura del espacio que generan los cosenos es
el espacio de las continuas. Si además las continuas son densas
en $L_2[0,1]$, tenemos lo pedido.

******* Son una familia ortonormal
Como además son familia ortonormal, forman una base ortonormal del 
espacio. Cuando $m \neq n$:

\[
\int_0^\pi cos(nx)cos(mx) \;dx = 
\frac{1}{n+m}[sen((n+m)x)]^\pi_0 +
\frac{1}{n-m}[sen((n-m)x)]^\pi_0 = 0
\]

Y cuando $m = n$, se tiene:

\[
\int_0^\pi cos(nx)^2 \;dx
=
\frac{1}{2}\int_0^\pi cos(2nx) - 1 \;dx
= \frac{\pi}{2}
\]

****** Segundo punto
******* Generan el espacio
Usaremos la derivación. Por el teorema anterior, tenemos un $p\circ cos$ que 
aproxima con precisión $\varepsilon$ a la siguiente función:

\[
g(x) = \left\{\begin{array}{ll} 
\frac{f(x)}{sin(x)} & \mbox{if } x \in [0+\varepsilon,\pi+\varepsilon]  \\
\psi(x) & \mbox{otherwise } 
\end{array} 
\right.
\]

Donde $\psi(x)$ la podemos construir con rectas para que haga continua
a la función e integre menos de $\varepsilon$, algo como:

[[./images/epsilonint.png]]

Sea una primitiva suya el polinomio $P$:

\[\begin{aligned} 
\|f(x) - \partial (P\circ cos)(x))\|_2 
&\leq
K + \int_{0-\varepsilon}^{\pi-\varepsilon} 
\left|f(x) - \partial (P\circ cos)(x) \right|^2\;dx \\
&\leq 
K + \int_{0-\varepsilon}^{\pi-\varepsilon} 
\left|\frac{f(x)}{sin(x)} - \frac{\partial (P\circ cos)(x)}{sin(x)} \right|^2\;dx \\
&=
K + \int_{0-\varepsilon}^{\pi-\varepsilon} 
\left|\frac{f(x)}{sin(x)} - p(cos(x)) \right|^2\;dx < \varepsilon + K\\
\end{aligned}\]

Por otro lado, tenemos que:

\[\begin{aligned}
K &= 
\int_0^\varepsilon |f(x) - \partial(P \circ cos)(x)|^2 \;dx
\\&\leq
\int_0^\varepsilon |f(x)|^2\;dx + \int_0^\varepsilon |sin(x)p(cos(x))|^2\;dx
\\&\leq
\int_0^\varepsilon |f(x)|^2\;dx + \int_0^\varepsilon |p(cos(x))|^2\;dx
\\&\leq 
\varepsilon \|f\|_\infty + \int_0^\varepsilon |p(cos(x)) - \psi(x)|^2\;dx + \int_0^\varepsilon |\psi(x)|^2\;dx
\\&\leq
\varepsilon \|f^2\|_\infty + \varepsilon + \varepsilon
\end{aligned}\]

Como $\varepsilon$ es arbitrario, se tiene lo pedido. Nótese que $\partial (P \circ cos)$ es la
derivada de una función polinómica en los cosenos que se puede escribir
como combinación lineal de la base anterior. Y nótese que la derivada
lleva cada elemento de la base anterior en uno de la nueva.

******* Son una familia ortonormal
Por último, como son ortonormales, forman una base ortonormal:

\[
\int^\pi_0 sin(nx)sin(mx) \;dx
= 
\int^\pi_0 cos((n-m)x) - cos((n+m)x)\;dx = 0
\]

****** Tercer punto
Toda función puede escribirse como:

\[
f(x) = \Re(f(x)) + i \Im(f(x))
\]

Y cada una de esas partes puede aproximarse como suma de cosenos o de
senos. Así, cualquier base ortonormal del espacio real que hemos 
construido anteriormente es también base del espacio complejo.

***** Ejercicio 11
#+begin_statement
Demostrar que:

\[B:= \left\{
e_0(x) = \frac{1}{\sqrt{2\pi}},\;
e_n(x) = \frac{1}{\sqrt{\pi}} cos(nx),\;
e_{-n}(x) = \frac{1}{\sqrt{\pi}} sin(nx) 
\mid n \in \mathbb{N}
\right\}\]

define una base ortonormal en un espacio de Hilbert real $L^2[-\pi,\pi]$.
#+end_statement

****** Es ortogonal
Comprobamos integrando la ortonormalidad de la base.

****** Genera el espacio
Las funciones pares pueden aproximarse por la misma función que las
aproximaba en $[0,\pi]$ con los cosenos; las impares pueden aproximarse
por la función que las aproximaba en $[0,\pi]$ con senos.

Toda función es suma de par y de impar.

\[f(x) = \frac{f(x)-f(-x)}{2}+\frac{f(x)+f(-x)}{2}\]

Así que toda función puede aproximarse por suma de senos y cosenos.

***** Ejercicio 12

***** Ejercicio 13
#+begin_statement
En el espacio $L^2[-\pi,\pi]$, en función de la base de Hilbert dada en el 
ejercicio 11, calcular el desarrollo en serie de Fourier de la función
$f(x) = |x|$ y deducir mediante la indentidad de Parseval que:

\[\sum^\infty_{n=1} \frac{1}{(2n-1)^4} = \frac{\pi^4}{96}\]
#+end_statement

****** Desarrollo en serie de Fourier
Usando que es función par

\[
\int_{-\pi}^\pi |x| \frac{1}{\sqrt{2\pi}} \;dx = \frac{\pi^2}{\sqrt{2\pi}}
\]

Usando que es una función par e integrando por partes:

\[
\int_{-\pi}^\pi |x| \frac{1}{\sqrt{\pi}} cos(nx) \;dx
=
\frac{2}{\sqrt{\pi}}\int_{0}^\pi x cos(nx) \;dx 
=
\frac{2}{\sqrt{\pi}n^2}((-1)^n-1)
\]

Usando que es una función impar:

\[
\int_{-\pi}^\pi |x| \frac{1}{\sqrt{\pi}} sin(nx) \;dx 
=
0
\]

****** Identidad de Parseval
Calculamos la norma de la función:

\[
\int_{-\pi}^\pi x^2 \;dx = \frac{2}{3} \pi^3
\]

Y tenemos finalmente, sumando cuadrados de los productos escalares
anteriores:

\[\begin{aligned}
\frac{\pi^3}{2} + \sum_{i=0}^\infty \frac{4}{\pi n^4}((-1)^n-1)^2
&=
\frac{2}{3} \pi^3
\\
\sum_{i=0}^\infty \frac{4}{n^4}((-1)^n-1)^2
&=
\frac{1}{6} \pi^4
\\
\sum_{i=1}^\infty \frac{1}{(2n-1)^4}
&=
\frac{1}{96} \pi^4
\end{aligned}\]

Considerando sólo los términos impares.

***** TODO Ejercicio 14
#+begin_statement
En el espacio $L^2[-\pi,\pi]$, en función de la base de Hilbert dada en el 
ejercicio 11, obtener el desarrollo en serie de Fourier de la función
$f(x) = x^2$. Usar dicho desarrollo para calcular:

\[\sum_{n=1}^\infty \frac{1}{n^2}\] y \[\sum_{n=1}^\infty \frac{1}{n^4}\]
#+end_statement

***** TODO Ejercicio 18
#+begin_statement
Encontrar $min_{\alpha,\beta,\gamma \in \mathbb{C}} \int_{-1}^1 |x^3-\alpha-\beta x -\gamma x^2|^2 \;dx$.
#+end_statement

Buscar la mejor aproximación en el espacio de los polinomios de grado
menor que 2. Hay que buscar primero una ortonormalización de la base
con Gram-Schmitd

**** 6. Espacios de Hilbert III
***** Ejercicio 1
#+begin_statement
Sea $H$ un espacio de Hilbert y $P \in L(H)$. Demostrar que las siguientes
afirmaciones son equivalentes:

  1. $P$ es la proyección ortogonal de $H$ sobre un subespacio cerrado $M$.
  2. $P$ es idempotente y autoadjunto.
  3. $P$ es idempotente y $H = P(H) \oplus (I-P)(H)$ siendo los subespacios
     $P(H)$ y $(I-P)(H)$ ortogonales.
  4. $P$ es idempotente y $P(H)^\perp = \ker P$.
#+end_statement

****** Primera implicación
Trivialmente idempotente. Es autoadjunto por tenerse:

\[\begin{aligned}
\langle u,pv \rangle &= \langle pu,v \rangle \\
\langle u-pu,pv \rangle &= \langle pu,v - pv \rangle \\
0 &= 0
\end{aligned}\]

Donde usamos que $pu \in M$, pero $u - pu \in M^\perp$.

****** Segunda implicación
Tenemos $u = p(u) + (u - p(u))$ y son ortogonales por:

\[\langle p(u),v-p(v) \rangle = \langle u , p(v-p(v)) \rangle = 0\]

****** Tercera implicación
Comprobamos que son iguales $(I-P)(H) = \ker P$. Tenemos que $g = g - p(g)$
para un caso y $p(g -p(g)) = p(g)-p(g) = 0$ para el otro.

****** Cuarta implicación
Es una proyección sobre $P(H)$ y es ortogonal por definición.

***** Ejercicio 2
#+begin_statement
Sea $H$ un espacio de Hilbert y $\{e_n\}$ una base ortonormal de $H$. Sea
$\{\alpha_n\}$ una sucesión acotada de números complejos y:

\[\alpha = \sup_{n \in \mathbb{N}} |\alpha_n|\]

Probar que existe un único $T\in L(H)$ tal que $Te_n = \alpha_ne_n$, para cada $n \in \mathbb{N}$,
y que $\|T\| = \alpha$. Calcular $T^\ast$ y $\|T^\ast\|$. Demostrar que $T$ es normal. ¿Qué
condición ha de cumplir la sucesión dada para que el operador $T$ sea
autoadjunto?¿y para que $T$ sea invertible?
#+end_statement

Expresando $u$ en serie de Fourier.

Autoadjunto cuando $\alpha_i = \overline{\alpha_i}$ e invertible cuando $\alpha_i \neq 0$.

***** Ejercicio 2.1
#+begin_statement
Sea $H = \mathbb{C}^3$ y sea $T \in L(H)$ el operador dado por:

\[T(\alpha_1,\alpha_2,\alpha_3) = (\alpha_1+\alpha_2,\alpha_1+\alpha_3,\alpha_3+2\alpha_1)\]

¿Es unitario?¿Es autoadjunto? Determinar el espectro de $T$.
#+end_statement

***** Ejercicio 3
#+begin_statement
Sea $H$ un espacio de Hilbert sobre $\mathbb{K}$ y $T \in L(H)$ un operador tal que
$\langle Tu,u \rangle = 0$ para cada $u \in H$. Demostrar que $T = 0$ si $\mathbb{K}=\mathbb{C}$, pero que no
puede decirse lo mismo si $\mathbb{K}=\mathbb{R}$, y buscar una condición suficiente para
que se verifique dicha propiedad en el caso real.
#+end_statement

****** Caso complejo
Desarrollando:

\[\begin{aligned}
0
&=& 
\langle T(u+v),u+v \rangle
&=&
\langle Tu,v \rangle + \langle Tv,u \rangle\\
0
&=& 
\langle T(u+iv),u+iv \rangle
&=&
(-i)\langle Tu,v \rangle + i\langle Tv,u \rangle
\end{aligned}\]

Por tanto, $\langle Tu,v \rangle = 0$ y debe tenerse $Tu = 0$.

****** Caso real
Hay contraejemplos en el caso real. En $\mathbb{R}^2$ se tiene:

\[T(x,y) = (-y,x)\]

cumpliendo lo pedido. En general, cuando se tiene $T^\ast = -T$, tenemos:

\[\langle Tu,u \rangle = -\langle u,Tu \rangle = -\langle Tu,u \rangle = 0\]

siendo una condición suficiente.

***** Ejercicio 4
#+begin_statement
Sea $H = \mathbb{C}^2$. Calcular el espectro y la norma del operador $T \in L(H)$ dado,
respectivamente, por cada una de las siguientes matrices:

  1. \[\begin{pmatrix} 0 & 1+i \\ 1 & 2+2i \end{pmatrix}\]

  2. \[\begin{pmatrix} 
     cos \theta & e^{i\phi} sen \theta \\
     e^{i\phi} sen \theta & -cos \theta
     \end{pmatrix}\]
#+end_statement

Usaremos que la [[http://math.stackexchange.com/a/586835/85067][norma de la matriz]] es la raíz del mayor valor propio
de $M\overline{M^T}$.

****** Primera matriz
Reduciendo la matriz, tenemos como valores propios:

\[\begin{aligned}
\lambda_1 &= 1+i+\sqrt{1+3i}\\
\lambda_2 &= 1+i-\sqrt{1+3i}
\end{aligned}\]

Calculamos:

\[M\overline{M^T} = 
\begin{pmatrix} 
2 & 4 \\ 4 & 9 
\end{pmatrix}\]

A la que le podemos encontrar los valores propios:

\[\lambda_1 = \frac{1}{2}(11-\sqrt{113})\]

\[\lambda_2 = \frac{1}{2}(11+\sqrt{113})\]

#+BEGIN_SRC sage
M = Matrix([[0,1+i],[1,2+2*i]])
(M*(M.transpose().conjugate())).eigenvalues()
#+END_SRC

#+RESULTS:
: [-1/2*sqrt(113) + 11/2, 1/2*sqrt(113) + 11/2]
: a^2 - 11*a + 18

****** Segunda matriz
Reduciendo la matriz, llegamos a los valores propios
$\lambda_1=1,\lambda_2 = -1$.

Y podemos aplicar lo mismo que en la anterior.

#+BEGIN_SRC sage
t,f = var('t f')
assume(t,'real')
assume(f,'real')
M = Matrix([[cos(t), e^(i*f)*sin(t)],[e^(i*f)*sin(t),-cos(t)]])
expand((M*(M.transpose().conjugate())).eigenvalues())
#+END_SRC

#+RESULTS:
: 
: [(cos(t)^2*e^(I*f) + (-I*e^(2*I*f) + I)*cos(t)*sin(t) + e^(I*f)*sin(t)^2)*e^(-I*f),
:  (cos(t)^2*e^(I*f) + (I*e^(2*I*f) - I)*cos(t)*sin(t) + e^(I*f)*sin(t)^2)*e^(-I*f)]

***** Ejercicio 5
#+begin_statement
Sea $T \in L(H)$ donde $H$ es un espacio de Hilbert de dimensión 3. 
Calcúlese el espectro de $T$ sabiendo que $T$ es autoadjunto,
que $\|T\| = 4$, que $T$ no tiene inverso, y que el rango de $T-2I$ es $2$.
#+end_statement

Sabemos que un valor propio es $2$, que otro valor propio es $0$ por no
tener inversa. Como la norma es la raíz 

***** Ejercicio 6
#+begin_statement
Sea $H$ un espacio de Hilbert complejo de dimensión $n+1$, y sea
$B = \{e_0,\dots,e_n\}$ una base ortonormal. Sea $T \in L(H)$ el operador determinado
por las igualdades:

   - \[T(e_0) = 0\]
   - \[T(e_j) = \sqrt{j} e_{j-1}\]
 
Obtener los operadores $T^\ast$ y $T^\ast T$. Probar que $T^{n+1} = 0$. Calcular el espectro
de los operadores $T$, $T^\ast$ y $T^\ast T$ así como $\|T\|$ y $\|T^\ast T\|$.
#+end_statement

La solución es:

  - $T^\ast T(e_j) = je_j$.
  - $G_p(T^\ast T) = \{0,1,\dots,n\}$.
  - $G_p(T) = \{0\}$.
  - $\|T\| = \sqrt{n}$, $\|T^\ast T\| =n$.

***** Ejercicio 7
#+begin_statement
Diagonalizar (si es posible) los operadores dados (respectivamente) por:

  1. \[\begin{pmatrix} 
     7 & -2 & 1 \\
     -2 & 10 & 2 \\
     -1 & -2 & 7
     \end{pmatrix}\]

  2. \[\begin{pmatrix} 
     2 & -2 & 3 \\
     1 & 1 & 1 \\
     1 & 3 & 1 \\
     \end{pmatrix}\]

  3. \[\begin{pmatrix} 
     2 & 2 & 1 \\
     1 & 3 & 1 \\
     1 & 2 & 2 \\
     \end{pmatrix}\]
#+end_statement
** Grupos y representaciones
*** 1. Álgebras y módulos
**** 1.1. Noción de álgebra
***** 1.1. Álgebra
Un *álgebra* sobre un cuerpo $K$ es un K-espacio vectorial dotado de una
aplicación bilineal $(\cdot) : K \times K \longrightarrow K$. La bilinealidad se expresa como:

  1. $(a+b)c = ac+bc$
  2. $a(b+c) = ab+ac$
  3. $(\alpha a)b = \alpha(ab) = a(\alpha b)$

****** Álgebra asociativa
Un álgebra es *asociativa* si $(ab)c = a(bc)$.

***** 1.2. Subálgebra
Una *subálgebra* es un subespacio vectorial de un álgebra cerrado para
el producto.

***** 1.3.a. Álgebra conmutativa
Un álgebra es *conmutativa* si $ab = ba$.

***** 1.3.b. Centro de un álgebra
Se define el *centro* de un álgebra asociativa como:

\[
Z(A) = \{c \in A \mid ac = ca,\; \forall a \in A \}
\]

***** 1.4. Ideal de un álgebra
Un subespacio vectorial de álgebra, $I \subseteq A$ es *ideal* si el producto por
cualquier elemento está en el ideal $ai,ia \in I$.

***** 1.5. Cociente por un ideal
Sobre el K-espacio vectorial cociente por un ideal $A/I$, podemos definir
una K-álgebra mediante $(a+I)(b+I) = ab+I$.

****** Buena definición
Supongamos que $a+I = a'+I$ y que $b+I = b'+I$, entonces tenemos 
que:

\[
ab- a'b' = a(b-b') - (a-a')b' \in I
\]

***** 1.6. Homomorfismos de K-álgebras
Una aplicación lineal entre álgebras $f : A \longrightarrow A'$ es homomorfismo de
K-álgebras si respeta el producto:

\[
f(ab) = f(a)f(b)
\]

****** Isomorfismo de K-álgebras
Cuando un homormofismo de K-álgebras es biyectivo, se llama *isomorfismo*
y su inversa es también homomorfismo de K-álgebras.

***** 1.7. Primer teorema de isomorfía
Si $f : A \longrightarrow A'$ es homomorfismo de K-álgebras, $\mathrm{Im} f$ es subálgebra y $\ker f$
es ideal. Además, tenemos un isomorfismo de K-álgebras canónico:

\[
\widehat f : A/\ker f \longrightarrow \im f
\]

dado por $\widehat f(a+\ker f) = f(a)$.

****** Demostración
******* La imagen es subálgebra
Trivialmente, la imagen es espacio vectorial y $f(a)f(b) = f(ab)$.

******* El núcleo es un ideal
El núcleo es subespacio vectorial y además,

\[
f(ak) = f(a)f(k) = 0 = f(k)f(b) = f(kb)
\]

para cualquier $f(k) = 0$.

******* Isomorfismo de álgebras
Comprobamos que está bien definido, ya que si $a + \ker f = b + \ker f$,
se tiene que $\widehat f(a+\ker f) - \widehat f(b + \ker f) = f(a-b) = 0$.

La función es lineal y preserva el producto por la definición de
producto con la que hemos dotado al ideal. Ahora, comprobamos que
es inyectiva por tenerse:

\[
\widehat f(a+\ker f) = 
\widehat f(b+\ker f) \implies f(a-b) =
0 \implies a-b \in I
\]

Es trivialmente sobreyectiva.

***** 1.8.a. Álgebras unitales
Una K-álgebra asociativa es *unital* si existe un neutro para el
producto.

\[
1_Aa = a = a1_A; \quad 1_A \neq 0
\]

****** Homormofisos de álgebras unitales
A los homomorfismos de álgebras unitales se les pide respetar la
unidad. Para $f : A \to B$, $f(1_A) = 1_B$.

****** Asunción posterior
En el curso trabajaremos siempre con álgebras asociativas y unitales.

***** 1.9. Inclusión del cuerpo en el álgebra
Sea $A$ una K-álgebra, la inclusión $u : K \longrightarrow A$ es homomorfismo inyectivo
de K-álgebras. Como consecuencia $\im u \subseteq Z(A)$, y es una K-subálgebra.

****** Demostración
******* Es homomorfismo
La inclusión definida por $u(k) = k1_A$ es lineal por tenerse:

\[
u(\gamma\alpha+\beta) =
(\gamma\alpha+\beta)1 =
\gamma(\alpha 1) + \beta 1 =
\gamma u(\alpha) + u(\beta)
\]

Y además es multiplicativa:

\[
u(\alpha)u(\beta) = (\alpha 1)(\beta 1) = \alpha\beta 11 = u(\alpha\beta)
\]

Y trivialmente unital por $u(1) = 1$.

******* Es inyectivo
Si $u(k) = u(k')$ entonces $(k-k')1_A = 0$.

******* Es subálgebra del centro
Aplicando bilinealidad de la multiplicación:

\[u(\alpha) a = 
(\alpha 1)a = 
\alpha (1a) = 
\alpha (a1) = 
a(\alpha 1) =
au(\alpha)\]

**** 1.2. La representación regular. Unidades y divisores de cero
***** 1.11.a. Álgebra de endomorfismos
Los endomorfismos de un K-espacio vectorial forman una K-álgebra con la
composición:

\[
End_K(V) = \{ f : V \longrightarrow V \mid f \text{ es lineal}\}
\]

****** Demostración
La suma se define por $(f+g)(v) = f(v)+g(v)$, lo que da un grupo abeliano
con el neutro $0(v) = 0$; además, con $(\alpha f)(v) = \alpha f(v)$, nos da un espacio
vectorial.

Comprobamos además que la composición es bilineal:

  1. $((f+g)\circ h)(v) = f(h(v)) + g(h(v)) = (f\circ h + g\circ h)(v)$
  2. $(f\circ (g+h))(v) = f(g(v)) + f(h(v)) = (f\circ g + f\circ h)(v)$
  3. $(\alpha f \circ g)(v) = \alpha (f\circ g)(v)) = f(\alpha g(v)) = (f \circ \alpha g)(v)$

Donde en el primer y segundo punto usamos la definición de suma; y
en el tercer punto usamos la linealidad de la función para conmutar
el elemento del cuerpo y la aplicación de la función.

***** 1.11.b. Inclusión en los endomorfismos
Sea $A$ cualquier K-álgebra. La aplicación $\lambda : A \longrightarrow End_K(A)$ que asigna
a cada $a \in A$ la aplicación $\lambda_a : A \longrightarrow A$ definida por $\lambda_a(b) = ab$ para
todo $b \in A$ es un homomorfismo inyectivo de K-álgebras.

****** Caso finito
Toda K-álgebra de dimensión finita es isomorfa a una subálgebra de
matrices con coeficientes en $K$.

****** Demostración
******* Es homormorfismo
Por los axiomas de K-álgebra, $\lambda_a$ es siempre lineal. Además, la propia
$\lambda$ es lineal por tenerse:

\[
\lambda_{a+\alpha b}(c) = (a+\alpha b)c = ac + \alpha bc = 
\lambda_a(c) + \alpha\lambda_b(c) = (\lambda_a+\alpha\lambda_b)(c)
\]

Además, es multiplicativa por asociatividad:

\[
\lambda_{ab}(c) = (ab)c = a(bc) = \lambda_a \circ \lambda_b (c)
\]

******* Es inyectiva
Si $\lambda_a = 0$, se tiene $a = \lambda_a(1) = 0$.

***** Álgebra opuesta
El álgebra opuesta $A^{op}$ es la propia $A$ con el producto dado por:

\[
a \cdot b = ba
\]

***** Unidades y divisores de cero
Un $a \in A$ no nulo es *unidad* si existe $a^{-1} \in A$ tal que $aa^{-1} = 1 = a^{-1}a$.
El conjunto de las unidades, $U(A)$ forma un grupo con el producto.

****** Divisor de cero
Un $a \in A$ no nulo es *divisor de cero* si $\exists b: ab = 0$ ó $ba = 0$.

****** Clasificación en unidades y divisores de cero en dimensión finita
Sea $a \in A$ no nulo para $A$ k-álgebra de /dimensión finita/:

1. Equivalen:

   - $a \in U(A)$
   - $\exists b \in A : ab = 1$
   - $\exists c \in A : ca = 1$

2. Equivalen:

   - $a \notin U(A)$
   - $\exists b \in A: ab = 0$
   - $\exists c \in A : ca = 0$

Es decir, todo elemento no nulo es una unidad o un divisor de cero.

******* Demostración primer punto
Si $ab = 1$, $\lambda_a$ es sobreyectiva y $\lambda_b$ es inyectiva. Por ser de dimensión
finita ambas son isomorfismos. Se aplica sobre el álgebra opuesta para
llegar a la otra implicación.

******* Demostración segundo punto
Ssi $ab = 0$, $\lambda_a$ no es inyectiva, y por tanto no puede ser unidad.

****** Clasificación por el determinante
Si en un álgebra de dimensión finita tomamos la representación regular
$\lambda: A \to \mathrm{End}(A)$; podemos usar el determinante para decidir si $a \in A$ es
una unidad.

***** Álgebra de división
Un álgebra $A$ es un *álgebra de división* si $U(A) = A \setminus \{0\}$. Los cuerpos
son álgebras de división conmutativas.

**** 1.3. Representaciones y módulos
***** Representación
Una *representación* de un álgebra $A$ es un homomorfismo de k-álgebras
$\mu : A \longrightarrow End_K(V)$, donde $V$ es el k-espacio vectorial de representación.

****** Representación fiel
Se llama representación *fiel* cuando $\mu$ es inyectiva.

****** Representación regular
La inclusión en los endomorfismos $A \to \mathrm{End}(A)$ es una *representación fiel*
que llamamos representación regular.

***** Módulos de un álgebra
Dada $A$ álgebra, un A-módulo por la izquierda es un espacio vectorial $V$
con un producto bilineal $A \times V \to V$ cumpliendo $(ab)v = a(bv)$ y $1v = v$.

****** Submódulos
Llamamos *submódulo a izquierda* a un subconjunto $N$ de un módulo que 
sea subgrupo aditivo y que cumpla $an \in N$ para $n \in N$. Los submódulos
de un álgebra se llaman *ideales a izquierda*.

****** Retículo de submódulos
Llamamos ${\cal L}(M)$ a la familia de submódulos de $A$. Forman un retículo bajo
la suma y la intersección.

****** Submódulo generado
El submódulo generado por un conjunto de elementos es el menor submódulo
que los contiene.

***** Equivalencia de módulos y representaciones
Sean $A$ una k-álgebra y $V$ un k-espacio vectorial. Hay una biyección
entre el conjunto de representaciones de $A$ sobre $V$ y los A-módulos
por la izquierda sobre $V$.

****** Demostración
Si tenemos una representación $\mu\colon A \to \mathrm{End}(V)$, definimos el A-módulo
dado por $av = \mu(a)(v)$. Si tenemos una estructura de A-módulo podemos
construir la representación $\mu(a)(v) = av$.

***** Suma directa de módulos
Llamamos *suma directa* de los módulos $M_1,\dots,M_n$ al módulo sobre su
producto cartesiano con las operaciones

 * $(m_1,\dots,m_n) + (m_1',\dots,m_n') = (m_1+m_1',\dots,m_n+m_n')$
 * $a(m_1,\dots,m_n) = (am_1,\dots,am_n)$

***** Teorema de Cayley-Hamilton
Todo endomorfismo de un espacio vectorial de dimensión finita satisface
su ecuación característica.

****** Demostración
Sea $T$ un endomorfismo en un espacio $V$ con base $\{v_1,\dots,v_n\}$, definido por
la matriz siguiente

\[C =\begin{pmatrix}
a_{11} & a_{12} & \dots \\
a_{21} & a_{22} & \dots \\
\vdots & \vdots & \ddots \\
\end{pmatrix}.
\]

Si consideramos la matriz $\Delta = (TI_n - C)^t$ en $K[X]$, tenemos que

\[\Delta\begin{pmatrix}
v_1 \\ v_2 \\ \vdots \\ v_n
\end{pmatrix} = \begin{pmatrix}
Tv_1 - \sum_{j=1}^n a_{j1}v_j \\
Tv_2 - \sum_{j=1}^n a_{j2}v_j \\
\vdots \\
Tv_n - \sum_{j=1}^n a_{jn}v_j  
\end{pmatrix} = \begin{pmatrix}
0 \\ 0 \\ \vdots \\ 0
\end{pmatrix}.
\]

Multiplicando ahora por su matriz adjunta, se tiene que

\[
\widetilde \Delta\Delta\begin{pmatrix}
v_1 \\ v_2 \\ \vdots \\ v_n
\end{pmatrix} = \begin{pmatrix}
\mathrm{det}(\Delta)v_1 \\ \mathrm{det}(\Delta)v_2 \\ \vdots \\ \mathrm{det}(\Delta)v_n
\end{pmatrix} = \begin{pmatrix}
0 \\ 0 \\ \vdots \\ 0
\end{pmatrix}.
\]

Luego, por ser una base, $\mathrm{det}(\Delta)v = 0$ para cualquier $v \in V$. Tenemos
entonces que $T$ satisface la ecuación polinómica

\[ \mathrm{det}(TI_n - C) = \mathrm{det}(\Delta^t) = \mathrm{det}(\Delta) = 0.
\]

***** Submódulo finitamente generado
Un $A\text{-módulo}$ $M$ es *finitamente generado* si existe $X \subseteq M$ subconjunto
finito que lo genera, $M = RX$.

****** Submódulo cíclico
Un módulo generado por un elemento se llama *cíclico*.

***** Suma de módulos
Dados submódulos $N_1,\dots,N_m \leq M$, su suma es el menor submódulo que contiene
a todos ellos.

****** Caracterización de la suma
Sea $M$ un $A\text{-módulo}$,

 1. Dados submódulos $N_1,\dots,N_m$ de $M$, tenemos que

    \[
    N_1+\dots+N_m = \left\{ n_1+\dots+n_m \mid n_i \in N_i \right\}.
    \]

 2. Dado $X = \{m_1,\dots,m_n\} \subseteq M$, tenemos que $RX= Rm_1 + \dots + Rm_{n}$.

******* Demostración
Comprobamos que un módulo que los contenga debe contener a todos
los elementos de esa forma, además, forman un módulo, así que es
el menor.

***** Homomorfismo de módulos
Un aplicación entre $A\text{-módulos}$ $f\colon M \to N$ es *homomorfismo de módulos*
si $f(am) = af(m)$ para $a \in A, m \in M$.

***** Cociente de módulos
Sea $L < M$ un submódulo. El cociente $M/L$ tiene estructura de módulo con

\[a(m+L) = am+L
\]

y la suma inducida en el cociente.

***** Primer teorema de isomorfía para módulos
Para $f\colon M \to N$ homomorfismo de módulos, $\mathrm{ker}(f)$ e $\mathrm{im}(f)$ son submódulos
y hay un isomorfismo $\widehat f\colon M/ \mathrm{ker}(f) \to \mathrm{im}(f)$ dado por

\[
\widehat f(m+ \mathrm{ker}(f)) = f(m)
\]

****** Demostración
Aplicamos primero el primer teorema de isomorfía en grupos. Y comprobamos
que además $\widehat f$ es $A\text{-lineal}$ por ser $f$ isomorfismo de módulos.

***** Bases y módulos libres
Un conjunto de generadores de un $A\text{-módulo}$ $M$ es *base* si cada $m \in M$
se escribe únicamente como

\[
m = \sum_{i=1}^n a_im_i
\]

****** Módulo libre
Un módulo que admite una base se llama *módulo libre*. Un ejemplo de
módulo libre es $A^n$.

***** Caracterización de bases
Un subconjunto $B \subseteq M$ no vacío finito es base si, y sólo si, para 
cualquier aplicación $f\colon B \to N$ existe un único homomorfismo de
$R\text{-módulos}$ $\overline{f} \colon M \to N$ con $\overline{f}_{|B} = f$.

\[\begin{tikzcd}
B \rar[hook]\drar[dashed, swap]{\exists! \overline{f}} & M \dar{f}\\
  & N
\end{tikzcd}\]

****** TODO Demostración

***** Caracterización de finitamente generados
Para $M$ un $A\text{-módulo}$,

 1. Si $M$ admite un conjunto de generadores $\left\{ m_1,\dots,m_n \right\}$, entonces
    $M \cong A^n/L$ para cierto submódulo $L$.
 2. Si $M$ es libre con base $\left\{ m_1,\dots,m_n \right\}$, entonces $M \cong A^n$.

****** TODO Demostración

***** Segundo teorema de isomorfía para módulos
Sean $L,N \in {\cal L}(M)$ submódulos. Existe un isomorfismo

\[
\frac{L+N}{L} \cong \frac{N}{L \cap N}.
\]

****** Demostración
Aplicamos el primer teorema de isomorfía a la función 

\[
f\colon N \to \frac{L+N}{L}
\]

dada por $f(n) = n+L$. Es sobreyectiva y tiene como núcleo a $L \cap N$.

***** Tercer teorema de isomorfía para módulos
Sean $L \subseteq N \in {\cal L}(M)$. Existe un isomorfismo

\[
\frac{M/L}{N/L}\cong \frac{M}{N}
\]

Además, hay una biyección creciente entre submódulos de $M$ conteniendo
a $L$ y ${\cal L}(M/L)$.

****** Demostración
Aplicamos priemr teorema de isomorfía a la aplicación

\[
f \colon M/L \to N/L
\]

dada por $f(m+L) = m+N$.

**** 1.4. Módulos simples. Teorema de Jordan-Hölder
***** Módulo simple
Un módulo $M$ se dice simple si no tiene submódulos propios.

***** Submódulo maximal
Un submódulo propio $N < M$ es *maximal* si lo es en ${\cal L}(M)$.

****** Caracterización por simplicidad
Por tercer teorema de isomorfía, esto equivale a que $M/N$ es simple.

***** Serie de composición
Una cadena de submódulos $0 \subset M_1 \subset M_2 \subset \dots \subset M$ es una *serie de composición*
de $M$ si cada $M_{i-1}$ es maximal en $M_i$.

***** Teorema de Jordan-Hölder
Sea $M$ un $A$ módulo de /dimensión finita/ como $K$ espacio vectorial con
dos series de composición:

\[0 = M_0 \subset M_1 \subset\dots\subset M_n = M\]
\[0 = N_0 \subset N_1 \subset\dots\subset N_m = M\]

Entonces $n=m$ y existe una permutación con $M_i/M_{i-1} \cong N_{\sigma(i)}/N_{\sigma(i)-1}$.

****** Factores de composición
Los módulos $M_i/M_{i-1}$ se llaman *factores de composición* de $M$ y están
únicamente determinados salvo isomorfismo y reordenación.

****** Demostración
Usaremos inducción sobre $n$. En el caso $n=1$, $M$ es simple y no tiene
submódulos propios, luego todas sus series de composición son la misma.
En otro caso, no es simple y $n,m>1$.

******* Caso 1
Si $M_{n-1}=N_{n-1}$, aplicamos a ambos la hipótesis de inducción y
ampliamos la permutación obtenida.

******* Caso 2
Si $M_{n-1} \neq N_{n-1}$, $M_{n-1}+N_{m-1} = M$ por maximalidad, y su intersección
tiene una serie de composición

\[
0 \subset L_1 \subset \dots \subset L_{k-1} \subset N_{m-1} \cap M_{n-1}
\]

que además puede extenderse de dos formas a $M_{n-1}$ y $N_{m-1}$, sabiendo por 
segundo teorema de isomorfía que

\[
\frac{M_{n-1}}{N_{m-1}\cap M_{n-1}} \cong \frac{M}{N_{m-1}}
\quad\text{ y que }\quad
\frac{N_{n-1}}{N_{m-1}\cap M_{n-1}} \cong \frac{M}{M_{m-1}}
\]

son simples. Aplicando la hipótesis de inducción dos veces, tenemos
dos permutaciones que nos dan

\[
L_i/L_{i-1} \cong M_{\tau i}/M_{\tau i - 1}
\quad\text{ y que }\quad
L_i/L_{i-1} \cong N_{\sigma i}/M_{\sigma i - 1}.
\]

Combinándolas tenemos lo pedido.

***** Longitud de un módulo
El número de factores de composición es la *longitud* del módulo $\ell(M)$.

***** Longitud y cociente
Si $M$ es de dimensión finita y $N \in {\cal L}(M)$. Entonces $\ell(M)=\ell(N)+\ell(M/N)$.

****** Demostración
Si tenemos series de composición

\[
0 \subset N_1 \subset N_2 \subset \dots \subset N
\qquad
\frac{N}{N} \subset \frac{M_1}{N} \subset \dots \subset \frac{M}{N}
\]

podemos aplicar el tercer teorema de isomorfía para tener
$M_j/M_{j-1} \cong \frac{M_j/N}{M_{j-1}/N}$ simple, y por tanto, una serie de composición

\[
0 \subset N_1 \subset \dots \subset N \subset M_1 \subset \dots \subset M.
\]

Como consecuencia, $\ell(M)=\ell(N)+\ell(M/N)$.

***** Longitud, suma e intersección
Sea $M$ un módulo dimensión finita con $N,L \in {\cal L}(M)$. Entonces:

\[\ell(N+L) + \ell(N\cap L) = \ell(N)+\ell(L)\]

****** Demostración
Aplicamos el [[*Segundo teorema de isomorfía para módulos][segundo teorema de isomorfía]] y la [[*Longitud y cociente][longitud de un cociente]]
para tener

\[
\frac{L+N}{L} \cong \frac{N}{L \cap N},
\]

y por tanto $\ell(L+N) - \ell(L) = \ell(N) - \ell(L \cap N)$.

**** 1.5. Independencia lineal y sumas directas internas
***** Familia independiente
Una familia $\{N_i \mid i \in I\} \subset {\cal L}(M)$ es *independiente* si se verifica:

\[
N_j \cap \sum_{j\neq i} N_i = \{0\}
\]

***** Suma directa interna
Dada una familia independiente, $\sum_{i\in I} N_i \subset M$ se llama *suma directa interna*.

***** Suma directa externa e interna
Existe un único homomorfismo de módulos $\theta : \bigoplus_{i\in I} N_i \to \sum_{i\in I} N_i$, tal que
$\theta\iota_i(m) = m$ para cualquier $m \in N_i$.

****** Demostración
Extendiendo por linealidad la condición, el único homomorfismo posible es:

\[
\theta((m_i)_{i \in I}) = \sum_{i \in I} m_i
\]

***** Caracterización de familia independiente
Equivalen:

 1. La familia $\{N_i\mid i\in I\}$ es independiente.
 2. Toda subfamilia /finita/ $F \subset \{N_i\mid i\in I\}$ es independiente.
 3. La expresión de cada $m = \sum_{i\in I} m_i$ con $m_i\in N_i$ es única.
 4. Si $0 = \sum_{i\in I} m_i$, entonces $m_i = 0$.
 5. El homomorfismo canónico $\theta : \bigoplus_{i\in I} N_i \to \sum_{i\in I} N_i$ es inyectivo e isomorfismo.
 6. Para $J_1,J_2 \subset I$ con $J_1\cap J_2 = \varnothing$ se tiene $\sum_{i\in J_1} N_i \cap \sum_{i\in J_2} N_i = \{0\}$.

En este caso, notaremos la suma directa interna también por $\bigoplus_{i \in I} N_i$.

****** Demostración
******* Implicación 1 a 2
Trivial por definición de independencia.

******* Implicación 2 a 3
Esto equivale a que cada $\sum_{i \in I} m_i = 0$ lleva a $m_i = 0$. Pero si hubiera
algún $m_j$ no nulo, sería $m_j = - \sum_{i \in I, i\neq j} m_i$, contraviniendo independencia.

******* Implicación 3 a 4
Trivial por la unicidad.

******* Implicación 4 a 5
Desde lo anterior, se tiene que tiene núcleo trivial y por tanto es
inyectivo. Además, es sobreyectivo porque genera trivialmente todos los
elementos de $\sum N_i$. Es por tanto una biyección e isomorfismo.

******* Implicación 5 a 6
Si no fuera así, existirían subconjuntos $J_1,J_2$ cumpliendo:

\[
\sum_{i \in J_1} m_i = \sum_{i \in J_2} n_i
\]

Nótese que entonces la función $\theta$ daría la misma imagen para ambos
subconjuntos, contraviniendo inyectividad.

******* Implicación 6 a 1
Trivial por el caso de $J_2$ con un elemento.

***** Ampliar familia independiente
Sea $\{N_i \mid i\in I\} \subset {\cal L}(M)$ es familia independiente y tenemos:

\[
N \cap \bigoplus_{i\in I} N_i = \{0\}
\]

Entonces, $\{N_i \mid i \in I\} \cup \{N\}$ es independiente.

****** Demostración
Si $n + \sum n_i = 0$, tenemos $n \in \bigoplus N_i \cap N$ y, por tanto, $n = 0$. Por 
independencia de la familia $\sum n_i = 0$, se llega a $n_i = 0$.

***** Suma directa en suma de simples
Sea $N \subset \sum_{i\in I} M_i$ suma de submódulos simples. Existe $\{M_i \mid i \in J \subseteq I\} \cup \{N\}$ 
independiente con:

\[
N \oplus \left( 
\bigoplus_{i \in J} M_i
\right) = \sum_{i \in I} M_i
\]

****** Demostración
Tomamos el conjunto $\Gamma$ de los subconjuntos $J \subseteq I$ tales que $\{M_i \mid i \in J\} \cup \{N\}$
es independiente. Veamos que es no vacío. Si para todo $N \cap M_i \neq 0$, 
debe tenerse por simplicidad $M_i \subset N$ y por tanto $\sum M_i \subset N$. Así, debe
existir algún $M_i$ para el que $N \cap M_i = 0$.

Tomamos el maximal $J$. Para cualquier índice $i \in I -J$, se tiene entonces
por maximalidad que $M_i \cap (N + \bigoplus_{j \in J} M_j) \neq 0$, pero eso implica por simplicidad
que $M_i \subseteq N + \bigoplus_{j\in J} M_j$.

***** Existencia de base para espacio vectorial finitamente generado
Sea $_DV$ espacio vectorial izquierdo sobre el anillo de división $D$.
Para todo sistema de generadores no nulos $\{v_i\mid i\in I\}$ de $V$ existe un 
subconjunto tal que $V = \bigoplus_{j\in J} Dv_j$.

Todo espacio vectorial finitamente generado sobre $D$ tiene una base.

****** Demostración
Un anillo de división es simple. Como $Dv_j \cong D$, tenemos que es un 
espacio suma de simples, luego [[*Suma directa en suma de simples][existe un conjunto]] de independientes que
genera el espacio.

**** 1.6. Independencia en familias infinitas
***** Suma directa externa infinita
Se define la *suma directa externa* $\bigoplus_{i\in I} N_i$ como el subconjunto del producto
cartesiano formado por las tuplas con un número finito de valores no nulos.

**** 1.7. Clasificación de las álgebras de división reales de dimensión finita
***** Determinante, traza, polinomio característico y mínimo
Dada $a \in D$ en un álgebra de división sobre $k$, consideramos su *traza*,
su *determinante*, su *polinomio característico* y su *polinomio mínimo*
como los del endomorfismo lineal multiplicación, $\lambda_a \colon D \to D$.

***** Lema de clasificación de álgebras de división
Sea $D$ álgebra real de dimensión finita mayor que $1$. Entonces:

\[
V = \{a \in D : a^2 \leq 0\} = \{a\in D\mid tr(a) = 0\}
\]

Luego es un subespacio vectorial con $D = \mathbb{R} \oplus V$. Además, la dimensión real
de $D$ es par.

****** Demostración
Llamamos $n = \mathrm{dim}_{\mathbb{R}}(D)$ y dado $a \in D$ consideramos su polinomio 
característico

\[
p(X) = (X-r_1)\dots (X-r_k)q_1(X)\dots q_m(X)
\]

descompuesto en factores lineales y cuadráticos. Por Cayley-Hamilton,
tenemos que $p(a) = 0$, luego debe anularse algún polinomio,

  * si $(a-r_i) = 0$ entonces $a \in \mathbb{R}$, y si $a^2 \leq 0$, nos da $a = 0$.
  * si $a \in D \setminus \mathbb{R}$, tendremos algún $q_j(a) = 0$ como polinomio mínimo de $a$.

Por Ejercicio 18 tenemos $p = q^t$, con $2t=n$ en este caso. Por irreducibilidad
se tiene $q = (X-z)(X-\overline{z})$ para algún complejo, así que

\[\begin{aligned}
q(X) &= X^2 - 2 \mathrm{Re}(z) X + |z|^2 \\
p(X) &= X^{2t} - 2 \mathrm{Re}(z)t X^{2t-1} + \dots \\
p(X) &= X^{2t} - \mathrm{tr}(a) X^{2t-1} + \dots \\
\end{aligned}
\]

desde el desarrollo de $q$ y la definición de la traza como coeficiente del
polinomio característico.

Sustituyendo en la primera ecuación desde la última tenemos que

\[
a^2 - \frac{\mathrm{tr}(a)}{t}a + |z|^2 = 0,
\]

y que por tanto $a^2 \in \mathbb{R}^-$ si y sólo si $\mathrm{tr}(a) = 0$.

***** Teorema de Frobenius
Sea $D$ álgebra de división real de dimensión finita. Entonces $D$ es isomorfa
a $\mathbb{R}$, $\mathbb{C}$, o $\mathbb{H}$.

****** Demostración
Si $D \not\cong \mathbb{R}$, aplicamos el [[*Lema de clasificación de álgebras de división][lema de clasificación]] para tener $D$ de dimensión
par con $D = \mathbb{R}\oplus V$. Consideramos

\[
B(a,b) = \frac{ab+ba}{2}
= \frac{1}{2}\left( (a+b)^2-a^2-b^2 \right) \in \mathbb{R},
\]

una forma bilineal simétrica definida negativa. Podemos diagonalizarla
para obtener una base donde $B(e_i,e_j) = 0$ si $i\neq j$ y $B(e_i,e_i) = -1$, es decir,
por definición de $B$,

\[
e_i^2 = -1
\quad\text{ y }\quad
e_ie_j = -e_je_i.
\]

En el caso $t=1$, tenemos $\mathbb{C}$. En el caso $t>1$, tenemos además la restricción
de que si tomamos $u = e_1e_2e_j$, se cumple

\[
u^2 = -e_1e_2e_1e_je_2e_j = 1,
\]

luego $0 = (u-1)(u+1)$ en un anillo de división nos da $e_j = \pm e_1e_2$, así que
debe tenerse $t=2$, con base $\left\{ 1,e_1,e_2,e_1e_2 \right\}$. En este caso, se comprueba que
hay un isomorfismo $\mathbb{H} \cong D$.

***** Corolario de Frobenius
La única álgebra de división compleja de dimensión finita es $\mathbb{C}$.

****** Demostración
Nótese que en particular sería un álgebra de división real y no podría
ser $\mathbb{H}$ porque no tiene a los complejos como centro.

**** 1.8. Idempotentes y anillos de matrices
***** Idempotente
Un elemento de un álgebra $e \in R$ se llama *idempotente* si $e^2 = e$.
Son idempotentes triviales $0$ y $1$.

***** Conjunto completo de idempotentes ortogonales (CCIO)
Un conjunto de idempotentes no triviales $\{e_1,\dots,e_n\}$ es conjunto completo de
idempotentes ortogonales si:

\[
1 = e_1 + \dots + e_n
\]

Y además, $e_ie_j = 0$ para $i \neq j$.

***** Descomposición de un CCIO
Sea $\{e_1,\dots,e_n\}$ un CCIO para $R$. Entonces $R = Re_1 \oplus \dots \oplus Re_n$.

****** Demostración
Cualquier elemento de $R$ se expresa como:

\[
r = r(e_1+e_2+\dots+e_n)
\]

Y la suma es directa porque si se tiene $x \in Re_j \cap \left(\sum_{i\neq j} Re_i \right)$, entonces:

\[
x = xe_j = \left(\sum_{i\neq j} xe_i\right)e_j = 0
\]

***** Descomposición en un CCIO
Sea $R = I_1 \oplus \dots \oplus I_n$ descomposición por ideales a izquierda no triviales.
Entonces, si $1 = e_1 + \dots + e_n$, para $e_i\in I_i$, $\{e_1,\dots,e_n\}$ forman un CCIO 
con $I_i = Re_i$.

****** Demostración
Si $x \in I_j$, $x = x\sum e_i$ y se tiene,

\[x - xe_j = 
\sum_{i\neq j} xe_i \in I_j \cap \left(\sum_{i\neq j} I_i\right) = 
\{0\}.\]

Así, hemos demostrado que

\[
I_j = \{ x \in R \mid xe_j = x\} = Re_i
\]

y que por tanto, $e_i^2 = e_i$. Por eso se tiene $\sum_{i\neq j} e_ie_j = 0$ y por independencia
lineal, se llega a $e_ie_j = 0$.

***** Matrices de descomposición
Llamamos al conjunto de matrices siguiente,

\[
Mat(e_iRe_j) = \left\{(r_{ij}) \mid r_{ij} \in e_iRe_j\right\}
\]

que es un subespacio vectorial multiplicativamente cerrado de $M_n(R)$. La
matriz diagonal

\[\begin{pmatrix}
e_1 & 0 & \dots & 0\\
0 & e_2 & \dots & 0 \\
\vdots & & & \vdots \\
0 & 0 & \dots & e_n
\end{pmatrix}
\]

es elemento neutro multiplicativo.

****** Demostración
Se comprueba trivialmente por tenerse:

\[
(e_ire_k)(e_kr'e_j) = e_i(re_kr')e_j \in e_iRe_j
\]

Multiplicando se comprueba además que la diagonal es la unidad
multiplicativa.

***** Descomposición en matrices
La aplicación $\phi \colon R \to Mat(e_iRe_j)$ dada por $\phi(r) = (e_ire_j)_{ij}$ es un isomorfismo
de K-álgebras.

****** Demostración
******* Es homomorfismo de álgebras
Por definición es lineal. Si calculamos la componente $(i,j)$ de
$\phi(r)\phi(s)$, tenemos

\[
\sum_k e_ire_ke_kse_j =
\sum_k e_ire_kse_j =
e_ir \left(\sum_k e_k\right) se_j =
e_irse_j
\]

que es la componente $(i,j)$ de $\phi(rs)$. Además, $\phi(1)$ es claramente la unidad.

******* Es isomorfismo
Supongamos que $\phi(r)=0$, entonces se tiene

\[
r = \left(\sum_i e_i\right)r \left( \sum_{j} e_{j} \right)
= \sum_{i,j} e_{i}re_{j} = 0
\]

y la función es inyectiva. Para comprobar que es sobreyectiva, simplemente
tomamos una matriz $(r_{ij})$ de la forma, y comprobamos que por ortogonalidad
e idempotencia se tiene

\[
\phi \left( \sum_{i,j} r_{ij} \right) = (r_{ij})
\]

***** Descomposición de endomorfismos
Sea $M = M_1 \oplus M_2 \oplus \dots \oplus M_n$ un A-módulo con $M_i \cong N$. Se tiene

\[
\mathrm{End}(M) = M_n(\mathrm{End}(N)).
\]

****** TODO Demostración

***** Descomposición en ideales biláteros
Sea $R = I_1\oplus I_2\oplus \dots \oplus I_n$ descompuesto en ideales biláteros. Sea $\left\{ e_1,\dots,e_n \right\}$
su CCIO asociado. Entonces $e_i \in Z(R)$, idempotente central.

***** Descomposición en álgebras
Sea $\{e_1,\dots,e_n\}$ un CCIO centrales de $R$. Entonces $Re_i$ es un álgebra con unidad
y tenemos un isomorfismo de álgebras $R \cong Re_1\times Re_2 \times \dots \times Re_n$ definido
por $r \mapsto (re_1,\dots,re_n)$.

***** Idempotente central primitivo
Un idempotente central es *primitivo* si $Re$ no es suma directa de dos ideales
propios de $R$.

***** Descomposión en centrales primitivos
Si $R$ tiene un CCIO centrales primitivos, este conjunto es único.

****** TODO Demostración

**** 1.9. El álgebra de enfomorfismos de un módulo semisimple
***** Complemento
Para $N \subseteq M$ submódulo, un *complemento* de $N$ es un $X$ tal que

\[
M = N \oplus X.
\]

En caso de que tenga complemento lo llamamos *sumando directo*.

***** Módulos semisimples
Un módulo de dimensión finita se dice *semisimple* si todo submódulo
es un sumando directo.

***** Caracterización de semisimples
Sea $M$ módulo con dimensión finita como K-espacio vectorial. Equivalen:

  1) $M$ es semisimple.
  2) $M$ es suma directa finita de submódulos simples.
  3) $M$ es suma finita de submódulos simples.

****** Demostración
******* Primera implicación
Tomamos una familia maximal de submódulos simples linealmente
independientes. Si el complemento de su suma no fuera nulo, entonces
contendría algún submódulo simple (por finitud) que sería linealmente
independiente, contraviniendo maximalidad.

******* Segunda implicación
Trivial.

******* Tercera implicación
Trivial porque podemos tomar [[*Suma directa en suma de simples][suma directa en suma de simples]] para
encontrar el complemento.

***** Lema de Schur
Sean $M,M'$ simples con $f\colon M \to M'$ homomorfismo de módulos. Se tiene $f=0$
o $f$ isomorfismo.

****** Corolario: anillo de endomorfismos de un módulo simple
El anillo de los endomorfismos de un módulo simple es un anillo de
división.

****** Demostración
Si no es nula, el núcleo es un submódulo propio, luego debe ser inyectiva.
La imagen entonces será un submódulo propio no nulo y será sobreyectiva.

***** Submódulos y cocientes de semisimples
Si $M$ es un semisimple de dimensión finita, entonces todo submódulo de $M$
y todo cociente de $M$ es semisimple.

****** Demostración
Si existe un epimorfismo de módulos $M \to N$, se tiene $N$ semisimple.
Cualquier cociente tendrá la proyección como epimorfismo hacia él y
cualquier submódulo $N \subseteq M$ será cociente por su complemento como

\[
\frac{M}{X} =
\frac{N \oplus X}{X} \cong
\frac{N}{N \cap X} \cong N.
\]

******* El epimorfismo da la semisimplicidad
Por [[*Lema de Schur][Lema de Schur]], se tiene que la imagen de un simple será simple o
nula. Así, podemos escribir

\[
N = \sum_{i\in I} f(M_i)
\]

y tendremos que es suma de simples y por [[*Caracterización de semisimples][caracterización]], semisimple.

***** Unicidad de la descomposición en simples
Sea $M = M_1\oplus \dots \oplus M_n = N_1 \oplus \dots \oplus N_m$ semisimple descompuesto como suma
directa de simples. Entonces $n=m$ y se tiene $M_i \cong N_{\sigma i}$ para alguna 
permutación.

****** Demostración
Tenemos dos series de composición

\[\begin{aligned}
\left\{ 0 \right\} &= M_0 \subset
M_1 \subset 
M_1 \oplus M_2 \subset 
&\dots& \subset
M_1 \oplus \dots \oplus M_n &= M \\
\left\{ 0 \right\} &= N_0 \subset
N_1 \subset 
N_1 \oplus N_2 \subset 
&\dots& \subset
N_1 \oplus \dots \oplus N_n &= M \\
\end{aligned}\]

en las que los factores son simples, explícitamente por segundo
teorema de isomorfía,

\[
\frac{M_j \oplus \dots \oplus M_0}{M_{j-1}\oplus \dots\oplus M_0} \cong
\frac{M_j}{(M_{j-1} \oplus \dots \oplus M_0) \cap M_j} \cong M_j.
\]

Pero aplicando [[*Teorema de Jordan-Hölder][Jordan-Hölder]], $M_j \cong N_{\sigma j}$.

***** Componentes isotópicas de un módulo
Sea $M = M_1\oplus \dots \oplus M_n$ descomposición finita en módulos simples. Podemos
escoger módulos simples $\Sigma_1,\dots,\Sigma_t$ y una partición $\{1,\dots,n\} = \Lambda_1 \cup \dots \cup \Lambda_t$
tal que $M_i \cong \Sigma_j$ si y sólo si $i \in \Lambda_j$.

Podemos tomar $M_{\Lambda_j} = \bigoplus_{i\in \Lambda_j} M_i$ para descomponer en *componentes isotópicas*

\[
M = M_{\Lambda_1}\oplus \dots \oplus M_{\Lambda_t}
\]

y llamar a $n_j$ la *multiplicidad* $\Sigma_j$ en $M$. Las componentes con su multiplicidad
son invarriantes llamados *estructura del módulo*.

***** Estructura de los endomorfismos
Sea $M$ con estructura $(\Sigma_1,n_1),\dots,(\Sigma_t,n_t)$ entonces $\Delta_j= \mathrm{End}(\Sigma_j)$ es una
$K\text{-álgebra}$ de dimensión finita y hay un isomorfismo

\[ \mathrm{End}(M) \cong
\mathrm{M}_{n_1}(\Delta_1) \times \dots \times \mathrm{M}_{n_t}(\Delta_t)
\]

****** TODO Demostración
**** 1.10. Álgebras semisimples de dimensión finita
***** Álgebras semisimples
Un álgebra $A$ de dimensión finita es *semisimple* si todo A-módulo de
dimensión finita es semisimple.

***** Caracterización de álgebras semisimples
Un álgebra de dimensión finita es semisimple si y sólo si es semisimple
como A-módulo.

****** Demostración
Si $M$ es un módulo finito-dimensional, es el cociente de un libre $A^n$.
Como $A^n$ es semisimple por serlo $A$, su [[*Submódulos y cocientes de semisimples][cociente]] $M$ es semisimple.

***** Estructura de los módulos de un álgebra semisimple
Sea $A$ es un álgebra semisimple con estructura $(n_1,\Sigma_1),\dots,(n_t,\Sigma_t)$ como
$A\text{-módulo}$, entonces todo $A\text{-módulo}$ finito tiene estructura $(m_1,\Sigma_1),\dots,(m_t,\Sigma_t)$
para algunos $m_1,\dots,m_t$. En particular, todo $A\text{-módulo}$ simple es isomorfo a 
un $\Sigma_j$.

****** Demostración
Los módulos de dimensión finita son cocientes de $A^n$, y la estructura de
$A^n$ es simplemente $(nn_1,\Sigma_1),\dots,(nn_t,\Sigma_t)$, y sabemos que la estructura de los
submódulos y de los cocientes es la misma con coeficientes menores.

***** Álgebra de matrices sobre anillo de división es semisimple
Dada $\Delta$ álgebra de división finito-dimensional, $M_n(\Delta)$ es un álgebra 
semisimple con estructura $(n, \Sigma)$ para $\Delta \cong \mathrm{End}(\Sigma)^{op}$. Además, $M_n(\Delta)^{op} \cong M_n(\Delta^{op})$.

****** Demostración
******* El álgebra de matrices es semisimple
Tomamos $A_j$ el ideal izquierda de $M_n(\Delta)$ con base $\left\{ E_{1j},\dots,E_{nj} \right\}$.
Comprobamos que es simple, ya que cualquiera de sus elementos no
nulos genera $M_n(\Delta)E_{jj}$, por ser $\Delta$ anillo de división.

Así, vemos que $M_n(\Delta)$ es semisimple por ser

\[ M_n(\Delta) = A_1 \oplus \dots \oplus A_n. \]

******* Estructura unimodular
Veamos que existe un isomorfismo de módulos $A_1 \cong A_j$, explícitamente

\[
f(a_1E_{11}+\dots +a_nE_{n1}) = a_1 E_{1j} + \dots + a_n E_{nj}
\]

es trivialmente isomorfismo de espacios vectoriales y se comprueba que
es homomorfismo de módulos por tenerse

\[
f\left(\left( \sum_{}  \right)\right)
\]

***** Teorema de Wedderburn
Una $K\text{-álgebra}$ de dimensión finita es semisimple ssi es isomorfa a un
álgebra de la forma

\[ \mathrm{M}_{n_1}(\Delta_1) \times \dots \times \mathrm{M}_{n_t}(\Delta_t).
\]

de forma única para algunas $\Delta_1,\dots,\Delta_t$ álgebras de división de dimensión
finita. Además, esta factorización es esencialmente única.

****** TODO Demostración

***** Centro de álgebra semisimple de dimensión finita
Si $A$ es semisimple de dimensión finita, $Z(A)$ es producto finito de cuerpos
extensión finita de $k$. El número de factores es el número de $A\text{-módulos}$ simples
no isomorfos en la estructura de $A$.

****** TODO Demostración
***** Semisimplicidad del álgebra opuesta
Si $A$ es semisimple, entonces $A^{op}$ es semisimple.

****** TODO Demostración

***** Teorema de Molien
Un álgebra compleja $A$ de dimensión finita es semisimple ssi es
isomorfa a exactamente una de la forma

\[ \mathrm{M}_{n_1}(\mathbb{C}) \times \dots \mathrm{M}_{n_t}(\mathbb{C})
\]

cumpliendo $\mathrm{dim}_{\mathbb{C}}(A) = n_1^2+\dots+n_t^2$.

*** 2. Representaciones de grupos finitos
**** 2.1. Representaciones lineales de grupos finitos y módulos
***** 2.1. Representación
Una *representación* $k\text{-lineal}$ de $G$ es un homomorfismo de grupos

\[\rho \colon G \to \mathrm{GL}(V).\]

****** Espacio de representación
Llamamos a $V$ /espacio de representación/ y a su dimensión la
/dimensión de la representación/. 

****** Dimensión finita
Aquí consideraremos sólo representaciones de dimensión finita.

***** Álgebra de grupo
Para $G$ grupo finito y $k$ cuerpo, el /álgebra de grupo/ $kG$ se define
como el $k\text{-espacio}$ vectorial libre sobre $G$ con el producto dado por la
extensión bilineal del producto sobre $G$.

***** Relación entre representación y módulo del álgebra de grupo
La aplicación que asigna cada homomorfismo de álgebras $\Pi\colon kG \to \mathrm{End}_k(V)$
su restricción $\rho \colon G \to \mathrm{GL}(V)$ es una biyección a las representaciones.

Las representaciones $k\text{-lineales}$ de $G$ son las estructuras de $kG\text{-módulo}$
sobre $V$.

****** Demostración
Sabemos que cada homomorfismo $G \to \mathrm{GL}(V)$ extiende de manera única
por ser una base de $kG$ y extiende al producto por estar definido
precisamente por extensión. Cada aplicación restringe a $GL(V)$ por
ser los elementos de $G$ invertibles en $kG$ y es homomorfismo de
grupos.

***** Subespacio invariante
Un subespacio $W \leq V$ es $\rho\text{-invariante}$ si $\rho(g)(W) \leq W$ para cualquier $g \in G$.

/Equivalentemente, es un $kG\text{-módulo}$/.

***** Representación irreducible
Una representación no nula es irreducible si no tiene espacios invariantes
propios.

/Equivalentemente, el $kG\text{-módulo}$ es simple/.

**** 2.2. Representaciones completamente reducibles. Teorema de Maschke
***** 2.8. Representación completamente reducible
Una representación se llama *completamente reducible* si es nula
o el espacio de representación es suma directa de espacios irreducibles.

/Equivalentemente, el $kG\text{-módulo}$ es semisimple/.

***** 2.9. Teorema de Maschke
Sea $G$ grupo finito y $k$ cuerpo con $\mathrm{char}(k) \nmid |G|$. Toda representación aquí es
completamente reducible.

/Equivalentemente, $kG$ es un álgebra semisimple/.

****** Demostración
Dada $\varphi \colon V \to U$ $k\text{-lineal}$, definimos

\[
\widetilde \varphi(v) = \frac{1}{|G|}\sum_{g \in G}g \varphi(g^{-1}v),
\]

usando que $\mathrm{char}(k) \nmid |G|$, y es un homomorfismo de $kG\text{-módulos}$,

\[\begin{aligned}
\widetilde\varphi(hv) = 
\frac{1}{|G|}\sum_{g \in G}hh^{-1}g\varphi(g^{-1}hv) =
h \frac{1}{|G|} \sum_{k \in G} k \varphi(k^{-1}v) = h \widetilde\varphi(v).
\end{aligned}\]

Sea ahora $V$ un $kG\text{-módulo}$ con $W \leq V$. Consideramos $\pi\colon V \to V/W$, y
usando el complemento como espacio vectorial, creamos $\varphi\colon V/W \to V$
lineal con $\pi\circ\varphi = \mathrm{id}_{V/W}$ y tomamos la $\widetilde \varphi$. Tenemos entonces

\[
\pi(\widetilde\varphi(x)) =
\pi \left( \frac{1}{|G|}\sum_{g \in G}g\varphi(g^{-1}x) \right) =
\frac{1}{|G|} g\pi(\varphi(g^{-1}x)) =
\frac{1}{|G|} \sum_{g \in G} gg^{-1}x = x,
\]

y por tanto $\pi \circ \widetilde\varphi = \mathrm{id}_{V/W}$. Si tomamos $U = \operatorname{Im} \widetilde\varphi$, vemos que $V = W \oplus U$;
luego todo submódulo es un sumando directo.

***** 2.10.a. Representaciones equivalentes
Dos representaciones $k\text{-lineales}$ de $G$ se llaman *equivalentes* si los
$kG\text{-módulos}$ son isomorfos.

***** 2.10.b. Representación regular
La representación regular $\rho_{reg}$ es la asociada al propio $kG$ como $k\text{-módulo}$.
Cuando $\mathrm{char}(k) \nmid |G|$ es, por [[*Teorema de Maschke][Teorema de Maschke]], suma de irreducibles, que
notaremos como

\[\rho \sim
\rho_1^{n_1}\oplus \dots\oplus \rho_t^{n_t}
\]

para ciertas multiplicidades $n_i$.

***** 2.10.c. Constituyentes
Usando la estructura de las álgebras semisimples, sabemos que cualquier
representación $k\text{-lineal}$ de $G$ será de la forma

\[\rho \sim
\rho_1^{m_1}\oplus \dots\oplus \rho_t^{m_t}
\]

para ciertas multiplicidades $m_i$. Llamamos a las $\rho_i$ con multiplicidad positiva
las *constituyentes* de $\rho$.

***** 2.11. Multiplicidades en la representación regular
Cuando $\mathrm{char}(k) \nmid |G|$, si las representaciones $k\text{-lineales}$ irreducibles de $G$
son $(V_1,\rho_1),\dots,(V_{t},\rho_t)$ y tenemos $n_i$ la multiplicidad de cada una de ellas
en la representación regular y $d_i = \mathrm{dim}_k(\Delta_i)$ la dimnesión asociada al
álgebra de división que da el teorema de Wedderburn; tenemos que
$\mathrm{dim}_k(V_i) = d_in_i$ y $|G| = d_1n_1^2 +\dots + d_tn_t^2$.

****** TODO Demostración

***** 2.12. Multiplicidades en al representación regular compleja
Sean $(V_1,\rho_1),\dots,(V_t,\rho_t)$ las representaciones irreducibles complejas de $G$.
Si las multiplicidades en la representación regular son $(n_1,\dots,n_t)$,
entonces $\mathrm{dim}_{\mathbb{C}} V_i = n_i$ para $i = 1,\dots,t$ y $|G| = n_1^2 + \dots + n_t^2$.

****** TODO Demostración
***** 2.13. Dimensión del centro del álgebra-grupo
Sean $C_1,\dots,C_r$ las clases de conjugación de $G$. Entonces $\mathrm{dim}_k Z(kG) = r$.

****** TODO Demostración

***** 2.14. Número de representaciones irreducibles complejas
El número de clases de conjugación de $G$ coincide con el número de
representaciones irreducibles complejas de $G$.

****** TODO Demostración
**** 2.3. Caracteres
***** 2.15. Carácter complejo
Para $(V,\rho)$ representación compleja de $G$, la aplicación $\chi_{\rho}\colon G \to \mathbb{C}$ dada
por $\chi_{\rho}(g) = \mathrm{tr}(\rho(g))$, se llama *carácter* complejo de $\rho$.

****** Carácter irreducible
El que procede de una representación irreducible.

****** Grado de un carácter
Dimensión de $V$ como espacio vectorial complejo.

***** 2.16. Carácter invariante por equivalencia
Dos representaciones complejas equivalentes proporcionan el mismo
carácter.

****** Demostración
Si $(V,\rho)$ y $(W,\pi)$ son equivalentes por $T \colon V \to W$, para $g \in G$ tenemos
que $T\rho(g) = \pi(g)T$, luego $\rho(g) = T^{-1}\pi(g)T$, y sabemos que la traza se
preserva por semejanza.

***** 2.17.a. Exponente de un grupo
El *exponente* de un grupo $G$ es el mínimo común múltiplo de los órdenes
de sus elementos.

***** 2.17.b. Diagonalización de elementos de la representación
Sea $G$ con exponente $m$ y $(V,\rho)$ representación de grado $n$. Existen raíces
$m\text{-ésimas}$ de la unidad $\omega_1,\dots,\omega_n$ en las que diagonaliza $\rho(g)$. Se tiene
entonces

\[\chi_{\rho}(g) = \omega_1+\dots + \omega_n \]

y

\[\chi_{\rho}(g^{-1}) = \overline{\chi_{\rho}(g)}.
\]

****** TODO Demostración

***** 2.18. Cota del carácter
Para $G$ con exponente $m$ y $(V,\rho)$ representación,

\[|\chi_{\rho}(g)| \leq \operatorname{deg} \chi_{\rho}.
\]

El caso de igualdad se tiene si y sólo si $\rho(g) = \omega \mathrm{id}_V$ para alguna raíz
$m\text{-ésima}$ de la unidad.

****** Caso de la identidad
En particular, $\chi_{\rho}(g) = \operatorname{deg} \chi_{\rho}$ si y sólo si $\rho(g) = \mathrm{id}_V$.

***** 2.19. Núcleo de un carácter
Dado $\chi$ carácter complejo, su *núcleo* se define como

\[\ker \chi = \left\{ g \in G \mid \chi(g) = \chi(1) \right\}.
\]

****** TODO El núcleo es un subgrupo normal

***** Extensión de representaciones y caracteres
Dada una representación $\rho \colon G \to \mathrm{Aut}(V)$, notamos por $\tilde{\rho}(g) \colon \mathbb{C}G \to \mathrm{End}_{\mathbb{C}}(V)$ la
extensión al álgebra-grupo. Dado un carácter $\chi_{\rho} \colon G \to \mathbb{C}$, notamos por 
$\widetilde{\chi_{\rho}} \colon \mathbb{C}G \to \mathbb{C}$ a la extensión al álgebra grupo.

***** Caracteres irreducibles complejos
Los *caracteres irreducibles* complejos de $G$ son los dados por sus
representaciones irreducibles.

****** Dimensión del espacio de representación
Nótese que para cualquier carácter irreducible se tiene
# ¿Necesitamos que sea irreducible?

\[n_i = \operatorname{dim}_{\mathbb{C}} V_{i} = \chi_i(1).\]

***** Carácter de la suma directa
Si $(W,\pi)$ es una representación con $W = W_{1} \oplus \dots \oplus W_m$, se tiene que

\[\chi_{\pi} = \chi_{\pi_1} + \dots + \chi_{\pi_m}.
\]

****** TODO Demostración

***** Carácter regular
El *carácter regular* es el carácter de la representación regular.
Cumple que

 1) \[\chi_{reg}(g) = \left\{\begin{array}{ll} |G|,  & \mbox{si } g=1 \\0, & \mbox{si }  g \neq 1.
    \end{array} 
    \right.\]
 2) $\chi_{reg} = \chi_1(1)\chi_1 + \dots + \chi_t(1)\chi_t$.

****** TODO Demostración

**** 2.4. La tabla de caracteres
***** TODO Tabla de caracteres
***** TODO Teorema de Frobenius
**** 2.5. Funciones de clase. Reciprocidad
***** Producto interno
En el espacio vectorial $\mathbb{C}^G$, de dimensión $|G|$, definimos el siguiente
*producto interno*

\[(\varphi,\psi) = \frac{1}{|G|} = \sum_{g \in G}\overline{\varphi(g)}\psi(g).
\]

****** Conjunto ortonormal
Nótese que los $\left\{ \chi_1,\dots,\chi_t \right\}$ forman un /conjunto ortonormal/ de vectores
en $\mathbb{C}^G$.

****** Base ortonormal
Si $G$ es /abeliano/, tiene tantas clases de conjugación como elementos.
Tenemos $t = |G|$ y los caracteres irreducibles son una base ortonormal
de $\mathbb{C}^G$.

***** Funciones de clase
Una *función de clase* de $G$ es una aplicación $\varphi\colon G \to \mathbb{C}$ constante sobre
cada clase de conjugación de $G$. Es decir,

\[
\varphi(hgh^{-1}) = h\varphi(g) h^{-1}.
\]

Al subespacio complejo de funciones de clase lo llamamos ${\cal C}(G)$.

***** Base ortonormal de las funciones de clase
Los caracteres irreducibles $\mathrm{Irr}(G) = \left\{ \chi_1,\dots,\chi_t \right\}$ forman una base ortonormal
de ${\cal C}(G)$.

****** TODO Demostración

***** Equivalencia por caracteres
Dos representaciones complejas de $G$ son equivalentes si, y sólo si,
proporcionan el mismo carácter.

****** TODO Demostración

***** Restricción e inducción
Fijados $H \leq G$, definimos

 * la *restricción* $(-)_H\colon {\cal C}(G) \to {\cal C}(H)$ de funciones de clase.
 * la *inducción* $(-)^G\colon {\cal C}(H) \to {\cal C}(G)$ de funciones de clase.

La /inducción/ se define como

\[
\varphi^G(g) = \frac{1}{|H|}\sum_{x \in G}\varphi^{\bullet}(x^{-1}gx),
\]

donde $\varphi^{\bullet}(g) = \varphi(g)$ cuando $g \in H$ y $\varphi^{\bullet}(g) = 0$ cuando $g \notin H$.

***** Reciprocidad de Frobenius
Sea $H$ un subgrupo de $G$, $\varphi \in {\cal C}(H)$ y $\psi \in {\cal C}(G)$. Entonces

\[(\psi_H,\varphi) = (\psi,\varphi^G).
\]

****** TODO Demostración

***** La inducción de un carácter es carácter
Si $\varphi$ es carácter de $H$, entonces $\varphi^G$ es un carácter de $G$.

****** TODO Demostración

***** TODO Constituyentes

*** Ejercicios de clase
**** Ejercicio 1
#+begin_statement
Comprobar que $K$ es una K-álgebra.
#+end_statement

Tenemos que $K$ es un espacio vectorial sobre sí mismo y su propio
producto es una aplicación bilineal sobre $K$, ya que cumple:

  - $(a+b)c = ac+bc$, por axiomas de anillo.
  - $a(b+c) = ab+ac$, por axiomas de anillo.
  - $a(bc) = (ab)c = b(ac)$, el producto es conmutativo y asociativo.

Además es un álgebra asociativa y unital.

**** Ejercicio 2
#+begin_statement
Calcular el centro del álgebra de matrices $M_n(K)$.
#+end_statement

Supongamos $A \in Z(M_n(K))$, si tomamos las matrices que sólo tienen una 
entrada unidad y el resto ceros $E_{ij} = (\delta_{ij})_{i,j}$. Así, tenemos:

\[
E_{ii}A = \begin{pmatrix}
0 & \dots & 0 \\
^{i)} a_{i1} & \dots & a_{in} \\
0 & \dots & 0 \\
\end{pmatrix}
\qquad
AE_{ii} = \begin{pmatrix}
0 & ^{i)}a_{1i} & 0 \\
\vdots & \vdots & \vdots \\
0 & a_{ni} & 0 \\
\end{pmatrix}
\]

Por lo tanto $a_{ij} = 0$ para $i \neq j$. Además,

\[
E_{ij}A = \begin{pmatrix}
0 & ^{j)}\dots & 0 \\
^{i)} \dots & a_{ii} & \dots \\
0 & \dots & 0 \\
\end{pmatrix}
\qquad
AE_{ij} = \begin{pmatrix}
0 & ^{j)}\dots & 0 \\
^{i)}\dots & a_{jj} & \dots \\
0 & \dots & 0 \\
\end{pmatrix}
\]

Por tanto, $A = \lambda I$. Se cumple que $(\lambda I) B = \lambda (I B) = \lambda B = \lambda (B I) = B (\lambda I)$,
y el centro es de la forma

\[
\left\{
\lambda I \mid \lambda \in K
\right\}
\]

**** Ejercicio 3
#+begin_statement
Comprobar que $Im(u) \subseteq Z(A)$, siendo $u : K \longrightarrow A$, $u(\alpha) = \alpha 1_A$.
#+end_statement

Usando la bilinealidad:

\[
u(\alpha) a =
(\alpha 1) a =
\alpha (1a) =
1 (\alpha a) =
(\alpha a) 1 =
a (\alpha 1)
\]

**** Ejercicio 4
#+begin_statement
Supongamos $A$ anillo y $K$ cuerpo. Dado un homomorfismo de anillos $u : K \longrightarrow A$,
demostrar que $A$ es una K-álgebra si defino su estructura de K-espacio 
vectorial como sigue:

\[
\forall\alpha \in K, a \in A:\quad \alpha a = u(\alpha) a
\]

Es decir, podemos definir alternativamente un álgebra sobre $K$ como un
homomorfismo de anillos $u : K \longrightarrow Z(A)$, el *homomorfismo de estructura*.
#+end_statement

Debemos comprobar que la multiplicación del anillo es bilineal sobre la
estructura de espacio vectorial:

  - $(a+b)c = ac+bc$
  - $a(b+c) = ab+ac$
  - $(\alpha a)c = (u(\alpha) a) c = a u(\alpha) c$

Por lo que forma un K-álgebra.

**** Ejercicio 5
#+begin_statement
Comprobar que $Z(\mathbb{H}) = \mathbb{R}$.
#+end_statement

Supongamos un elemento en el centro $z = a+bi+cj+dk$, debería conmutar con
$i,j$, así que:

\[
0 = zi-iz = (ai-b-ck+dj) - (ai-b+ck-dj) = 2(dj-ck)
\]
\[
0 = zj-jz = (aj+bk-c-di) - (aj-bk-c+di) = 2(bk-di)
\]

De donde tenemos $b=c=d=0$, y por tanto, el elemento debe estar en $\mathbb{R}$.

**** Ejercicio 6
#+begin_statement
Dados $q,p\in \mathbb{H}$, escritos como suma de vector y escalar, se tiene la fórmula:

\[
(a+v)(b+w) = ab + aw + bv - v\cdot w + v \wedge w
\]
#+end_statement

Los tres primeros términos se tienen porque el producto escalar coincide
con el producto de un real por un cuaternión. Los dos últimos términos se
tienen como sigue. Si tomamos $v = xi+yj+zk$, $w = oi+pj+qk$; y los
interpretamos como vectores como $v = (x\ y\ z)$, $w = (o\ p\ q)$:

\[
vw = (-xo-yp-qz) + (pxk-qxj - oyk+qyi + ozj-pzi)
\]

Y comprobamos que:

\[(x\ y\ z)(o\ p\ q) = xo+yp+zq\]

\[\begin{vmatrix}
i&j&k \\
x&y&z \\
o&p&q \\
\end{vmatrix}
=
pxk-qxj - oyk+qyi + ozj-pzi
\]

**** TODO Ejercicio 7
#+begin_statement
Demostrar que un grupo abeliano $(V,+)$ junto a una acción $A\times V \to V$ es
un módulo ssi verifica las cuatro condiciones siguientes:

  1. $(a+a')v = av + a'v$
  2. $a(v+v') = av+av'$
  3. $a(a'v) = (aa')v$
  4. $1v = v$
#+end_statement
**** Ejercicio 8
#+begin_statement
Definir un submódulo.
#+end_statement

Un submódulo debe tener estructura de módulo y una inclusión al módulo
del que es submódulo. Exigimos entonces, para que tenga estructura de módulo,
que sea cerrado respecto a la suma y al producto por elementos del álgebra.
Nótese que dentro de los elementos del álgebra están los elementos del 
cuerpo base del álgebra.

**** Ejercicio 9
#+begin_statement
Sea $N_1,\dots,N_m \in {\cal L}(M)$. Demostrar que:

\[
N_1+\dots+N_m
=
\{m_1+\dots+m_n \mid m_i \in N_i \}
\]
#+end_statement

Primero notamos que es un módulo, ya que:

 - $a(m_1+\dots+m_n) = am_1+\dots+am_n$
 - $(m_1+\dots+m_n)+(m'_1+\dots+m'_n) = (m_1+m'_1) + \dots + (m_n+m'_n)$

Después notamos que si un módulo contiene a $N_1,\dots,N_m$ debe contener
todas las sumas de sus elementos por ser cerrado para la suma. Así,
este es el mínimo módulo conteniendo a $N_i$.

**** Ejercicio 10
#+begin_statement
¿Para qué valores del ángulo el giro en el plano da sólo submódulos propios?
Es decir, ¿cuándo es $\mathbb{R}^2$ simple como $\mathbb{R}[T]$ módulo con $T$ giro?
#+end_statement

Sea $M$ un submódulo de $\mathbb{R}^2$ con $v \not\in M$. Si $T(v),v$ son linealmente 
independientes, el espacio $\langle Tv,v \rangle$ será $\mathbb{R}^2$ y no podrá existir un módulo
propio. En otro caso, $\langle v \rangle$ será un módulo propio.

Para tener $Tv,v$ independientes, es necesario tener un giro múltiplo de $\pi$.

**** TODO Ejercicio 11 (★★)
#+begin_statement
Calcular todos los $\mathbb{R}[X]\text{-módulos}$ de $\mathbb{P}_n$ para la acción de derivación.
#+end_statement

**** Ejercicio 12?
#+begin_statement
Sean $M = S_1\oplus \dots \oplus S_t$, $N = T_1\oplus \dots \oplus T_n$ con $S_i,T_i$ simples y cumpliendo
$S_i \not\cong T_j$. Probar que todo homomorfismo de módulos $f \colon M \to N$ es $0$.
#+end_statement

Similar al [[*Ejercicio 23 (★)][ejercicio 23]].

*** Ejercicios de los apuntes
**** Ejercicio 1 (*)
#+begin_statement
Calcular el centro del álgebra de matrices $M_n(K)$.
#+end_statement

**** Ejercicio 2
#+begin_statement
Escribir la demostración de la Proposición 1.7.
#+end_statement

***** La imagen es subálgebra
Trivialmente, la imagen es espacio vectorial y $f(a)f(b) = f(ab)$.

***** El núcleo es un ideal
El núcleo es subespacio vectorial y además,

\[
f(ak) = f(a)f(k) = 0 = f(k)f(b) = f(kb)
\]

para cualquier $f(k) = 0$.

***** Isomorfía
Notamos primero que $\widehat f$ es el mismo que obtendríamos aplicando el
primer teorema de Isomorfía entre espacios vectoriales. Así, sabemos
que está bien definido y que es una función lineal biyectiva.

Comprobaremos simplemente que preserva el producto, probando así que
es un isomorfismo de k-álgebras; pero esto es trivial por la estructura
de álgebra con la que hemos dotado al cociente:

\[
\widehat f((a+I)(b+I)) = 
\widehat f(ab+I) = f(ab) = f(a)f(b) 
= \widehat f(a+I) \widehat f(b+I).
\]

**** Ejercicio 3
#+begin_statement
Supongamos que $K$ es un cuerpo, y $A$ es un anillo (no necesariamente
conmutativo). Sea $u : K \to A$ un homomorfismo de anillos tal que
$Im(u) \subseteq Z(A)$, donde $Z(A)$ denota el centro de $A$, definido de manera
obvia. Comprobar que si definimos la acción de $K$ sobre $A$ dada por
$\alpha a = u(\alpha) a$, para todo $\alpha \in K, a \in A$, entonces $A$ es una k-álgebra.
#+end_statement

Comprobamos primero que $A$ es un k-espacio vectorial. Con su suma es
un grupo abeliano, y por ser el producto sobre ella distributivo y
el homomorfismo de anillos unital y asociativo:

 - $u(\alpha)(a+b) = u(\alpha)a + u(\alpha)b$
 - $u(1)a = 1a = a$
 - $u(\alpha)u(\beta)(a+b) = u(\alpha\beta)(a+b)$
 - $u(\alpha+\beta)a = u(\alpha)a + u(\beta)a$

Ahora comprobaremos simplemente que el producto del anillo es una
operación bilineal en este espacio vectorial.

  - $(a+b)c = ac+bc$
  - $a(b+c) = ab+ac$
  - $(\alpha a)c = (u(\alpha) a) c = a u(\alpha) c$

Donde hemos usado distributividad del producto y que $u(\alpha) \in Z(A)$.

**** Ejercicio 4
#+begin_statement
Demostrar que, realmente, $End_K(V)$, con las operaciones recién descritas
(suma, producto escalar y composición), es una K-álgebra.
#+end_statement

La suma se define por $(f+g)(v) = f(v)+g(v)$, lo que da un grupo abeliano
con el neutro $0(v) = 0$; además, con $(\alpha f)(v) = \alpha f(v)$, nos da un espacio
vectorial.

Comprobamos además que la composición es bilineal:

  1. $((f+g)\circ h)(v) = f(h(v)) + g(h(v)) = (f\circ h + g\circ h)(v)$
  2. $(f\circ (g+h))(v) = f(g(v)) + f(h(v)) = (f\circ g + f\circ h)(v)$
  3. $(\alpha f \circ g)(v) = \alpha (f\circ g)(v)) = f(\alpha g(v)) = (f \circ \alpha g)(v)$

Donde en el primer y segundo punto usamos la definición de suma; y
en el tercer punto usamos la linealidad de la función para conmutar
el elemento del cuerpo y la aplicación de la función.

**** Ejercicio 5 (*)
#+begin_statement
Comprobar todas las afirmaciones hechas en el Ejemplo 11.
#+end_statement

***** Estructura del espacio cociente
Sabemos que cada ideal no nulo lo genera un polinomio por ser un
Dominio de Ideales Principales, que además podemos suponer mónico por ser $K$ 
un cuerpo. Como además los polinomios forman un dominio euclídeo con el
grado como función euclídea, podemos escribir cualquier polinomio $t$ como

\[
t(X) = r(X) + p(X)q(X), \text{ para } \mathrm{deg}(r) < n,
\]

y por tanto, ${\cal B} = \left\{ 1+I, x+I,\dots, x^{n-1}+I \right\}$ es un sistema generador. Sabemos
que es linealmente independiente porque si no lo fuese, tendríamos una
relación lineal que daría lugar a que un polinomio de grado menor que $n$
estuviera en el ideal. Así, ${\cal B}$ es base.

***** Matriz compañera
Podemos comprobar que la matriz compañera es la que representa a $\lambda_{x+I}$
por tenerse que $(x+I)(x^{i-1}+I) = (x^{i}+I)$ para $i < n$ y que

\[x^{n}+I = p_0-p_1x-\dots-p_{n-1}x^{n-1} + I\]

Sabemos ahora que $\lambda : A \to \mathrm{End}(A)$ es un homomorfismo inyectivo de álgebras
que lleva $\lambda_{x+I} = \tilde N(p)$ y que por ser inyectivo preserva la independencia
lineal de la base. Así, la imagen de los elementos de la base es una base
de la imagen, y tenemos que el álgebra $A$ es isomorfa a la subálgebra de
$M_n(K)$

\[
\left\{ a_0I+a_1\tilde N(p) + \dots + a_{n-1}\tilde N(p)^{n-1} \mid
a_0,a_1,\dots,a_{n-1} \in K \right\} \subseteq M_n(K).
\]

**** Ejercicio 6
#+begin_statement
Expresar el cuerpo $\mathbb{Q}(\sqrt{2})$ como una $\mathbb{Q}$ subálgebra de un álgebra de matrices
sobre $\mathbb{Q}$.
#+end_statement

Empezamos notando que

\[
\mathbb{Q}\left(\sqrt{2}\right) = \frac{\mathbb{Q}}{(X^2-2)},
\]

y que podemos por tanto aplicar el razonamiento del ejemplo 11 para saber
que si la matriz compañera del polinomio $p(x) = x^2-2$ es

\[\tilde N(p) = \begin{pmatrix}
0 & 2 \\
1 & 1
\end{pmatrix},\]

el álgebra será isomorfa a la subálgebra de $M_2(\mathbb{Q})$ dada por

\[
\left\{ aI + b\tilde N(p) \mid a,b \in \mathbb{Q} \right\}.
\]

**** Ejercicio 7
#+begin_statement
Sea

\[\mathbb{H} = \left\{ \begin{pmatrix}
\alpha & -\overline{\beta} \\
\beta & \overline{\alpha}
\end{pmatrix} \mid \alpha,\beta \in \mathbb{C} \right\}\]

  1. Demostrar que $\mathbb{H}$ es una subálgebra real de $M_2(\mathbb{C})$ y que $Z(\mathbb{H}) = \mathbb{R}$.
  2. Demostrar que todo elemento no nulo de $\mathbb{H}$ es una unidad.
  3. Demostrar que las matrices

     \[\mathbf{1} = \begin{pmatrix}1 & 0 \\0 & 1\end{pmatrix},\; 
     \mathbf{i} = \begin{pmatrix}0 & -1 \\ 1 & 0\end{pmatrix},\;
     \mathbf{j} = \begin{pmatrix}i & 0 \\ 0 & -i\end{pmatrix},\;
     \mathbf{k} = \begin{pmatrix}0 & i \\ i & 0\end{pmatrix}
     \]

     forman una base de $\mathbb{H}$ como espacio vectorial real.
  4. Comprobar las identidades

     \[
     i^2=j^2=k^2=-1,\; ij=k,\; jk=i,\; ki=j
     \]

El álgebra así construida se llama álgebra de los cuaterniones de Hamilton.
#+end_statement

***** Primer punto
Comprobamos que es cerrada bajo el producto por reales

\[\lambda\begin{pmatrix}
\alpha & -\overline{\beta} \\
\beta & \overline{\alpha}
\end{pmatrix} = \begin{pmatrix}
\lambda\alpha & -\lambda\overline{\beta} \\
\lambda\beta & \lambda\overline{\alpha}
\end{pmatrix} = \begin{pmatrix}
\lambda\alpha & -\overline{\lambda\beta} \\
\lambda\beta & \overline{\lambda\alpha}
\end{pmatrix}
\]

y que es cerrada bajo su producto

\[\begin{pmatrix}
\alpha & -\overline{\beta} \\
\beta & \overline{\alpha}
\end{pmatrix}\begin{pmatrix}
\gamma & -\overline{\delta} \\
\delta & \overline{\gamma}
\end{pmatrix} = \begin{pmatrix}
\alpha\gamma-\overline{\beta}\delta & -\overline{\delta}\alpha-\overline{\beta}\overline{\gamma} \\
\beta\gamma+\overline{\alpha}\delta & -\overline{\delta}\beta + \overline{\gamma}\overline{\alpha}
\end{pmatrix} = \begin{pmatrix}
\alpha\gamma-\overline{\beta}\delta & -\left(\overline{\beta\gamma+\overline{\alpha}\delta}\right)\\
\beta\gamma+\overline{\alpha}\delta & \overline{\alpha\gamma-\overline{\beta}\delta}
\end{pmatrix}.
\]

Además, si tomamos una matriz en el centro, debe cumplir

\[\begin{aligned}\begin{pmatrix}
a & -\overline{b} \\
b & \overline{a}
\end{pmatrix}\begin{pmatrix}
c & -\overline{d} \\
d & \overline{c}
\end{pmatrix} = \begin{pmatrix}
ac-\overline{b}d & -a\overline{d}-\overline{bc} \\
bc+\overline{a}d & \overline{ac} - b\overline{d}
\end{pmatrix} &=\\ =\begin{pmatrix}
ac-b\overline{d} & -\overline{b}c-\overline{da} \\
ad+\overline{c}b & \overline{ac}-\overline{b}d
\end{pmatrix} &= \begin{pmatrix}
c & -\overline{d} \\
d & \overline{c}
\end{pmatrix}\begin{pmatrix}
a & -\overline{b} \\
b & \overline{a}
\end{pmatrix},\end{aligned}
\]

así que $\overline{b}d = b\overline{d}$ y $\overline{a}d+bc = ad + \overline{c}d$. Tomando $c=0$ y $d=1$ llegamos a que
$a,b \in \mathbb{R}$; y tomando $d = i$, que $b=0$. Así, las únicas matrices en el centro
serán las que representan a los reales, de la forma

\[\left\{\begin{pmatrix}\lambda & 0 \\ 0 & \lambda
\end{pmatrix}\mid \lambda \in \mathbb{R}\right\}\]

***** Segundo punto
Simplemente comprobar que cada elemento tiene una inversa a derecha

\[\begin{pmatrix}
a & -\overline{b} \\ b & \overline{a}
\end{pmatrix}\begin{pmatrix}
\frac{\overline{a}}{a\overline{a}+b\overline{b}} & 
\frac{\overline{b}}{a\overline{a}+b\overline{b}} \\ 
\frac{-b}{a\overline{a}+b\overline{b}} & 
\frac{a}{a\overline{a}+b\overline{b}}
\end{pmatrix} = \begin{pmatrix}
1 & 0 \\ 0 & 1
\end{pmatrix}\]

usando que si $a\overline{a}+b\overline{b} = 0$, es porque $a=b=0$ y el elemento es nulo.

***** Tercer punto
Sabiendo que los complejos son un espacio vectorial de dimensión $2$
con base $\{1,i\}$, podemos escribir los elementos de $\mathbb{H}$ como

\[\begin{pmatrix}
a+bi & -c+di \\
c+di & a-bi
\end{pmatrix} = a\begin{pmatrix}
1 & 0 \\ 0 & 1
\end{pmatrix}+
b\begin{pmatrix}
i & 0 \\ 0 & -i
\end{pmatrix}+
c\begin{pmatrix}
0 & 1 \\ -1 & 0
\end{pmatrix}+
d\begin{pmatrix}
0 & i \\ i & 0
\end{pmatrix}\]

que trivialmente es una descomposición única por independencia lineal.

***** Cuarto punto
Podemos comprobar trivialmente los cálculos.

**** Ejercicio 8
#+begin_statement
Dado un A-módulo $V$, demostrar que $\mathrm{Ann}_A(V) = \left\{ a \in A \mid av=0\; \forall v\in V \right\}$ es un
ideal de $A$. Dotar a $V$ de estructura de $A/\mathrm{Ann}_{A}(V)\text{-módulo}$ fiel (es decir,
la representación correspondiente es fiel).
#+end_statement

Si $a \in \mathrm{Ann}_A(V)$ tenemos que para cualquier $r \in A$ y $v \in V$, $rav = r0 = 0$ y 
$(ar)v = a(rv) = 0$. Podemos dotar a $V$ de estructura de módulo en el cociente
como

\[
\left( a+ \mathrm{Ann}(V) \right)v = av.
\]

Esta representación es fiel porque si tenemos $\forall v\in V\colon av = bv$, entonces
se tiene $a-b \in \mathrm{Ann}(V)$.

**** Ejercicio 9
#+begin_statement
Dar una demostración del Lema 1.25.
#+end_statement

***** Primer punto
Es claro que el menor submódulo que contenga a $N_1 \cup \dots \cup N_m$ debe contener
en particular a todas las sumas y por tanto

\[
\left\{ n_1+\dots+n_m \mid n_i \in N_i \right\} \subseteq N_1 + \dots + N_m.
\]

Si además probamos que es un submódulo, tendremos que debe ser el menor
conteniendo a la unión. Es cerrado para la suma por tenerse

\[
(n_1+\dots+n_m)+(n'_1+\dots+n'_m) =
(n_1+n'_1)+\dots+(n_m+n_m')
\]

y cerrado para el producto por elementos del anillo por tenerse

\[
a(n_1+\dots+n_m) = an_1+\dots+an_m.
\]

***** Segundo punto
De la misma forma, es claro que el menor submódulo conteniendo a $X$ debe
contener al menor módulo conteniendo a cada uno de sus elementos, y por
tanto al menor submódulo conteniendo a todos esos submódulos. Sabemos
entonces que

\[
RX \supseteq Rm_1 + \dots + Rm_n.
\]

Pero además, una suma de módulos es un submódulo, así que este es el menor
submódulo que contiene a $X$.

**** Ejercicio 10
#+begin_statement
Dados $A\text{-módulos}$ por la izquierda $M,N$ y una aplicación $f\colon M \to N$,
demostrar que $f$ es homomorfismo de $A\text{-módulos}$ si, y sólo si,
$f(am+a'm') = af(m) + a'f(m')$ para todo $a,a'\in A;\; m,m'\in M$.
#+end_statement

***** Si es homomorfismo de módulos cumple la regla
Aplicando primero linealidad y luego dos veces la condición de homomorfismo
de módulos tenemos

\[
f(am+a'm') = f(am)+f(a'm') = af(m) + a'f(m').
\]

***** Si cumple la regla, es homomorfismo de módulos
La linealidad la comprobamos tomando $a=a'=1$, la unidad del álgebra,

\[
f(m+m') = f(1m+1m') = 1f(m) + 1f(m') = f(m) + f(m').
\]

Y la condición de homomorfismo de módulos se comprueba tomando $a' = m'=0$,

\[
f(am) = f(am+0) = af(m) + 0f(0) = af(m).
\]

**** Ejercicio 11
#+begin_statement
Demostrar que un conjunto de generadores $\{m_i \mid i \in I\}$ de un módulo $_RM$ es una
base si, y sólo si, la igualdad $\sum_{i\in I}r_im_i = 0$ para $r_i \in R$ implica $r_i = 0$ para
todo $i \in I$.
#+end_statement

***** Si es una base, se tiene la condición
Si tenemos una base $\{m_i \mid i \in I\}$, en particular el $0$ se escribe de forma 
única como $0 = \sum_{i\in I} 0m_i$. Así, cualquier otra forma de escribir $0 = \sum_{i\in I} r_i m_i$
nos da $r_i = 0$.

***** Si se tiene la condición, es una base
Si tenemos la condición y tenemos dos formas distintas de escribir un
elemento, tendríamos en particular

\[
\sum_{i\in I} r_im_i = m = \sum_{i\in I}s_im_i
\quad\text{ y }\quad
\sum_{i \in I} (r_i-s_i)m_i = 0.
\]

Lo que nos llevaría a $r_i = s_i$ para cumplir la condición.

**** Ejercicio 12
#+begin_statement
Sea $\theta \in \mathbb{R}$ y $T_\theta : \mathbb{R}^2\to\mathbb{R}^2$ el endomorfismo que gira los vectores un ángulo $\theta$
en sentido contrario de las agujas del reloj. Consideremos la correspondiente
estructura de $\mathbb{R}[X]$ módulo definida por $T_\theta$ sobre $\mathbb{R}^2$. Discutir para qué valores
de $\theta$ es este módulo simple.
#+end_statement

Supongamos un $v \in M$, subespacio vectorial. Como $Tv \in M$, tenemos dos casos,

  * si $Tv,v$ son linealmente dependientes, se tiene $Tv = \lambda v$ y por tanto debe
    tenerse $\theta = k\pi$ para algún $k \in \mathbb{Z}$. El módulo no sería simple, ya que se
    tendría $T^2v = v$.
  * si no son linealmente dependientes, se tiene un espacio de dimensión al
    menos $2$, que debe ser por tanto el total. El módulo sería simple.

Es decir, salvo en el caso $\theta = k\pi$, el módulo es simple.

**** Ejercicio 13
#+begin_statement
Sea $M$ un $A\text{-módulo}$. Demostrar que $M$ es simple si, y sólo si, $M = Am$ para
todo $0 \neq m \in M$.
#+end_statement

***** Supongamos M simple
Entonces $Am$ es un submódulo no nulo, que debe ser por tanto $M$.

***** Supongamos la caracterización
Sea un submódulo de $M$ que contiene a algún elemento no nulo $m$. Por
las propiedades de submódulo, debe contener también a todo $Am = M$.
Así, no existen submódulos propios.

**** Ejercicio 14 (*)
#+begin_statement
Consideramos $T\colon \mathbb{R}^3 \to \mathbb{R}^3$ una aplicación lineal, y la estructura de $\mathbb{R}[X]\text{-módulo}$
correspondiente sobre $\mathbb{R}^3$. Discutir los posibles valores de la longitud de
$\mathbb{R}^3$ como $\mathbb{R}[X]\text{-módulo}$. Poner un ejemplo de $T$ para el que se alcance cada longitud.
#+end_statement

La longitud debe ser como máximo $3$, su dimensión como espacio vectorial
sobre $\mathbb{R}$. Estudiaremos los casos posibles.

*Longitud 1.*
Probaremos que no puede tenerse una cadena de longitud $1$; es decir, que
$\mathbb{R}^3$ sea simple. Toda aplicación lineal $T$ nos da una ecuación polinómica

\[ | T - \lambda I | = 0
\]

de grado $3$ con coeficientes reales, que debe tener al menos una solución
en los reales. Esto nos da un vector propio y por tanto un subespacio que
queda fijo por la acción de $T$; es decir, un submódulo.

*Longitud 2.*
Tomamos $T$ la aplicación que gira un plano mientras deja fija la recta
ortogonal a él; específicamente,

\[T = \begin{pmatrix}
0 & 1 & 0 \\
-1 & 0 & 0 \\
0 & 0 & 1
\end{pmatrix}
\]

nos da el subespacio $\left\langle e_3 \right\rangle$ fijo bajo su acción. Por otro lado, el
submódulo $\left\langle e_1,e_2 \right\rangle \cong \mathbb{R}^3/ \left\langle e_3 \right\rangle$ es simple; la rotación no dejará ninguna
recta fija, no hay vectores propios. Así, tenemos una serie de
composición

\[
0 \subset \left\langle e_1,e_2 \right\rangle \subset \mathbb{R}^3.
\]

*Longitud 3.*
Simplemente tomando la identidad y retirando a cada paso una dimensión
del espacio vectorial

\[
0 \subset \left\langle e_1 \right\rangle
\subset \left\langle e_1,e_2 \right\rangle
\subset \left\langle e_1,e_2,e_3 \right\rangle.
\]

**** Ejercicio 15
#+begin_statement
Sea $\mathbb{P}_{n}$ el espacio vectorial real de las funciones polinómicas en una variable
de grado menor o igual que $n$. Sea $T\colon \mathbb{P}_n \to \mathbb{P}_n$ la aplicación lineal que asigna
a cada polinomio su derivada. Calcular una serie de composición de $\mathbb{P}_n$ visto
como $\mathbb{R}[X]\text{-módulo}$ via $T$.
#+end_statement

Tenemos una base del espacio vectorial dada por $\left\{ 1,x,\dots,x^n \right\}$, podemos generar
una serie de composición donde vemos que cada uno es un submódulo cerrado para
la derivación y que cada cociente es simple por ser de dimensión $1$ en los reales
como

\[
0 \subset 
\left\langle 1 \right\rangle \subset
\left\langle 1,x \right\rangle \subset 
\dots \subset
\left\langle 1,x,\dots,x^n \right\rangle.
\]

**** Ejercicio 16 (**)
#+begin_statement
En las condiciones del Ejercicio 15, calcular todos los $\mathbb{R}[X]\text{-submódulos}$ de $\mathbb{P}_n$.
#+end_statement

Probaremos que los únicos submódulos de $\mathbb{P}_n$ son de la forma $\left\langle 1,x,x^2,\dots,x^k \right\rangle$.
Si tomamos un polinomio en un submódulo podemos suponerlo mónico por estar
en un cuerpo; y como además es de característica $0$, sus derivadas serán cada
una de un grado menor. Así, dado $p = x^k+ \dots +a_1x + a_0 \in \mathbb{P}_n$ tendremos

\[\begin{aligned}
p =& x^k+& a_{k-1}x^{k-1} +& \dots &+& a_1x &+& a_0 \\
\partial p =&  &kx^{k-1}+& \dots &+& 2a_2x &+ &a_1 \\
\dots \\
\partial^n p =&  && && && k! \\
\end{aligned}\]

Lo que constituye una base del espacio de polinomios de dimensión $k$ 
equivalente a $\left\langle 1,x,x^2,\dots,x^k \right\rangle$ gracias a que estamos en un cuerpo. Así,
cada submódulo será el submódulo de los polinomios de grado menor o igual
a $k$ para $k$ el grado de su polinomio de mayor grado.

**** Ejercicio 17 (**)
#+begin_statement
Supongamos $T \colon V \to V$ un endomorfismo $K\text{-lineal}$, donde $V$ es un espacio vectorial
de dimensión finita que consideramos, como de costumbre, como $K[X]\text{-módulo}$.
Supongamos que el polinomio mínimo $m(X)$ de $T$ es irreducible en $K[X]$ (ver
Ejemplo 14 para el concepto de polinomio mínimo). Demostrar que existen 
$K[X]\text{-submódulos}$ simples $V_1,\dots,V_t$ de $V$ tal que $V = V_1\oplus \dots \oplus V_{t}$ como
$K[X]\text{-módulo}$.
#+end_statement

Como $m(X)$ es irreducible y estamos en un DIP el ideal que genera,
$(m(X))$, es maximal, y por tanto el cociente

\[
k \cong \frac{K[X]}{(m(X))}
\]

es un cuerpo. Y $V$ es un $k\text{-espacio vectorial}$ ya que por el primer teorema de 
isomorfía tenemos que $K[X] \to \mathrm{End}_K(V)$ descompone en una proyección y una
inyección

\[\begin{tikzcd}
K[X] \rar[two heads] & 
\displaystyle\frac{K[X]}{(m(X))} \rar[hook] &
\mathrm{End}_K(V).
\end{tikzcd}\]

Ahora, si $V$ tiene una base finita como $K\text{-espacio vectorial}$, sabiendo que $K \subseteq k$,
tenemos que $V$ tiene un sistema de generadores finito como $k\text{-espacio vectorial}$.
Por el Corolario 1.45 existe entonces un subconjunto de ese sistema de 
generadores tal que

\[
V = \bigoplus_{j \in J} kv_j = V_1 \oplus \dots \oplus V_t.
\]

Nótese que cada uno de ellos es un submódulo simple por ser isomorfos a $k$.

**** Ejercicio 18 (**)
#+begin_statement
En las condiciones del Ejercicio 17, demostrar que el polinomio característico
de $T$ es $m(X)^t$.
#+end_statement

Por Cayley-Hamilton, sabemos que $T$ cumple su ecuación característica, y por
tanto, $m(X)$ divide a su polinomio característico. 

Por otro lado, supongamos que tenemos un factor irreducible $p$ del
polinomio característico; este tendrá alguna raíz $\lambda$ en la clausura
algebraica de $K$. Es decir, tendremos un vector propio con coeficientes
en $\overline{K}$ cumpliendo $Tv = \lambda v$.

Si aplicamos el polinomio mínimo evaluado en $T$ a ese vector tendremos

\[
0 = m(T)v = m(\lambda)v,
\]

así que $\lambda$ es una raíz de $m$ en la clausura algebraica. Ahora, como el
polinomio irreducible de $\lambda$ en $K$ sigue siendo $p$, concluimos que $p \mid m$.

En general, hemos demostrado que todo factor irreducible del polinomio
característico divide al polinomio mínimo. Cuando además el polinomio
mínimo es irreducible, se tiene que el polinomio característico debe
ser de la forma $m(X)^s$.

Ahora comprobaremos que $s=t$. En efecto, tenemos que si $\mathrm{gr}(m) = n$,
entonces, por construcción, $\mathrm{dim}_Kk=n$ y por ser $V_i \cong k$, tenemos
$\mathrm{dim}_{K}(V) = tn$; que debe ser el grado del polinomio característico,
a la vez que debe ser $sn$.

**** Ejercicio 19
#+begin_statement
Demostrar que si $R$ es un dominio de integridad conmutativo, entonces $R$ no
tiene idempotentes no triviales.
#+end_statement

Si $e^2=e$, entonces $e(e-1) = 0$; lo que, en un dominio de integridad implica
que $e = 0$ ó $e-1 = 0$.

Nótese que no hemos usado la conmutatividad.

**** Ejercicio 20
#+begin_statement
Dar un CCIO para $R = M_n(k)$.
#+end_statement

Sean $E_{ii}$ las matrices nulas excepto por un $1$ en la entrada $i,i$. Se comprueba
trivialmente que $E_{ii}E_{jj} = 0$ para cualesquiera $i \neq j$, y que $E_{ii}^2 = 1$. Forman
además un conjunto completo por tenerse:

\[
I = E_{11} + E_{22} + \dots + E_{nn}
\]
**** TODO Ejercicio 21
#+begin_statement
Comprobar las afirmaciones realizadas en el Ejemplo 17.
#+end_statement
**** Ejercicio 22
#+begin_statement
Sea $\left\{ e_1,\dots,e_n \right\}$ un ccio para $R$. Demostrar que los idempotentes $e_1,\dots,e_n$ son
centrales si, y sólo si, $e_iRe_j = 0$ para todo $i \neq j$.
#+end_statement

***** Si son centrales, cumplen la condición
Si son centrales, se tiene que, para cualquier $r \in R$,

\[
e_ire_j = re_ie_j = 0
\]

por ortogonalidad.

***** Si cumplen la condición, son centrales
Sabiendo que cumplen que $e_ire_j = 0$ para cualquier $r \in R$, tenemos

\[
e_ir = e_ir\left(\sum_j e_j\right) = \sum_j e_ire_j = e_ire_i = \sum_j e_jre_i = re_i
\]

por ser completos.

**** Ejercicio 23 (*)
#+begin_statement
Sean $M$ y $N$ módulos semisimples con descomposiciones como sumas directas
de submódulos simples $M = S_1 \oplus \dots \oplus S_t$ y $N = T_1\oplus \dots \oplus T_s$. Supongamos que
$S_i$ no es isomorfo a $T_j$ para todo $i = 1,\dots,t$, $j = 1,\dots,s$. Demostrar que
todo homomorfismo de módulos de $M$ a $N$ es cero.
#+end_statement

Desde el ejemplo 17, sabemos que, en los endomorfismos de un módulo suma
directa, la composición de inclusión y proyección en las distintas componentes
nos da un ccio. Vamos a llamar $q_i \colon M \to M$ al endomorfismo que proyecta e
incluye en la componente $i\text{-ésima}$; y vamos a llamar $p_j \colon N\to N$ al que hace
lo mismo en la componente $j\text{-ésima}$ de $N$. Sabemos que

\[
q_1 + \dots + q_t = \mathrm{id}
\quad\text{ y que }\quad
p_1 + \dots + p_s = \mathrm{id}.
\]

Ahora, calculamos que

\[\begin{aligned}
f &= (q_1+\dots+q_t) \circ f \circ (p_1+\dots+p_s) \\
  &= \sum_{i=1}^t\sum_{j=1}^s q_i\circ f\circ p_j = 0,
\end{aligned}\]

ya que $q_i\circ f\circ p_j\colon S_i\to T_i$ debe ser nulo o isomorfismo por el Lema de Schur
y hemos supuesto que no es isomorfismo.

# Nótese que no es exactamente esto, sino que hay que partir q en sus
# componentes para igualar a cero.

**** TODO Ejercicio 24
#+begin_statement
Sea $M$ un módulo semisimple de dimensión finita con estructura
$\left( n_1,\Sigma_1 \right),\dots,(n_t,\Sigma_t)$. Si $N$ es un submódulo de $M$, demostrar que su estructura
es $\left( m_1,\Sigma_1 \right),\dots,(m_t,\Sigma_t)$ para ciertos $m_j \leq n_j$ (admitimos que $m_j=0$ significa
que $\Sigma_j$ no aparece en la estructura de $M$).
#+end_statement
**** TODO Ejercicio 25
#+begin_statement
Establecer un enunciado análogo al del Ejercicio 24 para cada cociente de $M$.
#+end_statement
**** TODO Ejercicio 26
#+begin_statement
Dada una $K\text{-álgebra}$ $A$, demostrar que la aplicación $\rho\colon A \to \mathrm{End}(A)^{op}$ definida
por $\rho(a)(a') = a'a$ es un isomorfismo de $K\text{-álgebras}$.
#+end_statement

**** TODO Ejercicio 27 (*)
#+begin_statement
Sea $B$ un álgebra. Demostrar que la aplicación que asigna a cada matriz
su traspuesta da un isomorfismo de álgebras $M_n(B)^{op} \cong M_n(B^{op})$.
#+end_statement

**** TODO Ejercicio 28
#+begin_statement
Sea $\varphi\colon R \to S$ un isomorfismo de $K\text{-álgebras}$, e $I,J$ ideales por la izquierda
de $R$. Demostrar que $\varphi(I),\varphi(J)$ son ideales por la izquierda de $S$ y que dado
cualquier homomorfismo de $R\text{-módulos}$ $f \colon I \to J$, la aplicación $\widehat f\colon \varphi(I) \to \varphi(J)$
definida por $\widehat f(y) = \varphi f \varphi^{-1}(y)$ para $y \in \varphi(I)$ es un homomorfismo de $S\text{-módulos}$.
#+end_statement

**** TODO Ejercicio 29
#+begin_statement
Sean $R_1,\dots,R_n$ $K\text{-álgebras}$ y $R = R_1\times \dots \times R_n$. Los ideales por la izquierda
de $R$ son de la forma $I_1\times \dots\times I_n$, con $I_i$ ideal por la izquierda de $R_i$ para
$i = 1,\dots,n$. Análoga descripción tienen los ideales biláteros de $R$.
#+end_statement

**** TODO Ejercicio 30 (*)
#+begin_statement
Sea $A$ un álgebra simple finito-dimensional. Demostrar que $R = \mathrm{M}(A)$ es un
álgebra simple de dimensión finita. Demostrar que asimismo que si $\Sigma$ es un
$A\text{-módulo}$ simple y $M$ es un $R\text{-módulo}$ simple, entonces $\mathrm{End}(\Sigma)$ y $\mathrm{End}(M)$
son álgebras isomorfas.
#+end_statement

**** Ejercicio 31 (*)                                                                                       :export:
#+begin_statement
Demostrar que $T_q \in SO(V)$ para todo cuaternio $q$ de norma $1$.
#+end_statement

Sabiendo que los cuaternios se expresan como $\mathbb{H} = \mathbb{R} \oplus V$ escribimos $q = a + bu$, 
donde $u \in V$ y $\|u\| = 1$, lo que nos da $u^2 = -u(-u) = -1$. Como $q$ es de norma $1$ 
debe cumplir

\[
1 = qq^{\ast} = a^2 - ub^2 = a^2 + b^2,
\]

luego puede expresarse como $q = \cos \theta + \sin\theta u$ para algún $\theta \in \mathbb{R}$. Pero entonces
tenemos un cuaternio $w = \cos(\theta/2) + \sin(\theta/2) u$ que al elevarlo al cuadrado
nos da $q$, ya que

\[ w^2 =
\left( \cos \frac{\theta}{2} + \sin \frac{\theta}{2}u \right)^2 =
\cos^2 \frac{\theta}{2} - \sin^2 \frac{\theta}{2} + 
2 \sin \frac{\theta}{2}\cos \frac{\theta}{2}u =
\cos \theta + \sin \theta u = q.
\]

Finalmente, como $T_q = T_w \circ T_w$ siendo isometrías, tenemos que
debe cumplirse que $|T_q| = |T_w|^2 = 1$ y por tanto, $T_q \in SO(V)$.

**** Ejercicio 32 (*)                                                                                       :export:
#+begin_statement
Calcular explícitamente una representación real no trivial de grado $2$ del
grupo de permutaciones $S_3$.
#+end_statement

Partimos de la idea de que $D_6 = S_{3}$, así que cada elemento representará
una simetría del triángulo equilátero con centro en el origen y un
vértice en $(1\ 0)$.

En $\mathbb{R}^2$, llamamos $r,s,t$ a las rectas de ángulos $0,2\pi/3,4\pi/3$. Consideraremos
las trasposiciones como simetrías respecto de estas rectas, y las permutaciones
de tres elementos serán rotaciones compuestas de dos simetrías. Explícitamente,
las trasposiciones de dos elementos son

\[
(2\ 3) \mapsto \begin{pmatrix} 1 & 0 \\ 0 & -1 \end{pmatrix},
\quad
(1\ 2) \mapsto \begin{pmatrix} -1/2 & \sqrt{3}/2 \\ \sqrt{3}/2 & 1/2 \end{pmatrix},
\quad
(1\ 3) \mapsto \begin{pmatrix} -1/2 & -\sqrt{3}/2 \\ -\sqrt{3}/2 & 1/2 \end{pmatrix},
\]

y las rotaciones son

\[
(1\ 2\ 3) \mapsto 
\begin{pmatrix} -1/2 & -\sqrt{3}/2 \\ \sqrt{3}/2 & -1/2 \end{pmatrix},
\quad
(1\ 3\ 2) \mapsto
\begin{pmatrix} -1/2 & \sqrt{3}/2 \\ -\sqrt{3}/2 & -1/2 \end{pmatrix}.
\]

Y podemos comprobar sobre ellas que cumplen la tabla de multiplicación
del grupo.

**** Ejercicio 33
#+begin_statement
Comprobar que la multiplicación definida sobre $KG$ es asociativa. Su elemento
neutro es $1e$, donde $e$ es el elemento neutro de $G$.
#+end_statement

Tenemos por bilinealidad

\[
\left( \sum_{g \in G} \lambda_gg \right)
\left( \sum_{h \in G} \mu_hh \sum_{k \in G} \delta_kk \right) =
\sum_{g \in G} \lambda_gg \sum_{j,k \in G} \mu_h\delta_k hk =
\sum_{g,j,k \in G} \lambda_g\mu_h\delta_k g(hk),
\]

mientras que

\[
\left( \sum_{g \in G} \lambda_gg \sum_{h \in G} \mu_hh \right)
\left( \sum_{k \in G} \delta_kk \right) =
\sum_{g \in G} \lambda_g\mu_hgh \sum_{j,k \in G} \delta_kk =
\sum_{g,j,k \in G} \lambda_g\mu_h\delta_k (gh)k,
\]

que son iguales por asociatividad del producto de grupo. Hemos demostrado
en general que cualquier bilineal que extienda un operador binario sobre
los vectores de la base es asociativo.

**** TODO [#A] Ejercicio 34
#+begin_statement
Calcular todos los subespacios invariantes para la representación de $Q_8$ 
del Ejemplo 20.
#+end_statement

**** TODO [#A] Ejercicio 35
#+begin_statement
Calcular todos los subespacios invariantes para la representación de $S_3$
del Ejemplo 32.
#+end_statement

**** TODO Ejercicio 36
**** TODO Ejercicio 37
**** TODO Ejercicio 38
**** TODO Ejercicio 39
**** Ejercicio 40 (*)                                                                                       :export:
#+begin_statement
Calcular razonadamente la tabla de caracteres de $Q_8$.
#+end_statement

Puede comprobarse multiplicando que el grupo tiene cinco clases de conjugación,
con representantes dados por $1,-1,i,j,k$, por lo que tiene cinco representaciones
irreducibles complejas. Sabemos que los cuadrados de las dimensiones de esas 
representaciones deben sumar el orden del grupo, es decir 

\[ 8 = n_1^2 + n_2^2 + n_3^2 + n_4^2 + n_5^2,\]

y como no pueden tenerse dos $n_i > 1$, la única solución posible es que tengan
dimensiones $1,1,1,1,2$, determinando el caracter de la identidad en cada una
de las representaciones.

 * El /primer carácter/ será el dado por la representación irreducible trivial
   que envía cada elemento del grupo a $1 \in \mathbb{C}$.
 * El /último carácter/, de dimensión $2$ es el dado por la representación de los
   cuaternios como matrices complejas que conocemos del Ejercicio 7. Es además
   irreducible por tenerse $(\chi_5,\chi_5) = (2^2+(-2)^2)/8 = 1$.
 * Para cualquiera de $i,j,k$, existe un subgrupo normal de $Q_8$ generado por
   el elemento con $4$ elementos, como por ejemplo $\left\{ 1,-1,i,-i \right\}$. Si llamamos a
   este grupo $A$, se tiene que $Q_8/A \cong \mathbb{Z}_2$, el único grupo de cardinalidad $2$.
   Este grupo tiene una representación irreducible en $\mathbb{C}$ como $1,-1$, y por
   el Ejercicio 38, sabemos que la composición de representación irreducible
   con una proyección a un cociente por un subgrupo normal es una 
   representación irreducible, así que lo es

   \[
   \rho_{A}\colon Q_8 \overset{\pi}\longrightarrow Q_8 / A \cong \mathbb{Z}_2 
   \longrightarrow \mathbb{C}.
   \]

   Esta representación la podemos repetir para los $A$ generados por $i,j,k$,
   dándonos las tres representaciones restantes con caracteres $\chi_2,\chi_3,\chi_4$ 
   respectivamente. Nótese que cada una de ellas
   envía al elemento $1$ a los elementos del grupo y a $-1$ a los elementos fuera
   del grupo.

Tenemos finalmente la tabla de caracteres irreducibles

\[\begin{tabular}{c|ccccc}
    & 1 &  1 & 2 & 2 & 2 \\
Q_8 & 1 & -1 & i & j & k \\
\hline
\chi_1 & 1 &  1 &  1 &  1 &  1 \\
\chi_2 & 1 &  1 & 1  & -1  & -1   \\
\chi_3 & 1 &  1  & -1   & 1   &  -1  \\
\chi_4 & 1 &  1  &  -1  & -1   & 1   \\
\chi_5 & 2 & -2 &  0 &  0 &  0 \\
\end{tabular}\]

**** TODO Ejercicio 41 (*)
#+begin_statement
Calcular razonadamente la tabla de caracteres del grupo dihédrico $D_4$.
#+end_statement

Tomamos la presentación del grupo dihédrico

\[
\left\langle r,s \mid r^4=s^2=e, sr = r^{-1}s \right\rangle
\]

y comprobamos multiplicando que tiene $8$ elementos y $5$ clases de conjugación
con representantes $e,r,s,r^2,sr$, por lo que tiene cinco representaciones
irreducibles complejas. Sabemos que los cuadrados de las dimensiones de esas 
representaciones deben sumar el orden del grupo, es decir 

\[ 8 = n_1^2 + n_2^2 + n_3^2 + n_4^2 + n_5^2,\]

y como no pueden tenerse dos $n_i > 1$, la única solución posible es que tengan
dimensiones $1,1,1,1,2$, determinando el caracter de la identidad en cada una
de las representaciones.

 * El /primer carácter/ será el dado por la representación irreducible trivial
   que envía cada elemento del grupo a $1 \in \mathbb{C}$.

 * Tenemos tres subgrupos normales generados por $\left\langle e,r^2,s \right\rangle$, $\left\langle e,r^2,r \right\rangle$ y $\left\langle e,r^2,sr \right\rangle$,
   cada uno de ellos con cuatro elementos. Si llamamos a cualquiera de ellos
   $A$, tenemos la representación irreducible dada por la composición de la
   proyección al cociente con la representación irreducible de $\mathbb{Z}_2$ en los
   complejos

   \[
   \rho_{A}\colon D_4 \overset{\pi}\longrightarrow D_4 / A \cong \mathbb{Z}_2 
   \longrightarrow \mathbb{C}
   \]

   que es irreducible en virtud del Ejercicio 38. Esto nos da las
   representaciones con caracteres $\chi_2,\chi_3,\chi_4$ que envían cada elemento del
   grupo $A$ al $1$ y cada elemento fuera del grupo al $-1$.

 * El último carácter proviene de la representación matricial

   \[
   r \mapsto \begin{pmatrix}
   0 & -1 \\ 1 & 0
   \end{pmatrix} 
   \qquad
   s \mapsto \begin{pmatrix}
   1 & 0 \\ 0 & -1
   \end{pmatrix},
   \]
   
   # la irreducibilidad se debe comprobar (χ,χ)=1
   que podemos comprobar que cumple las relaciones de la presentación.
   Por el caracter que define, que no es suma de otros dos caracteres 
   irreducibles, sabemos que es forzosamente la representación irreducible
   que nos falta.

Tenemos finalmente la tabla de caracteres irreducibles como

\[\begin{tabular}{c|ccccc}
    & 1 &  1 & 2 & 2 & 2 \\
D_4 & $e$ & $r^2$ & $s$ & $r$ & $sr$ \\
\hline
\chi_1 & 1 &  1 &  1 &  1 &  1 \\
\chi_2 & 1 &  1 & 1  & -1  & -1   \\
\chi_3 & 1 &  1  & -1   & 1   &  -1  \\
\chi_4 & 1 &  1  &  -1  & -1   & 1   \\
\chi_5 & 2 & -2 &  0 &  0 &  0 \\
\end{tabular}\]

Nótese que es la misma tabla de caracteres que $Q_8$.

**** Ejercicio 42 (**)                                                                                      :export:
#+begin_statement
Calcular razonadamente la tabla de caracteres del grupo dihédrico $D_n$, 
para $n \geq 2$.
#+end_statement

Tomamos la presentación del grupo dihédrico

\[
\left\langle r,s \mid r^n=s^2=e, sr = r^{-1}s \right\rangle,
\]

y sabemos que es un grupo de $2n$ elementos. 

***** Clases de conjugación del caso impar
Cuando $n$ sea impar, sus clases de conjugación, que obtenemos
conjugando con los generadores, serán las siguientes:

 * La clase trivial $\left\{ 1 \right\}$.
 * Las clases de la forma $\left\{ r^i,r^{-i} \right\}$, donde $0 < i < n$, que se puede comprobar
   que permanecen invariantes por conjugación de los generadores. Tenemos
   $(n-1)/2$ clases de este tipo, cada una con dos elementos ya que por
   ser $n$ impar, $r^i\neq r^{-i}$.
 * La clase $\left\{ sr^i \mid 0 \leq i < n \right\}$, que se genera desde $s$ usando que $r^isr^{-i} = sr^{-2i}$ 
   y que $n$ es impar. Es una clase de $n$ elementos.

Sumando las cardinalidades de todas ellas, observamos que no hay más, ya
que

\[
2n = 1 + 2 \frac{n-1}{2} + n.
\]

Tenemos $(n+3)/2$ clases de conjugación, luego tendremos $(n+3)/2$
representaciones irreducibles complejas.

***** Representaciones en el caso impar
Podemos considerar los caracteres y representaciones siguientes:

 * el caracter trivial dado por la *representación irreducible trivial*
   que envía cada elemento del grupo a $1 \in \mathbb{C}$.

 * el grupo generado por $\left\langle r \right\rangle$ es normal y tenemos $D_n/\left\langle r \right\rangle \cong \mathbb{Z}_2$, luego una
   representación dada por la proyección y la representación irreducible
   de $\mathbb{Z}_2$ en los complejos es irreducible. La llamamos $\chi_2$.

 * si interpretamos los grupos dihédricos como grupos de simetrías de
   los polígonos, podemos escribir representaciones bidimensionales
   que toman $r$ como cualquiera de las rotaciones de ángulos $2\pi k/n$ en
   los complejos y $s$ como la simetría, es decir,

   \[
   r \mapsto \begin{pmatrix}
   e^{2\pi i k/n} & 0 \\
   0 & e^{-2\pi i k/n} \\
   \end{pmatrix}, \quad
   s \mapsto \begin{pmatrix}
   0 & 1 \\
   1 & 0 \\
   \end{pmatrix}.\]
   
   Comprobaremos que para $k>0$ todas ellas son irreducibles. Los
   espacios que deja invariantes la primera son claramente $(1\ 0)$ y
   $(0\ 1)$ con dos valores propios $e^{2\pi i k/n} \neq e^{-2\pi i k/n}$
   (aquí usamos $n$ impar), pero no son invariantes bajo simetrías,
   por lo que no existen subespacios invariantes y la representación
   es irreducible. A sus caracteres los llamamos $\chi_{k+2}$.

Dentro de las últimas, existirán algunas que serán equivalentes. Notamos
que la característica de $r$ bajo la representación dada por $k$ es $2\cos(2\pi k/n)$,
por lo que cada $k$ entre $1, \dots, (n-1)/2$ da una característica distinta y por
tanto una representación no equivalente a las demás. Con estas tenemos en
total $(n+3)/2$ representaciones irreducibles distintas, por lo que el resto
serán equivalentes.

***** Tabla de caracteres del caso impar
Tenemos finalmente la tabla de caracteres irreducibles como

\[
\small
\begin{tabular}{c|cccccc}
    & 1 &  2 & 2 & \dots & 2 & $n$ \\
D_n & $e$ & $r$ & $r^2$ & $\dots$ & $r^{(n-1)/2} & $s$ \\
\hline
\chi_1 & 1 &  1 &  1 &  \dots &  1 & 1 \\
\chi_2 & 1 &  1 & 1  &  \dots  & 1 & -1  \\
\chi_{2+1} &  2 & 2\cos(2\pi 1/n) &  2\cos(2 \pi 2/n)  & \dots   & 2\cos(2 \pi (n-1)/2n)  & 0 \\
\chi_{2+2} &  2 & 2\cos(2\pi 2/n) &  2\cos(2 \pi 4/n)  & \dots   & 2\cos(2 \pi 2(n-1)/2n)  & 0 \\
\dots & \dots & \dots & \dots  & \dots  & \dots & \dots \\
\chi_{2+(n-1)/2} &  2 & 2\cos(2\pi (n-1)/2n) &  2\cos(2 \pi 2(n-1)/2n)  & \dots   & 2\cos(2 \pi (n-1)(n-1)/4n)  & 0 \\
\end{tabular}\]

***** Clases de conjugación del caso par
Cuando $n$ es par, sus clases de conjugación, que obtendremos conjugando
con los generadores, serán las siguientes:

 * La clase trivial $\left\{ 1 \right\}$.
 * La clase que forma $\left\{ r^{n/2} \right\}$.
 * Las clases de la forma $\left\{ r^i,r^{-i} \right\}$, donde $0 < i < n$ y además exigimos que
   $i = n/2$ para evitar el caso $r^i = r^{-i}$. Tenemos $(n-2)/2$ clases de este
   tipo, cada una con $2$ elementos;
 * La clase $\left\{ sr^{2a} \mid 0 \leq a < n/2 \right\}$, que es cerrada para conjugación
   gracias a la paridad de $n$. Es una clase con $n/2$ elementos.
 * La clase $\left\{ sr^{2a+1} \mid 0 \leq a < n/2 \right\}$, de nuevo con $n/2$ elementos.
 
Sumando las cardinalidades de todas ellas, observamos que no hay más, ya
que

\[
2n = 1 + 1 + 2\frac{n-2}{2} + \frac{n}{2} + \frac{n}{2}.
\]

Tenemos por tanto $n/2 + 3$ clases de conjugación y representaciones 
irreducibles complejas distintas.

***** Representaciones en el caso par
Podemos considerar los caracteres y representaciones siguientes

 * el caracter trivial dado por la *representación irreducible trivial*
   que envía cada elemento del grupo a $1 \in \mathbb{C}$.

 * el grupo generado por $\left\langle r \right\rangle$ es normal y tenemos $D_n/\left\langle r \right\rangle \cong \mathbb{Z}_2$, luego una
   representación dada por la proyección y la representación irreducible
   de $\mathbb{Z}_2$ en los complejos es irreducible. La llamamos $\chi_2$.

 * el grupo generado por $\left\langle r^2 \right\rangle$ es normal y tenemos $D_n/\left\langle r^2 \right\rangle \cong \mathbb{Z}_2 \times \mathbb{Z}_2$, luego
   podemos buscar las representaciones irreducibles del grupo de Klein. Las
   cuatro representaciones irreducibles unidimensionales de este grupo abeliano
   podemos obtenerlas con la trivial y enviando dos de sus elementos no nulos
   al $-1$. Esto nos da los caracteres $\chi_3,\chi_4$ nuevos además de los dos anteriores.

 * si interpretamos los grupos dihédricos como grupos de simetrías de
   los polígonos, podemos escribir representaciones bidimensionales
   que toman $r$ como cualquiera de las rotaciones de ángulos $2\pi k/n$ en
   los complejos y $s$ como la simetría, es decir,

   \[
   r \mapsto \begin{pmatrix}
   e^{2\pi i k/n} & 0 \\
   0 & e^{-2\pi i k/n} \\
   \end{pmatrix}, \quad
   s \mapsto \begin{pmatrix}
   0 & 1 \\
   1 & 0 \\
   \end{pmatrix}.\]
   
   Comprobaremos que para $0<k<n/2$ todas ellas son irreducibles. Los
   espacios que deja invariantes la primera son claramente $(1\ 0)$ y
   $(0\ 1)$ con dos valores propios $e^{2\pi i k/n} \neq e^{-2\pi i k/n}$
   (aquí usamos $k < n/2$), pero no son invariantes bajo simetrías,
   por lo que no existen subespacios invariantes y la representación
   es irreducible. A sus caracteres los llamamos $\chi_{k+2}$.

Con esto tenemos los $n/2+3$ caracteres irreducibles.

***** Tabla de caracteres del caso par

\[
\small
\begin{tabular}{c|cccccccc}
    & 1  & 1 & 2 & \dots & 2 & $n/2$ & $n/2$ \\
D_n & $e$   & $r^{n/2}$ & $r$ & $\dots$ & $r^{n/2-1} & $s$ & $sr$ \\
\hline
\chi_1 & 1 &1 & 1 & \dots & 1 & 1 & 1 \\
\chi_2 & 1 &1& 1 & \dots & 1 & -1 & -1 \\
\chi_3 & 1 & (-1)^{n/2}& 1 &\dots & (-1)^{n/2-1} & 1 & -1 \\
\chi_4 & 1 & (-1)^{n/2} & 1 &\dots  & (-1)^{n/2-1} & -1 & 1 \\
\chi_{2+1} &  2 & 2\cos(2 \pi 1/2) & 2\cos(2\pi 1/n) & \dots & 2\cos(2 \pi (n/2-1)/n) & 0 & 0\\
\chi_{2+2} &  2 & 2\cos(2 \pi 2/2) & 2\cos(2\pi 2/n) & \dots  & 2\cos(2 \pi 2(n/2-1)/n) & 0 & 0 \\
\dots & \dots & \dots & \dots  & \dots  & \dots & \dots & \dots \\
\end{tabular}\]

**** DONE Ejercicio 43
#+begin_statement
Sea $G$ un grupo abeliano finito, y sea $\widehat G$ el conjunto de los caracteres 
complejos irreducibles de $G$. Demostrar que el producto inducido por el
de números complejos dota a $\widehat G$ de estructura de grupo.
#+end_statement

Todas las representaciones irreducibles de un grupo abeliano son de 
dimensión $1$, luego $\chi_{\rho}(g) = \rho(g)$. La irreducibilidad se tiene por ser
todas de dimensión 1.

**** TODO Ejercicio 44 (**)
#+begin_statement
Sea $G$ un grupo abeliano finito, y $\widehat G$ el grupo definido en el Ejercicio 43.
Demostrar que existe un isomorfismo de grupos $G \cong \widehat G$.
#+end_statement

**** TODO Ejercicio 45
#+begin_statement
Sea $G$ un grupo finito y $g \in G$. Demostrar que $g$ es conjugado con $g^{-1}$ si,
y sólo si, $\chi(g) \in \mathbb{R}$ para todo carácter complejo irreducible $\chi$ de $G$.
#+end_statement
**** TODO Ejercicio 46
#+begin_statement
Demostrar que $\varphi^G \in {\cal C}(G)$ para cada $\varphi \in {\cal C}(H)$, y que $\varphi^G(1) = |G:H|\varphi(1)$.
#+end_statement
**** TODO Ejercicio 47 (*)
#+begin_statement
Sea $G$ un grupo abeliano finito, y $H$ un subgrupo de $G$. Demostrar que la
aplicación $(-)_H\colon {\cal C}(G) \to {\cal C}(H)$ es sobreyectiva. Identificar su núcleo.
#+end_statement
**** Ejercicio 48 (**)                                                                                      :export:
#+begin_statement
Calcular la tabla de caracteres complejos de $A_5$.
#+end_statement

***** Clases de conjugación
Para determinar las clases de conjugación usaremos crucialmente
que

\[
\sigma (a\ b\ \dots) \sigma^{-1} = (\sigma(a)\ \sigma(b)\ \dots).
\]

Tenemos las siguientes clases:

 * la clase trivial con el único elemento $()$.
 * la clase de ciclos de longitud $3$ con todos los elementos de la forma
   $(a\ b\ c)$, que pueden conseguirse desde cualquiera de ellos usando que
   $(a\ d\ e)(a\ b\ c)(d\ a\ e) = (d\ b\ c) = (c\ d\ b)$. Esta clase tiene cardinalidad
   $5\cdot 4\cdot 3/3 = 20$.
 * la clase de pares de trasposiciones disjuntas de la forma $(a\ b)(c\ d)$, 
   que pueden conseguirse desde cualquiera de ellos usando que
   $(e\ b\ a)(a\ b)(c\ d)(e\ a\ b) = (a\ e)(c\ d)$. Esta clase tiene cardinalidad
   $5\cdot 4\cdot 3\cdot 2/4\cdot 2 = 15$.
 * la clase de los ciclos de longitud 5 que se obtienen desde una
   permutación par desde $(1\ 2\ 3\ 4\ 5)$, que son todos aquellos que podemos
   obtener conjugando. Esta clase tiene cardinalidad $5!/5\cdot 2 = 12$.
 * la clase de los ciclos de longitud 5 que se obtienen desde una
   permutación impar desde $(2\ 1\ 3\ 4\ 5)$. Nótese que todos los ciclos de
   longitud 5 deben ser como este o como los anteriores según cómo
   sea la permutación que los lleva a $(1\ 2\ 3\ 4\ 5)$ por conjugación.
   Esta clase tiene cardinalidad $5!/5\cdot 2 = 12$.

Comprobamos que la suma de la cardinalidad de las clases de conjugación
es la cardinalidad del grupo completo,

\[
60 = 1 + 20 + 15 + 12 + 12.
\]

Y como hay $5$ clases de conjugación, existirán $5$ representaciones
irreducibles complejas, cuyas dimensiones además deberán sumar la
cardinalidad del grupo, es decir,

\[
60 = n_1^2+n_2^2+n_3^2+n_4^2+n_5^2.
\]

Sabiendo que la primera será la representación trivial, podemos
buscar exhaustivamente soluciones a $59 = n_2^2+n_3^2+n_4^2+n_5^2$ y
encontrar que la única, salvo reordenación, es $3,3,4,5$. Esas
deben ser las dimensiones de nuestras representaciones.

***** Tabla de caracteres
Calculamos la tabla de caracteres usando que:

 - tenemos claramente la representación trivial $\chi_1$.
 - desde $S_{5}$ tenemos la representación $\psi$ dada por permutar
   los vectores de una base de dimensión $5$. Si la restringimos
   tenemos $\psi_{A_5}$. Esta representación tiene un espacio
   invariante claro en $\left\langle (1,1,1,1,1) \right\rangle$ sobre el que actúa trivialmente. 
   Puede descomponerse entonces en la suma de dos representaciones,
   siendo una de ellas la trivial, y sabemos entonces que el caracter
   del otro sumando de la representación será $\psi_{A_5} - \chi_1$, por lo que
   nos queda una fila

   \[
   \small
   \begin{tabular}{c|cccccc}
   & 1    & 15             & 20          & 12                & 12                \\
   A_5        & $()$ & $(1\ 2)(3\ 4)$ & $(1\ 2\ 3)$ & $(1\ 2\ 3\ 4\ 5)$ & $(1\ 2\ 3\ 5\ 4)$ \\
   \hline
   \chi_4     & 5-1=4    & 1-1=0              & 2-1=1           & 0-1=-1                 & 0-1=-1                 \\ 
   \end{tabular}\]

   Comprobamos además que el caracter $\chi_4$ así obtenido es irreducible, 
   ya que cumple que $(\chi_4,\chi_4) = (4^2+20+12+12)/60 = 1$.

 - podemos obtener la segunda columna aplicando el teorema de ortogonalidad
   consigo misma para obtener $4 = 1^2 + x^2 + y^2 + z^2$ y con la primera
   columna para obtener $0 = 1 + 3x + 3y + 5z$. Si diagonalizamos la 
   representación de un elemento de esa clase de conjugación, como tiene
   orden $2$ la diagonal estaría formada por $\pm 1$; como además las dimensiones
   son $5,3,3$, todos impares, nunca podría ser $0$ su traza. Así, la única
   solución a la primera ecuación es $x^2 = y^2 = z^2 = 1$ y la solución a la
   segunda ecuación es $x=-1, y=-1, z=1$.

 - la última fila de la tabla de caracteres la podemos completar usando
   las relaciones de ortogonalidad. Sabemos que

   \[\begin{aligned}
   40 + 20b^2 + 12c^2 + 12d^2 &= 60 \\
   5 +15 + 20b   + 12c   + 12d   &= 0  \\
   20 + 20b   - 12c   - 12d   &= 0  \\
   \end{aligned}\]

   de donde deducimos primero que $c+d=0$, luego $b=-1$ y $c=d=0$.
   Hemos llegado a la conclusión de que

   \[\small
   \begin{tabular}{c|cccccc}
   & 1    & 15             & 20          & 12                & 12                \\
   A_5        & $()$ & $(1\ 2)(3\ 4)$ & $(1\ 2\ 3)$ & $(1\ 2\ 3\ 4\ 5)$ & $(1\ 2\ 3\ 5\ 4)$ \\
   \hline
   \chi_5     & 5    & 1              & b=-1           & c=0                 & d=0                 \\ 
   \end{tabular}\]   

 - la tercera columna de la tabla podemos obtenerla de nuevo con relaciones
   de ortogonalidad, tenemos $3 = 1 + u^2 + v^2 + 1 + 1$ y $1 -u-v-1=0$, 
   luego $u = -v$ y $u=v=0$.

 - las dos últimas entradas están sujetas a las mismas condiciones, así
   que esperamos obtenerlas como soluciones distintas del mismo sistema
   de ecuaciones de ortogonalidad. Aplicando ortogonalidad tenemos
   $3^2 + 15 + 12p^{2}+ 12q^{2} = 60$ y $3 -15+12p+12q=0$, luego $p=1-q$,
   y como $p^2+(1-p)^2 = 3$, tenemos que las dos soluciones posibles
   serán las de $p^2 - p - 1 = 0$, es decir $p=\pm(1+\sqrt{5})/2$.


Así, la tabla de caracteres acaba quedando como

\[\small
\begin{tabular}{c|cccccc}
           & 1    & 15             & 20          & 12                & 12                \\
A_5        & $()$ & $(1\ 2)(3\ 4)$ & $(1\ 2\ 3)$ & $(1\ 2\ 3\ 4\ 5)$ & $(1\ 2\ 3\ 5\ 4)$ \\
\hline
\chi_1     & 1    & 1              & 1           & 1                 & 1                 \\ 
\chi_2     & 3    & -1             & 0           & (1+\sqrt{5})/2    & (1-\sqrt{5})/2    \\ 
\chi_3     & 3    & -1             & 0           & (1-\sqrt{5})/2    & (1+\sqrt{5})/2    \\ 
\chi_4     & 4    & 0              & 1           & -1                & -1                \\ 
\chi_5     & 5    & 1              & -1          & 0                 & 0                 \\ 
\end{tabular}\]
** Inferencia estadística
# ##
# Estos apuntes se han reescrito desde los apuntes de A. Hermoso Carazo y
# M.D. Ruiz Medina para la asignatura de Inferencia Estadística del grado
# de matemáticas de la Universidad de Granada.
# ##

*** Prerrequisitos
**** Distribuciones
***** Función generatriz de momentos
Se define para una variable aleatoria $X$ con función de distribución
$f$ como:

\[
M_X(t) = 
\mathbb{E}(e^{tX}) =
\int_\Omega e^{tx}f(x) \;dx
\]

****** Cálculo de momentos
Se cumple que:

\[
\mathbb{E}[X^n] = \frac{\partial^n}{\partial t^n} M_X(0)
\]

***** Función característica
Se define para una variable aleatoria $X$ con función de distribución $f$:

\[
\varphi_X(t) = \mathbb{E}[e^{itX}] = \int_\Omega e^{itx}f(x)\;dx
\]

****** Cálculo de momentos
Se cumple que:

\[
\varphi_X^{(n)}(0) = i^n\mathbb{E}[X^n]
\]

**** Varianza
***** Varianza
La varianza se define equivalentemente como:

\[Var(X) = E\Big[(X-EX)^2\Big] = E[X^2] - E[X]^2\]

***** Covarianza
La covarianza se define equivalentemente como:

\[cov(X,Y) = E[(X-EX)(Y-EY)] = E[XY] - E[X]E[Y]\]

Nótese que $cov(X,X) = Var(X)$. Nótese además se comporta como el 
[[https://en.wikipedia.org/wiki/Covariance#Relationship_to_inner_products][producto interno]] de un espacio prehilbertiano.

***** Varianza de la suma
La varianza de una suma cumple:

\[
Var(X+Y) = Var(X) + Var(Y) + 2cov(X,Y)
\]

En el caso general:

\[Var\left(\sum X_i\right) = \sum_i\sum_j cov(X_i,X_j)\]

***** Cauchy-Schwarz para la covarianza
Se tiene la desigualdad:

\[cov(X,Y)^2 \leq Var(X)Var(Y)
\]

****** Demostración
Sabiendo que la varianza es siempre no negativa:

\[
0 \leq Var\left(X - \frac{cov(X,Y)}{Var(Y)} Y\right) =
Var(X) - \frac{\left(cov(X,Y)\right)^2}{Var(Y)}
\]

****** Demostración por Cauchy-Schwarz
Se comprueba que la covarianza da un producto escalar que genera
un [[https://en.wikipedia.org/wiki/Covariance#Relationship_to_inner_products][espacio cociente]] prehilbertiano. Aplicamos Cauchy-Schwarz.

**** Esperanza condicional
***** Esperanza condicional en caso discreto
Definimos la esperanza condicional de dos variables discretas como:

\[\mathbb{E}[X|Y] = \sum_x xP(X=x\mid Y=y) = \sum_x x\frac{P(X=x, Y=y)}{P(Y=y)}\]

***** Esperanza condicional en el caso continuo
Más generalmente se define para el caso continuo:

\[
\mathbb{E}[X|Y] = \int_X x f_{X|Y}(x|y) dx = \int_X x \frac{f_{X,Y}(x,y)}{f_Y(y)} dx
\]

***** Ley de esperanza total
La esperanza condicional cumple:

\[\mathbb{E}[X] = \mathbb{E}[\mathbb{E}[X|Y]]\]

****** Demostración en el caso discreto
Se tiene:

\[\begin{aligned}
E[E[X|Y]] &= \int_Y f(y)  \left(\int_X x \frac{f(x,y)}{f(y)} dx \right) dy \\ñ
&= \int_X x \int_Y f(x,y) dy dx \\&= \int_X x f(x) dx = E[X]
\end{aligned}\]

Nótese que asumimos una conmutatividad de las integrales discretas.

****** Demostración en el caso continuo
Puede consultarse la [[https://en.wikipedia.org/wiki/Law_of_total_expectation#Proof_in_the_general_case][Ley de la esperanza total]].

**** Desigualdades
***** Desigualdad de Chebyshev
Para una variable aleatoria $X$ de segundo orden:

\[
P(|X-\mathbb{E}[X]| \geq a) \leq \frac{Var(X)}{a^2}
\]

**** Convergencia
***** Convergencia casi segura
Una sucesión de variables aleatorias converge de forma casi segura a
otra $X_n \overset{c.s.}\longrightarrow X$ cuando el conjunto de sucesos que lo hacen tiene 
probabilidad 1.

\[
P\left(\lim_{n\to\infty} X_n = X\right) = 1
\]

***** Convergencia en probabilidad
Una sucesión de variables aleatorias converge en probabilidad a
otra $X_n \overset{P}\longrightarrow X$ cuando:

\[
\lim_{n\to\infty} P\left(|X_n-X| \geq \varepsilon\right) = 0
\]

para cualquier $\varepsilon$.

****** Equivalentemente
Si consideramos su complemento:

\[
\lim_{n\to\infty} P(|X_n-X| < \varepsilon) = 1
\]

***** Convergencia en distribución
Una sucesión de variables aleatorias converge en ley o en distribución 
a otra $X_n \overset{d}\longrightarrow X$, si se tiene que, dadas sus funciones de distribución,
convergen en los puntos en los que es continua:

\[
\forall x: F \mbox{ continua en } x:
\quad
\lim_{n\to\infty} F_n(x) = F(x)
\]

****** Equivalentemente
Se tiene $X_n\overset{d}\longrightarrow X$ si para cualquier $t$ real:

\[
\lim_{n\to\infty} E\left[ e^{tX_n} \right] = E\left[e^{tX}\right]
\]

***** Implicaciones
La convergencia casi segura implica la convergencia en probabilidad, que
implica a su vez la convergencia en distribución.

****** TODO Demostración

***** Ley débil de los grandes números
Si $X_1,X_2,\dots$ es una sucesión infinita de variables aleatorias 
independientes con la misma esperanza y varianza, entonces:

\[
\overline{X}_n = \frac{1}{n}(X_1+\dots+X_n)
\]

converge en probabilidad a $\mu$:

\[
\lim_{n\to\infty} P(|\overline{X}_n - \mu| \geq \varepsilon) = 0
\]

***** Ley fuerte de los grandes números
Si $X_1,X_2,\dots$ es una sucesión infinita de variables aleatorias 
independientes e idénticamente distribuidas con $E\left[|X_i|\right] < \infty$ y
valor esperado $\mu$, entonces:

\[
P\left(
\lim_{n\to\infty} \overline{X}_n = \mu
\right) = 1
\]

*** Distribuciones discretas
**** 1. Distribución uniforme
***** Definición
Se define sobre un conjunto finito de valores $\{x_i\}$ con la misma 
probabilidad como:

\[f(x_i|n) = \frac{1}{n}\]
**** 2. Distribución binomial
***** Definición
Determina la probabilidad de $x$ aciertos en $n$ experimentos de Bernoulli.
La función de distribución de $B(x|n,p)$ es:

\[
f(x|n,p) = {n \choose x}p^x (1-p)^{n-x}
\]

****** Esperanza

\[\mathbb{E}[X] = np\]

****** Varianza

\[Var[X] = np(1-p)\]

**** 3. Distribución multinomial
***** Definición
Deriva de una binomial con $k$ salidas distintas de probabilidades $p_1,\dots,p_k$
como:

\[
f(X|n,p_1,\dots,p_k) = \frac{n!}{X_1!X_2!\dots X_n!}p^{X_1}p^{X_2}\dots p^{X_k}
\]

**** 4. Distribución de Poisson
***** Definición
Definimos la distribución de Poisson $Poi(\lambda)$ como:

\[
f(n|\lambda) = \frac{e^{-\lambda}\lambda^n}{n!}
\]

****** Es una distribución
Comprobamos que suma la unidad:

\[
\sum_{n=1}^\infty f(n|\lambda) =
\sum_{n=1}^\infty e^{-\lambda}\frac{\lambda^n}{n!} = 1
\]

***** Función generatriz de momentos
La función generatriz se calcula como:

\[
M_X(t) = \sum_{n=1}^\infty e^{-\lambda}\frac{(e^t\lambda)^n}{n!}
= e^{\lambda(e^t-1)}
\]

****** Esperanza
Desde la función generadora:

\[
\mathbb{E}[X] = \frac{\partial M_X}{\partial t}(0) = \lambda
\]

****** Varianza
Desde la función generadora:

\[
Var(X) = \mathbb{E}[X^2] - \mathbb{E}[X]^2 = \lambda
\]

***** Suma de Poisson
Para $X \leadsto Poi(\lambda_1)$, $Y \leadsto Poi(\lambda_2)$ independientes, su suma sigue la
distribución con el parámetro suma.

\[
X + Y \leadsto Poi(\lambda_1+\lambda_2)
\]

*** Distribuciones continuas
**** 1. Distribución normal
***** Definición
Definimos la distribución normal ${\cal N}(\mu,\sigma^2)$ como aquella con función de
densidad:

\[f(x) = \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(x-\mu)^2}{2\sigma^2}}\]

****** Imagen de la distribución
#+BEGIN_SRC R :file images/normal.png :results graphics
  library(ggplot2)
  library(ggfortify)
  gg = NULL
  for (i in c(1,2,3,4,5)) {
      gg = ggdistribution(dnorm, seq(-3, 3, 0.1),
                          mean = 0, sd = 1+0.1*i,
                          colour=topo.colors(5)[i], p=gg)
  }
  print(gg + labs(title = "Distribución normal, variando σ²."))
#+END_SRC

#+RESULTS:
[[file:images/normal.png]]

****** Es una distribución
Tenemos que comprobar que integra la unidad sobre los reales, y
de hecho, tomando cambio de variable $y = (x-\mu)/\sqrt{2\sigma^2}$ queda:

\[\begin{aligned}
\int^{+\infty}_{-\infty} 
\frac{1}{\sqrt{2\pi\sigma^2}}e^{-\left(\frac{x-\mu}{\sqrt{2\sigma^2}}\right)^2} =
\frac{1}{\sqrt{\pi}}\int^{+\infty}_{-\infty} 
e^{-y^2} = 1
\end{aligned}\]

Que es la [[https://en.wikipedia.org/wiki/Gaussian_integral][integral de Gauss]].

***** Función característica
La función característica de ${\cal N}(\mu,\sigma^2)$ es:

\[\varphi_X(t) = e^{it\mu - t^2\sigma^2/2}\]

****** TODO Demostración
Usamos la definición de función característica y completamos
cuadrados para tener:

\[\begin{aligned}
\varphi_X(t) &= 
\mathbb{E}\left[e^{itX}\right] &= 
\int_{-\infty}^{+\infty}
e^{itx}\frac{1}{\sqrt{2\pi\sigma^2}} 
e^{-\frac{(x-\mu)^2}{2\sigma^2}}dx \\&=
\frac{1}{\sqrt{2\pi\sigma^2}} 
\int_{-\infty}^{+\infty}
e^{it\mu}
\end{aligned}\]

***** Suma de normales
Sean $X \leadsto {\cal N}(\mu_1,\sigma_1^2)$ e $Y \leadsto {\cal N}(\mu_2,\sigma_2^2)$. Entonces $X+Y\leadsto {\cal N}(\mu_1+\mu_2,\sigma_1^2+\sigma_2^2)$.

****** TODO Demostración

***** Producto por escalar
Si $X \leadsto {\cal N}(\mu,\sigma^2)$, entonces $kX \leadsto {\cal N}(k\mu,k\sigma^2)$.

****** TODO Demostración
***** Teorema de Cramer
Sean $X,Y$ independientes. Si $X+Y$ es normal, $X$ e $Y$ son normales.

****** TODO Demostración
**** 2. Distribución χ² de Pearson
***** Distribución chi cuadrado
Es un caso particular de la distribución gamma, $X \leadsto \chi^2(k) = \Gamma(k/2,1/2)$.
Al parámetro $k$ se le llama *número de grados de libertad*.

****** Gráfica de la función de densidad
#+BEGIN_SRC R :file images/chi.png :results graphics
  library(ggplot2)
  library(ggfortify)
  gg = NULL
  for (i in c(1,2,3,4,5)) {
      gg = ggdistribution(dchisq, seq(0, 6, 0.1),
                          df = i,
                          colour=topo.colors(5)[i], p=gg)
  }
  print(gg + labs(title = "Distribución χ²(n), variando n."))
#+END_SRC

#+RESULTS:
[[file:images/chi.png]]

****** Función de densidad

 \[f(x) = \frac{1}{\Gamma(\frac{k}{2})2^{k/2}} x^{k/2-1}e^{-x/2}\]

******* TODO Demostración
***** Función generatriz de momentos

\[M_X(t) = \frac{1}{(1-2t)^{k/2}}\], para $t < 1/2$.

****** TODO Demostración
****** Esperanza y varianza

 - $E[X] = k$
 - $Var[X] = 2k$

******* Demostración
Se calculan desde la función generatriz.

***** Propiedad de reproductividad
Si tengo una serie de variables independientes distribuidas 
por $X_i \leadsto \chi^2(k_i)$, entonces:

\[\sum_{i=1}^n X_i \leadsto \chi^2 \left(\sum_{i=1}^n k_i \right)\]

***** Relación con la normal
Dadas variables independientes $X_i \leadsto {\cal N}(0,1)$,

 \[\sum_{i=1}^n X^2_i \leadsto \chi^2(n)\]

****** TODO Demostración

***** Teorema central del límite de Lèvy
Para valores pequeños, pueden usarse tablas. Para valores grandes
de $n$, podemos aproximarla mediante el Teorema Central del Límite
como:

\[ \chi^2(n) \approx {\cal N}(n,2n)\]

****** TODO Demostración                                                                                   :extra:
**** 3. Distribución t de Student
***** Definición 
Dadas dos variables independientes $X \leadsto {\cal N}(0,1)$ e $Y \leadsto \chi^2(n)$,
tenemos:

\[ T = \frac{X}{\sqrt{Y/n}} \leadsto t(n) \]

****** Función de densidad

\[ f(t) 
= \frac
{\Gamma\left(\frac{n+1}{2}\right)}
{\Gamma\left(\frac{n}{2}\right) \sqrt{n\pi}} 
\left(
1 + \frac{t^2}{n}
\right)^{-\frac{n+1}{2}}
\], $t \in \mathbb{R}$

******* TODO Demostración

****** Gráfica de la función de densidad
#+BEGIN_SRC R :file images/tstudent.png :results graphics
  library(ggplot2)
  library(ggfortify)
  gg = NULL
  for (i in c(1,2,3,4,5)) {
      gg = ggdistribution(dt, seq(0, 3, 0.1),
                          df=i,
                          colour=topo.colors(5)[i], p=gg)
  }
  print(gg + labs(title = "T de Student, variando n."))
#+END_SRC

#+RESULTS:
[[file:images/tstudent.png]]

***** Momentos
Tenemos que $\exists E[T^k] \iff k < n$. Cuando existen, se tiene

 - $E[T] = 0$
 - $Var[T] = \frac{n}{n-2}$

****** TODO Demostración

***** Aproximación por la normal
Tabulada para $n$ pequeños y aproximada por ${\cal N}(0,1)$ para valores
grandes.
**** 4. Distribución F de Snedecor
***** Definición
*F de Snedecor*. Dadas dos variables independientes $X \leadsto \chi^2(m)$ e
$Y \leadsto \chi^2(n)$, su cociente nos da:

\[F = \frac{X/m}{Y/n} \leadsto F(m,n)\]

****** Gráfica de la función de densidad
#+BEGIN_SRC R :file images/fsnedecor.png :results graphics
  library(ggplot2)
  library(ggfortify)
  gg = NULL
  for (i in c(1,2,3,4,5)) {
      gg = ggdistribution(df, seq(0, 2, 0.04),
                          df1=i, df2=i-1,
                          colour=topo.colors(5)[i], p=gg)
  }
  print(gg + labs(title = "F de Snedecor, variando n y m."))
#+END_SRC

#+RESULTS:
[[file:images/fsnedecor.png]]

****** Función de densidad

\[g(t)
= \frac
{\Gamma(\frac{m+n}{2})}
{\Gamma(\frac{m}{2})\Gamma(\frac{n}{2})}
\left(\frac{m}{n}\right)^{\frac{m}{2}}
t^{m/2-1}
\left(1+\frac{m}{n}t\right)^{-\frac{m+n}{2}}\], para $t>0$.

******* TODO Demostración

***** Momentos
Tenemos que $\exists E[T^k] \iff k < n/2$.

 - $n > 2 \Rightarrow \exists E[F] = \frac{n}{n-2}$
 - $n > 4 \Rightarrow \exists Var[F] = \frac{n^2(2m+2n-4)}{m(n-2)^2(n-4)}$

****** TODO Demostración

***** Propiedades
\[ F \leadsto F(m,n) \iff F^{-1} \leadsto F(n,m)\]
\[T \leadsto t(n) \iff T^2 \leadsto F(1,n)\]

***** Aproximación
La distribución está tabulada y las tablas incluyen aproximaciones 
para valores grandes de $n$ y $m$.

**** 5. Distribución exponencial
***** Distribución exponencial
Dado un $\lambda>0$, definimos la distribución exponencial, $\operatorname{Exp}(\lambda)$, como aquella
con función de densidad:

\[f(x) = \lambda e^{-\lambda x}\qquad \forall x \in \mathbb{R}^+_0\]

****** Es una distribución
Trivialmente integrando:

\[
\int_0^\infty \lambda e^{-\lambda x} = 
-\left[ e^{-\lambda x} \right]^\infty_0 = 1
\]

***** Suma de exponenciales
La suma de variables exponenciales es una distribución Gamma:

***** Caso particular de la distribución Gamma
La exponencial es un caso particular de la distribución Gamma:

\[
Exp(\lambda) = \Gamma(1,\lambda)
\]
**** 6. Distribución de Dirichlet
***** Distribución de Dirichlet
Dado un vector de reales $\alpha_1,\alpha_2,\dots,\alpha_n$, definimos la distribución $Dir(\alpha)$ 
como la que tiene función de densidad:

\[
f(x) = \frac{1}{B(\alpha)} \prod_{i=1}^K x_i^{\alpha_i-1}
\]

donde,

\[
B(\alpha) =
\frac
{\prod_{i=1}^K \Gamma(\alpha_i)}
{\Gamma\left(\sum_{i=1}^K \alpha_i\right)}
\]

***** Momentos
****** Esperanza

\[
E[X_i] = \frac{\alpha_i}{\sum_k \alpha_k}
\]

****** Varianza

\[
Var[X_i] = \frac{\alpha_i(\alpha_0-\alpha_i)}{\alpha_0^2(\alpha_0+1)}
\]
**** 7. Distribución Gamma
***** Función Gamma
Se define la función gamma $\Gamma : (0,\infty) \longrightarrow (0,\infty)$ como:

\[\Gamma(\alpha) = \int^\infty_0 t^{\alpha-1}e^{-t} dt\]

****** La integral está definida
Por un lado, $t^{a-1}e^{-t} < t^{a-1}$, integrable en $[0,b]$. Por otro lado,

\[\lim_{t \to \infty} \frac{t^{\alpha-1}e^{-t}}{e^{-t/2}} = 0\]

Por lo que $t^{\alpha-1}e^{-t} < e^{-t/2}$ integrable, a partir de algún punto.
Partimos la integral como:

\[\int_0^b t^{\alpha-1}e^{-t}dt + \int^{\infty}_b t^{\alpha-1}e^{-t}dt
< \infty\]

***** Propiedades de la función Gamma
Sea $\alpha > 0$, se verifica:

  1. $\Gamma(1) = 1$.
  2. $\Gamma(\alpha+1) = \alpha\Gamma(\alpha)$.
  3. $\Gamma(n+1) = n!$ para $n \in \mathbb{N}$.
  4. $\Gamma(\alpha)\Gamma(1-\alpha) = \frac{\pi}{\sin(\alpha\pi)}$ para $0<\alpha<1$.
  5. $\Gamma(1/2) = \sqrt{\pi}$.
  6. $\Gamma(\alpha) = \beta^\alpha \int^\infty_0 t^{\alpha-1}e^{-\beta t} dt$ para $\beta > 0$.

****** Demostración
******* Punto 1
Trivial.
******* Punto 2
Integral por partes.
******* Punto 3
Inducción sobre los dos primeros apartados.
******* TODO Punto 4
******* Punto 5
Trivial desde el punto anterior.
******* Punto 6
Cambio de variable $\varphi(t) = \beta t$.

***** Distribución Gamma
Dados $\alpha,\beta > 0$, definimos la distribución Gamma $\Gamma(\alpha,\beta)$ como aquella con
función de densidad:

\[f(x) = \frac{\beta^\alpha}{\Gamma(\alpha)}x^{\alpha-1}e^{-\beta x}\]

para $x>0$. 

****** Imagen de la distribución
#+BEGIN_SRC R :results graphics :file images/gamma.png
  library(ggplot2)
  library(ggfortify)
  gg = NULL
  for (i in c(1,2,3,4,5)) {
      gg = ggdistribution(dgamma, seq(0, 4, 0.05),
                          shape = i, rate = 1,
                          colour=topo.colors(5)[i], p=gg)
  }
  print(gg + labs(title = "Distribución gamma, variando α."))
#+END_SRC

#+RESULTS:
[[file:images/gamma.png]]
***** Propiedades de la distribución Gamma
La función de densidad de una distribución $\Gamma(\alpha,\beta)$ verifica:

  1. Cuando $0<\alpha<1$, $f$ es decreciente y $\lim_{x\to 0} f(x) = \infty$.
  2. Cuando $\alpha = 1$, $f$ es decreciente y $f(0)=1$.
  3. Cuando $\alpha>1$, $f$ es creciente en $[0,(\alpha-1)/\beta]$ y decreciente 
     en $[(\alpha-1)/\beta,\infty]$.

Y sobre convexidad y concavidad se tiene:

  1. Si $0<\alpha\leq 1$, es convexa.
  2. Si $1 < \alpha \leq 2$, es cóncava en $[0,(\alpha-1+\sqrt{\alpha+1})/\beta]$ y convexa
     en $[(\alpha-1+\sqrt{\alpha+1})/\beta,\infty]$.
  3. Si $2 < \alpha$, es cóncava en $[(\alpha-1-\sqrt{\alpha+1})/\beta,(\alpha-1+\sqrt{\alpha+1}/\beta)]$ y
     convexa en todo el resto del dominio.

****** TODO Demostración
***** Suma de Gammas
Para $X \leadsto \Gamma(\alpha_1,\beta)$, $Y \leadsto \Gamma(\alpha_2,\beta)$, independientes:

\[
X+Y \leadsto \Gamma(\alpha_1+\alpha_2,\beta)
\]
**** 8. Distribución Beta
***** Función Beta
Se define la función beta $\beta : (0,\infty) \longrightarrow (0,\infty)$ como:

\[\beta(x,y) = \int^1_0 t^{x-1}(1-t)^{y-1}dt\]

****** Está bien definida
Por la [[*Relación con la función Gamma][relación con la función Gamma]] sabemos que debe estar
bien definida.

***** Relación con la función Gamma
Para cada $x,y$ se tiene:

\[\frac{\Gamma(x)\Gamma(y)}{\Gamma(xy)} = \beta(x,y)\]

****** TODO Demostración

***** Distribución Beta
Dados $p,q>0$, definimos la distribución Beta $\beta(p,q)$ como aquella con 
función de densidad:

\[f(x) = \frac{1}{\beta(p,q)} x^{p-1}(1-x)^{q-1}\]
*** 1. Introducción a la inferencia estadística. Estadísticos muestrales
**** Planteamiento de un problema de inferencia
***** Modelo estadístico
Un modelo estadístico $(X,{\cal P})$ consta de:

  - $X : (\Omega, {\cal A},{\cal P}) \longrightarrow (\mathbb{R},{\cal B},P_X)$ variable aleatoria que describe el 
    objeto de estudio.
  - ${\cal P}$ familia de distribuciones que pueden ser la de $X$.

***** Modelo estadístico paramétrico
Cuando se conoce la forma funcional de $P_X$ y sólo desconocemos un 
parámetro tenemos una familia paramétrica de distribuciones $F(x,\theta)$ 
para $\theta$.

***** Modelo estadístico no paramétrico
Cuando la forma funcional de $P_X$ es desconocida.

***** Muestra aleatoria simple
Una muestra aleatoria simple es un vector $(X_1,\dots,X_n)$
de variables independientes idénticamente distribuidas. 

****** Realización muestral 
Una realización muestral a un valor concreto obtenido al
observar la muestra.

****** Espacio muestral
Conjunto de todas las posibles realizaciones.

**** Función de distribución empírica
***** Función de distribución muestral
La *función de distribución empírica* es una función de 
distribución razonable que podemos obtener desde una 
realización muestral.

 \[F^\ast_{X_1,\dots,X_n}(x) = \frac{1}{n} \sum_{i=1}^n \mathbf{1}_{(X_i < x)} \]

***** Propiedades de la función de distribución empírica
Fijado un $x \in \mathbb{R}$, $F^\ast(x)$ es una variable aleatoria siguiendo por 
definición una binomial:

\[ nF^\ast(x) \leadsto {\cal B}(n, F(x))\]

Calculamos su *esperanza* y *varianza* desde Bernoulli como:

 - Esperanza: $E[F^\ast(x)] = F(x)$
 - Varianza: $Var[F^\ast(x)] = \frac{F(x) (1-F(x))}{n}$

Aplicando entonces el Teorema Central del Límite:

\[ \frac{F^\ast(x) - F(x)}{\sqrt{\frac{F(x)(1-F(x))}{n}}} \leadsto {\cal N}(0,1) \]

***** Teorema de Glivenko-Cantelli
Las funciones de distribución muestrales convergen 
casi seguramente uniformemente a la teórica.

\[ P\left\{ \lim_{n \rightarrow \infty} 
\sup_{x \in \mathbb{R}} |F^\ast_n(x) - F(x)| = 0\right\} = 1\]

****** Equivalentemente
Con probabilidad 1 se tiene que, al tomar sucesivas observaciones 
independientes y considerar las correspondientes funciones de 
distribución muestrales:

\[\forall x \in \mathbb{R}: \forall \epsilon>0: \exists n_\epsilon : \forall n \geq n_\epsilon:
\quad F^\ast_n(x) - \epsilon < F_X(x) < F^\ast_n(x) + \epsilon\]

****** Demostración
[[http://matematicas.unex.es/~nogales/estadisticamatematica/TGC.pdf][Teorema de Glivenko-Cantelli]].

**** Estadísticos muestrales
***** Estadístico muestral
Dada una muestra aleatoria simple, un *estadístico muestral* es una 
función sobre ella $T : (\mathbb{R}^n,{\cal B}^n)\longrightarrow (\mathbb{R}^k,{\cal B}^k)$ medible e independiente 
de cualquier parámetro desconocido.

***** Momentos muestrales no centrados
Para cada $k \in \mathbb{N}$:

\[A_k = \frac{1}{n}\sum_{i=1}^n X_i^k\]

***** Momentos muestrales centrados
Para cada $k \in \mathbb{N}$:

\[B_k = \frac{1}{n}\sum_{i=1}^n(X_i - \overline{X})^k\]

***** Media muestral
Caso particular,

\[A_1 = \frac{1}{n}\sum_{i=1}^n X_i = \overline{X}\]

***** Varianza muestral
Caso particular,

\[B_2 = \frac{1}{n}\sum_{i=1}^n(X_i - \overline{X})^2\]

***** Cuasivarianza muestral

\[S^2 = \frac{1}{n-1} \sum_{i=1}^n (X_i-\overline{X})^2\]

*** 2. Muestreo de poblaciones normales
**** Muestreo de la normal
***** Lema de Fisher
Sea $(X_1,\dots,X_n)$ una muestra aleatoria simple con $X \leadsto {\cal N}(\mu,\sigma^2)$.
Los estadísticos $\overline{X}$ y $S^2$ son independientes.

****** TODO Demostración

***** A1. Inferencia de la media con varianza conocida
Sea $X \leadsto {\cal N}(\mu,\sigma^2)$, y $\overline{X}$ su media muestral:

\[
\frac{\overline{X}-\mu}{\sigma/\sqrt{n}} \leadsto {\cal N}(0,1)
\]

****** Demostración
Usando las propiedades de la suma de normales y la linealidad de la
esperanza y cuadracidad de la varianza tenemos:

\[
\overline{X} \leadsto {\cal N}(\mu,\sigma^2/n)
\]

Desde donde simplemente normalizamos.

***** A2. Inferencia de la media con varianza desconocida
Sea $X \leadsto {\cal N}(\mu,\sigma^2)$ con $\overline{X}$ su media muestral y $S^2$ su cuasivarianza muestral,
entonces:

\[
\frac{\overline{X}-\mu}{S/\sqrt{n}} \leadsto t(n-1)
\]

****** Demostración
Por la definición de t de Student, sabiendo:

\[
\frac{\overline{X} - \mu}{S/\sqrt{n}}
=
\frac{\frac{\overline{X} - \mu}{\sigma/\sqrt{n}}}{\sqrt{\frac{(n-1)S^2}{\sigma^2}/n-1}}
\leadsto
t(n-1)
\]

***** B1. Inferencia de la varianza con media conocida
Sea $X \leadsto {\cal N}(\mu,\sigma^2)$, entonces:

\[
\sum_{i=1}^n \left(\frac{X_i-\mu}{\sigma}\right)^2
\leadsto
\chi^2(n)
\]

****** Demostración
Usando que la suma de cuadrados de normales estándar es una
distribución chi cuadrado.

***** B2. Inferencia de la varianza con media desconocida
Sea $X \leadsto {\cal N}(\mu,\sigma^2)$ con $S^2$ su cuasivarianza muestral, entonces:

\[
\frac{(n-1)S^2}{\sigma^2} \leadsto \chi^2(n-1)
\]

****** Demostración
Usamos la independencia entre $X_i-\overline{X}$ y $\overline{X}-\mu$ para escribir:

\[
\sum_{i=1}^n (X_i - \mu)^2
=
\sum_{i=1}^n (X_i - \overline{X})^2 +
\sum_{i=1}^n (\overline{X} - \mu)^2
\]

Ahora bien, sabemos que:

\[
\sum_{i=1}^n \left(\frac{X_i - \mu}{\sigma}\right)^2
\leadsto
\chi^2(n)
\]

\[
n\left(\frac{\overline{X} - \mu}{\sigma}\right)^2}
\leadsto
\chi^2(1)
\]

Y desde aquí, por unicidad de las funciones generadoras de momentos
se tiene:

\[
\sum_{i=1}^n \frac{(X_i-\overline{X})^2}{\sigma^2}
\leadsto
\chi^2(n-1)
\]

**** Muestreo de dos normales
***** Extensión del lema de Fisher
Sean $X \leadsto {\cal N}(\mu_1,\sigma_1^2)$ y $Y \leadsto {\cal N}(\mu_2,\sigma_2^2)$ independientes.
Los vectores $(\overline{X},\overline{Y})$ y $(S^2_1,S^2_2)$ son independientes.

****** TODO Demostración
***** Inferencia sobre diferencia de medias con varianzas conocidas
Sean $X \leadsto {\cal N}(\mu_1,\sigma_1^2)$ y $Y \leadsto {\cal N}(\mu_2,\sigma_2^2)$ independientes:

\[
\frac{(\overline{X}-\overline{Y}) - (\mu_1-\mu_2)}
{
\sqrt{\frac{(n_1-1)S^2_1}{\sigma_1^2} + \frac{(n_2-1)S^2_2}{\sigma_2^2}}
\sqrt{\frac{\sigma_1^2/n_1 + \sigma_2^2/n_2}{n_1+n_2-2}}
}
\leadsto
t(n_1+n_2-2)
\]

****** Demostración
El numerador sigue una distribución ${\cal N}(0,\sigma^2_1/n_1+\sigma^2_2/n_2)$, así que lo
dividimos para una normal estándar. Cada uno de los sumandos de
la otra raíz forma una chi cuadrada, que al sumarse da $\chi(n_1+n_2-2)$.

Usamos entonces la definición de t de Student.
***** Inferencia sobre diferencia de medias con varianzas iguales
Sean $X \leadsto {\cal N}(\mu_1,\sigma^2)$, $Y \leadsto {\cal N}(\mu_2,\sigma^2)$ independientes:

\[
\frac{(\overline{X}-\overline{Y}) - (\mu_1-\mu_2)}
{
\sqrt{\frac{(n_1-1)S^2_1+ (n_2-1)S^2_2}{n_1+n_2-2}}
\sqrt{\frac{1}{n_1}+\frac{1}{n_2}}
}
\leadsto
t(n_1+n_2-2)
\]

****** Demostración
Desde el caso anterior, tomando las varianzas iguales.

****** Demostración alternativa
El numerador sigue una ${\cal N}(0,\sigma^2(1/n_1+1/n_2))$. Podemos dividirlo por
la raíz de la varianza e incluir otra varianza en la raíz de las
cuasivarianzas muestrales para tener una $\chi^2(n_1+n_2-2)$.

Aplicamos definición de t de Student.
***** Inferencia sobre cociente de varianzas con media conocida
Sean $X \leadsto {\cal N}(\mu_1,\sigma_1^2)$ y $Y \leadsto {\cal N}(\mu_2,\sigma_2^2)$ independientes con muestras de
tamaños $n_1$ y $n_2$:

\[
\frac
{\sum_{i=1}^{n_1}(X_i-\mu_1)^2 / n_1\sigma_1^2}
{\sum_{i=1}^{n_2}(X_i-\mu_2)^2 / n_2\sigma_2^2}
\leadsto
F(n_1,n_2)
\]

****** Demostración
Desde la definición de la F de Snedecor, sabiendo que cada factor
es una chi cuadrada.

***** Inferencia sobre cociente de varianzas con media desconocida
Sean $X \leadsto {\cal N}(\mu_1,\sigma_1^2)$ y $Y \leadsto {\cal N}(\mu_2,\sigma_2^2)$ independientes:

\[
\frac
{S_1^2/\sigma_1^2}
{S_2^2/\sigma_2^2}
\leadsto
F(n-1,m-1)
\]

****** Demostración
Aplicando la definición de F de Snedecor y sabiendo que son dos
distribuciones chi cuadrado.

*** 3. Suficiencia y completitud
**** Estadísticos suficientes
***** Estadístico suficiente
Un estadístico $t$ es *suficiente* para un parámetro $\theta$ cuando una vez 
conocido no puede obtenerse más información de sobre $\theta$ de los datos;
esto es:

\[\Pr(\theta| t,x) = \Pr(\theta|t)\]

****** Definición equivalente
De forma equivalente, es *suficiente* si la distribución condicionada 
al estadístico es independiente del parámetro $\theta$:

 \[\Pr(x|t,\theta) = \Pr(x|t)\]

***** Teorema de factorización de Fisher-Neyman
$T$ es suficiente para una familia $\theta \in \Theta$ ssi existen funciones no negativas
$g$,$h$ tales que la distribución $f_\theta$ es:

\[f_\theta(x) = h(x)g_\theta(T(x))\]

Donde $g_\theta$ sólo depende de $x$ a través de $T$ y $h$ no depende de $\theta$.

****** TODO Demostración
***** Propiedades de los estadísticos suficientes
Los estadísticos suficientes cumplen:

  1. Si $T$ es suficiente para $\{P_\theta \mid \theta \in \Theta\}$, lo es para $\{P_\theta \mid \theta \in \Theta' \subset \Theta\}$.
  2. Si $T$ es suficiente y $T = h'(U)$, $U$ es suficiente.
  3. Toda transformación biunívoca de suficiente es suficiente.

****** Demostración
******* Punto 1
Si cumple la factorización para un conjunto, lo cumple para también
un subconjunto.

******* Punto 2
Por el teorema de factorización:

\[f_\theta(x) = h(x)g_\theta(h'(U(x)))\]

******* Punto 3
Trivial desde lo anterior usando la inversa.

**** Estadísticos completos
***** Familia de distribuciones completa
Una familia $\{P_\theta \mid \theta \in \Theta\}$ es completa si dada $X \leadsto P_\theta$ se tiene que
para cada $g$ medible:

\[
E_\theta[g(X)] = 0,\;\forall\theta\in\Theta
\implies
P_\theta(g(X) = 0) = 1,\;\forall\theta\in\Theta
\]

***** Estadístico completo
Un estadístico $T$ es *completo* cuando para cualquier función medible $g$,
se tiene:

\[ E_\theta [g(T)] = 0, \; \forall\theta\in\Theta
\implies
P_\theta(g(T) = 0) = 1,\; \forall\theta\in\Theta\]

**** Suficiencia y completitud en familias exponenciales
***** Familia exponencial k-paramétrica
Una familia $\{P_\theta : \theta \in \Theta\}$ es exponencial k-paramétrica si:

 1. $\Theta$ es intervalo de $\mathbb{R}^k$.
 2. Los valores de la variable no dependen de $\theta$, esto es:
    $\{{ x \mid f_{\theta}(x) > 0 \} = \{{ x \mid f_{\theta'}(x) > 0 \}$ para cualesquiera $\theta,\theta' \in \Theta$.
 3. La familia es de la forma:

    \[f_\theta(x) = exp\left\{\sum_{h=1}^k {Q_h(\theta) T_h(x) + S(x) + D(\theta)}\right\}\]

***** Teorema de suficiencia y complitud
Si una familia $\{P_\theta : \theta \in \Theta\}$ es exponencial k-paramétrica, cualquier muestra
aleatoria simple también lo es:

\[
f^n_\theta(x_1,\dots,x_n) = 
exp\left\{
\sum^k_{h=1} Q_h(\theta) \left(
\sum^n_{i=1} T_h(x_i)
\right) +
\sum^n_{i=1} S(x_i) + nD(\theta)
\right\}
\]

Teniéndose además:

 1. $(\sum_i T_1(X_i), \dots \sum_i T_k(X_i))$ estadístico *suficiente* para $\theta$.
 2. Si $k \leq n$, y $(Q_1(\Theta), \dots Q_k(\Theta))$ contiene un abierto;
    $(\sum_i T_1(X_i), \dots \sum_i T_k(X_i))$ es *completo*.

****** TODO Demostración

***** Ejemplo: la normal para la media
La familia $\{{\cal N}(\mu,\sigma^2) \mid \mu \in \mathbb{R}\}$ es uniparamétrica escribiendo la función
de distribución como:

\[
f_\theta(x) = 
exp\left\{
log\left(\frac{1}{\sqrt{2\pi\sigma^2}}\right) -
\left( \frac{x^2}{2\sigma^2} - 2\frac{x\mu}{2\sigma^2} + \frac{\mu^2}{2\sigma^2} \right)
\right\}
\]

De aquí tenemos el $T(x) = x$ suficiente para $\mu$. Y con para una muestra 
tenemos $T(x_1,\dots,x_n) = x_1 + \dots + x_n$.

***** Ejemplo: la normal para la varianza
La familia $\{{\cal N}(\mu,\sigma^2) \mid \sigma\in\mathbb{R}\}$ es uniparamétrica escribiendo la función
de distribución como:

\[
f_\theta(x) = 
exp\left\{
log\left(\frac{1}{\sqrt{2\pi\sigma^2}}\right) -
\frac{1}{2\sigma^2}\left(x^2 - 2x\mu + \mu^2 \right)
\right\}
\]

Así $T(x) = \sum_{i=1}^n (x_i - \mu)^2$ es suficiente. Además es completo porque
tenemos que $Q(\sigma) = -\frac{1}{2\sigma^2}$ tiene en la imagen un intervalo abierto.

***** Ejemplo: distribución de Poisson
La familia de Poisson $\{Poi(\lambda) \mid \lambda \in \mathbb{R}\}$ tiene como estimador suficiente 
del parámetro a la suma de las muestras. Tenemos:

\[
f_\lambda(x) = \frac{1}{\prod x_i!} e^{-n\lambda} \lambda^{\sum x_i}
\]

Luego por Fisher-Neyman, sabemos que $\sum x_i$ es suficiente.

*** 4. Estimación puntual
**** Planteamiento del problema de estimación
***** Estimador puntual
Un estimador puntual de $\theta$ es un estadístico $T$ tomando valores en el 
dominio del parámetro, $\Theta$.

***** Función de pérdida y de riesgo
La *función de pérdida*, $L(\theta,t)$, nos dice la pérdida asociada a estimar 
un parámetro si su verdadero valor es otro.

\[
L : \Theta \times \Theta \longrightarrow \Theta
\]

***** Función de riesgo
La *función de riesgo* es la que asocia a cada valor del parámetro la 
pérdida media asociada al estimador.

\[ R^L_T(\theta) = E_\theta [L(\theta,T)] \]

***** Estimador óptimo
El *estimador óptimo*, $T$, dada una función de pérdida, es el que minimiza 
uniformemente la función de riesgo:

\[ R^L_T(\theta) \leq R^L_{T''}(\theta),\quad \forall \theta \in \Theta,\; \forall T''\]

***** TODO Ejemplo de estimador óptimo
**** Estimación de menor error cuadrático
***** Función de pérdida cuadrática
La función de pérdida cuadrática, ${\cal L}(\theta, t) = (t - \theta)^2$, hace a la función de 
riesgo de un estimador su error cuadrático medio:

\[R^L_T(\theta) = E_\theta[(T - \theta)^2]\]

Nótese que en el caso de $E[T] = \theta$, se tiene $R^L_T(\theta) = Var_\theta[T]$.

**** Estimación insesgada de mínima varianza
***** Estimador insesgado
Un estimador $T$ de $g(\theta)$, es *insesgado* o *centrado* si:

 $E_\theta[T] = g(\theta)$

***** UMVUE: Estimador insesgado uniformemente de mínima varianza
Un estimador $T$ insesgado y de segundo orden es *UMVUE* para $g(\theta)$ si para 
cualquier otro estimador insesgado $T'$ se tiene que:

\[ Var_\theta[T] \leq Var_\theta[T']\]

****** De segundo orden
Lo llamamos de segundo orden cuando existe el momento de segundo orden:

\[
\exists \mathbb{E}_\theta[T^2(X_1,\dots,X_n)]
\quad
\forall \theta \in \Theta
\]

***** Propiedades del UMVUE
El estimador UMVUE cumple:

 - Unicidad: El UMVUE de cualquier función paramétrica, si existe, es único.
 - Linealidad: Si $T,Q$ son UMVUE para $g,h$; $aT+bQ$ es UMVUE para $ag+bh$.

****** Unicidad
Si existieran dos UMVUE con $Var(T) = Var(T')$, tendríamos:

\[\begin{aligned}
Var\left(\frac{1}{2}(T+T')\right) &= 
\frac{1}{4}
\left(
Var(T) + Var(T') + 2cov(T,T')
\right) \\& \leq
\frac{1}{4}
\left(
Var(T) + Var(T') + 2\sqrt{Var(T)Var(T')}
\right) \\& = Var(T)
\end{aligned}\]

La igualdad se da por ser UMVUE, y entonces, $cov(T,T') = Var(T)$.
De aquí $cov(T-T',T-T') = 0$, haciendo constante la diferencia entre los
dos. La diferencia entre ellos debe ser constantemente $0$ por ser ambos 
insesgados.

****** TODO Linealidad
***** Teorema de Raó-Blackwell
Si $T$ es suficiente para $\theta$ y $S$ es un estimador insesgado de $g(\theta)$ de 
segundo orden:

  - $E[S \mid T]$ es estimador insesgado de $g(\theta)$ de segundo orden.
  - $Var_\theta[E[S \mid T]] \leq Var_\theta[S]$

Es decir, $E[S \mid T]$ será normalmente mejor estimador y nunca peor que $S$.

****** Demostración
Sabemos $E[S|T] = E[S] = \theta$ por la [[*Ley de esperanza total][ley de esperanza total]]. La desigualdad
entre varianzas la vemos como:

\[\begin{aligned}
E\Big[(E[S|T] - \theta)^2 \Big] &= 
E\Big[E[S-\theta | T]^2 \Big] \leq
E\Big[E[(S-\theta)^2|T] \Big] = E\Big[(S-\theta)^2\Big]
\end{aligned}\]

Donde volvemos a usar la ley de esperanza total. La desigualdad viene
de que la varianza es positiva, o de la desigualdad de Jensen para el
cuadrado.

***** Teorema de Lehmann-Scheffé
Para $T$ suficiente y completo para $\theta$; si $g(\theta)$ admite un estimador insesgado 
de segundo orden $S$, entonces existe el UMVUE de $g(\theta)$ y está dado por:

\[ \mathbb{E} [S \mid T]\]

De otra forma, un estimador insesgado que es función de estimador completo
y suficiente es el UMVUE.

****** Demostración
Por [[*Teorema de Raó-Blackwell][Raó-Blackwell]], sabemos que es un estimador insesgado; y que, dado
cualquier otro estimador insesgado $Q$, tenemos que:

\[ Var[E[Q|T]] \leq Var[Q]\]

Ahora bien, dado otro, tendríamos:

\[
E\Big[ E[S|T] - E[Q|T] \Big] = 0
\]

Y como $T$ es completo y ambos son dependientes de $T$, eso implica que:

\[P\Big(
E[S|T] - E[Q|T] = 0
\Big) = 1\]

Por lo tanto, ambos son el UMVUE.

***** Cálculo del UMVUE
Dado $T$ suficiente y completo. Para calcular el UMVUE de $g(\theta)$ podemos:

  1. Buscar un estimador insesgado y de segundo orden cualquiera de $g(\theta)$.
     Entonces $\mathbb{E}[S|T]$ será el UMVUE.
  2. Buscar $h(T)$ tal que $\mathbb{E}_\theta[h(T)] = g(\theta)$, un estimador insesgado que es
     sólo función de $T$. Se cumplirá $\mathbb{E}[h(T)|T] = h(T)$.

**** Estimación eficiente
***** Condiciones de regularidad de Fréchet-Cramer-Rao
Una familia $\{P_\theta \mid \theta\in\Theta\}$ es *regular* en el sentido de Fréchet-Cramer-Rao
si cumple que:

  1. $\Theta$ es intervalo abierto de $\mathbb{R}$.
  2. $\forall \theta,\theta'\in\Theta : \{x \mid f_\theta(x) > 0\} = \{x \mid f_{\theta'}(x) > 0\} = \chi$
  3. Tenemos $f_\theta(x)$ derivable respecto a $\theta$ para todo $x \in \chi$ con:

     \[ \int_\chi \frac{d f_\theta(x)}{d\theta} dx = 
     \frac{d}{d\theta} \int_\chi f_\theta(x) dx = 
     0, \quad \forall \theta\in\Theta\]
   
     O, cuando la distribución es discreta:
   
     \[\sum_\chi \frac{d f_\theta(x)}{d\theta}
     = 
     \frac{d}{d\theta}\sum_\chi f_\theta(x)
     = 
     0\]

***** Función de información de Fisher
Si $\{P_\theta : \theta \in \Theta\}$ es regular, definimos la *función de información* asociada
a $X$ como:

\[I_X(\theta) = E_\theta\left[\left( \frac{d}{d\theta} \ln(f_\theta(X))
\right)^2\right]\]

Y la función de información asociada a una muestra como:

\[
\[I_{X_1,\dots,X_n}(\theta) = 
E_\theta\left[\left( \frac{d}{d\theta}\ln(f_\theta(X_1,\dots,X_n))
\right)^2\right]\]

***** Propiedades de la función de información
La función de información tiene como propiedades:

  1. $I_X(\theta) \geq 0$.

  2. En el caso $I_X(\theta) = 0$, $f_\theta(X)$ no depende de $\theta$.

  3. \[E_\theta \left[\frac{d}{d\theta} \ln f_\theta(X) \right] = 0\].

  4. \[ Var_\theta \left[\frac{d}{d\theta} \ln f_\theta(X) \right] = I_X(\theta) \].

  5. \[E_\theta \left[\frac{d}{d\theta} \ln f_\theta(X_1,\dots,X_n) \right] = 0\].

  6. \[ Var_\theta \left[\frac{d}{d\theta} \ln f_\theta(X_1,\dots,X_n) \right] = I_{X_1,\dots,X_n}(\theta) \].

  7. Aditividad, $I_{X_1,\dots,X_n}(\theta) = nI_X(\theta)$.
 
****** Demostración
******* Punto 3
Derivando y asumiendo las condiciones de regularidad:

\[
\mathbb{E}_\theta\left[\frac{\partial}{\partial\theta} \ln f_\theta(x)\right]
=
\int_\chi \left(\frac{\partial}{\partial\theta} \ln f_\theta(x)\right) f_\theta(x)\; dx
=
\int_\chi \frac{\partial}{\partial\theta} f_\theta(x)\;dx
= 0
\]

***** Función de información bajo Cramer-Raó
Bajo las hipótesis de regularidad fuertes de Fréchet-Cramer-Raó:

\[
I(\theta) = E_{\theta}\left[
-\frac{\partial^2}{\partial\theta^2} \log f_\theta(X)
\right]
\]

Es decir, debemos exigir que:

\[
\int_X \frac{\partial^2}{\partial\theta^2} f_\theta(x) dx =
\frac{\partial^2}{\partial\theta^2} \int_X  f_\theta(x) dx
\]

****** Demostración
Notando primero la siguiente igualdad:

\[
\frac{\partial^2}{\partial\theta^2}\log f_\theta(x) =
\frac{1}{f_\theta(x)}\frac{\partial^2}{\partial\theta^2}f_\theta(x) -
\left(\frac{\partial}{\partial\theta}\log f_\theta(x)\right)^2
\]

Y simplemente tomamos esperanzas, sabiendo que por las condiciones de
regularidad:

\[
\mathbb{E}\left[
\frac{1}{f_\theta(x)}
\frac{\partial^2}{\partial\theta^2} f_\theta(x)
\right]
=
\frac{\partial^2}{\partial\theta^2}
\int_X f_\theta(x)\;dx 
= 
\frac{\partial^2}{\partial\theta^2}
1
=
0
\]

***** Estadístico regular
Un estadístico $T$ es regular en el sentido de Fréchet-Cramer-Raó, si
siendo una distribución discreta:

\[\begin{aligned}
\frac{d}{d\theta}
E_\theta[T] &=
\frac{d}{d\theta} 
\sum_{x \in \chi^n} T(x)f_\theta(x) \\&= 
\sum_{x \in \chi^n} T(x) \frac{d}{d\theta} f_\theta(x)
\end{aligned}\]

O, siendo una distribución continua:

\[\begin{aligned}
\frac{d}{d\theta}
E_\theta[T] &=
\frac{d}{d\theta} 
\int_{x \in \chi^n} T(x)f_\theta(x) \;dx \\&= 
\int_{x \in \chi^n} T(x) \frac{d}{d\theta} f_\theta(x) \;dx
\end{aligned}\]

***** Cota de Fréchet-Cramer-Raó
Si $\{P_\theta \mid \theta \in \Theta\}$ es regular, la función de información se acota
$0 < I_X(\theta) < \infty$, y $T$ es un estadístico regular, de segundo orden e
insesgado en una función derivable $g(\theta)$, se tiene:

  1. \[Var_\theta[T] \geq \frac{g'(\theta)^2}{I_{X_1,\dots,X_n}(\theta)}\]

  2. Para todo $\theta \in \Theta$ tal que $g'(\theta) \neq 0$:

     \[Var_\theta[T] = \frac{g'(\theta)^2}{I_{X_1,\dots,X_n}(\theta)}\]
     
     ssi existe $a(\theta) \neq 0$ tal que:

     \[P_\theta\left(
     \frac{d}{d\theta} \ln f^n_\theta(X_1,\dots,X_n) = 
     a(\theta)[T(X_1,\dots,X_n) - g(\theta)]
     \right) = 1\]

****** Demostración
******* Primer punto
Llamamos primero:

\[V_\theta = \frac{\partial}{\partial\theta} \ln f_\theta(x_1,\dots,x_n)\]

Tenemos que:

  - $Var_\theta(V_\theta) = I_{X_1,\dots,X_n}(\theta)$
  - $\mathbb{E}(V_\theta) = 0$
  - $Cov(T,V_\theta) = \mathbb{E}[TV_\theta] - \mathbb{E}[T]\mathbb{E}[V]$

Calculando:

\[\begin{aligned}
Cov(T,V_\theta) 
&=
\int_{\chi^n} 
T(x_1,\dots,x_n)
\left(\frac{\partial}{\partial\theta} \ln f_\theta(x_1,\dots,x_n)\right)
f_\theta(x_1,\dots,x_n)\;dx 
\\&=
\int_{\chi^n} 
T(x_1,\dots,x_n)
\left(\frac{\partial}{\partial\theta} f_\theta(x_1,\dots,x_n)\right)\;dx 
\\&=
\frac{\partial}{\partial\theta} \int_{\chi^n} 
T(x_1,\dots,x_n)
\left(f_\theta(x_1,\dots,x_n)\right)\;dx 
\\&=
\frac{\partial}{\partial\theta} g(\theta)
\end{aligned}\]

Y finalmente aplicamos la desigualdad de Cauchy-Schwartz a la 
covarianza entre $T,V_\theta$ para tener:

\[
Cov(T,V_\theta) \leq Var[T]Var[V_\theta]
\]
    
***** Estimador eficiente
Sea $\{P_\theta \mid \theta \in \Theta\}$ regular, con la función de información acotada 
$0 < I_X(\theta) < \infty$ y $g(\theta)$ función paramétrica derivable. Un estimador $T$ de $g(\theta)$ 
es *eficiente* si es insesgado, regular, y su varianza alcanza la
cota de Fréchet-Cramer-Raó en todo punto:

\[Var_\theta[T] = \frac{(g'(\theta))^2}{I_{X_1,\dots,X_n}(\theta)},
\qquad \forall\theta \in \Theta\]

***** Caracterización de estimadores eficientes
Sea $\{P_\theta \mid \theta \in \Theta\}$ regular, con $0 < I_X(\theta) < \infty$ y $g(\theta)$ función paramétrica
derivable y *no constante*. Un estimador $T$ es eficiente ssi existe un $a(\theta)$
cumpliendo:

  1. \[P_\theta\left(\frac{d}{d\theta} \ln f^n_\theta(X_1,\dots,X_n) = a(\theta)[T(X_1,\dots,X_n) - g(\theta)]\right) = 1\]

  2. \[I_{X_1,\dots,X_n}(\theta) = a(\theta)g'(\theta)\]

****** Demostración
******* Primera implicación
Si tenemos un $T$ eficiente, tomamos el $T$ de la cota y $g'(\theta)\neq 0$,
de ahí tenemos la primera igualdad.

***** Ejemplo: distribución binomial
Dada la familia de distribuciones $\{B(k_0,p) \mid p \in (0,1)\}$, veremos que es
regular.

****** Es regular
El intervalo $p \in (0,1)$ es abierto y $\chi = (0,\dots,k_0)$.

Si la expresamos exponencialmente es más fácil calcular su derivada
y relacionarla con una esperanza:

\[
f_p(x)
= 
\exp\left\{\log{k_0\choose x} + x \log p + (k_0-x)\log (1-p)\right\}
\]

Tenemos:

\[
\sum_\chi \frac{\partial f_p(x)}{\partial p}
=
\sum_\chi \frac{x-pk_0}{p(1-p)} f_p(x)
=
\mathbb{E}\left[\frac{X-pk_0}{p(1-p)} \right] = 0
\]

****** Función de información
Desde la derivada podemos calcular la función de información:

\[
I_{X_1,\dots,X_n}(p) = \frac{nk_0}{p(1-p)}
\]

****** Caracterización del estimador eficiente
Calcularemos para usar la caracterización:

\[
\frac{\partial}{\partial p} \ln f_p(x_1,\dots,x_n)
=
\sum \frac{\partial}{\partial p} f_p(x_i)
=
n\frac{\overline{x}-pk_0}{p(1-p)}
\]

Así, para cumplir la caracterización, tiene sentido tomar:

  - $g(p) = pk_0$
  - $T(X_1,\dots,X_n) = \overline{X}$
  - $a(p) = \frac{n}{p(1-p)}$

**** Estimación de máxima verosimilitud
***** Función de verosimilitud
Para cada realización muestral se define la función de verosimilitud
de la realización, $L_{x_1,\dots,x_n} : \Theta \longrightarrow \mathbb{R}^+_0$, como:

\[L(\theta) = f_\theta(x_1,\dots,x_n)\]

***** Estimador de máxima verosimilitud
Tenemos $\hat\theta$ estimador de máxima verosimilitud de $\theta$ cuando la estimación
asociada a cada realización muestral maximiza la verosimilitud:

\[L_{x_1,\dots,x_n}\left(\hat\theta(x_1,\dots,x_n)\right)
= \max_{\theta \in \Theta} L_{x_1,\dots,x_n}(\theta)\]

***** Ecuación de máxima verosimilitud
El procedimiento habitual para hallar el estimador de máxima 
verosimilitud es derivar e igualar:

\[
\frac{\partial}{\partial\theta_j} \ln L_{X_1,\dots,X_n}(\theta_1,\dots,\theta_k)
= 0
\]

Nótese que esto sólo nos da un punto crítico.

****** Demostración
Usando simplemente que el logaritmo es creciente y la caracterización
de los máximos.

***** Propiedades del estimador de máxima verosimilitud
Un estimador de máxima verosimilitud $\hat\theta$ de $\theta$ cumple:

  1. Consistencia:

     \[\lim_{n \to \infty}\hat\theta(x_1,\dots,x_n) = \theta\]

  2. Normalidad asintótica. Para $n$ suficientemente grande, sus errores
     pueden aproximarse por una normal:

     \[\sqrt{n}(\hat\theta(x_1,\dots,x_n) - \theta) \leadsto {\cal N}(0,1/I_X(\theta))\]

****** TODO Demostración

***** Relación con estadísticos suficientes
Si $\{P_\theta \mid \theta \in \Theta\}$ admite estadístico suficiente $T$, entonces $\hat\theta$ es función
de $T$.

****** Demostración
Por Teorema de factorización de Fisher-Neyman, tenemos que la
función de distribución se escribirá como:

\[
f_\theta(x) = h(x)g_\theta(T)
\]

Entonces para maximizarla habrá que maximizar $g_\theta(T)$.

***** Relación con estimadores eficientes
Si $T$ es estimador eficiente de $\theta$, entonces $T$ es el único estimador 
máximo verosímil de $\theta$.

****** TODO Demostración

***** Función de verosimilitud de una función paramétrica
Se define la función de verosimilitud de $g : \Theta \longrightarrow \Lambda$ asociada a
una realización, $M_{x_1,\dots,x_n} : \Lambda \longrightarrow \mathbb{R}^+_0$, como:

\[M_{x_1,\dots,x_n}(\lambda)
= \sup_{\theta \in g^{-1}(\lambda)} L_{x_1,\dots,x_n}(\theta) \]

***** Estimador de máxima verosimilitud de una función paramétrica
Será $\hat\lambda$ estimador máximo verosímil de $\lambda$ cuando:

\[M_{x_1,\dots,x_n}(\hat\lambda(x_1,\dots,x_n)) 
= \max_{\lambda \in \Lambda} M_{x_1,\dots,x_n}(\lambda) \]

***** Teorema de invarianza de Zenha
Si $\hat\theta$ es estimador máximo verosímil de $\theta$, entonces $g(\hat\theta)$ es estimador
máximo verosímil de $g(\theta)$.

****** TODO Demostración
Se cumple:

\[
M(\lambda') = sup_{\theta \in g^{-1}(\lambda')} L(\theta)
\leq
sup_{\theta \in \Theta} L(\theta)
=
L(\hat\theta)
=
M(g(\hat\theta))
\]

**** Método de los momentos
***** Descripción
El estimador de una función dependiente en los momentos
poblacionales es el mismo dependiendo en los momentos muestrales.

\[g(\theta) = h(m_{\theta,1},\dots,m_{\theta,k}) 
\quad\Rightarrow\quad
\widehat{g(\theta)}(X_1,\dots,X_n) = h(A_1,\dots,A_k)\]

****** Momentos poblacionales
Definimos los momentos poblacionales como:

\[m_{\theta,j} = E_\theta[X^j]\]

****** Momentos muestrales
Definimos los momentos muestrales como:

\[A_j = \frac{1}{n}\sum_{i=1}^n X^j_i\]

**** Método de mínimos cuadrados
***** Descripción
Si $X_i$ son las observaciones aleatorias de una magnitud $\varphi(t,\theta)$ con
errores $\varepsilon_i$; es decir:

\[X_i = \varphi(t_i,\theta) + \varepsilon_i\]

Entonces el estimador de mínimos cuadrados de $\theta$ es el que minimice
la suma de cuadrados de los errores:

\[\sum^n_{i=1}(X_i - \varphi(t_i,\theta))^2\]

*** 5. Estimación por intervalos de confianza
**** Definiciones y métodos de construcción
***** Intervalo de confianza
Para $X \leadsto P_\theta$, un intervalo de confianza $\alpha$ para $\theta$ es un intervalo 
aleatorio $(I_1,I_2)$ tal que para cualquier $\theta \in \Theta$:

\[P_\theta\left(
I_1(X_1,\dots,X_n) \leq \theta \leq I_2(X_1,\dots,X_n)
\right)
\geq 1 - \alpha\]

***** Intervalo de confianza de menor longitud esperada uniformemente
Un interavlo $(I_1,I_2)$ es el de menor longitud esperada uniformemente 
si para cualquier otro $(I_1',I_2')$ al mismo nivel, se tiene:

\[
E_\theta[I_2(X_1,\dots,X_n) - I_1(X_1,\dots,X_n)]
\leq
E_\theta[I_2'(X_1,\dots,X_n) - I_1'(X_1,\dots,X_n)]
\]

***** Intervalos mediante desigualdad de Chevychev
Si $T$ es estimador insesgado de $\theta$ con varianza uniformemente acotada:

  - $E_\theta[T(X_1,\dots,X_n)] = \theta$
  - $Var_\theta[T(X_1,\dots,X_n)] \leq c$

Por lo que por Chevychev tenemos, dado $k>0$, un intervalo de confianza
para $\theta$ al nivel de confianza $1 - c/k^2$:

\[P\left(T - k \leq \theta \leq  T + k \right) \geq 1 - c/k^2\]

****** TODO Demostración

***** Pivote para un parámetro
Un pivote es una función $T(X_1,\dots,X_n,\theta)$ tal que fijado cualquier $\theta$,
$T(X_1,\dots,X_n,\theta)$ es una variable con distribución independiente de $\theta$.

***** Intervalos obtenidos mediante el método pivotal
Dado un pivote $T$ estrictamente monótono respecto a $\theta$, y dos valores
$\lambda_1,\lambda_2$, tales que:

\[P_\theta(\lambda_1 < T < \lambda_2) \geq 1 - \alpha\]

Tomamos las soluciones $\hat\theta_1, \hat\theta_2$, cumpliendo $T(X_1,\dots,\hat\theta_1) = \lambda_1$ y
$T(X_1,\dots,\hat\theta_2) = \lambda_2$; y ellas forman un intervalo de confianza:

  - $P_\theta(\hat\theta_1 < \theta < \hat\theta_2) \geq 1 - \alpha$, para $T$ creciente.
  - $P_\theta(\hat\theta_2 < \theta < \hat\theta_1) \geq 1 - \alpha$, para $T$ decreciente.

****** TODO Demostración

***** Un pivote en distribuciones continuas
Si $X$ es continua con $F_\theta$ función de distribución, un pivote es:

\[ T(X_1,\dots,X_n,\theta) = -2 \sum_{i=1}^n \ln F_\theta(X_i) \leadsto \chi^2(2n)\]

****** TODO Demostración
***** Un pivote dado un estadístico
Sea $S$ un estadístico de distribución continua con $F^S_\theta$ función de 
distribución. Un pivote es:

\[T(X_1,\dots,X_n,\theta) = F^S_\theta(S(X_1,\dots,X_n)) \leadsto U(0,1)\]

****** TODO Demostración
**** Ejemplos de intervalos de confianza
***** A1. Intervalo para la media de una normal con varianza conocida
Sea $X \leadsto {\cal N}(\mu,\sigma^2_0)$. El intervalo para $\mu$ de menor longitud
media uniforme a nivel de confianza $1-\alpha$ será:

\[\left(
\overline{X}-z_{\alpha/2}\frac{\sigma_0}{\sqrt{n}},
\overline{X}+z_{\alpha/2}\frac{\sigma_0}{\sqrt{n}}
\right)\]

donde $z_{\alpha/2}$ cumple que \[P\left(Z > z_{\alpha/2}\right) = \alpha/2\] con $Z \leadsto {\cal N}(0,1)$.

****** Pivote
Usamos como pivote a la normalizada:

\[T(X_1,\dots,X_n,\mu) = \frac{\overline{X} - \mu}{\sigma / \sqrt{n}} \leadsto {\cal N}(0,1)\]

****** Intervalos candidatos
Usando el pivote, tenemos el siguiente candidato a intervalo de
confianza:

\[
1 - \alpha > 
P_\mu\left(
\lambda_1 < 
\frac{\overline{X} - \mu}{\sigma_0 / \sqrt{n}} <
\lambda_2
\right)
=
P_\mu\left(
\overline{X} - \lambda_2\frac{\sigma_0}{\sqrt{n}} <
\mu <
\overline{X} - \lambda_1\frac{\sigma_0}{\sqrt{n}}
\right)
\]

Debiendo tenerse que, si $\Phi$ es la función de distribución de la
normal $\Phi(\lambda_2)-\Phi(\lambda_1) = 1 - \alpha$.

****** Longitud media
Buscamos el que minimice la longitud media:

\[E_\mu \left[
\left( \overline{X} - \lambda_1\frac{\sigma_0}{\sqrt{n}} \right) -
\left( \overline{X} - \lambda_2\frac{\sigma_0}{\sqrt{n}} \right)
\right] 
= (\lambda_2-\lambda_1)\frac{\sigma_0}{\sqrt{n}}\]

Por lo que tratamos de minimizar $(\lambda_2-\lambda_1)$.

****** Minimización
Usamos multiplicadores de Lagrange para definir:

\[F(\lambda_1,\lambda_2) = \lambda_2-\lambda_1 + \lambda(\Phi(\lambda_2) - \Phi(\lambda_1) - (1-\alpha))\]

Calculando las derivadas parciales tenemos:

\[\begin{aligned}
-1-\lambda\Phi'(\lambda_1) &= 0\\
1 + \lambda\Phi'(\lambda_2) &= 0
\end{aligned}
\]

Luego debe tenerse $\Phi'(\lambda_1) = \Phi'(\lambda_2)$. Sabiendo que $\Phi'$ es la función
de distribución de la normal, tenemos $\lambda_1 = \pm \lambda_2$. Como deben ser
distintos para cumplir la restricción, tenemos $\lambda_1 = -\lambda_2$.

****** Conclusión
La restricción nos fuerza a $\Phi(\lambda_2) - \Phi(-\lambda_2) = 1 - \alpha$, luego estamos
buscando el $z_{\alpha/2}$ que cumple, para una normalizada $Z$, $P(Z > z_{\alpha/2}) = \alpha/2$.

***** A2. Intervalo para la media de una normal con varianza desconocida
Sea $X \leadsto {\cal N}(\mu,\sigma^2)$. El intervalo para $\mu$ de menor longitud media uniforme
a nivel de confianza $1-\alpha$ será:

\[
\left(
\overline{X} - t_{n-1;\alpha/2}\frac{S}{\sqrt{n}},\,
\overline{X} + t_{n-1;\alpha/2}\frac{S}{\sqrt{n}}
\right)
\]

donde $t_{n-1;\alpha/2}$ cumple que $P(Z \leq t_{n-1;\alpha/2}) = \alpha/2$ con $Z \leadsto T(n-1)$.

****** Pivote
Usaremos como pivote la t de Student:

\[
T = \frac{\overline{X}-\mu}{S/\sqrt{n}} \leadsto t(n-1)
\]

****** Intervalos candidatos
Usando el pivote tenemos el siguiente intervalo de confianza:

\[
1 - \alpha =
P_\mu\left(
\lambda_1 < 
\frac{\overline{X} - \mu}{S / \sqrt{n}} <
\lambda_2
\right)
=
P_\mu\left(
\overline{X} - \lambda_2\frac{S}{\sqrt{n}} <
\mu <
\overline{X} - \lambda_1\frac{S}{\sqrt{n}}
\right)
\]

Donde, si $\Phi$ es la función de distribución de $t(n-1)$, tenemos
que $1-\alpha = \Phi(\lambda_2)-\Phi(\lambda_1)$.

****** Longitud media
Queremos minimizar la longitud esperada del intervalo:

\[
\mathbb{E}\left[
\left(\overline{X}-\lambda_1\frac{S}{\sqrt{n}}\right) - 
\left(\overline{X}-\lambda_2\frac{S}{\sqrt{n}}\right)
\right]
=
(\lambda_2-\lambda_1)\mathbb{E}\left[
\frac{S}{\sqrt{n}}
\right]
\]

Buscamos por tanto minimizar $\lambda_2-\lambda_1$.

****** Minimización
Usamos multiplicadores de Lagrange para definir:

\[F(\lambda_1,\lambda_2) = \lambda_2-\lambda_1 + \lambda(\Phi(\lambda_2) - \Phi(\lambda_1) - (1-\alpha))\]

De donde deducimos $\Phi'(\lambda_1) = \Phi'(\lambda_2)$. Como la t de Student es simétrica
y monótona en cada mitad, tenemos $\lambda_1 = -\lambda_2$.

****** Conclusión
Buscamos entonces el $t_{\alpha/2}$ que cumple $P(Z > t_{\alpha/2}) = \alpha/2$.

***** B1. Intervalo para la varianza de una normal con media conocida
Sea $X \leadsto {\cal N}(\mu,\sigma^2)$. El intervalo para $\sigma^2$ de menor longitud media uniforme
a nivel de confianza $1-\alpha$ es:

\[
\left(
\frac{\sum_{i=1}^n(X_i-\mu)^2}{\chi^2_{n;\alpha/2}}
,\quad
\frac{\sum_{i=1}^n(X_i-\mu)^2}{\chi^2_{n;1-\alpha/2}}
\right)
\]

Donde $\chi^2_{n;\alpha/2}$ cumple que $P(Z > \chi^2_{n;\alpha/2}) = \alpha/2$ para $Z \leadsto \chi^2(n)$.

****** Pivote
Tomamos como pivote a la función:

\[
\sum_{i=1}^n \left(\frac{X_i - \mu}{\sigma}\right)^2
\leadsto
\chi(n)
\]

****** Intervalos candidatos
Usando el pivote tenemos el siguiente intervalo de confianza:

\[
1-\alpha = P\left(
\frac{\sum_{i=1}^n (X_i-\mu)^2}{\lambda_2}
\leq
\sigma^2
\leq
\frac{\sum_{i=1}^n (X_i-\mu)^2}{\lambda_1}
\right)
\]

Donde, si $\Phi$ es la función de distribución de $\chi(n)$, tenemos que
$1-\alpha = \Phi(\lambda_2)-\Phi(\lambda_1)$. Buscamos minimizar $1/\lambda_1-1/\lambda_2$.

****** Minimización
Usamos minimizadores de Lagrange. Definimos:

\[
F(\lambda_1,\lambda_2) = 
\frac{1}{\lambda_2}-\frac{1}{\lambda_1} + 
\lambda(\Phi(\lambda_2)-\Phi(\lambda_1) - (1-\alpha))
\]

Calculando las derivadas parciales tenemos:

\[
\lambda\Phi'(\lambda_2) - \frac{1}{\lambda_2^2} = 0
\]
\[
\lambda\Phi'(\lambda_1) - \frac{1}{\lambda_1^2} = 0
\]

Y por tanto se minimiza cuando $\Phi(\lambda_1)/\Phi(\lambda_2) = \lambda_2^2/\lambda_1^2$. En la práctica
se usa el intervalo de colas iguales.

****** Conclusión
El intervalo de colas iguales nos da $\lambda_1 = \chi^2_{n;1-\alpha/2}$ y $\lambda_2 = \chi^2_{n;\alpha/2}$.

***** B2. Intervalo para la varianza de una normal con media desconocida
Sea $X \leadsto {\cal N}(\mu,\sigma^2)$. El intervalo para $\sigma^2$ de menor longitud media uniforme
a nivel de confianza $1-\alpha$ es:

\[
\left(
\frac{(n-1)S^2}{\chi^2_{n-1;\alpha/2}}
,\quad
\frac{(n-1)S^2}{\chi^2_{n-1;1-\alpha/2}}
\right)
\]

Donde $\chi^2_{n-1;\alpha/2}$ cumple que $P(Z > \chi^2_{n-1;\alpha/2}) = \alpha/2$ para $Z \leadsto \chi^2(n-1)$.

****** Pivote
Tomamos como pivote:

\[
\frac{(n-1)S^2}{\sigma^2} \leadsto \chi^2(n-1)
\]

***** C1. Intervalo para la diferencia de medias de normales de varianza dada
Sean $X \leadsto {\cal N}(\mu_1,\sigma_1^2)$, $Y \leadsto {\cal N}(\mu_2,\sigma_2^2)$. El intervalo para $\mu_1-\mu_2$ de menor
longitud media uniforme a nivel de confianza $1-\alpha$ es:

\[
\left(
\overline{X}-\overline{Y} - 
z_{\alpha/2}\sqrt{\frac{\sigma_1^2}{n_1}+\frac{\sigma_2^2}{n_2}}
,\quad
\overline{X}-\overline{Y} +
z_{\alpha/2}\sqrt{\frac{\sigma_1^2}{n_1}+\frac{\sigma_2^2}{n_2}}
\right)
\]

Donde $z_{\alpha/2}$ cumple que $P(Z>z_{\alpha/2}) = \alpha/2$ para $Z\leadsto {\cal N}(0,1)$.

****** Pivote
Usamos como pivote:

\[
\frac
{\overline{X}-\overline{Y}-(\mu_1-\mu_2)}
{\sqrt{\frac{\sigma_1^2}{n_1}+\frac{\sigma_2^2}{n_2}}}
\leadsto
{\cal N}(0,1ñ)
\]

***** C2. Intervalo para la diferencia de medias de normales de varianza igual
Sean $X \leadsto {\cal N}(\mu_1,\sigma^2)$, $Y \leadsto {\cal N}(\mu_2, \sigma^2)$. El intervalo para $\mu_1-\mu_2$ de menor
longitud media uniforme a nivel de confianza $1-\alpha$ es:

\[
\left(
\overline{X}-\overline{Y} - t_{n_1+n_2-2;\alpha/2}S_p\sqrt{\frac{1}{n_1}+\frac{1}{n_2}}
,\quad
\overline{X}-\overline{Y} + t_{n_1+n_2-2;\alpha/2}S_p\sqrt{\frac{1}{n_1}+\frac{1}{n_2}}
\right)
\]

donde,

\[
S_p = \sqrt{\frac{(n_1-1)S_1^2+(n_2-1)S^2_2}{n_1+n_2-2}}
\]

y donde $t_{n_1+n_2-2;\alpha/2}$ cumple que $P(Z > t_{\alpha/2}) = \alpha/2$ con $Z \leadsto t(n_1+n_2-2)$.

****** Pivote
Tomamos como pivote a la función:


\[
\frac{(\overline{X}-\overline{Y}) - (\mu_1-\mu_2)}
{
S_p
\sqrt{\frac{1}{n_1}+\frac{1}{n_2}}
}
\leadsto
t(n_1+n_2-2)
\]

****** Intervalos candidatos
Usando el pivote tenemos el siguiente invervalo de confianza:

\[
1-\alpha = P\left(
\overline{X}-\overline{Y} - \lambda_1S_p\sqrt{\frac{1}{n_1}+\frac{1}{n_2}}
\leq
\mu_1-\mu_2
\leq
\overline{X}-\overline{Y} + \lambda_2S_p\sqrt{\frac{1}{n_1}+\frac{1}{n_2}}
\right)
\]

Donde, si $\Phi$ es la función de distribución de $t(n_1+n_2-2)$, tenemos
que $1-\alpha = \Phi(\lambda_2) - \Phi(\lambda_1)$. Buscamos minimizar $\lambda_2-\lambda_1$.

****** Minimización
Usaremos minimizadores de Lagrange para deducir de nuevo que
$\Phi'(\lambda_1) = \Phi'(\lambda_2)$, por monotonía y simetricidad, $\lambda_1=\lambda_2$.

****** Conclusión
Buscamos entonces el $t_{\alpha/2}$ que cumple $P(Z > t_{\alpha/2}) = \alpha/2$.

***** D1. Intervalo para el cociente de varianzas de normales de media dada
Sean $X \leadsto {\cal N}(\mu_1,\sigma_1^2)$, $Y \leadsto {\cal N}(\mu_2,\sigma_2^2)$. El intervalo para $\sigma_1^2/\sigma_2^2$ de menor
longitud media uniforme a nivel de confianza $1-\alpha$ es:

\[
\left(
F_{n_2,n_1;1-\alpha/2}
\frac{\sum_{i=1}^{n_1} (X_i-\mu_1)^2/n_1}{\sum_{i=1}^{n_2} (Y_i-\mu_2)^2/n_2}
,
F_{n_2,n_1;\alpha/2}
\frac{\sum_{i=1}^{n_1} (X_i-\mu_1)^2/n_1}{\sum_{i=1}^{n_2} (Y_i-\mu_2)^2/n_2}
\right)
\]

donde, $F_{n_2,n_1;\alpha/2}$ cumple que $P(Z > F_{\alpha/2}) = \alpha/2$ con $Z \leadsto F(n_2,n_1)$.

****** Pivote
Tomamos como pivote a la función:

\[
\frac
{\sum_{i=1}^{n_2} (Y_i-\mu_2)^2 / n_2\sigma_2^2}
{\sum_{i=1}^{n_2} (X_i-\mu_1)^2 / n_1\sigma_1^2}
\leadsto
F(n_2,n_1)
\]

****** Intervalos candidatos
Usando el pivote tenemos el siguiente intervalo de confianza:

\[
1 - \alpha = P
\left(
\lambda_1\frac
{\frac{1}{n_1}\sum_{i=1}^{n_1} (X_i-\mu_1)^2}
{\frac{1}{n_2}\sum_{i=1}^{n_2} (Y_i-\mu_2)^2}
\leq
\frac{\sigma^2_1}{\sigma^2_2}
\leq
\lambda_2\frac
{\frac{1}{n_1}\sum_{i=1}^{n_1} (X_i-\mu_1)^2}
{\frac{1}{n_2}\sum_{i=1}^{n_2} (Y_i-\mu_2)^2}
\right)
\]

Donde, si $\Phi$ es la función de distribución de $F(n_1,n_2)$, tenemos que
$1-\alpha = \Phi(\lambda_2)-\Phi(\lambda_1)$. Buscamos minimizar $\lambda_2-\lambda_1$.

****** Minimización
Por el mismo razonamiento con multiplicadores de Lagrange, llegamos
a $\Phi'(\lambda_2) = \Phi'(\lambda_1)$. Nótese que en este caso la distribución no es
simétrica.

****** Conclusión
Buscamos entonces:

  - el $F_{n_2,n_1;1-\alpha/2}$ que cumple $P(Z > F) = 1-\alpha/2$.
  - el $F_{n_2,n_1;\alpha/2}$ que cumple $P(Z>F) = \alpha/2$.

***** D2. Intervalo para el cociente de varianzas de normales de media desconocida
Sean $X \leadsto {\cal N}(\mu_1,\sigma^2_1)$, $Y \leadsto {\cal N}(\mu_2,\sigma_2^2)$. El intervalo para $\sigma^2_1/\sigma^2_2$ de menor
longitud media uniforme a nivel de confianza $1-\alpha$ es:

\[
\left(
F_{n_2-1,n_1-1; 1-\alpha/2}\frac{S_1^2}{S_2^2}
,
F_{n_2-1,n_1-1; \alpha/2}\frac{S_1^2}{S_2^2}
\right)
\]

donde, $F_{n_2-1,n_1-1; 1-\alpha/2}$ cumple que $P(Z > F_{\alpha/2}) = \alpha/2$ con $Z \leadsto F(n_2-1,n_1-1)$.

****** Pivote
Tomamos como pivote a la función:

\[
\frac{S_2^2/\sigma_2^2}{S_1^2/\sigma_1^2}
\leadsto
F(n_2-1,n_1-1)
\]

****** Intervalos candidatos
Usando el pivote llegamos al siguiente intervalo de confianza:

\[
1-\alpha = P
\left(
\frac{\sigma_1^2}{\sigma_2^2}\lambda_1
\leq
\frac{S_2^2}{S_1^2}
\leq
\frac{\sigma_1^2}{\sigma_2^2}\lambda_2
\right)
\]

Donde, si $\Phi$ es la función de distribución de $F(n_2-1,n_1-1)$, tenemos
que $1-\alpha = \Phi(\lambda_2) - \Phi(\lambda_1)$. Buscamos minimizar $\lambda_2-\lambda_1$.

****** Minimización
Por el mismo razonamiento con multiplicadores de Lagrange, llegamos
a $\Phi'(\lambda_2) = \Phi'(\lambda_1)$. Nótese que en este caso la distribución no es
simétrica.

****** Conclusión
Buscamos entonces:

  - el $F_{n_2-1,n_1-1;1-\alpha/2}$ que cumple $P(Z > F) = 1-\alpha/2$.
  - el $F_{n_2-1,n_1-1;\alpha/2}$ que cumple $P(Z>F) = \alpha/2$.

**** TODO Intervalos unilaterales
*** 6. Contraste de hipótesis
**** Planteamiento del problema
***** Problema de contraste de hipótesis
Dada $(X_1,\dots,X_n)$ una muestra aleatoria simple de $X \leadsto P_\theta$, para
$\theta \in \Theta_0 \cup \Theta_1$, llamamos:

 - *Hipótesis nula*: $H_0 : \theta \in \Theta_0$
 - *Hipótesis alternativa*: $H_1 : \theta \in \Theta_1$

a dos hipótesis posibles.

***** Test de hipótesis
El *test de hipótesis* es un estadístico $\varphi$ tomando valores en $[0,1]$, que 
da la posibilidad de rechazar $H_0$ dada una realización muestral. Se 
llama:

  - *Test no aleatorizado*, si toma valores $0,1$.
  - *Test aleatorizado*, si toma valor distinto de $0,1$.

***** Tipos de errores de un test de hipótesis
Hay dos tipos de erorres:

  - *Error de tipo 1*: Rechazar $H_0$ siendo cierta. Falso negativo.
  - *Error de tipo 2*: Aceptar $H_0$ siendo falsa. Falso positivo.

***** Función de potencia de un test
Dado un test $\varphi$, su función de potencia $\beta_\varphi : \Theta \longrightarrow [0,1]$ se define:

\[\beta_\varphi(\theta) = E_\theta[\varphi(X_1,\dots,X_n)]\]

Que es la probabilidad media de rechazar $H_0$ bajo $P_\theta$.

***** Tamaño del test
El tamaño del test es $\sup_{\theta \in \Theta_0} \beta_\varphi(\theta)$, la máxima probabilidad media de
cometer un error de tipo 1.

***** Nivel de significación de un test
Un test $\varphi$ tiene nivel de significación $\alpha$ si su tamaño es menor o igual
que $\alpha$. Es decir,

\[
\forall \theta \in \Theta_0, \quad
\beta_\varphi(\theta) =
E_\theta[\varphi(X_1,\dots,X_n)] \leq
\alpha
\]

***** Test uniformemente más potente
Un test con nivel de significación $\alpha$ es uniformemente más potente a 
dicho nivel si para cualquier otro test $\varphi'$ con nivel de significación
$\alpha$, se tiene:

\[\beta_{\varphi'}(\theta) \leq \beta_\varphi(\theta)
\quad \forall \theta \in \Theta_1\]

**** Lema de Neyman-Pearson
***** El problema de contraste
Fijado un nivel de significación, encontrar el test uniformemente más
potente a dicho nivel.

***** Lema de Neyman-Pearson
Sea $X \longrightarrow \{P_{\theta_0}, P_{\theta_1}\}$ y $(X_1,\dots,X_n)$ una muestra aleatoria simple
con funciones de densidad $f_0,f_1$. Consideramos el problema de contraste 
con $H_0 : \theta = \theta_0$ y $H_1 : \theta = \theta_1$.

  1. Cualquier test de la forma:

     \[
     \varphi(\tilde X) = 
     \threepartdef
     {1}{f_1(\tilde X) > kf_0(\tilde X)}
     {\gamma(\tilde X)}{f_1(\tilde X) = kf_0(\tilde X)}
     {0}{f_1(\tilde X) < kf_0(\tilde X)}
     \]
     
     con $k \in \mathbb{R}^+_0$ y $\gamma(X_1,\dots,X_n) \in [0,1]$, es de máxima potencia entre todos
     los de nivel de significación $\alpha = E_{\theta_0}[\varphi]$, su tamaño.
     
  2. Para todo $\alpha \in (0,1]$ existe un test de la forma anterior con
     $\gamma(X_1,\dots,X_n) = \gamma$ constante y tamaño $\alpha$.

  3. Si $\varphi'$ es de máxima potencia al nivel de significación $\alpha = E_{\theta_0}[\varphi']$, 
     entonces $\varphi'$ es de la forma anterior con probabilidad 1 bajo $P_{\theta_0}$ y $P_{\theta_1}$.

  4. El test de máxima potencia entre todos los de nivel de significación
     0 es:
     
     \[
     \varphi_0(\tilde X) = \twopartdef
     {1}{f_0(\tilde X) = 0}
     {0}{f_0(\tilde X) > 0}
     \]

****** Demostración
******* Punto 1
Dado otro test $\varphi'$, como toma valores en $[0,1]$ tenemos que:

\[
(\varphi-\varphi')(f_1-kf_0) \geq 0
\]

Podemos entonces integrar para tener:

\[
\int (\varphi(x)-\varphi'(x))(f_1(x)-kf_0(x)) \;dx \geq 0
\]

Conociendo las funciones de potencia $\int \varphi f_i = \beta_\varphi(\theta_i)$ y $\int \varphi' f_i = \beta_{\varphi'}(\theta_i)$ , 
tenemos:

\[
\beta_{\varphi}(\theta_1) - \beta_{\varphi'}(\theta_1) +
k(\beta_{\varphi'}(\theta_0) - \beta_{\varphi}(\theta_0))
\geq 0\]

Usando ahora que $\beta_{\varphi'}(\theta_0) \leq \beta_\varphi(\theta_0) = \alpha$, tenemos que $\beta_\varphi(\theta_1) \geq \beta_{\varphi'}(\theta_1)$.
Así, nuestro test es el más potente uniformemente.

******* Punto 3
Cuando es de máxima potencia, se da el caso de igualdad en la última
ecuación, que lleva el caso de igualdad a la integral. Como es una
integral de términos positivos, debe ser distinta de cero sólo en
un conjunto de medida nula.

**** TODO Descripción mediante p-valores
**** Test de la razón de verosimilitudes
***** Test de la razón de verosimilitudes
Sea $(X_1,\dots,X_n) \in \chi^n$ una muestra aleatoria simple de $X \leadsto \{P_\theta \mid \theta \in \Theta_0 \cup \Theta_1\}$.
El test de razón de verosimilitudes para el problema de contraste con
$H_0 : \theta \in \Theta_0$ y $H_1 : \theta \in \Theta_1$; se define como:

\[
\varphi(X_1,\dots,X_n) = \twopartdef
{1}{\lambda(X_1,\dots,X_n) < c}
{0}{\lambda(X_1,\dots,X_n) \geq c}
\]

donde se define:

\[\lambda(x_1,\dots,x_n) = \frac
{\sup_{\theta \in \Theta_0} L_{x_1,\dots,x_n}(\theta)}
{\sup_{\theta \in \Theta} L_{x_1,\dots,x_n}(\theta)}
\]

siendo $L$ la función de verosimilitud y $c \in (0,1]$ una constante que se 
determina imponiendo el tamaño o nivel de significación requerido.

**** Dualidad entre tests de hipótesis y regiones de confianza
***** Dualidad
Sea $X \leadsto \{P_\theta \mid \theta \in \Theta\}$. Para cada $\theta_0 \in \Theta$ consideramos un conjunto $A(\theta_0) \subseteq \chi^n$
y para cada relización se define:

\[
\varphi_{\theta_0}(x_1,\dots,x_n) =
\left\{\begin{array}{ll} 
1 & \mbox{if } (x_1,\dots,x_n) \notin A(\theta_0) \\
0 & \mbox{if } (x_1,\dots,x_n) \in A(\theta_0) \\
\end{array} 
\right.
\]

Y con esto se define:

\[
S(x_1,\dots,x_n) = \{\theta\in \Theta \mid (x_1,\dots,x_n) \in A(\theta)\}
\]

Cada uno de los tests $\varphi_{\theta_0}$ tiene nivel de significación $\alpha$ ssi $S$ es una
región de confianza para $\theta$ a nivel de confianza $1-\alpha$.

**** Ejemplos
***** Contrastes sobre la media de una normal con varianza conocida
****** Hipótesis: valor de la media
Si tomamos $H_0:\mu=\mu_0$ y $H_1:\mu\neq\mu_0$, podemos crear un [[*Test de la razón de verosimilitudes][TRV]] como:

\[
\varphi(X_1,\dots,X_n) =
\left\{\begin{array}{ll} 
1 & \mbox{if } \left| \frac{\overline{X}-\mu_0}{\sigma_0/\sqrt{n}} \right| > z_{\alpha/2} \\
0 & \mbox{if } \left| \frac{\overline{X}-\mu_0}{\sigma_0/\sqrt{n}} \right| \leq z_{\alpha/2} \\
\end{array} 
\right.
\]

******* Cálculo
Sabiendo que la función de verosimilitud es:

\[
L_{x_1,\dots,x_n}(\mu) = 
\frac{1}{(\sigma_0^2)^{n/2}(2\pi)^{n/2}}
e^{-\sum_{i=1}^n (x_i-\mu)^2/2\sigma_0^2}
\]

Calculamos el test:

\[
\lambda = 
\frac{\sup_{\mu = \mu_0} L(\mu)}{\sup_{\mu\in\mathbb{R}} L(\mu)} = 
\frac{L(\mu_0)}{L(\overline{x})} =
\exp\left\{\frac{-n(\overline{x}-\mu_0)^2}{2\sigma^2_0}\right\}
\]

Y podemos tomar raíces para tener otro test equivalente que, al
seguir una distribución normal, podemos ajustar para tener el
parámetro $\alpha$ pedido.

****** Hipótesis: media menor que un valor
Si tomamos $H_0 : \mu \leq \mu_0$ y $H_1 : \mu > \mu_0$, podemos crear un TRV como:

\[
\varphi(X_1,\dots,X_n) = 
\left\{\begin{array}{ll} 
1 & \mbox{if  } \frac{\overline{X}-\mu_0}{\sigma_0/\sqrt{n}} > z_\alpha \\
0 & \mbox{if  } \frac{\overline{X}-\mu_0}{\sigma_0/\sqrt{n}} \leq z_\alpha \\
\end{array} 
\right.
\]

******* Cálculo
Si en este caso calculamos la $\lambda$ tenemos que:

\[
\lambda(x_1,\dots,x_n) = 
\frac{\sup_{\mu\leq\mu_0} L(\mu)}{L(\overline{x})} =
\left\{\begin{array}{ll} 
1 & \mbox{if } \frac{\overline{x}-\mu_0}{\sigma_0/\sqrt{n}} \leq 0 \\
\frac{L(\mu_0)}{L(\overline{x})} 
& \mbox{if } \frac{\overline{x}-\mu_0}{\sigma_0/\sqrt{n}} \geq 0 \\
\end{array} 
\right.
\]

****** Hipótesis: media mayor que un valor
Si tomamos $H_0 : \mu \geq \mu_0$ y $H_1 : \mu < \mu_0$, podemos crear un TRV como:

\[
\varphi(x_1,\dots,x_n) = 
\left\{\begin{array}{ll} 
1 & \mbox{if } \frac{\overline{x}-\mu_0}{\sigma_0/\sqrt{n}} < z_{1-\alpha} \\
0 & \mbox{if } \frac{\overline{x}-\mu_0}{\sigma_0/\sqrt{n}} \geq z_{1-\alpha}
\end{array} 
\right.
\]

******* Cálculo
Si en este caso calculamos la $\lambda$ tenemos que:

\[
\lambda(x_1,\dots,x_n) 
=
\frac{\sup_{\mu\geq\mu_0} L(\mu)}{L(\overline{x})}
=
\left\{\begin{array}{ll} 
1& \mbox{if } \overline{x} \geq \mu_0 \\
\frac{L(\mu_0)}{L(\overline{x})}& \mbox{if } \overline{x} \leq \mu_0
\end{array} 
\right.
\]

Dándonos un test:

\[
\varphi(x_1,\dots,x_n) = 
\left\{\begin{array}{ll} 
1 & \mbox{if } \lambda(x_1,\dots,x_n) < c \\
0 & \mbox{if } \lambda(x_1,\dots,x_n) \geq c
\end{array} 
\right.
=
\left\{\begin{array}{ll} 
0 & \mbox{if } \overline{x} \geq \mu_0 \\
1 & \mbox{if } \frac{L(\mu_0)}{L(\overline x)} < c \\
0 & \mbox{if } \frac{L(\mu_0)}{L(\overline x)} \geq c
\end{array} 
\right.
\]

Las dos primeras condiciones colapsan cuando tomamos la raíz y
comparamos con ella:

\[
\varphi(x_1,\dots,x_n) = 
\left\{\begin{array}{ll} 
1 & \mbox{if } \frac{\overline{x}-\mu_0}{\sigma_0/\sqrt{n}} < c \\
0 & \mbox{if } \frac{\overline{x}-\mu_0}{\sigma_0/\sqrt{n}} \geq \min(0,c)
\end{array} 
\right.
\]

Ahora ajustamos la $c$ para que nos dé la significancia $\alpha$:

\[
\alpha = 
\sup_{\mu \geq \mu_0} 
P\left( \frac{\overline{X}-\mu_0}{\sigma_0/\sqrt{n}} < c' \right)
=
\sup_{\mu \geq \mu_0}
P\left( \frac{\overline{X}-\mu}{\sigma_0/\sqrt{n}} < \frac{\mu_0-\mu}{\sigma_0/\sqrt{n}} + c' \right)
\]

Tomamos entonces como $c' = z_{1 - \alpha}$. Nótese que es negativo.

***** Contrastes sobre la varianza de una normal con media conocida
****** Hipótesis: valor de la varianza
Si tomamos $H_0 : \sigma^2 = \sigma_0^2$ y $H_1 : \sigma^2 \neq \sigma_0^2$, creamos un TRV como:

\[
\varphi(x_1,\dots,x_n) = 
\left\{\begin{array}{ll} 
1& \mbox{if } \frac{\sum^n_{i=1} (x_i-\mu_0)^2}{\sigma_0^2} < \chi^2_{n;1-\alpha/2} 
   \mbox{ ó } \frac{\sum^n_{i=1} (x_i-\mu_0)^2}{\sigma_0^2} > \chi^2_{n;\alpha/2} \\
0& \mbox{if } \chi^2_{n;1-\alpha/2} \leq \frac{\sum^n_{i=1} (x_i-\mu_0)^2}{\sigma_0^2} \leq \chi^2_{n;\alpha/2}
\end{array} 
\right.
\]

******* Cálculo
Sabiendo que la función de verosimilitud es:

\[
L_{x_1,\dots,x_n}(\sigma) = 
\frac{1}{(\sigma^2)^{n/2}(2\pi)^{n/2}}
e^{-\sum_{i=1}^n (x_i-\mu)^2/2\sigma^2}
\]

Usamos que el estimador máximo verosímil de $\sigma^2$ es:

\[
\widehat\sigma^2 = \frac{\sum_{i=1}^n (x_i-\mu_0)^2}{n}
\]

Calculamos el test:

\[
\lambda = 
\frac{\sup_{\sigma = \sigma_0} L(\sigma)}{\sup_{\sigma\in\mathbb{R}} L(\sigma)} = 
\frac{L(\sigma_0)}{L(\widehat\sigma)} =
\left(\frac{\widehat\sigma^2}{\sigma_0^2}\right)^{n/2}
\exp\left\{
\frac{-n\widehat\sigma_0^2}{2\sigma_0^2}+\frac{n}{2}
\right\}
\]

La función $xe^{-x}$ tiene un máximo antes de ir hacia $-\infty$ por ambos
lados. Así, podemos escribir:

\[
\varphi(x_1,\dots,x_n) = 
\left\{\begin{array}{ll} 
1& \mbox{if } \frac{\sum^n_{i=1} (x_i-\mu_0)^2}{\sigma_0^2} < c_1 
   \mbox{ ó } \frac{\sum^n_{i=1} (x_i-\mu_0)^2}{\sigma_0^2} > c_2 \\
0& \mbox{if } c_1 \leq \frac{\sum^n_{i=1} (x_i-\mu_0)^2}{\sigma_0^2} \leq c_2
\end{array} 
\right.
\]

Nótese que sigue una distribución $\chi^2(n)$ como suma de $n$ normales.

***** Contrastes sobre la varianza de una normal con media desconocida
Se tendrá como estimador máximo verosímil a:

\[
\widehat\sigma^2 = \frac{\sum_{i=1}^n (x_i-\overline{x})^2}{n}
\]

*** 7. Teoría general de modelos lineales
**** Modelo lineal general y modelo de Gauss Markov
***** Modelo lineal general
El modelo general lineal queda descrito por:

\[\mathbf{Y = X\beta + \varepsilon}\]

****** Vector observable
$Y = (Y_1,\dots,Y_n)$ es un vector aleatorio observable.

****** Matriz de diseño
Una matriz conocida $X$ de dimensión $n \times k$, cuyo rango determina el 
rango del modelo.

****** Vector de efectos
Un vector desconocido $\beta = (\beta_1,\dots,\beta_k)$.

****** Vector de errores
Un vector aleatorio no observable $\varepsilon = (\varepsilon_1,\dots,\varepsilon_n)$ representando el 
error entre $Y$ y $X\beta$.

***** Modelo de Gauss-Markov
Modelo lineal donde las componentes del vector de errores son variables
aleatorias de segundo orden, centradas, homocedásticas (igual varianza)
e incorreladas:

  - $E[\varepsilon_i] = 0$
  - $E[\varepsilon_i^2] = \sigma^2$
  - $E[\varepsilon_i\varepsilon_j] = 0$

****** Enunciado vectorial
Las condiciones sobre el vector de errores equivalen a exigir:

  - $E[\varepsilon] = 0$
  - $E[\varepsilon\varepsilon^T] = \sigma^2 I_{n \times n}$

****** Objetivo del modelo
Inferir $\beta$ y $\sigma^2$ a partir de observaciones del vector $Y$.

**** Estimación de mínimos cuadrados del vector de efectos
***** Modelo
En el modelo de Gauss-Markov queremos minimizar la suma de
cuadrados de los errores:

\[S^2(\beta) = 
\sum^n_{i=1} \varepsilon^2_i =
\|Y - X\beta\|^2\]

****** Minimización
Para minimizarlo, calculamos la derivada:

\[\frac{\partial}{\partial \beta_h} S^2(\beta) = 
-2 x_{ih} \sum^n_{i=1} \left(
Y_i - \sum^k_{j=1} x_{ij}\beta_j
\right) = 0
\]

Y obtenemos las ecuaciones normales siguientes:

\[
\sum^n_{i=1} Y_i x_{ih} = \sum^n_{i=1}\sum^k_{j=1} x_{ij}x_{ih}\beta_j
\]

Que pueden expresarse matricialmente como:

\[X^TY = (X^TX)\beta\]

***** Estimador de mínimos cuadrados de beta
Llamamos $\widehat\beta$ al estimador de mínimos cuadrados de $\beta$.

  - Existencia: existe al menos un estimador de mínimos cuadrados de $\beta$.
  - Unicidad: garantizada cuando el modelo es de rango máximo por tenerse
    la solución \[\widehat\beta(Y) = (X^TX)^{-1}X^TY\].

**** Funciones estimables
***** Función lineal estimable
Una $\psi(\beta) = a_1\beta_1 + \dots + a_k\beta_k$ es estimable si admite un estimador insesgado,
lineal en las componentes de $Y$. Es decir:

\[\exists \widehat\psi(Y) = c_1Y_1 + \dots + c_nY_n\]

tal que $E[\widehat\psi(Y)] = \psi(\beta)$.

***** Teorema de Gauss-Markov
Si $\psi(\beta) = a_1\beta_1 + \dots + a_k\beta_k$ es estimable, admite un único UMVUE. 
Dicho estimador es:

\[\widehat\psi(Y) = a_1\widehat\beta_1(Y) + \dots + a_k\widehat\beta_k(Y) \]

Donde $\widehat{\beta}(Y)$ es un estimador de mínimos cuadrados de $\beta$.

****** TODO Demostración

***** Propiedades del estimador de mínimos cuadrados en modelos de rango máximo
Sea $\widehat\beta(Y) = (X^TX)^{-1}X^TY$ el estimador de mínimos cuadrados en un modelo 
de rango máximo.

  1. $\widehat\beta_j(Y)$ es el estimador lineal insesgado de mínima varianza de $\beta_j$.
  2. Las varianzas y covarianzas vienen dadas: $Cov(\widehat\beta(Y)) = \sigma^2(X^TX)^{-1}$.
  3. Toda función lineal de las componentes de $\beta$ es estimable con 
     estimador lineal insesgado de mínima varianza
     $\widehat\psi(Y) = a_1\widehat\beta_1(Y) + \dots + a_k\widehat\beta_k(Y)$.

****** TODO Demostración

**** Modelo estimado
***** Modelo estimado
Siendo $\widehat\beta$ el estimador de mínimos cuadrados, llamamos:

  - Modelo estimado: $\widehat Y = X\widehat\beta$
  - Residuos mínimo-cuadráticos: $R = Y - X\widehat\beta$

***** Propiedades del modelo estimado
El modelo estimado cumple:

  1. $\widehat Y_i$ es el estimador lineal insesgado de mínima varianza de $E[Y_i]$.
  2. Los residuos son centrados $E[R_i] = 0$.
  3. El vector de residuos es ortogonal al vector estimado:

     \[X^TR = 0,\quad \widehat{Y}^TR = 0\]

***** Varianza residual
Siendo $r$ el rango de $X$, la *varianza residual* es un estimador
insesgado de $\sigma^2$:

\[
S^2_R = \frac{1}{n-r}\sum_{i=1}^n R_i^2 = \frac{1}{n-r}\|Y-X\widehat\beta\|^2
\]

**** Inferencia bajo hipótesis de normalidad
***** Hipótesis de normalidad
La hipótesis de normalidad asume que los errores se distribuyen
bajo una distribución normal:

\[
Y_i = \sum_{j=1}^k x_{ij}\beta_j + \varepsilon_i 
\leadsto 
{\cal N}\left(\sum_{j=1}^k x_{ij}\beta_j, \sigma^2 \right)
\]

Para $Y_1,\dots,Y_n$ independientes.

****** Equivalentemente
Podemos expresar los errores como:

\[\varepsilon \leadsto {\cal N}(0,\sigma^2)\]

***** Función de máxima verosimilitud
La función de máxima verosimilitud bajo la hipótesis de normalidad queda
como:

\[
L_y(\beta,\sigma^2) = 
\frac{1}{(2\pi)^{n/2}\sigma^n}
\exp\left\{
-\frac{\sum_{i=1}^n(y_i - \sum_{j=1}^k x_{ij}\beta_j)^2}{2\sigma^2}
\right\}
\]

***** Estimadores máximo verosímiles de efectos
Los estimadores máximo verosímiles de $\beta$ son $\widehat\beta$, estimadores de mínimos
cuadrados.

****** TODO Demostración

***** Estimador máximo verosímil de la varianza
El estimador máximo verosímil de la varianza es:

\[
\widehat\sigma^2 = \frac{1}{n}\sum_{i=1}^n R_i^2 = \frac{n-r}{n}S^2_R
\]

*** 8. Inferencia Bayesiana
# ##
# Este capítulo se ha escrito siguiendo los apuntes de estadística
# de Andrés Herrera, Nuria Rodríguez, Javier Poyatos, María del Mar Ruiz y 
# Juan Luis Suárez.
#
# Pueden consultarse los apuntes originales en:
#   https://github.com/andreshp/math-notes/tree/master/StatisticalInference
# ##

**** 8.1. Introducción
***** Ley de la probabilidad total
La ley de la probabilidad total establece, para $A_i$ una partición del
espacio de sucesos:

\[
P(B) = \sum_{i=1}^n P(B|A_i)P(A_i)
\]

***** Teorema de Bayes
Para un espacio de probabilidad $(\Omega,{\cal A},P)$, si tenemos una partición dada
por $A_1,\dots,A_n$ con probabilidad no nula:

\[P(A_i|B) 
=
\frac{P(A_i \cap B)}{P(B)} 
= 
\frac{P(B|A_i)P(A_i)}{P(B)}
\]

***** Distribución a priori
Sea $X$ variable aleatoria con distribución $f(x|\theta)$, con $\theta \in \Theta$. A una 
distribución $\pi(\theta)$ establecida con información previa sobre $\theta$ se le
llama *distribución a priori*.

***** Distribución condicionada
Dada una muestra $\tilde{X} = (X_1,\dots,X_n)$ y una distribución a priori $\pi(\theta)$,
tenemos una distribución conjunta con función de densidad:

\[
f(\tilde x,\theta) = f(\tilde x|\theta)\pi(\theta)
\]

***** Distribución marginal
La distribución marginal de $\tilde X$ la definimos como:

\[
m(\tilde x) 
= 
\int_{\Omega} f(\tilde x,\theta) d\theta
=
\int_{\Omega} f(\tilde x|\theta) \pi(\theta) d\theta
\]

***** Distribución a posteriori
Dada una realización de la muestra y una distribución a priori, definimos
una distribución a posteriori como:

\[
\pi(\theta|\tilde x) = 
\frac{f(\tilde x|\theta)\pi(\theta)}{m(\tilde x)} =
\frac{f(\tilde x|\theta)\pi(\theta)}{\int_\Omega f(\tilde x|\theta)\pi(\theta) d\theta}
\]

**** 8.2. Estadística clásica
Se destacan las siguientes diferencias con la estadística clásica.
En la estadística clásica:

  1. La probabilidad se limita a sucesos con frecuencias relativas.
  2. El parámetro $\theta$ es fijo, completamente desconocido.
  3. Se usan estimadores de máxima verosimilitud o insesgados.
  4. Los tests de hipótesis se construyen fijando un tamaño $\alpha$.

Mientras que en la estadística bayesiana:
  
  1. La probabilidad se puede establecer previa a cualquier suceso.
  2. El parámetro $\theta$ es una variable aleatoria.
  3. El método de muestreo es irrelevante.
  4. Podemos calcular la probabilidad de que una hipótesis sea cierta.

**** 8.3. Familias conjugadas
***** Familia conjugada
Sea ${\cal F} = \{\pi_i(\theta) \mid i \in I\}$ una familia de distribuciones a priori. Se llama
*conjugada* respecto a una familia de densidades $P = \{f(x|\theta) \mid \theta \in \Theta\}$ si
para cada $\pi(\theta) \in {\cal F}$ y $f(x\mid \theta) \in P$, se tiene que $\pi(\theta\mid \tilde x) \in {\cal F}$.

***** Lema de caracterización de familias conjugadas
Para $\pi(\theta),\Pi(\theta) \in {\cal F}$, equivalen:

  1. $f(\tilde x|\theta)\pi(\theta) \propto \Pi(\theta)$
  2. $\pi(\theta|\tilde x) = \Pi(\theta)$

****** Demostración
******* Primera implicación
Por definición:

\[
\pi(\theta|\tilde x) 
=
\frac{f(\tilde x|\theta)\pi(\theta)}{\int_\Omega f(\tilde x|\theta)\pi(\theta) d\theta}
=
\frac{M\Pi(\theta)}{M \int_\Omega \Pi(\theta) d\theta}
=
\Pi(\theta)
\]

Usando que $\int_\Omega \Pi = 1$ por ser distribución.

******* Segunda implicación
Por definición:

\[
f(\tilde x|\theta)\pi(\theta) = \Pi(\theta)\int_\Omega f(\tilde x|\theta)\pi(\theta) d\theta
\]

***** Caracterización de familias conjugadas
Una familia de distribuciones a priori ${\cal F}$ es conjugada respecto a ${\cal P}$ ssi
el producto de cualesquiera dos distribuciones de ambas familias vuelve
a ser una distribución de la familia de distribuciones a priori, salvo
alguna constante.

\[\forall f \in {\cal P}, \pi \in{\cal F}: \exists k:\quad 
kf(x|\theta)\pi(\theta) \in {\cal F}\]

***** Ejemplos de familias conjugadas
****** Beta para Bernoulli
La familia de distribuciones Beta es una familia conjugada para:

  - distribuciones de Bernoulli.
  - distribuciones binomiales.
  - distribuciones binomiales negativas.

Se tiene:

  - $X \leadsto B(n,\theta)$
  - $\theta \leadsto \beta(p,q)$
  - $\theta|x \leadsto \beta(x+p,n-x+q)$

****** Gamma para Poisson
La familia de distribuciones Gamma es una familia conjugada para
distribuciones de Poisson.

Se tiene:

  - $X\leadsto Poi(\theta)$
  - $\theta \leadsto \Gamma(\alpha,\beta)$
  - $\theta|\tilde x \leadsto \Gamma(\sum x_i + \alpha, n + \beta)$

****** Normales para normales con varianza conocida
La familia de distribuciones normales es conjugada para las 
distribuciones normales de varianza conocida.

Se tiene:

  - $X \leadsto {\cal N}(\mu,\sigma^2)$
  - $\mu \leadsto {\cal N}(\eta,\tau)$
  - $\mu|\tilde x \leadsto {\cal N}\left(\frac{n\overline{x}\tau^2+\sigma^2\eta}{n\tau^2+\sigma^2}, \frac{\sigma^2\tau^2}{n\tau^2+\sigma^2}\right)$

****** Dirichlet para multinomiales
La familia de distribuciones de Dirichlet es conjugada para la
familia de distribuciones multinomiales.

Se tiene:

  - $X_1,\dots,X_n \leadsto Multi(\theta_1,\dots,\theta_k)$
  - $\theta_1,\dots,\theta_k \leadsto Dir(\alpha_1,\dots,\alpha_k)$
  - $\theta_1,\dots,\theta_n|x_1,\dots,x_n \leadsto Dir(x_1+\alpha_1,\dots,x_k+\alpha_k)$

**** 8.4. Distribuciones objetivas
***** Distribución de Jeffreys
Para una familia $\{f(x|\theta) \mid \theta\in\Theta\}$, la distribución de Jeffreys se define 
como:

\[\pi^J(\theta) \propto \sqrt{{\cal I}_X(\theta)}\]

para la información de Fisher.

**** 8.5. Convergencia de distribuciones a posteriori
***** Convergencia en un espacio paramétrico discreto
Sea $\Theta = \{\theta_1,\dots,\theta_k\}$, cuando el tamaño de la muestra diverge, la distribución
a posteriori degenera en $\theta_0$, el valor verdadero del parámetro.

\[
\pi(\theta\mid X_1,\dots,X_n) 
\overset{P_{\theta_0}}{\underset{n \to \infty}\longrightarrow} \theta_0
\]

Nótese que los $\theta_i$ deben generar distribuciones distintas para aplicar
este resultado.

****** Demostración
Dada una distribución a priori $\pi$, llamamos $\pi(\theta_j) = p_j \in [0,1]$. Llamamos
$\theta_t$ al verdadero parámetro, y tomamos $X_1,\dots,X_n$ con la distribución
dada por $f(x|\theta_t)$.

\[
\pi(\theta_i|X_1,\dots,X_n)
=
\frac
{\displaystyle p_i\prod_{j=1}^n f(X_j|\theta_i)}
{\displaystyle \sum_{r=1}^k\left(\prod_{j=1}^n f(X_j|\theta_r) \right) p_r}
\]

Si multiplicamos por $\prod_{j=1}^n f(X_j|\theta_t)$ tenemos:

\[
\pi(\theta_i|X_1,\dots,X_n)
=
\frac
{\displaystyle p_i\prod_{j=1}^n \frac{f(X_j|\theta_i)}{f(X_j|\theta_t)}}
{\displaystyle \sum_{r=1}^k\left(
\prod_{j=1}^n \frac{f(X_j|\theta_r)}{f(X_j|\theta_t)}
\right) p_r}
\]

Tomando logaritmos estudiamos las variables aleatorias $Z_j = \log\frac{f(X_j|\theta_i)}{f(X_j|\theta_t)}$,
que son i.i.d. y por la Ley fuerte de los grandes números, tenemos que
converge casi seguramente respecto a la probabilidad que define $\theta_t$:

\[
\frac{1}{n}\sum_{j=1}^n \log\frac{f(X_j|\theta_i)}{f(X_j|\theta_t)}
\longrightarrow
\mathbb{E}\left[\log \frac{f(X_j|\theta_i)}{f(X_j|\theta_t)} \right]
\]

Que además sabemos (no trivialmente) que es negativo. Tenemos entonces
por continuidad del logaritmo que:

\[
\prod_{j=1}^n \frac{f(X_j|\theta_i)}{f(X_j|\theta_t)}
\longrightarrow
0
\]

Aplicando esto a la probabilidad a posteriori tenemos que sólo converge
a uno en el valor $\theta_t$ y converge a cero en todos los demás.

***** Nota: Influencia de la distribución a priori
Nótese que la distribución a priori ha sido independiente de la 
convergencia a la distribución a posteriori degenerada.

***** Nota: Estimadores bayesianos
Los modelos bayesianos asignan probabilidad 1 a la hipótesis correcta
cuando el tamaño de la muestra diverge.

**** 8.6. Test de hipóesis bayesianos
***** Probabilidad a posteriori de un modelo
Dados dos modelos $M_1 : \{f_{\theta_1}(x), \pi(\theta_1|M_1), \pi(M_1)\}$ y $M_2 : \{f_{\theta_2}(x), \pi(\theta_2|M_2), \pi(M_2)\}$,
la probabilidad de que se cumpla el primero condicionada a una muestra es:

\[
\pi(M_1|x) = \frac{\pi(M_1)m(x|M_1)}{\pi(M_1)m(x|M_1) + \pi(M_2)m(x|M_2)}
\]

****** Modelos
Cada modelo $M : \{f(x|\theta,M), \pi(\theta|M), \pi(M)\}$ viene dado por:

  1. Una función de distribución condicionada a cada parámetro $\theta$.
  2. Una probabilidad para cada parámetro, condicionada al modelo.
  3. Probabilidad de que se cumpla el modelo.

Necesitamos $\pi(M_1)+\pi(M_2) = 1$ en el caso de comparar esos dos modelos.

***** Factor de Bayes
Dados dos modelos $M_1 : \{f_{\theta_1}(x), \pi(\theta_1|M_1), \pi(M_1)\}$ y $M_2 : \{f_{\theta_2}(x), \pi(\theta_2|M_2), \pi(M_2)\}$,
Definimos el factor de Bayes como:

\[
B_{21}(x) = \frac{m(x|M_2)}{m(x|M_1)}
\]

cociente entre distribuciones marginales.

Cuanto más alto es, más baja es la probabilidad a posteriori del modelo $M_1$.

***** Método de Leamer: motivación
Si usamos distribuciones impropias para realizar tests de hipótesis y
las multiplicamos por coeficientes para que sean integrables, el factor
de Bayes se vería afectado arbitrariamente por estos coeficientes.

***** Método de Leamer: muestras de entrenamiento
Una *muestra de entrenamiento* $\tilde x_1 \subset \tilde x$ es una sublista de la muestra original.
Se llama *propia* si $0 < m(\tilde x_1 | M) < \infty$. Se llama *minimal* si es propia y
ninguna sublista suya lo es.

***** Método de Leamer
Dada una muestra de entrenamiento, sabemos que $\pi(\theta|M)f(\tilde x_1|\theta,M)$
integrará y podremos usarlo como distribución a priori.

Interesa utilizar una muestra minimal para que se pierdan el menor
número de elementos en la muestra para el test de hipótesis.

**** TODO 8.7. Probabilidades subjetivas
*** Ejercicios
**** Tema 1. Introducción a la inferencia estadística
***** Ejercicio 1
#+begin_statement
Sea $(X_1,\dots,X_n)$ una muestra aleatoria simple de una variable $X$. 
Dar el espacio muestral y calcular la función masa de probabilidad 
de $(X_1,\dots,X_n)$ en cada uno de los siguientes casos:

  1. $X \longrightarrow \{{\cal B}(k_0,p); p \in (0,1)\}$ binomial
  2. $X \longrightarrow \{{\cal P}(\lambda); \lambda\in\mathbb{R}^+\}$ Poisson
#+end_statement

****** Punto 1
El espacio muestral es $\{0,1,\dots,k_0\}^n$, una palabra $k_0\text{-aria}$ de $n$ letras. 
Usando independencia:

\[P(x_1,\dots,x_n) = \prod P(x_i) 
= \prod_{i=1}^n \left({k_0 \choose x_i} p^{x_i}(1-p)^{k_0-x_i} \right)\]
****** Punto 2
El espacio muestral es $\mathbb{N}^n$, palabras en los naturales.
Usando independencia:

\[P(x_1,\dots,x_n) = \prod P(x_i) = \prod_{i=0}^n e^{-\lambda}\frac{\lambda^{x_i}}{x_i!}\]

***** Ejercicio 2
#+begin_statement
Sea $(X_1,\dots,X_n)$ una muestra aleatoria simple de una variable $X$. Dar el espacio
muestral y calcular la función masa de probabilidad de $(X_1,\dots,X_n)$ en cada uno de
los siguientes casos:

  1. $X \longrightarrow \{U(a,b); a,b\in\mathbb{R}; a < b\}$ uniforme
  2. $X\longrightarrow \{{\cal N}(\mu,\sigma^2)\}$ normal
#+end_statement
****** Punto 1
El espacio muestral aquí es $[a,b]^n$, donde por independencia tengo como función
de densidad:

\[f(x_1,\dots,x_n) = \prod f(x_i) = \left(\frac{1}{b-a}\right)^n\]

****** Punto 2
El espacio muestral es $\mathbb{R}^n$, siendo la función de densidad:

\[f(x_1,\dots,x_n) = 
\prod_{i=0}^n \frac{1}{\sigma\sqrt{2\pi}} 
e^{-\frac{1}{2}\left(\frac{x_i-\mu}{\sigma}\right)^2}\]

***** Ejercicio 4
#+begin_statement
Se dispone de una muestra aleatoria simple de tamaño 40 de una
distribución exponencial de media 3, ¿cuál es la probabilidad de que
los valores de la función de distribución muestral y la teórica, en
$x=1$, difieran menos de 0.01?  Aproximadamente, ¿cuál debe ser el
tamaño muestral para que dicha probabilidad sea como mínimo 0.98?
#+end_statement

****** Probabilidad de que difieran
Tenemos que $nF^\ast_X(1) \leadsto {\cal B}(n,F(1))$, luego podemos calcular la probabilidad
como:

\[\begin{aligned}
P\Big( F(1) - 0.01 < F^\ast(1) < F(1) + 0.01 \Big) = \\
P\Big( 10.93 < 40F^\ast(1) < 11.73 \Big) = \\
P\Big(10 < 40F^\ast(1) < 12) =\\
P\Big(11 = 40F^\ast(1)) =\\
{40 \choose 11} F(1)^{11}(1-F(1))^{40-11} \approx\\
0.1318
\end{aligned}\]

Sabiendo que $F(1) = 1 - e^{-1/3} \approx 0.283$ y que $F^\ast$ es variable discreta.

******* Cálculos
#+BEGIN_SRC R :results output
f1 = 1-exp(-1/3)
f1
n = 40
n*(f1 + 0.01)
n*(f1 - 0.01)
dbinom(11,n,0.3)
#+END_SRC

#+RESULTS:
: [1] 0.2834687
: [1] 11.73875
: [1] 10.93875
: [1] 0.1318644

****** TODO Tamaño muestral
Llamamos $\sqrt{\frac{1}{n}F(1)(1-F(1))} = \sigma_n$, y esta vez aplicamos el Teorema 
Central del Límite para tener que:

\[\frac{F^\ast(1) - F(1)}{\sigma_n} \leadsto {\cal N}(0,1)\]

Lo que buscamos es que:

\[\begin{aligned}
P\Big( -0.01 < F^\ast(1)-F(1) < 0.01 \Big) > 0.98 \\
P\Big( \frac{-0.01}{\sigma_n} < \frac{F^\ast(1)-F(1)}{\sigma_n} < \frac{0.01}{\sigma_n} \Big) > 0.98 \\
\end{aligned}\]

Dada $\Phi$ función de distribución de la normal tipificada, 
tenemos que:

\[\begin{aligned}
\Phi\left(\frac{0.01}{\sigma_n}\right) -
\Phi\left(\frac{-0.01}{\sigma_n}\right) > 0.98 \\
2\Phi\left(\frac{0.01}{\sigma_n}\right) > 0.98 +1 \\
1 -\Phi\left(\frac{0.01}{\sigma_n}\right) < 0.01
\end{aligned}\]

Usando la tabla de la normal, tenemos:

\[\frac{0.01}{\sigma_n} \geq 2.33\]

Desde donde calculamos:

\[n = 10978\]

# Esto debe estar mal

******* Cálculos
#+BEGIN_SRC R :results output
# Lookup on the normal distribution table
qnorm(1-0.01)
#+END_SRC

#+RESULTS:
: [1] 2.326348

***** Ejercicio 7
#+begin_statement
Dada una muestra aleatoria simple $(X_1,\dots,X_n)$ de una variable $X$, obtener
la distribución en el muestreo de $\overline{X}$ en los casos:

  1. $X \leadsto B(1,p)$
  2. $X\leadsto P(\lambda)$
  3. $X \leadsto exp(\lambda)$
#+end_statement

****** Punto 1
Por independencia y suma de binomiales:

\[
\overline{X} \leadsto \frac{1}{n}B(n,p)
\]

Nótese que deja de ser una binomial.

****** Punto 2
Por independencia y suma de Poisson:

\[
\overline{X} \leadsto \frac{1}{n}Poi(n\lambda)
\]

****** Punto 3
Por independencia y suma de Gammas:

\[
\overline{X} = \frac{1}{n}\Gamma(n,\lambda)
\]

***** Ejercicio 10
Desde la distribución de la estimación de la normal.

**** Tema 2. Distribuciones en el muestreo de poblaciones normales
***** Ejercicio 1
#+begin_statement
Se toma una muestra aleatoria simple de tamaño $5$ de una variable aleatoria
con distribución ${\cal N}(2.5, 36)$. Calcular:

  1. Probabilidad de que la cuasivarianza muestral esté comprendida entre
     $1.863$ y $2.674$.
  2. Probabilidad de que la media muestral esté comprendida entre $1.3$ y $3.5$,
     supuesto que la cuasivarianza muestral está entre $30$ y $40$.
#+end_statement

****** Probabilidad de la Cuasivarianza
Buscamos:

\[\begin{aligned}
P\Big(1.863 \leq S^2 \leq 2.674 \Big) &\leq 
P\Big(\frac{n-1}{\sigma^2}1.863 \leq \frac{n-1}{\sigma^2}S^2 \leq \frac{n-1}{\sigma^2}2.674 \Big)
\end{aligned}\]

Y sabiendo que $\frac{n-1}{\sigma^2}S^2 \leadsto \chi^2(n-1)$, sea $\phi$ la función de distribución para
tener que la probabilidad será:

\[\phi\left(\frac{n-1}{\sigma^2}2.674\right) - 
\phi\left(\frac{n-1}{\sigma^2}1.863\right) =
0.010 - 0.005 = 0.005
\]

Consultando la tabla de Poisson.

******* Cálculos
#+BEGIN_SRC R
n = 5
s2 = 36
pchisq((n-1)/s2 * 2.674, df=n-1) - pchisq((n-1)/s2 * 1.863, df=n-1)
#+END_SRC

#+RESULTS:
: 0.00499959549303851

****** Probabilidad de la Media Muestral
La suposición de que la cuasivarianza muestral está entre 30 y 40 no
aporta nada porque la media y ella son estadísticos independientes por
el Lema de Fisher.

Buscamos:

\[P\Big(  
1.3 \leq \overline{X} \leq 1.5
\Big) = 
P\Big(  
\frac{1.3 - \mu}{\sigma/\sqrt{n}} \leq 
\frac{\overline{X} - \mu}{\sigma/\sqrt{n}} \leq 
\frac{1.5 - \mu}{\sigma/\sqrt{n}}
\Big)
\]

Y como $\frac{\overline{X} - \mu}{\sigma/\sqrt{n}} \leadsto {\cal N}(0,1)$, siendo $\phi$ la distribución de la normal, calculamos
la probabilidad usando las tablas de la normal.

\[
\phi(-0.3726) - \phi(-0.4472) = 0.3557 - 0.3300 = 0.0257
\]

******* Cálculos
#+BEGIN_SRC R
n = 5
m = 2.5
s2 = 36
s = sqrt(36)
pnorm((1.5-m)/(s/sqrt(n))) - pnorm((1.3-m)/(s/sqrt(n)))
#+END_SRC

#+RESULTS:
: 0.0273336344978247

***** Ejercicio 3
#+begin_statement 
¿De qué tamaño mínimo habría que seleccionar una muestra de una variable
con distribución normal ${\cal N}(\mu,4)$ para poder afirmar, con probabilidad mayor
que $0.9$, que la media muestral diferirá de la poblacional menos de $0.1$?
#+end_statement

Buscamos:

\[P\Big(
\frac{-0.1}{\sigma/\sqrt{n}} \leq 
\frac{\overline{X} - \mu}{\sigma/\sqrt{n}} \leq
\frac{0.1}{\sigma/\sqrt{n}}
\Big)\]

Sabiendo que $\frac{\overline{X} - \mu}{\sigma/\sqrt{n}} \leadsto {\cal N}(0,1)$, calculamos:

\[\begin{aligned}
1 - 2\phi\left(\frac{-0.1}{\sigma/\sqrt{n}}\right) &\geq 0.9 \\
\phi\left(\frac{-0.1}{\sigma/\sqrt{n}}\right) &\leq 0.05 \\
\end{aligned}\]

Usando la tabla de la distribución, tenemos que:

\[\frac{0.1}{2/\sqrt{n}} = 1.65\]

Desde donde: $n = 1089$.

****** Cálculos
#+BEGIN_SRC R
s2 = 4
s = sqrt(s2)
q = qnorm(1-0.05)
((s*q)/0.1)^2
#+END_SRC

#+RESULTS:
: 1082.21738163816

***** Ejercicio 7
Comprobando sumas se llega a que siguen una Poisson.

**** Tema 3. Suficiencia y complitud
***** Ejercicio 1
#+begin_statement
Sea $(X_1,\dots,X_n)$ una muestra aleatoria simple de una variable $X \leadsto B(k,p)$
y sea $T(X_1,\dots,X_n) = \sum^n_{i=1} X_i$. Probar, usando la definición y aplicando el
teorema de factorización, que $T$ es suficiente para $p$.
#+end_statement

****** Usando la definición
Llamamos $S = \sum^n_{i=1} X_i$. Veremos que $P(x_1,\dots,x_n\mid S)$ no depende de $p$.
En el caso $x_1+\dots+x_n \neq S$, la probabilidad es $0$ y claramente 
independiente de $p$. En el otro caso, tenemos:

\[\begin{aligned}
P(x_1,\dots,x_n\mid S) = 
\frac{P(x_1,\dots,x_n)}{P(S)} =
\frac
{\prod {k \choose x_i} p^{x_i}(1-p)^{k-x_i}}
{{nk \choose S} p^{S}(1-p)^{nk-S}} =
\frac
{\prod {k \choose x_i}}
{{nk \choose S}}
\end{aligned}\]

Que no depende de $p$. Hemos usado que $S = \sum_{i=1}^n X_i \leadsto {\cal B}(nk,p)$ para 
calcular la probabilidad de que valga un valor concreto.

****** Usando el teorema de factorización
Factorizamos la función de densidad como:

\[
f(x_1,\dots,x_n) =
\prod_{i=1}^n {k \choose x_i} p^{x_i}(1-p)^{k-x_i} =
\left(p^{\sum x_i}(1-p)^{nk - \sum x_i}\right)
\left(\prod^{k}_{i=1} {k\choose x_i}\right)
\]

El primer factor sólo depende de los datos a través de la suma y el
segundo factor no depende de la probabilidad.

***** Ejercicio 3
#+begin_statement
Sea $(X_1,X_2,X_3)$ una muestra aleatoria simple de una variable $X \leadsto B(1,p)$.
Probar que el estadístico $X_1+2X_2+3X_3$ no es suficiente.
#+end_statement

Llamamos $S=X_1+2X_2+3X_3$. Vamos a calcular $P(1,1,0\mid S=3)$ y 
comprobaremos que depende de $p$. Nótese que puede llegarse a $S=3$ de dos
formas, como $1+2+0$ y como $0+0+3$.

\[
P(1,1,0\mid S=3) =
\frac{P(1,1,0)}{P(S=3)} =
\frac{p^2(1-p)}{p^2(1-p)+p(1-p)^2}=
p
\]

**** Tema 4. Estimación puntual. Métodos de estimación
***** Ejercicio 2
#+begin_statement
Sea $(X_1,\dots,X_n)$ una muestra aleatoria simple de $X \leadsto B(1,p)$ y sea 
$T = \sum_{i=1}^n X_i$.

  1. Probar que si $k \in \mathbb{N}$ y $k\leq n$ el estadístico

     \[\frac{T(T-1)\dots(T-k+1)}{n(n-1)\dots(n-k+1)}\]

     es un estimador insesgado de $p^k$. ¿Es este estimador el UMVUE?
  2. Probar que si $k>n$, no existe ningún estimador insesgado para $p^k$.
  3. ¿Puede afirmarse que $\frac{T}{n}\left(1-\frac{T}{n}\right)^2$ es insesgado para $p(1-p)^2$?
#+end_statement

****** Punto 1. Es insesgado.
Llamamos $M = \frac{T(T-1)\dots(T-k+1)}{n(n-1)\dots(n-k+1)}$. Comprobamos que es insesgado calculando 
la esperanza. Dividimos entre los casos $i\leq k$ que son nulos y los demás.
Usamos $P(T = i) = {n \choose i}p^i(1-p)^{n-i}$.

\[\begin{aligned}
\mathbb{E}[M] &=
\sum_{i=1}^n {n \choose i} p^i (1-p)^{n-i}
\frac{i(i-1)\dots(i-k+1)}{n(n-1)\dots(n-k+1)} \\&=
\sum_{i=1}^n p^i (1-p)^{n-i}
\frac{(n-k)!}{(i-k)!((n-k)-(i-k))!} \\&=
p^k \sum_{i=1}^n p^{i-k} (1-p)^{(n-k)-(i-k)}
{n-k \choose i-k} \\&= p^k
\end{aligned}\]

Usando binomio de Newton en el último paso.

****** Punto 1. Es el UMVUE.
Usaremos el teorema de Lehmann-Scheffé, sabiendo que $M$ es un estimador
insesgado de $p^k$; y que $T$ es suficiente y completo para $p$.

Para ver que $T$ es completo, calculamos:

\[\begin{aligned}
\mathbb{E}[g(T)] 
&= \sum_{t=0}^n g(t) {n \choose t} p^t(1-p)^{n-t} \\
&= (1-p)^n \sum_{t=0}^n g(t) {n \choose t} \left(\frac{p}{1-p}\right)^t \\
\end{aligned}\]

Para que se anule siempre, debe anularse el polinomio
$\sum g(t) {n \choose t}r^t$ para $r \in \mathbb{R}^+$, lo que implica $g(t) = 0$.

Pero ahora, por Lehmann-Scheffé, tenemos que el UMVUE será:

\[\mathbb{E}[M\mid T] = \frac{T(T-1)\dots(T-k+1)}{n(n-1)\dots(n-k+1)}\]

Que es un UMVUE.

****** Punto 2.
Supongamos un estimador $Q$ que fuera insesgado para $p^q$. Tendríamos:

\[\mathbb{E}[Q(X)] = p^q\]

Es decir, llamando $R(T) = \sum_{\sum x_i = T} Q(X)$,

\[
\sum^n {n \choose k} R(t) p^t(1-p)^{n-t} = p^q
\]

Pero esto nos daría un polinomio de grado $q$ sobre $p$, que no puede ser 
nulo.

****** TODO Punto 3.
No. Si calculamos la esperanza usando linealidad obtenemos algo distinto.

#+BEGIN_SRC sage
n,p = var('n p')
m1 = n*p
m2 = m1*(1-p+m1)
m3 = m1*(1-3*p+3*m1+2*p^2 - 3*n*p^2 + n^2*p^2)
(p - 2*m2/n^2 + m3/n^3).normalize()
#+END_SRC

#+RESULTS:
: (n^2*p^3 - 2*n^2*p^2 - 3*n*p^3 + n^2*p + 5*n*p^2 + 2*p^3 - 2*n*p - 3*p^2 + p)/n^2

***** Ejercicio 3
#+begin_statement
Sea $(X_1,\dots,X_n)$ una muestra aleatoria simple de una variable
$X \leadsto \{{\cal P}(\lambda)\mid \lambda > 0\}$. Encontrar, si existe, el UMVUE para $\lambda^s$, siendo
$s \in \mathbb{N}$ arbitrario.
#+end_statement

Por familia uniparamétrica demostramos $T = \sum X_i$ suficiente y completo.
Probando llegamos a que $\frac{1}{n^s}T(T-1)\dots(T-s)$ es insesgado.

***** Ejercicio 7
****** Punto 1
Se comprueba que es familia exponencial uniparamétrica. Con
$T(X) = X$ y por tanto con $\sum_i T(X_i)$ como estadístico suficiente.
Además, es completo porque $Q(\Theta)$ tiene un abierto en su imagen.

****** DONE Punto 2

***** Ejercicio 8
****** DONE Punto 1

**** Tema 5. Intervalos de confianza
***** Ejercicio 1
El mínimo es $n=44$.
***** Ejercicio 2
****** Primer punto
Intervalo de $(170.75, 179.75)$.

****** Segundo punto
Da un $n \geq 865$.
***** Ejercicio 5
Se llega a $t = 2.1788$.

***** Ejercicio 7
****** Primer punto
Calculamos:

  - $\overline{X} = 37.2$
  - $\overline{Y} = 16.88$
  - $S_X^2 = 482.137$
  - $S_Y^2 = 208.517$
  - $n_1 = 6$
  - $n_2 = 5$

Y tenemos un intervalo de confianza para el cociente de varianzas.
Calculando primero desde las tablas (?), con $\alpha = 0.95$:

  - $F_{1-\alpha/2} =$
  - $F_{\alpha/2} =$
***** Ejercicio 9
Tomamos el estimador:

\[
T = \frac{1}{n}\sum_{i=1}^n X_i
\]

Si partimos de la desigualdad de Chebyshev con la cota $c = 1/n$ a la
varianza, llegamos a $k = 1/\sqrt{n\alpha}$, que nos da el intervalo:

\[
\left(
\frac{1}{n} \sum X_i + \frac{1}{\sqrt{n\alpha}}
,\quad
\frac{1}{n} \sum X_i - \frac{1}{\sqrt{n\alpha}}
\right)
\]

Con la confianza $\alpha$.
**** Tema 6. Contraste de hipotésis
**** Ejercicio 1
#+begin_statement
Se toma una observación de una variable con distribución de Poisson para
contrastar que la media vale 1 frente a que vale 2.

  1. Construir un test no aleatorizado con nivel de significación 0.05 
     para el contraste planteado. Calcular las probabilidades de cometer
     error de tipo 1 y de tipo 2, el tamaño y la potencia del test frente
     a la hipótesis alternativa.
  2. ¿Cómo debe aleatorizarse el test para alcanzar el tamaño 0.05?¿Cuál
     es la potencia de este test?
#+end_statement

Usaremos el lema de Neyman-Pearson para crear un test donde el problema
de contraste es: $H_0 : \lambda = 2$, $H_1 : \lambda = 1$, para una distribución $Poi(\lambda)$.

\[
\varphi(X) =
\left\{\begin{array}{ll} 
1 & \mbox{if } f_1(X) \geq kf_0(X) \\
0 & \mbox{if } f_1(X) < kf_0(X)
\end{array} 
\right.
\]

Sabemos que este test tendrá tamaño $\mathbb{E}_{\lambda=2}[\varphi]$, calculamos:

\[f_1(x) = \frac{1}{ex!}\]

\[
f_0(x) = \frac{2^x}{e^2x!}
\]

La condición $f_1(X) \geq kf_0(X)$ equivale a:

\[
x \leq \log_2 \frac{e}{k}
\]

Siendo $\Phi$ la función de distribución de una Poisson $Poi(2)$, que es la 
distribución que sigue aquí $x$, tenemos, consultando las tablas:

\[
\mathbb{E}_{\lambda=2}[\varphi] = 
\Phi\left(\log_2\frac{e}{k}\right) = 
0.05
\]

# Tenemos que resolver esto y no parece que en las tablas se dé nada
# sensato. Repasar el ejercicio.
**** Ejercicio 2
#+begin_statement
Una urna contiene 10 bolas, blancas y negras. Para contrastar que el 
número de bolas blancas es 5 frente a que dicho número es 6 ó 7, se
extraen tres bolas con reemplazamiento y se rechaza $H_0$ sólo si se 
obtienen 2 ó 3 bolas blancas. Calcular el tamaño de este test y la
potencia frente a alternativas.
#+end_statement

***** Tamaño del test
Llamamos $X$ a la variable dada por cada extracción, siendo 1 si es blanca
y 0 si es negra. Vemos que $X \leadsto B(1,\theta/10)$. Tenemos como hipótesis la
hipótesis nula $H_0 : \theta = 5$ y la alternativa $H_1 : \theta \in \{6,7\}$. Nuestro test está
definido por:

\[
\varphi(X_1,X_2,X_3) = 
\left\{\begin{array}{ll} 
1 & \mbox{if } \sum X_i = 2,3 \\
0 & \mbox{if } \sum X_i = 0,1
\end{array} 
\right.
\]

Calculamos el tamaño sabiendo que $Z = \sum X_i \leadsto B(3,\theta/10)$:

\[
\sup_{\theta = 5} \beta_\varphi(\theta) = E_{\theta=5}[\varphi]
=
P(Z = 2) + P(Z=3) = \frac{1}{2}
\]

***** Potencia frente alternativas
Calculamos:

\[\beta_\varphi(6)\]
\[\beta_\varphi(7)\]

**** Ejercicio 3
#+begin_statement
Sea $(X_1,\dots,X_n)$ una muestra aleatoria simple de una variable aleatoria
con distribución de Poisson de parámetro $\lambda$. Encontrar el test más potente
de tamaño $\alpha$ para resolver el problema de contraste:

\[
H_0 : \lambda = \lambda_0
\]
\[
H_1 : \lambda = \lambda_1
\]

Aplicación: En una centralita telegónica el número de llamadas por minuto
sigue una distribución de Poisson. Si en cinco minutos se han recibido 12
llamadas, ¿puede aceptarse que el número medio de llamadas por minuto es
1.5, frente a que dicho número es 2, al nivel de significación 0.05?
Calcular la potencia del test obtenido.
#+end_statement

***** Desarrollo teórico
Por Neyman-Pearson, el test más potente de tamaño $\alpha$ será de la forma:

\[
\varphi(x_1,\dots,x_n) = \left\{\begin{array}{ll} 
1 & \mbox{if } f_1(x_1,\dots,x_n) > kf_0(x_1,\dots,x_n) \\
\gamma & \mbox{if } f_1(x_1,\dots,x_n) = kf_0(x_1,\dots,x_n) \\
0 & \mbox{if } f_1(x_1,\dots,x_n) < kf_0(x_1,\dots,x_n)
\end{array} 
\right.
\]

La desigualdad es equivalente a:

\[
\frac{e^{-n\lambda_1}\lambda_1^{\sum x_i}}{\prod x_i!} 
> 
k \frac{e^{-n\lambda_0}\lambda_0^{\sum x_i}}{\prod x_i!} 
\]

\[
k = \frac
{n(\lambda_0-\lambda_1)-c}
{\log\left(\lambda_0/\lambda_1\right)}
> \sum x_i
\leadsto
Poi(n\lambda_0)
\]

Por tanto podemos tomar una distribución de Poisson siendo $\rho_\alpha$ el valor
que da $\alpha$ en la función de distribución y tener:

\[
c = n(\lambda_0-\lambda_1) + \rho_\alpha\log(\lambda_0/\lambda_1)
\]

Tenemos por tanto un test de la forma:

\[
\varphi(x_1,\dots,x_n) = \left\{\begin{array}{ll} 
1 & \mbox{if } \sum x_i < \rho_\alpha \\
0 & \mbox{if } \sum x_i \geq \rho_\alpha
\end{array} 
\right.
\]

El tamaño del test entonces será $\alpha$.

***** Aplicación
En este caso tenemos $\sum x_i = 12$, para $n=5$. Para nivel de significación
$\alpha = 0.05$, tenemos $P(Poi(10) > \rho_{0.05}) = 0.05$.

Tenemos:

\[
P(Poi(10) > 14) = 0.05
\]

Y como $12 < 14$, se el test da la hipótesis alternativa.
# Esto hay que comprobarlo, que lo he hecho muy rápido y creo que le
# dado la vuelta.

**** Ejercicio 4
#+begin_statement
Sea $(X_1,\dots,X_n)$ muestra aleatoria simple de una variable con distribución
${\cal N}(\mu,\sigma^2_0)$. Deducir el test más potente de tamaño arbitrario para contrastar
hipótesis simples sobre $\mu$.
#+end_statement

Aplicaremos Neyman-Pearson para crear un test con dos hipótesis,
$H_0 : \mu =\mu_0$, $H_1:\mu =\mu_1$, de la forma:

\[
\varphi(X) =
\left\{\begin{array}{ll} 
1 & \mbox{if } f_1(X) > kf_0(X) \\
\gamma(X) & \mbox{if } f_1(X) = kf_0(X)\\
0& \mbox{if } f_1(X) < kf_0(X)
\end{array} 
\right.
\]

Que será el de mayor potencia con nivel de significación $E_{\mu_0}[\varphi]$.
Calculamos la significación sabiendo que la condición $f_1 > kf_0$ nos
da:

\[
f_1(X) = \frac{1}{(2\pi\sigma)^{n/2}} e^{-\sum \frac{(x_i-\mu_1)^2}{2\sigma^2}}
\]

\[
f_0(X) = \frac{1}{(2\pi\sigma)^{n/2}} e^{-\sum \frac{(x_i-\mu_0)^2}{2\sigma^2}}
\]

Simplificando la condición:

\[
\sum x_i > \frac{\log k - (\mu_0^2-\mu_1^2)}{2(\mu_1-\mu_0)} = k'
\]

Y usamos la normal con $P(Z \geq z_\alpha) = \alpha$ para obtener el valor necesario para
$k'$ si queremos un test de tamaño $\alpha$:

\[
k' = z_\alpha\sigma/\sqtr{n} + \mu_0
\]

El test más potente de tamaño $\alpha$ es entonces:

\[
\varphi(X) =
\left\{\begin{array}{ll} 
1 & \mbox{if } \sum x_i > k' \\
0& \mbox{if } \sum x_i \leq k'
\end{array} 
\right.
\]

**** DONE Ejercicio 5
#+begin_statement
Deducir el test más potente de tamaño $\alpha$ para contrastar $H_0:\theta=\theta_0$
frente a $H_1:\theta=\theta_1$ y calcular su potencia. ¿Cuál es el test óptimo fijado
un nivel de significación arbitrario?
#+end_statement

**** Ejercicio 6
#+begin_statement
Deducir el test más potente de tamaño arbitrario para contrastar $H_0 : \theta = \theta_0$
frente a $H_1 : \theta = \theta_1$, basándose en una muestra de tamaño $n$ de una variable
aleatoria con función de densidad


\[
f_\theta(x) = \frac{\theta}{x^2}, \quad x > \theta
\]

Deducir el test óptimo para un nivel de significación arbitrario.
#+end_statement


**** Ejercicio 8
Minimizando y calculando se llega a:

\[
\lambda(X) =
\frac{1}{\theta_0^n} e^{(1-1/\theta_0)\sum x_i}
\]

**** Ejercicio 9
#+begin_statement
En base a una observación $X \leadsto B(n,p)$, deducir el test de razón de 
verosimilitudes para contrastar la hipótesis de que el parámetro $p$ no
supera un determinado valor, $p_0$.
#+end_statement

**** Ejercicio 10
#+begin_statement
Sea $X$ variable con función de densidad

\[
f_\theta(x) = \theta x^{\theta-1},\quad 0<x<1
\]

Basándose en una observación de $X$, deducir el test de razón de 
verosimilitudes de tamaño arbitrario para contrastar:

\[
H_0 : \theta \leq \theta_0
\]
\[
H_1 : \theta > \theta_0
\]
#+end_statement

**** Ejercicio 13
#+begin_statement
Un profesor asegura que tiene un nuevo método de enseñanza mejor que el
usado tradicionalmente. Para comprobar si tiene razón se selecciona de
forma aleatoria e independiente dos grupos de alumnos, A y B, utilizándose
el nuevo método en el grupo A y el tradicional con el B. A final de curso
se hace un examen a los alumnos, obteniéndose las siguientes puntuaciones.

  - Grupo A: 6, 5, 4, 7, 3, 5.5, 6, 7, 6
  - Grupo B: 5, 4, 5, 6, 4, 6, 5, 3, 7

Supuesto que las puntuaciones de cada grupo siguen una distribución normal,
¿proporcionan estos datos evidencia para rechazar el nuevo método, con
un nivel de significación 0.05?
#+end_statement

Usaremos la dualidad entre intervalos de confianza y tests de hipótesis
para buscar si el 0 está en un intervalo de confianza 0.95 de la diferencia
de ambas medias. Las varianzas son desconocidas pero las suponemos iguales.

El intervalo para $\mu_1-\mu_2$ de menor longitud media uniforme a nivel de
confianza $1-\alpha$ es:

\[
\left(
\overline{X}-\overline{Y} - t_{n_1+n_2-2;\alpha/2}S_p\sqrt{\frac{1}{n_1}+\frac{1}{n_2}}
,\quad
\overline{X}-\overline{Y} + t_{n_1+n_2-2;\alpha/2}S_p\sqrt{\frac{1}{n_1}+\frac{1}{n_2}}
\right)
\]

Y simplemente calculamos.
** Informática gráfica

 - curena@ugr.es
 - [[http://lsi.ugr.es/curena]]
 - [[http://lsi.ugr.es/doce/ig/17-18]]

1 punto por trabajo aparte.
Defensa de prácticas con 1 semana antelación.

*** Tema 1. Introducción
**** 1. Introducción
**** 2. Proceso de visualización
**** 3. Librería OpenGL
**** 4. Programación del cauce gráfico
***** 4.1. Cauce programable
En la GPU se ejecutan dos etapas y entre ambas la rasterización y
recortado de polígonos.

 * *Transformación* de coordenadas de vértice a ventana; realizado por
   el /vertex shader/ que se ejecuta al llamar a =glVertex=.
 * *Sombreado*, cálculo del color de pixel; realizado por el
   /fragment shader/.

Hay dos opciones para seleccionar shaders

 * *cauce de funcionalidad fija*, predefinidos hasta OpenGL 3.0;
 * *cauce programable*, escrito en GLSL, más flexible y eficiente,
   compilado en tiempo de ejecución.

El cauce gráfico fluye entonces como:

 1) CPU, aplicación.
 2) Implementación de OpenGL.
 3) Vertex shader para cada vértice.
 4) Rasterización.
 5) Fragment shader para cada pixel.
 6) Framebuffer.

***** 4.2. Shaders básicos
Un *program* es un /vertex shader/ con un /fragment shader/. Se
almacenan en =char*=, se compilan con OpenGL y se enlazan.

****** TODO Programar un vertex shader
****** TODO Programar un fragment shader
***** 4.3. Creación y ejecución de programas
Un *program* tiene un =GLuint= identificador.

 * =glCreateShader=
 * =glShaderSource=
 * =glCompileShader=
 * =glCreateProgram=
 * =glAttachShader=
 * =glLinkProgram=
 * =glUseProgram=

***** 4.4. Funciones auxiliares
**** 5. Apéndice: puntos, vectores y marcos
*** Tema 2. Modelado de objetos
**** 2.1. Modelos geométricos
***** 2.1.1. Introducción
El modelo geométrico más general son los conjuntos pero no permiten
una representación computacional clara. Se usan

 * *voxels*, cuadrículas de volúmenes,
 * *fronteras*, polígonos planos.

**** 2.2. Modelos de fronteras
***** 2.2.1. Elementos y adyacencia
Los modelos de fronteras usan mallas de polígonos, normalmente
mallas de triángulos. Se consideran adyacencias entre vértices,
aristas y caras bajo un *marco de referencia local de la malla*.

La malla tiene como atributos

 * normales de las caras,
 * normales de los vértices,
 * colores de caras, 
 * colores de vértices, que luego interpolarán las caras;
 * coordenadas de textura,
 * vectores bitangentes.

***** 2.2.2. Lista de triángulos
La estructura más simple es la *lista de triángulos aislados*, una
entrada para cada tres vértices, $9n$ floats; consume mucha memoria
innecesaria. =Objeto3D=, =MallaTA=

****** Visualización
Puede hacerse

 * con =glBegin/glEnd= llamando a =glVertex3fv=,
 * con =glDrawArrays=, usando $3n$ tuplas de coordenadas.

***** 2.2.3. Mallas como tiras de triángulos
Cada triángulo es adyacente al anterior y tenemos $3(n+2)$ floats.
En algunos casos hay que usar varias o repetir vértices. La complejidad
de representarlas luego es mayor. =MallaTT=

***** 2.2.4. Mallas indexadas
Usar dos tablas

 * *tabla vértices*, con entrada por vértice,
 * *tabla triángulos*, llamando a tabla vértices.

Mucho más efiicente =MallaInd=, $3n$.

***** 2.2.5. Representación con aristas aladas
Las aristas tienen dos caras adyacentes, hay una tabla de vértices y
otrade aristas, donde la segunda guarda

 * vértice inicial,
 * vértice final,
 * triángulo a la izquierda,
 * triángulo a la derecha,
 * arista anterior en el triángulo izquierda,
 * arista siguiente en el triángulo izquierda,
 * arista anterior en el triángulo derecha,
 * arista siguiente en el triángulo derecha.

Podemos así resolver adyacencias, pueden usarse también

 * tabla de aristas de vértice,
 * tabla de aristas de triángulo.

***** 2.2.6. Representación con atributos
A los vértices se les puede asignar

 * colores,
 * normales,
 * coordenadas de textura,
 * otros atributos.

Pueden asociarse con =glVertex= o usando =glDrawArrays= con
=glDrawElements=. A las caras no se pueden asignar atributos
directamente, pero se pueden cambiar al enviar la cara.

***** 2.2.7. Visualización de mallas en modo diferido
Se envía todo una sóla vez a la GPU. Puede hacerse con

 * display lists (obsoletas),
 * vertex buffer objects (VBO).

El VBO se crea tomando un identificador, generando luego el VBO,
asignándolo al dentificador y haciendo la transferencia a GPU,
puede desactivarse luego.

#+BEGIN_SRC c++
GLuint id_vbo;
glGenBuffers(1, &id_vbo);
glBindBuffer(tipo, id_vbo);
glBufferData(tipo, tamanio, puntero, GL_STATIC_DRAW);
glBindBuffer(tipo, 0);
#+END_SRC

La malla se puede visualizar muchas veces entonces sin enviar datos a
GPU usando =glBindBuffer= y =glDrawElements=. Colores y normales se
pueden almacenar en los mismos VBOs.

**** 2.3. Transformaciones geométricas
***** 2.3.1. Transformación geométrica
Todas las mallas deben acabar apareciendo en *coordenadas del mundo*.
Se usan transformaciones geométricas matriciales para mostrar los
objetos.

Se consideran matrices 4x4 donde el último vector indica si es un punto
y las coordenadas de ese punto. Se transforma sobre un marco de coordenadas
$R$ desde $p = R(x,y,z,w)^t$ a $p' = R(x',y',z',w')^t$; viene así determinada
por tres funciones lineales

\[\begin{aligned}
x' &= f_x(x,y,z,w) \\
y' &= f_y(x,y,z,w) \\
z' &= f_z(x,y,z,w) \\
w' &= w
\end{aligned}\]

que dependen del marco de referencia.

***** 2.3.2. Transformaciones usuales en IG
Todas ellas son afines y coherentes, $T(p-q) = Tp - Tq$.

****** Traslación
Para puntos $\mathrm{Tra}[d](p) = p + d$ y para vectores $\mathrm{Tra}[d](v) = v$.
Queda como

\[\begin{aligned}
x' &= f_x(x,y,z,w) &= x + d_xw \\
y' &= f_y(x,y,z,w) &= y + d_yw \\
z' &= f_z(x,y,z,w) &= z + d_zw \\
w' &= w
\end{aligned}\]

y puede escribirse como =MAT_Traslacion(dx,dy,dz)=.

****** Escalado

****** Cizalla

****** Rotación

****** Composición

****** Representación matricial
***** 2.3.3. Matrices y marcos de coordenadas
Si las coordenadas del marco $B$ en $A$ vienen dadas por $a,b,c,d$,
la matriz de cambio de $B$ a $A$ viene dada por

\[M_{A,B} = \begin{pmatrix}
a_x & b_x & c_x & d_x \\
a_y & b_y & c_y & d_y \\
a_z & b_z & c_z & d_z \\
0 & 0 & 0 & 1 \\
\end{pmatrix}\]

y se calculan las coordenadas como $Mc_{A} = c_B$.

***** 2.3.4. Representación de matrices en memoria
Se usa el tipo =Matriz4f=.

***** 2.3.5. Transformaciones en OpenGL
OpenGL almacena

 * *matriz de modelado* (N), pasa de coordenadas de objeto a coordenadas
   del mundo; posiciona un objeto en la escena;

 * *matriz de vista* (V), pasa de coordenadas del mundo a coordenadas de
   ojo, relativas a la cámara;

 * *modelview* (M), compone modelado y vista $M = VN$.

La modelview puede especificarse por composición

#+BEGIN_SRC c++
glMatrixMode(GL_MODELVIEW);
glLoadIdentity();
gluLookAt(..);     // Vista
glMultMatrix(..);  // Modelado
#+END_SRC

La gestión directa de matrices es obsoleta a partir de OpenGL3.1.

***** 2.3.6. Gestión de matriz de modelado en GLSL
**** 2.4. Modelos jerárquicos, representación y visualización
*** Tema 3. Visualización
**** 3.1. Cauce gráfico y definición de la cámara
***** 3.1.1. El cauce gráfico del algoritmo Z-buffer
El algoritmo Z-buffer elimina partes ocultas (EPO) en 3D y se
implementa en hardware. Tiene 4 pasos.

 * Transformación de coordenadas de vértices, proyección a la
   pantalla.
 * Recortado de polígonos fuera de zona visible.
 * Rasterización y EPO, cálculo de píxeles donde proyectar.
 * Iluminación y texturación.

****** Sistemas de coordenadas

 * (OC) Coordenadas de *objeto*, propias de cada objeto fuera de escena.
 * (WC) Coordenadas de *mundo*, colocando los objetos en la escena.
 * (EC) Coordenadas de *cámara* u *ojo*, relativas a la cámara virtual.
 * (CC) Coordenadas de *recortado*, distancias normalizadas relativas al
   rectángulo de la pantalla.
 * (NDC) Coordenadas *normalizadas de dispositivo*, de recortado dentro de
   la zona visible.
 * (DC) Coordenadas de *dispositivo*, en pixels.

****** Cambios de coordenadas

 * (N) La matriz de *modelado* pasa objeto a mundo.
 * (V) La matriz de *vista* pasa mundo a cámara.
 * (P) La matriz de *proyección* pasa de cámara a recortado.
 * (D) La matriz de *viewport* pasa normalizadas (NDC) a dispositivo (DC).

***** 3.1.2. Transformación de vista
La matriz de vista se define con

 * $o_c$, posición de observador (PRP),
 * $n$, normal al plano de proyección (VPN),
 * $a$, punto de atención (VRP), alternativa a especificar $n$,
 * $u$, dirección que señala el "arriba" de la imagen (VUP).

****** Construir del marco de referencia
A partir de los parámetros se pueden construir tres vectores
perpendiculares formando el *marco del observador*,

\[\begin{aligned}
n &= o - a \\
z_c &= \frac{n}{\|n\|} \\
x_c &= \frac{n \times u}{\|n \times u\|} \\
y_c &= z_c \times u_c
\end{aligned}\]

y este marco se representa en coordenadas de mundo $W$. =gluLookAt=
toma $o,a,u$ como parámetros.

****** Cálculo de matriz de vista dado un marco
Dado $p$ en coordenadas del mundo podemos tomar los productos escalares
de $p-o_c$ con los ejes $x_c,y_c,z_c$. La matriz de vista será entonces

\[V = \begin{pmatrix}
a_x & a_y & a_z & 0 \\
b_x & b_y & b_z & 0 \\
c_x & c_y & c_z & 0 \\
0 & 0 & 0 & 1 \\
\end{pmatrix}
\begin{pmatrix}
1 & 0 & 0 & -o_{x} \\
0 & 1 & 0 & -o_{y} \\
0 & 0 & 1 & -o_{z} \\
0 & 0 & 0 & 1 \\
\end{pmatrix}\]

donde $a = x_c, b = y_c, c = z_c$ son los tres ejes.

****** Cálculo de matriz de vista con ángulos de Euler
Los ángulos de Euler pueden construirse a partir de las coordenadas
del marco

\[
V = \mathrm{Rot}[\gamma,z] \cdot \mathrm{Rot}[\beta,y] \cdot \mathrm{Rot}[\alpha,x] \cdot \mathrm{Tra}[-o_c]
\]

***** 3.1.3. Transformación de proyección
Se proyecta sobre un *viewplane* de dos formas

 * *perspectiva*, con líneas proyectoras hacia un foco; hay un factor de
   escala que decrece afínmente con la distancia $s = 1/(ad_z + b)$;
 * *ortográfica*, con líneas proyectoras paralelos, es una proyecció
   afín simple.

****** El view-frustum
Región de la escena visible en el viewport. La transformación de
proyección debe transformarlo en un cubo de lado 2 centrado en el
origen, esta no es lineal pero puede serlo en cuatro dimensiones.

 * Es un ortoedro en proyección ortográfica.
 * Es una pirámide truncada en proyección perspectiva.

****** Parámetros del view-frustum
Se interpretan en coordenadas de vista, y se usan para transformar
de vista a recortado (matriz P)

 * $n,f$, near y far, son los límites en Z del view-frustum, se exigen
   positivos, determinan planos de recorte trasero y delantero;

 * $l,r,b,t$, bottom y top, límites en X e Y, que se transformarán en
   [-1,1];

 * $(r-l)/(t-b)$ debe ser la relación de aspecto del viewport.

****** TODO Matriz de proyección perspectiva
****** TODO Matriz de proyección ortográfica
****** Matrices en OpenGL
#+BEGIN_SRC c++
glFrustum(l,r,b,t,n,f); // perspectiva
glOrtho(l,r,b,t,n,f);   // ortográfica

gluPerspective(fovy,a,n,f) // perspectiva (alternativa)
#+END_SRC

donde para =gluPerspective= se asume $r = -l$ y $t = -b$ y se tiene

 * =fovy= es la apertura del campo de visión, grados de 0 a 180;
 * =a= es la relación de aspecto $r/b$;
 * =n,f= son near y far.

**** 3.2. Modelos de iluminación
***** 3.2.1. Radiación visible
La *radiancia* $L(\lambda,p,v)$ determina el tono y brillo de un punto. 
Los colores pueden medirse en RGB usando mezcla aditiva, la
traducción dependerá del dispositivo.

***** 3.2.2. Emisión y reflexión de la radiación
La radiancia es suma de emitida y reflejada, para cada radiancia
incidente desde cada punto, se refleja una fracción en cada dirección
$v$,

\[
L(\lambda, p,v) = L_{em}(\lambda, p,v) + \sum_i L_{in}(\lambda,p,u_i)f_r(\lambda,p,v,u_i)
\]

***** 3.2.3. Simplificaciones en modelos computacionales
Se asume para calcular

 * fuentes puntuales no extensas,
 * la única iluminación indirecta es constante,
 * objetos opacos,
 * no hay sombras arrojadas,
 * no hay dispersión,
 * sólo funciona en RGB.

**** 3.3. Modelo de iluminación local (MIL) básico
***** 3.3.1. Elementos del modelo: normales y colores
La iluminación depende de la orientación caracterizada por el *vector
normal*.

***** 3.3.2. Fuentes de luz, materiales y reflexión
 * Posicionales, con vector unitario

   \[
   l_i = \frac{q_i-p}{\|q_i-p\|}
   \]

 * Direccionales, a distancia infinita, dirección constante.

***** 3.3.3. Componentes del modelo
 * Radiancia emitida $L_{em}(p)$, emisividad del material.

 * Reflectividad difusa $f_{ra}(p,v,l_i) = M_A(p)$.

 * Componente difusa dependiendo de la posición, independiente de la
   dirección; $f_{rd}(p,v,l_i) = M_D(p) \max(0,n_p \cdot l_i)$.

 * Material difuso $M_A(p)$.

 * Componente pseudo-especular, el reflejo de la luz en objetos
   brillantes. *Modelo de Phong*,

   \[
   f_{rs}(p,v,l_i) = M_S(p) d_i [\max(0,r_i \cdot v)]^{e}
   \]

   con $r_i$ reflejado, $e$ exponente de brillo, $d_i$ midiendo si
   está de cara a la superficie.

***** 3.3.4. Modelo completo
\[
L(p,v) = M_E(p) + A_G(p) + \sum_{i=0}^{n-1}S_iC_i
\]

donde

\[
C_i = M_A(p) + M_D(p) \max(0,n\cdot l_i) + M_S(p) d_i (\max(0,r_i \cdot v))^e
\]

**** 3.4. Iluminación en OpenGL
***** 3.4.1. Iluminación vs asignación de colores
Obsoleta y eliminada a partir de OpenGL3.1. Cuando está activada se
usa el MIL para calcular el color.

#+BEGIN_SRC c++
glEnable(GL_LIGHTING);
glDisable(GL_LIGHTING);
#+END_SRC

Los parámetros del MIL son

 * $M_E$, emisividad,
 * $M_A,M_{D},M_S$, reflexividad difusa, ambiente y pseudoespecular,
 * $A_G$, luz ambiente,
 * $e$, exponente,
 * $S_{iA},S_{iD},S_{iS}$, luminosidad de cada fuente de luz,
 * $q_i,l_i$, posición y dirección de cada fuente de luz.

El modelo de funcionalidad fija es parecido al MIL visto.

***** 3.4.2. Definición de fuentes de luz
Hay luces =GL_LIGHTi= para =i = 0..8=. Pueden especificarse en varios
marcos de coordenadas con transformaciones.

#+BEGIN_SRC c++
// Activación
glEnable(GL_LIGHTi);
glDisable(GL_LIGHTi);

// Configuración de colores
glLightfv(GL_LIGHTi, GL_AMBIENT, caf);
glLightfv(GL_LIGHTi, GL_DIFFUSE, caf);
glLightfv(GL_LIGHTi, GL_SPECULAR, caf);

// Posición/dirección
glLightfv(GL_LIGHTi, GL_POSITION, tupla);
glLightfv(GL_LIGHTi, GL_DIRECTION, dirf);
#+END_SRC

***** 3.4.3. Representación de fuentes de luz
Clase =FuenteLuz=, se guardan en =ColeccionFL=.

***** 3.4.4. Vector hacia observador
El observador puede ser local o en el infinito.

#+BEGIN_SRC c++
glLightModeli(GL_LIGHT_MODEL_LOCAL_VIEWER, GL_FALSE); // Ortogonal
glLightModeli(GL_LIGHT_MODEL_LOCAL_VIEWER, GL_TRUE); // Perspectiva
#+END_SRC

***** 3.4.5. Normales de vértices
Se pueden especificar con =glNormal= y normalizarse con
=glEnable(GL_NORMALIZE)=.

***** 3.4.6. Atributos materiales
El término ambiente, emisividad y colores se controlan.

#+BEGIN_SRC c++
glLightModelf(GL_LIGHT_MODEL_AMBIENT, color);
glMaterialf(GL_FRONT_AND_BACK, GL_EMISSION, color);
glMaterialfv(GL_FRONT_AND_BACK, GL_AMBIENT, color);
glMaterialfv(GL_FRONT_AND_BACK, GL_DIFFUSE, color);
glMaterialfv(GL_FRONT_AND_BACK, GL_SPECULAR, color);
glMaterialfv(GL_FRONT_AND_BACK, GL_SHININESS, color);
#+END_SRC

***** 3.4.7. Representación de materiales
Clase =Material=.

**** 3.5. Métodos de sombreado para Z-Buffer
***** 3.5.1. Evaluación del MIL con Z-Buffer
El MIL puede evaluarse

 * *sombreado plano* (flat shading): una vez por polígono.
 * *sombreado de vértices* (smooth shading, Gouround): una vez por vértice.
 * *sombreado de pixel* (pixel shading): una vez por pixel.

***** 3.5.2. Sombreado plano
Eficiente, discontinuidades y poco realista. Crea bandas Mach

***** 3.5.3. Sombreado en vértices
Eficiente pero más realista, puede tener bandas Mach. Puede perder
zonas brillantes.

***** 3.5.4. Sombreado en pixeles
Costoso, más calidad y realismo.

***** 3.5.5. OpenGL: método de sombreado
Sólo plano y vértices

#+BEGIN_SRC c++
glShadeModel(GL_FLAT);
glShadeModel(GL_SMOOTH);
#+END_SRC

**** 3.6. Visualización de texturas
***** 3.6.1. Detalles a pequeña escala
Rugosidades variando la normal y la reflectividad. Pueden usarse
polígonos de detalle, pero las *texturas* son más eficientes, llevan
texels a un cuadrado del espacio. Pueden ser procedurales.

***** 3.6.2. Coordenadas de textura
Aplican la textura al objeto.

***** 3.6.3. Asignación explícita de coordenadas de textura
Se asignan al modelar el objeto en escena.

***** 3.6.4. Asignación procedural de coordenadas de textura
Un subprograma =CoordText(p)= que las calcula en cada punto.

 * Asignación a vértices, interpolando luego.
 * Asignación a puntos.

Se suelen usar:

 * funciones lineales,
 * coordenadas paramétricas,
 * coordenadas polares,
 * coordenadas cilíndricas.

En los casos de una superficie paramétrica, podemos usar las coordenadas
como coordenadas de textura. Las esféricas y cilíndricas pueden proporcionar
mejores resultados en algunos casos.

***** 3.6.5. Consulta de texels
El texel (i,j) tiene centro en un punto $(c_i,d_j)$ y puede
consultarse

 * el texel más cercano a ese punto,
 * una interpolación bilineal entre los cuatro texels.

La interpolación es más suave.

**** 3.7. Texturas en OpenGL
***** 3.7.1. Activación y desactivación
#+BEGIN_SRC c++
glEnable(GL_TEXTURE_2D);
glDisable(GL_TEXTURE_2D);
#+END_SRC

Cuando se activan, el color de textura sustituye a reflexividades del
material y al color.

***** 3.7.2. Carga de texturas
OpenGL gestiona varias texturas por identificadores, en cada momento
habrá una sola activa. Las texturas se guardan en RAM.

#+BEGIN_SRC c++
// Genera
GLuint idTex;
glGenTextures(1, &idTex);

// Asocia, con potencias o mipmaps
glTexImage2D(GL_TEXTURE_2D, 0,GL_RGB,ancho,alto,borde = 0, GL_RGB,GL_UNSIGNED_BYTE, texels);
gluBuild2DMipmaps(GL_TEXTURE_2D, GL_RGB, ancho,alto, GL_RGB, GL_UNSIGNED_BYTE, texels);

// Activa
glBindTexture(GL_TEXTURE_2D, idTex);
#+END_SRC

***** 3.7.3. Configuración de texturas
Determinan la apariencia de textura

 * color de texels,
 * selección de texels (cercano o interpolación),
 * selección fuera de rango (replicado o truncamiento),
 * coordenadas explícitas o procedurales.

****** Texturas, reflectividades e iluminación
#+BEGIN_SRC c++
glLightModeli(GL_LIGHT_MODEL_COLOR_CONTROL, GL_SINGLE_COLOR); // Color en lugar de reflectividades
glLightModeli(GL_LIGHT_MODEL_COLOR_CONTROL, GL_SEPARATE_SPECULAR_COLOR); // Especular aparte
#+END_SRC

****** Selección de texels
#+BEGIN_SRC c++
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST); // Más cercano
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR);  // Interpolación
#+END_SRC

****** Tipo de generación procedural
Dos tipos de generación,

#+BEGIN_SRC c++
glTexGeni(GL_S, GL_TEXTURE_GEN_MODE, GL_OBJECT_LINEAR); // Coordenadas de objeto
glTexGeni(GL_T, GL_TEXTURE_GEN_MODE, GL_OBJECT_LINEAR); // Coordenadas de ojo
#+END_SRC

****** Especificación de coeficientes de generación procedural
Los coeficientes de las funciones lineales de generación

#+BEGIN_SRC c++
glTexGenfv(GL_S, GL_OBJECT_PLANE, coefsS);
glTexGenfv(GL_T, GL_OBJECT_PLANE, coefsT);
#+END_SRC

***** 3.7.4. Asignación explícita de texturas y VBOs
Puede hacerse con =glBegin/glEnd= usando =glTexCoord2f=. Pueden
crearse VBOs con coordenadas de textura.

***** 3.7.5. Representación de texturas
Clase =Textura=.

**** 3.8. Materiales en grafo de escena
***** 3.8.1. Modelo de aspecto
Los materiales dan un modelo de aspecto que puede insertarse en el
grafo de escena afectando a todas las entradas por debajo. Para esto
es cómodo tener una =PilaMateriales=.

***** 3.8.2. Implementación de materiales en el grafo
Añadimos materiales a =EntradaNGE= y visualizamos con =visualizarGL=.

**** 3.9. Visualización con cauce gráfico programable
***** 3.9.1. Introducción
La única forma de evaluar el MIL es usar vertex+fragment shader en el
cauce gráfico con GLSL.

****** Parámetros del vertex shader
Hay parámetros de entrada al vertex shader, que se enviarán con
=glVertexAttrib= y =glVertexAttribPointer=

 * *uniform*, mismo valor para todos los vértices,
 * *vértice*, potencialmente distintos para cada vértice.

Los parámetros de salida se entregan interpolados al fragment shader.
Pueden declararse explícitamente y están predefinidos algunos.

***** 3.9.2. Sombreado de pixeles (fragment shader)
El shader tiene

 * parámetros *uniform*, iguales en todos los pixeles =glUniform=,
 * parámetros *in*, interpolados a partir de los *out* del vertexShader.

El factor geométrico de la pseudo-especular puede calcularse usando
Blinn-Phong y puede escribirse una completa evaluación del MIL.

***** 3.9.3. Atributos vértice genéricos
Es necesario usar atributos de vértice para los parámetros de entrada.
Tienen,

 * localización, identificador en la aplicación,
 * nombre, identificador en el fuente del vertexshader.

Se puede asociar localización a los nombres con =glBindAttribLocation=
y se pueden enviar tablas de atributos genéricos.

*** Tema 4. Interacción y animación
**** 4.1. Introducción
Buscamos un sistema gráfico interactivo que responda al usuario
interactivamente. Habrá retroalimentación, técnicas y funciones de
entrada que lean de dispositivos lógicos, cambiando su estado y
generando eventos.

***** Leer de dispositivos
Existen tres modos

 - modo de muestreo :: variables con el estado actual, la CPU debe
      muestrear a frecuencia suficiente.
 - modo de petición :: se hace una petición y se espera a que ocurra
      el evento determinado, pueden perderse eventos y tiempo
      esperando.
 - modo cola de eventos :: se añade a una cola FIFO cada evento y se
      va procesando luego.

**** 4.2. Eventos en GLUT
GLUT gestiona los eventos con cola de eventos; cada evento va asociado
a un *callback*, una función que lo trata y toma parámetros de él.

***** Funciones de registro de callback
#+BEGIN_SRC c++
glutDisplayFunc(); // es necesario redibujar la imagen.
glutMouseFunc(); // pulsar/levantar de botones del ratón.
glutMotionFunc(); // movimiento del ratón con un botón pulsado.
glutPassiveMotionFunc(); // movimiento del ratón sin botón pulsado.
glutReshapeFunc(); // cambio de tamaño de la ventana.
glutKeyFunc(); // pulsar o levantar de tecla.
glutIdleFunc(); // ausencia de eventos externos.
glutTimerFunc(); // ha transcurrido un intervalo de tiempo.
#+END_SRC

***** Eventos de botones de ratón
Declaramos un callback 

#+BEGIN_SRC c++
void FGE_BotonRaton(GLint boton, GLint estado, GLint x, GLint y);
#+END_SRC

donde =boton= toma tres constantes (=GLUT_LEFT_BUTTON=,
=GLUT_RIGHT_BUTTON=, =GLUT_MIDDLE_BUTTON=) según el botón pulsado y
dos estados (=GLUT_UP=, =GLUT_DOWN=) según se haya pulsado o levantado
la =x,y= indica la posición del ratón en cada momento.

****** Ejemplo de callback de botones de ratón
#+BEGIN_SRC c++
int xClickIzq, yClickIzq; // posición del último click del botón izquierdo
[...]

void FGE_BotonRaton(int boton,int estado,int x,int y) {
  if (boton == GLUT_LEFT_BUTTON && estado == GLUT_DOWN) { 
    xClickIzq = x; 
    yClickIzq = y; 
  }
  else if
  [...]
}
#+END_SRC
***** Eventos de movimiento de ratón
****** Ejemplo de callback de movimiento de ratón
**** 4.3. Posicionamiento
La posición que introduce un usuario está en /coordenadas de dispositivo/
y es necesario pasarla a coordenadas de mundo.

***** Posicionamiento 2D
Las coordenadas de dispositivo $x,y$ se convierten a mundo $x',y'$ con una
transformación inversa

\[\begin{aligned}
x' &= X_{min} + x (X_{max} + X_{min}) / \mathrm{ancho}; \\
y' &= Y_{max} - y (Y_{max} + Y_{min}) / \mathrm{alto}; \\
\end{aligned}\]

donde los parámetros son los que determinan el ancho y alto del
dispositivo y mínimos y máximos del mundo.

#+BEGIN_SRC c++
glOrtho(Xmin,Xmax, Ymin,Ymax, Zmin,Zmax);
glViewport(x0, y0, ancho, alto);
#+END_SRC

***** Posicionamiento 3D
Se restringe a un plano no perpendicular al de proyección y se traza
una recta desde el centro de proyección por el punto introducido, que
cortará al plano dado.

**** 4.4. Control de cámaras
Dos usos de la cámara

 - visualización de objetos en modo *orbital* centrando el objeto;
 - exploración de escenario en *primera persona*, desplazando VRP y
   rotando VPN y VUP en torno al marco de coordenadas de la cámara.

El *marco de coordenadas de vista* está determinado por tres versores
ortonormales $x_c, y_c, z_c$ y un origen $o_c$. La *matriz de vista* se obtiene
directamente desde ellas

\[V = \begin{pmatrix}
x_c(0) & y_c(0) & z_c(0) & -o_c \cdot x_c \\
x_c(1) & y_c(1) & z_c(1) & -o_c \cdot y_c \\
x_c(2) & y_c(2) & z_c(2) & -o_c \cdot z_c \\
0 & 0 & 0 & 1 \\
\end{pmatrix}
\]

y transforma coordenadas de mundo en coordenadas de cámara.

***** 4.4.1. Cámaras en modo primera persona

 * *Rotaciones*: se rotan VPN y VUP en torno a PRP (origen). VPN rota
   en horizontal o vertical y VUP permite rotar en torno a un centro.
   La rotación se hace con los ejes del marco.

 * *Traslaciones*: se desplaza PRP en la dirección de traslación.
   La traslación se hace con los ejes del marco.

***** 4.4.2. Cámaras orbitales
Las coordenadas esféricas, el punto de atención y la distancia a él
fijan la cámara. El marco de vista puede obtenerse desde estos
parámetros.

**** 4.5. Selección
Se pueden dar identificadores de selección a

 * triángulos,
 * mallas,
 * grupos de objetos,
 * nodos del grafo de escena.

Puede seleccionarse pixel en pantalla y buscar identificadores
proyectados en ese pixel. La búsqueda puede hacerse por

 * *ray-casting*, por intersección de rectas,
 * *clipping*, recortando dentro de un view-frustum pequeño,
 * *rasterización*, visualiza con identificadores.

En OpenGL hay un modo selección y puede usarse un framebuffer distinto
para rasterizar con identificadores.

***** 4.5.1. Selección de OpenGL [Obsoleto]
#+BEGIN_SRC c++
glRenderMode(GL_SELECT);
glRenderMode(GL_RENDER);
#+END_SRC

Hay una pila de nombres que se almacenan en un buffer de
selección. Durante la rasterización, OpenGL registra nombres.

***** 4.5.2. Selección con frame-buffer invisible
Se puede usar de dos formas, la segunda más simple

 * crear un *frame-buffer object* (FBO);
 * *doble buffer* un back buffer y un front buffer.

****** Visualización con identificadores
Codificamos los identificadores como colores en lugar de usar los
colores de los objetos. Cambiamos el color actual de OpenGL y desactivamos
la iluminación, las texturas, usar sombreado plano y triángulos planos.

Este es el *modo identificadores* de visualización.

****** Transformación de identificadores a colores
Los identificadores deben ser =unsigned char= con una variante de
=glColor= que los acepta en lugar de valores flotantes. Puede
reconstruirse el unsigned de nuevo desde los tres colores.

**** 4.6. Animación
#+BEGIN_SRC c++
glutPostRedisplay(); // Regenera la imagen
glutSwapBuffers();   // Intercambia buffer dibujado
glutInitDisplayMode(GLUT_DOUBLE | GLUT_RGBA | GLUT_DEPTH); // Activación de buffer
#+END_SRC

La modificación en escena se puede hacer con

 * *keyframes*, configuraciones sobre las que se interpola,
 * *simulación física*, usando mecánica clásica,
 * *esqueletos*, que simplifican la animación,
 * *animación procedural*, objetos descritos por procedimientos.

*** Tema 5. Realismo en rasterización, ray-tracing
**** 5.1. Técnicas realistas de rasterización
***** 5.1.1. Mipmaps
La resolución de las texturas debe adaptarse a la imagen. Puede
solucionarse con *antialiasing* o con *mipmaps*, una serie de texturas
$\left\{ M_i \right\}$ donde cada una se obtiene promediando grupos de
$4$ pixels de la anterior, con resoluciones $2^{n-i} \times 2^{n-i}$.

El $i$ de textura que se usa crece con el logaritmo de la distancia.

***** 5.1.2. Perturbación de la normal
Las rugosidades a pequeña escala causarían un rendering muy lento; se
usa una textura que modifica la normal a pequeña escala (*bump-maps*).

 * La textura la da un campo de alturas, que puede ser generado
   procedural o dado como tonos de gris.

 * Sobre ese campo de alturas se calculan derivadas parciales o
   diferencias finitas $d_u,d_{v}$.

 * A las derivadas en un punto se les llama tangente y bitangente y
   definen un plano tangente perpendicular a la normal. Pueden
   obtenerse interpolando en algunos casos.

***** 5.1.3. Sombras arrojadas
Las sombras arrojadas plantean un problema similar a visibilidad. 

 * Lo soluciona el Algoritmo de Weiler-Atherton-Greenberg, para
   eliminación de partes ocultas.

 * Más eficiente es usar Z-buffer.

***** 5.1.4. Superficies transparentes
La refracción la calcula la ley de Snell, $n_i\sin(\theta_i) = n_j\sin(\theta_j)$.

 * El Z-buffer sólo puede tener en cuenta los rayos que van hacia el
   observador, pero puede adaptarse a superficies transparentes cuando
   no hay refracción. Los colores en superficies transparentes dependen
   del orden de los polígonos.

 * La reflexión especular no puede reproducirse con los métodos
   vistos.  Pueden usarse mapas de entorno tipo caja; y en espejos
   planos puede sintetizarse directamente una cámara simétrica.

**** 5.2. Ray-tracing
***** 5.2.1. El algoritmo de Ray-tracing
Ray-tracing reúne todos los efectos anteriores y es más sencillo y realista
que el Z-buffer. Cada pixel crea un rayo primario.

***** 5.2.2. Evaluación del MIL

 * Las sombras se calculan siguiendo el rayo hasta la fuente.
 * Las superficies especulares o con refracción crean rayos
   secundarios.

***** 5.2.3. Esquema del algoritmo
La función es recursiva, devuelve un color y tendrá algún parámetro
para evitar la recursividad infinita.

*** Ejercicios
**** Ejercicio 12
***** apartado a
4by

vértices = (n+1)*(m+1) = nm + n + m + 1
caras = 2nm

floats = 3*vertices = 3nm + 3n + 3m + 3
ints = 3*caras = 6nm

tamaño = 4*ints + 4*floats = 24nm + 12nm + 12n + 12m + 12 = 36nm + 12n + 12m + 12

***** apartado b
592908

***** apartado c
1/2

**** Ejercicio 13
verticestira = 2n+2
totalvert = verticestira * m
tamaño = 4*totalvert = 3*4m(2n+2) = 24nm + 24m
**** Ejercicio 39
La matriz de vista simplemente centraría en la cámara

\[
\mathrm{gluLookAt}((c_x,c_y,c_z), (c_x,c_y,c_z-1), (0,1,0))
\]

mientras que la de proyección describe el cuadro ortogonal

\[
\mathrm{glOrtho}\left(-\frac{s}{2},\frac{s}{2},-\frac{s}{2},\frac{s}{2},-\frac{s}{2},\frac{s}{2}\right).
\]
**** TODO Ejercicio 40
**** TODO Ejercicio 41
**** TODO Ejercicio 42
**** TODO Ejercicio 43
**** Ejercicio 46
# Tabla de coordenadas de textura
** Ingeniería, empresa y sociedad
#
# Estos apuntes de empresa han sido escritos por Mario Román, tomando
# como base la docencia de Matilde Ruiz Arroyo para la asignatura de
# Ingeniería, Empresa y Sociedad.
#
# Pueden copiarse y distribuirse bajo la siguiente licencia respetando
# la nota de autoría original:
#
#  Creative Commons Attribution-NonCommercial-ShareAlike 4.0 
#  International Public License
# 

*** Detalles de la asignatura
Profesora Matilde Ruiz, departamento de Organización de Empresas. 
(matilderuiz@ugr.es)

*Evaluación:*

- 70% Pruebas objetivas: la prueba final de junio y los exámenes parciales.
- 30% Actividades prácticas: participación, ejercicios y asistencia.

*Bibliografía:*

 - Fuentes Fuentes M. et al. /"Fundamentos de dirección y administración de empresas"/

*** 1. La empresa y dirección de empresas
**** 1.0. Introducción
***** Economía
La *economía* se define como la ciencia que estudia la administración
eficiente de la escasez de recursos. También como ciencia que
estudia la elección.

Este concepto proviene de las ideas de *Malthus*. La escasez justifica
la necesidad de reparto y la pobreza.

***** Administración de empresas
La *administración de empresas* estudia la economía en el contexto de
una empresa, así como la gestión de proyectos, la planificación y el
liderazgo. Es una disciplina científica multidisciplinar y contempla
aspectos psicosociales.

**** 1.1. Concepto de empresa y de organización
***** Organización
Una *organización* es una unidad social deliberadamente destinada a un
objetivo específico. Requiere constar de una estructura interna
deliberada y fijar el objetivo común.

****** Definición de Gibson
La *organización* es una unidad coordinada /deliberada/ formada por
más de una persona que trabaja para alcanzar un /objetivo común/.

****** Definición de Etzioni
Unidades sociales deliberadamente constituidas para promover objetivos
específicos.

****** Clasificación de organizaciones
Una clasificación genérica sencilla las separa según tengan o no
*ánimo de lucro*.

******* Ejemplo: Inditex
Industria de diseño textil INDITEX S.A. es una empresa multinacional
que tiene como objetivo maximizar el beneficio. Según la empresa,
su objetivo es "/escuchar a los clientes para ofrecerles las propuestas/
/de moda que desean/".

******* Ejemplo: Amigos del museo del Prado
En sus estatutos aclara que su fin primario es cultural. Puede
obtener beneficios económicos, pero serán un fin secundario, sólo
un medio para su fin primario cultural:

"/tiene por fin particular todo lo relacionado con la promoción,/
/estímulo, apoyo y desarrollo de cuantas acciones culturales,/
/educativas y de otra índole tengan relación con el Museo/"

***** Definición de empresa
La *empresa* es una organización que /transforma/ un conjunto de recursos
físicos, monetarios y cognitivos en bienes y/o servicios, con el objetivo
principal de /obtener beneficios/.

****** Autores
Otras definiciones de empresa.

 - Unidad técnico-económica que combina elementos humanos y financieros.
 - Una organización con ánimo de lucro.
 - Unidad de decisión.
 - Sistema en el que se coordinan factores de producción.
 - Conjunto de factores de producción.

***** ¿Es el beneficio el único objetivo?
Hay posiciones distintas.

****** Friedman
Sí, hay que maximizarlo teniendo como únicas restricciones

 * las leyes,
 * las normas de la economía capitalista, y
 * evitar engaños y fraudes.

****** Freeman
No, no sólo hay que maximizar el beneficio, también hay que satisfacer
a los *stakeholders*, que son todas las personas que tienen intereses en
la compañía.

***** Stakeholder
Los *stakeholders* son todas las partes interesadas en una empresa. Pueden
ser

 * *internas*, como los empleados, gerentes y propietarios.
 * *externas*, como los proveedores, clientes y la sociedad.

Originalmente, los stakeholders se definieron como los miembros de los grupos
sin cuyo apoyo la empresa dejaría de existir.

***** La empresa social
Las *empresas sociales* nacen con el objetivo de resolver problemas
sociales. No tienen ánimo de lucro, sino que buscan un objetivo
social.

Organizaciones con ánimo de lucro y sin ánimo de lucro pueden tener un
fin fundamental con beneficio social, medioambiental o político. Pero
a las empresas sociales se les exige que sean rentables por sí mismas.

En su filosofía se incluye que no reemplaza a la empresa tradicional,
sino que que quiere coexistir con ella. Como ejemplos:

 - plataformas sociales, como /Ashoka/ y /SocialEmprende/.
 - /DBS/.

***** Tipos de responsabilidad jurídica
Existen varias formas de responsabilidad, que indican cómo responderá la
empresa ante las posibles pérdidas. La responsabilidad puede ser limitada
o ilimitada y solidaria o mancomunada.

****** Responsabilidad ilimitada
Se llama *responsabilidad ilimitada* cuando el propietario responde
con todo el patrimonio ante las posibles pérdidas de la
empresa. Existe cuando éste realiza la actividad con su propia persona
como personalidad jurídica.

****** Responsabilidad limitada
Se llama *responsabilidad limitada* a aquella que no obliga a responder
con el patrimonio a los socios ante posibles pérdidas. La responsabilidad
de cada socio está limitada por sus aportaciones.

****** Responsabilidad solidaria
La *responsabilidad solidaria* se reparte entre los socios equitativamente.

****** Responsabilidad mancomunada
La *responsabilidad mancomunada* hace que cada socio responda por su parte.

***** Clasificación de empresas según forma jurídica (individuales)
Constituidas por una persona física, que sigue usando su NIF y tributando
mediante el IRPF.

****** Empresario individual
Cuando el *empresario individual* responde por la empresa de manera
ilimitada. Se constituye como una mera persona física, que responde
con su patrimonio, utiliza su NIF como persona jurídica y paga el IRPF.

****** Emprendedor de responsabilidad limitada
El *emprendedor de responsabilidad limitada* es una forma jurídica
permitida según ciertos criterios. La única diferencia es que la
responsabilidad del empresario individual pasa a limitarse. 

Aun así, sigue siendo un empresario individual. No tiene CIF y paga el
IRPF.

***** Clasificación de empresas según forma jurídica (societarias)
En una *forma societaria*, varias personas aportan capital o trabajo
bajo un contrato de asociación que da lugar a una personalidad jurídica
nueva.

****** Sociedad colectiva
En una *sociedad colectiva* la responsabilidad es /ilimitada y
mancomunada/ entre los socios, pero sólo participan del beneficio por
la parte que han aportado de capital y trabajo.

****** Sociedad comanditaria
En una *socidedad comanditaria* existen dos tipos de socios

 - *socios colectivos*, similares a los de las sociedades colectivas,
   aportando trabajo y capital y con responsabilidad ilimitada.
 - *socios comanditarios*, sólo aportan capital y no trabajan en la
   empresa. Su responsabilidad se limita a su capital y sus beneficios
   son proporcionales a su aportación.

****** Sociedad limitada (SL)
En una *sociedad limitada* el capital se divide en *participaciones 
sociales*. Estas se diferencian de las /acciones/ en que existen obstáculos
legales a su transmisión directa; sólo pueden ser transmitidas si da el
visto bueno una /junta de socios/ o la transmisión se hace a familiares o a
otros socios.

Tiene trámites más costosos y lentos que otras formas societarias de
responsabilidad ilimitada. El capital social en ellas no puede ser inferior
a los 3000€ mínimos iniciales.

****** Sociedad de responsabilidad limitada unitaria (SLU)
Hay una *sociedad de responsabilidad limitada unitaria* cuando existe un
socio único, que debe cumplir con una declaración de unipersonalidad y que
puede tomar decisiones unilateralmente.

****** Sociedad de responsabilidad limitada nueva empresa (SLNE)
La *sociedad limitada nueva empresa* es una especialización de la
sociedad limitada que facilita su creción. Se da de alta en un
procedimiento telemático de 48 horas y se utilizan modelos genéricos
para constituirla.

****** Sociedad anónima (SA)
En una *sociedad anónima*, el capital se divide en partes iguales
(alícuotas) llamadas *acciones*. Las acciones se transmiten libremente
en el mercado financiero a terceros, suelen representar un voto y la
responsabilidad de los socios o /accionistas/ se limita a su
aportación. Es el único tipo de sociedad que puede cotizar en Bolsa.

Necesita 60000€ como capital mínimo inicial.

****** Empresas de economía social
Las *empresas de economía social* suelen constituirse para solventar
crisis de las empresas. Suelen ser democráticas.

******* Sociedades cooperativas (SC)
Las *sociedades cooperativas* no tienen ánimo de lucro. Cada socio
aporta capital y trabajo; responde sólo con el capital aportado y
tiene un voto independientemente del capital. Es /limitada/ y 
/solidaria/.

Estas uniones de trabajo asociado suelen darse cuando los trabajadores
tienen un objetivo común fuerte. Tienen regulación estatal y
autonómica y en ocasiones exenciones fiscales (las andaluzas se llaman
SCA).

El beneficio se llama /retorno/. Las reservas (la parte del beneficio
que no se distribuye entre los socios), suelen ser más grandes. Suelen
tener una reserva obligatoria para invertir en la formación de los
socios.

/Ejemplo: cooperativa Mondragón/

******* Sociedades laborales
Las *sociedades laborales* son sociedades anónimas o de responsabilidad
limitada donde los trabajadores poseen al menos el 51% del capital.

Suelen ser intentos de los trabajadores de evitar la quiebra de la
empresa.

***** Clasificación de empresas según tamaño
La clasificación según tamaño se realiza en base a varios criterios, tales
como

 * *número de trabajadores* contratados en la empresa.

 * *volumen de negocio anual*, el total de ingresos por ventas
   contabilizadas. Equivale al valor total de los bienes y servicios
   vendidos en un año.

 * *balance general anual (activo)*, bienes y derechos de la empresa, sin
   contar las obligaciones de pago, que pertenecerían al /pasivo/.

Por ellos se dividen en: grandes, medianas, pequeñas y
microempresas. El 99.9% de empresas en España son PYMEs (pequeñas y
medianas empresas).

****** Empresas autónomas o asociadas
En el caso de que la empresa tenga relación con otras, sus datos
deberán incluirse al calcular su tamaño. Una empresa se clasifica
según su relación con otras en

  * *autónoma* si es totalmente independiente y no tiene participación en
    otras empresas, ni otras empresas en ella.
  * *asociada* si hay terceros con más del 25% de la empresa o tiene
    participación de más del 25% en otra empresa.

Aun así existen empresas que se consideran autónomas a pesar de esto.
Además, dos empresas están *vinculadas* cuando una puede ejercer
influencia dominante sobre la otra, ya sea nombrando miembros del
consejo de administración, mediante cláusulas estatutarias o contratos.

**** 1.2. Enfoque sistémico de la empresa
***** Definición de sistema
Un *sistema* es un conjunto de elementos relacionados dinámicamente que
realizan una actividad para alcanzar un objetivo; operando con entradas
y proveyendo salidas.

***** Condiciones para la existencia de un sistema
Para considerar algo un sistema se le exigen

 * un *conjunto de elementos*, los factores productivos.
 * una *estructura de sistema*, jerarquía de la empresa.
 * un *plan común*, la misión de la empresa.
 * unas *funciones características*, las funciones técnicas y
   administrativas que desarrollan la actividad.
 * un *conjunto de estados*, el balance de la empresa.

La empresa transforma materias primas (proceso técnico), transforma
ahorro en capital (proceso financiero) y procesa información (proceso
mental).

***** Clasificación de sistemas
Se clasifican en

 * *abiertos* si se relacionan con el entorno.
 * *cerrados* si no interaccionan con el entorno.
 * *naturales* si no influye el ser humano en su creación.
 * *artificiales* si se crean por voluntad humana.

La empresa se considera un sistema abierto artificial.

***** Retroalimentación o feedback
La empresa se considera *autorregulada* porque cuando se desvía de los
objetivos, el proceso de *retroalimentación o feedback* permite
conocer a la empresa que se han producido estas desviaciones y
corregirlas. Puede así adaptarse al entorno.

La *homeostasis* es la capacidad de la empresa de mantener esa
estabilidad.

**** 1.3. Subsistemas funcionales de la empresa
***** Principio de jerarquía
El *principio de jerarquía* permite descomponer un sistema en
subsistemas y estudiarlos concretamente.

***** Subsistemas según criterio funcional
El *criterio funcional* de jerarquización divide a la empresa en tantos
subsistemas como actividades desarrolle. Estos son

 * *subsistema de aprovisionamiento*, que adquiere los insumos.
 * *subsistema de producción*, transforma insumos en productos.
 * *subsistema de comercialización*, decide precio, promoción y
   distribución.
 * *subsistema de recursos humanos*, selecciona y orienta
   trabajadores.
 * *subsistema financiero*, decide los fondos y aplica inversiones.
 * *subsistema de dirección*, estrategia y gestión de la empresa.

***** Sinergia
La *sinergia* es el aumento de productividad de varios sistemas cuando
interactúan entre ellos frente a cuando trabajan de manera aislada.

**** 1.4. La dirección de empresas
***** Eficiencia y eficacia
La *eficacia* mide el nivel de cumplimiento de los objetivos. La *eficiencia*
mide el uso de la cantidad adecuada de recursos para lograr sus objetivos.

Una empresa bien dirigida debe ser eficaz y eficiente.

***** Funciones de los administradores
La gestión empresarial define las siguientes *funciones del directivo*, que
son propias del subsistema de management o dirección.

 * La *planificación* define la estrategia de la empresa y los planes para
   conseguir los objetivos.
 * La *organización* diseña la estructura para realizar las tareas,
   asignando personal y decidiendo cómo se tomarán decisiones.
 * La *dirección* coordina a la organización, motivando, comunicando y
   resolviendo potenciales conflictos.
 * El *control* vigila el desempeño de la organización, lo compara con
   los objetivos y lo corrige en caso de que sea necesario.

*** 2. Teorías de la empresa y del empresario
**** 2.1. Teorías de la empresa
# Nada

**** 2.2. Teorías del empresario
***** Evolución histórica del empresario
Se consideran figuras distintas según la época, en

 * *capitalismo mercantilista* (S. XVI-XVIII), existe un estado que es el
   agente económico predominante y mercaderes, que simplemente comercian.
 * *revolución industrial* (S. XVIII-XIX), se desarrolla el pensamiento
   clásico capitalista del empresario *Adam Smith* habla de la regulación
   del mercado por la mano invisible. En el siglo XIX, *Karl Marx* explica
   el beneficio como la extracción de la plusvalía de los trabajadores
   mediante la propiedad privada de los medios de producción.
 * *aportaciones posteriores*, Cantillon define en el S. XVIII el
   /entrepreneur/ y habla del talento del empresario. Say aporta la
   función directiva en el S. XIX.

***** Teoría del empresario riesgo. Knight (1921)
*Knight* desarrolla la figura del empresario como persona que asegura las
rentas de los factores productivos, adelantando el pago. El riesgo que
asume al aportar el dinero es lo que justifica el beneficio empresarial.

Los riesgos serán

  - *técnicos*, como cumplir con la producción esperada.
  - *financieros*, al aportar el capital inicial.

***** Teoría del innovador de Schumpeter (1912)
*Schumpeter* diferencia en /Teoría del desenvolvimiento económico/
entre capitalista y empresario. El empresario será el que aplica una
tecnología existente a un problema real, el capitalista pone el dinero.

Se justifica el beneficio porque se dice que esa innovación es la que
desencadena el desarrollo económico y social.  Así, el empresario que
innova es el motor del progreso económico y social.

El cambio tecnológico se desarrolla en un ciclo entre un *monopolio*
*temporal* del empresario sobre la innovación y lo pierde luego a una
*situación de equilibrio*.

# **** Autónomos
# Nos dicen que hay menos autónomos en España que en Europa por
# culpa de las cuotas de autónomo. Aquí artículos en contra:
#
# - [[http://www.ticbeat.com/empresa-b2b/desmontando-el-mito-de-la-cuota-de-autonomos-en-espana-y-europa/][Desmontando el mito de la cuota de autónomos en España]]
# - [[http://www.elderecho.com/actualidad/Espana-quinto-Europa-autonomos-ATA_0_457500143.html][España, quinto país de Europa que más autónomos crea con 46.000 nuevas altas]]
#
# Pero hay miles a favor también. Ojalá manejáramos datos.

****** Proceso de cambio tecnológico
Se definen tres fases

 - *invención*, generación de nuevas ideas, ajena a la actividad empresarial.
 - *innovación*, aplicación de la invención a un producto.
 - *imitación*, difusión de la innovación.

***** Tecnoestructura de Galbraith (1950s)
*Galbraith* supera la concepción de empresario como persona y deja que
delegue en la /tecnoestructura/, un grupo de personas, un órgano
colegiado, que dirige la empresa.

Separa propietario (capital de la empresa) y gestor (administración).

**** 2.3. Propiedad, dirección y gobierno de la empresa
***** Definición de directivo
El *directivo* supervisa la combinación de los recursos productivos. Sus
funciones son

 * fijar objetivos y toma decisiones.
 * coordinar la empresa.
 * coordinar relación de la empresa con el entorno.

Los directivos suelen ser los mismos propietarios, pero pueden ser gestores
contratados u otras personas al nombre del propietario.

***** Definición de capitalista
El *capitalista* es el propietario del capital de la empresa.

***** Empresario
El *empresario* es un directivo capitalista. 

/Ejemplos: Amancio, Florentino./

****** Emprendedor
Llamamos *emprendedor* al empresario que es a su vez el creador de la
idea del negocio o del cambio y se implica a nivel gestor y
capitalista.

****** Empresario individual propietario
Según Cuervo (1997), es el empresario clásico en el que convergen 
capitalista y directivo; sigue las nociones de [[*Teoría del empresario riesgo. Knight (1921)][empresario riesgo]] y
[[*Teoría del innovador de Schumpeter (1912)][empresario innovador]].

****** Empresario corporativo
Controla la empresa sin participar significativamente en el capital.
Es parte sólo de la tecnoestructura.

***** Estructura de la propiedad de la empresa
La *estructura de la propiedad* de una empresa es el modo en el que se
distribuye la propiedad del capital de la empresa entre sus
propietarios legales. Todo partícipe en el capital de la empresa tiene
la consideración legal de *propietario*; es decir, los propietarios
son las personas (físicas y jurídicas) que aportan el dinero y los
bienes necesarios para la actividad productiva.

Los propietarios pueden haber accedido a la titularidad

  * creándola.
  * heredándola.
  * comprándola.

****** Grupos de propiedad
Se consideran los siguientes grupos de propiedad en la empresa

 * sector público.
 * particulares y familias.
 * empresas industriales y servicios (capital empresarial).
 * entidades financieras (capital bancario).

La estructura de la propiedad refleja la importancia relativa de los
grupos. Varía según sectores y países y condiciona los objetivos que
persigue la empresa.

***** Estructura accionarial
La /estructura de la propiedad/ en sociedades anónimas se distribuye
entre los *accionistas*. Los hay de dos tipos

 * *accionistas de control*, si son activos en las decisiones de la
   empresa.
 * *accionistas pasivos*, si son simples inversores financieros.

La estructura accionarial completa se divide en

 * *Autocartera*, las acciones propias que la sociedad mantiene entre
   sus activos.
 * *Accionistas mayoritarios y de control*, que tienen control de la
   empresa.
 * *Pequeños accionistas*, capital flotante en compraventa libre en el
   mercado financiero. Son propietarios sin poder en la empresa, para
   controlarla necesitan asociarse.
 * *Inversores institucionales*, sociedades de inversión, fondos de
   pensiones o compañías de seguros que buscan la rentabilidad.

***** Gobierno corporativo
El *gobierno corporativo* es la estructura que concreta las relaciones
entre todos los /stakeholders/ para establecer los objetivos de la empresa
y los medios para controlarla.

****** Motivación
Cuando las empresas son pequeñas, suele coincidir la propiedad y la
gestión. Conforme crecen, deben dotarse de estructuras que limiten
conflictos y aseguren que los directores no toman decisiones
contrarias a los propietarios.

Se intenta paliar un problema que surge en un contexto de información
asimétrica; donde las partes interesadas pueden tener intereses
contrarios a la empresa.

****** Responsabilidad social corporativa
Los criterios de *responsabilidad social corporativa* (RSC) son códigos
de buen gobierno que buscan asegurar
 
 * la confianza y la transparencia.
 * el adecuado funcionamiento de los órganos y la separación entre ellos.
 * el control interno y la responsabilidad.

En particular, las empresas que cotizan en la comisión del mercado de
valores deben seguir un código de gobierno específico.

***** Mecanismos de control
Los *mecanismos de control* delimitan el modelo de gobierno corporativo que
sigue la empresa.

***** Mecanismos internos de control
Los *mecanismos internos* son los diseñados por la propia organización.

****** Junta general de socios accionistas
En una /sociedad anónima/, la *Junta General de Socios* es una reunión
de accionistas que toma acuerdos por mayoría. 

Sus competencias son:

 * nombrar al consejo de administración.
 * nombrar y destituir administradores.
 * disolver la sociedad.
 * elegir consejero ejecutivo.
 * adquirir de determinados bienes y tomar otras decisiones.

Es obligatoria y debe reunirse anualmente. Nótese que no puede
administrar, tomar acuerdos contrarios a los estatutos o representar a
la sociedad; sólo puede nombrar a los /administradores/.

****** Consejo de administración
En /sociedades de capital/ (limitadas, anónimas y comandatarias), el
*consejo de administración* está formado por personas elegidas por los
propietarios que administran y representan a la empresa.

Está compuesto por:

 * *Consejeros internos o ejecutivos.* Delegados de la
   empresa. /Ejemplo: Jobs, Zuckerberg./
 * *Consejeros externos dominicales.* Significativos. Representan
   empresas con capital en la sociedad.
 * *Consejeros externos independientes.* Expertos en gestión que son
   independientes. /Ejemplo: Felipe González, José María Aznar./

****** Caso de las empresas pequeñas
Normalmente coinciden. Sólo a partir de cierto tamaño tienen que
nombrar administradores.

***** Mecanismos externos de control
Los *mecanismos externos* son los que se derivan de la estructura de la
economía de mercado.

****** Oferta Pública de Adquisición de Valores (OPA)
Intenta comprar parte de una empresa para controlar sus cambios de
dirección. Puede intentarse por alterar su estructura financiera o
para construir imperios empresariales.

****** Mercados financieros
Con los fondos se determinará el valor de la empresa y la posibilidad
de ser controlada desde el exterior.

****** Mercado laboral de consejeros y directivos
La alta competencia del mercado laboral de consejeros y directivos hace
que funcionen correctamente. Se compra su reputación positiva, que deben
haber ganado en otras empresas previamente.

**** 2.4. La dirección: funciones y niveles
La *dirección* consiste en la integración de las distintas partes de la
empresa entre sí. Se divide en varios niveles de jerarquización de las 
decisiones.

***** Alta dirección
La *alta dirección* está formada por personas con responsabilidad
sobre toda la empresa que fijan los grandes objetivos.  Lo forma el
/comité ejecutivo/ de la empresa con el /director ejecutivo/ (también
consejero delegado o CEO) y las personas que considere para participar
de los análisis gestores de la empresa. 

/CEOs, Comité Ejecutivo, Presidente Ejecutivo, Consejero Delegado./

***** Dirección media
La *dirección media* la forman los directivos que actúan como enlace
jerárquico entre la alta dirección y la dirección de primera línea.
Marcan objetivos a medio y corto plazo, que deben estar alineados con
los grandes objetivos.

/Directores departamentales, director financiero, director comercial./

***** Dirección de primera línea
La *dirección de primera línea* la constituyen supervisores y directivos
que toman decisiones en problemas diarios y rutinarios para la empresa.

/Jefes de equipo, capataces, jefe de planta./

*** 3. Entorno de la empresa
**** Objetivos
Conocer:

 - Análisis de entorno. PEST.
 - Comprender su utilidad en la dirección estratégica.

En conjunto forma el análisis DAFO.

***** Análisis externo: amenazas y oportunidades
Provenientes del entorno.

 * *Amenaza*, aspecto negativo del entorno.
 * *Oportunidad*, aspecto positivo del entorno.

***** Análisis interno: debilidades y fortalezas
Provenientes de la propia empresa.

 * *Debilidad*, aspecto negativo interno.
 * *Fortaleza*, aspecto positivo interno.

**** 3.1. Definición de entorno
Entendiendo la empresa como un sistema abierto que se relaciona con el
exterior, tiene sentido estudiar el entorno como el conjunto de
fuerzas externas con las que se relaciona. 

***** Definición de entorno
El *entorno* es el conjunto de factores que, siendo /externos/ a la
empresa, tienen o pueden tener incidencia en sus actuaciones y
resultados. La viabilidad depende de la empresa depende de ellos.

*(!) Nada que sea parte de la empresa es entorno de la empresa.*

****** Definición de Downey y Slocum
El *entorno* es un conjunto de personas y grupos con las que la
organización tiene relaciones de intercambio y de las que depende su
viabilidad.

****** Definición de Mintzberg
El *entorno* es todo aquello ajeno a la empresa como organización.

***** Relación con el entorno
Según sus decisiones cambia su relación con el entorno. La empresa
puede influir, pero no controlar el entorno.

****** Factores estratégicos
El entorno está formado por los *factores estratégicos*, que son todos
los factores que pueden incidir en las actuaciones de la empresa son
los factores estratégicos, tanto en el presente como en el futuro. Son
*amenazas* y *oportunidades*.

****** Entorno relevante
La influencia del entorno puede ser diferente según tiempo y
organización. Los factores estratégicos son los más influyentes y
sobre los que centra la atención el análisis de entorno; aquellos
que afectan a la empresa son parte de su entornro relevante.

****** Análisis del entorno
Debe sistematizarse el análisis de los factores estratégicos para 
tratar de estar preparado y anticiparse a los cambios.

***** Límites del entorno
Los límites del entorno varían según la relación con el exterior.
Los proveedores pueden considerarse internos a la empresa. Son los
llamados *límites difusos*.

***** Niveles del entorno
Según /Bueno (2002)/, se establecen varios niveles del entorno según
el ámbito geográfico.

 * Entorno *global*, a nivel mundial.
 * Entorno *internacional*, a nivel de una región internacional.
 * Entorno *nacional o doméstico*, a nivel del país.
 * Entorno *regional*, dentro de un país o varios países.
 * Entorno *local*, a nivel de un núcleo urbano.
 
La mayoría de las empresas en la actualidad funcionan a niveles globales,
debido a la /globalización/ de la actividad económica.

**** 3.2. Características del entorno
Las *características del entorno* son los atributos a los que se enfrenta
una organización. 

Identifica /características o atributos/ que definen unos entornos
frente a otros.

***** Entorno como fuente de recursos
La idea del entorno como *fuente de recursos* aparece en las teorías de
Aldrich, Pfeffer y Salancik. Estas fuentes de recursos se caracterizan por

 * si los recursos son *abundantes*.
 * si los recursos son *variados*.
 * si están *concentrados*.
 * si otras empresas *compiten* por ellos.

En base a estas características se consideran distintos tipos de entorno.

****** Estable-Aleatorio
En un entorno *estable-aleatorio*, no hay competencia por los recursos,
están distribuidos y son abundantes.

/Ultramarinos de un pueblo. No hay competencia pero hay demanda estable./

****** Plácido-Integrado
En un entorno *plácido-integrado*, los recursos son estables pero están
concentrados; haciendo algunas posiciones en el entorno más ventajosas
que otras.

/Silicon Valley aprovecha recursos tecnológicos de la zona./

****** Inestable-Reactivo
En un entorno *inestable-reactivo* los cambios son pocos pero
existen varias empresas con las mismas necesidades de recursos. Todos
los movimientos por los recursos serán respondidos por los
competidores.

/Empresas de software intentando captar empleados./

****** Turbulento
En un entorno *turbulento* existe competencia entre las empresas y
además las condiciones y los recursos están en continuo cambio.

/Empresas en zonas de inestabilidad política./

***** Entorno como fuente de incertidumbre
La idea del entorno como *fuente de incertidumbre* aparece en las
teorías de Duncan, Lawrence y Lorsch. Se considera el entorno como una
fuente de información sobre la que la empresa toma decisiones. Estas
fuentes de información se caracterizan por

 * la *predecibilidad e incertidumbre*, que viene dada por la cantidad
   de información a la que se puede acceder en el entorno.

Se establecen cuatro dimensiones para medirlo.

****** Dinámico/Estable
Un entorno es *dinámico* si hay variaciones numerosas e impredecibles;
y es *estable* si no hay cambios o son muy predecibles.

****** Complejo/Sencillo
Un entorno es *complejo* cuando se necesitan muchos conocimientos
específicos para entenderlo; y *sencillo* cuando el conocimento es
comprensible.

****** Diverso/Integrado
Un entorno es *diverso* cuando hay un gran número de clientes
distintos a los que abastecer; e *integrado* cuando son todos
similares y se concentran en áreas próximas.

****** Hostil/Munificiente
Un entorno es *hostil* cuando existe mucha competencia por los
recursos; y *munificiente* cuando la competencia es pequeña.

***** Entorno general
El *entorno general* está integrado por un conjunto de factores que
ejercen influencia sobre todas las empresas dentro de un sistema
socioeconómico.

****** Definición de Cuervo (2001)
El *entorno genérico* agrupo los elementos que afectan de manera
similar a todas las empresas en un espacio dado independientemente
de su sector.

***** Entorno general: Análisis PESTEL
El *análisis PESTEL* tiene como objetivo diagnosticar el entorno
general valorando el impacto que varias variables tienen en la
actuación de la empresa. Identifica las principales oportunidades y
amenazas.

****** Variables
El análisis *PESTEL* analiza las dimensiones

 * *política*, dada por la estabilidad, proteccionismo e
   intervencionismo del estado. Nivel de corrupción de un país.

 * *económica*, dada por factores económicos como

   - la /inflación/, maracada por el IPC y los precios al
     consumo. Hay inflación y deflación según suban o bajen.
   - la /tasa de desempleo/.
   - el /tipo de cambio/ frente al dólar como base.
   - la /renta disponible/ de las familias, corregida por inflación.
   - los /tipos de interés/.

 * *social*, dada por preferencias como valores, creencias,
   desigualdad, religión, feminismo, tradición, cultura.

 * *tecnológica*, dada por el grado de infraestructuras del
   país. Gasto en I+D. Inversión pública del gobierno y
   patentes. Leyes de proyección del conocimiento.

 * *ecológica*, dada por la política medioambiental y el consumo de
   energía.

 * *legal*, dada por la legislación laboral, la normativa de fusiones
   y adquisiciones y las restricciones a la libre competencia.

****** Etapas del análisis
El análisis PEST se divide en varias etapas

 * en el *Paso 1*, se delimitan los factores estratégicos y se estudia
   qué variables pueden tener más incidencia sobre la empresa. Se
   estudian /variables y factores clave/.

 * en el *Paso 2*, se describe la evolución esperada de los factores
   estratégicos del entorno.

 * en el *Paso 3*, se valoran y jerarquizan las oportunidades y
   amenazas.

****** Realización de la tabla y perfil estratégico del entorno
Todo el análisis puede representarse en una tabla plantilla que
considera los factores principales del entorno. Pueden colocarse
también en un perfil estratégico del entorno.

****** Consideraciones sobre el análisis PEST
El análisis PEST proporciona una herramienta fácil de usar e
interpretar, pero tiene el problema de que

 * es un análisis muy subjetivo y cualitativo. 
 * este análisis debe entrar en detalles y por tanto debe tratar los
   factores más relevantes.
 * no todas las variables estarán en un análisis PEST. Hay que ser
   selectivos y sólo considerar los factores estratégicos.
 * el impacto de un mismo entorno puede variar entre distintas
   industrias y entre empresas de una misma industria.

En ocasiones se utiliza el análisis PESTEL como una ampliación del
análisis PEST.

***** Entorno general: Diamante de Porter
***** Entorno específico
El *entorno específico o competitivo* lo forma el conjunto de empresas
que se dedican a la misma actividad económica que la empresa que se
está analizando y que conforman su /sector/. El entorno específico
marca las reglas de competencia.

****** Componentes de Hall (1996)
Según Hall, el entorno específico está formado por

 * *proovedores* de los recursos necesarios.
 * *clientes*, que consumen los productos.
 * *competidores*, que compiten por los recursos y clientes.
 * *reguladores* que controlan y fiscalizan a las organizaciones.

***** Entorno específico: Modelo de Porter (2009)
El *modelo de las cinco fuerzas competitivas de Porter*, desarrollado
en el 2009 mide el /grado de atractivo/ de una industria por cinco
fuerzas competitivas básicas, que definen la posibilidad de obtener
rentas superiores en la industria. A más rivalidad, menos posibilidad
de obtener rentas superiores.

También se llama *modelo de rivalidad ampliada*.

****** 1. Competidores actuales
Grado de rivalidad con los competidores del sector. La amenaza que
representan depende de varios factores.

******* Número y equilibrio entre competidores
En las *industrias concentradas* hay pocos competidores y están muy
desequilibrados formando oligopolios; no hay competencia. En las
*industrias fragmentadas* hay muchos competidores y están equilibrados,
por lo que la competencia es mayor.

/Un ejemplo de industria concentrada es la farmacéutica./
/Un ejemplo de industria fragmentada son los bares./

******* Ritmo de crecimiento del sector
El ritmo de crecimiento determina la competencia. Cuanto más reciente
es el sector, menos competencia hay. Según el ritmo de crecimiento una
industria se consideran las fases de

 * *introducción*, donde la industria se está creando. Un ejemplo
   son los coches autónomos.

 * *crecimiento*, donde hay oportunidades y /menos competencia/. Un 
   ejemplo son los drones.

 * *madurez*, donde la industria se estabiliza. Un ejemplo son los
   electrodomésticos.
   
 * *declive*, donde las ventas se reparten y hay /más competencia/.
   Un ejemplo son los SMS.

Y la posibilidad de incrementar las ventas es más difícil
después. La intensidad de la competencia es mayor conforme
avanza.

******* Barreras de movilidad
Las *barreras de movilidad* son las que se encuentran las empresas
para ampliar su línea de productos a otros segmentos. Si hay muchas
barreras, las empresas se quedarán donde están y la competencia del
sector será menor.

******** Ejemplo: banca privada
Es muy difícil iniciarse en la banca privada. Hay unas barreras muy
grandes entre servicios usuales y los servicios privados. Los
contratos suelen estar blindados y los canales de distribución suelen
trabajar con las marcas que ya conocen.

******** Ejemplo: automoción
Sólo unas pocas fabrican coches y camiones. Es difícil saltar del
diseño de unos al diseño de otros; se necesita tecnología, cadenas
y materiales diferentes.

******* Barreras de salida
Las *barreras de salida* son el equivalente a la movilidad a nivel
del sector. Cuanto más difícil sea salir del sector, más se intentará
sobrevivir y mayor será la competencia.

******** Ejemplo: activos especializados
Si hay activos especializados que no se amortizan, y que por ser tan
específicos, es muy difícil vender.

******** Ejemplo: costes fijos de salida
Para cerrar, hay que hacer frente a costes como los costes de
despidos. Las empresas que no quieren pagarlos, se mantienen en el
sector.

******** Ejemplo: imagen de marca
En ocasiones se mantiene un sector sólo para mantener el prestigio de
la imagen de marca. El daño a la imagen es un coste de salida.

******** Ejemplo: empresas familiares
La barrera emocional de seguir negocio familiar tradicional constituye
una barrera de salida. Están dispuestas a continuar a pesar de las
pérdidas.

El ejemplo usual es la /almazara/.

******** Ejemplo: presiones externas
Fábricas que emplean a mucha gente en una región tienen la presión
externa para seguir empleando a la gente.

******* Estructura de costes de las empresas
Un mayor peso de los costes fijos en la *estructura de costes* lleva
a operar a plena capacidad y por tanto a incrementar la intensidad
competitiva.

******** Estructura de costes
La *estructura de costes* es la proporción entre costes fijos y
costes variables que cumplen $CT = CF + CV$ siendo
 
 * CF: los *costes fijos*. Hay que pagarlos siempre.
 * CV: los *costes variables*. Se pagan según cuánto produzcas.
 * CT: los *costes totales*.

******** Margen de beneficio
El margen de beneficio es la diferencia del precio y el coste de
producción unitario $\mathrm{margen_{unitario}} = p - c_v$. El margen bruto es el
margen unitario por número de unidades

\[\mathrm{margen} = u(p - c_v).
\]

Nótese que es distinto del beneficio (!), que tiene en cuenta también
los costes fijos. El beneficio es $B = \mathrm{Ingresos} - CT$.

Así, cuando los costes fijos son muy grandes, es muy difícil entrar
en la competencia, así que la competencia será menor. El *punto muerto*
es el punto a partir del cual se van a obtener beneficios.

******* Grado de diferenciación de los productos/servicios
La *diferenciación* de productos disminuye la intensidad de la
competencia. Cada uno vende cosas distintas y tiene una cartera de
clientes fieles que es difícil que cambien de proveedor.

/Ejemplo: compañías telefónicas tienen poca diferenciación./
/Ejemplo: las bebidas son diferentes./

******* Costes de cambio
Los *costes de cambio* son los que debe asumir un cliente para cambiar
de proveedor. Cuantos más altos, más difícil es que cambie un cliente
y menor es la competencia. Pueden ser técnicos, de formación o
financieros.

/Ejemplo: es difícil el cambio de compañía telefónica por permanencias./

******* Capacidad productiva instalada
Cuando más *capacidad productiva* instalada, hay más necesidad de
vender los productos, y más alta es la competencia.

/Un planta produciendo 1000 unidades/día debe producir a ese volumen./ 

******* Diversidad de competidores
Si los competidores difieren en estrategias, puede aumentar la
competitividad.

******* Intereses estratégicos
Cuando todas las empresas están interesadas en el sector, mayor será
la competencia.

****** 2. Competidores potenciales
Los *competidores potenciales* son las empresas potencialmente
interesadas en entrar en el sector. La amenaza depende de dos
factores.

******* Barreras de entrada
Las *barreras de entrada* son los obstáculos que enfrentan las
empresas para entrar al sector. Se resumen en

 1. la *economía de escala*. Las empresas que entran al sector deben
    hacerlo a gran escala para beneficiarse de las reducciones de
    costes que da el incremento de volumen productivo; esto supone
    una barrera para los nuevos. Al caso contrario se le llama una
    /deseconomía de escala/. La sinergia es una causa de la economía
    de escala.

 2. la *diferenciación de productos*. Cuando todos tienen
    diferenciados sus productos, para entrar al sector habrá que
    ofrecer algo diferente para poder competir al mismo nivel.

 3. las *necesidades de capital*. Un sector que necesita una inversión
    muy grande tiene una barrera de entrada muy grande.

 4. los *costes de cambio*. Si los clientes están fidelizados, el que
    entre nuevo en el sector va a tener que saltar la barrera de los
    costes de cambio.

 5. el *acceso a canales de distribución*, que normalmente estarán en
    manos de las empresas del sector.

 6. las desventajas en *costes de desarrollo*. Hay que pagar patentes
    o desarrollar tecnologías alternativas. Hay que encontrar buenas
    localizaciones, que las tienen las empresas del sector. La
    experiencia del sector la tienen las empresas.

 7. la *política gubernamental*. Pueden existir restricciones que
    limitan la entrada al sector. Normas reguladoras de la competencia
    que impiden la libre competencia en el mercado.

******* Represalias esperadas
Represalias de los competidores que están ya en el sector contra
los nuevos competidores. Las represalias son mayores cuanto más
recursos de defensa pueden invertir en la represalia.

/Empresas como las teleoperadoras pueden ejercerlos contra nuevas
empresas./

****** 3. Productos sustitutivos
Los *productos sustitutivos* son aquellos que cubren las mismas
funciones desde el punto de vista de los clientes usando otra tecnología
u otras materias primas.

Si hay muchos productos sustitutivos, será menos atractivo el sector;
dependerá además de

  * el grado de *sustitución*.
  * los *precios relativos* al sustitutivo.
  * *obsolescencia* que causan los sustitutivos.
  * *costes de cambio* al sustitutivo.

Pueden no tener siquiera el mismo CNAE, y no los consideramos dentro
del mismo sector, pero hay competencia entre ellos.

/Ejemplo: azúcar y sacarina./

/Ejemplo: aceite oliva y el girasol./

****** 4. Proveedores
A mayor poder de *negociación de los proveedores*, más podrán influir en
el coste o los plazos de entrega de las empresas del sector. Cuanto
más concentrados estén y menos sustitutos haya para los proveedores,
más poder de negociación tendrán.

******* Integración vertical
La *integración vertical* es el proceso por el cual un proveedor o
un cliente pasa a integrar otra parte de la cadena de producción.

El poder de negociación del proveedor aumenta cuanto más informado
esté el proveedor y más fácil sea que entre en el sector por
integración vertical.

/Ejemplo: Inditex realiza integración hacia atrás al producir tela./

/Ejemplo: Apple realiza integración hacia alante al crear tiendas./
******* Número de proveedores y grado de concentración
******* Grado de diferenciación de los proveedores
******* Existencia de productos sustitutos al del proveedor
******* Importancia de nuestra empresa para el proveedor
******* Nivel y calidad de la información
****** 5. Clientes
A mayor poder de *negociación de los clientes*, más podrán influir en
lo que debe producir la empresa.

******* Número de clientes y grado de concentración
******* Grado de diferenciación de los productos
******* Existencia de sustitutos al producto
******* Amenaza de integración vertical
******* Información de la que dispone el cliente
***** Entorno específico: limitaciones y extensiones del modelo
Al modelo de las 5 fuerzas de Porter se le plantean las siguientes
críticas y limitaciones

 * tiene un *carácter estático*, requiere de una actualización del
   análisis siempre que se pueda.
 * no tiene en cuenta *industrias auxiliares* y complementarias; no
   considera relaciones de colaboración.
 * la realidad es *heterogénea*, no todas las fuerzas ni todos los
   factores tienen la misma influencia.
 * no todos los *competidores* se encuentran afectados de la misma
   manera por las fuerzas del sistema. (Se intenta salvar esto
   mediante el análisis de los sectores estratégicos, que aplica un
   análisis particular en los distintos grupos estratégicos; es
   distinta la competencia de Inditex y la de una pequeña textil)

*** 4. La dirección estratégica
**** 4.1. Concepto de dirección estratégica
La *dirección de empresa* es la gestión diaria de la misma para lograr
eficacia y eficiencia. Este concepto contrastará con la idea de
dirección estratégica.

***** Concepto de estrategia
La *dirección estratégica* es el proceso de diseño e implantación de
una estrategia con la que responder al entorno. 

La idea de la dirección estratégica surge porque la empresa debe
responder a un entorno que es turbulento y que presenta debilidades y
amenazas.

****** Estrategia
Del griego /stratos/ (ejército), /ego/ (líder, guía); se entiende
como la guía que marca el camino de la empresa hacia unos objetivos.

****** Definición de estrategia (Johnson)
La *estrategia* es la dirección en el sentido de orientación a largo
plazo para lograr ventajas en un entorno cambiante para conseguir
los beneficios de los stakeholders.

****** Definición de estrategia (Porter)
La *estrategia* es una acción ofensiva o defensiva para obtener una
posición competitiva en un sector; afrontar las cinco fuerzas
competitivas y conseguir un mayor rendimiento sobre la inversión de la
empresa.

****** Definición de estrategia (Grant)
La *estrategia* define cómo desplegará la empresa sus recursos en el
entorno para satisfacer los objetivos a largo plazo. La estrategia
aporta coherencia y cohesión, dando sentido a toda la organización.

****** Definición de estrategia (Guerras y Navas)
La *estrategia* es la respuesta que se diseña para sobrevivir o para
responder al entorno.

***** Ideas básicas del concepto
El concepto de estrategia se basa
 
 * en la *respuesta* de la empresa su entorno. El entorno
   es cambiante y por tanto la estrategia también lo será.

 * Tiene el objetivo último de posicionar y mejorar la empresa frente
   a competidores. Busca la *ventaja competitiva*.

 * en conseguir los objetivos a largo plazo de los *stakeholders*.
   Refleja dónde quiere llegar la empresa.

 * en la *toma de decisiones* como proceso que la genera. Se evalúan
   distintas opciones según su ajuste a la empresa y al entorno.

 * en definir los *cursos de acción*. En la estrategia se *definen las
   decisiones* que se toman en toda la organización. El resto de
   decisiones se supeditan a ella.

***** Componentes de la estrategia: campo de actividad
El *campo de actividad* es el conjunto de productos y mercados que
componen la actividad económica de la empresa. La estrategia define
/el campo de actividad/.

Puede estar integrado por distintas *Unidades Estratégicas de Negocio*
*(UEN)*, conjuntos homogéneos para los que se puede definir una
estrategia específica para ellos y diferente a las demás.

****** Empresa diversificada
Las *empresas diversificadas* son aquellas que tienen varias Unidades
Estratégicas de Negocio, actuando en varios sectores distintos. Las
estrategias en cada uno de ellos serán distintos.

Existen dos tipos de diversificación

 * se considera *diversificación relacionada* si se pueden compartir
   proveedores, canales de distribución o partes del proceso de
   producción entre varias UEN.

 * se considera *diversificación no relacionada* si no se comparten
   partes del proceso de producción entre UEN.

/Ejemplo: Danone hace diversificación relacionada/

/Ejemplo: Virgin hace diversificación no relacionada./

****** Estrategias distintas
Cada UEN tiene una estrategia competitiva distinta porque

 * se desarrolla en un *entorno* distinto.
 * tiene *competidores* distintos.
 * tiene *oportunidades* distintas.
 * las *competencias* y capacidades requeridas son diferentes.

******** Ejemplo: grupo PRISA
Tiene varias unidades distintas de educación, noticias, audiovisual...

******** Ejemplo: Danone
Productos lácteos, agua, nutrición médica y nutrición infantil. Aunque
sean grupos similares, las estrategias serán distintas en cada uno de
ellos.

***** Componentes de la estrategia: capacidades distintivas
Las *capacidades distintivas* son el conjunto de recursos y capacidades
que permiten a la empresa realizar determinados procesos mejor que sus
competidores. Constituyen la base de la /ventaja competitiva/.

/Ejemplo: la capacidad de innovación./

***** Componentes de la estrategia: ventaja competitiva
La *ventaja competitiva* es el conjunto de características por las que
se tiene una mejor posición competitiva respecto a los competidores.

No debe confundirse con las /bases de la ventaja competitiva/, que son
todos aquellos factores que provocan la ventaja competitiva. La ventaja
competitiva es el resultado final de la formulación e implantación de
la estrategia de la empresa.

***** Componentes de la estrategia: sinergia
La *sinergia* es el efecto que hace que los recursos y capacidades
integrados ofrezcan un rendimiento mayor al que ofrecerían de forma
aislada. La integración y la conexión entre campos de actividad debe
formar parte de la estrategia.

En las empresas diversificadas las sinergias pueden conseguirse fácilmente
si la diversificación es relacionada.

***** Niveles de la estrategia
La estrategia se aborda a distintos *niveles* relacionados entre sí.
Las estrategias de cada nivel deben estar integradas y ser coherentes
entre sí. Derivan de una estrategia corporativa global.

****** Nivel de estrategia corporativa
La *estrategia corporativa* responde a la pregunta de /¿dónde competir?/.  
Es la estrategia global de la empresa, la que define el campo de actividad.

****** Nivel de estrategia competitiva o negocio
La *estrategia competitiva* responde a la pregunta de /¿cómo competir?/. 
Persigue alcanzar una /ventaja competitiva/ en costes o en diferenciación.

****** Nivel funcional
La *estrategia funcional* determina las decisiones a tomar en cada
área funcional de la empresa teniendo en cuenta los recursos y
capacidades distintivas de la misma.

Implica tomar decisiones sobre

 * dirección comercial o de márketing.
 * dirección de la producción.
 * dirección financiera.
 * dirección de recursos humanos.

****** Resumen
La estrategia corporativa decide los campos de actividad, dónde va a
diversificar la empresa. La estrategia de negocio se formula para cada
UEN distinto; y por último, la estrategia funcional decide cómo vamos
a aplicar los recursos dentro de cada área funcional.

|-------------+----------------------------------+------------------------|
| Corporativa | Campo de actividad de la empresa | Dirección general      |
| De negocio  | UENs                             | Jefes de división      |
| Funcionales | áreas funcionales                | Directores sectoriales |
|-------------+----------------------------------+------------------------|

**** 4.2. Proceso de dirección estratégica
Análisis del entorno e interno. En base a él formulamos las direcciones
para los objetivos, decidiremos cuál es la más adecuada y lo implementaremos.

Se divide en varias etapas.

***** Etapa de análisis estratégico
En la fase de *análisis estratégico* debe realizarse un diagnóstico de
la situación de la empresa, partiendo del objetivo a largo plazo, la
misión, valores y objetivos.

Partiendo del objetivo a largo plazo, se hace un análisis DAFO, con un
análisis tanto externo como interno.

****** Análisis DAFO
El análisis DAFO puede usarse en esta fase para analizar la situación
externa e interna de la empresa. Recoge debilidades y fortalezas,
amenazas y oportunidades.

***** Etapa de formulación de estrategias
En la fase de *formulación de estrategias* se diseñan, evalúan y
seleccionan las estrategias que vamos a implementar, a niveles
coorporativo y competitivo.

***** Etapa de implantación
En la fase de *implantación de la estrategia* se pone en práctica la
estrategia seleccionada. Suele elaborarse un /plan estratégico/ que
recoja las decisiones tomadas. Puede suponer cambios de dirección, de
equipamiento técnico, de compromiso, de recursos y de control; y debe
adecuarse a la cultura organizativa de la empresa.

**** 4.3. Opciones estratégicas básicas
***** Opciones a nivel de estrategia corporativa
Las opciones a nivel de *estrategia corporativa* decidirán la estrategia
global de la empresa; /dónde competirá/, qué actividades vamos a
desarrollar y en qué mercados vamos a tener presencia.

****** Estrategias de crecimiento
Las *estrategias de crecimiento* deben responder hacia dónde se quiere
crecer y cómo se quiere crecer. Para ello, nos valemos de la matriz de
Ansoff, que clasifica las estrategias de crecimiento.

|---------------------+------------------------+----------------------|
|                     | Productos Existentes   | Productos nuevos     |
|---------------------+------------------------+----------------------|
| Mercados Existentes | Penetración de mercado | Desarrollo productos |
| Mercados Nuevos     | Desarrollo de mercados | *Diversificación*    |
|---------------------+------------------------+----------------------|

Dentro de estas estrategias se consideran tres *estrategias de expansión*, 
que implican crecimiento sin variar el campo de actividad 
considerablemente. Son

 * *estrategia de penetración en el mercado*, cuando se siguen explotando
   los mismos productos en los mismos mercados. Se busca incrementar
   la cuota de mercado. Se siguen estrategias de márketing.

 * *estrategia de desarrollo de productos*, cuando se desarrollan nuevas
   variedades de productos para los mercados habituales; o se migra
   hacia modelos superiores.

 * *estrategia de desarrollo de mercados*, cuando se introducen los
   mismos productos en nuevos mercados. Incluye la
   /internacionalización/.

Además, se considera una estrategia que sí supone un cambio sustancial,
la

 * *estrategia de diversificación*, busca explotar productos nuevos
   en mercados desconocidos. Incluye la /integración vertical/.

****** Formas de crecimiento
La empresa crece con distintos métodos

 * *crecimiento interno u orgánico* cuando invierte en sí misma para
   incrementar su valor económico y su capacidad productiva.

 * *crecimiento externo* cuando lleva a cabo adquisiciones o fusiones
   con otras empresas; o toma control sobre las decisiones de otra
   empresa. No implica crecimiento real de la economía.

 * *crecimiento híbrido* cuando existen acuerdos temporales entre
   empresas que no varían su identidad jurídica. Ejemplos son 
   la /franquicia/, las /subcontratas/ o los /UTE/.

****** Estrategia de reestructuración
La *estrategia de reestructuración* es aquella que emprende cambios en
el *campo de actividad*, reduciendo la importancia de algunos negocios
y abandonando la explotación de unidades estratégicas. Al abandonar
negocios estamos cambiando nuestro campo de actividad.

***** Opciones a nivel de estrategia competitiva
Las opciones a nivel de *estrategia competitiva* decidirán la estrategia
particular de cada UEN; /cómo competirá/, y qué guías deberá seguir la
empresa para obtener y mantener la ventaja competitiva.

|-----------+---------------------+----------------------------|
|           | Costes              | Diferenciación             |
|-----------+---------------------+----------------------------|
| Industria | Liderazgo en costes | Diferenciación de producto |
| Segmento  | Segmentación        | Segmentación               |
|-----------+---------------------+----------------------------|

****** Liderazgo en costes
La estrategia de *liderazgo en costes* persigue producir con costes
inferiores a los de los competidores. Sabiendo que los costes son

\[m = p - c\]

donde

 * $m$ es el margen de beneficio,
 * $p$ el precio unitario del producto, y
 * $c$ el coste unitario.

Puede explotarse la bajada del coste unitario manteniendo el
precio e incrementando su rentabilidad, o disminuyendo el precio
y esperando un aumento de ventas frente a los competidores.

****** Diferenciación
La estrategia de *diferenciación* busca que el producto sea percibido
como diferente o superior por los clientes. Por calidad, atención o
por ser diferente.

Puede explotarse la diferenciación aumentando el precio unitario y 
manteniendo los clientes gracias a esta diferenciación.

****** Segmentación
La estrategia de *segmentación* se centra en un segmento de los
clientes o se enfoca en sólo una parte de la población. Normalmente el
enfoque va acompañado de una estrategia de costes o diferenciación.

****** Problema: stuck in the middle
Cuando se persiguen los objetivos de coste y diferenciación a la vez,
se corre el riesgo de no conseguir ninguno. A esto se le llama
quedarse /atrapado en el medio/.

***** Opciones a nivel funcional
Las *opciones estratégicas* a nivel funcional son específicas y
variadas para cada área funcional. Se consideran compuestas de todas las
decisiones estratégicas derivadas de las decisiones de los niveles
superiores y se clasifican por áreas.

****** Producción
Se toman decisiones como

 * nivel de integración vertical.
 * nivel de capacidad máxima por unidad productiva.
 * gestión de la producción.
 * localización de la producción.

****** Márketing
Se toman decisiones como

 * elección del producto.
 * política de precios.
 * canales de distribución.

****** Recursos humanos
Se toman decisiones como

 * incentivos y promoción interna.
 * criterios de selección de personal.
 * remuneración.

****** Financiero
Se toman decisiones como

 * política de dividendos.
 * selección de inversores.
 * gestión del riesgo.

**** Sobre misión y visión
En el proceso de dirección estratégica, hay una parte de análisis
externo, análisis DAFO y análisis interno. En la formulación de
estrategias. Pero todo ello depende en primera instancia de la
visión y misión de las empresas.

/Nótese que algunas empresas mezclan misión y visión./

***** La misión
La *misión* es el motivo de la empresa. Responde a la pregunta
de /qué/ hace la empresa. Es la expresión de la identidad de la
empresa y declaración de propósito general.

****** Diferenciación
Dos empresas competidoras en el mismo sector tendrán normalmente
misiones distintas. Harán énfasis en cosas distintas.

****** Empresas diversificadas
En empresas diversificadas, la misión es el hilo conductor; pero
pueden enunciarse misiones distintas para las distintas unidades
en casos de diversificación extrema no relacionada.

***** La visión
Enuncia la *visión* ideal futura de la empresa. Se expresa en términos
de ideales, procurando que no sólo haga referencia a los stakeholders.

***** El eslogan
Nótese que no se relacionan con el eslogan, que es sólo un
reconocimiento a nivel publicitario y comercial.

**** Modelos de negocio
La lógica de la estrategia competitiva es crear valor. Los modelos de
negocio estudian cómo construir la ventaja competitiva. El modelo de
negocio se suele plasmar en un lienzo de 9 bloques creado por
Osterwalder (el /Business Model Canvas/).

Dos empresas que satisfacen la misma necesidad a los clientes pueden
tener dos modelos de negocio diferentes.

***** Business model canvas
Debemos entender el problema del cliente y ofrecerle soluciones.
Osterwalder considera que el verdadero producto que ofrece una empresa
es su modelo de negocio.

***** Elementos del modelo de negocio
El orden y tamaño de los bloques en el canvas es semántico. La parte
izquierda es el backend mientras que la derecha es el frontend. Abajo
queda la parte financiera.

 * Propuesta de valor.
 * Segmentos de clientes.
 * Canales de comunicación con el cliente.
 * Relación con el cliente.
 * Fuentes de ingresos.
 * Asociaciones clave: competidores, proovedores.
 * Canales.
 * Recursos clave.
 * Actividades clave: verbos, acciones esenciales para construir y
   crear la propuesta de valor.
 * Fuentes de ingresos y de gastos.

*** Ejercicios
**** Ejercicio 1
#+begin_statement
En el modelo de las 5 fuerzas competitivas de Porter, ¿qué
representaría el nuevo servicio de llamadas de Whatsapp para las
empresas de telecomunicación en 2015?¿Crees que suponía en aquel
entonces una amenaza relevante?
#+end_statement

El servicio de llamadas de Whatsapp cubre la misma necesidad que
cubrían las llamadas tradicionales usando una tecnología distinta, la
VoIP. Es por tanto un *producto sustitutivo* de las llamadas
tradicionales según el modelo de Porter.

En el 2015 parecía suponer una amenaza relevante porque era un
sustitutivo accesible a la mayoría de consumidores (700 millones de
personas usaban Whatsapp) y existían previsiones de que superaría a
las llamadas en 2018. Además, los SMS eran un precedente de cómo un
proceso similar había sido una amenaza para las telefónicas.

**** Ejercicio 2
#+begin_statement
Ante el lanzamiento en 2015 del nuevo servicio de llamadas de Whatsapp,
¿qué reacciones se esperaban por parte de las compañías de telefonía móvil?
#+end_statement

Según César Córcoles y otros profesores de la UOC, las estrategias
podrían ser

 * *reducir el costo* de las llamadas, ofreciendo más minutos de voz en
   las tarifas. Están bajando los precios relativos al sustitutivo.
 * *incluir la VoIP* en sus servicios y promocionarla para vender más en
   las tarifas de internet.
 * *rebajar la calidad del servicio de VoIP* en detrimento del servicio
   de Whatsapp y otras aplicaciones similares. Iría contra sus propios
   usuarios y el principio de neutralidad de la red. Sería una represalia
   contra un potencial competidor.

**** Ejercicio 3
#+begin_statement
Según el informe de Cisco Systems citado en el artículo, "se prevé que
en 2018 los minutos de llamadas por Wifi superen los minutos de
llamads por la red telefónica convencional". Ante la cercanía del
momento pronosticado, ¿crees que se han cumplido las previsiones?¿Cómo
calificarías, según los parámetros estudiados en clase, la amenaza de
este servicio para las operadoras de telefonía tradicionales?
#+end_statement

Las previsiones parecen no haberse cumplido y parece que todavía las
llamadas sobre WiFi no superaran a las llamadas tradicionales, aunque
seguramente la existencia de servicios de mensajería y mensajes de voz
haya hecho caer ambas.

Como amenaza, debemos tener en cuenta parámetros como

 * el *coste de cambio* al VoIP es muy bajo. La mayoría de usuarios ya 
   lo tienen instalado.
 * el *acceso a canales de distribución* lo tienen ya las empresas de
   VoIP, que tienen clientes obtenidos gracias a ofrecer servicios de
   mensajería.
 * el *grado de sustitución*. Aunque la VoIP sustituye las llamadas en
   la mayoría de los casos, si se quieren llamadas de alta calidad y sin
   cortes, podría necesitarse volver a las llamadas tradicionales.
 * los *precios relativos al sustitutivo* son mucho más bajos para las
   llamadas por VoIP en general debido a que aprovechan la red Wifi que
   se esté usando.
 * la *obsolescencia* no es en este caso un problema para las llamadas
   tradicionales, que siguen teniendo normalmente mayor calidad que las
   llamadas VoIP.

**** Ejercicio 4
#+begin_statement
¿Cuál era la estrategia inicial pensada por Zuckerberg para poder
ofrecer servicios "efímeros" de realidad aumentada e intercambio de
archivos para usuarios de smartphones?
#+end_statement

La estrategia pretendía eliminar o integrar en sí toda la competencia.
Estrategia de adquisición por vía de crecimiento externo.

Específicamente, comprar la principal empresa de la competencia, como
intentó en 2013, y crear una plataforma de realidad aumentada, con la
que el resto de potenciales competidores se verían obligados a
integrarse.

**** Ejercicio 5
#+begin_statement
Tras la marcha de los acontecimientos, ¿cómo podemos clasificar a
Facebook Stories en el marco del modelo de rivalidad ampliada de
Porter, respecto de Snapchat (suponiendo que la industria de
referencia es la que ofrece el tipo de servicios descritos en el punto
1)?
#+end_statement

Actúa como un competidor actual. Específicamente sabemos que no es un
producto sustitutivo porque está usando exactamente las mismas
tecnologías, que, de hecho, ha imitado directamente en lugar de
innovar.

Además, quiere realizar integración vertical para crear una plataforma
de realidad aumentada y convertirse en proveedor del resto de plataformas
que pudieran existir en el sector.

** Teoría de Números y Criptografía
*** Factorización
**** Métodos básicos de factorización
***** Fuerza bruta
Probando a dividir cada número hasta $\sqrt{n}$.

***** Método de Fermat
Escribimos un número como diferencia de cuadrados para factorizarlo como
$n = t^2 - s^2 = (t+s)(t-s)$.

****** Soluciones en congruencias no triviales
Si $(t,s)$ es una solución no trivial de $x^2 \equiv y^2$, entonces $gcd(n,t+s)\neq 1$
y $gcd(n,t-s) \neq 1$.

**** Método de factor base
Una *base* es un conjunto $B = \{p_0 = -1,p_1,\dots,p_h\}$ donde $p_0,p_1,\dots,p_n$
son enteros primos.

***** Conjunto de candidatos B-números
Un conjunto de candidatos B-números es $\mathbb{Z}_n$ escribiendo la
mitad de números más grandes dentro de la base, como:

\[
\mathbb{Z}_n =
\{0,1\dots,-2,-1\}
\]

Llamamos $\operatorname{abmod}$ a la clase de equivalencia del número en el conjunto 
de candidatos.

***** B-número
Un número $b$ es B-número respecto de $n$ si $\operatorname{abmod}(b^2,n)$ factoriza por los 
elementos de la base $B$.

***** Alfa-vectores
Dado $b$ un B-número, con:

\[
\operatorname{abmod}(b^2,n) = p_0^{e_0}\dots p_h^{e_h}
\]

definimos el *α-vector* como $\alpha vect(b) = (e_0,e_1,\dots,e_h)$.

***** TODO Idea del algoritmo
Sea $S_0 = \{\alpha_0,\dots,\alpha_r\}$ un α-vector del conjunto de B-números.

**** Métodos de elección de la base B y los B-números
***** Algoritmo: voy a tener suerte
Se eligen los $h \in \mathbb{N}$ primeros números primos. Escogemos dos índices
$k_{max} \leq i_{max}$ y calculamos:

  - $\lfloor \sqrt{n}\rfloor, \lfloor \sqrt{2n}\rfloor, \dots, \lfloor \sqrt{k_{max}n}\rfloor$
  - $\lfloor \sqrt{n}\rfloor+1, \lfloor \sqrt{2n}\rfloor+1, \dots, \lfloor \sqrt{k_{max}n}\rfloor+1$
  - $\dots$
  - $\lfloor \sqrt{n}\rfloor + i_{max}, \lfloor \sqrt{2n}\rfloor+i_{max}, \dots, \lfloor \sqrt{k_{max}n}\rfloor+i_{max}$

Entre estos, buscamos B-números y calculamos los α-vectores 
correspondientes.

***** Algoritmo: voy a forzar la suerte
**** Fracciones continuas
***** Fracción continua
Notamos una fracción continua como:

\[
[a_0,a_1,a_2,\dots] =
a_0 + \frac{1}{a_1+\frac{1}{a_2+\dots}}
\]

***** Propiedades de las fracciones continuas
Las fracciones continuas cumplen:

  1. Todo racional se expresa como fracción continua finita.
  2. Todo real se expresa como fracción continua.
  3. Se cumple la fórmula:

     \[\frac{a+\sqrt{d}}{b} = [a_0,[a_1,\dots,a_r]]\]

     Si notamos $[a_0,[a_1,\dots,a_r]] = [a_0,a_1,\dots,a_r,a_1,\dots,a_r,\dots]$.

***** Cálculo de la fracción continua de un real
Sea $x \in \mathbb{R}$, tomamos $a_0 = \lfloor x \rfloor$ y podemos escribir recursivamente la 
fracción continua como:

\[
x = a_0 + \frac{1}{x_1^{-1}}
\]
** Taller de Geometría y Topología
*** 1. Construcciones con regla y compás
**** 1.1. Construcciones posibles
***** 1.1.0. Construcciones elementales
Axiomáticamente consideramos realizables las siguientes construcciones
elementales:

  1. Dados dos puntos, puede construirse un *segmento* entre ellos.
  2. Todo segmento puede extenderse.
  3. Dados dos puntos, puede construirse un *círculo* con centro y radio.
  4. Dadas dos rectas secantes, puede construirse su *punto* de corte.
  5. Dados círculo y rectas, puede construirse su *punto* de corte.
  6. Dados círculos tangentes, pueden construirse *puntos* de corte.

****** Equivalencia de compases                                                                            :extra:
Asumimos un compás colapsable, pero podríamos usar uno no colapsable
con el mismo efecto, por la [[https://en.wikipedia.org/wiki/Compass_equivalence_theorem][equivalencia de compases]].

***** 1.1.1. Construcciones básicas
****** 1. Triángulo equilátero sobre un segmento
****** 2. Copiar un segmento
****** 3. Cortar segmento de otro dado
****** 4. Bisecar ángulo
****** 5. Mediatriz de un segmento
****** 6. Perpendicular a través de un punto en una recta
****** 7. Perpendicular a través de un punto fuera de una recta
****** 8. Triángulo con longitudes de lados dada
****** 9. Copiar un segmento a un segmento dado
****** 10. Copiar un ángulo a un rayo
****** 14. Paralela a una recta a través de un punto exterior
***** 1.1.2. Construcciones involucrando razones geométricas
****** 15. Cortar un segmento en n partes iguales
****** 16. Cortar un segmento en un racional
****** 17. Media geométrica de dos segmentos
***** 1.1.3. Construcciones involucrando áreas
****** 19. Paralelogramo con igual área que un triángulo dado
***** 1.1.4. Circunferencias destacadas
****** 24. Centro de una circunferencia
****** 25. Circunferencia inscrita a un triángulo
Usando bisectrices.
****** 26. Circunferencia circunscrita a un triángulo
**** 1.2. Construcciones imposibles
***** 1.2.1. Elementos constructibles o realizables
Un real $x$ es constructible cuando podemos construir puntos $C,D$ tales que
$\overline{CD} = x$.

****** Subcuerpo de números constructibles
Los números constructibles forman un subcuerpo de $\mathbb{R}$. Llamamos $\mathfrak{C}$ al
cuerpo de los constructibles.

******* TODO Demostración
****** Los racionales son constructibles
Todo subcuerpo de $\mathbb{R}$ debe contener a los racionales.

****** Las raíces de constructible son constructibles
Si $x \in\mathfrak{C}$, entonces $\sqrt{|x|} \in \mathfrak{C}$.

***** 1.2.1. Extensión cuadrática
Dado $\mathbb{K}$ subcuerpo de $\mathbb{R}$ llamamos a:

\[
\mathbb{K}(\sqrt{e}) = \{ a+ b\sqrt{e} \mid a,b\in\mathbb{K}\}
\]

una extensión cuadrática de $\mathbb{K}$.

***** 1.2.1. Teorema de Descartes
Un número real es constructible ssi está en alguna extensión cuadrática
iterada de $\mathbb{Q}$.

****** TODO Demostración

*** 2. Geometría no euclídea
**** El Quinto Postulado de Euclides
***** Quinto postulado de Euclides
El Quinto Postulado de Euclides afirma que, dadas $r,s,t$ rectas
cortando $r$ a $t,s$ con ángulos $\alpha,\beta$; si $\alpha+\beta < \pi$, entonces $s \cap t \neq \varnothing$.

***** Teorema de Legendre
El Quinto Postulado equivale a que la suma de los ángulos de un
triángulo es exactamente $\pi$. Si la suma de los ángulos de un triángulo
es $\pi$, se cumple el Quinto Postulado.

***** Cuadriláteros de Saccheri
Un cuadrilátero $ABCD$ es *de Saccheri* cuando $\widehat{A},\widehat{B}$ son rectos y 
además $\overline{AD}=\overline{BC}$.

***** Cuadrilátero de Lambert
Un cuadrilátero es *de Lambert* si tiene tres ángulos rectos.

***** Independencia del Quinto Postulado
Los siguientes resultados son independientes del Quinto Postulado

 * la suma de los ángulos de un triángulo es menor o igual que $\pi$.
 * los dos ángulos no rectos de un cuadrilátero de Saccheri son
   iguales y menores o iguales que $\pi/2$.
 * el lado superior de un cuadrilátero de Saccheri es menor que 
   el lado inferior.

***** Implicación al Quinto Postulado
Los siguientes resultados equivalen al Quinto Postulado

 * los ángulos de un triángulo suman $\pi$.
 * los ángulos de todos los triángulos suman $\pi$.
 * un cuadrilátero de Saccheri tiene todos los ángulos rectos.

**** Geometría hiperbólica
***** Axioma de Lobachevsky
Dada una recta $r$ y un punto $a \notin r$, existen al menos dos rectas $s_1,s_2$
distintas con $a \in s_1\cap s_2$, pero $s_1\cap r = s_2\cap r = \varnothing$.

***** Infinitas rectas
Dada una recta $r$ y un punto $a \notin r$, existen infinitas rectas que pasan
por $a$ y no contienen a $r$.

**** Paralelas en geometría hiperbólica
***** Existencia de rectas dado un ángulo
Dada una recta $r$ y un punto $a \notin r$, dado cualquier ángulo $\alpha \in (0,\pi)$ y
siendo $a \in t_a \perp r$, existen dos rectas $l_1,l_2$ formando un ángulo $\alpha$ con
$t_a$.

***** Existencia de paralelas
Dada una recta $r$ y un punto $a \notin r$, tomamos $t_{a}$ la perpendicular por $a$
y $l_{\alpha}$ la dada con ángulo $\alpha$ por el teorema anterior. Existe un único
$\beta \in (0,\pi/2)$ tal que

  * $l_{\beta}\cap r = \varnothing$,
  * $\forall a \in (0,\beta): l_{\alpha}\cap r \neq \varnothing$.
 
En este caso, la recta $l_{\beta}$ es *paralela*.

***** El paralelismo es independiente del punto elegido
Si una recta es paralela a otra por un punto, lo es por todos sus
puntos.

***** El ángulo de paralelismo sólo depende de la distancia
El ángulo de paralelismo de una recta por un punto sólo depende de
la distancia de la recta al punto.

***** Existen exactamente dos paralelas
Dada una recta y un punto exterior, existen exactamente dos paralelas
distintas que pasan por el punto.

***** Simetría del paralelismo
Si $r$ es paralela a $s$, $s$ es paralela a $r$.

***** Ultraparalelas
Dos rectas se dicen ultraparalelas si no son secantes ni paralelas.

***** Caracterización de ultraparalelas
Dos rectas son ultraparalelas si y sólo si admiten una perpendicular
común.

**** Defecto de triángulos
***** Defecto de un triángulo
El *defecto* de un triángulo $ABC$ es

\[ \mathrm{def}(ABC) =
\pi - {\widehat A} - \widehat B - \widehat C > 0.
\]

***** Los defectos de triángulos son aditivos
Dado un $D \in AB$ y $ABC$ un triángulo, se tiene

\[ \mathrm{def}(ABC) = \mathrm{def}(ACD) + \mathrm{def}(BCD).
\]

***** Dos triángulos son congruentes si tienen los mismos ángulos
Dos triángulos con los mismos ángulos en geometría hiperbólica
deben ser congruentes.

***** Paralela a una y perpendicular a otra
Dadas dos semirectas formando un ángulo agudo, existe una única
perpendicular a una y paralela a la otra.

***** El defecto es el área
El defecto es igual al área del triángulo.

**** Semiplano de Poincaré
***** Definición
Llamamos $\mathbb{H}^2 = \left\{ (x,y) \in \mathbb{R}^2\mid y>0
\right\}$ y $\forall p = (x,y) \in \mathbb{H}^2$ y sobre él tomamos 
la métrica $g_p = \frac{1}{y^{2}}\left\langle \cdot,\cdot \right\rangle$.

*** Ejercicios
**** Formas del universo
***** Ejercicio 1
#+begin_statement
Como seres de dimensión 3 en un mundo de tres dimensiones es fácil
dibujar y entender posibles formas de Planilandia pero no de nuestro
propio Universo. Imaginar la forma de nuestro Universo en alguna de
las siguientes situaciones:

 * Hacemos una expedición a una galaxia remota. Al llegar a ella
   descubrimos estar de vuelta en la tierra.

 * Un astrónomo acaba de descubrir que los mismos objetos se
   encuentran en posiciones distintas del Universo.

 * Buscando ondas de radio que detecten señales extraterrestres,
   detectamos una señxal que procede de una galaxia lejana.
   Investigamos y vemos que se trata de la señal de un programa de TV
   emitido hace 50 años.

A las posibles formas de nuestro Universo les llamaremos
variedades de dimensión 3 y su estudio constituye la Topología
3-dimensional.
#+end_statement

En cualquiera de esos casos podríamos estar ante un toro tridimensional.
Los objetos se repetirían en el espacio una y otra vez, y todo el espacio
se repetiría con ellos. Podríamos interpretar que vivimos en un cubo en el
que están identificadas cada una de las caras con la opuesta. Nótese que
seguría siendo un universo orientable.

En un segundo ejemplo, podría ocurrir que tuviéramos un universo similar
al anterior pero en el que una de las paredes del cubo cambiara la 
orientación. Al pasar por ella volveríamos al mismo punto pero habríamos
intercambiado derecha e izquierda.

En un tercer ejemplo, podría ocurrir que el universo fuera infinito en
una dimensión pero en las otras dos se comportara como un toro plano.
Dependiendo de la dirección que tomáramos, volveríamos o no al punto
de partida.

***** Ejercicio 2
#+begin_statement
1. ¿Cuáles de las siguientes superficies tienen la misma topología?
   
   [[./img/formasuniverso1.png]]

2. En Planilandia CP descubrió que dos caminos cerrados partiendo del mismo
   punto en direcciones opuestas no tienen por qué volver a cruzarse en un
   punto diferente. ¿Es esta propiedad geométrica o topológica?
3. Describir superficies con la misma topología pero diferente geometría.
#+end_statement

1) Tienen la misma topología:
   * la esfera y el objeto justo debajo.
   * el toro y la taza.
   * el resto de objetos.
2) Esta es una propiedad topológica. El hecho seguirá siendo cierto al
   aplicar deformaciones continuas al espacio.
3) Por ejemplo de un ejercicio anterior tomamos el toro y la taza, que
   tenían la misma topología pero se puede observar que al hacer la
   deformación del toro en la taza han cambiado propiedades como área
   que es diferente para ambas figuras.

***** Ejercicio 3
#+begin_statement
Distingue según su topología intrínseca y extrínseca.

[[./img/formasuniverso2.png]]

 * ¿Puedes forrar un cilidro con parte de una hoja de papel sin deformarla?,
   ¿y un cono?, ¿y un trozo de esfera?
 * ¿Coḿo pueden los planilandeses que vivan en mundos como los de la figura
   conocer que sus geometrías intrínsecas son diferentes? ¿Qué pueden decir
   acerca de sus topologías extrínsecas e intrínsecas?

   [[./img/formasuniverso3.png]]

$\quad$
#+end_statement

Todas las figuras tienen misma topología intrínseca. En el caso de la
topología extrínseca podemos distinguir tres grupos:

 * las figuras azules junto a la morada adyacente a estas.
 * las figuras amarillas.
 * la morada que nos queda.

Podemos forrar el cilindro y el cono, por el contrario se crearían
pliegues en el papel al intentar cubrir el trozo de esfera.

En el trozo de esfera al medir los ángulos de un triángulo el
resultado sería mayor que PI, en el hiperboloide sería menor que PI, y
en el plano sería igual a PI.

***** Ejercicio 4
#+begin_statement
  * Justifica que el toro llano y la superficie de un donut son
    topológicamente equivalentes.

  * Consigue en la siguiente figura un de un toro llano tres =X=
    en línea.

    #+attr_latex: :width 5cm 
    [[./img/formasuniverso4.png]]

  * Cuáles de las posiciones siguientes serían equivalentes al jugar
    unas "tres en línea" sobre un toro llano.

    [[./img/formasuniverso5.png]]

  * En el siguiente tablero de ajedrez sobre un toro llano, ¿qué figuras
    están amenazadas por el caballo blanco?

    #+attr_latex: :width 5cm 
    [[./img/formasuniverso6.png]]

  * ¿Qué figuras están amenazadas por el caballo y la reina blancos?

    #+attr_latex: :width 5cm 
    [[./img/formasuniverso7.png]]

  * Las siguientes figuras muestran un toro llano de tres dimensiones.
    Explica cómo se construye e imagina qué verías al mirar en una dirección
    concreta.

    #+attr_latex: :width 5cm 
    [[./img/formasuniverso8.png]]

$\quad$
#+end_statement

 * Triangulando el toro llano y el donut llegamos fácilmente a la misma
   triangulación.
 * Escribimos X en la casilla inferior central.
 * Todos los celestes por un lado; todos los amarillos excepto los de la
   primera columna y el último de la tercera columna, y todos los demás.
 * Rey, afil, y dos caballos negros.
 * Todas.
 * Identificando las caras, veríamos nuestra espalda delante, nuestros pies
   hacia arriba y nuestra cabeza hacia abajo.

***** Ejercicio 5
#+begin_statement
Jugando en la botella de Klein:

  * ¿Cuáles de las siguientes posiciones ganan en el juego del tres en
    raya dentro de una botella de Klein?

    [[./img/formasuniverso10.png]]

  * Analiza cómo hacer tres en línea en la siguiente figura.

    [[./img/formasuniverso11.png]]
#+end_statement

De las tres posiciones del tres en raya

 * la primera gana.
 * la segunda gana.
 * la tercera gana.

Si escribimos coordenadas del tres en raya como

| 0,0 | 0,1 | 0,2 |
| 1,0 | 1,1 | 1,2 |
| 2,0 | 2,1 | 2,2 |

se ganan las partidas con la posición

 * primera: (2,2)
 * segunda: (0,0)
 * tercera: (0,2)
 * cuarta: (2,2)
 * quinta: (1,1)

***** Ejercicio 6
#+begin_statement
Actividades:

 * Si un planilandés viviendo en un plano proyectivo cruza el ecuador,
   ¿vuelve como su imagen especular?
 * Una familia de planilandeses vive en un plano proyectivo. Planean
   edificar dos gasolineras separadas cuanto más mejor. ¿Dónde deberían
   construirlas?
 * CP conoce que vive en una esfera o en un plano proyectivo. ¿Cómo
   podría saber cuál de los dos es su mundo?
 * Un segundo planilandés sabe que su Universo es un plano proyectivo o
   una botella de Klein, ¿qué podría hacer para conocer de cuál de los dos
   se trata?

$\quad$
#+end_statement

 1) Sí, el plano no es orientable.
 2) Una en el centro y otra en el ecuador.
 3) Cruzando la frontera y al volver, comparando su orientación.
 4) Ampliar primero una zona segura en la que pudiera volver a cada punto
    sin haber cambiado la orientación y luego comprobar si el resto del
    universo ha quedado dividido en dos (suma de planos) o en uno (plano).

***** Ejercicio 7
#+begin_statement
Haciendo sumas conexas:

 * Deducir que si a una cinta de Möbius le pagamos un disco por el borde,
   obtenemos un plano proyectivo.
 * Corrobora las palabras de Klein: "La cinta de Möbius es divina, si pegas
   dos por su borde obtienes mi botella".
 * Construye usando papel la suma conexa de una cinta de Möbius a un toro
   y a una botella de Klein.
 * Muestra que la suma conexa de un toro con un plano proyectivo es 
   topológicamente equivalente a la suma conexa de una botella de Klein con
   un plano proyectivo.
 * Establece una correspondencia por equivalencia topológica entre las
   superficies de los conjuntos A y B:

   \[
   A = \{
   \mathbb{T}^2\#\mathbb{S}^2,
   \mathbb{P}^2\#\mathbb{P}^2\#\mathbb{P}^2,
   \mathbb{B}^2,
   \mathbb{S}^2\#\mathbb{S}^2\#\mathbb{S}^2,
   \mathbb{P}^2\#\mathbb{T}^2,
   \mathbb{B}^2\#\mathbb{T}^2\#\mathbb{P}^2
   \}
   \]

   \[
   B = \{
   \mathbb{P}^2\#\mathbb{P}^2,
   \mathbb{B}^2\#\mathbb{P}^2,
   \mathbb{S}^2\#\mathbb{S}^2,
   \mathbb{P}^2\#\mathbb{P}^2\#\mathbb{P}^2\#\mathbb{B}^2,
   \mathbb{T}^2,
   \mathbb{T}^2\#\mathbb{P}^2
   \}
   \]
#+end_statement

1) Un plano proyectivo menos un disco es una banda de Möbius porque
   podemos dibujar el plano proyectivo en un disco y quitarle un disco
   que corte la frontera del disco.
2) Nótese que si partimos la botella de Klein por la mitad, lo que queda
   en cada una de las mitades es una banda de Möbius.
3) Serían al final 5 planos proyectivos.
4) Usando la clasificación de superficies compactas sabemos que no
   necesitamos mezclar asas con gorros cruzados $\times \circ = \times^3$.
5) Usaremos clasificación de superficies compacatas para escribir cada
   una como suma de planos proyectivos o toros. La $\mathbb{S}^2$ es neutra bajo la
   suma conexa.

   Nos quedan

   * $\mathbb{B}^2 \cong \mathbb{P}\#\mathbb{P}$,
   * $\mathbb{B}^2 \#\mathbb{P}^2 \cong \mathbb{P}^2 \# \mathbb{P}^2 \# \mathbb{P}^2$,
   * $\mathbb{S}^2\# \mathbb{S}^2 \cong \mathbb{S}^2 \# \mathbb{S}^2 \# \mathbb{S}^2$,
   * $\mathbb{P}^2\#\mathbb{P}^2\#\mathbb{P}^2\#\mathbb{B}^2 \cong \mathbb{B}^2\#\mathbb{T}^2\#\mathbb{P}^2$,
   * $\mathbb{T}^2 \cong \mathbb{T}^2\#\mathbb{S}^2$,
   * $\mathbb{T}^2\#\mathbb{P}^2 \cong \mathbb{P}^2\#\mathbb{T}^2$.


Las geodésicas del modelo vienen dadas por intersecciones del hiperboloide
con subespacios lineales bidimensionales, que nunca serán vacíos
** Desarrollo y sistemas de información
*** 1. Sistemas de información
**** Definición
***** Sistema
Conjunto de elementos ordenadamente relacionados contribuyendo a
una determinada función

***** Datos
Representación simbólica de variables cuantitativas o cualitativas.

***** Información
Conjunto organizado de datos procesados, formando un mensaje que
cambia el estado de conocimiento del sistema que lo procesa.

***** Sistema de información
Un sistema de información es

 * un sistema automatizado o manual para recopilar, procesar y
   transmitir datos representando información.

 * la infraestructura para la recopilación, procesamiento y transmisión
   de información.

**** Sistemas de información empresarial: gestión de recursos
La *gestión de recursos* de una empresa es una utilidad de sistemas de
información. Sirven para

 * *comunicación*
   * intranets/extranets
   * value added networks (VANs)

 * *resolución de problemas*
   * decision support systems (DSSs)
   * knowledge-based systems (KBSs)

debido a la complejidad de los sistemas actuales y al ahorro económico
que proporcionan.

Gestionan recursos físicos y conceptuales.

**** Sistemas de información empresarial: funciones de un gerente
Las funciones de un gerente son

 - funciones de Fayol :: planificar, organizar, apoyar, dirigir y
      controlar.
 - papeles de Mintzberg :: interpersonales, información y toma de
      decisiones.

a distintos niveles gerenciales

 - planificación estratégica :: ejecutivos,
 - control gerencial :: directores de producto, jefes de sección,
 - control operativo :: jefes de proyecto, jefes de departamento,

a distintos niveles varía el origen y nivel de detalle de la información
requerida.

**** TODO Sistemas de información empresarial: CBIS

*** 2. Diseño conceptual de sistemas de información
**** Modelo Entidad-Relación
El *modelo entidad-relación* es el más extendido para el diseño
conceptual; debe reflejar fielmente las necesidades de información y
ofrecer un diseño independiente. Representa y manipula información
de forma general y sistemática.

 - Datos :: tratamiento de un recurso conceptual.
 - Convenciones :: actuación sistemática y rigurosa.
 - Redundancia mínima :: modelado único de cualquier objeto.

**** Elementos del modelo
# Pasar a folio los diagramas
Los elementos del modelo son

 - entidades :: objetos delimitados y distinguibles de los demás;
 - conjuntos de entidades :: grupo de entidades con las mismas
      cualidades; también llamados *tipos*;
 - atributos :: propiedades caracterizando un conjunto de entidades.

***** Atributos
Sobre los atributos, se consideran 

 - dominio :: valores permitidos para un atributo,
 - identificadores :: atributos que identifican unívocamente a
      una entidad (se señalan rellenando el círculo),
 - atributo compuesto :: formado por varios (se señala como un
      círculo con atributos a su vez).

***** Entidades fuertes y débiles
Decimos que B *depende existencialmente* de A si cada B tiene
un A asociado y es imposible identificar a un b sin identificar
su a. La B es una entidad débil respecto de A.

# TODO: Cardinalidad en entidades débiles!

***** Asociaciones
Relaciones semánticas entre dos o más conjuntos de entidades.
Pueden tener *cardinalidad*

 * n:m - muchos a muchos
 * m:1 - uno a muchos
 * 1:m - muchos a uno
 * 1:1 - uno a uno,

y *participación*

 * 0 si es parcial u opcional,
 * 1 si es total.

Se leen fijando un objeto de la relación. Las relaciones pueden
tener atributos en algunos casos.

***** Especialización
A es una especialización de B si está completamente incluído en él.
Todo a es un b.

 * *(p) Obligatoriedad parcial:* si hay entidades que no pertenezcan a
   ninguna especialidad.
 * *(t) Obligatoriedad total:* si toda entidad tiene que pertenecer a
   algún conjunto especializado.
 * *(e) Exclusividad*: si sólo se pertenece a una especialización.
 * *(s) Solapada*: si puede pertenecerse a varias especializaciones.

***** Agregación
Entidad genérica de la que no se especifica estructura interna.

**** Heurísticas de modelado

 1. El grado de las relaciones suele ser binario. La cardinalidad
    n-aria hay que analizarla por partes.

 2. La aparición de ciclos es normal, pero pueden estar dando lugar
    a información redundante.

 3. No se debe abusar de las agregaciones. Quizá un conjunto nuevo
    solucione la agregación.

**** Refinamiento
El refinamiento transforma diagramas E/R.

***** TODO Primitivas descendentes
Parten de versión general y llegan a versión específica. No todos
los esquemas son producibles descendentemente, sólo los basados en
conexiones en serie y paralelo.

# TODO: Tipos de primitivas
***** TODO Primitivas ascendentes
Van de una visión específica a la versión conectada. Todos los
esquemas son producibles ascendentemente.

# TODO: Tipos de primitivas
***** TODO Diseño centrífugo
Varía el orden de aplicación en los refinamientos.

***** Diseño mixto
Se produce un armazón y se modela cada parte con primitivas descendentes,
luego se conecta con primitivas ascendentes. Permite más flexibilidad.

*** Seminario 4: Modelado de datos
**** Esquemas de navegación

 - I :: inserción,
 - D :: borrado,
 - U :: actualización,
 - R :: consulta.

Las flechas marcan los atributos de entrada. Los atributos que aparecen
sin flecha son de salida. El sentido en el que se obtienen lo marcan las
flechas.

***** Errores
Un esquema de navegación sólo puede tener una consulta de inserción,
borrado o actualización; la única excepción son las entidades débiles.

*** 4. Normalización
**** Algoritmos
***** Simplificación de conjunto de dependencias funcionales
Dado un conjunto de dependencias funcionales, lo simplifica a uno
equivalente. Usos:

 * facilitar la normalización posterior,
 * facilitar el cálculo de claves candidatas.

****** Algoritmo
1. Simplificar partes *derechas* A→BC como A→B y A→C.
2. Simplificar partes izquierdas eliminando *atributos raros*, esto
   es, si AB→C y A→B, tenemos directamente A→C.
3. *Eliminar* las dependencias que se deducen de otras.

***** Cálculo de claves candidatas
Obtener las claves candidatas de una relación. Se resume en tener cuidado
con independientes y equivalentes y luego simplemente formar claves con la
izquierda y con ambas.

****** Algoritmo
Clasificamos en

 * atributos independientes de las relaciones,
 * parejas de atributos equivalentes
 * atributos solo a izquierda,
 * atributos en ambos lados,
 * atributos solo a derecha.

Y ejecutamos

1. Elimina atributos *independientes* del algoritmo, formarán
   siempre parte de la clave.
2. Elimina *equivalencias*, puede considerar uno y olvidar el otro,
   podría formar parte de la clave cualquiera de los dos.
3. Comprueba si con los de izquierda se forma clave.
4. Comprueba en caso de que no haya funcionado añadiendo atributos
   de ambos lados.
5. Incorpora independientes.
6. Incorpora equivalentes.

**** Repaso de formas normales
Se definen

 * 1NF: los dominios de atributo tienen valores indivisibles.
 * 2NF: todo atributo no-primo depende completamente de cualquier
   clave candidata.
 * 3NF: todo atributo no-primo depende de forma no transitiva de cada
   clave candidata de R.
 * BCNF: cada dependencia no trivial (subconjunto) tiene a la derecha
   una clave candidata.

Se resuelven

 * 1NF: partiendo los atributos.
 * 2NF: partiendo en dos tablas distintas.
 * 3NF: partiendo en dos tablas distintas por la transitividad.
 * BCNF: rediseñando en tablas distintas.

***** Pledge
Every [non-key](FNBC) attribute must provide a fact about the key (1NF), the
whole key (2NF) and nothing but the key (3NF). For each candidate key.

***** Non-solvable problems
Beeri and Bernstein showed in 1979 that, for example, a set of
functional dependencies {AB → C, C → B} cannot be represented by a
BCNF schema.

**** 4.1. Normalización
***** Dependencias
****** Dependencia funcional
Sean relaciones R(A₁,A₂ ⋯ Aₙ), α ⊂ R, β ⊂ R entre atributos.
Decimos que α → β ssi ∀ t,s ∈ r: t[α] = s[α] → t[β] = s[β].

Los valores para el subconjunto α determinan de forma única
los valores para el subconjunto β.

****** Dependencia funcional completa
Una dependencia funcional es completa, α →→ β cuando se tiene
que ningún subconjunto de atributos γ ⊂ α tiene una dependencia
γ → β. Este α es minimal en ese sentido.

****** Atributo primo
Forma parte de una clave candidata

***** Axiomas de Armstrong sobre dependencias
1. Reflexividad. β ⊂ α nos da α → β.
2. Ampliación. α → β nos da αγ → βγ.
3. Transitividad. α → β y β → γ nos dan α → γ.
4. Unión. α → β y α → γ nos dan α → βγ.
5. Descomposición. α → βγ nos da α → β y α → γ.
6. Pseudotransitividad. α → β y βγ → δ nos dan αγ → δ.

****** Cierre de un conjunto de dependencias
F+ se obtiene como clausura de las dependencias de F aplicando
axiomas de Armstrong. Llamamos α+ a todos los atributos que se
obtienen como dependencias desde α.

****** Recubrimiento minimal o canónico
Es el mínimo F' tal que (F')+ = F+.

***** Obtención del recubrimiento minimal

1. *Partimos con la regla de descomposición* todas las partes derechas
   compuestas: A→BC parte en A→B y A→C.

2. *Simplificamos los atributos raros* de la izquierda, aquellos que
   dependen de los que le acompañan: si AB → C y sabemos A → B,
   podemos dejar A → C.

3. *Eliminamos dependencias redundantes* que puedan obtenerse de
   otras.

La ventaja de trabajar con recubrimiento minimal es que, al no
tener dependencias redundantes, podemos comprobar directamente si
cualquiera de ellas se ha perdido al aplicar Teorema de Heath.

***** 1FN
El dominio de cada atributo es atómico y cada valor del atributo
sólo contiene un valor para ese dominio.

***** 2FN
La 2FN es

 * estar en 1FN,
 * todos los atributos no primos dependen de forma completa de las
   claves candidatas.


****** Descomposición sin pérdidas
Una relación (R,r) se descompone *sin pérdidas* en (R1,r1) y (R2,r2)
cuando R1 ∪ R2 = R y además (r1 join r2) = r.

****** Teorema de Heath
Si tenemos grupos α, β, γ con β → γ, podemos separar la relación
sin pérdidas en

 * R1(α,β)
 * R2(β,γ)

***** 3FN
La 3FN es

 * estar en 2FN,
 * no tener dependencias transitivas problemáticas, a través de
   atributos no primos.

****** Dependencia transitiva
CK → β, para β formado por algún atributo no primo, es transitiva
cuando ∃α ⊂ R, (α → R) ∉ F+, tal que

(CK → α) ∈ F;  y además,  (α → β) ∈ F

***** FNBC
La definición original de 3FN tiene deficiencias si hay varias claves
candidatas. La FNBC considera estos casos, es

 * estar en 3FN,
 * ∀ α→β ∈ F se cumple que
   * α es clave candidata y β⊄α, o
   * β ⊂ α.

Es decir, todo determinante es una clave candidata.

***** Cálculo de llaves candidatas
1. Eliminación de atributos independientes: de ellos no se deduce
   ningún otro, tendrán que estar en la clave candidata en cualquier
   caso.

2. Construcción de atributos equivalentes: para cada pareja de
   equivalentes se usa sólo uno de ellos.

3. Clave sin determinantes determinados: se selecciona un candidato a
   clave candidata sin determinantes no determinados.

4. Si hay más claves sin determinantes determinados se necesitará
   cubrir todas las claves posibles, añadiendo a cada paso n nuevo
   determinante que sea determinado.

5. Añadimos atributos independientes a las claves obtenidas

6. Replicamos las claves con las equivalencias del paso 2.

***** Proceso de normalización
1) Localizar las claves candidatas.

   1) Descomponer dependencias a la derecha.
   2) Eliminar atributos raros a la izquierda.
   3) Eliminar dependencias redundantes.
   4) Localizar claves candidatas

2) Comprobar 2FN, usar Teorema de Heath.

3) Comprobar 3FN, eliminar transitividades problemáticas.

**** 4.2. Diseño físico
**** Ejercicios
***** Soluciones normalización
****** Ejercicio 1
Simplificando dependencias queda

| Tabla        | ABCDE        |
| Claves       | AD, DBC, DBE |
|--------------+--------------|
| Dependencias | A → B        |
|              | A → C        |
|              | BC → A       |
|              | BCD → E      |
|              | E → C        |

No existiendo atributos primos, está en 3FN. Normalizamos
a FNBC como

| Tabla        | ABC    | BDE     | EC    |
| Claves       | A, BC  | BDE     | E     |
|--------------+--------+---------+-------|
| Dependencias | A → B  |         | E → C |
|              | A → C  |         |       |
|              | BC → A |         |       |

se ha perdido la dependencia BCD→E.

****** Ejercicio 2
Simplificando dependencias queda

| Tabla        | ABCD   |
| Claves       | AB, AC |
|--------------+--------|
| Dependencias | C → D  |
|              | AB → C |
|              | C → B  |

La tabla no está en 2FN por C→D. Partimos como sigue para llegar a 3FN

| Tabla        | ABC    | CD    |
| Claves       | AB, AC | C     |
|--------------+--------+-------|
| Dependencias | C → B  | C → D |
|              | AB → C |       |


Y partimos de nuevo para llegar a FNBC

| Tabla        | AC | CB    | CD    |
| Claves       | AC |       | C     |
|--------------+----+-------+-------|
| Dependencias |    | C → B | C → D |
|              |    |       |       |
|              |    |       |       |

Hemos perdido la dependencia AB→C.

****** Ejercicio 3
Simplificando dependencias queda

| Tabla        | AOIVND |
| Claves       | VI     |
|--------------+--------|
| Dependencias | V → D  |
|              | I → A  |
|              | IV → N |
|              | A → O  |

No estamos en 2FN por V→D y I→A, partimos en

| Tabla        | IVN    | IA    | AO    | VD    |
| Claves       | VI     | I     | A     | V     |
|--------------+--------+-------+-------+-------|
| Dependencias | IV → N | I → A | A → O | V → D |

Que está en FNBC.

****** Ejercicio 5
Simplificando dependencias queda

| Tabla        | SIDBQO |
| Claves       | S      |
|--------------+--------|
| Dependencias | S → I  |
|              | S → D  |
|              | I → B  |
|              | S → Q  |
|              | B → O  |

Estamos en 2FN porque todas dependen completamente por transitividad
de S, pero no estamos en 3FN. Corregimos partiendo en

| Tabla        | SIDQ  | IB    | BO    |
| Claves       | S     | I     | B     |
|--------------+-------+-------+-------|
| Dependencias | S → I | I → B | B → O |
|              | S → D |       |       |
|              | S → Q |       |       |

Que están en FNBC.

****** Ejercicio 6
Simplificando dependencias queda

| Tabla        | ABCDE  |
| Claves       | BE     |
|--------------+--------|
| Dependencias | A → C  |
|              | B → C  |
|              | C → D  |
|              | DE → C |
|              | CE → A |

No está en 2FN porque B→C, por ejemplo. Vamos a partir la tabla para
llegar a 3FN sin pérdidas. A cada paso, partiremos de forma que los
atributos compartidos entre las dos partes sean una clave en alguna de
ellas.

| Tabla        | BE | BC    | ECD    | ECA    |
| Claves       | BE | B     | EC, ED | EC, EA |
|--------------+----+-------+--------+--------|
| Dependencias |    | B → C | DE → C | CE → A |
|              |    |       | C → D  | A → C  |

Esta separación no está en FNBC por C → D y A → C, partimos de nuevo
para llegar a FBNC,
 
| Tabla        | BE | BC    | EC | CD    | EA | AC    |
| Claves       | BE | B     | EC | C     | EA | A     |
|--------------+----+-------+----+-------+----+-------|
| Dependencias |    | B → C |    | C → D |    | A → C |

hemos perdido DE → C y CE → A como dependencias.

****** Ejercicio 7
Simplificando dependencias

| Tabla        | ABCDE  |
| Claves       | AB     |
|--------------+--------|
| Dependencias | AB → C |
|              | C → E  |
|              | E → C  |
|              | C → D  |

Estamos en 2FN porque todos dependen de AB de forma completa; pero no
estamos en 3FN. Partimos para llegar a 3FN.

| Tabla        | ABC    | CE    | CD    |
| Claves       | AB     | C, E  | C     |
|--------------+--------+-------+-------|
| Dependencias | AB → C | E → C | C → D |
|              |        | C → E |       |

Que están en FNBC.

***** Ejercicio 1
#+begin_statement
Normalizar,

A → BC,  BC → A, BCD → E, E → C.
#+end_statement

Las dependencias están ya descompuestas a la derecha.

Eliminamos atributos raros a izquierda, BC → E no tiene
atributos raros; para BCD → E podemos comprobar que ni
BC genera D, ni BD genera C ni CD genera B.

Eliminamos dependencias redundantes, la A → BC no lo es
porque no se sigue de las demás ninguna dependencia de A.
La BC → A tampoco lo es, así como la BCD → E ni E → C.
***** Ejercicio 2
#+begin_statement
Normalizar R(A,B,C,D) con

AB → D,  C → D,  AB → C,  C → B.
#+end_statement

****** Recubrimiento minimal
Descomponemos a derecha, ya hecho. simplificamos atributos
raros, ya hecho. Eliminamos dependencias redundantes, como
la AB → D; nos queda

C → D,  AB → C,  C → B.

****** Clave candidata
Localizamos claves candidatas

| Izquierda | Ambos | Derecha |
|-----------+-------+---------|
| A         | BC    | D       |

tenemos A+={A}, luego añadimos otra, AB+={ABCD} es clave
candidata.

****** 2FN
Los atributos C, D deberían depender de forma completa.
Tenemos que no dependen de A sola ni de B sola, luego lo
hacen de forma completa.

****** 3FN
Tenemos una transitividad AB → C y C → D. Queremos que todo
determinante sea una clave candidata, así que partimos

R1(_A,B_,C) y R2(_C_,D)

donde R1 tiene AB → C y C → B; mientras que R2 tiene C → D.

****** FNBC
Tenemos un determinante en R1 que no es clave candidata.
Solucionamos partiendo

R2(_C_,D),
R3(_A,C_),
R4(_C_,B),

el problema aquí es que se pierde el hecho de que AB → C.

***** Ejercicio 3
#+begin_statement
Normalizar R(A,O,I,V,N,D) con,

V → D,  I → A,  IV → N,  A → O.
#+end_statement

****** Clave candidata
Las dependencias están descompuestas a la derecha.
Eliminamos atributos raros a izquierda, nótese que en IV → N, tenemos
I⁺={IAO} y V⁺={VD}, luego no hay atributos raros.
No hay ninguna dependencia redundante, ya que cada
dependencia genera un atributo distinto.

Localizamos claves candidatas,

| Izquierda | Ambos | Derecha |
|-----------+-------+---------|
| VI        | A     | NDO     |

Tenemos que VI forman parte de cualquier clave candidata.
VI⁺={VIANDO}, luego es clave candidata.

****** Segunda forma normal
Comprobamos ahora que esté en segunda forma normal.

 * Los atributos AOD no primo no dependen de forma completa de las
   claves candidatas. Descomponemos

   R(V,I,N)
   R(I,A,O)
   R(V,D)

   tal que cada una está en forma normal. 

****** Tercera forma normal
La única transitividad está en I → A y A → O. Descomponemos
como

 R($V,$I,N)
 R($V,D)
 R($I,A)
 R($A,O)

y todas estas tablas están en FNBC; ya que sólo la primera tiene
una clave candidata compuesta y el único atributo depende de la
clave de forma completa.
***** Ejercicio 4 (es el 2!?)
#+begin_statement
Normalizar R(A,B,C,D)

AB → C,  AB → D,  C → D,  C → B.
#+end_statement

****** Recubrimiento minimal
Partimos a la derecha, ya hecho. Simplificamos atributos raros

***** Ejercicio 5
#+begin_statement
Normalizar

S → ID,  I → B,  IS → Q,  B → O
#+end_statement

****** Recubrimiento minimal
Partimos a la derecha S → I, S → D. Simplificamos atributos raros, con
S → Q, nos queda

 S→I, S→D, I→B, S→Q, B→O.

****** Clave candidata

| Izq | Amb | Der |
|-----+-----+-----|
| S   | IB  | DQO |

Y tenemos que S+={SIDBQO}, luego es clave candidata.

****** 2FN
Deberían depender todos de forma completa de S y lo hacen
porque está formada por un sólo atributo.

****** 3FN
Tenemos una transitividad S→I, I→B, B→O; la quitamos como

R1(_S_,I,D,Q)
R2(_I_,B)
R3(_B_,O)

****** FNBC
Todas las relaciones con una única llave candidata en 3FN están en
FNBC.  Todo determinante es clave candidata.

***** Ejercicio 6
Sea el esquema R(A,B,C,D,E) con dependencias

 A→C, B→C, C→D, DE→C, CE→A.

****** Recubrimiento minimal
Empezamos trabajando con un recubrimiento minimal de las
dependencias, simplificamos a derecha y eliminamos atributos
raros. Eliminamos dependencias redundantes. Ya hecho.

****** Clave candidata

| Izq   | Ambos | Der |
|-------+-------+-----|
| BE    | ACD   |     |

Tenemos {BE}+={BECAD}, luego es clave candidata.

R(_B,E_,A,C,D)

****** 2FN
Todos deberían depender de forma completa de BE, pero no lo hacen;
tenemos B→C, B→D, luego partimos

R1(_B,E_,A)
R2(_B_,C,D)

****** 3FN
No queremos ahora dependencias transitivas completas, luego

R1(_B,E_,A)
R2(_B_,C)
R3(_C_,D)

hemos perdido que CE→A (??).

****** FNBC
???

***** Ejercicio 7
#+begin_statement
Sea el esquema R(A,B,C,D,E) con dependencias

AB → C,  C → E,  E → C,  C → D,  AB → E.
#+end_statement

****** Recubrimiento minimal
Descomponemos a derecha, quitamos atributos raros y eliminamos
redundancia.

Quitamos AB → E.

****** Clave candidata
Quitamos independientes, que no hay. Reducimos equivalentes,
donde tenemos C→E y E→C. Nos queda

AB→C, C→D

| Izq | Amb | Der |
|-----+-----+-----|
| AB  | C   | D   |

Como {AB}+={ABCDE}, ya tenemos clave candidata única.

****** 2FN
Dependencia completa se tiene siempre.

****** 3FN
Transitividades que se pueden quitar están C→E y C→D

R1(_A,B_,C)
R2(_C_,D,*E*)

Perdemos que E→C.

****** FNBC
En R2 tenemos dos llaves candidatas, queremos que todo determinante
sea clave candidata.

R1(A,B,C) con clave A,B
R2(C,D,E) con clave C o con clave E.

***** Ejercicio 8
#+begin_statement
Dado

A→B, A→C, A→B, B→C, B→A, B→D, D→C
#+end_statement

****** Claves candidatas

| Izq | Med | Der |
|-----+-----+-----|
|     | ABD | C   |

A+={A,B,C,D}
B+={B,A,C,D}
D+={C}

La A y la B son claves candidatas. Hay dependencias transitivas
pasando por la D.

****** 3FN
No queremos transitividad a través de no primos, así que

R(A,B) candidatas A y B
R(A,D) clave A
R(D,C) clave D

****** FNBC
Todo determinante debe ser clave candidata. Lo es.
** Apuntes de álgebra homológica de Pascual Jara
*** Homología de Hochschild
**** R;R módulos
***** R;R módulo
Sea $R$ una $K\text{-álgebra}$; un $(R;R)$ *módulo* es un $R$ módulo a
izquierda y derecha verificando la *relación de compatibilidad*:

\[r_1(mr_2) = (r_1m)r_2\]

En particular, se tiene,

\[km = mk \quad \forall k \in K\]

Un *homomorfismo de R;R-módulos* es un homomorfismo de R-módulos a izquierda y
R-módulos a derecha. Forman la categoría $(R;R)\mathtt{-Mod}$.

***** Álgebra envolvente
Sea $R$ una $K\text{-álgebra}$, llamamos *álgebra envolvente* a $R^e = R \otimes R^{op}$.
Con el producto:

\[ (r_1 \otimes s_1)(r_2 \otimes s_2) = (r_1r_2) \otimes (s_2s_1)\]

***** Caracterización de R;R-módulos
Para cada $K\text{-álgebra}$, $R$, las categorías siguientes son isomorfas:

  - $(R;R)\text{-Mod}$
  - $R^e\text{-Mod}$
  - $\text{Mod-}R^e$

****** Demostración
Nótese primero que a $R^e$ le damos estructura de álgebra con el
producto:

\[
(r_1\otimes s_1)(r_2\otimes s_2) = (r_1r_2\otimes s_2s_1)
\]

******* Primera implicación
Si tenemos $M$ un $(R;R)$ módulo, podemos darle estructura de $R^e$ módulo
con: $(r\otimes s)m = rms$. Que esta estructura es compatible con el producto
se comprueba trivialmente con:

\[
(a\otimes b)(c \otimes d)m = acmdb = (ac \otimes bd)m
\]

******* Segunda implicación
Si tenemos $M$ un $R^e$ módulo, podemos darle estructura de $R;R$ módulo
tomando: $rms = (r\otimes s) m$. La relación de compatibilidad se tiene por
el mismo proceso anterior.

**** Cohomología de Hochschild
***** Definición
Sea $R$ una $K\text{-álgebra}$ y $M$ un $(R;R)\text{-módulo}$, llamamos:

  - *Cohomología de Hochschild* de $R$ en $M$ a $HH^{\bullet}(R,M) = \operatorname{Ext}^\bullet_{R^e}(R,M)$.
  - *Homología de Hochschild* de $R$ en $M$ a $HH_{\bullet}(R,M) = \operatorname{Tor}_\bullet^{R^e}(R,M)$.

***** Notas
1. [[https://sbseminar.wordpress.com/2007/07/22/hochschild-homology/][Hochschild homology | Secret Blogging Seminar]]

***** Resolución estándar
Para cada k-álgebra $R$ se tiene $(P_{\bullet},d_{\bullet})$ resolución proyectiva de $R$ en 
$(R;R)\mathrm{-mod}$. Se llama *resolución estándar* de $R$, definiendo

 - $P = R \otimes (R^{\otimes n}) \otimes R$
 - $d_{n} = \sum_{i=0}^n (-1)^id^i_n$

donde tomamos

\[
d_n^i(a_0 \otimes \dots \otimes a_{n+1}) =
a_0 \otimes \dots \otimes a_ia_{i+1}\otimes \dots \otimes a_{n+1}.
\]

***** Complejo de cocadenas
Para el cálculo de la cohomología tenemos un complejo de cocadenas

\[
\mathrm{Hom}_K(K,M) \overset{b^0} \longrightarrow
\mathrm{Hom}_K(R,M) \overset{b^1} \longrightarrow
\mathrm{Hom}_K(R^{\otimes 2},M) \overset{b^2} \longrightarrow
\dots.
\]

Donde están definidas las $b^{n}$ como

 - $b^0(m)(a) = am-ma$
 - $b^n = \sum^{n+1}_{i=0}(-1)^ib_i^n$

para unas aplicaciones auxiliares $b_i^n$ definidas como

\[
b^n_i(f)(a_1\otimes \dots \otimes a_{n+1}) =
\left\{\begin{array}{ll} 
a_1f(a_2\otimes\dots\otimes a_{n+1})& \mbox{if } i=0  \\
f(a_1\otimes\dots\otimes a_ia_{i+1}\otimes\dots\otimes a_{n+1}}& \mbox{if } i=1,\dots,n \\
f(a_1\otimes\dots\otimes a_n)a_{n+1}& \mbox{if } i=n+1
\end{array} 
\right.
\]

**** Desde Weibel
***** Identidades simpliciales
Las identidades simpliciales son las relaciones entre morfismos cara y
morfismos degenerados en un objeto simplicial.

****** Objeto simplicial
Un conjunto simplicial con morfismos:

 - *Morfismos cara*, $\partial_i : S_n \to S_{n-1}$, que eliminan el vértice $i$.
 - *Morfismos degenerados*, $\sigma_i : S_n \to S_{n+1}$, que duplican el vértice $i$.

****** Identidades simpliciales
Se cumplen:

 1. $\partial_i\circ\partial_j = \partial_{j-1}\partial_i$ cuando $i<j$
 2. $\sigma_i\comp\sigma_j = \sigma_j\circ\sigma_{i-1}$ cuando $i > j$
 3. Se componen como:

    \[
    \partial_i\circ s_j = \left\{\begin{array}{ll} 
    s_{j-1}\circ\partial_i & \mbox{if } i<j \\
    id & \mbox{if } i=j \mbox{ or } i=j+1 \\
    s_j\circ \partial_{i-1}& \mbox{if } i>j+1
    \end{array} 
    \right.
    \]

****** Diferencial alternado
Definimos el morfismo cara alternado como la suma alternada de morfismos
cara:

\[
\partial(x) =
\sum_{k=0}^n (-1)^k \partial_k(x)
\]

Esto nos da un operador de frontera cumpliendo $\partial\circ\partial=0$.

******* Demostración
Usando distributividad de la composición y la primera identidad 
simplicial:

\[\begin{aligned}
\partial\circ\partial
&=
\left(
\sum (-1)^k \partial_k
\right)
\left(
\sum (-1)^t \partial_t
\right)
\\&= 
\sum_{k,t} (-1)^{k+t} \partial_k\partial_t
\\&=
\sum_{k<t} 
\left(
(-1)^{k+t} \partial_k\partial_t +
(-1)^{k+t-1} \partial_{t-1}\partial_k
\right)
\\&= 0
\end{aligned}
\]
***** Módulo simplicial sobre R;R módulo
Sea $R$ una k-álgebra y $M$ un $R;R$ módulo. Tenemos un k-módulo simplicial
en $M\otimes R^{\otimes\ast}$, dado por:

\[
\dots \longrightarrow
M\otimes R\otimes R \longrightarrow
M\otimes R \longrightarrow
M \longrightarrow 
0
\]

Con fronteras:

\[
\partial_i(m\otimes r_1 \otimes \dots \otimes r_n) =
\left\{\begin{array}{ll} 
mr_1 \otimes r_2 \otimes \dots \otimes r_n& \mbox{if } i = 0 \\
m \otimes r_1 \otimes r_2 \otimes \dots \otimes r_ir_{i+1} \otimes \dots \otimes r_n& \mbox{if } 0 < i < n \\
r_nm \otimes r_1 \otimes r_2 \otimes \dots \otimes r_{n-1} & \mbox{if } i = n
\end{array}.
\right.
\]

Y con degeneración

\[
\sigma_i(m \otimes r_1 \otimes \dots \otimes r_n) =
m \otimes \dots \otimes r_i \otimes 1 \otimes r_{i+1} \otimes \dots \otimes r_n.
\]

***** Homología de Hochschild
La homología de Hochschild se define como la de los k-módulos:

\[
HH_n(R,M) = H_nC(M\otimes R^{\otimes\ast})
\]

**** Ejemplos de cálculo de cohomología de Hoschild
***** TODO Derivaciones y derivaciones externas
*** Álgebras separables
**** Álgebras separables
***** Dimensión de Hochschild
Definimos $\mathrm{Hdim}(R)$ como el menor $n$ tal que $HH^{n+1}(R,M) = 0$ para cualquier
módulo $M$. Si no existe, decimos que hay dimensión de Hochschild infinita.

***** Álgebras separables
Las álgebras de dimensión de Hochschild $0$ se llaman *separables*. Se
tiene $R$ un $R^e-\mathrm{mod}$ izquierda proyectivo.

***** Caracterización de álgebras separables
Para una k-álgebra R equivalen:

  1) Existen $a_i,b_i \in R$ con $\sum_{i=1}^na_ib_i=1$ y $\sum_{i=1}^n ra_i\otimes b_i = \sum_{i=1}^n a_i \otimes b_ir$.
  2) Dimensión de Hochschild de $R$ cero.
  3) $\mathrm{Der(R,M)} = \mathrm{Der}_{int}(R,M)$ para cada $M$ y $n \geq 1$.

Llamamos $e = \sum_{i=1}^n a_i\otimes b_i \in R^e$ *idempotente de separabilidad*.

***** Teorema de Zelinsky
Toda k-álgebra separable es un k-espacio vectorial de dimensión finita.

**** Álgebras semisimples
***** Álgebra semisimple
Una k-álgebra es semisimple si cada módulo a la izquierda suyo es proyectivo.

***** Separable es semisimple
Toda k-álgebra separable es semisimple.

****** TODO Demostración

***** Álgebras separables sobre cuerpos algebraicamente cerrados
Una k-álgebra separable en un cuerpo de característica cero es de la forma:

\[
R \cong
M_{n_1}(K) \times \dots \times M_{n_t}(K)
\]

***** Traza
Llamamos *traza* de $\varphi \in \mathrm{End}(R)$ a la suma de su diagonal. Tenemos

 - una aplicación $\tau(r) = \mathrm{Tr}(\lambda(r))$ k-lineal.
 - una aplicación $\sigma(r,s) = \tau(rs)$ k-bilineal simétrica.

Cuando $R$ es k-álgebra separable, $\sigma$ es no degenerada.

***** Caracterización de álgebras separables
Para una k-álgebra $R$ equivalen

 1) $R$ una k-álgebra separable.
 2) $\mathrm{dim}_{k}(R) < \infty$ y $\sigma$ es forma bilineal simétrica no degenerada.
 3) Existe un único idempotente de separabilidad simétrico.

**** Álgebras formalmente lisas
***** Extensiones de Hochschild
Para $\pi : S \longrightarrow R$ homomorfismo sobreyectivo con $\ker(\pi)^2=0$,

\[
0 \longrightarrow 
\mathsf{a}= \mathrm{ker}(\pi) \longrightarrow
S \longrightarrow
R \longrightarrow
0
\]

es una *extensión de Hochschild* de $R$ por $\mathsf{a}$.

***** Estructura de R;R-módulo de la extensión
Si $0 \longrightarrow \mathsf{a} \overset{\pi}\longrightarrow S \longrightarrow R \longrightarrow 0$ es una extensión de Hochschild, entonces
$\mathsf{a}$ es un R;R-módulo.

****** Demostración
Consideramos una inversa del homomorfismo sobreyectivo $\pi \circ \psi = id$.
Definimos el producto como

 - $ax = \psi(a)x$
 - $xa = x\psi(a)$

y comprobamos que $a(bx) = (ab)x$. Se tiene en efecto que

\[
\psi(a)\psi(b) - \psi(ab) \in \mathrm{ker}(\pi) = \mathsf{a}
\]

***** Extensiones equivalentes
Dos extensiones de Hochschild son equivalentes si existe un diagrama
conmutativo

\[\begin{tikzcd}
0 \rar & M \arrow[d,equal] \rar & S_1\dar{\varphi}\rar{\pi_{1}} & R \rar\dar[equal] & 0 \\
0 \rar & M \rar & S_2\rar{\pi_{2}} & R \rar & 0
\end{tikzcd}\]

para $\varphi$ un homomorfismo de k-álgebras.

***** Álgebra formalmente lisa
Un álgebra $R$ es formalmente lisa si su dimensión de Hochschild es menor o
igual que 1. Equivalentemente, $HH^2(R,M) = 0$ para cualquier $M$. Como
consecuencia, toda extensión de Hochschild es trivial.

***** Producto de separable y formalmente lisa
Si $S$ es separable y $R$ es formalmente lisa, $R \otimes S$ es formalmente lisa.

*** Anillos graduados
**** Álgebra aumentada
Una $K\text{-álgebra}$ $R$ es *aumentada* si existe un $R\text{-módulo}$ $M$ con un 
epimorfismo $\varepsilon\colon R \to M$.

***** Álgebra aumentada tensor
Si $\varepsilon\colon R \to M$ es un álgebra aumentada, $\varepsilon\otimes S\colon R\otimes_K S \longrightarrow M \otimes_K S$ es
un álgebra aumentada.

**** Módulos y álgebras graduadas
***** Módulo graduado
Un $K\text{-módulo}$ graduado es aquel que se escribe como suma directa,

\[
M = \bigoplus_{n \in \mathbb{N}} M_n.
\]

****** Elemento homogéneo
Un elemento es homogéneo de grado $n$ si pertenece a $M_n$.

****** Homomorfismo graduado
Un homomorfismo $f\colon M \to N$ tal que $f(M_n) \subseteq f(N_n)$.

****** Álgebra graduada
Un $K\text{-módulo}$ graduado $R = \bigoplus R_i$ cumpliendo

\[
R_rR_t \subseteq R_{r+t}.
\]

***** Ejemplos de álgebras graduadas
****** Graduación trivial
****** Graduación del anillo de polinomios
****** Graduación del anillo de endomorfismos
***** Homomorfismos graduados
Un homomorfismo graduado de grado $t \in \mathbb{N}$ es aquel homomorfismo $f\colon M \to N$
cumpliendo $f(M_r) \subseteq f(M_{r+t})$.

*** Módulos diferenciales
**** Diferencial
Un homomorfismo graduado de grado uno, $\delta\colon M \to M$ se llama *diferencial*
si $\delta\circ\delta = 0$.

**** DG-módulo
Un par $(M,\delta)$ formado por un $K\text{-módulo}$ graduado $M$ y un diferencial $\delta$.

***** Homomorfismo de DG-módulos
Un homomorfismo de DG-módulos $f \colon (M,\delta_1) \to (N,\delta_2)$ es un homomorfismo
de módulos graduados cumpliendo

\[
f\delta_1 = \delta_2 f.
\]

**** Álgebra graduada diferencial
Una $K\text{-álgebra}$ graduada $R$ con un diferencial $\delta\colon R\to R$ que verifica:

  * $(R,\delta)$ es un DG-módulo.
  * $\delta(ab) = \delta(a)b + (-1)^{|b|}a\delta(b)$.

Es lo que conocemos como *álgebra graduada diferencial*, o DG-álgebra.

***** Aritmética en álgebras graduadas I
Dada una DG-álgebra $(R,\delta)$,

 1) Para elementos homogéneos $h_1,\dots,h_n$ se verifica

    \[ \delta(h_1\dots h_n) =
    \sum_{i=1}^t (-1)^{|h_1|+\dots+|h_{i-1}|}h_1\dots \delta(h_i)\dots h_t.
    \]

 2) Para elementos $a_0,\dots,a_n \in R_0$ se verifica

    \[\delta(a_0 \delta(a_1)\dots \delta(a_n)) =
    \delta(a_0)\delta(a_1)\dots\delta(a_n).
    \]

***** TODO Aritmética en álgebras graduadas II

**** Complejo de Hochschild
Definimos el *complejo de Hochschild* como

\[
C_{\bullet}(R,M)\colon \dots 
\longrightarrow M \otimes R^{\otimes n}
\overset{d}\longrightarrow M \otimes R^{\otimes n-1}
\overset{d}\longrightarrow \cdots
\]

donde las diferenciales se definen como $d = \sum (-1)^id_i$ para

\[\begin{aligned}
d_0(m\otimes a_1\otimes\dots\otimes a_n) &= (ma_1)\otimes \dots \otimes a_n \\
d_i(m\otimes a_1\otimes\dots\otimes a_n) &= m \otimes a_1\otimes \dots \otimes a_ia_{i+1} \otimes \dots \otimes a_n \\
d_i(m\otimes a_1\otimes\dots\otimes a_n) &= a_nm \otimes a_1\otimes \dots \otimes \dots \otimes a_{n-1} \\
\end{aligned}
\]

***** Es un diferencial
Se tiene que $d\circ d = 0$.

***** Complejo bar
En el caso particular de $R=M$ tenemos

\[C_{\bullet}(R) = C_{\bullet}(R,R) = 
(\cdots \to R^{\otimes n+1} \to \cdots \to R)\]

Llamamos *complejo bar* a

\[ C^{bar}_{\ast}(R) = (\cdots \to R^{\otimes n} \to \cdots \to R^{\otimes 2}).
\]

***** Complejo bar normalizado
Llamamos $D_n$ al generado por elementos $m\otimes a_1\otimes \dots\otimes a_n$ donde algún $a_i = 1$.
Podemos crear el complejo bar normalizado con módulos de la forma

\[\frac{M\otimes R^{\otimes n}}{D_n} \cong M \otimes \overline{R}^{\otimes n}.
\]

Lo representamos por $\overline{C}(R,M)$.

*** La DG-álgebra Omega
**** DG-álgebra omega
Definimos

\[
\Omega_S^nR = 
R \otimes_S \overline{R}^{\otimes n}
\quad\text{ y, en total, }\quad
\Omega_SR = \bigoplus_{n\in \mathbb{N}} \Omega_S^n R.
\]

La diferencial la definimos mediante

\[
\delta(a_0\oplus \overline{a_1} \oplus\dots\oplus \overline{a_r})
=
1 \oplus \overline{a_0} \oplus \dots \oplus \overline{a_r}.
\]

** Álgebra conmutativa de Carlos Ivorra
*** I. Funtores Derivados
**** 1.1. Haces
***** Prehaces
Un *prehaz* sobre un espacio topológico $X$ es un par $({\cal F},\rho)$, donde cada abierto $U$
tiene un grupo asociado ${\cal F}(U)$ y cada inclusión $U \subset V$ tiene asociado un homomorfismo
llamado *restricción*, $\rho_U^V : {\cal F}(V) \longrightarrow {\cal F}(U)$ cumpliendo:

  - ${\cal F}(\varnothing) = 0$
  - $\rho_U^U$ es la identidad
  - Si $U\subset V\subset W$, entonces $\rho_V^W \circ \rho_U^V = \rho_U^W$

Cuando los grupos ${\cal F}(U)$ son anillos o módulos tenemos un *prehaz de anillos* o un
*prehax de módulos*.

# Categóricamente, un funtor contravariante desde los conjuntos del espacio
# topológico con la inclusión a los grupos, o módulos, o álgebras...

***** Notación de restricción
Normalmente escribiremos $f|_{U}$ para llamar a la restricción de $f$ a $U$, esto 
es $\rho_U^V(f)$.

***** Haces
Un *haz* es un prehaz tal que si $U = \bigcup U_i$ es el recubrimiento de un abierto:

  - Si $f|_{U_i} = 0$ para todos los $i$, entonces $f = 0$.
  - Para una familia de elementos $f_i \in {\cal F}(U_i)$ cumpliendo que 
    $f_i|_{U_i \cap U_j} = f_j|_{U_i \cap U_j}$, se tiene que hay un $f \in {\cal F}(U)$ tal que $f|_{U_i} = f_i$.

***** Grupo de gérmenes o grupo local
Dado un prehaz ${\cal F}$ sobre $X$, con $P \in X$, llamamos *grupo de gérmenes* en $P$ al grupo
${\cal F}_P$, formado por las clases de equivalencia de pares $(U,f)$ con $P\in U$, $f \in {\cal F}(U)$;
respecto de la relación dada por $(U,f) \sim (V,g)$ ssi hay un abierto $W \subset U \cap V$
tal que $P \in W$ y además $f|_W = g|_W$. Teniendo como operación de grupo a:

\[ [(U,f)]+[(V,g)] = [(U\cap V, f|_{U\cap V} + g|_{U\cap V})] \]

***** Homomorfismo de prehaces
Un *homomorfismo de prehaces* $\alpha : {\cal F} \longrightarrow {\cal G}$, asigna a cada abierto $U$ un homomorfismo
de grupos $\alpha_U : {\cal F}(U) \longrightarrow {\cal G}(U)$, tal que:

\[ \begin{tikzcd}
{\cal F}(V) \rar{\alpha_V} \dar[swap]{\rho_U^V} & {\cal G}(V) \dar{\rho_U^V} \\
{\cal F}(U) \rar{\alpha_U} & {\cal G}(U)
\end{tikzcd} \]

# Categóricamente son transformaciones naturales.

** Koszul pairs
# Parte de la memoria de beca de colaboración con Pascual Jara.
*** Introduction
*Koszul algebras* have numerous applications in diverse fields of
Mathematics such as Algebraic Topology, Combinatorics, Representation
Theory or Algebraic Geometry, as it is showed in cite:polishchuk05,
and many of its fundamental properties still hold in *Koszul rings*,
a particular case of graded rings.

*Almost-Koszul pairs* are a tool for the study of Koszul rings; to
every strongly graded ring corresponds a canonical almost-Koszul pair.
Every almost-Koszul pair has three associate chain complexes and three
cochain complexes. If any of this six complexes is exact, all the others
are exact too; in this case, we call the pair a *Koszul pair*.

*** Area of interest
In order to define Koszul pairs, we need to introduce some homological
algebra prerequsites. We will define abelian categories in general,
even if we are going to use later only the particular case of module
categories, where we will define projective, injective and flat
modules.

In particular, we will need to define *Hoschschild comohology*.

**** Abelian categories
The theory of abelian categories was introduced by Buchsbaum and Grothendieck
in cite:grothendieck57 to unify the multiple cohomology theories at the time.

***** Additive category
The original motivation for additive categories is the category of abelian
groups, and, more generally, the category of momdules over a fixed ring $R$.
In these categories, morphisms between two objects form an abelian group;
and we can define functors preserving this group structure.

#+begin_definition
${\cal C}$ is an *additive category* if:

 - $\mathrm{Hom}(A,B)$ is an /abelian group/.
 - /Distributivity/ holds: $b \circ (f+g) = b\circ f + b \circ g$ and $(f+g)\circ a = f\circ a + g\circ a$.
 - Has a /zero object/.
 - Has finite /products/ and /coproducts/.

A functor $T$ between two additive categories is and *additive functor* 
if $T(f+g) = Tf+Tg$. cite:rotman08_setting
#+end_definition

***** Abelian category
Our interest is specifically on abelian categories. We will need to
assume that every morphism has a kernel and a cokernel in order to
prove results on homological algebra.

#+begin_definition
An *abelian category* is an /additive category/ such that

  * every morphism has a kernel and cokernel.
  * every monomorphism is a kernel.
  * every epimorphism is a cokernel.
#+end_definition

The category of $R\text{-modules}$ is an abelian category, but also
the category of chain complexes of an arbitrary abelian category,
$\mathtt{Ch}({\cal A})$, is an abelian category.

**** Chain complexes and homology
/Homology/ was originally defined in algebraic topology as a rigorous
method allowing the topological distinction of manifolds with arbitrary
dimensional holes. The same construction can be translated into multiple
different homology theories.

$\quad$

In abelian categories, the homology provides a formal description of
the failure of a functor to be exact.

***** Chain complexes
/Chain complexes/ were initially a representation the relationships
between cycles and boundaries on a topological space; we will study
chain complexes in the abstract setting of module categories, devoided
of any explicit relation to its motivating example.

#+begin_definition
A *chain complex* is a family of $R\text{-modules}$ $\left\{ C_n \right\}$ and homomorphisms
$d_n \colon C_n \to C_{n-1}$ called /differentials/, such that each composite of
consecutive differentials is zero, i.e. $d_{n-1} \circ d_n = 0$.
#+end_definition

#+begin_theorem
Given an abelian category ${\cal A}$, the category $\mathtt{Ch}({\cal A})$ is an abelian category.
cite:weibel94_introd
#+end_theorem

***** Exact sequences
/Exact sequences/ provide a convenient framework for homological questions
such as the completion of the middle term of a particular sequence in such
a way that the homology groups are exactly zero. This kind of problems, in
particular in the category of groups, have been proven to be useful to the
resolution of problems such as the classification of finite simple groups.

#+begin_definition
A pair of composable morphisms is *exact* in the object where they can be
composed when $\mathrm{img}(f) = \mathrm{ker}(g)$. Equivalently, when $\mathrm{coker}(f) = \mathrm{coimg}(g)$.
#+end_definition

#+begin_definition
A *short exact sequence* is a diagram

\[
0 \longrightarrow
a \overset{f}\longrightarrow
b \overset{g}\longrightarrow
c \longrightarrow
0
\]

exact on $a$,$b$ and $c$.
#+end_definition

#+begin_definition
A *morphism of short exact sequences* is defined by three morphisms
$f,g,h$ making the following diagram commute

\[\begin{tikzcd}
0 \rar& 
\cdot \rar{m}\dar{f}& 
\cdot \rar{e}\dar{g}& 
\cdot \rar\dar{h}& 
0 \\
0 \rar& 
\cdot \rar{m'}& 
\cdot \rar{e'}& 
\cdot \rar& 
0 & .\\
\end{tikzcd}\]

The short exact sequences of an abelian category $A$ define a category with
these morphisms called $\mathtt{Ses}(A)$, which is preadditive with the component by 
component sum.
#+end_definition

***** Snake lemma
The /snake lemma/ will provide us with a tool to construct long exact sequences,
which will be used in the definition of derived functors. This is a first result
on algebraic homology theory.

#+begin_theorem
Given a morphism of short exact sequences $f,g,h$; there exists a morphism
$\delta \colon \operatorname{ker} h \to \operatorname{coker} f$ such that the following sequence is exact

\[\begin{tikzcd}
0 \rar &
\mathrm{ker}(f) \rar{m} &
\mathrm{ker}(g) \rar{e} &
\mathrm{ker}(h) \arrow[out = 0,in =180,swap]{dll}{\delta} \\&
\mathrm{coker}(f) \rar{m'} &
\mathrm{coker}(g) \rar{e'} &
\mathrm{coker}(h) \rar &
0
\end{tikzcd}\]
#+end_theorem
#+begin_proof
In this extended diagram

 \[ \begin{tikzcd}
	& 0 \dar              & 0 \dar            & 0 \dar           &   \\
 0 \rar & ker(f) \rar \dar  & ker(g) \rar \dar    & ker(h) \dar \ar[out=355, in=175,looseness=1, overlay, swap]{dddll}{\delta}       &   \\
 0 \rar & a \rar{m} \dar{f}  & b \rar{e} \dar{g} & c \rar \dar{h}        & 0 \\
 0 \rar & a' \rar{m'} \dar & b' \rar{e'} \dar & c' \rar \dar        & 0 \\
	& coker(f) \rar \dar & coker(g) \rar \dar  & coker(h) \rar \dar & 0 \\
	& 0                   & 0                 & 0                &
 \end{tikzcd} \]

we can first define the morphism $\delta$ using the properties of abelian categories
to prove that it exists and then prove that it is exact using again the
properties of monomorphisms and epimorphisms.
#+end_proof

***** Homology
The definition of /homology/ tries to capture the failure of the complex to be
exact as the quotient of the kernel and the image of the sucessive differential
maps.

#+begin_definition
Given a chain complex $\left\{ C_n \right\}$ with differentials $d_n$, we define the nth
homology group as

\[ H_n(C) \cong \mathrm{ker}(d_n) / \mathrm{im}(d_{n+1}).
\]
#+end_definition

It is important to notice that a sequence will be exact if and only if
all their homology groups are zero.

**** Projective, injective and flat resolutions
Resolutions of injective modules are needed to define Hochschild
homology.

***** Definitions
#+begin_definition
An R-module $D$ is:

 1. *Projective* if $\mathrm{Hom}(D, -)$ is exact.
 2. *Injective* if $\mathrm{Hom}(-,D)$ is exact.
 3. *Flat* if $D \otimes -$ is exact.
#+end_definition

We know that $\mathrm{Hom}(D,-)$ and $\mathrm{Hom}(-,D)$ are left-exact and that
$D\otimes -$ is right-exact; so for them to be exact, we only need:

 - A module $D$ is *projective* when $B \longrightarrow C$ epimorphism induces
   $\mathrm{Hom}(D,B) \longrightarrow \mathrm{Hom}(D,C)$ epimorphism.

   \[ \begin{tikzcd}
               & B \dar[two heads] \\
   D \rar\urar[dashed]{\exists} & C
   \end{tikzcd} \]

 - A module $D$ is *injective* when $A \longrightarrow B$ epimorphism induces
   $\mathrm{Hom}(B,D) \longrightarrow \mathrm{Hom}(A,D)$ epimorphism.

   \[ \begin{tikzcd}
     & A \dar[two heads]\dlar \\
   D & B \lar[dashed]{\exists}
   \end{tikzcd} \]

 - A module $D$ is *flat* when $A \longrightarrow B$ monomorphism induces 
   $D\otimes A \longrightarrow D \otimes B$ monomorphism.

***** Resolutions
#+begin_definition
A *projective resolution* is a resolution

\[\dots\longrightarrow P_2\longrightarrow P_1\longrightarrow P_0
\longrightarrow M \longrightarrow 0\]

where every $P_i$ is projective.
#+end_definition

#+begin_definition
An *injective resolution* is a resolution

\[0 \longrightarrow M \longrightarrow E^0\longrightarrow E^1
\longrightarrow E^2 \longrightarrow \dots\]

where every $E^i$ is injective.
#+end_definition

#+begin_definition
A *flat resolution* is a resolution

\[\dots\longrightarrow F_2\longrightarrow F_1\longrightarrow F_0
\longrightarrow M \longrightarrow 0\]

where $F_i$ is flat.
#+end_definition

****** Explicit construction
Notice that, given a module $M$, we can always find
a surjection from a proyective module (if we have /enough
projectives/). So we can construct a projective resolution as

\[ \begin{tikzcd}[column sep=tiny]
&\ker f_2 \drar&&&&\ker \pi\drar &&& \\
\dots&&P_2 \drar[two heads]{f_2}&&P_1 \urar[two heads]{f_1} && P_0 \ar[two heads,rr]{\pi} && M \rar & 0\\
&&&\ker f_1 \urar&&&&
\end{tikzcd} \]

We can also reverse the arrows to obtain an injective resolution.

***** Derived functors
/Derived functors/ provide a canonical way to extend the image of an
exact sequence by a non two-sided exact functor.  We need an abelian
category $A$ with enough injectives to construct left-derived
functors; and we need enough projectives to construct right-derived
functors.

****** Construction of the right derived functor
Let $F$ be additive, covariant and left-exact. Let $0 \longrightarrow M \longrightarrow E^\bullet$ be an 
injective resolution with $M$ deleted; then $F(E^\bullet)$ is a complex, and we define:

\[R^i F(M) = H^i(F(E^\bullet)) = 
\frac{\ker \{F(E^i) \longrightarrow F(E^{i+1})\}}
{\im\{ F(E^{i-1}) \longrightarrow F(E^i)\}}\]

That is, if we take the /injective resolution/

\[ 0 \longrightarrow M \longrightarrow E^0 \longrightarrow E^1 
\longrightarrow \dots\]

we can delete $M$ and apply $F$ to get a (non neccesarily exact) complex where 
we can compute the homology

\[ 0 \longrightarrow F(E^0) \longrightarrow F(E^1)
\longrightarrow F(E^2) \longrightarrow \dots.\]

****** Construction of the left derived functor
Let $F$ be additive, contravariant and left-exact. Let 
$P^\bullet \longrightarrow M \longrightarrow 0$ be a projective resolution with $M$ deleted; 
then $F(P^\bullet)$ is a complex, and we define

\[R^i F(M) = H^i(F(P^\bullet)) = 
\frac{\ker \{F(P_i) \longrightarrow F(P_{i+1})\}}
{\im\{ F(P_{i-1}) \longrightarrow F(P_i)\}}\]

That is, if we take the /projective resolution/

\[\dots \longrightarrow P_2\longrightarrow P_1\longrightarrow P_0
\longrightarrow M \longrightarrow 0\]

Delete $M$ and apply $F$ to get a (non neccesarily exact) complex 
where we can compute the homology:

\[ 0 \longrightarrow F(P_0) \longrightarrow F(P_1)
\longrightarrow F(P_2) \longrightarrow \dots\]

**** Hochschild homology
***** Preliminaries
Our main interest will be on a particular kind of homology and comology called
/Hochschild homology/. This section defines the preliminary necessary concepts
to develop the notion of Hochschild homology.

****** Opposite algebra.
The definition of an /opposite algebra/ is a trvial notion which will be crucial
to create the definition of a standard resolution of an algebra over a field.

#+begin_definition
If $A$ is an $R\text{-algebra}$, the *opposite algebra* of $A$, with a multiplication
given by yuxtaposition is $A^\ast$; an algebra with the same set of elements and where
the multiplication $\circ$ is defined as $x \circ y = yx$.
#+end_definition

****** Enveloping algebra.
#+begin_definition
Let $R$ be a $k\text{-algebra}$, the *enveloping algebra* of $R$ is the tensor
product $R^e = R \otimes R^{op}$, where the product is defined as

\[ (r_1 \otimes s_1)(r_2 \otimes s_2) = (r_1r_2) \otimes (s_2s_1).\]
#+end_definition

#+begin_theorem
Given any $k\text{-algebra}$, $R$, the following categories are isomorphic:

  - $(R;R)\text{-Mod}$
  - $R^e\text{-Mod}$
  - $\text{Mod-}R^e$
#+end_theorem
#+begin_proof
If $M$ is an $(R;R)\text{-module}$, we can provide it with $R^e\text{-module}$ structure
by defining $(r\otimes s)m = rms$. It is trivial to check that this structure is
compatible with our previously defined product, as

\[
(a\otimes b)(c \otimes d)m = acmdb = (ac \otimes bd)m.
\]

If $M$ is an $R^e\text{-module}$, we can provide it with $R;R\text{-module}$ structure
taking $rms = (r\otimes s) m$. Compatibility relation can be checked by the same
reasoning.
#+end_proof

****** Standard resolution.
#+begin_definition
Given $R$, a $k\text{-algebra}$ we define the *standard resolution* $(P_{\bullet},d_{\bullet})$ of $R$ in
$(R;R)\mathrm{-Mod}$ as

 - $P_n = R \otimes (R^{\otimes n}) \otimes R$
 - $d_{n} = \sum_{i=0}^n (-1)^id^i_n$

where

\[
d_n^i(a_0 \otimes \dots \otimes a_{n+1}) =
a_0 \otimes \dots \otimes a_ia_{i+1}\otimes \dots \otimes a_{n+1}
\]
#+end_definition

***** Hochschild homology
#+begin_definition
Given $R$, a $K\text{-algebra}$, and $M$, an $(R;R)\text{-module}$, we define:

  - The *Hochschild cohomology* of $R$ in $M$ as $HH^{\bullet}(R,M) = \operatorname{Ext}^\bullet_{R^e}(R,M)$.
  - The *Hochschild homology* of $R$ in $M$ as $HH_{\bullet}(R,M) = \operatorname{Tor}_\bullet^{R^e}(R,M)$.
#+end_definition

In order to compute the cohomology, we can take the following cochain
complex

\[
\mathrm{Hom}_K(K,M) \overset{b^0} \longrightarrow
\mathrm{Hom}_K(R,M) \overset{b^1} \longrightarrow
\mathrm{Hom}_K(R^{\otimes 2},M) \overset{b^2} \longrightarrow
\dots.
\]

where the $b^n$ are defined as

 - $b^0(m)(a) = am-ma$
 - $b^n = \sum^{n+1}_{i=0}(-1)^ib_i^n$

and the auxiliary morphisms $b_i^n$ are defined as

\[
b^n_i(f)(a_1\otimes \dots \otimes a_{n+1}) =
\left\{\begin{array}{ll} 
a_1f(a_2\otimes\dots\otimes a_{n+1})& \mbox{if } i=0  \\
f(a_1\otimes\dots\otimes a_ia_{i+1}\otimes\dots\otimes a_{n+1}}& \mbox{if } i=1,\dots,n \\
f(a_1\otimes\dots\otimes a_n)a_{n+1}& \mbox{if } i=n+1
\end{array}.
\right.
\]

*** Methods
Our methodology is based on the review of the basic bibliography of the
subject. This article is an attempt to collect all the needed
prerequisites to work with homology and cohomology theory and
ultimately to work with Hochschild homology and Koszul pairs.

Apart from the bibliographic review, we have developed materials for
future students interested in the subject.

***** Wikipedia articles
In order to achieve a higher level of understanding of the topic and
to provide future students with accesible resources, we have written
the following articles for the Spanish wikipedia; they are published
using a Creative Commons license.

 * [[https://es.wikipedia.org/wiki/Compleci%C3%B3n_(%C3%A1lgebra)][Compleción (álgebra)]]
 * [[https://es.wikipedia.org/wiki/Lema_de_escisi%C3%B3n][Lema de escisión]]
 * [[https://es.wikipedia.org/wiki/Lema_de_la_serpiente][Lema de la serpiente]]
 * [[https://es.wikipedia.org/wiki/Funtor_Tor][Funtor Tor]]
 * [[https://es.wikipedia.org/wiki/Homolog%25C3%25ADa_de_Hochschild][Homología de Hochschild]]
 * [[https://es.wikipedia.org/wiki/Categor%25C3%25ADa_coma][Categoría coma]]
 
***** Student-organized seminars
Two student-organized seminars have been held in the university. In
those seminars, the author has lectured about category theory; giving
a basic introduction to mathematics and computer science students.

*** Discussion
**** Koszul algebra
/Koszul rings/ will be a generalization of /Koszul algebras/. A pair of a
ring and its categorical dual, a coring; toghether with certain coherence
relations, will constitute our definition of a Koszul pair.

#+begin_definition
A graded algebra $A$ is a *Koszul algebra* over a field $k$ if
every graded module has a graded projective resolution
$P_{\bullet}$ where the projective module $P_j$ is generated by homogeneous
elements of degree $j$.
#+end_definition

***** Quadratic algebras
Koszul algebras are a particular case of quadratic algebras. We can describe
them in full generality with the following definition.

#+begin_definition
A graded algebra $A$ is a *quadratic algebra* if the natural
application from its tensor algebra $T(A) \to A$ is surjective
and its kernel $J_A$ is generated from $J_{A} \cap (A^{1} \otimes A^1)$. cite:polishchuk05
#+end_definition

In other words, a graded quadratic algebra is determined as the
quotient of a vector space $A_{1}$ by a subspace of homogeneous
quadratic relations $S \subset V \otimes V$ as

\[
A = T(V) / \left\langle S \right\rangle.
\]

#+begin_theorem
Every Koszul $R\text{-ring}$ is a quadratic algebra.
#+end_theorem

**** Almost-koszul pairs
Previous to the definition of Koszul pairs, we are going to define
/almost-koszul pairs/. Those will provide us with a weaker set of
requirements and we will be able to obtain a definition of Koszul
pairs suitable to every almost-koszul pair.

***** Graded rings
#+begin_definition 
A *graded ring* is a ring that can be written as a direct sum of
abelian groups

\[ A = \bigoplus_{n \in \mathbb{N}} A_n\]

such that $A_iA_j \subset A_{i+j}$.
#+end_definition

A *homogeneous element* is an element of any submodule $A_i$ of the
decomposition.

***** Koszul rings
#+begin_definition
A graded ring $A$ is a *Koszul ring* if $A^0$ is a semisimple ring 
and it has a resolution $P_\ast$ by projective graded left A-modules such 
that each $P_n$ is generated by homogeneous elements of degree $n$.
cite:jarastefan10
#+end_definition

***** R-rings
#+begin_definition
An $R\text{-ring}$ is an associative and unital algebra. It is an associative and
unital ring $A$ together with a morphism $u : R \longrightarrow A$.
#+end_definition

A R-ring is *graded* if it is equipped with a decomposition

\[A = \bigoplus_{n \in \mathbb{N}} A^n \]

such that multiplicaton $m^{p,q}$ maps $A^p \otimes A^q$ into $A^{p+q}$. It is *connected* 
when $A_0 = R$. It is *strongly graded* when $m^{1,p}$ is surjective. We 
call $\pi^n_A$ to the projection of $A$ onto $A^n$.

***** R-coring
Corings will be the categorical dual of rings. In order to define them, we
proceed by giving defitions of coalgebra and certain properties of this kind
of algebras. Those are also the dual notions to the preliminary definitions
we described at the start of this chapter.

#+begin_definition
A *coalgebra* over a field $K$ is a *vector space* $V$ together with linear
maps $\Delta : V \longrightarrow V \otimes V$ and $\varepsilon : V \longrightarrow K$ such that:

 1. $(id \otimes \Delta) \circ \Delta = (\Delta \otimes id) \circ \Delta$
 2. $(id \otimes \varepsilon) \circ \Delta = id 
    = (\varepsilon \otimes id) \circ \Delta$
#+end_definition

When writting in coalgebras, we will follow the *Sweedler
notation*. cite:underwood15_hopf

#+begin_definition
An $\mathbf{R\text{-coring}}$ is a /coassociative/ and /counital/ /coalgebra/. It is an 
$R\text{-bimodule}$ with a /comultiplication/ $\Delta : C \longrightarrow C \otimes C$ and  a /counit/
$\epsilon : C \longrightarrow R$.
#+end_definition

A $R\text{-coring}$ is *graded* if it is equipped with a decomposition 
$C = \bigoplus_{n \in \mathbb{N}} C_n$, such that

\[\Delta(C_n) \subset \bigoplus_{p=0}^n C_p \otimes C_{n-p}.\]

***** Almost-koszul pair
#+begin_definition
An *almost-Koszul pair* is a connected $R\text{-ring}$ and $R\text{-coring}$ $(A,C)$ 
with an isomorphism $\theta_{C,A} : C_1 \longrightarrow A^1$ that satisfies the relation

\[ m^{1,1} \circ (\theta_{C,A} \otimes \theta_{C,A}) \circ \Delta_{1,1}
= 0.\]
#+end_definition

Using Sweedler notation we can rewrite the condition as follows 


\[ \sum \theta_{C,A}(c_{(1,1)}) \theta_{C,A}(c_{(2,1)}) = 0,\]

for any $c \in C_2$.

**** Almost-koszul pair complexes
Six complexes will be associated to any given Koszul pair. Its
exactness will be related, i.e., if any one of them is exact, the six
complexes will be exact. This provides a definition of Koszul
pairs relying only on this kind of complexes.

#+begin_definition
Let $(A,C)$ be an almost-Koszul pair, if we define

\[
K^{-1}_l(A,C) = R
\quad\text{ and }\quad
K^n_l(A,C) = C \otimes A^n,
\]

and the differential maps

\[
d^n_l(c \otimes a) = \sum c_{(1,p-1)} \otimes \theta_{C,A}(c_{(2,1)})a,
\]

with the exceptional case $n = -1$, where we take $d^n_l$ to be the canonical
bimodule morphisms $R \to C \otimes A^0$, mapping $1 \mapsto 1 \otimes 1 \in C_0 \otimes A^0$. We will
also define the same notion on the opposite pair as

\[
K_r^{\ast}(A,C) = K^{\ast}_l(A^{op},C^{op}).
\]
#+end_definition

#+begin_definition
Let $(A,C)$ be an almost-Koszul pair, we define

\[
K^{-1}(A,C) = C
\quad\text{ and }\quad
K^n(A,C) = C \otimes A^n\otimes C,
\]

and the differential relations given by $d^{-1} = \Delta$ and

\[
d^n = d^n_l \otimes I_C + (-1)^{n+1}I_C \otimes d^n_r.
\]
#+end_definition

#+begin_definition
Let $(A,C)$ be an almost-Koszul pair, if we define

\[
K^r_{-1}(A,C) = R
\quad\text{ and }\quad
K^r_n(A,C) = C_n \otimes A,
\]

and the differential maps

\[
d_n^r(c \otimes a) = \sum c_{(1,n-1)} \otimes \theta_{C,A}(c_{(2,1)})a.
\]

Appliying the same construction to the opposite almost-Koszul pair
gives us the complex $K^l_{\ast}$.
#+end_definition

#+begin_definition
Let $(A,C)$ be an almost-Koszul pair, we define

\[
K_{-1}(A,C) = A
\quad\text{ and }\quad
K_n(A,C) = A \otimes C_n \otimes A,
\]

and the differential relations given by $d_0$, induced by multiplication,
and

\[
d_n^{l}(a \otimes c) = \sum a\theta_{C,A}(c_{(1,1)}) \otimes c_{(2,n-1)};
\]

defining $d_n = d_n^l \otimes I_A + (-1)^nI_A\otimes d_n^r$.
#+end_definition

**** Koszul pairs
#+begin_theorem
Given an almost-Koszul pair $(A,C)$, if one of these six complexes is
exact, all of them are exact, as it is showed in cite:jarastefan10.

 * $K^{l}_{\ast}(A,C)$.
 * $K^r_{\ast}(A,C)$.
 * $K_{\ast}(A,C)$.
 * $K^{\ast}_l(A,C)$.
 * $K_r^{\ast}(A,C)$.
 * $K^{\ast}(A,C)$.
#+end_theorem

#+begin_definition
An almost-Koszul pair $(A,C)$ is said to be *Koszul* if and only if the
previously discussed complexes are exact.
#+end_definition

*** Conclusions
Starting from a very basic undergraduate mathematical level, all the
necessary definitions of categories, chain complexes and homology have
been developed in this work. This constitutes a reference for students
interested on the specific field of Koszul pairs and sets the ground
for future developments and undergraduate and graduate-level research.

$\quad$

In particular, future work should be able to find new
characterizations of Koszul pairs in terms of homology and cohomology
apart from the known characterizations found on cite:jarastefan10.

*** References
bibliographystyle:unsrt
bibliography:math.bib
** TFG I: links and resources
*** Journal
**** June 2017
***** <2017-05-31 Wed>
****** created this file.
****** read MacLane chapter III.2.
***** <2017-06-01 Thu>
****** read https://golem.ph.utexas.edu/category/2006/08/cartesian_closed_categories_an_1.html
****** started reading chapter 4 on Lecture Notes on the lambda calculus by Selinger
****** superficial complete lecture of Selinger
***** <2017-06-02 Fri>
****** read https://bartoszmilewski.com/2016/11/21/monads-programmers-definition/
****** read multiple sections of MacLane
****** wrote a mikrokosmos section
***** <2017-06-03 Sat>
****** read MacLane. Yoneda Lemma
****** exercises from MacLane
***** <2017-06-04 Sun>
****** read I.1.1 to I.1.6 of Hott book
****** installed agda on emacs
***** <2017-06-05 Mon>
****** installed hott-library on agda
****** wrote simple proofs in agda
****** read I.1.10 and I.1.11 of Hott book
***** <2017-06-06 Tue>
****** installed [[https://proofgeneral.github.io/download/][Proofgeneral]] and [[https://coq.inria.fr/][Coq]]
****** completed first chapter exercises of Software Foundations
****** added 'tasty-hunit' tests to mikrokosmos
****** added travis-ci to mikrokosmos
***** <2017-06-07 Wed>
****** read MacLane: monads and algebras
***** <2017-06-08 Thu>
****** exercises from MacLane
***** <2017-06-09 Fri>
****** read Sheaves in geometry and logic
***** <2017-06-10 Sat>
****** applied to EUTypes 2017
***** <2017-06-11 Sun>
****** exercises from chapters 1 and 2 of software foundations
***** <2017-06-12 Mon>
****** created a specific ctlc.org file
****** rewrote tfg.org
Mikrokosmos won't solve the IO problem. If IO is needed,
it can be achieved via scripts.
***** <2017-06-13 Tue>
****** installed Why3
***** <2017-06-14 Wed>
****** installed docker container for Why3 and solvers
****** installed Coq-hott library
***** <2017-06-15 Thu>
****** wrote a jupyter kernel for mikrokosmos
***** <2017-06-16 Fri>
****** minor changes on mikrokosmos
****** wrote mikrokosmos user's guide
***** <2017-06-17 Sat>
****** wrote highlighter for Jupyter Notebook
****** solved minor problems on Jupyter output formatting
****** saw [[https://www.youtube.com/watch?v=21qPOReu4FI][Five Stages of Accepting Constructive Mathematics, by Andrej Bauer]]
****** wrote a section on simply typed lambda calculus
***** <2017-06-18 Sun>
****** started reading Types and programming languages
****** started following the agda tutorial
***** <2017-06-19 Mon>
****** wrote notes on the first lecture on HoTT.
****** wrote notes on the second lecture on HoTT.
***** <2017-06-20 Tue>
****** done homework 1 of the course on HoTT.
****** wrote notes on the third lecture on HoTT.
****** wrote notes on the fourth lecture on HoTT.
***** <2017-06-21 Wed>
****** wrote notes on the fifth lecture on HoTT.
***** <2017-06-22 Thu>
****** wrote notes on the sixth lecture on HoTT.
****** wrote notes on the seventh lecture on HoTT.
****** wrote notes on the eighth lecture on HoTT.
***** <2017-06-23 Fri>
****** wrote notes on the ninth lecture on HoTT.
****** wrote notes on the tenth lecture on HoTT.
****** wrote an org-mode template for the thesis.
***** <2017-06-24 Sat>
****** [[http://orgmode.org/cgit.cgi/org-mode.git/commit/?id=e903288e5080775cbd4d87c69deeba3268cda5c1][fixed bug]] in org-mode
***** <2017-06-25 Sun>
****** wrote notes on the eleventh lecture on HoTT.
****** wrote notes on the twelfth lecture on HoTT.
****** wrote notes on the thirteenth lecture on HoTT.
****** wrote notes on the fourteenth lecture on HoTT.
***** <2017-06-26 Mon>
****** wrote notes on the fiveteenth lecture on HoTT.
***** <2017-06-27 Tue>
****** [[https://math.stackexchange.com/questions/2337093/does-homotopy-type-theory-have-a-computational-interpretation][has HoTT a computational interpretation?]]
***** <2017-06-28 Wed>
***** <2017-06-29 Thu>
****** wrote hott code in agda
***** <2017-06-30 Fri>
****** wrote hott code in agda
**** July 2017
***** <2017-07-01 Sat>
***** <2017-07-02 Sun>
****** wrote hott code in agda
***** <2017-07-04 Tue>
****** wrote notes on the 16th lecture on HoTT.
***** <2017-07-05 Wed>
****** wrote notes on the 17th lecture on HoTT.
****** wrote notes on the 18th lecture on HoTT.
***** <2017-07-06 Thu>
****** wrote notes on the 19th lecture on HoTT.
****** wrote notes on the 20th lecture on HoTT.
***** <2017-07-07 Fri>
****** wrote notes on the 21th lecture on HoTT.
****** wrote notes on the 22th lecture on HoTT.
****** wrote notes on the 23th lecture on HoTT.
****** finished course on HoTT.
***** <2017-07-08 Sat>
****** EUTypes 2017. Ohrid, Macedonia.
***** <2017-07-09 Sun>
****** EUTypes 2017. Ohrid, Macedonia.
***** <2017-07-10 Mon>
****** EUTypes 2017. Ohrid, Macedonia.
***** <2017-07-11 Tue>
****** EUTypes 2017. Ohrid, Macedonia.
***** <2017-07-12 Wed>
****** EUTypes 2017. Ohrid, Macedonia.
***** <2017-07-13 Thu>
****** EUTypes 2017. Ohrid, Macedonia.
***** <2017-07-14 Fri>
****** EUTypes 2017. Ohrid, Macedonia.
***** <2017-07-15 Sat>
****** EUTypes 2017. Ohrid, Macedonia.
***** <2017-07-16 Sun>
****** read about the continuum hypothesis
***** <2017-07-17 Mon>
****** solved a bug in the stack tool by updating.
****** mikrokosmos starts using GHC 8.0.2.
****** color and verbose options for mikrokosmos.
****** multiple line format on mikrokosmos.
***** <2017-07-18 Tue>
****** Ski abstraction on mikrokosmos.
***** <2017-07-19 Wed>
****** Ski option for the user.
****** pip-installable jupyter kernel.
***** <2017-07-20 Thu>
****** Closed multiple minor issues on mikrokosmos
***** <2017-07-21 Fri>
****** Read about algebraic Lawvere theories
****** Rewrote installation
****** Rewrote user's guide
****** Mikrokosmos tutorial: part 1
***** <2017-07-22 Sat>
****** Published mikrokosmos v0.3.0
****** Mikrokosmos tutorial: part 2
***** <2017-07-23 Sun>
****** Untyped lambda calculus
***** <2017-07-24 Mon>
****** Wrote: Church-Rosser theorem
****** Wrote: Programming in the untyped \lambda-calculus
***** <2017-07-25 Tue>
****** Types on mikrokosmos
****** Type unification algorithm
****** Type inference algorithm
***** <2017-07-26 Wed>
****** Type normalization algorithm
****** Update tutorial and user's guide
***** <2017-07-29 Sat>
****** Read about Topoi
***** <2017-07-30 Sun>
****** Rewrote STCL using only the implication
****** Wrote a section on Curry typing
***** <2017-07-31 Mon>
****** Wrote about the curry-howard correspondence
****** Implementing generalized STLC types on mikrokosmos
**** August 2017
***** <2017-08-01 Tue>
****** Wrote about the curry-howard correspondence
****** Wrote about natural deduction
***** <2017-08-02 Wed>
****** Refactored mikrokosmos code
****** Updated jupyter-kernel
****** Added unicode and agda output to the latex template
***** <2017-08-03 Thu>
****** updated user's guide
****** updated tutorial
****** wrote programming on STLC
***** <2017-08-04 Fri>
****** wrote about normalization and evaluation strategies
***** <2017-08-05 Sat>
****** wrote about categories
***** <2017-08-06 Sun>
****** tried (and failed) to create a debian package for mikrokosmos
***** <2017-08-07 Mon>
****** Wrote about basic category theory
***** <2017-08-08 Tue>
****** Heyting algebras
****** Minor changes to Mikrokosmos
***** <2017-08-09 Wed>
****** Russell's paradox in agda
***** <2017-08-12 Sat>
****** Wrote about Heyting algebras
***** <2017-08-13 Sun>
****** Talk on Categorical foundations by Awodey
***** <2017-08-14 Mon>
****** Notes on categorical foundations
****** Fix minor bugs on mikrokosmos
****** Use macros on latex
***** <2017-08-15 Tue>
****** Created server on Digital ocean
****** Created domain name on Namecheap
****** Created SSL certificate
****** Installed mikrokosmos in the server
****** Installed JupyterHub
****** GitHub OAuth
****** trymikrokosmos.me
***** <2017-08-16 Wed>
****** Wrote 7 tutorials on mikrokosmos
****** Updated libraries on trymikrokosmos.me
****** Minor additions to the category theory chapter
****** Wrote about SKI combinators
****** Wrote about evaluation and output in mikrokosmos
***** <2017-08-17 Thu>
****** Tested mikrokosmos under NixOS
***** <2017-08-18 Fri>
****** Wrote about pure type systems and the lambda cube
***** <2017-08-19 Sat>
****** Wrote about Haskell
****** Wrote about the lambda cube
***** <2017-08-20 Sun>
****** Algebraic theories
****** Models as functors
****** Closed multiple issues on Mikrokosmos
***** <2017-08-21 Mon>
****** Introduction to topos theory
****** Derivatives of regular types and zippers
***** <2017-08-23 Wed>
****** Read An introduction to topos theory.
***** <2017-08-24 Thu>
****** Wrote about dinatural transformations.
***** <2017-09-25 Mon>
***** <2017-09-26 Tue>
****** Experimenting with GHCJS
***** <2017-09-27 Wed>
****** MikrokosmosJS
***** <2017-09-28 Thu>
****** Codemirror pads for MikrokosmosJS
***** <2017-09-29 Fri>
****** Tutorials for mikrokosmos
****** Gentzen deduction trees
***** <2017-09-30 Sat>
****** Mikrokosmos 0.7.0
****** Update libraries
***** <2017-08-31 Thu>
****** Wrote tutorials for Mikrokosmos
**** September 2017
***** <2017-09-01 Fri>
****** JupyterHub server on iemath
****** Testing Mikrokosmos on NixOS
***** <2017-09-02 Sat>
****** Lawvere algebraic theories
***** <2017-09-03 Sun>
****** From sets to types to categories to sets
***** <2017-09-04 Mon>
****** Cartesian closed categories and lambda theories
***** <2017-09-05 Tue>
****** Meeting
****** Rewrote first sections on untyped lambda calculus
***** <2017-09-06 Wed>
****** Rewrote untyped lambda calculus
****** Added a section on SKI combinators
***** <2017-09-07 Thu>
***** <2017-09-08 Fri>
***** <2017-09-09 Sat>
***** <2017-09-10 Sun>
***** <2017-09-11 Mon>
****** Ends
****** 2-categories
***** <2017-09-16 Sat>

*** Notes
**** [[file:ctlc.org][Category theory and lambda-calculus]]
**** [[file:categoriesfortheworking.org][Categories for the working mathematician - MacLane]]
**** [[file:lecturesonthelambdacalculus.org][Lecture notes on the lambda calculus - Selinger]]
**** [[file:homotopytypetheory.org][Homotopy type theory - Univalent foundations]]
**** [[file:sheavesgeometrylogic.org][Sheaves in geometry and logic - MacLane]]
**** [[file:typesandprogramminglanguages.org][Types and programming languages - Pierce]]
**** DONE [[file:courseonhott.org][Course on Homotopy Type Theory - Robert Harper]]
**** [[file:introcategoricallogic.org][Introduction to categorical logic - Bauer, Awodey]]
*** Tasks
**** Write
***** Ideas
****** Syntax and semantics
****** Variable capture and deBruijn indices.
***** Mikrokosmos section
***** Untyped lambda calculus section
***** Type theory introduction
***** Category theory introduction
***** Wikipedia
****** Agda
**** Read
***** From sets to categories to types to sets
***** Elienberg categorical foundations
***** Extensionality on categories
Commutativity and efficiency

**** [#A] Mikrokosmos
Mikrokosmos is a lambda calculus interpreter.

***** TODO Implement type theory http://www.cse.chalmers.se/%7Ebengt/papers/GKminiTT.pdf
***** TODO Implement simply-typed lambda calculus with products and a terminal type
It is the language of CCCs.
It can be showed that it is strongly normalizable.

***** TODO Implement Hindley-Milner or System F
System F has no decidable inference, you have to write more.
Hindley-Milner does not allow for types on quantifiers.

System F and the Girard-Reynolds isomorphism seem like great ideas.

***** DONE [#C] Multiple lines on modules
Multiple line notation should be allowed by joining multiple lines whenever
they start with a <TAB> or a space.
***** DONE Write tests
***** DONE Should Multibimap be a package on its own?
***** Compile to categories
***** CHECK Seminars about mikrokosmos
***** Dependent types
http://math.andrej.com/2012/11/08/how-to-implement-dependent-type-theory-i/
***** Write a pygments lexer
http://pygments.org/docs/lexerdevelopment/

***** Emacs theme
***** DONE Logo background should be a "cosmos" background
***** DONE [#A] Module system
The module system is being written.

I should first find every module I have to load and, only then,
load all of them in a single command.

Every module should have a list of DEPENDENCY directives.
***** DONE [#B] Jupyter kernel
[[https://ipython.org/ipython-doc/3/development/kernels.html][Making kernels for IPython]]
[[http://andrew.gibiansky.com/blog/ipython/ipython-kernels/]]
***** DONE Change notation
In order to avoid confusions with types

#+BEGIN_SRC haskell
:load -- !load
qwer != asdf -- qwer ?= asdf
#+END_SRC

***** DONE Use a .mikrokosmos config file
Is it really necessary?

***** DONE Config files
A simply typed mikroskosmos would be great for writing configuration files.

***** TODO compiling mikrokosmos
It could be compiled to C.

***** TODO Write a compiler
Maybe a compiler would work better than an interpreter.

***** TODO Optimizing mikrokosmos in Agda
It seems very difficult to write a mikrokosmos interpreter on Agda.

***** TODO [#C] The IO problem
How to declare an imperative - Wadler

****** syscall proposal
******* Output
#+BEGIN_SRC 
#printNum (\s.\z.(s (s z)))
#+END_SRC

printNum.hs
#+BEGIN_SRC haskell
num :: Lambda -> Int
num Nil = 0
num (Lambda x s) = 1 + printnum s

main :: IO ()
main = do
  l <- read :: Lambda
  print $ printnum l
  return ()
#+END_SRC

******* Input
#+BEGIN_SRC
#readNum ()
#+END_SRC

****** syscall with literals
Add a "literal" type.

******* Output
#+BEGIN_SRC mikrokosmos
churchLiteral n = n (\k . syscall ("increment.sh" k)) "0"
printLiteral l = syscall2 ""
#+END_SRC

******* Input
It would use =$= as an antiliteral. Any string started on =$= would be interpreted as
a lambda term.

#+BEGIN_SRC mikrokosmos
readChurch = syscall "readChurch"
#+END_SRC

=readChurch= would return something as ="@(\s.\z.s (s (s z)))"=. Two literals applied one
over thw other would be reinterpreted as their concatenation.
**** [#C] Write articles
***** TODO Adjoint functors post
***** TODO Church-Rosser post
***** TODO Wikipedia article Church-Rosser
**** Ask for a type theory book on SO
**** Ask for a category theory + lambda calculus book on SO
*** Resources
**** Books on categories and types for the TFG
***** Books on category theory
****** [[http://www.maths.ed.ac.uk/~aar/papers/maclanecat.pdf][Categories for the working mathematician - Saunders Mac Lane]]
A complete course on category theory.

  * Category theory.
  * Monoidal categories.
  * 2-categories.

****** [[https://github.com/Mzk-Levi/texts/blob/master/Lambek%2520J.,%2520Scott%2520P.J.%2520Introduction%2520to%2520Higher%2520Order%2520Categorical%2520Logic.pdf][Introduction to Higher order categorical logic - Lambek]]
A course in categorical logic.

  * Cartesian closed categories.
  * Type theory and toposes.

****** [[https://s3.amazonaws.com/arena-attachments/325201/2ff932bf546d8985eb613fccf02b69c7.pdf][Conceptual Mathematics: a first introduction to categories - Lawvere]]
A course on category theory, oriented towards categorical logic.

  * Basic cateogory theory
  * Categorical logic, toposes

****** [[http://paultaylor.eu/prafm/][Practical foundations of Mathematics - Paul Taylor]]
A type-oriented foundation of mathematics.

  * Type theory.
  * Cartesian closed categories.
  * Algebra of dependent types.

****** [[http://tocs.ulb.tu-darmstadt.de/35821485.pdf][Sheaves in Geometry and Logic - MacLane, Moerdijk]]
A course on sheaves, topoi and logic. It assumes a categorical background.

  * Grothendieck topologies and sheaves.
  * Topoi and logic.
  * Classifying topoi.

****** [[http://www.mathematik.tu-darmstadt.de/~streicher/CTCL.pdf][Introduction to category theory and categorical logic - Thomas Streicher]]
Basic notions of category theory and a bit on \lambda-calculus,
cartesian-closed categories and toposes.

  * Basic category theory
  * Cartesian closed categories and \lambda-calculus
  * Logic of toposes
  
****** An introduction to topos theory - Kostecki
****** [[http://www.tac.mta.ca/tac/reprints/articles/12/tr12.pdf][Toposes, Triples and Theories - Barr & Wells]]
***** Books on \lambda-calculus
****** [[http://pages.di.unipi.it/ferrari/CORSI/PR2/HarperBook.pdf][Practical foundations for Programming Languages - Robert Harper]]
A complete course on types, syntax and programming languages.

  * Judgements and rules.
  * Levels of syntax.
  * Data types.
  * System F.
  * Types and propositions.
  * Laziness, paralellism and concurrency.

****** Types and programming languages - Benjamin C. Pierce
****** [[http://www.mscs.dal.ca/~selinger/papers/lambdanotes.pdf][Lecture notes on the lambda calculus - Peter Selinger]]
****** [[https://homotopytypetheory.org/book/][Homotopy Type Theory Book - The univalent foundations program]]
The foundational book on homotopy type theory.
****** [[http://pds14.egloos.com/pds/200901/16/93/Lambda-Calculus_and_Combinators.pdf][Lambda Calculus and Combinators. An Introduction - Hindley, Seldin]]
Basic introduction to the \lambda-calculus.

  * Combinatory logic.
  * Formal theories of \lambda-calculus.
  * Typing.
  * Models of \lambda-calculus.

****** [[http://www.cse.chalmers.se/research/group/logic/book/book.pdf][Programming in Martin-Löf's Type Theory - Nordström, Petersson]]
Martin-Löf type theory and how to write languages based on it.
Based on sets.

****** [[https://github.com/pigworker/CS410-14][CS410 Advanced Functional Programming - Connor McBride]]
A course on Agda.

  * Propositions as types.
  * Dependent types.
****** Software foundations - Benjamin C. 
**** Blog articles and web pages
***** [[https://hottheory.files.wordpress.com/2012/08/hott2.pdf][hott2.pdf]] - Master thesis on HoTT
***** [[https://en.wikipedia.org/wiki/Typed_lambda_calculus][Typed lambda calculus - Wikipedia]]
The kinds of typed lambda calculi.
http://homepages.inf.ed.ac.uk/wadler/papers/esslli/esslli-1.pdf

A typed lambda calculus in which the user can set the base types
and its constants. If we add products and a terminal type, this is
the language of cartesian closed categories; and a fragment of
intuitionistic logic called minimal logic.

More precisely, there exist functors between the category of Cartesian
closed categories, and the category of simply-typed lambda theories.

Not making assumptions about the type gives us something that behaves
like type variables.

***** https://github.com/Zepheus/SystemF
A SystemF implementation on Haskell following the B. Pierce's book.
***** [[https://ncatlab.org/homotopytypetheory/files/Joyal.pdf][Categorical Homotopy Type Theory - Joyal.pdf]]
***** [[https://homotopytypetheory.org/2011/04/23/running-circles-around-in-your-proof-assistant/][Running Circles Around (In) Your Proof Assistant; or, Quotients that Compute | Homotopy Type Theory]]
How to implement HIT on Agda using Licata's trick.
***** [[http://sweet.ua.pt/dirk/ct2015/slides/Guallart.pdf][Guallart.pdf]] A comparison between ITT and COC
It uses a categorical formulation of STLC similar to H-M.
***** [[http://www.cse.chalmers.se/research/group/logic/Types/tutorials.html][The Types Project]]
***** [[https://en.wikipedia.org/wiki/Intuitionistic_type_theory#Categorical_models_of_type_theory][Intuitionistic type theory - Wikipedia]] - Categorical models
***** [[https://www.microsoft.com/en-us/research/wp-content/uploads/1997/01/henk.pdf][The Henk intermediate language. core.dvi - henk.pdf]]
Based on the lambda cube with a single syntax for terms, types and kinds.
***** [[https://stackoverflow.com/questions/23995736/example-of-type-in-system-f-that-is-not-available-in-hindley-milner-type-inferen][Example of type in System F that is not available in Hindley Milner type inference - Stack Overflow]]
***** [[http://typessummerschool07.cs.unibo.it/courses/coquand-1.pdf][Models of type theory - Coquand]]
***** https://en.wikipedia.org/wiki/Pure_type_system
***** [[http://strictlypositive.org/calculus/][Differential Calculus with Datatypes]]
***** TODO [[http://people.inf.elte.hu/divip/AgdaTutorial/Index.html][Agda Tutorial]]
***** [[https://cs.stackexchange.com/questions/14674/intro-to-martin-l%C3%B6f-type-theory][logic - Intro to Martin-Löf type theory - Computer Science Stack Exchange]]

***** [[https://plato.stanford.edu/entries/type-theory-intuitionistic/][Intuitionistic Type Theory (Stanford Encyclopedia of Philosophy)]]
Intuitionistic type theory is thus a typed functional programming
language with the unusual property that all programs terminate.
***** DONE [[https://www.youtube.com/watch?v=21qPOReu4FI][Five Stages of Accepting Constructive Mathematics - Andrej Bauer - YouTube]]
"Taking the Principle of the Excluded Middle from the mathematician... 
is the same as ... prohibiting the boxer the use of his fists."
- /David Hilbert/

 * [[https://en.wikipedia.org/wiki/Brouwer%E2%80%93Hilbert_controversy][Brouwer–Hilbert controversy - Wikipedia]]

***** [[https://www.quora.com/What-is-the-best-textbook-for-Category-theory][What is the best textbook for category theory - Edward Kmett]]
***** DONE [[https://golem.ph.utexas.edu/category/2006/08/cartesian_closed_categories_an_1.html][CCCs and the λ-calculus | The n-Category Café]] :math:
***** [[https://github.com/mattearnshaw/lawvere][mattearnshaw/lawvere: The collected works of F. W. Lawvere]] :logic:math:
***** [[https://www.cs.cmu.edu/~rwh/][Robert Harper's Home Page]]                                      :math:logic:
***** [[http://www.jonmsterling.com/index.html][Notes from Jon Sterling Thought]]           :math:logic:philosophy:
***** [[http://www2.tcs.ifi.lmu.de/~abel/MscThesisJoakimOhman.pdf][MscThesisJoakimOhman.pdf]] A logical relation for dependent type theory :mikrokosmos:types:logic:
Talks about identity types.
***** [[https://mathoverflow.net/questions/152497/formalizations-of-category-theory-in-proof-assistants][Formalizations of category theory in proof assistants - MathOverflow]] 
***** [[http://strictlypositive.org/Easy.pdf][Easy.pdf]] Simply Easy! - Conor McBride            :mikrokosmos:math:
***** [[https://github.com/lambda-pi-plus/lambda-pi-plus][lambda-pi-plus: A simple Depdently-Typed Language for Research&Learning]] :mikrokosmos:math:
***** [[http://strictlypositive.org/Easy.pdf][Easy.pdf]] Implementation of dependent lambda calculus :math:logic:mikrokosmos:
***** [[https://www2.eecs.berkeley.edu/Pubs/TechRpts/2007/EECS-2007-113.pdf][EECS-2007-113.pdf]] Adam Chipala - Implementing dependent types :types:math:logic:
***** [[http://math.andrej.com/2012/11/08/how-to-implement-dependent-type-theory-i/][How to implement dependent type theory I | Mathematics and Computation]] :math:types:
***** [[http://www.hedonisticlearning.com/posts/category-theory-syntactically.html][Category Theory, Syntactically ]] :math:logic:
***** [[https://github.com/Mzk-Levi/texts][Mzk-Levi/texts]] - Type theory and categorical logic texts :math:types:categories:
***** [[http://www.cs.ru.nl/B.Jacobs/CLT/bookinfo.html][Categorical Logic and Type Theory]] :math:categories:logic:
***** [[https://www.newton.ac.uk/event/bprw01][Computer-aided mathematical proofs]]              :types:logic:math:
***** [[http://math.ucr.edu/home/baez/topos.html][Topos theory in a nutshell]]
***** [[http://www.logicmatters.net/tyl/][Logic matters]]
***** [[https://mathoverflow.net/questions/69251/is-mac-lane-still-the-best-place-to-learn-category-theory/70891#70891][Is MacLane still the best place to learn category theory?]]
***** Homotopy type theory
****** [[http://dlicata.web.wesleyan.edu/pubs/lb14cubical/lb14cubes-oxford.pdf][A cubical type theory]]
****** [[https://ncatlab.org/homotopytypetheory/files/AwodeyDMVrev.pdf][AwodeyDMVrev.pdf]] Cubical type theory
****** [[http://www.helsinki.fi/lc2015/materials/slides_awodey.pdf][slides_awodey.pdf]] Cubical Type theory
****** [[http://www.cse.chalmers.se/%7Ecoquand/cubicaltt.pdf][Cubical Type Theory - Coquand, Cohen]]
****** [[http://neil-strickland.staff.shef.ac.uk/formal/][Formalised mathematics]] in Agda
****** https://mathoverflow.net/questions/156238/function-extensionality-does-it-make-a-difference-why-would-one-keep-it-out-of/156295#156295
The conversation here between Sterling and Bauer is very interesting.
****** [[http://math.andrej.com/2013/08/28/the-elements-of-an-inductive-type/][The elements of an inductive type | Mathematics and Computation]]
****** [[https://github.com/HoTT/book/issues/460][Path induction again (sorry) · Issue #460 · HoTT/book]]
****** [[https://www.youtube.com/watch?v=fJJ7NhkySXM][Homotopy Group - (1)Dan Licata, (2)Guillaume Brunerie, (3)Peter Lumsdaine - YouTube]]
****** [[https://homotopytypetheory.org/links/][Links | Homotopy Type Theory]]
****** [[https://agda.readthedocs.io/en/latest/language/cubical.html][Cubical Type Theory in Agda — Agda 2.6.0 documentation]]
****** [[http://www-sop.inria.fr/members/Anders.Mortberg/slides/TTT-cubicaltt.pdf][Cubical Type Theory: a constructive interpretation of the univalence axiom - TTT-cubicaltt.pdf]]
**** Articles
***** [[http://www.ams.org/notices/201309/rnoti-p1164.pdf][The Univalence Axiom in Homotopy Type Theory]] - Awodey
***** [[http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.207.4309][CiteSeerX — Observational Equality, Now!]] - McBride, Altenkirch
***** [[http://www.cse.chalmers.se/~ulfn/papers/tphols09/tutorial.pdf][A brief overview of Agda]] - Ulf Norell
***** [[http://homepages.inf.ed.ac.uk/wadler/papers/propositions-as-types/propositions-as-types.pdf][propositions-as-types.pdf]] Philip Wadler
***** TODO [[http://imps.mcmaster.ca/doc/seven-virtues.pdf][seven-virtues]] Seven virtues of type theory
***** TODO [[http://conal.net/papers/compiling-to-categories/compiling-to-categories.pdf][Compiling to categories]]
**** Mikrokosmos resources
***** [[http://www.madore.org/~david/computers/callcc.html][A page about call/cc]]
***** [[http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=3FF1F113BC01E491476F4F1930F838FE?doi=10.1.1.44.1497&rep=rep1&type=pdf][An untyped lambda calculus with IO]]
** Miscellany
*** CARDS
**** Partitions of a set                                                                                     :drill:
:PROPERTIES:
:ID:       6e56efc2-7a11-42dd-b8cb-815b65f26021
:END:
Number of partitions of a set of $n$ elements.
***** Answer
In combinatorial mathematics, *Bell numbers* count the partitions of a set.
https://en.wikipedia.org/wiki/Bell_number

** Notas sueltas y borradores
*** Teorema de aproximación de Weierstrass                                                                    :extra:
# La generalización de Stone es mucho más elegante, simple y general.

**** Convolución
La convolución de dos funciones $f,g \colon \mathbb{R} \to \mathbb{R}$ es la función

\[
(f \ast g)(x) := \int_{\mathbb{R}}f(x-t)g(t)\,dt,
\]

que no tiene por qué estar bien definida.

**** Propiedades de la convolución
La convolución es

 * conmutativa, $f \ast g = g \ast f$,
 * asociativa, $f \ast (g \ast h) = (f \ast g) \ast h$
 
***** Proof
# Estaría bien una demostración que fuera usando conjuntos de integración.
# Asociatividad por Fubini.

**** Identidades aproximadas
Una *identidad aproximada* es una sucesión de funciones $g_n$ tales que

 * $\int_{\mathbb{R}} g_n = 1$,

 * $\int_{\mathbb{R}}\abs{g_n} < M$ acotadas por una constante uniforme,

 * $\forall \delta,\varepsilon > 0\colon \exists n_0 \colon \forall n \geq n_0\colon \forall x \geq \delta\colon |g_n(x)| < \varepsilon$,

 * $g_n(x) = 0$ para $|x|>1$.

**** Aproximación por identidades
Para $f$ continua y nula fuera de $[0,1]$ y para $g_n$ identidad aproximada
se tiene $g_n\ast f \overset{c.u.}\longrightarrow f$.

***** Proof
Fijado un $\varepsilon > 0$ probaremos $\abs{(f \ast g_n)(x) - f(x)} < \varepsilon$. Al ser $f$ continua
en el compacto $[0,1]$, es uniformemente continua y existe $\delta$ tal que para
cualquier $x \in \mathbb{R}$ y $t \in (x-\delta,x+\delta)$ se tiene
\[
\abs{f(x) - f(x-t)} < \frac{\varepsilon}{2M},
\]
donde $M$ es la constante que acota las integrales en valor absoluto de $g_n$.
Por otro lado, por Teorema de Weierstrass, existe una acotación $\abs{f(x)} \leq C$,
y podemos usar la propiedad de la identidad aproximada $g_n$ para
tener que existe un $N$ tal que para todo $n \geq N$ y $|t| > \delta$ se tiene $\abs{g_n(t)} < \frac{\varepsilon}{8C}$.
Ahora, podemos usar lo que acabamos de probar y las propiedades de
la identidad aproximada para tener
\[\begin{aligned}
\abs{(f \ast g_n)(x) - f(x)} &= 
\abs{\int_{-\delta}^{\delta} f(x-t)g_n(t)\,dt - f(x)\int_{-\delta}^{\delta} g_n(t)\,dt} \\&=
\abs{\int_{-\delta}^{\delta} \Big(f(x-t) - f(x)\Big)g_n(t)\,dt} \\&\leq
\int_{-\delta}^{\delta} \abs{f(x-t)-f(x)}\abs{g_n(t)}\,dt +
\int_{|t| > \delta} \Big(\abs{f(x-t)}+\abs{f(x)}\Big)\abs{g_n(t)}\,dt \\&\leq
\frac{\varepsilon}{2M}\int_{-\delta}^{\delta} \abs{g_n(t)}\,dt +
2C\int_{|t| > \delta} \abs{g_n(t)}\,dt \\&\leq
\frac{\varepsilon}{2} + 2C\frac{2\varepsilon}{8C} < \varepsilon.
\end{aligned}\]

**** Convolución de polinomios
Sea $f \colon [0,1] \to \mathbb{R}$ continua y con $f(0)=f(1)=0$, y sea $P$ un polinomio
restringido a $[-1,1]$; entonces $f \ast P$ es una función polinomial.

***** Proof
Nótese que al ser $P$ un polinomio, $P(x-t)f(t)$ puede escribirse
como una suma de términos de la forma $a_ix^jt^kf(t)$ por lo que podemos
escribir.
\[
\int_{\mathbb{R}}P(x-t)f(t)\,dt =
\sum a_ix^j \left(\int_{\mathbb{R}} t^kf(t)\,dt\right).
\]

**** Polinomios para aproximación
La familia de polinomios $Q_n(x) = C_n(1-x^2)^n$ restringidos a $[-1,1]$
y con 
\[
C_n = \sum_{k=0}^n (-1)^k\frac{2}{2k+1}{n \choose k},
\]
entonces $Q_n$ es una identidad aproximada.

# TODO: Integración por partes
***** TODO Proof

**** TODO Teorema de aproximación de Weierstrass
**** TODO Teorema de aproximación en localmente compactos
* Local variables                                                                                              :ignore:
# Local Variables:
# eval: (rainbow-delimiters-mode -1)
# org-tags-column: -119
# org-latex-inputenc-alist: (("utf8" . "utf8x"))
# eval: (setq org-latex-default-packages-alist (cons '("mathletters" "ucs" nil) org-latex-default-packages-alist))
# End:
